[
    {
        "id": "test_0",
        "question": "Calculate the de Broglie wavelength for (a) an electron with a kinetic energy of $100 \\mathrm{eV}$",
        "golden_answers": [
            " 0.123"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 11469371,
                    "contents": "The development of soviet optics and spectroscopy during the past fifty years.\nA history of Soviet spectroscopy is given, with special emphasis on various areas indicating the earliest workers in each specialty and their principal successors; for example, the work of Rozhdestvenskii (anomalous dispersion); Fok (self-consistant field calculations), Terenin (photochemistry, atomic beams), Mandelstam (combination scattering), Vavilov (luminescence, quantum properties of light), Cerenkov (radiation), Chaika (atomic lifetimes), Gross (excitons), and Volkenstein (molecular vibrations).",
                    "score": 0.8805903196334839
                },
                {
                    "id": 9553079,
                    "contents": "The efficiency curve: a new function.\nWorking from first principles, an efficiency curve function has been developed by considering the physics of photon transport through matter. The function has been compared to other function in popular usage and been found to fit the data better especially about the knee of the curve. The main disadvantage of the new function is that it is data hungry, but this can be overcome by use of Monte Carlo simulations.",
                    "score": 0.8800036311149597
                },
                {
                    "id": 23547850,
                    "contents": "An electron walks into a quantum bar….\nQuantum electron-light interaction may find use in microscopy applications.",
                    "score": 0.8797756433486938
                },
                {
                    "id": 15592425,
                    "contents": "Note: Derivation of two-photon circular dichroism--Addendum to \"Two-photon circular dichroism\" [J. Chem. Phys. 62, 1006 (1975)].\nThis addendum shows the detailed derivation of the fundamental equations for two-photon circular dichroism which are given in a very condensed form in the original publication [I. Tinoco, J. Chem. Phys. 62, 1006 (1975)]. In addition, some minor errors are corrected and some of the derivations in the original publication are commented. ",
                    "score": 0.8736984133720398
                },
                {
                    "id": 16592458,
                    "contents": "Unusual distance dependences of electron transfer rates.\nUsually the rates for electron transfer (kET) decrease with increasing donor-acceptor distance, but Marcus theory predicts a regime in which kET is expected to increase when the transfer distance gets longer. Until recently, experimental evidence for such counter-intuitive behavior had been very limited, and consequently this effect is much less well-known than the Gaussian free energy dependence of electron transfer rates leading to the so-called inverted driving-force effect. This article presents the theoretical concepts that lead to the prediction of electron transfer rate maxima at large donor-acceptor distances, and it discusses conditions that are expected to favor experimental observations of such behavior. It continues with a consideration of specific recent examples in which electron transfer rates were observed to increase with increasing donor-acceptor distance, and it closes with a discussion of the importance of this effect in the context of light-to-chemical energy conversion. ",
                    "score": 0.8729709386825562
                },
                {
                    "id": 4736833,
                    "contents": "Observation of the Kapitza-Dirac effect.\nIn their famous 1927 experiment, Davisson and Germer observed the diffraction of electrons by a periodic material structure, so showing that electrons can behave like waves. Shortly afterwards, Kapitza and Dirac predicted that electrons should also be diffracted by a standing light wave. This Kapitza-Dirac effect is analogous to the diffraction of light by a grating, but with the roles of the wave and matter reversed. The electron and the light grating interact extremely weakly, via the 'ponderomotive potential', so attempts to measure the Kapitza-Dirac effect had to wait for the development of the laser. The idea that the underlying interaction with light is resonantly enhanced for electrons in an atom led to the observation that atoms could be diffracted by a standing wave of light. Deflection of electrons by high-intensity laser light, which is also a consequence of the Kapitza-Dirac effect, has also been demonstrated. But the coherent interference that characterizes wave diffraction has not hitherto been observed. Here we report the diffraction of free electrons from a standing light wave-a realization of the Kapitza-Dirac effect as originally proposed.",
                    "score": 0.8727468252182007
                },
                {
                    "id": 14583760,
                    "contents": "The refractive index in electron microscopy and the errors of its approximations.\nIn numerical calculations for electron diffraction often a simplified form of the electron-optical refractive index, linear in the electric potential, is used. In recent years improved calculation schemes have been proposed, aiming at higher accuracy by including higher-order terms of the electric potential. These schemes start from the relativistically corrected Schrödinger equation, and use a second simplified form, now for the refractive index squared, being linear in the electric potential. The second and higher-order corrections thus determined have, however, a large error, compared to those derived from the relativistically correct refractive index. The impact of the two simplifications on electron diffraction calculations is assessed through numerical comparison of the refractive index at high-angle Coulomb scattering and of cross-sections for a wide range of scattering angles, kinetic energies, and atomic numbers.",
                    "score": 0.8718098998069763
                },
                {
                    "id": 13955594,
                    "contents": "A surprise in the first Born approximation for electron scattering.\nA standard textbook derivation for the scattering of electrons by a weak potential under the first Born approximation suggests that the far-field scattered wave should be in phase with the incident wave. However, it is well known that waves scattered from a weak phase object should be phase-shifted by π/2 relative to the incident wave. A disturbing consequence of this missing phase is that, according to the Optical Theorem, the total scattering cross section would be zero in the first Born approximation. We resolve this mystery pedagogically by showing that the first Born approximation fails to conserve electrons even to first order. Modifying the derivation to conserve electrons introduces the correct phase without changing the scattering amplitude. We also show that the far-field expansion for the scattered waves used in many texts is inappropriate for computing an exit wave from a sample, and that the near-field expansion also give the appropriately phase-shifted result.",
                    "score": 0.8714994192123413
                },
                {
                    "id": 15506163,
                    "contents": "Ground State Electroluminescence.\nElectroluminescence, the emission of light in the presence of an electric current, provides information on the allowed electronic transitions of a given system. It is commonly used to investigate the physics of strongly coupled light-matter systems, whose eigenfrequencies are split by the strong coupling with the photonic field of a cavity. Here we show that, together with the usual electroluminescence, systems in the ultrastrong light-matter coupling regime emit a uniquely quantum radiation when a flow of current is driven through them. While standard electroluminescence relies on the population of excited states followed by spontaneous emission, the process we describe herein extracts bound photons from the dressed ground state and it has peculiar features that unequivocally distinguish it from usual electroluminescence. ",
                    "score": 0.8703837394714355
                },
                {
                    "id": 21609262,
                    "contents": "Beyond the One-Electron Approximation: Density of States for Interacting Electrons.\nThe concept \"density of states\" can be given many different meanings when we go beyond the one-electron approximation. In this survey we concentrate on the definition tied to excitation processes, where one electron is added or removed from the solid. We discuss the one-particle spectral function for conduction and core electrons in metals, how it can be approximately calculated, and how it can be related to different types of experiments like x-ray photoemission, x-ray emission and absorption, photoemission and optical absorption in the ultraviolet, and the Compton effect. We also discuss the form of the exchange-correlation potential for use in band structure calculations.",
                    "score": 0.8702780604362488
                },
                {
                    "id": 15144670,
                    "contents": "Ruling Engines, Diffraction Gratings and Wavelength Measurements before the Rowland Era.\nDiffraction gratings have contributed enormously to modern science. Although some historians have written about them, there is much more to be brought to light. This paper discusses their development and use in the period up to about 1880 before Rowland began to produce them. Rittenhouse described the action of a diffraction grating in 1786, but no explanation was possible until the wave theory of light was developed. Fraunhofer discovered the dark lines in the solar spectrum in 1814, and then investigated diffraction, producing the first ruled gratings, making detailed measurements and calculating the wavelengths of prominent spectral lines. After Bunsen and Kirchhoff showed the association between spectral lines and chemical elements there was an upsurge of interest in measuring wavelengths. The gratings used in this work almost all came from one source, a relatively unknown instrument maker called Nobert, who made them by an extremely laborious process using a machine he had built himself. The most significant wavelength measurements were made by Ångström, but Mascart, Van der Willigen, Stefan, Ditscheiner and Cornu also did important work. Nobert gratings were investigated by Quincke, copied photographically by Rayleigh, and were known and discussed in the USA. Nobert's work helped to advance spectroscopy much more than has been acknowledged. ",
                    "score": 0.8686468601226807
                },
                {
                    "id": 10456023,
                    "contents": "Ludvig Lorenz and nineteenth century optical theory: the work of a great Danish scientist.\nThe career of the Danish physicist Ludvig V. Lorenz (1829-1891) is outlined and his contributions to optical theory between 1860 and 1891 are discussed: the elastic theory of light (1860-1861), the phenomenological wave equation (1862-1864), the electrodynamic theory of light (1867), the Lorenz-Lorentz refraction theory (1869), and the theory of scattering of plane waves by spherical particles (1890). The differences between the Lorenz and the Maxwell theories of light are pointed out, and it is argued that Lorenz's phenomenological attitude and indifference to Maxwellian theory were the main reasons why his mature works in optics exerted little influence.",
                    "score": 0.8677513003349304
                },
                {
                    "id": 6490065,
                    "contents": "Electromagnetic fields on a quantum scale. I.\nThis is the first in a series of two articles, the second of which provides an exact electro-magnetic field description of photon emission, absorption, and radiation pattern. Photon energy exchanges are analyzed and shown to be the triggered, regenerative response of a non-local eigenstate electron. This first article presents a model-based, hidden variable analysis of quantum theory that provides the statistical nature of wave functions. The analysis uses the equations of classical electro-magnetism and conservation of energy while modeling an eigenstate electron as a nonlocal entity. Essential to the analysis are physical properties that were discovered and analyzed only after the historical interpretation of quantum mechanics was established: electron non-locality and the standing electro-magnetic energy that accompanies and encompasses an active, electrically small volume. The standing energy produces a driving radiation reaction force that, under certain circumstances, is many orders of magnitude larger than currently accepted values. These properties provide a sufficient basis for the Schrödinger equation as a descriptor of non-relativistic eigenstate electrons in or near equilibrium. The uncertainty principle follows, as does the exclusion principle. The analysis leads to atomic stability and causality in the sense that the status of physical phenomena at any instant specifies the status an instant later.",
                    "score": 0.8661656379699707
                },
                {
                    "id": 21353628,
                    "contents": "Publisher Correction: Selective manipulation of electronically excited states through strong light-matter interactions.\nAn amendment to this paper has been published and can be accessed via a link at the top of the paper.",
                    "score": 0.8652365803718567
                },
                {
                    "id": 11109051,
                    "contents": "Nonlinear optics: the next decade.\nThis paper concludes the Focus Serial assembled of invited papers in key areas of nonlinear optics (Editors: J.M. Dudley and R.W. Boyd), and it discusses new directions for future research in this field.",
                    "score": 0.8645748496055603
                },
                {
                    "id": 1646793,
                    "contents": "Is the electron wavelength an observable?\nThis paper is concerned with a problem often overlooked; it stems from the fact that the electron wave is also influenced by the magnetic vector potential. If one considers this influence, problems arise from the ambiguities in the gauge of the vector potential. They bear on the question of whether the electron wavelength can be considered observable or not. The answer lies, probably, in the definition of measurability.",
                    "score": 0.8644691705703735
                },
                {
                    "id": 6729924,
                    "contents": "Electron interference: mystery and reality.\nInterference of electron waves has developed from a fascinating phenomenon in basic physics to a key method for the highly sophisticated investigation of both electric and magnetic structures in solid-state materials. After more than 20 years of development, electron holography in the transmission electron microscope is now a very powerful technique for the analysis of micro-fields down to atomic dimensions. The applications extend from highly sensitive measurements in semiconductor technology to the quantitative characterization of atomic structures.",
                    "score": 0.8639920949935913
                },
                {
                    "id": 22566436,
                    "contents": "Extreme Electron Acceleration with Fixed Radiation Energy.\nWe examine the extreme situation of radiation from an electron that is asymptotically accelerated to the speed of light, resulting in finite emission energy. The analytic solution explicitly demonstrates the difference between radiation power loss and kinetic power loss (null).",
                    "score": 0.8625777363777161
                },
                {
                    "id": 19358685,
                    "contents": "The Hellmann-Feynman theorem: a perspective.\nThe Hellmann-Feynman theorem has, with a few exceptions, not been exploited to the degree that it merits. This is due, at least in part, to a widespread failure to recognize that its greatest value may be conceptual rather than numerical, i.e., in achieving insight into molecular properties and behavior. In this brief overview, we shall discuss three examples of significant concepts that have come out of the Hellmann-Feynman theorem: (1) The forces exerted upon the nuclei in molecules are entirely Coulombic in nature. (2) The total energies of atoms and molecules can be expressed rigorously in terms of just the electrostatic potentials at their nuclei that are produced by the electrons and other nuclei. (3) Dispersion forces are due to the attractions of nuclei to their own polarized electronic densities. To summarize, energy and force analyses should not be viewed as competitive but rather as complementary.",
                    "score": 0.8623660802841187
                },
                {
                    "id": 9667144,
                    "contents": "Erratum.\nIn Arthur L. Robinson's Research News article \"Electron microscope inventors share Nobel physics prize\" (14 Nov., p. 821), the quantum mechanical wavelength of an electron with an energy of 100 kiloelectron volts is incorrectly stated to be about 0.1 angstrom (p. 821, column 2). The correct value is 0.037 angstrom. Also, the electron column of the first electron microscope was vertical, not horizontal.",
                    "score": 0.8607513904571533
                },
                {
                    "id": 21057275,
                    "contents": "Author Correction: Analysis of laser radiation using the Nonlinear Fourier transform.\nAn amendment to this paper has been published and can be accessed via a link at the top of the paper.",
                    "score": 0.8606049418449402
                },
                {
                    "id": 16008519,
                    "contents": "Erratum: The NIST Length Scale Interferometer.\n[This corrects the article on p. 225 in vol. 104.].",
                    "score": 0.8604859113693237
                },
                {
                    "id": 10595100,
                    "contents": "Average local ionization energy: A review.\nThe average local ionization energy I(r) is the energy necessary to remove an electron from the point r in the space of a system. Its lowest values reveal the locations of the least tightly-held electrons, and thus the favored sites for reaction with electrophiles or radicals. In this paper, we review the definition of I(r) and some of its key properties. Apart from its relevance to reactive behavior, I(r) has an important role in several fundamental areas, including atomic shell structure, electronegativity and local polarizability and hardness. All of these aspects of I(r) are discussed.",
                    "score": 0.8604797124862671
                },
                {
                    "id": 10456024,
                    "contents": "Gustav Mie: the person.\nAbout 25 years ago, when I became acquainted with the name Gustav Mie, I was unable to find an entry for him in such major encyclopedias as the Britannica or even in several listings of famous scientists [T. I. Williams, A Biographical Sketch of Scientists (Wiley, New York, 1967); J. Turkevich and L. Turkevich, Prominent Scientists of Continental Europe (Elsevier, New York, 1968)]. This puzzled me indeed when I considered that Mie's 1908 paper and the terms Mie scattering and Mie effect were and continue to be copiously cited in the literature on particle light scattering. One can find few issues of Applied Optics, the Journal of Aerosol Science, Aerosol Science and Technology, and many related publications that do not mention Mie. Yet he is a shadowy figure, almost a disembodied three-letter name without much real existence. Within this biographical note, I try to put some flesh and bones on that apparently ghostly scientist.",
                    "score": 0.8604221343994141
                },
                {
                    "id": 7570090,
                    "contents": "What diffraction limit?\nSeveral approaches are capable of beating the classical 'diffraction limit'. In the optical domain, not only are superlenses a promising choice: concepts such as super-oscillations could provide feasible alternatives.",
                    "score": 0.860164999961853
                },
                {
                    "id": 10508698,
                    "contents": "Introductory photoemission theory.\nAn introductory review is presented on the basis of many-body scattering theory. Some fundamental aspects of photoemission theory are discussed in detail. A few applications are also discussed; photoelectron diffraction, depth distribution function and multi-atom resonant photoemission are also discussed briefly.",
                    "score": 0.8598442077636719
                },
                {
                    "id": 17642017,
                    "contents": "Asymmetry and non-dispersivity in the Aharonov-Bohm effect.\nDecades ago, Aharonov and Bohm showed that electrons are affected by electromagnetic potentials in the absence of forces due to fields. Zeilinger's theorem describes this absence of classical force in quantum terms as the \"dispersionless\" nature of the Aharonov-Bohm effect. Shelankov predicted the presence of a quantum \"force\" for the same Aharonov-Bohm physical system as elucidated by Berry. Here, we report an experiment designed to test Shelankov's prediction and we provide a theoretical analysis that is intended to elucidate the relation between Shelankov's prediction and Zeilinger's theorem. The experiment consists of the Aharonov-Bohm physical system; free electrons pass a magnetized nanorod and far-field electron diffraction is observed. The diffraction pattern is asymmetric confirming one of Shelankov's predictions and giving indirect experimental evidence for the presence of a quantum \"force\". Our theoretical analysis shows that Zeilinger's theorem and Shelankov's result are both special cases of one theorem.",
                    "score": 0.8592304587364197
                },
                {
                    "id": 11864319,
                    "contents": "Correction to the Beer-Lambert-Bouguer law for optical absorption.\nThe Beer-Lambert-Bouguer absorption law, known as Beer's law for absorption in an optical medium, is precise only at power densities lower than a few kW. At higher power densities this law fails because it neglects the processes of stimulated emission and spontaneous emission. In previous models that considered those processes, an analytical expression for the absorption law could not be obtained. We show here that by utilizing the Lambert W-function, the two-level energy rate equation model is solved analytically, and this leads into a general absorption law that is exact because it accounts for absorption as well as stimulated and spontaneous emission. The general absorption law reduces to Beer's law at low power densities. A criterion for its application is given along with experimental examples.",
                    "score": 0.8587663173675537
                },
                {
                    "id": 10014731,
                    "contents": "Books and Software: Getting the basics of NMR.\nA review of Acomplete Introduction to Modern NMR Spectroscopy.",
                    "score": 0.8578282594680786
                },
                {
                    "id": 14236886,
                    "contents": "Examples of electrostatic electron optics: the Farrand and Elektros microscopes and electron mirrors.\nThe role of Gertrude Rempfer in the design of the Farrand and Elektros microscopes is evoked. The study of electron mirror optics, aberration correction using mirrors and the development of microscopes employing electron mirrors are recapitulated, accompanied by a full bibliography, of earlier publications in particular.",
                    "score": 0.8572965264320374
                },
                {
                    "id": 10673696,
                    "contents": "Multiphoton absorption and emission by interaction of swift electrons with evanescent light fields.\nWe introduce a theory to describe the interaction of swift electrons with strong evanescent light fields. This allows us to explain recent experimental results of multiple energy losses and gains for electrons passing near illuminated nanostructures. A complex evolution of the electron state over attosecond time scales is unveiled, giving rise to non-Poissonian distributions of multiphoton features in the electron spectra. Prospects for application to nanoscale-resolved transmission electron microscopy and spectroscopy are discussed.",
                    "score": 0.8571702241897583
                },
                {
                    "id": 15981740,
                    "contents": "Employing Theories Far beyond Their Limits-The Case of the (Boguer-) Beer-Lambert Law.\nFor spectroscopists, the (Bouguer-)Beer-Lambert law is unquestionably an essential principle, since it is inseparably linked with one of the most important quantities in spectroscopy, the absorbance. In spite of its importance, a quantitative discussion of the legitimacy of relating the transmittance, the quantity that is usually measured, to the absorbance by assuming a logarithmic relation between both quantities cannot be found in literature. In this contribution, we quantitatively discuss, based on examples, the errors that can be introduced by disregarding the exact solution based on Maxwell's equations and show that these errors can easily exceed one order of magnitude. We also re-derive the Beer-Lambert law, thereby providing guidance as how to convert transmittance into absorbance properly. ",
                    "score": 0.8571205735206604
                },
                {
                    "id": 2094351,
                    "contents": "Theoretical research on electron optics.\nThis paper summarizes theoretical research on electron optics in the field of electron microscopy that has been carried out by the author and his colleagues over a long period of time. The main topics to be discussed include the rotationally symmetrical imaging system and its aberrations; the method of matrix algebraic calculation and its applications to electron optics; new developments in scanning electron beam systems, i.e., the combined electromagnetic focusing-deflection system with superimposed fields; the electromagnetic multipole system and its aberrations; the ion optical system with a curvilinear axis and its aberrations; and the phase retrieval in Fourier electron microscopy. This review may help to promote a better understanding of the present state of, and trends in, Chinese electron optics research.",
                    "score": 0.8570338487625122
                },
                {
                    "id": 11469361,
                    "contents": "Hakenmethode.\nThe experimental technique and the general theory of the hakenmethode (hook method or dispersion method) is reviewed. The review presents the basic experimental arrangement for the formation of hooks in a crossed interferometer-spectrometer system and the experimental parameters of importance of an f-value measurement by the hakenmethode. The significance of the complex index of refraction of a dispersive and dissipative medium and its relation to the hakenmethode technique, as applied to single- and multiple-line spectra is described in some detail. Penkin's total absorption method for measuring absolute f values by combining the hakenmethode with absorption measurements is reviewed. A method (similar to a Voigt profile analysis) is introduced for studying the formation of hooks about spectral lines whose absorption widths may be an appreciable fraction of the hook separation.",
                    "score": 0.8567273020744324
                },
                {
                    "id": 13417811,
                    "contents": "No surprise in the first Born approximation for electron scattering.\nIn a recent article it is argued that the far-field expansion of electron scattering, a pillar of electron diffraction theory, is wrong (Treacy and Van Dyck, 2012). It is further argued that in the first Born approximation of electron scattering the intensity of the electron wave is not conserved to first order in the scattering potential. Thus a \"mystery of the missing phase\" is investigated, and the supposed flaw in scattering theory is seeked to be resolved by postulating a standing spherical electron wave (Treacy and Van Dyck, 2012). In this work we show, however, that these theses are wrong. A review of the essential parts of scattering theory with careful checks of the underlying assumptions and limitations for high-energy electron scattering yields: (1) the traditional form of the far-field expansion, comprising a propagating spherical wave, is correct; (2) there is no room for a missing phase; (3) in the first Born approximation the intensity of the scattered wave is conserved to first order in the scattering potential. The various features of high-energy electron scattering are illustrated by wave-mechanical calculations for an explicit target model, a Gaussian phase object, and for a Si atom, considering the geometric conditions in high-resolution transmission electron microscopy.",
                    "score": 0.8566117286682129
                },
                {
                    "id": 17597372,
                    "contents": "Electronegativity-a perspective.\nElectronegativity is a very useful concept but it is not a physical observable; it cannot be determined experimentally. Most practicing chemists view it as the electron-attracting power of an atom in a molecule. Various formulations of electronegativity have been proposed on this basis, and predictions made using different formulations generally agree reasonably well with each other and with chemical experience. A quite different approach, loosely linked to density functional theory, is based on a ground-state free atom or molecule, and equates electronegativity to the negative of an electronic chemical potential. A problem that is encountered with this approach is the differentiation of a noncontinuous function. We show that this approach leads to some results that are not chemically valid. A formulation of atomic electronegativity that does prove to be effective is to express it as the average local ionization energy on an outer contour of the atom's electronic density.",
                    "score": 0.8565537929534912
                },
                {
                    "id": 11231225,
                    "contents": "Studying atomic structures by aberration-corrected transmission electron microscopy.\nSeventy-five years after its invention, transmission electron microscopy has taken a great step forward with the introduction of aberration-corrected electron optics. An entirely new generation of instruments enables studies in condensed-matter physics and materials science to be performed at atomic-scale resolution. These new possibilities are meeting the growing demand of nanosciences and nanotechnology for the atomic-scale characterization of materials, nanosynthesized products and devices, and the validation of expected functions. Equipped with electron-energy filters and electron-energy-loss spectrometers, the new instruments allow studies not only of structure but also of elemental composition and chemical bonding. The energy resolution is about 100 milli-electron volts, and the accuracy of spatial measurements has reached a few picometers. However, understanding the results is generally not straightforward and only possible with extensive quantum-mechanical computer calculations.",
                    "score": 0.8563405871391296
                },
                {
                    "id": 9698700,
                    "contents": "Free-electron lasers: present status and future prospects.\nFree-electron lasers as scientific instruments are reviewed. The present status and future prospects are delineated with attention drawn to the size, complexity, availability, and performance capability of this new tool.",
                    "score": 0.8563184142112732
                },
                {
                    "id": 4457894,
                    "contents": "Electron crystallography and non-linear optics.\nElectron crystallography can be used to obtain specific information about molecular parameters such as the polarisability, dipole moment, and hyperpolarisability. In this, work we show how a combination of quantum mechanics and simulation methods can be used to solve several unknown organic structures and how the calculated molecular parameters can be used to predict the corresponding physical properties of the crystals.",
                    "score": 0.8561179637908936
                },
                {
                    "id": 9667893,
                    "contents": "One hundred years of quantum physics.\nThis year marks the 100th anniversary of Max Planck's creation of the quantum concept, an idea so revolutionary that it took nearly 30 years for scientists to develop it into the theory that has transformed the way scientists view reality. In this month's essay, Daniel Kleppner and Roman Jackiw recount how quantum theory, which they rate as \"the most precisely tested and most successful theory in the history of science,\" came to be, how it changed the world, and how it might continue to evolve to make the dream of ultimate understanding of the universe come true.",
                    "score": 0.8555521965026855
                },
                {
                    "id": 9961089,
                    "contents": "Maxwell's Scientific Papers.\nThis article is a review of a reprint of the 1890 commemoration edition of The Scientific Papers of James Clerk Maxwell (Dover Publications, Inc., New York), $12.50. Vol. 1, 607 pp.; Vol.2, 806 pp. One hundred and one of Maxwell's shorter papers, articles, speeches, and reviews on electricity and magnetism, the dynamical theory of gases, theory of light, color vision and other optical problems, elastic solids, molecular physics, etc., are in this reprint; his longer treatises on electricity and magnetism, heat, and matter and motion are not included. This review is illustrated with photographs from the Maxwell family archives which have not been published before.",
                    "score": 0.8555375337600708
                },
                {
                    "id": 7897791,
                    "contents": "Surface microanalysis with slow electrons.\nMicroanalysis on the 10-nm level using imaging, diffraction, and spectroscopy of slow photo-emitted and reflected electrons is discussed. The instrumentation that uses a cathode lens is briefly reviewed, and a number of applications illustrate the power of this microanalysis method.",
                    "score": 0.8551244735717773
                },
                {
                    "id": 10059428,
                    "contents": "Single-photon generation by electron beams.\nWe propose a drastically new method for generating single photons in a deterministic way by interaction of electron beams with optical waveguides. We find a single swift electron to produce a guided photon with large probability. The change in energy and propagation direction of the electron reveals the creation of a photon, with the photon energy directly read from the energy-loss spectrum or the beam displacement. Our study demonstrates the viability of deterministically creating single guided photons using electron beams with better than picosecond time uncertainty, thus opening a new avenue for making room temperature, heralded frequency-tunable sources affordable for scientific and commercial developments.",
                    "score": 0.8550889492034912
                },
                {
                    "id": 6392221,
                    "contents": "[Not Available].\nThe object of this study is Leonhard Euler's physical optics as it is formulated in Nova theoria lucis et colorum (1746). The focus is on this particular work by Euler for two reasons: 1) Nova theoria represents undoubtedly the most comprehensive and systematic medium theory of the 18th century; 2) it contains the basic principles of Euler's conception of the nature of light, which he later maintained. The works of the most important advocates of this tradition (Huygens, Malebranche and Johann II Bernoulli) are here analyzed to give a historical frame to Euler's role in the medium tradition. Though these authors try to elaborate a theory of light alternative to the emission theory, they never realize the contrast between the medium and the emission traditions. From this perspective, Nova theoria is a real transition point: Euler is fully aware of the antithesis between the two traditions; he compares them, he refutes the arguments in favor of emission theory and formulates an alternative one, that will substantially be the first and the most significant antagonist of emission model. The essay examines also the central questions of Euler's theory of light, i.e. how pulses are generated and propagated, the nature of the rays of light and the relations among pulse distance, frequency, and velocity.",
                    "score": 0.8546903133392334
                },
                {
                    "id": 23109414,
                    "contents": "Photoelectron energy peaks shift against the radiation pressure in strong-field ionization.\nThe photoelectric effect describes the ejection of an electron upon absorption of one or several photons. The kinetic energy of this electron is determined by the photon energy reduced by the binding energy of the electron and, if strong laser fields are involved, by the ponderomotive potential in addition. It has therefore been widely taken for granted that for atoms and molecules, the photoelectron energy does not depend on the electron's emission direction, but theoretical studies have questioned this since 1990. Here, we provide experimental evidence that the energies of photoelectrons emitted against the light propagation direction are shifted toward higher values, while those electrons that are emitted along the light propagation direction are shifted to lower values. We attribute the energy shift to a nondipole contribution to the ponderomotive potential that is due to the interaction of the moving electrons with the incident photons.",
                    "score": 0.8546339869499207
                },
                {
                    "id": 23679517,
                    "contents": "Correction: Mid-infrared spectroscopy and microscopy of subcellular structures in eukaryotic cells with atomic force microscopy - infrared spectroscopy.\n[This corrects the article DOI: 10.1039/C7RA10240B.].",
                    "score": 0.854400098323822
                },
                {
                    "id": 4203003,
                    "contents": "The tracks of the Compton effect.\nThe observation of scattered radiations of larger wavelength than the primary had been repeatedly rejected or explained away by many researchers, including Compton. After years of vacillations, he recognized the effect named after him and was the first to develop a quantal equation predicting the wavelength of scattered radiation. It became one of the most significant contributions to modern radiation physics, opening the doors of quantum mechanics.",
                    "score": 0.8540446758270264
                },
                {
                    "id": 20631560,
                    "contents": "The Bethe-Salpeter Equation Formalism: From Physics to Chemistry.\nThe Bethe-Salpeter equation (BSE) formalism is steadily asserting itself as a new efficient and accurate tool in the ensemble of computational methods available to chemists in order to predict optical excitations in molecular systems. In particular, the combination of the so-called <iGW</i approximation, giving access to reliable ionization energies and electron affinities, and the BSE formalism, able to model UV/vis spectra, has shown to provide accurate singlet excitation energies with a typical error of 0.1-0.3 eV. With a similar computational cost as time-dependent density-functional theory (TD-DFT), BSE is able to provide an accuracy on par with the most accurate global and range-separated hybrid functionals without the unsettling choice of the exchange-correlation functional, resolving further known issues (e.g., charge-transfer excitations). In this Perspective, we provide a historical overview of BSE, with a particular focus on its condensed-matter roots. We also propose a critical review of its strengths and weaknesses in different chemical situations.",
                    "score": 0.8537330627441406
                },
                {
                    "id": 10633824,
                    "contents": "Optical emission from the interaction of fast electrons with metallic films containing a circular aperture: a study of radiative decoherence of fast electrons.\nLight emission resulting from the interaction of swift electrons with a distant material is shown to produce an unexpectedly large fraction of decoherence in the moving charges. The decoherence probability diverges for an electron passing through a hole drilled in a perfectly conducting metal film, regardless of the size of the opening. This divergence, which is logarithmic in the ratio of film radius to aperture radius, originates in an infrared catastrophe that differs from other sources of decoherence (e.g., bremsstrahlung radiation). Our results provide new avenues for controlling and assessing the role of coherence during electron acceleration (for example, in transmission electron microscopes) and for exploiting partial quantum interference of fast electrons.",
                    "score": 0.8536379933357239
                },
                {
                    "id": 15619163,
                    "contents": "Quantum optics: science and technology in a new light.\nLight facilitates exploration of quantum phenomena that illuminate the basic properties of nature and also enables radical new technologies based on these phenomena. The critical features of quantum light that underpin the opportunities for discovery and application are exceptionally low noise and strong correlations. Rapid progress in both science and technology has been stimulated by adopting components developed for optical telecommunications and networking, such as highly efficient detectors, integrated photonic circuits, and waveguide- or nanostructure-based nonlinear optical devices. These provide the means to generate new quantum states of light and matter of unprecedented scale, containing many photons with quantum correlations across space and time. Notably, networks with only several tens of photons are already beyond what can be efficiently analyzed by current computers. ",
                    "score": 0.8532766699790955
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_1",
        "question": "The threshold wavelength for potassium metal is $564 \\mathrm{~nm}$. What is its work function? \r\n",
        "golden_answers": [
            " 3.52"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 13131488,
                    "contents": "Measurement of a wavelength of light for which the energy shift for an atom vanishes.\nLight at a magic-zero wavelength causes a zero energy shift for an atom. We measured the longest magic-zero wavelength for ground state potassium atoms to be λ(zero)=768.9712(15) nm, and we show how this measurement provides an improved experimental benchmark for atomic structure calculations. This λ(zero) measurement determines the ratio of the potassium atom D1 and D2 line strengths with record precision. It also demonstrates a new application for atom interferometry, and we discuss how decoherence will fundamentally limit future measurements of magic-zero wavelengths.",
                    "score": 0.8555669188499451
                },
                {
                    "id": 11740875,
                    "contents": "On the atomic weight of potassium.\nA brief survey of data is made, which indicates the possibility that the present internationally accepted value for the atomic weight of potassium (39.102) is too high. Additional experimental evidence is brought to light, which also supports this conclusion.",
                    "score": 0.8312040567398071
                },
                {
                    "id": 22146259,
                    "contents": "Author Correction: Maximizing and stabilizing luminescence from halide perovskites with potassium passivation.\nAn amendment to this paper has been published and can be accessed via a link at the top of the paper.",
                    "score": 0.8257133364677429
                },
                {
                    "id": 3023823,
                    "contents": "Transition Element-Like Chemistry for Potassium Under Pressure\nAt high pressure the alkali metals potassium, rubidium, and cesium transform to metals that have a d1 electron configuration, becoming transition metal-like. As a result, compounds were shown to form between potassium and the transition metal nickel. These results demonstrate that the chemical behavior of the alkali metals under pressure is very different from that under ambient conditions, where alkali metals and transition metals do not react because of large differences in size and electronic structure. They also have significant implications for the hypothesis that potassium is incorporated into Earth's core.",
                    "score": 0.8213188648223877
                },
                {
                    "id": 19108204,
                    "contents": "Electromagnetically induced transparency in vacuum and buffer gas potassium cells probed via electro-optic frequency combs.\nElectromagnetically induced transparency (EIT) in K39 and K41 was probed using electro-optic frequency combs generated by applying chirped waveforms to a phase modulator. The carrier tone of the frequency comb served as the pump beam and induced the necessary optical cycling. Comb tooth spacings as narrow as 20 kHz were used to probe potassium in both buffer gas and evacuated cells at elevated temperatures. Atomic absorption features as narrow as 33(5) kHz were observed, allowing for the K39 lower-state hyperfine splitting to be optically measured with a fit uncertainty of 2 kHz. Due to the ultranarrow width of the EIT features, long-lived optical free induction decays were also observed which allowed for background-free detection.",
                    "score": 0.8185281157493591
                },
                {
                    "id": 21881776,
                    "contents": "Retraction Note: Optical rectification and absorption coefficients studied by a short-range topless exponential potential well with inverse square root.\nThis article has been retracted.",
                    "score": 0.8119809031486511
                },
                {
                    "id": 11523551,
                    "contents": "Sodium: a charge-transfer insulator at high pressures.\nBy first-principles methods we analyze the optical response of transparent dense sodium as a function of applied pressure. We discover an unusual kind of charge-transfer exciton that proceeds from the interstitial distribution of valence electrons. The absorption spectrum is strongly anisotropic, which, just at pressures above the metal-insulator transition, manifests as sodium being optically transparent in one direction but reflective in the other. This result provides key information about the crystal structure of transparent sodium, a new unconventional inorganic electride.",
                    "score": 0.8117879629135132
                },
                {
                    "id": 22208463,
                    "contents": "Life on the Urbach Edge.\nThe Urbach energy is an expression of the static and dynamic disorder in a semiconductor and is directly accessible via optical characterization techniques. The strength of this metric is that it elegantly captures the optoelectronic performance potential of a semiconductor in a single number. For solar cells, the Urbach energy is found to be predictive of a material's minimal open-circuit-voltage deficit. Performance calculations considering the Urbach energy give more realistic power conversion efficiency limits than from classical Shockley-Queisser considerations. The Urbach energy is often also found to correlate well with the Stokes shift and (inversely) with the carrier mobility of a semiconductor. Here, we discuss key features, underlying physics, measurement techniques, and implications for device fabrication, underlining the utility of this metric.",
                    "score": 0.8111072182655334
                },
                {
                    "id": 21126921,
                    "contents": "The importance of relativistic effects on two-photon absorption spectra in metal halide perovskites.\nDespite intense research into the optoelectronic properties of metal halide perovskites (MHPs), sub-bandgap absorption in MHPs remains largely unexplored. Here we recorded two-photon absorption spectra of MHPs using the time-resolved microwave conductivity technique. A two-step upward trend is observed in the two-photon absorption spectrum for methylammonium lead iodide, and some analogues, which implies that the commonly used scaling law is not applicable to MHPs. This aspect is further confirmed by temperature-dependent conductivity measurements. Using an empirical multiband tight binding model, spectra for methylammonium lead iodide were calculated by integration over the entire Brillouin zone, showing compelling similarity with experimental results. We conclude that the second upward trend in the two-photon absorption spectrum originates from additional optical transitions to the heavy and light electron bands formed by the strong spin-orbit coupling. Hence, valuable insight can be obtained in the opto-electronic properties of MHPs by sub-bandgap spectroscopy, complemented by modelling.",
                    "score": 0.8102813959121704
                },
                {
                    "id": 18674351,
                    "contents": "Unveiling the Nature of Charge Carrier Interactions by Electroabsorption Spectroscopy: An Illustration with Lead-Halide Perovskites.\nUnravelling the nature of the interactions between photogenerated charge carriers in solar energy conversion devices is key to enhance performance. In this perspective, we discuss electroabsorption spectroscopy (EAS), as the spectral bandshape of the electroabsorption (EA) signal directly depends on the strength of the charge carrier interactions. For instance, the electroabsorption response in molecular or confined excitonic systems can be modelled perturbatively yielding the Stark effect. In contrast, most solids exhibit weaker interactions, and a perturbative approach cannot be taken in general. For solids with negligible charge carrier interactions, one resorts to the Franz-Keldysh theory of a continuum in a field, that, in the low-field limit, simplifies to the low-field FKA effect. Alternatively, when the continuum approximation breaks down, the problem of a Wannier exciton in a field has to be solved, and numerical methods emerged as the best solution. We illustrate our discussion with two examples involving lead-halide perovskites, a new, high-stake solar cell material. In the first example, we discuss the lineshape of the electroabsorption response for thin-films of lead-iodide perovskite, that sustains the photogeneration of free carriers. In the second example, we address a confined excitonic case with lead-bromide perovskite nanoparticles, and demonstrate the presence of so-called charge-transfer excitons.",
                    "score": 0.8097098469734192
                },
                {
                    "id": 19898031,
                    "contents": "<i>Quantum Materials</i>: A New Open Section in Materials.\n<iQuantum Materials</i is a new open section of <iMaterials</i aimed at publishing original and review articles on novel scientific and applied research that significantly contribute to the understanding and discovery of quantum materials and related phenomena, functions, and applications [...].",
                    "score": 0.8094950318336487
                },
                {
                    "id": 10727741,
                    "contents": "Essay: Fifty years of atomic, molecular and optical physics in Physical Review Letters.\nThe fiftieth anniversary of Physical Review Letters is a good opportunity to review the extraordinary progress of atomic, molecular, and optical physics reported in this journal during the past half-century. As both a witness and an actor of this story, I recall personal experiences and reflect about the past, present, and possible future of my field of research.",
                    "score": 0.8094115257263184
                },
                {
                    "id": 14641002,
                    "contents": "Temperature-dependent absorption and emission of potassium double tungstates with high ytterbium content.\nWe study the spectroscopic properties of thin films of potassium ytterbium gadolinium double tungstates, KYb&lt;sub&gt;0.57&lt;/sub&gt;Gd&lt;sub&gt;0.43&lt;/sub&gt;(WO&lt;sub&gt;4&lt;/sub&gt;)&lt;sub&gt;2&lt;/sub&gt;, and potassium ytterbium lutetium double tungstates, KYb&lt;sub&gt;0.76&lt;/sub&gt;Lu&lt;sub&gt;0.24&lt;/sub&gt;(WO&lt;sub&gt;4&lt;/sub&gt;)&lt;sub&gt;2&lt;/sub&gt;, specifically at the central absorption line near 981 nm wavelength, which is important for amplifiers and lasers. The absorption cross-section of both thin films is found to be similar to those of bulk potassium rare-earth double tungstates, suggesting that the crystalline layers retain their spectroscopic properties albeit having &gt;50 at.% Yb&lt;sup&gt;3+&lt;/sup&gt; concentration. The influence of sample temperature is investigated and found to substantially affect the measured absorption cross-section. Since amplifiers and lasers typically operate above room temperature due to pump-induced heating, the temperature dependence of the peak-absorption cross-section of the KYb&lt;sub&gt;0.57&lt;/sub&gt;Gd&lt;sub&gt;0.43&lt;/sub&gt;(WO&lt;sub&gt;4&lt;/sub&gt;)&lt;sub&gt;2&lt;/sub&gt; is evaluated for the sample being heated from 20 °C to 170 °C, resulting in a measured reduction of peak-absorption cross-section at the transitions near 933 nm and 981 nm by ~40% and ~52%, respectively. It is shown that two effects, the change of Stark-level population and linewidth broadening due to intra-manifold relaxation induced by temperature-dependent electron-phonon interaction, contribute to the observed behavior. The effective emission cross-sections versus temperature have been calculated. Luminescence-decay measurements show no significant dependence of the luminescence lifetime on temperature.",
                    "score": 0.8092410564422607
                },
                {
                    "id": 12643497,
                    "contents": "Quasi-electric fields and band offsets: teaching electrons new tricks (Nobel lecture).\nThe invention and development of fast opto- and microelectronic components based on layered semiconductor structures, termed semiconductor heterostructures, is described herein. Such fast transistors are used in radio link satellites and the base stations of mobile telephones, for examples. Laser diodes built with the same technology drive the flow of information along fiber-optic cables, and may be found also in CD players, bar-code readers, and laser pointers. The double-heterostructure principle is also increasingly used in incoherent light-emitting diodes, for example in traffic lights and other light sources requiring colored visible light.",
                    "score": 0.809004545211792
                },
                {
                    "id": 9666890,
                    "contents": "APPLIED PHYSICS: How to Be Truly Photonic.\nPhotonic crystals behave toward light waves as semiconductors do toward electron waves. Yablonovitch discusses a report by Noda et al., who have made a photonic crystal with unprecedented performance, using GaAs, the best material for integration into optoelectronic devices. According to Yablonovitch, the work thus represents a significant step toward photonic integrated circuits.",
                    "score": 0.8079206347465515
                },
                {
                    "id": 11850291,
                    "contents": "It's time to reinvent the transistor!\nA breakthrough in materials could refresh and sustain the information technology revolution.",
                    "score": 0.8076146841049194
                },
                {
                    "id": 17196837,
                    "contents": "Single Photon Sources in Atomically Thin Materials.\nLayered materials are very attractive for studies of light-matter interactions at the nanoscale. In particular, isolated quantum systems such as color centers and quantum dots embedded in these materials are gaining interest due to their potential use in a variety of quantum technologies and nanophotonics. Here, we review the field of nonclassical light emission from van der Waals crystals and atomically thin two-dimensional materials. We focus on transition metal dichalcogenides and hexagonal boron nitride and discuss the fabrication and properties of quantum emitters in these systems and proof-of-concept experiments that provide a foundation for their integration in on-chip nanophotonic circuits. These experiments include tuning of the emission wavelength, electrical excitation, and coupling of the emitters to waveguides, dielectric cavities, and plasmonic resonators. Finally, we discuss current challenges in the field and provide an outlook to further stimulate scientific discussion.",
                    "score": 0.8075442314147949
                },
                {
                    "id": 15320552,
                    "contents": "Ion-Switchable Quantum Dot Förster Resonance Energy Transfer Rates in Ratiometric Potassium Sensors.\nThe tools for optically imaging cellular potassium concentrations in real-time are currently limited to a small set of molecular indicator dyes. Quantum dot-based nanosensors are more photostable and tunable than organic indicators, but previous designs have fallen short in size, sensitivity, and selectivity. Here, we introduce a small, sensitive, and selective nanosensor for potassium measurements. A dynamic quencher modulates the fluorescence emitted by two different quantum dot species to produce a ratiometric signal. We characterized the potassium-modulated sensor properties and investigated the photonic interactions within the sensors. The quencher's protonation changes in response to potassium, which modulates its Förster radiative energy transfer rate and the corresponding interaction radii with each quantum dot species. The nanosensors respond to changes in potassium concentrations typical of the cellular environment and thus provide a promising tool for imaging potassium fluxes during biological events.",
                    "score": 0.8063434958457947
                },
                {
                    "id": 17870070,
                    "contents": "Large tunable photoeffect on ion conduction in halide perovskites and implications for photodecomposition.\nIn the same way as electron transport is crucial for information technology, ion transport is a key phenomenon in the context of energy research. To be able to tune ion conduction by light would open up opportunities for a wide realm of new applications, but it has been challenging to provide clear evidence for such an effect. Here we show through various techniques, such as transference-number measurements, permeation studies, stoichiometric variations, Hall effect experiments and the use of blocking electrodes, that light excitation enhances by several orders of magnitude the ionic conductivity of methylammonium lead iodide, the archetypal metal halide photovoltaic material. We provide a rationale for this unexpected phenomenon and show that it straightforwardly leads to a hitherto unconsidered photodecomposition path of the perovskite.",
                    "score": 0.8062916398048401
                },
                {
                    "id": 20388031,
                    "contents": "Coherent light brightens the quantum science frontier.\nControlling coherent light across a vast spectral range enables ultraprecise measurements and the quantum control of atomic, molecular, and condensed-matter systems.",
                    "score": 0.8062708973884583
                },
                {
                    "id": 11440559,
                    "contents": "'... a metal conducts and a non-metal doesn't'.\nIn a letter to one of the authors, Sir Nevill Mott, then in his tenth decade, highlighted the fact that the statement '... a metal conducts, and a non-metal doesn't' can be true only at the absolute zero of temperature, T=0 K. But, of course, experimental studies of metals, non-metals and, indeed, the electronic and thermodynamic transition between these canonical states of matter must always occur above T=0 K, and, in many important cases, for temperatures far above the absolute zero. Here, we review the issues-theoretical and experimental-attendant on studies of the metal to non-metal transition in doped semiconductors at temperatures close to absolute zero (T=0.03 K) and fluid chemical elements at temperatures far above absolute zero (T&gt;1000 K). We attempt to illustrate Mott's insights for delving into such complex phenomena and experimental systems, finding intuitively the dominant features of the science, and developing a coherent picture of the different competing electronic processes. A particular emphasis is placed on the idea of a 'Mott metal to non-metal transition' in the nominally metallic chemical elements rubidium, caesium and mercury, and the converse metallization transition in the nominally non-metal elements hydrogen and oxygen. We also review major innovations by D. A. Goldhammer (Goldhammer 1913 Dispersion und absorption des lichtes) and K. F. Herzfeld (Herzfeld 1927 Phys. Rev. 29, 701-705. (doi:10.1103/PhysRev.29.701)) in a pre-quantum theory description of the metal-non-metal transition, which emphasize the pivotal role of atomic properties in dictating the metallic or non-metallic status of the chemical elements of the periodic table under ambient and extreme conditions; a link with Pauling's 'metallic orbital' is also established here.",
                    "score": 0.8061496019363403
                },
                {
                    "id": 21402801,
                    "contents": "Correction: Highly efficient room-temperature phosphorescence achieved by gadolinium complexes.\nCorrection for 'Highly efficient room-temperature phosphorescence achieved by gadolinium complexes' by Boxun Sun et al., Dalton Trans., 2019, 48, 14958-14961.",
                    "score": 0.804877519607544
                },
                {
                    "id": 1072677,
                    "contents": "Intracellular compartmentalization of potassium.\nThe evidence that there is intracellular compartmentalization of potassium is indirect but diverse. Intracellular electrode measurement of potassium activity, 42K radioisotope studies, and more recently 39K nuclear magnetic resonance (NMR) all support such compartmentalization. The use of rubidium to apparently shift potassium between sites with different NMR characteristics (visibility) is strong evidence for such compartmentalization. The evidence that intracellular compartmentalization of potassium is of (patho) physiological significance is also indirect. Postulated roles for regulation of intracellular K+ activity, perhaps by control of compartmentalization, include enzyme activity, protein synthesis, and cell growth. There is also evidence that compartmentalization of potassium may contribute to the maintenance of a stable intracellular environment following potassium loading. The apparent magnetic field dependence of the visibility of K+ by 39K NMR offers the opportunity to explore further the phenomenon of compartmentalization.",
                    "score": 0.804364800453186
                },
                {
                    "id": 7579024,
                    "contents": "The quantum electrical triangle.\nThe past 35 years have seen the development of an unexpected plethora of quantum electrical standards based on just two fundamental constants, e and h. First came a voltage standard based on the Josephson a.c. effect, in terms of which most maintained primary standards of voltage are defined. This was followed a decade later by the quantized Hall effect, based on the von Klitzing constant which allows the ohm to be maintained very precisely. It became clear 20 years ago that there is also a possible quantum current standard. This third standard has yet to play a full part in practical electrical metrology. However, recent developments suggest that there are many different possible manifestations in which such a current standard might be realized. The three quantum standards, taken together, define the quantum electrical triangle of standards which would allow the units to be realized in terms of different combinations of e and h. We summarize the very different physics behind the three standards, reviewing the present state of development in all three. Implications for the future are also considered, especially relating to ultra-low temperature, nanoscale and truly quantum mechanical versions of the standards.",
                    "score": 0.8041081428527832
                },
                {
                    "id": 17597661,
                    "contents": "Author Correction: Ultrafast and highly sensitive infrared photodetectors based on two-dimensional oxyselenide crystals.\nAn amendment to this paper has been published and can be accessed via a link at the top of the paper.",
                    "score": 0.8039162158966064
                },
                {
                    "id": 17217698,
                    "contents": "Atomic dispensers for thermoplasmonic control of alkali vapor pressure in quantum optical applications.\nAlkali metal vapors enable access to single electron systems, suitable for demonstrating fundamental light-matter interactions and promising for quantum logic operations, storage and sensing. However, progress is hampered by the need for robust and repeatable control over the atomic vapor density and over the associated optical depth. Until now, a moderate improvement of the optical depth was attainable through bulk heating or laser desorption - both time-consuming techniques. Here, we use plasmonic nanoparticles to convert light into localized thermal energy and to achieve optical depths in warm vapors, corresponding to a ~16 times increase in vapor pressure in less than 20 ms, with possible reload times much shorter than an hour. Our results enable robust and compact light-matter devices, such as efficient quantum memories and photon-photon logic gates, in which strong optical nonlinearities are crucial.",
                    "score": 0.8034201860427856
                },
                {
                    "id": 17475772,
                    "contents": "An ultrastable metal-organic material emits efficient and broadband bluish white-light emission for luminescent thermometers.\nWe discover a rare bluish white-light-emitting Sb3+-based coordination polymer with an unusually large Stokes shift of 230 nm (2.3 eV), ascribed to the assymetric-symmetric coordination shift of the Sb3+ centers. The photoemission renders both a high photoluminescence quantum yield exceeding 30% and a large full width at half maximum of 116 nm. Moreover, the strongly light-emissive material exhibits a linear relationship between the correlated color temperature and the absolute temperature in a wide range (157-457 K), thus presenting the first solid-state luminescent thermometer based on photoemission energy.",
                    "score": 0.803297758102417
                },
                {
                    "id": 14032626,
                    "contents": "Giant Nernst effect and bipolarity in the quasi-one-dimensional metal Li0.9Mo6O17.\nThe Nernst coefficient for the quasi-one-dimensional metal, Li{0.9}Mo{6}O{17}, is found to be among the largest known for metals (ν≃500  μV/KT at T∼20  K), and is enhanced in a broad range of temperature by orders of magnitude over the value expected from Boltzmann theory for carrier diffusion. A comparatively small Seebeck coefficient implies that Li{0.9}Mo{6}O{17} is bipolar with large, partial Seebeck coefficients of opposite sign. A very large thermomagnetic figure of merit, ZT∼0.5, is found at high field in the range T≈35-50  K.",
                    "score": 0.8027828931808472
                },
                {
                    "id": 15687886,
                    "contents": "High conductance 2D transport around the Hall mobility peak in electrolyte-gated rubrene crystals.\nWe report the observation of the Hall effect at hole densities up to 6×10¹³ cm⁻² (0.3  holes/molecule) on the surface of electrolyte-gated rubrene crystals. The perplexing peak in the conductance as a function of gate voltage is confirmed to result from a maximum in mobility, which reaches 4  cm² V⁻¹ s⁻¹ at 2.5×10¹³ cm⁻². Measurements to liquid helium temperatures reveal that this peak is markedly asymmetric, with bandlike and hopping-type transport occurring on the low density side, while unconventional, likely electrostatic-disorder-affected transport dominates the high density side. Most significantly, near the mobility peak the temperature coefficient of the resistance remains positive to as low as 120 K, the low temperature resistance becomes weakly temperature dependent, and the conductance reaches within a factor of 2 of e²/h, revealing conduction unprecedentedly close to a two-dimensional metallic state.",
                    "score": 0.8018906116485596
                },
                {
                    "id": 11419730,
                    "contents": "Les propriétés optiques de couches minces d'yttrium sous ultravide statique.\nIt is shown that yttrium presents a normal absorption band near 5.6 eV and another band whose characistics depend upon their film structure. The influence of temperature on the films shows the existence of an anomalous absorption phenomenon.",
                    "score": 0.8014741539955139
                },
                {
                    "id": 13705404,
                    "contents": "Optical detection of potassium chloride vapor using collinear photofragmentation and atomic absorption spectroscopy.\nA sensitive and selective optical technique to detect potassium chloride (KCl) vapor is introduced. The technique is based on the photofragmentation of KCl molecules, using a pulsed UV laser, and optical probing of the temporarily increased amount of potassium atoms with a near-infrared laser. The two laser beams are aligned to go through the sample volume along the same optical path. The performance of the technique is demonstrated by detecting KCl concentrations from 25 ppb to 30 ppm in a temperature-controlled cell.",
                    "score": 0.8013290166854858
                },
                {
                    "id": 22005386,
                    "contents": "Hiroshi Kitagawa.\n\"The secrets of being a successful scientist are dreams, imagination, and lots of effort. The biggest challenge facing scientists is the room-temperature superconductor …\" Find out more about Hiroshi Kitagawa in his Author Profile.",
                    "score": 0.8012180924415588
                },
                {
                    "id": 10980124,
                    "contents": "Frequency doubled 1534 nm laser system for potassium laser cooling.\nWe demonstrate a compact laser source suitable for trapping and cooling potassium. By frequency doubling a fiber laser diode at 1534 nm in a waveguide, we produce 767 nm laser light. A current modulation of the diode allows us to generate the two required frequencies for cooling in a simple and robust apparatus. We successfully used this laser source to trap K39.",
                    "score": 0.8004255890846252
                },
                {
                    "id": 6904115,
                    "contents": "Potassium channels.\nThe atomic structures of K+ channels have added a new dimension to our understanding of K+ channel function. I will briefly review how structures have influenced our views on ion conduction, gating of the pore, and voltage sensing.",
                    "score": 0.8003706336021423
                },
                {
                    "id": 22145386,
                    "contents": "Mid-infrared, long-wave infrared, and terahertz photonics: introduction.\nThis feature issue presents recent progress in long-wavelength photonics, focusing on wavelengths that span the mid-infrared (3-50 µm), the long-wavelength infrared (30-60 µm), and the terahertz (60-300 µm) portions of the electromagnetic spectrum. The papers in this feature issue report recent progress in the generation, manipulation, detection, and use of light across this long-wave region of the \"photonics spectrum,\" including novel sources and cutting edge advances in detectors, long-wavelength non-linear processes, optical metamaterials and metasurfaces, and molecular spectroscopy. The range of topics covered in this feature issue provide an excellent insight into the expanding interest in long-wavelength photonics, which could open new possibilities for basic research and applications in industries that span health, environmental, and security.",
                    "score": 0.8002098798751831
                },
                {
                    "id": 22973171,
                    "contents": "The fascinating world of biogenic crystals.\nThe diverse properties of these crystals may lead to a variety of applications.",
                    "score": 0.7997979521751404
                },
                {
                    "id": 9241011,
                    "contents": "Kondo resonances and anomalous gate dependence in the electrical conductivity of single-molecule transistors.\nWe report Kondo resonances in the conduction of single-molecule transistors based on transition metal coordination complexes. We find Kondo temperatures in excess of 50 K, comparable to those in purely metallic systems. The observed gate dependence of the Kondo temperature is inconsistent with observations in semiconductor quantum dots and a simple single-dot-level model. We discuss possible explanations of this effect, in light of electronic structure calculations.",
                    "score": 0.7997766137123108
                },
                {
                    "id": 9666882,
                    "contents": "ELECTRONIC OPTICS: Organic Lasers Promise New Lease on Light.\nMany of today's lasers are made from ceramic chips that require expensive clean-room facilities to manufacture, and their color palette is somewhat limited. Researchers have long pinned their hopes on organic materials, which are typically easier and cheaper to process. Now, on page 599, a team reports that they've devised the first electrically powered solid state organic laser, a step that could open the floodgates for novel lasers that are cheaper and that shine in colors inorganics can't match.",
                    "score": 0.799409031867981
                },
                {
                    "id": 3435823,
                    "contents": "Potassium channels and their evolving gates.\nPotassium channels allow potassium ions to flow across the membrane and play a key role in maintaining membrane potential. Recent research has begun to reveal how these channels transport potassium in preference to other ions, how their activity is controlled, and how they are related to other channels.",
                    "score": 0.7993832230567932
                },
                {
                    "id": 15992803,
                    "contents": "Tungsten Oxide Materials for Optoelectronic Applications.\nTungsten oxide is a versatile transition-metal oxide with a vast number of polymorphs and sub-stoichiometric compositions, featuring innate tunnels and oxygen vacancies. The structure-determined nature, such as altered optical absorption and metal-like conductivity, makes tungsten oxide an attractive candidate for optoelectronic applications. A brief summary of the recent progress in tungsten oxide for optoelectronic applications is provided, including not only the traditional field of electrochromism/photochromism, but also new areas of application, such as visible-light-driven photocatalysis, photothermal therapy, and surface enhanced Raman spectroscopy (SERS). Also, the prospects for future applications of tungsten oxide are summarized and highlighted.",
                    "score": 0.7991361021995544
                },
                {
                    "id": 16149956,
                    "contents": "Comparative study on three highly sensitive absorption measurement techniques characterizing lithium niobate over its entire transparent spectral range.\nWe employ three highly sensitive spectrometers: a photoacoustic spectrometer, a photothermal common-path interferometer and a whispering-gallery-resonator-based absorption spectrometer, for a comparative study of measuring the absorption coefficient of nominally transparent undoped, congruently grown lithium niobate for ordinarily and extraordinarily polarized light in the wavelength range from 390 to 3800 nm. The absorption coefficient ranges from below 10(-4) cm(-1) up to 2 cm(-1). Furthermore, we measure the absorption at the Urbach tail as well as the multiphonon edge of the material by a standard grating spectrometer and a Fourier-transform infrared spectrometer, providing for the first time an absorption spectrum of the whole transparency window of lithium niobate. The absorption coefficients obtained by the three highly sensitive and independent methods show good agreement.",
                    "score": 0.7990703582763672
                },
                {
                    "id": 13745076,
                    "contents": "A nanoscale standard for the Seebeck coefficient.\nThe Seebeck coefficient, a key parameter describing a material's thermoelectric performance, is generally difficult to measure, and no intrinsic calibration standard exists. Quantum dots and single electron tunneling devices with sharp transmission resonances spaced by many kT have a material-independent Seebeck coefficient that depends only on the electronic charge and the average device temperature T. Here we propose the use of a quantum dot to create an intrinsic, nanoscale standard for the Seebeck coefficient and discuss its implementation.",
                    "score": 0.7988166213035583
                },
                {
                    "id": 23110409,
                    "contents": "Editorial for the Special Issue on Wide Bandgap Based Devices: Design, Fabrication and Applications, Volume II.\nWide bandgap (WBG) semiconductors are becoming a key enabling technology for several strategic fields of human activities [...].",
                    "score": 0.7987731695175171
                },
                {
                    "id": 8892558,
                    "contents": "Materials that emit light by chemical reaction.\nMany chemical reactions are associated with the emission of electromagnetic radiation in the form of heat and/or light. This paper reviews the categories of materials that produce visible light when they react, either spontaneously upon contact with air or upon ignition, as well as the processes by which such materials are synthesized. Emphasis is placed on compositions and processes that relate most closely with those found in nature.",
                    "score": 0.7987685799598694
                },
                {
                    "id": 15231254,
                    "contents": "Optical Hall effect-model description: tutorial.\nThe optical Hall effect is a physical phenomenon that describes the occurrence of magnetic-field-induced dielectric displacement at optical wavelengths, transverse and longitudinal to the incident electric field, and analogous to the static electrical Hall effect. The electrical Hall effect and certain cases of the optical Hall effect observations can be explained by extensions of the classic Drude model for the transport of electrons in metals. The optical Hall effect is most useful for characterization of electrical properties in semiconductors. Among many advantages, while the optical Hall effect dispenses with the need of electrical contacts, electrical material properties such as effective mass and mobility parameters, including their anisotropy as well as carrier type and density, can be determined from the optical Hall effect. Measurement of the optical Hall effect can be performed within the concept of generalized ellipsometry at an oblique angle of incidence. In this paper, we review and discuss physical model equations, which can be used to calculate the optical Hall effect in single- and multiple-layered structures of semiconductor materials. We define the optical Hall effect dielectric function tensor, demonstrate diagonalization approaches, and show requirements for the optical Hall effect tensor from energy conservation. We discuss both continuum and quantum approaches, and we provide a brief description of the generalized ellipsometry concept, the Mueller matrix calculus, and a 4×4 matrix algebra to calculate data accessible by experiment. In a follow-up paper, we will discuss strategies and approaches for experimental data acquisition and analysis. ",
                    "score": 0.7980824708938599
                },
                {
                    "id": 2115263,
                    "contents": "[Johann Wilhelm Ritter (1776-1810) and the discovery of ultraviolet irradiation 185 years ago].\nOn 22 February 1801, Johann Wilhelm Ritter discovered UV radiation in Jena. In general, this achievement is less well known than his work on galvanism. Ritter was the creator of modern electrochemistry. Though since described as \"the most brilliant physicist of the Romantic period,\" he was a controversial figure in his own time. His scientific work was not fully acknowledged until after his death.",
                    "score": 0.7980448603630066
                },
                {
                    "id": 18500487,
                    "contents": "Light-Addressable Ion Sensing for Real-Time Monitoring of Extracellular Potassium.\nWe report here on a light addressable potassium (K<sup+</sup ) sensor where light illumination of a semiconducting silicon electrode substrate results in a localized activation of the faradaic electrochemistry at the illuminated spot. This allows one, by electrochemical control, to oxidize surface bound ferrocene moieties that in turn trigger K<sup+</sup transfer from the overlaid K<sup+</sup -selective film to the solution phase. The resulting voltammetric response is shown to be K<sup+</sup -selective, where peak position is a direct function of K<sup+</sup activity at the surface of electrode. This concept was used to measure extracellular K<sup+</sup concentration changes by stimulating living breast cancer cells. The associated decrease of intracellular K<sup+</sup level was confirmed with a fluorescent K<sup+</sup indicator. In contrast to light addressable potentiometry, the approach introduced here relies on dynamic electrochemistry and may be performed in tandem with other electrochemical analysis when studying biological events on the electrode.",
                    "score": 0.797763466835022
                },
                {
                    "id": 10633791,
                    "contents": "Brighter light sources from black metal: significant increase in emission efficiency of incandescent light sources.\nBy applying the femtosecond laser blackening technique directly to a tungsten incandescent lamp filament, we dramatically brighten the tungsten lamp and enhance its emission efficiency to approach 100%. A comparison study of emission and absorption for the structured metal surfaces shows that Kirchhoff's law is applicable for the black metal. Furthermore, we demonstrate that we can even obtain partially polarized light as well as control the spectral range of the optimal light emission from the laser-blackened tungsten lamp.",
                    "score": 0.7975801825523376
                },
                {
                    "id": 19128025,
                    "contents": "How Indium Nitride Senses Water.\nThe unique electronic band structure of indium nitride InN, part of the industrially significant III-N class of semiconductors, offers charge transport properties with great application potential due to its robust n-type conductivity. Here, we explore the water sensing mechanism of InN thin films. Using angle-resolved photoemission spectroscopy, core level spectroscopy, and theory, we derive the charge carrier density and electrical potential of a two-dimensional electron gas, 2DEG, at the InN surface and monitor its electronic properties upon in situ modulation of adsorbed water. An electric dipole layer formed by water molecules raises the surface potential and accumulates charge in the 2DEG, enhancing surface conductivity. Our intuitive model provides a novel route toward understanding the water sensing mechanism in InN and, more generally, for understanding sensing material systems beyond InN.",
                    "score": 0.7974096536636353
                },
                {
                    "id": 15524146,
                    "contents": "Terahertz optical properties of potassium titanyl phosphate crystals.\nThis paper studies the terahertz optical properties of nonlinear potassium titanyl phosphate crystals with different conductivities in the spectral range of 0.2 to 2.6 THz. The observed properties are characterized by several absorption lines lying along different optical axes which represent the relevant potassium sublattice phonon modes. The peculiarities of these absorption lines are attributed to the structural order of potassium ions. ",
                    "score": 0.7974095344543457
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_2",
        "question": "Evaluate the series\r\n$$\r\nS=\\sum_{n=0}^{\\infty} \\frac{1}{3^n}\r\n$$",
        "golden_answers": [
            " 3 / 2"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 21453649,
                    "contents": "Improving series convergence: the simple pendulum and beyond.\nA simple and easy to implement method for improving the convergence of a power series is presented. We observe that the most obvious or analytically convenient point about which to make a series expansion is not always the most computationally efficient. Series convergence can be dramatically improved by choosing the center of the series expansion to be at or near the average value at which the series is to be evaluated. For illustration, we apply this method to the well-known simple pendulum and to the Mexican hat type of potential. Large performance gains are demonstrated. While the method is not always the most computationally efficient on its own, it is effective, straightforward, quite general, and can be used in combination with other methods.",
                    "score": 0.8765344619750977
                },
                {
                    "id": 21421458,
                    "contents": "On powers that are sums of consecutive like powers.\nLet <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:mik</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn</mml:mrow </mml:math be even, and let <ir</i be a non-zero integer. We show that for almost all <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:mid</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn</mml:mrow </mml:math (in the sense of natural density), the equation <DispFormula <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow<mml:msup<mml:mix</mml:mi <mml:mik</mml:mi</mml:msup <mml:mo+</mml:mo <mml:msup<mml:mrow<mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo+</mml:mo <mml:mir</mml:mi <mml:mo)</mml:mo</mml:mrow <mml:mik</mml:mi</mml:msup <mml:mo+</mml:mo <mml:mo⋯</mml:mo <mml:mo+</mml:mo <mml:msup<mml:mrow<mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo+</mml:mo <mml:mrow<mml:mo(</mml:mo <mml:mid</mml:mi <mml:mo-</mml:mo <mml:mn1</mml:mn <mml:mo)</mml:mo</mml:mrow <mml:mir</mml:mi <mml:mo)</mml:mo</mml:mrow <mml:mik</mml:mi</mml:msup <mml:mo=</mml:mo <mml:msup<mml:miy</mml:mi <mml:min</mml:mi</mml:msup <mml:mo,</mml:mo <mml:mspace/ <mml:mix</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:miy</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:min</mml:mi <mml:mo∈</mml:mo <mml:miZ</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:min</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn <mml:mo,</mml:mo</mml:mrow </mml:math </DispFormula has no solutions.",
                    "score": 0.8739391565322876
                },
                {
                    "id": 22558670,
                    "contents": "Division of Power Series: Recursive and Non-Recursive Formulas.\nIn this paper we propose a new formula to divide power series. We develop two versions of the formula: a recursive and a non-recursive one, the latter aiming to reduce the computational cost for high-order series truncation. To use the non-recursive formula we define certain fundamental sets of summation indexes. Additional non-trivial information about effects of repetition of the indexes are needed and contabilized within a coefficient 𝛾 in the formula, we explain how to calculate the coefficient 𝛾 for each summation index by constructing appropriate mappings between the fundamental sets of indexes previous defined.",
                    "score": 0.8734018802642822
                },
                {
                    "id": 20650615,
                    "contents": "Approximate Entropy and Sample Entropy: A Comprehensive Tutorial.\nApproximate Entropy and Sample Entropy are two algorithms for determining the regularity of series of data based on the existence of patterns. Despite their similarities, the theoretical ideas behind those techniques are different but usually ignored. This paper aims to be a complete guideline of the theory and application of the algorithms, intended to explain their characteristics in detail to researchers from different fields. While initially developed for physiological applications, both algorithms have been used in other fields such as medicine, telecommunications, economics or Earth sciences. In this paper, we explain the theoretical aspects involving Information Theory and Chaos Theory, provide simple source codes for their computation, and illustrate the techniques with a step by step example of how to use the algorithms properly. This paper is not intended to be an exhaustive review of all previous applications of the algorithms but rather a comprehensive tutorial where no previous knowledge is required to understand the methodology.",
                    "score": 0.871282696723938
                },
                {
                    "id": 19031252,
                    "contents": "A series of sequences convergent to Euler's constant.\nIn this paper, using continued fraction, we provide a new quicker sequence convergent to Euler's constant. We demonstrate the superiority of our new convergent sequences over DeTemple's sequence, Mortici's sequences, Vernescu's sequence, and Lu's sequence.",
                    "score": 0.8708591461181641
                },
                {
                    "id": 17462513,
                    "contents": "Beyond the LSD method for the partial sums of multiplicative functions.\nThe Landau-Selberg-Delange method gives an asymptotic formula for the partial sums of a multiplicative function <if</i whose prime values are <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miα</mml:mi</mml:math on average. In the literature, the average is usually taken to be <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miα</mml:mi</mml:math with a very strong error term, leading to an asymptotic formula for the partial sums with a very strong error term. In practice, the average at the prime values may only be known with a fairly weak error term, and so we explore here how good an estimate this will imply for the partial sums of <if</i, developing new techniques to do so.",
                    "score": 0.8648972511291504
                },
                {
                    "id": 14094978,
                    "contents": "Estimation of the entropy based on its polynomial representation.\nEstimating entropy from empirical samples of finite size is of central importance for information theory as well as the analysis of complex statistical systems. Yet, this delicate task is marred by intrinsic statistical bias. Here we decompose the entropy function into a polynomial approximation function and a remainder function. The approximation function is based on a Taylor expansion of the logarithm. Given n observations, we give an unbiased, linear estimate of the first n power series terms based on counting sets of k coincidences. For the remainder function we use nonlinear Bayesian estimation with a nearly flat prior distribution on the entropy that was developed by Nemenman, Shafee, and Bialek. Our simulations show that the combined entropy estimator has reduced bias in comparison to other available estimators.",
                    "score": 0.86073237657547
                },
                {
                    "id": 10299610,
                    "contents": "Algorithm for computation of Zernike polynomials expansion coefficients.\nA numerically efficient algorithm for expanding a function in a series of Zernike polynomials is presented. The algorithm evaluates the expansion coefficients through the standard 2-D integration formula derived from the Zernike polynomials' orthogonal properties. Quadratic approximations are used along with the function to be expanded to eliminate the computational problems associated with integrating the oscillatory behavior of the Zernike polynomials. This yields a procedure that is both fast and numerically accurate. Comparisons are made between the proposed scheme and a procedure using a nested 2-D Simpson's integration rule. The results show that typically at least a fourfold improvement in computational speed can be expected in practical use.",
                    "score": 0.858588457107544
                },
                {
                    "id": 14718520,
                    "contents": "Universal series induced by approximate identities and some relevant applications.\nWe prove the existence of series [Formula: see text], whose coefficients [Formula: see text] are in [Formula: see text] and whose terms [Formula: see text] are translates by rational vectors in [Formula: see text] of a family of approximations to the identity, having the property that the partial sums are dense in various spaces of functions such as Wiener's algebra [Formula: see text], [Formula: see text], [Formula: see text], [Formula: see text], for every [Formula: see text], and the space of measurable functions. Applying this theory to particular situations, we establish approximations by such series to solutions of the heat and Laplace equations as well as to probability density functions.",
                    "score": 0.8570164442062378
                },
                {
                    "id": 17269017,
                    "contents": "Correction to: Explicit upper bound for the average number of divisors of irreducible quadratic polynomials.\n[This corrects the article DOI: 10.1007/s00605-017-1061-y.].",
                    "score": 0.8561450839042664
                },
                {
                    "id": 9691374,
                    "contents": "Fast algorithms for classical physics.\nSome of the recently developed fast summation methods that have arisen in scientific computing are described. These methods require an amount of work proportional to N or N log N to evaluate all pairwise interactions in an ensemble of N particles. Traditional methods, by contrast, require an amount of work proportional to N(2). As a result, largescale simulations can be carried out using only modest computer resources. In combination with supercomputers, it is possible to address questions that were previously out of reach. Problems from diffusion, gravitation, and wave propagation are considered.",
                    "score": 0.8543732166290283
                },
                {
                    "id": 12379440,
                    "contents": "On the higher power sums of reciprocal higher-order sequences.\nLet {u(n)} be a higher-order linear recursive sequence. In this paper, we use the properties of error estimation and the analytic method to study the reciprocal sums of higher power of higher-order sequences. Then we establish several new and interesting identities relating to the infinite and finite sums.",
                    "score": 0.8540636301040649
                },
                {
                    "id": 23389571,
                    "contents": "A fast algorithm for computing the Boys function.\nWe present a new fast algorithm for computing the Boys function using a nonlinear approximation of the integrand via exponentials. The resulting algorithms evaluate the Boys function with real and complex valued arguments and are competitive with previously developed algorithms for the same purpose.",
                    "score": 0.8521215319633484
                },
                {
                    "id": 7634727,
                    "contents": "A unifying view of wiener and volterra theory and polynomial kernel regression.\nVolterra and Wiener series are perhaps the best-understood nonlinear system representations in signal processing. Although both approaches have enjoyed a certain popularity in the past, their application has been limited to rather low-dimensional and weakly nonlinear systems due to the exponential growth of the number of terms that have to be estimated. We show that Volterra and Wiener series can be represented implicitly as elements of a reproducing kernel Hilbert space by using polynomial kernels. The estimation complexity of the implicit representation is linear in the input dimensionality and independent of the degree of nonlinearity. Experiments show performance advantages in terms of convergence, interpretability, and system sizes that can be handled.",
                    "score": 0.8520177006721497
                },
                {
                    "id": 9617151,
                    "contents": "A Simple Proof of Siegel's Theorem.\nA brief and simple proof of Siegel's celebrated theorem that h(d) &gt;&gt; d(1/2-[unk]), as d --&gt; infinity, is given. Here h(d) denotes the class number of the quadratic field Q([unk]-d). Simple proofs that do not make use of algebraic number theory have been previously given by Estermann and Chowla.",
                    "score": 0.8516863584518433
                },
                {
                    "id": 7952328,
                    "contents": "Discrete sums for the rapid determination of exponential decay constants.\nSeveral computational methods are presented for the rapid extraction of decay time constants from discrete exponential data. Two methods are found to be comparably fast and highly accurate. They are corrected successive integration and a method involving the Fourier transform (FT) of the data and the application of an expression that does not assume continuous data. FT methods in the literature are found to introduce significant systematic error owing to the assumption that data are continuous. Corrected successive integration methods in the literature are correct, but we offer a more direct way of applying them which we call linear regression of the sum. We recommend the use of the latter over FT-based methods, as the FT methods are more affected by noise in the original data.",
                    "score": 0.8513484001159668
                },
                {
                    "id": 15539424,
                    "contents": "On the additive properties of the fat-shattering dimension.\nThe properties of the VC-dimension under various compositions are well-understood, but this is much less the case for classes of continuous functions. In this brief, we show that a commonly used scale-sensitive dimension, Vγ, is much less well-behaved under Minkowski summation than its VC cousin, while the fat-shattering dimension retains some compositional similarity to the VC-dimension. As an application, we analyze the fat-shattering dimension of trigonometric functions and series.",
                    "score": 0.8501166701316833
                },
                {
                    "id": 12258677,
                    "contents": "A new sum analogous to Gauss sums and its fourth power mean.\nThe main purpose of this paper is to use the analytic methods and the properties of Gauss sums to study the computational problem of one kind of new sum analogous to Gauss sums and give an interesting fourth power mean and a sharp upper bound estimate for it. ",
                    "score": 0.8497980237007141
                },
                {
                    "id": 8058211,
                    "contents": "A computationally simple and robust method to detect determinism in a time series.\nWe present a new, simple, and fast computational technique, termed the incremental slope (IS), that can accurately distinguish between deterministic from stochastic systems even when the variance of noise is as large or greater than the signal, and remains robust for time-varying signals. The IS method is more accurate than the widely utilized Poincare plot analysis especially when the data are severely contaminated by noise. The efficacy of the IS is demonstrated with several simulated deterministic and stochastic signals.",
                    "score": 0.8495896458625793
                },
                {
                    "id": 20573763,
                    "contents": "The exponentiated generalized power series: Family of distributions: theory, properties and applications.\nWe propose a new generalized family of distributions called the exponentiated generalized power series (EGPS) family of distributions and study its sub-model, the exponentiated generalized logarithmic (EGL) class of distributions, in detail. The structural properties of the new model (EGPS) and its sub-model (EGL) distribution including moments, order statistics, Rényi entropy, and maximum likelihood estimates are derived. We used the method of maximum likelihood to estimate the parameters of this new family of distributions. Simulation study was carried out to examine the bias and the mean square error of the maximum likelihood estimators for each of the model's parameters. Finally, we showed real life data examples to illustrate the models' applicability, flexibility and usefulness.",
                    "score": 0.8487847447395325
                },
                {
                    "id": 8254968,
                    "contents": "Detrended cross-correlation analysis: a new method for analyzing two nonstationary time series.\nHere we propose a new method, detrended cross-correlation analysis, which is a generalization of detrended fluctuation analysis and is based on detrended covariance. This method is designed to investigate power-law cross correlations between different simultaneously recorded time series in the presence of nonstationarity. We illustrate the method by selected examples from physics, physiology, and finance.",
                    "score": 0.8487547039985657
                },
                {
                    "id": 2667573,
                    "contents": "Further remarks on convergence of decomposition method.\nThe decomposition method solves a wide class of nonlinear functional equations. This method uses a series solution with rapid convergence. This paper is intended as a useful review and clarification of related issues.",
                    "score": 0.8480680584907532
                },
                {
                    "id": 19477880,
                    "contents": "Correction: The complex dynamics of products and its asymptotic properties.\n[This corrects the article DOI: 10.1371/journal.pone.0177360.].",
                    "score": 0.8466764092445374
                },
                {
                    "id": 9617330,
                    "contents": "Maximal functions: Poisson integrals on symmetric spaces.\nLet u be a harmonic function on a symmetric space which is the Poisson integral of a function f in L(p), 1 &lt;/= p &lt;/= infinity. Then u converges restrictedly and admissibly to f almost everywhere. This result is proved by obtaining an appropriate maximal theorem which takes into account the structure of the Poisson kernel.",
                    "score": 0.8463262319564819
                },
                {
                    "id": 22388509,
                    "contents": "Extended Wang sum and associated products.\nThe Wang sum involving the exponential sums of Lerch's Zeta functions is extended to the finite sum of the Huwitz-Lerch Zeta function to derive sums and products involving cosine and tangent trigonometric functions. The general theorem used to derive these sums and products is in the form of the finite sum over positive integers of the Hurwitz-Lerch Zeta function where the associated parameters are general complex numbers. New Hurwitz-Lerch Zeta function recurrence identities with consecutive neighbours are derived. Some finite sum and product formulae examples involving cosine, tangent and the product of cosine and tangent functions are also derived and evaluated.",
                    "score": 0.8463117480278015
                },
                {
                    "id": 15997402,
                    "contents": "The rapidly convergent solutions of strongly nonlinear oscillators.\nBased on the harmonic balance method (HBM), an approximate solution is determined from the integral expression (i.e., first order differential equation) of some strongly nonlinear oscillators. Usually such an approximate solution is obtained from second order differential equation. The advantage of the new approach is that the solution converges significantly faster than that obtained by the usual HBM as well as other analytical methods. By choosing some well known nonlinear oscillators, it has been verified that an n-th (n ≥ 2) approximate solution (concern of this article) is very close to (2n - 1)-th approximations obtained by usual HBM. ",
                    "score": 0.8452388048171997
                },
                {
                    "id": 21716799,
                    "contents": "Computing sums in terms of beta, polygamma, and Gauss hypergeometric functions.\nIn the paper, by virtue of the binomial inversion formula, a general formula of higher order derivatives for a ratio of two differentiable function, and other techniques, the authors compute several sums in terms of the beta function and its partial derivatives, polygamma functions, the Gauss hypergeometric function, and a determinant. These results generalize known ones in combinatorics.",
                    "score": 0.844903826713562
                },
                {
                    "id": 8378619,
                    "contents": "Fundamentals of superresolution.\nThe fundamental principles behind superresolution are discussed, and different schemes classified. Different definitions for localization of a wave are discussed.",
                    "score": 0.8448936939239502
                },
                {
                    "id": 19088042,
                    "contents": "Some new results on convex sequences.\nIn the present paper, we obtained a main theorem related to factored infinite series. Some new results are also deduced.",
                    "score": 0.844635546207428
                },
                {
                    "id": 20867802,
                    "contents": "Practical rules for summing the series of the Tweedie probability density function with high-precision arithmetic.\nFor some ranges of its parameters and arguments, the series for Tweedie probability density functions are sometimes exceedingly difficult to sum numerically. Existing numerical implementations utilizing inversion techniques and properties of stable distributions can cope with these problems, but no single one is successful in all cases. In this work we investigate heuristically the nature of the problem, and show that it is not related to the order of summation of the terms. Using a variable involved in the analytical proof of convergence of the series, the critical parameter for numerical non-convergence (\"alpha\") is identified, and an heuristic criterion is developed to avoid numerical non-convergence for a reasonably large sub-interval of the latter. With these practical rules, simple summation algorithms provide sufficiently robust results for the calculation of the density function and its definite integrals. These implementations need to utilize high-precision arithmetic, and are programmed in the Python programming language. A thorough comparison with existing R functions allows the identification of cases when the latter fail, and provide further guidance to their use.",
                    "score": 0.8444045186042786
                },
                {
                    "id": 15791453,
                    "contents": "Nonlinear time-series analysis revisited.\nIn 1980 and 1981, two pioneering papers laid the foundation for what became known as nonlinear time-series analysis: the analysis of observed data-typically univariate-via dynamical systems theory. Based on the concept of state-space reconstruction, this set of methods allows us to compute characteristic quantities such as Lyapunov exponents and fractal dimensions, to predict the future course of the time series, and even to reconstruct the equations of motion in some cases. In practice, however, there are a number of issues that restrict the power of this approach: whether the signal accurately and thoroughly samples the dynamics, for instance, and whether it contains noise. Moreover, the numerical algorithms that we use to instantiate these ideas are not perfect; they involve approximations, scale parameters, and finite-precision arithmetic, among other things. Even so, nonlinear time-series analysis has been used to great advantage on thousands of real and synthetic data sets from a wide variety of systems ranging from roulette wheels to lasers to the human heart. Even in cases where the data do not meet the mathematical or algorithmic requirements to assure full topological conjugacy, the results of nonlinear time-series analysis can be helpful in understanding, characterizing, and predicting dynamical systems. ",
                    "score": 0.8439950942993164
                },
                {
                    "id": 6590341,
                    "contents": "Approximate entropy (ApEn) as a complexity measure.\nApproximate entropy (ApEn) is a recently developed statistic quantifying regularity and complexity, which appears to have potential application to a wide variety of relatively short (greater than 100 points) and noisy time-series data. The development of ApEn was motivated by data length constraints commonly encountered, e.g., in heart rate, EEG, and endocrine hormone secretion data sets. We describe ApEn implementation and interpretation, indicating its utility to distinguish correlated stochastic processes, and composite deterministic/ stochastic models. We discuss the key technical idea that motivates ApEn, that one need not fully reconstruct an attractor to discriminate in a statistically valid manner-marginal probability distributions often suffice for this purpose. Finally, we discuss why algorithms to compute, e.g., correlation dimension and the Kolmogorov-Sinai (KS) entropy, often work well for true dynamical systems, yet sometimes operationally confound for general models, with the aid of visual representations of reconstructed dynamics for two contrasting processes. (c) 1995 American Institute of Physics.",
                    "score": 0.8439869284629822
                },
                {
                    "id": 18974547,
                    "contents": "Correction: Fitting power-laws in empirical data with estimators that work for all exponents.\n[This corrects the article DOI: 10.1371/journal.pone.0170920.].",
                    "score": 0.8439429998397827
                },
                {
                    "id": 9652484,
                    "contents": "Systematic series expansions for processes on networks.\nWe use series expansions to study dynamics of equilibrium and nonequilibrium systems on networks. This analytical method enables us to include detailed nonuniversal effects of the network structure. We show that even low order calculations produce results which compare accurately to numerical simulation, while the results can be systematically improved. We show that certain commonly accepted analytical results for the critical point on networks with a broad degree distribution need to be modified in certain cases due to disassortativity; the present method is able to take into account the assortativity at sufficiently high order, while previous results correspond to leading and second order approximations in this method. Finally, we apply this method to real-world data.",
                    "score": 0.8437315225601196
                },
                {
                    "id": 9694945,
                    "contents": "Mathematics and computer science: coping with finiteness.\nBy presenting these examples, I have tried to illustrate four main points. 1) Finite numbers can be really enormous, and the known universe is very small. Therefore the distinction between finite and infinite is not as relevant as the distinction between realistic and unrealistic. 2) In many cases there are subtle ways to solve very large problems quickly, in spite of the fact that they appear at first to require examination of too many possibilities. 3) There are also cases where we can prove that a fairly natural problem is intrinsically hard, far beyond our conceivable capabilities. 4) It takes a good deal of skill to decide whether a given problem is in the easy or hard class; but even if a problem does turn out to be hard there are useful and interesting ways to change it into one that can be done satisfactorily.",
                    "score": 0.8431384563446045
                },
                {
                    "id": 21334684,
                    "contents": "A Fast Summation Method for Oscillatory Lattice Sums.\nWe present a fast summation method for lattice sums of the type which arise when solving wave scattering problems with periodic boundary conditions. While there are a variety of effective algorithms in the literature for such calculations, the approach presented here is new and leads to a rigorous analysis of Wood's anomalies. These arise when illuminating a grating at specific combinations of the angle of incidence and the frequency of the wave, for which the lattice sums diverge. They were discovered by Wood in 1902 as singularities in the spectral response. The primary tools in our approach are the Euler-Maclaurin formula and a steepest descent argument. The resulting algorithm has super-algebraic convergence and requires only milliseconds of CPU time.",
                    "score": 0.842953622341156
                },
                {
                    "id": 9616968,
                    "contents": "Airey's Converging Factor.\nAsmptotic series for the calculation of functions, for values of the argument numerically &gt;1, start off with terms whose numerical values decrease but, at a certain stage, the terms begin to increase in numerical value and must be ignored. At this stage, there may be two adjacent terms of equal numerical value; when the least term of the asymptotic series is spoken of, it is in reference to the first of these two terms. The sum of the initial terms of the asymptotic series up to, and including, the least term often furnishes a fair approximation to the desired value of the function being evaluated. It was early observed by computers that if the terms of the asymptotic series alternate in sign, this approximation was often improved by replacing the least term by its half. The factor by which the least term of the asymptotic series must be multiplied so that the true value of the function being evaluated is obtained by addition of this modified least term to the remaining initial terms of the asymptotic series is known as the converging factor for the asymptotic series. The converging factor for the asymptotic series involved in the calculation of the exponential integral, for large negative values of the argument, was given as a power series in the reciprocal of the argument by Airey; the first term of this series is (1/2). A method for the determination of the coefficients of this series is given.",
                    "score": 0.842944860458374
                },
                {
                    "id": 23167501,
                    "contents": "Simple renormalization schemes for multiple scattering series expansions.\nA number of renormalization schemes for improving the convergence of multiple scattering series expansions are investigated. Numerical tests on a small Cu(111) cluster demonstrate their effectiveness, for example increasing the rate of convergence by up to a factor 2 or by transforming a divergent series into a convergent one. These techniques can greatly facilitate multiple scattering calculations, especially for spectroscopies such as photoelectron diffraction, Auger electron diffraction, low energy electron diffraction <ietc.</i, where an electron propagates with a kinetic energy of hundreds of eV in a cluster of hundreds of atoms.",
                    "score": 0.8428056240081787
                },
                {
                    "id": 9618297,
                    "contents": "Rational approximations to linear forms of exponentials and binomials.\nMahler proved the following quantitative result supplementing the Lindemann-Weierstrass theorem: Sigma(i=0) (n)C(i)e(ri) &gt; H(-n-epsilon) for any distinct rational numbers r(0),r(1),..., r(n) and rational integers C(0),C(1),...,C(n) with H = max(0&lt;/=i&lt;/=n) C(i). We improve Mahler's estimate by replacing exponentials e(ri) by linearly independent linear forms L(i) = Sigma L(ij)e(sij) with rational L(ij),s(ij)i = 0,1,...,n. Similar results are obtained for binomials (a/b)(ri) or Sigma L(ij)(a/b)(sij) with integers a,b and logb/loga &gt; 1 - epsilon. The simplest examples of new numbers with the irrationality exponent \"2 + epsilon\" are sinh 1 or sin 1.",
                    "score": 0.842790961265564
                },
                {
                    "id": 18129605,
                    "contents": "Fourier series of finite products of Bernoulli and Genocchi functions.\nIn this paper, we consider three types of functions given by products of Bernoulli and Genocchi functions and derive some new identities arising from Fourier series expansions associated with Bernoulli and Genocchi functions. Furthermore, we will express each of them in terms of Bernoulli functions.",
                    "score": 0.842612087726593
                },
                {
                    "id": 18347567,
                    "contents": "Monotone and fast computation of Euler's constant.\nWe construct sequences of finite sums [Formula: see text] and [Formula: see text] converging increasingly and decreasingly, respectively, to the Euler-Mascheroni constant <iγ</i at the geometric rate 1/2. Such sequences are easy to compute and satisfy complete monotonicity-type properties. As a consequence, we obtain an infinite product representation for [Formula: see text] converging in a monotone and fast way at the same time. We use a probabilistic approach based on a differentiation formula for the gamma process.",
                    "score": 0.8425699472427368
                },
                {
                    "id": 17926147,
                    "contents": "A new type of Taylor series expansion.\nWe present a variant of the classical integration by parts to introduce a new type of Taylor series expansion and to present some closed forms for integrals involving Jacobi and Laguerre polynomials, which cannot be directly obtained by usual symbolic computation programs, i.e., only some very specific values can be computed by the mentioned programs. An error analysis is given in the sequel for the introduced expansion.",
                    "score": 0.8423383831977844
                },
                {
                    "id": 6146107,
                    "contents": "Predictability, complexity, and learning.\nWe define predictive information I(pred)(T) as the mutual information between the past and the future of a time series. Three qualitatively different behaviors are found in the limit of large observation times T:I(pred)(T) can remain finite, grow logarithmically, or grow as a fractional power law. If the time series allows us to learn a model with a finite number of parameters, then I(pred)(T) grows logarithmically with a coefficient that counts the dimensionality of the model space. In contrast, power-law growth is associated, for example, with the learning of infinite parameter (or nonparametric) models such as continuous functions with smoothness constraints. There are connections between the predictive information and measures of complexity that have been defined both in learning theory and the analysis of physical systems through statistical mechanics and dynamical systems theory. Furthermore, in the same way that entropy provides the unique measure of available information consistent with some simple and plausible conditions, we argue that the divergent part of I(pred)(T) provides the unique measure for the complexity of dynamics underlying a time series. Finally, we discuss how these ideas may be useful in problems in physics, statistics, and biology.",
                    "score": 0.8420178294181824
                },
                {
                    "id": 19847374,
                    "contents": "<i>Entropy</i> 2021 Best Paper Award.\nOn behalf of the Editor-in-Chief, Prof [...].",
                    "score": 0.8418369889259338
                },
                {
                    "id": 15272780,
                    "contents": "On the general Dedekind sums and two-term exponential sums.\nWe use the analytic methods and the properties of Gauss sums to study the computational problem of one kind hybrid mean value involving the general Dedekind sums and the two-term exponential sums, and give an interesting computational formula for it. ",
                    "score": 0.841801106929779
                },
                {
                    "id": 9962175,
                    "contents": "Computing the multifractal spectrum from time series: an algorithmic approach.\nWe show that the existing methods for computing the f(alpha) spectrum from a time series can be improved by using a new algorithmic scheme. The scheme relies on the basic idea that the smooth convex profile of a typical f(alpha) spectrum can be fitted with an analytic function involving a set of four independent parameters. While the standard existing schemes [P. Grassberger et al., J. Stat. Phys. 51, 135 (1988); A. Chhabra and R. V. Jensen, Phys. Rev. Lett. 62, 1327 (1989)] generally compute only an incomplete f(alpha) spectrum (usually the top portion), we show that this can be overcome by an algorithmic approach, which is automated to compute the D(q) and f(alpha) spectra from a time series for any embedding dimension. The scheme is first tested with the logistic attractor with known f(alpha) curve and subsequently applied to higher-dimensional cases. We also show that the scheme can be effectively adapted for analyzing practical time series involving noise, with examples from two widely different real world systems. Moreover, some preliminary results indicating that the set of four independent parameters may be used as diagnostic measures are also included.",
                    "score": 0.8416969180107117
                },
                {
                    "id": 5937873,
                    "contents": "Fast algorithm for generating long self-affine profiles.\nWe introduce a fast algorithm for generating long self-affine profiles. The algorithm, which is based on the fast wavelet transform, is faster than the conventional Fourier filtering algorithm. In addition to increased performance for large systems, the algorithm, named the wavelet filtering algorithm, a priori gives rise to profiles for which the long-range correlation extends throughout the entire system independently of the length scale.",
                    "score": 0.8414535522460938
                },
                {
                    "id": 23351778,
                    "contents": "A Class of Double Integrals Involving Gaussian and Trigonometric Factors.\nThe five parameter double integral <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow <mml:mrow<mml:msubsup<mml:mo∫</mml:mo <mml:mn0</mml:mn <mml:mi∞</mml:mi</mml:msubsup <mml:mid</mml:mi</mml:mrow <mml:miy</mml:mi <mml:mtextexp</mml:mtext <mml:mrow<mml:mo(</mml:mo <mml:mrow<mml:mo-</mml:mo <mml:msup<mml:mip</mml:mi <mml:mn2</mml:mn</mml:msup <mml:msup<mml:miy</mml:mi <mml:mn2</mml:mn</mml:msup </mml:mrow <mml:mo)</mml:mo</mml:mrow <mml:mtextsin</mml:mtext <mml:mo(</mml:mo <mml:miβ</mml:mi <mml:miy</mml:mi <mml:mo+</mml:mo <mml:miθ</mml:mi <mml:mo)</mml:mo</mml:mrow </mml:math times <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow <mml:mrow<mml:msubsup<mml:mo∫</mml:mo <mml:mn0</mml:mn <mml:miy</mml:mi</mml:msubsup <mml:mid</mml:mi</mml:mrow <mml:mix</mml:mi <mml:mtextexp</mml:mtext <mml:mrow<mml:mo(</mml:mo <mml:mrow<mml:mo-</mml:mo <mml:msup<mml:mix</mml:mi <mml:mn2</mml:mn</mml:msup </mml:mrow <mml:mo)</mml:mo</mml:mrow <mml:mtextcos</mml:mtext <mml:mo(</mml:mo <mml:miϵ</mml:mi <mml:miβ</mml:mi <mml:mix</mml:mi <mml:mo+</mml:mo <mml:miϕ</mml:mi <mml:mo)</mml:mo</mml:mrow </mml:math is evaluated in terms of Fourier transforms of exp(- <ix</i <sup2</sup)erfc(<iαx</i). Some new expressions for these transforms are obtained.",
                    "score": 0.841408371925354
                },
                {
                    "id": 4319805,
                    "contents": "TSAN: a package for time series analysis.\nMany biomedical data are in the form of time series. Analyses of these data include: (1) search for any biorhythm; (2) test of homogeneity of several time series; (3) assessment of stationarity; (4) test of normality of the time series histogram; (5) evaluation of dependence between data points. In this paper we present a subroutine package called TSAN. It is developed to accomplish these tasks. Computational methods, as well as flowcharts, for these subroutines are described. Two sample runs are demonstrated.",
                    "score": 0.8403196334838867
                },
                {
                    "id": 9097437,
                    "contents": "Systematic perturbation calculation of integrals with applications to physics.\nIn this paper we generalize and improve a method for calculating the period of a classical oscillator and other integrals of physical interest, which was recently developed by some of the authors. We derive analytical expressions that prove to be more accurate than those commonly found in the literature, and test the convergence of the series produced by the approach.",
                    "score": 0.8402946591377258
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_3",
        "question": "Evaluate the series\r\n$$\r\nS=\\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{2^n}\r\n$$",
        "golden_answers": [
            " 1"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 21453649,
                    "contents": "Improving series convergence: the simple pendulum and beyond.\nA simple and easy to implement method for improving the convergence of a power series is presented. We observe that the most obvious or analytically convenient point about which to make a series expansion is not always the most computationally efficient. Series convergence can be dramatically improved by choosing the center of the series expansion to be at or near the average value at which the series is to be evaluated. For illustration, we apply this method to the well-known simple pendulum and to the Mexican hat type of potential. Large performance gains are demonstrated. While the method is not always the most computationally efficient on its own, it is effective, straightforward, quite general, and can be used in combination with other methods.",
                    "score": 0.8792939782142639
                },
                {
                    "id": 22558670,
                    "contents": "Division of Power Series: Recursive and Non-Recursive Formulas.\nIn this paper we propose a new formula to divide power series. We develop two versions of the formula: a recursive and a non-recursive one, the latter aiming to reduce the computational cost for high-order series truncation. To use the non-recursive formula we define certain fundamental sets of summation indexes. Additional non-trivial information about effects of repetition of the indexes are needed and contabilized within a coefficient 𝛾 in the formula, we explain how to calculate the coefficient 𝛾 for each summation index by constructing appropriate mappings between the fundamental sets of indexes previous defined.",
                    "score": 0.8731149435043335
                },
                {
                    "id": 20650615,
                    "contents": "Approximate Entropy and Sample Entropy: A Comprehensive Tutorial.\nApproximate Entropy and Sample Entropy are two algorithms for determining the regularity of series of data based on the existence of patterns. Despite their similarities, the theoretical ideas behind those techniques are different but usually ignored. This paper aims to be a complete guideline of the theory and application of the algorithms, intended to explain their characteristics in detail to researchers from different fields. While initially developed for physiological applications, both algorithms have been used in other fields such as medicine, telecommunications, economics or Earth sciences. In this paper, we explain the theoretical aspects involving Information Theory and Chaos Theory, provide simple source codes for their computation, and illustrate the techniques with a step by step example of how to use the algorithms properly. This paper is not intended to be an exhaustive review of all previous applications of the algorithms but rather a comprehensive tutorial where no previous knowledge is required to understand the methodology.",
                    "score": 0.8730841279029846
                },
                {
                    "id": 21421458,
                    "contents": "On powers that are sums of consecutive like powers.\nLet <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:mik</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn</mml:mrow </mml:math be even, and let <ir</i be a non-zero integer. We show that for almost all <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:mid</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn</mml:mrow </mml:math (in the sense of natural density), the equation <DispFormula <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow<mml:msup<mml:mix</mml:mi <mml:mik</mml:mi</mml:msup <mml:mo+</mml:mo <mml:msup<mml:mrow<mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo+</mml:mo <mml:mir</mml:mi <mml:mo)</mml:mo</mml:mrow <mml:mik</mml:mi</mml:msup <mml:mo+</mml:mo <mml:mo⋯</mml:mo <mml:mo+</mml:mo <mml:msup<mml:mrow<mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo+</mml:mo <mml:mrow<mml:mo(</mml:mo <mml:mid</mml:mi <mml:mo-</mml:mo <mml:mn1</mml:mn <mml:mo)</mml:mo</mml:mrow <mml:mir</mml:mi <mml:mo)</mml:mo</mml:mrow <mml:mik</mml:mi</mml:msup <mml:mo=</mml:mo <mml:msup<mml:miy</mml:mi <mml:min</mml:mi</mml:msup <mml:mo,</mml:mo <mml:mspace/ <mml:mix</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:miy</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:min</mml:mi <mml:mo∈</mml:mo <mml:miZ</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:min</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn <mml:mo,</mml:mo</mml:mrow </mml:math </DispFormula has no solutions.",
                    "score": 0.8729037046432495
                },
                {
                    "id": 19031252,
                    "contents": "A series of sequences convergent to Euler's constant.\nIn this paper, using continued fraction, we provide a new quicker sequence convergent to Euler's constant. We demonstrate the superiority of our new convergent sequences over DeTemple's sequence, Mortici's sequences, Vernescu's sequence, and Lu's sequence.",
                    "score": 0.8706409335136414
                },
                {
                    "id": 14094978,
                    "contents": "Estimation of the entropy based on its polynomial representation.\nEstimating entropy from empirical samples of finite size is of central importance for information theory as well as the analysis of complex statistical systems. Yet, this delicate task is marred by intrinsic statistical bias. Here we decompose the entropy function into a polynomial approximation function and a remainder function. The approximation function is based on a Taylor expansion of the logarithm. Given n observations, we give an unbiased, linear estimate of the first n power series terms based on counting sets of k coincidences. For the remainder function we use nonlinear Bayesian estimation with a nearly flat prior distribution on the entropy that was developed by Nemenman, Shafee, and Bialek. Our simulations show that the combined entropy estimator has reduced bias in comparison to other available estimators.",
                    "score": 0.8657978773117065
                },
                {
                    "id": 17462513,
                    "contents": "Beyond the LSD method for the partial sums of multiplicative functions.\nThe Landau-Selberg-Delange method gives an asymptotic formula for the partial sums of a multiplicative function <if</i whose prime values are <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miα</mml:mi</mml:math on average. In the literature, the average is usually taken to be <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miα</mml:mi</mml:math with a very strong error term, leading to an asymptotic formula for the partial sums with a very strong error term. In practice, the average at the prime values may only be known with a fairly weak error term, and so we explore here how good an estimate this will imply for the partial sums of <if</i, developing new techniques to do so.",
                    "score": 0.8648249506950378
                },
                {
                    "id": 14718520,
                    "contents": "Universal series induced by approximate identities and some relevant applications.\nWe prove the existence of series [Formula: see text], whose coefficients [Formula: see text] are in [Formula: see text] and whose terms [Formula: see text] are translates by rational vectors in [Formula: see text] of a family of approximations to the identity, having the property that the partial sums are dense in various spaces of functions such as Wiener's algebra [Formula: see text], [Formula: see text], [Formula: see text], [Formula: see text], for every [Formula: see text], and the space of measurable functions. Applying this theory to particular situations, we establish approximations by such series to solutions of the heat and Laplace equations as well as to probability density functions.",
                    "score": 0.8604140281677246
                },
                {
                    "id": 10299610,
                    "contents": "Algorithm for computation of Zernike polynomials expansion coefficients.\nA numerically efficient algorithm for expanding a function in a series of Zernike polynomials is presented. The algorithm evaluates the expansion coefficients through the standard 2-D integration formula derived from the Zernike polynomials' orthogonal properties. Quadratic approximations are used along with the function to be expanded to eliminate the computational problems associated with integrating the oscillatory behavior of the Zernike polynomials. This yields a procedure that is both fast and numerically accurate. Comparisons are made between the proposed scheme and a procedure using a nested 2-D Simpson's integration rule. The results show that typically at least a fourfold improvement in computational speed can be expected in practical use.",
                    "score": 0.8602203130722046
                },
                {
                    "id": 12379440,
                    "contents": "On the higher power sums of reciprocal higher-order sequences.\nLet {u(n)} be a higher-order linear recursive sequence. In this paper, we use the properties of error estimation and the analytic method to study the reciprocal sums of higher power of higher-order sequences. Then we establish several new and interesting identities relating to the infinite and finite sums.",
                    "score": 0.8538684248924255
                },
                {
                    "id": 7634727,
                    "contents": "A unifying view of wiener and volterra theory and polynomial kernel regression.\nVolterra and Wiener series are perhaps the best-understood nonlinear system representations in signal processing. Although both approaches have enjoyed a certain popularity in the past, their application has been limited to rather low-dimensional and weakly nonlinear systems due to the exponential growth of the number of terms that have to be estimated. We show that Volterra and Wiener series can be represented implicitly as elements of a reproducing kernel Hilbert space by using polynomial kernels. The estimation complexity of the implicit representation is linear in the input dimensionality and independent of the degree of nonlinearity. Experiments show performance advantages in terms of convergence, interpretability, and system sizes that can be handled.",
                    "score": 0.853289783000946
                },
                {
                    "id": 9691374,
                    "contents": "Fast algorithms for classical physics.\nSome of the recently developed fast summation methods that have arisen in scientific computing are described. These methods require an amount of work proportional to N or N log N to evaluate all pairwise interactions in an ensemble of N particles. Traditional methods, by contrast, require an amount of work proportional to N(2). As a result, largescale simulations can be carried out using only modest computer resources. In combination with supercomputers, it is possible to address questions that were previously out of reach. Problems from diffusion, gravitation, and wave propagation are considered.",
                    "score": 0.8531262874603271
                },
                {
                    "id": 17269017,
                    "contents": "Correction to: Explicit upper bound for the average number of divisors of irreducible quadratic polynomials.\n[This corrects the article DOI: 10.1007/s00605-017-1061-y.].",
                    "score": 0.8524232506752014
                },
                {
                    "id": 7952328,
                    "contents": "Discrete sums for the rapid determination of exponential decay constants.\nSeveral computational methods are presented for the rapid extraction of decay time constants from discrete exponential data. Two methods are found to be comparably fast and highly accurate. They are corrected successive integration and a method involving the Fourier transform (FT) of the data and the application of an expression that does not assume continuous data. FT methods in the literature are found to introduce significant systematic error owing to the assumption that data are continuous. Corrected successive integration methods in the literature are correct, but we offer a more direct way of applying them which we call linear regression of the sum. We recommend the use of the latter over FT-based methods, as the FT methods are more affected by noise in the original data.",
                    "score": 0.8521959781646729
                },
                {
                    "id": 8058211,
                    "contents": "A computationally simple and robust method to detect determinism in a time series.\nWe present a new, simple, and fast computational technique, termed the incremental slope (IS), that can accurately distinguish between deterministic from stochastic systems even when the variance of noise is as large or greater than the signal, and remains robust for time-varying signals. The IS method is more accurate than the widely utilized Poincare plot analysis especially when the data are severely contaminated by noise. The efficacy of the IS is demonstrated with several simulated deterministic and stochastic signals.",
                    "score": 0.8518618941307068
                },
                {
                    "id": 9617151,
                    "contents": "A Simple Proof of Siegel's Theorem.\nA brief and simple proof of Siegel's celebrated theorem that h(d) &gt;&gt; d(1/2-[unk]), as d --&gt; infinity, is given. Here h(d) denotes the class number of the quadratic field Q([unk]-d). Simple proofs that do not make use of algebraic number theory have been previously given by Estermann and Chowla.",
                    "score": 0.8503917455673218
                },
                {
                    "id": 20573763,
                    "contents": "The exponentiated generalized power series: Family of distributions: theory, properties and applications.\nWe propose a new generalized family of distributions called the exponentiated generalized power series (EGPS) family of distributions and study its sub-model, the exponentiated generalized logarithmic (EGL) class of distributions, in detail. The structural properties of the new model (EGPS) and its sub-model (EGL) distribution including moments, order statistics, Rényi entropy, and maximum likelihood estimates are derived. We used the method of maximum likelihood to estimate the parameters of this new family of distributions. Simulation study was carried out to examine the bias and the mean square error of the maximum likelihood estimators for each of the model's parameters. Finally, we showed real life data examples to illustrate the models' applicability, flexibility and usefulness.",
                    "score": 0.850333571434021
                },
                {
                    "id": 8254968,
                    "contents": "Detrended cross-correlation analysis: a new method for analyzing two nonstationary time series.\nHere we propose a new method, detrended cross-correlation analysis, which is a generalization of detrended fluctuation analysis and is based on detrended covariance. This method is designed to investigate power-law cross correlations between different simultaneously recorded time series in the presence of nonstationarity. We illustrate the method by selected examples from physics, physiology, and finance.",
                    "score": 0.8501917719841003
                },
                {
                    "id": 23389571,
                    "contents": "A fast algorithm for computing the Boys function.\nWe present a new fast algorithm for computing the Boys function using a nonlinear approximation of the integrand via exponentials. The resulting algorithms evaluate the Boys function with real and complex valued arguments and are competitive with previously developed algorithms for the same purpose.",
                    "score": 0.8497642278671265
                },
                {
                    "id": 9616968,
                    "contents": "Airey's Converging Factor.\nAsmptotic series for the calculation of functions, for values of the argument numerically &gt;1, start off with terms whose numerical values decrease but, at a certain stage, the terms begin to increase in numerical value and must be ignored. At this stage, there may be two adjacent terms of equal numerical value; when the least term of the asymptotic series is spoken of, it is in reference to the first of these two terms. The sum of the initial terms of the asymptotic series up to, and including, the least term often furnishes a fair approximation to the desired value of the function being evaluated. It was early observed by computers that if the terms of the asymptotic series alternate in sign, this approximation was often improved by replacing the least term by its half. The factor by which the least term of the asymptotic series must be multiplied so that the true value of the function being evaluated is obtained by addition of this modified least term to the remaining initial terms of the asymptotic series is known as the converging factor for the asymptotic series. The converging factor for the asymptotic series involved in the calculation of the exponential integral, for large negative values of the argument, was given as a power series in the reciprocal of the argument by Airey; the first term of this series is (1/2). A method for the determination of the coefficients of this series is given.",
                    "score": 0.8493599891662598
                },
                {
                    "id": 15539424,
                    "contents": "On the additive properties of the fat-shattering dimension.\nThe properties of the VC-dimension under various compositions are well-understood, but this is much less the case for classes of continuous functions. In this brief, we show that a commonly used scale-sensitive dimension, Vγ, is much less well-behaved under Minkowski summation than its VC cousin, while the fat-shattering dimension retains some compositional similarity to the VC-dimension. As an application, we analyze the fat-shattering dimension of trigonometric functions and series.",
                    "score": 0.8488289713859558
                },
                {
                    "id": 9618297,
                    "contents": "Rational approximations to linear forms of exponentials and binomials.\nMahler proved the following quantitative result supplementing the Lindemann-Weierstrass theorem: Sigma(i=0) (n)C(i)e(ri) &gt; H(-n-epsilon) for any distinct rational numbers r(0),r(1),..., r(n) and rational integers C(0),C(1),...,C(n) with H = max(0&lt;/=i&lt;/=n) C(i). We improve Mahler's estimate by replacing exponentials e(ri) by linearly independent linear forms L(i) = Sigma L(ij)e(sij) with rational L(ij),s(ij)i = 0,1,...,n. Similar results are obtained for binomials (a/b)(ri) or Sigma L(ij)(a/b)(sij) with integers a,b and logb/loga &gt; 1 - epsilon. The simplest examples of new numbers with the irrationality exponent \"2 + epsilon\" are sinh 1 or sin 1.",
                    "score": 0.8483335971832275
                },
                {
                    "id": 9652484,
                    "contents": "Systematic series expansions for processes on networks.\nWe use series expansions to study dynamics of equilibrium and nonequilibrium systems on networks. This analytical method enables us to include detailed nonuniversal effects of the network structure. We show that even low order calculations produce results which compare accurately to numerical simulation, while the results can be systematically improved. We show that certain commonly accepted analytical results for the critical point on networks with a broad degree distribution need to be modified in certain cases due to disassortativity; the present method is able to take into account the assortativity at sufficiently high order, while previous results correspond to leading and second order approximations in this method. Finally, we apply this method to real-world data.",
                    "score": 0.8473930358886719
                },
                {
                    "id": 9617330,
                    "contents": "Maximal functions: Poisson integrals on symmetric spaces.\nLet u be a harmonic function on a symmetric space which is the Poisson integral of a function f in L(p), 1 &lt;/= p &lt;/= infinity. Then u converges restrictedly and admissibly to f almost everywhere. This result is proved by obtaining an appropriate maximal theorem which takes into account the structure of the Poisson kernel.",
                    "score": 0.8469884395599365
                },
                {
                    "id": 12258677,
                    "contents": "A new sum analogous to Gauss sums and its fourth power mean.\nThe main purpose of this paper is to use the analytic methods and the properties of Gauss sums to study the computational problem of one kind of new sum analogous to Gauss sums and give an interesting fourth power mean and a sharp upper bound estimate for it. ",
                    "score": 0.8468175530433655
                },
                {
                    "id": 6590341,
                    "contents": "Approximate entropy (ApEn) as a complexity measure.\nApproximate entropy (ApEn) is a recently developed statistic quantifying regularity and complexity, which appears to have potential application to a wide variety of relatively short (greater than 100 points) and noisy time-series data. The development of ApEn was motivated by data length constraints commonly encountered, e.g., in heart rate, EEG, and endocrine hormone secretion data sets. We describe ApEn implementation and interpretation, indicating its utility to distinguish correlated stochastic processes, and composite deterministic/ stochastic models. We discuss the key technical idea that motivates ApEn, that one need not fully reconstruct an attractor to discriminate in a statistically valid manner-marginal probability distributions often suffice for this purpose. Finally, we discuss why algorithms to compute, e.g., correlation dimension and the Kolmogorov-Sinai (KS) entropy, often work well for true dynamical systems, yet sometimes operationally confound for general models, with the aid of visual representations of reconstructed dynamics for two contrasting processes. (c) 1995 American Institute of Physics.",
                    "score": 0.8467404842376709
                },
                {
                    "id": 6146107,
                    "contents": "Predictability, complexity, and learning.\nWe define predictive information I(pred)(T) as the mutual information between the past and the future of a time series. Three qualitatively different behaviors are found in the limit of large observation times T:I(pred)(T) can remain finite, grow logarithmically, or grow as a fractional power law. If the time series allows us to learn a model with a finite number of parameters, then I(pred)(T) grows logarithmically with a coefficient that counts the dimensionality of the model space. In contrast, power-law growth is associated, for example, with the learning of infinite parameter (or nonparametric) models such as continuous functions with smoothness constraints. There are connections between the predictive information and measures of complexity that have been defined both in learning theory and the analysis of physical systems through statistical mechanics and dynamical systems theory. Furthermore, in the same way that entropy provides the unique measure of available information consistent with some simple and plausible conditions, we argue that the divergent part of I(pred)(T) provides the unique measure for the complexity of dynamics underlying a time series. Finally, we discuss how these ideas may be useful in problems in physics, statistics, and biology.",
                    "score": 0.8462357521057129
                },
                {
                    "id": 23167501,
                    "contents": "Simple renormalization schemes for multiple scattering series expansions.\nA number of renormalization schemes for improving the convergence of multiple scattering series expansions are investigated. Numerical tests on a small Cu(111) cluster demonstrate their effectiveness, for example increasing the rate of convergence by up to a factor 2 or by transforming a divergent series into a convergent one. These techniques can greatly facilitate multiple scattering calculations, especially for spectroscopies such as photoelectron diffraction, Auger electron diffraction, low energy electron diffraction <ietc.</i, where an electron propagates with a kinetic energy of hundreds of eV in a cluster of hundreds of atoms.",
                    "score": 0.8460327386856079
                },
                {
                    "id": 9962175,
                    "contents": "Computing the multifractal spectrum from time series: an algorithmic approach.\nWe show that the existing methods for computing the f(alpha) spectrum from a time series can be improved by using a new algorithmic scheme. The scheme relies on the basic idea that the smooth convex profile of a typical f(alpha) spectrum can be fitted with an analytic function involving a set of four independent parameters. While the standard existing schemes [P. Grassberger et al., J. Stat. Phys. 51, 135 (1988); A. Chhabra and R. V. Jensen, Phys. Rev. Lett. 62, 1327 (1989)] generally compute only an incomplete f(alpha) spectrum (usually the top portion), we show that this can be overcome by an algorithmic approach, which is automated to compute the D(q) and f(alpha) spectra from a time series for any embedding dimension. The scheme is first tested with the logistic attractor with known f(alpha) curve and subsequently applied to higher-dimensional cases. We also show that the scheme can be effectively adapted for analyzing practical time series involving noise, with examples from two widely different real world systems. Moreover, some preliminary results indicating that the set of four independent parameters may be used as diagnostic measures are also included.",
                    "score": 0.8459209203720093
                },
                {
                    "id": 15997402,
                    "contents": "The rapidly convergent solutions of strongly nonlinear oscillators.\nBased on the harmonic balance method (HBM), an approximate solution is determined from the integral expression (i.e., first order differential equation) of some strongly nonlinear oscillators. Usually such an approximate solution is obtained from second order differential equation. The advantage of the new approach is that the solution converges significantly faster than that obtained by the usual HBM as well as other analytical methods. By choosing some well known nonlinear oscillators, it has been verified that an n-th (n ≥ 2) approximate solution (concern of this article) is very close to (2n - 1)-th approximations obtained by usual HBM. ",
                    "score": 0.8455904722213745
                },
                {
                    "id": 15791453,
                    "contents": "Nonlinear time-series analysis revisited.\nIn 1980 and 1981, two pioneering papers laid the foundation for what became known as nonlinear time-series analysis: the analysis of observed data-typically univariate-via dynamical systems theory. Based on the concept of state-space reconstruction, this set of methods allows us to compute characteristic quantities such as Lyapunov exponents and fractal dimensions, to predict the future course of the time series, and even to reconstruct the equations of motion in some cases. In practice, however, there are a number of issues that restrict the power of this approach: whether the signal accurately and thoroughly samples the dynamics, for instance, and whether it contains noise. Moreover, the numerical algorithms that we use to instantiate these ideas are not perfect; they involve approximations, scale parameters, and finite-precision arithmetic, among other things. Even so, nonlinear time-series analysis has been used to great advantage on thousands of real and synthetic data sets from a wide variety of systems ranging from roulette wheels to lasers to the human heart. Even in cases where the data do not meet the mathematical or algorithmic requirements to assure full topological conjugacy, the results of nonlinear time-series analysis can be helpful in understanding, characterizing, and predicting dynamical systems. ",
                    "score": 0.8455566167831421
                },
                {
                    "id": 22388509,
                    "contents": "Extended Wang sum and associated products.\nThe Wang sum involving the exponential sums of Lerch's Zeta functions is extended to the finite sum of the Huwitz-Lerch Zeta function to derive sums and products involving cosine and tangent trigonometric functions. The general theorem used to derive these sums and products is in the form of the finite sum over positive integers of the Hurwitz-Lerch Zeta function where the associated parameters are general complex numbers. New Hurwitz-Lerch Zeta function recurrence identities with consecutive neighbours are derived. Some finite sum and product formulae examples involving cosine, tangent and the product of cosine and tangent functions are also derived and evaluated.",
                    "score": 0.8453848958015442
                },
                {
                    "id": 19088042,
                    "contents": "Some new results on convex sequences.\nIn the present paper, we obtained a main theorem related to factored infinite series. Some new results are also deduced.",
                    "score": 0.8452999591827393
                },
                {
                    "id": 2667573,
                    "contents": "Further remarks on convergence of decomposition method.\nThe decomposition method solves a wide class of nonlinear functional equations. This method uses a series solution with rapid convergence. This paper is intended as a useful review and clarification of related issues.",
                    "score": 0.8452672958374023
                },
                {
                    "id": 19477880,
                    "contents": "Correction: The complex dynamics of products and its asymptotic properties.\n[This corrects the article DOI: 10.1371/journal.pone.0177360.].",
                    "score": 0.8440278768539429
                },
                {
                    "id": 21716799,
                    "contents": "Computing sums in terms of beta, polygamma, and Gauss hypergeometric functions.\nIn the paper, by virtue of the binomial inversion formula, a general formula of higher order derivatives for a ratio of two differentiable function, and other techniques, the authors compute several sums in terms of the beta function and its partial derivatives, polygamma functions, the Gauss hypergeometric function, and a determinant. These results generalize known ones in combinatorics.",
                    "score": 0.8440091013908386
                },
                {
                    "id": 20867802,
                    "contents": "Practical rules for summing the series of the Tweedie probability density function with high-precision arithmetic.\nFor some ranges of its parameters and arguments, the series for Tweedie probability density functions are sometimes exceedingly difficult to sum numerically. Existing numerical implementations utilizing inversion techniques and properties of stable distributions can cope with these problems, but no single one is successful in all cases. In this work we investigate heuristically the nature of the problem, and show that it is not related to the order of summation of the terms. Using a variable involved in the analytical proof of convergence of the series, the critical parameter for numerical non-convergence (\"alpha\") is identified, and an heuristic criterion is developed to avoid numerical non-convergence for a reasonably large sub-interval of the latter. With these practical rules, simple summation algorithms provide sufficiently robust results for the calculation of the density function and its definite integrals. These implementations need to utilize high-precision arithmetic, and are programmed in the Python programming language. A thorough comparison with existing R functions allows the identification of cases when the latter fail, and provide further guidance to their use.",
                    "score": 0.8438857197761536
                },
                {
                    "id": 18974547,
                    "contents": "Correction: Fitting power-laws in empirical data with estimators that work for all exponents.\n[This corrects the article DOI: 10.1371/journal.pone.0170920.].",
                    "score": 0.8437659740447998
                },
                {
                    "id": 8378619,
                    "contents": "Fundamentals of superresolution.\nThe fundamental principles behind superresolution are discussed, and different schemes classified. Different definitions for localization of a wave are discussed.",
                    "score": 0.8433759212493896
                },
                {
                    "id": 3888305,
                    "contents": "Metrics from nonlinear dynamics adapted for characterizing the behavior of nonequilibrium enzymatic rate functions.\nSeveral metrics from nonlinear dynamics and statistical mechanics have been characterized on computer-generated number series with various signal-to-noise ratios, demonstrating their individual reliability as a function of sample size and their relationships to each other. The root mean square (RMS) evaluates amplitude, and the power spectral density (PSD) provides a visual display of the frequency spectrum; both measures have very high reliability even for an N as low as 50. The Fractal Dimension (D) is shown to converge rapidly and also to be reliable when N is as low as 50. These three measures (RMS, PSD, and D) have been applied to the complex kinetics of tyrosine hydroxylase time courses (50-point curves) at various BH4 concentrations (near physiological, but far from equilibrium levels). Recently developed measures of spectral entropy and the Liapunov Exponent, -lambda are also characterized.",
                    "score": 0.8431746959686279
                },
                {
                    "id": 6590342,
                    "contents": "Tests for nonlinearity in short stationary time series.\nTo compare direct tests for detecting determinism in chaotic time series, data from Henon, Lorenz, and Mackey-Glass equations were contaminated with various levels of additive colored noise. These data were analyzed with a variety of recently developed tests for determinism, and the results compared. (c) 1995 American Institute of Physics.",
                    "score": 0.84302818775177
                },
                {
                    "id": 14442606,
                    "contents": "Entropy rate estimates from mutual information.\nWe show how to estimate the Kolmogorov-Sinai entropy rate for chaotic systems using the mutual information function, easily obtainable from experimental time series. We state the conditions under which the relationship is exact, and explore the usefulness of the approach for both maps and flows. We also explore refinements of the method, and study its convergence properties as a function of time series length.",
                    "score": 0.8430044651031494
                },
                {
                    "id": 18347567,
                    "contents": "Monotone and fast computation of Euler's constant.\nWe construct sequences of finite sums [Formula: see text] and [Formula: see text] converging increasingly and decreasingly, respectively, to the Euler-Mascheroni constant <iγ</i at the geometric rate 1/2. Such sequences are easy to compute and satisfy complete monotonicity-type properties. As a consequence, we obtain an infinite product representation for [Formula: see text] converging in a monotone and fast way at the same time. We use a probabilistic approach based on a differentiation formula for the gamma process.",
                    "score": 0.8424316048622131
                },
                {
                    "id": 9097437,
                    "contents": "Systematic perturbation calculation of integrals with applications to physics.\nIn this paper we generalize and improve a method for calculating the period of a classical oscillator and other integrals of physical interest, which was recently developed by some of the authors. We derive analytical expressions that prove to be more accurate than those commonly found in the literature, and test the convergence of the series produced by the approach.",
                    "score": 0.8421297669410706
                },
                {
                    "id": 6590021,
                    "contents": "Practical implementation of nonlinear time series methods: The TISEAN package.\nWe describe the implementation of methods of nonlinear time series analysis which are based on the paradigm of deterministic chaos. A variety of algorithms for data representation, prediction, noise reduction, dimension and Lyapunov estimation, and nonlinearity testing are discussed with particular emphasis on issues of implementation and choice of parameters. Computer programs that implement the resulting strategies are publicly available as the TISEAN software package. The use of each algorithm will be illustrated with a typical application. As to the theoretical background, we will essentially give pointers to the literature. (c) 1999 American Institute of Physics.",
                    "score": 0.8417816162109375
                },
                {
                    "id": 23351778,
                    "contents": "A Class of Double Integrals Involving Gaussian and Trigonometric Factors.\nThe five parameter double integral <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow <mml:mrow<mml:msubsup<mml:mo∫</mml:mo <mml:mn0</mml:mn <mml:mi∞</mml:mi</mml:msubsup <mml:mid</mml:mi</mml:mrow <mml:miy</mml:mi <mml:mtextexp</mml:mtext <mml:mrow<mml:mo(</mml:mo <mml:mrow<mml:mo-</mml:mo <mml:msup<mml:mip</mml:mi <mml:mn2</mml:mn</mml:msup <mml:msup<mml:miy</mml:mi <mml:mn2</mml:mn</mml:msup </mml:mrow <mml:mo)</mml:mo</mml:mrow <mml:mtextsin</mml:mtext <mml:mo(</mml:mo <mml:miβ</mml:mi <mml:miy</mml:mi <mml:mo+</mml:mo <mml:miθ</mml:mi <mml:mo)</mml:mo</mml:mrow </mml:math times <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow <mml:mrow<mml:msubsup<mml:mo∫</mml:mo <mml:mn0</mml:mn <mml:miy</mml:mi</mml:msubsup <mml:mid</mml:mi</mml:mrow <mml:mix</mml:mi <mml:mtextexp</mml:mtext <mml:mrow<mml:mo(</mml:mo <mml:mrow<mml:mo-</mml:mo <mml:msup<mml:mix</mml:mi <mml:mn2</mml:mn</mml:msup </mml:mrow <mml:mo)</mml:mo</mml:mrow <mml:mtextcos</mml:mtext <mml:mo(</mml:mo <mml:miϵ</mml:mi <mml:miβ</mml:mi <mml:mix</mml:mi <mml:mo+</mml:mo <mml:miϕ</mml:mi <mml:mo)</mml:mo</mml:mrow </mml:math is evaluated in terms of Fourier transforms of exp(- <ix</i <sup2</sup)erfc(<iαx</i). Some new expressions for these transforms are obtained.",
                    "score": 0.8414695262908936
                },
                {
                    "id": 17926147,
                    "contents": "A new type of Taylor series expansion.\nWe present a variant of the classical integration by parts to introduce a new type of Taylor series expansion and to present some closed forms for integrals involving Jacobi and Laguerre polynomials, which cannot be directly obtained by usual symbolic computation programs, i.e., only some very specific values can be computed by the mentioned programs. An error analysis is given in the sequel for the introduced expansion.",
                    "score": 0.8414669036865234
                },
                {
                    "id": 8682396,
                    "contents": "Computing second derivatives in feed-forward networks: a review.\nThe calculation of second derivatives is required by recent training and analysis techniques of connectionist networks, such as the elimination of superfluous weights, and the estimation of confidence intervals both for weights and network outputs. We review and develop exact and approximate algorithms for calculating second derivatives. For networks with |w| weights, simply writing the full matrix of second derivatives requires O(|w|(2)) operations. For networks of radial basis units or sigmoid units, exact calculation of the necessary intermediate terms requires of the order of 2h+2 backward/forward-propagation passes where h is the number of hidden units in the network. We also review and compare three approximations (ignoring some components of the second derivative, numerical differentiation, and scoring). The algorithms apply to arbitrary activation functions, networks, and error functions.",
                    "score": 0.8412207365036011
                },
                {
                    "id": 4319805,
                    "contents": "TSAN: a package for time series analysis.\nMany biomedical data are in the form of time series. Analyses of these data include: (1) search for any biorhythm; (2) test of homogeneity of several time series; (3) assessment of stationarity; (4) test of normality of the time series histogram; (5) evaluation of dependence between data points. In this paper we present a subroutine package called TSAN. It is developed to accomplish these tasks. Computational methods, as well as flowcharts, for these subroutines are described. Two sample runs are demonstrated.",
                    "score": 0.8409010171890259
                },
                {
                    "id": 5937873,
                    "contents": "Fast algorithm for generating long self-affine profiles.\nWe introduce a fast algorithm for generating long self-affine profiles. The algorithm, which is based on the fast wavelet transform, is faster than the conventional Fourier filtering algorithm. In addition to increased performance for large systems, the algorithm, named the wavelet filtering algorithm, a priori gives rise to profiles for which the long-range correlation extends throughout the entire system independently of the length scale.",
                    "score": 0.8403646945953369
                }
            ],
            "metric_score": {
                "retrieval_recall": 1,
                "retrieval_precision": 0.2
            }
        }
    },
    {
        "id": "test_4",
        "question": "The relationship introduced in Problem $1-48$ has been interpreted to mean that a particle of mass $m\\left(E=m c^2\\right)$ can materialize from nothing provided that it returns to nothing within a time $\\Delta t \\leq h / m c^2$. Particles that last for time $\\Delta t$ or more are called real particles; particles that last less than time $\\Delta t$ are called virtual particles. The mass of the charged pion, a subatomic particle, is $2.5 \\times 10^{-28} \\mathrm{~kg}$. What is the minimum lifetime if the pion is to be considered a real particle?",
        "golden_answers": [
            " 2.9"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 6979271,
                    "contents": "The concave-convex procedure.\nThe concave-convex procedure (CCCP) is a way to construct discrete-time iterative dynamical systems that are guaranteed to decrease global optimization and energy functions monotonically. This procedure can be applied to almost any optimization problem, and many existing algorithms can be interpreted in terms of it. In particular, we prove that all expectation-maximization algorithms and classes of Legendre minimization and variational bounding algorithms can be reexpressed in terms of CCCP. We show that many existing neural network and mean-field theory algorithms are also examples of CCCP. The generalized iterative scaling algorithm and Sinkhorn's algorithm can also be expressed as CCCP by changing variables. CCCP can be used both as a new way to understand, and prove the convergence of, existing optimization algorithms and as a procedure for generating new algorithms.",
                    "score": 0.8791881799697876
                },
                {
                    "id": 11626417,
                    "contents": "Current trends in finite-time thermodynamics.\nThe cornerstone of finite-time thermodynamics is all about the price of haste and how to minimize it. Reversible processes may be ultimately efficient, but they are unrealistically slow. In all situations-chemical, mechanical, economical-we pay extra to get the job done quickly. Finite-time thermodynamics can be used to develop methods to limit that extra expenditure, be it in energy, entropy production, money, or something entirely different. Finite-time thermodynamics also includes methods to calculate the optimal path or mode of operation to achieve this minimal expenditure. The concept is to place the system of interest in contact with a time-varying environment which will coax the system along the desired path, much like guiding a horse along by waving a carrot in front of it.",
                    "score": 0.875817596912384
                },
                {
                    "id": 22566453,
                    "contents": "Schrödinger's Cat Meets Occam's Razor.\nWe discuss V.P. Belavkin's approach to the Schrödinger cat problem and show its close relation to ideas based on superselection and interaction with the environment developed by N.P. Landsman. The purpose of the paper is to explain these ideas in the most simple possible context, namely: discrete time and separable Hilbert spaces, in order to make them accessible to those coming from the philosophy of science and not too happy with idiosyncratic notation and terminology and sophisticated mathematical tools. Conventional elementary mathematical descriptions of quantum mechanics take \"measurement\" to be a primitive concept. Paradoxes arise when we choose to consider smaller or larger systems as measurement devices in their own right, by making different and apparently arbitrary choices of location of the \"Heisenberg cut\". Various quantum interpretations have different resolutions of the paradox. In Belavkin's approach, the classical world around us does really exist, and it evolves stochastically and dynamically in time according to probability laws following from successive applications of the Born law. It is a collapse theory. The quantum/classical distinction is determined by the arrow of time. The underlying unitary evolution of the wave-function of the universe enables the designation of a collection of beables which grows as time evolves, and which therefore can be assigned random, classical trajectories. In a slogan: the past is particles, the future is a wave. We, living in the now, are located on the cutting edge between past and future.",
                    "score": 0.8732814192771912
                },
                {
                    "id": 19581677,
                    "contents": "OUR EXPERIENCE \nThe article raises the problem of optimization and",
                    "score": 0.8732028007507324
                },
                {
                    "id": 22499973,
                    "contents": "Some minimal notes on notation and minima: A comment on \"How particular is the physics of the free energy principle?\" by Aguilera, Millidge, Tschantz, and Buckley.\nWe comment on a technical critique of the free energy principle in linear systems by Aguilera, Millidge, Tschantz, and Buckley, entitled \"How Particular is the Physics of the Free Energy Principle?\" Aguilera and colleagues identify an ambiguity in the flow of the mode of a system, and we discuss the context for this ambiguity in earlier papers, and their proposal of a more adequate interpretation of these equations. Following that, we discuss a misinterpretation in their treatment of surprisal and variational free energy, especially with respect to their gradients and their minima. In sum, we argue that the results in the target paper are accurate and stand up to rigorous scrutiny; we also highlight that they, nonetheless, do not undermine the FEP.",
                    "score": 0.8700888156890869
                },
                {
                    "id": 3071350,
                    "contents": "DIVANU: a new method for global optimization.\nWe propose a new method, DIVANU (Diminution of Variables Number), for numerically solving minimization problems involving any function of any variables. This method uses a reducing transformation. We have used this method for applications to biological problems. The identification of models is treated.",
                    "score": 0.8689377307891846
                },
                {
                    "id": 15625953,
                    "contents": "Determining the Tsallis parameter via maximum entropy.\nThe nonextensive entropic measure proposed by Tsallis [C. Tsallis, J. Stat. Phys. 52, 479 (1988)] introduces a parameter, q, which is not defined but rather must be determined. The value of q is typically determined from a piece of data and then fixed over the range of interest. On the other hand, from a phenomenological viewpoint, there are instances in which q cannot be treated as a constant. We present two distinct approaches for determining q depending on the form of the equations of constraint for the particular system. In the first case the equations of constraint for the operator Ô can be written as Tr(F(q)Ô)=C, where C may be an explicit function of the distribution function F. We show that in this case one can solve an equivalent maxent problem which yields q as a function of the corresponding Lagrange multiplier. As an illustration the exact solution of the static generalized Fokker-Planck equation (GFPE) is obtained from maxent with the Tsallis enropy. As in the case where C is a constant, if q is treated as a variable within the maxent framework the entropic measure is maximized trivially for all values of q. Therefore q must be determined from existing data. In the second case an additional equation of constraint exists which cannot be brought into the above form. In this case the additional equation of constraint may be used to determine the fixed value of q.",
                    "score": 0.8652611970901489
                },
                {
                    "id": 11700195,
                    "contents": "Problem-solving test: The mechanism of protein synthesis.\nTerms to be familiar with before you start to solve the test: protein synthesis, ribosomes, amino acids, peptides, peptide bond, polypeptide chain, N- and C-terminus, hemoglobin, α- and β-globin chains, radioactive labeling, [(3) H] and [(14) C]leucine, cytosol, differential centrifugation, density gradient centrifugation, trypsin, electrophoresis, chromatography.",
                    "score": 0.8645152449607849
                },
                {
                    "id": 19147774,
                    "contents": "[A short note to the last two sentences of \"Entirely And For Nothing\"].\nNo abstract available.",
                    "score": 0.864305853843689
                },
                {
                    "id": 16521664,
                    "contents": "A Look at the Generalized Heron Problem through the Lens of Majorization-Minimization.\nIn a recent issue of this journal, Mordukhovich, Nam, and Salinas pose and solve an interesting non-differentiable generalization of the Heron problem in the framework of modern convex analysis. In the generalized Heron problem, one is given <ik</i + 1 closed convex sets in ℝ <sup<id</i</sup equipped with its Euclidean norm and asked to find the point in the last set such that the sum of the distances to the first <ik</i sets is minimal. In later work, the authors generalize the Heron problem even further, relax its convexity assumptions, study its theoretical properties, and pursue subgradient algorithms for solving the convex case. Here, we revisit the original problem solely from the numerical perspective. By exploiting the majorization-minimization (MM) principle of computational statistics and rudimentary techniques from differential calculus, we are able to construct a very fast algorithm for solving the Euclidean version of the generalized Heron problem.",
                    "score": 0.8638685345649719
                },
                {
                    "id": 19368151,
                    "contents": "[72 years of existence].\nNo Abstract available.",
                    "score": 0.863732099533081
                },
                {
                    "id": 14995853,
                    "contents": "Maximum caliber inference and the stochastic Ising model.\nWe investigate the maximum caliber variational principle as an inference algorithm used to predict dynamical properties of complex nonequilibrium, stationary, statistical systems in the presence of incomplete information. Specifically, we maximize the path entropy over discrete time step trajectories subject to normalization, stationarity, and detailed balance constraints together with a path-dependent dynamical information constraint reflecting a given average global behavior of the complex system. A general expression for the transition probability values associated with the stationary random Markov processes describing the nonequilibrium stationary system is computed. By virtue of our analysis, we uncover that a convenient choice of the dynamical information constraint together with a perturbative asymptotic expansion with respect to its corresponding Lagrange multiplier of the general expression for the transition probability leads to a formal overlap with the well-known Glauber hyperbolic tangent rule for the transition probability for the stochastic Ising model in the limit of very high temperatures of the heat reservoir.",
                    "score": 0.863492488861084
                },
                {
                    "id": 6251544,
                    "contents": "Optimal prediction and the Klein-Gordon equation.\nThe method of optimal prediction is applied to calculate the future means of solutions to the Klein-Gordon equation. It is shown that, in an appropriate probability space, the difference between the average of all solutions that satisfy certain constraints at time t = 0 and the average computed by an approximate method is small with high probability.",
                    "score": 0.8627530336380005
                },
                {
                    "id": 20648694,
                    "contents": "The Second Law of Thermodynamics as a Force Law.\nThe second law of thermodynamics states the increase of entropy, Δ S &gt; 0 , for real processes from state A to state B at constant energy from chemistry over biological life and engines to cosmic events. The connection of entropy to information, phase-space, and heat is helpful but does not immediately convince observers of the validity and basis of the second law. This gave grounds for finding a rigorous, but more easily acceptable reformulation. Here, we show using statistical mechanics that this principle is equivalent to a force law ⟨ ⟨ f ⟩ ⟩ &gt; 0 in systems where mass centers and forces can be identified. The sign of this net force--the average mean force along a path from A to B--determines the direction of the process. The force law applies to a wide range of processes from machines to chemical reactions. The explanation of irreversibility by a driving force appears more plausible than the traditional formulation as it emphasizes the cause instead of the effect of motions.",
                    "score": 0.861775279045105
                },
                {
                    "id": 15674834,
                    "contents": "Communication: Maximum caliber is a general variational principle for nonequilibrium statistical mechanics.\nThere has been interest in finding a general variational principle for non-equilibrium statistical mechanics. We give evidence that Maximum Caliber (Max Cal) is such a principle. Max Cal, a variant of maximum entropy, predicts dynamical distribution functions by maximizing a path entropy subject to dynamical constraints, such as average fluxes. We first show that Max Cal leads to standard near-equilibrium results—including the Green-Kubo relations, Onsager's reciprocal relations of coupled flows, and Prigogine's principle of minimum entropy production—in a way that is particularly simple. We develop some generalizations of the Onsager and Prigogine results that apply arbitrarily far from equilibrium. Because Max Cal does not require any notion of \"local equilibrium,\" or any notion of entropy dissipation, or temperature, or even any restriction to material physics, it is more general than many traditional approaches. It also applicable to flows and traffic on networks, for example.",
                    "score": 0.8617348074913025
                },
                {
                    "id": 13058808,
                    "contents": "A derivation of the master equation from path entropy maximization.\nThe master equation and, more generally, Markov processes are routinely used as models for stochastic processes. They are often justified on the basis of randomization and coarse-graining assumptions. Here instead, we derive nth-order Markov processes and the master equation as unique solutions to an inverse problem. We find that when constraints are not enough to uniquely determine the stochastic model, an nth-order Markov process emerges as the unique maximum entropy solution to this otherwise underdetermined problem. This gives a rigorous alternative for justifying such models while providing a systematic recipe for generalizing widely accepted stochastic models usually assumed to follow from the first principles.",
                    "score": 0.8611699938774109
                },
                {
                    "id": 17869918,
                    "contents": "The solution of the sixth Hilbert problem: the ultimate Galilean revolution.\nI argue for a full mathematization of the physical theory, including its axioms, which must contain no physical primitives. In provocative words: 'physics from no physics'. Although this may seem an oxymoron, it is the royal road to keep complete logical coherence, hence falsifiability of the theory. For such a purely mathematical theory the physical connotation must pertain only the interpretation of the mathematics, ranging from the axioms to the final theorems. On the contrary, the postulates of the two current major physical theories either do not have physical interpretation (as for von Neumann's axioms for quantum theory), or contain physical primitives as 'clock', 'rigid rod', 'force', 'inertial mass' (as for special relativity and mechanics). A purely mathematical theory as proposed here, though with limited (but relentlessly growing) domain of applicability, will have the eternal validity of mathematical truth. It will be a theory on which natural sciences can firmly rely. Such kind of theory is what I consider to be the solution of the sixth Hilbert problem. I argue that a prototype example of such a mathematical theory is provided by the novel algorithmic paradigm for physics, as in the recent information-theoretical derivation of quantum theory and free quantum field theory.This article is part of the theme issue 'Hilbert's sixth problem'.",
                    "score": 0.860110878944397
                },
                {
                    "id": 16714914,
                    "contents": "The second laws of quantum thermodynamics.\nThe second law of thermodynamics places constraints on state transformations. It applies to systems composed of many particles, however, we are seeing that one can formulate laws of thermodynamics when only a small number of particles are interacting with a heat bath. Is there a second law of thermodynamics in this regime? Here, we find that for processes which are approximately cyclic, the second law for microscopic systems takes on a different form compared to the macroscopic scale, imposing not just one constraint on state transformations, but an entire family of constraints. We find a family of free energies which generalize the traditional one, and show that they can never increase. The ordinary second law relates to one of these, with the remainder imposing additional constraints on thermodynamic transitions. We find three regimes which determine which family of second laws govern state transitions, depending on how cyclic the process is. In one regime one can cause an apparent violation of the usual second law, through a process of embezzling work from a large system which remains arbitrarily close to its original state. These second laws are relevant for small systems, and also apply to individual macroscopic systems interacting via long-range interactions. By making precise the definition of thermal operations, the laws of thermodynamics are unified in this framework, with the first law defining the class of operations, the zeroth law emerging as an equivalence relation between thermal states, and the remaining laws being monotonicity of our generalized free energies. ",
                    "score": 0.8599709868431091
                },
                {
                    "id": 19787989,
                    "contents": "The Matter of Time.\nAbout a century ago, in the spirit of ancient atomism, the quantum of light was renamed the photon to suggest that it is the fundamental element of everything. Since the photon carries energy in its period of time, a flux of photons inexorably embodies a flow of time. Thus, time comprises periods as a trek comprises legs. The flows of quanta naturally select optimal paths (i.e., geodesics) to level out energy differences in the least amount of time. The corresponding flow equations can be written, but they cannot be solved. Since the flows affect their driving forces, affecting the flows, and so on, the forces (i.e., causes) and changes in motions (i.e., consequences) are inseparable. Thus, the future remains unpredictable. However, it is not all arbitrary but rather bounded by free energy. Eventually, when the system has attained a stationary state where forces tally, there are no causes and no consequences. Since there are no energy differences between the system and its surroundings, the quanta only orbit on and on. Thus, time does not move forward either but circulates.",
                    "score": 0.8594346046447754
                },
                {
                    "id": 16097319,
                    "contents": "Maximum entropy principle for stationary states underpinned by stochastic thermodynamics.\nThe selection of an equilibrium state by maximizing the entropy of a system, subject to certain constraints, is often powerfully motivated as an exercise in logical inference, a procedure where conclusions are reached on the basis of incomplete information. But such a framework can be more compelling if it is underpinned by dynamical arguments, and we show how this can be provided by stochastic thermodynamics, where an explicit link is made between the production of entropy and the stochastic dynamics of a system coupled to an environment. The separation of entropy production into three components allows us to select a stationary state by maximizing the change, averaged over all realizations of the motion, in the principal relaxational or nonadiabatic component, equivalent to requiring that this contribution to the entropy production should become time independent for all realizations. We show that this recovers the usual equilibrium probability density function (pdf) for a conservative system in an isothermal environment, as well as the stationary nonequilibrium pdf for a particle confined to a potential under nonisothermal conditions, and a particle subject to a constant nonconservative force under isothermal conditions. The two remaining components of entropy production account for a recently discussed thermodynamic anomaly between over- and underdamped treatments of the dynamics in the nonisothermal stationary state. ",
                    "score": 0.8584177494049072
                },
                {
                    "id": 2905106,
                    "contents": "The new equation.\nWhat the formula doesn't say is what happens to the other half of all workers, the half no longer needed. Nor does it make clear that as well as being paid twice as much, the favored half will also have to work twice as hard. Hence the paradox that half of the people have money but no time, and the other half have time but no money.",
                    "score": 0.8580053448677063
                },
                {
                    "id": 16630366,
                    "contents": "Sharpening the second law of thermodynamics with the quantum Bayes theorem.\nWe prove a generalization of the classic Groenewold-Lindblad entropy inequality, combining decoherence and the quantum Bayes theorem into a simple unified picture where decoherence increases entropy while observation decreases it. This provides a rigorous quantum-mechanical version of the second law of thermodynamics, governing how the entropy of a system (the entropy of its density matrix, partial-traced over the environment and conditioned on what is known) evolves under general decoherence and observation. The powerful tool of spectral majorization enables both simple alternative proofs of the classic Lindblad and Holevo inequalities without using strong subadditivity, and also novel inequalities for decoherence and observation that hold not only for von Neumann entropy, but also for arbitrary concave entropies. ",
                    "score": 0.8574881553649902
                },
                {
                    "id": 13005689,
                    "contents": "Michaelis-Menten kinetics, the operator-repressor system, and least squares approaches.\nThe Michaelis-Menten (MM) function is a fractional linear function depending on two positive parameters. These can be estimated by nonlinear or linear least squares methods. The non-linear methods, based directly on the defect of the MM function, can fail and not produce any minimizer. The linear methods always produce a unique minimizer which, however, may not be positive. Here we give sufficient conditions on the data such that the nonlinear problem has at least one positive minimizer and also conditions for the minimizer of the linear problem to be positive. We discuss in detail the models and equilibrium relations of a classical operator-repressor system, and we extend our approach to the MM problem with leakage and to reversible MM kinetics. The arrangement of the sufficient conditions exhibits the important role of data that have a concavity property (chemically feasible data). ",
                    "score": 0.857377827167511
                },
                {
                    "id": 9571285,
                    "contents": "Dynamic programming.\nLittle has been done in the study of these intriguing questions, and I do not wish to give the impression that any extensive set of ideas exists that could be called a \"theory.\" What is quite surprising, as far as the histories of science and philosophy are concerned, is that the major impetus for the fantastic growth of interest in brain processes, both psychological and physiological, has come from a device, a machine, the digital computer. In dealing with a human being and a human society, we enjoy the luxury of being irrational, illogical, inconsistent, and incomplete, and yet of coping. In operating a computer, we must meet the rigorous requirements for detailed instructions and absolute precision. If we understood the ability of the human mind to make effective decisions when confronted by complexity, uncertainty, and irrationality then we could use computers a million times more effectively than we do. Recognition of this fact has been a motivation for the spurt of research in the field of neurophysiology. The more we study the information processing aspects of the mind, the more perplexed and impressed we become. It will be a very long time before we understand these processes sufficiently to reproduce them. In any case, the mathematician sees hundreds and thousands of formidable new problems in dozens of blossoming areas, puzzles galore, and challenges to his heart's content. He may never resolve some of these, but he will never be bored. What more can he ask?",
                    "score": 0.856673002243042
                },
                {
                    "id": 19581491,
                    "contents": "[Short comment to \"Entirely and For Nothing\"].\nNo abstract available.",
                    "score": 0.8564864993095398
                },
                {
                    "id": 21881016,
                    "contents": "Generalizing the Marcus equation.\nThe Marcus equation for the rate of an electron-transfer reaction can be generalized to cover larger electronic-interaction matrix elements, irregular free-energy surfaces, and coupling to multiple vibrational modes and to recognize the different effects of vibrational relaxations and pure dephasing. Almost all the information needed to calculate the rate constant can be obtained from a quantum-classical molecular dynamics simulation of the system in the reactant state. Because the final expression for the rate constant does not depend on the reorganization energy, it is insensitive to slow relaxations that follow the reaction.",
                    "score": 0.8563266396522522
                },
                {
                    "id": 6768169,
                    "contents": "Deterministic and stochastic algorithms for mechanical systems under constraints.\nWe discuss the general philosophy underlying the statistical behaviour, the dynamical evolution and the integration of the equations of motion for systems subject to constraints. We also show how all this is related to the treatment of general non-Hamiltonian systems. Then we introduce a family of algorithms derivable from approximations of the evolution operator obtained via the Trotter formula. Generalizing the treatment to time-dependent force fields we also show how one can adapt those algorithms to ordinary stochastic differential equations.",
                    "score": 0.8561520576477051
                },
                {
                    "id": 14914803,
                    "contents": "Finding limiting possibilities of thermodynamic systems by optimization.\nWe consider typical problems of the field called the finite time thermodynamics (also called the optimization thermodynamics). We also outline selected formal methods applied to solve these problems and discuss some results obtained. It is shown that by introducing constraints imposed on the intensity of fluxes and on the magnitude of coefficients in kinetic equations, it is possible not only to investigate limiting possibilities of thermodynamic systems within the considered class of irreversible processes, but also to state and solve problems whose formulation has no meaning in the class of reversible processes.This article is part of the themed issue 'Horizons of cybernetical physics'.",
                    "score": 0.8554881811141968
                },
                {
                    "id": 21821742,
                    "contents": "The fourth law of thermodynamics: steepest entropy ascent.\nWhen thermodynamics is understood as the science (or art) of constructing effective models of natural phenomena by choosing a minimal level of description capable of capturing the essential features of the physical reality of interest, the scientific community has identified a set of general rules that the model must incorporate if it aspires to be consistent with the body of known experimental evidence. Some of these rules are believed to be so general that we think of them as laws of Nature, such as the great conservation principles, whose 'greatness' derives from their generality, as masterfully explained by Feynman in one of his legendary lectures. The second law of thermodynamics is universally contemplated among the great laws of Nature. In this paper, we show that in the past four decades, an enormous body of scientific research devoted to modelling the essential features of non-equilibrium natural phenomena has converged from many different directions and frameworks towards the general recognition (albeit still expressed in different but equivalent forms and language) that another rule is also indispensable and reveals another great law of Nature that we propose to call the 'fourth law of thermodynamics'. We state it as follows: every non-equilibrium state of a system or local subsystem for which entropy is well defined must be equipped with a metric in state space with respect to which the irreversible component of its time evolution is in the direction of steepest entropy ascent compatible with the conservation constraints. To illustrate the power of the fourth law, we derive (nonlinear) extensions of Onsager reciprocity and fluctuation-dissipation relations to the far-non-equilibrium realm within the framework of the rate-controlled constrained-equilibrium approximation (also known as the quasi-equilibrium approximation). This article is part of the theme issue 'Fundamental aspects of nonequilibrium thermodynamics'.",
                    "score": 0.8549415469169617
                },
                {
                    "id": 18256813,
                    "contents": "Erratum to 10.1177/0003702817724164.\n<bDominic V. Poerio and Steven D. Brown</b In this article, we regret there were some revisions that were not made at the request of the authors. On page 379, on lines 7 and 10, within the Theory section, the epsilons should be in bold. On page 380, line 17, first column, first paragraph, the equation should have been displayed as follows: [Formula: see text] On page 380, line 20, first column, first paragraph, the equation should have been displayed as follows: [Formula: see text] On page 380, line 32, first column, first paragraph, the equation should have been displayed as follows: [Formula: see text] On page 380, line 17, second column, first paragraph, the equation should have been displayed as follows: [Formula: see text] On page 380, line 19, second column, first paragraph, the equation should have been displayed as follows: [Formula: see text] On page 380, line 25, second column, first paragraph, the equation should have appeared as [Formula: see text] On page 380, line 28, second column, first paragraph, the equation should have appeared as [Formula: see text] On page 380, line 29, second column, first paragraph, there was an extra character that did not belong in the line. It should instead have been <bX</b<i<subf  </sub</i. On page 380, line 33, second column, first paragraph, the equation should have appeared as [Formula: see text] On page 381, line 30, first column, second paragraph, the equation should have appeared as [Formula: see text] On page 381, line 33, first column, second paragraph, the equation should have appeared as [Formula: see text] On page 381, lines 42 to 43, first column, second paragraph, the equation should have appeared as [Formula: see text] On page 381, lines 14 to 15, second column, second paragraph, the equation should have appeared as [Formula: see text] On page 381, line 25, second column, second paragraph, the equation should have appeared as [Formula: see text] On page 388, there was a typographical error in Figure 3. It should have appeared as On page 390, line 4, first column, first paragraph, the line should have read, \"Figure 5 shows a comparison of the mean training spectrum for Foss1 and Foss2 …\" Reference 11 on page 391 was incomplete. It should have appeared as, \"G. Strang, T. Nguyen. 'Finite Length Signals'. In: G. Strang, T. Nguyen, editors. Wavelengths and Filter Banks. Wellesley, MA: Wellesley-Cambridge Press, 1976. Pp. 263-289\".",
                    "score": 0.8545857667922974
                },
                {
                    "id": 12370849,
                    "contents": "Dissipation, interaction, and relative entropy.\nMany thermodynamic relations involve inequalities, with equality if a process does not involve dissipation. In this article we provide equalities in which the dissipative contribution is shown to involve the relative entropy (also called the Kullback-Leibler divergence). The processes considered are general time evolutions in both classical and quantum mechanics, and the initial state is sometimes thermal, sometimes partially so. As an application, the relative entropy is related to transport coefficients. ",
                    "score": 0.8543609976768494
                },
                {
                    "id": 8992347,
                    "contents": "Prethermalization.\nPrethermalization of the equation of state and the kinetic temperature to their equilibrium values occurs on time scales dramatically shorter than the thermal equilibration time. This is a crucial ingredient for the understanding of collisions of heavy nuclei or other nonequilibrium phenomena in complex quantum and classical many body systems. We also compare the chemical equilibration time with other characteristic time scales.",
                    "score": 0.8542316555976868
                },
                {
                    "id": 14855842,
                    "contents": "Computing the optimal path in stochastic dynamical systems.\nIn stochastic systems, one is often interested in finding the optimal path that maximizes the probability of escape from a metastable state or of switching between metastable states. Even for simple systems, it may be impossible to find an analytic form of the optimal path, and in high-dimensional systems, this is almost always the case. In this article, we formulate a constructive methodology that is used to compute the optimal path numerically. The method utilizes finite-time Lyapunov exponents, statistical selection criteria, and a Newton-based iterative minimizing scheme. The method is applied to four examples. The first example is a two-dimensional system that describes a single population with internal noise. This model has an analytical solution for the optimal path. The numerical solution found using our computational method agrees well with the analytical result. The second example is a more complicated four-dimensional system where our numerical method must be used to find the optimal path. The third example, although a seemingly simple two-dimensional system, demonstrates the success of our method in finding the optimal path where other numerical methods are known to fail. In the fourth example, the optimal path lies in six-dimensional space and demonstrates the power of our method in computing paths in higher-dimensional spaces.",
                    "score": 0.8540327548980713
                },
                {
                    "id": 6593946,
                    "contents": "The concept of drift and its application to multiphase and multibody problems.\nThe concept of drift is built around understanding how a rigid body moving in a straight line distorts a material sheet in an unbounded perfect fluid. As the body moves from infinity through a material sheet, which is initially perpendicular to the direction of translation of the body, the sheet is permanently distorted. Darwin showed that the 'drift' volume, D(f), formed between the distorted and undistorted sheet is equal to C(m)V, where the added-mass coefficient, C(m), characterizes the shape of the body whose volume is V. Darwin's result is important for two reasons: first, it provides a means of quantifying how dyed fluid is transported from one place to another and dispersed; second, it provides a fundamental Lagrangian coordinate system to study inhomogeneous inviscid problems. The aim of this article is to review Darwin's contribution to fluid mechanics. By drawing on recent experimental measurements of drift and the drift volume, we aim to demonstrate how Darwin's drift concept has developed and to describe its broader significance for multiphase and multibody problems.",
                    "score": 0.8539668321609497
                },
                {
                    "id": 10600845,
                    "contents": "Problem-solving test: catalytic activities of a human nuclear enzyme.\nTerms to be familiar with before you start to solve the test: ion exchange chromatography, polynucleotides, oligonucleotides, radioactive labeling, template, primer, DNA polymerase, reverse transcriptase, helicase, nucleoside triphosphates, nucleoside diphosphates, nucleoside monophosphates, nucleosides, 5′-end and 3′-end, bacteriophage, polyacrylamide gel electrophoresis, urea, autoradiography, proofreading, telomerase, endonucleases, exonucleases, primase, topoisomerases, and excinuclease.",
                    "score": 0.8537645936012268
                },
                {
                    "id": 8250817,
                    "contents": "Formal solution of a class of reaction-diffusion models: reduction to a single-particle problem.\nWe consider the trapping reaction A+B--&gt;B in space dimension d&lt;or=2. By formally eliminating the B particles from the problem, we derive an effective dynamics for the A particles from which the survival probability of a given A particle and the statistics of its spatial fluctuations can be calculated in a rather general way. The method can be extended to the study of annihilation and coalescence reactions, B+B--&gt;0 or B, in d=2.",
                    "score": 0.8534836769104004
                },
                {
                    "id": 15073351,
                    "contents": "Guide to nonlinear potential estimates.\nOne of the basic achievements in nonlinear potential theory is that the typical linear pointwise estimates via fundamental solutions find a precise analog in the case of nonlinear equations. We give a comprehensive account of this fact and prove new unifying families of potential estimates. We also describe new fine properties of solutions to measure data problems.",
                    "score": 0.8533679842948914
                },
                {
                    "id": 6451958,
                    "contents": "The problem may be more difficult to solve than it appears: a reply to zelaznik.\nZelznik (1978) and I agree that his comment applies only to Experiment 1 of my series of three experiments, and I note that the weight of my argument was based on the other two experiments. Although agreeing with his analysis of the problem in Experiment 1, I note that the recommended solution may introduce a new problem in the course of eliminating the old one. It is fortunate that my conclusion can rest on converging operations and is not tied to the particular paradigm in question.",
                    "score": 0.8533517122268677
                },
                {
                    "id": 6224171,
                    "contents": "A survey of non-linear optimization techniques.\nOptimization means the provision of a set of numerical parameter values which will give the best fit of an equation, or series of equations, to a set of data. For simple systems this can be done by differentiating the equations with respect to each parameter in turn, setting the set of partial differential equations to zero, and solving this set of simultaneous equations (as for exwnple in linear regression). In more complicated cases, however, it may be impossible to differentiate the equations, or very difficultly soluble non-linear equations may result. Many numerical optimization techniques to overcome these difficulties have been developed in the least ten years, and this review explains the logical basis of most of them, without going into the detail of computational procedures.The methods fall naturally into two classes - direct search methods, in which only values of the function to be minimized (or maximized) are used - and gradient methods, which also use derivatives of the function. The author considers all the accepted methods in each class, although warning that gradient methods should not be used unless the analytical differentiation of the function to be minimized is possible.If the solution is constrained, that is, certain values of the parameters are regarded as impossible or certain relations between the parameter values must be obeyed, the problem is more difficult. The second part of the review considers methods which have been proposed for the solution of constrained optimization problems.",
                    "score": 0.8533463478088379
                },
                {
                    "id": 8655749,
                    "contents": "Direct evaluation of large-deviation functions.\nWe introduce a numerical procedure to evaluate directly the probabilities of large deviations of physical quantities, such as current or density, that are local in time. The large-deviation functions are given in terms of the typical properties of a modified dynamics, and since they no longer involve rare events, can be evaluated efficiently and over a wider ranges of values. We illustrate the method with the current fluctuations of the Totally Asymmetric Exclusion Process and with the work distribution of a driven Lorentz gas.",
                    "score": 0.8532310724258423
                },
                {
                    "id": 16471457,
                    "contents": "Stochastic approach to equilibrium and nonequilibrium thermodynamics.\nWe develop the stochastic approach to thermodynamics based on stochastic dynamics, which can be discrete (master equation) and continuous (Fokker-Planck equation), and on two assumptions concerning entropy. The first is the definition of entropy itself and the second the definition of entropy production rate, which is non-negative and vanishes in thermodynamic equilibrium. Based on these assumptions, we study interacting systems with many degrees of freedom in equilibrium or out of thermodynamic equilibrium and how the macroscopic laws are derived from the stochastic dynamics. These studies include the quasiequilibrium processes; the convexity of the equilibrium surface; the monotonic time behavior of thermodynamic potentials, including entropy; the bilinear form of the entropy production rate; the Onsager coefficients and reciprocal relations; and the nonequilibrium steady states of chemical reactions. ",
                    "score": 0.8532187938690186
                },
                {
                    "id": 12353081,
                    "contents": "Problem-solving test: transport of a viral protein in a cell-free system.\nTerms to be familiar with before you start to solve the test: protein glycosylation, glycoprotein, endoplasmic reticulum, Golgi complex, mannose, oligosaccharide, free polysomes, cell fractionation, [(35) S]methionine; pulse labeling; nuclear fraction, mitochondrial fraction, microsomal fraction, cytosol, gel electrophoresis, autoradiography, trypsin, deoxycholate, detergent, sucrose density gradient, isopycnic gradient centrifugation.",
                    "score": 0.8530933856964111
                },
                {
                    "id": 16482850,
                    "contents": "Tibor Gánti and Robert Rosen: Contrasting approaches to the same problem.\nOf the various theories of life that appeared in the second half of the 20th century the chemoton of Tibor Gánti and the (M,R)-systems of Robert Rosen are among the most important, of which the former is rooted in chemical engineering and the latter is highly abstract. Despite apparent differences, in part due to very different ways of presenting them, these two approaches share some important characteristics: both are \"closed to efficient causation\", which means that they require nothing from their environment, and in particular not catalysts, apart from \"food\", or chemical species that allow for the production of energy. On the other hand Rosen insisted that a living organism cannot be regarded as a machine, whereas Gánti explicitly discussed its mechanical nature, and the enclosing boundary is explicitly created by the system itself in the chemoton, but is (at best) simply implicit in (M,R)-systems. ",
                    "score": 0.8529951572418213
                },
                {
                    "id": 22764915,
                    "contents": "Physics-constrained Bayesian inference of state functions in classical density-functional theory.\nWe develop a novel data-driven approach to the inverse problem of classical statistical mechanics: Given the experimental data on the collective motion of a classical many-body system, how does one characterize the free energy landscape of that system? By combining non-parametric Bayesian inference with physically motivated constraints, we develop an efficient learning algorithm that automates the construction of approximate free-energy functionals. In contrast to optimization-based machine learning approaches, which seek to minimize a cost function, the central idea of the proposed Bayesian inference is to propagate a set of prior assumptions through the model, derived from physical principles. The experimental data are used to probabilistically weigh the possible model predictions. This naturally leads to humanly interpretable algorithms with full uncertainty quantification of predictions. In our case, the output of the learning algorithm is a probability distribution over a family of free energy functionals, consistent with the observed particle data. We find that surprisingly small data samples contain sufficient information for inferring highly accurate analytic expressions of the underlying free-energy functionals, making our algorithm highly data efficient. In particular, we consider classical particle systems with excluded volume interactions, which are ubiquitous in nature, while being highly challenging in terms of free energy modeling. We validate our approach on the paradigmatic case of one-dimensional fluid and develop inference algorithms for the canonical and grand-canonical statistical-mechanical ensembles. Extensions to higher dimensional systems are conceptually straightforward, while standard coarse-graining techniques allow one to easily incorporate attractive interactions.",
                    "score": 0.8528326153755188
                },
                {
                    "id": 14970571,
                    "contents": "First Passage under Restart.\nFirst passage under restart has recently emerged as a conceptual framework suitable for the description of a wide range of phenomena, but the endless variety of ways in which restart mechanisms and first passage processes mix and match hindered the identification of unifying principles and general truths. Hope that these exist came from a recently discovered universality displayed by processes under optimal, constant rate, restart-but extensions and generalizations proved challenging as they marry arbitrarily complex processes and restart mechanisms. To address this challenge, we develop a generic approach to first passage under restart. Key features of diffusion under restart-the ultimate poster boy for this wide and diverse class of problems-are then shown to be completely universal.",
                    "score": 0.8526645302772522
                },
                {
                    "id": 14625293,
                    "contents": "A variational perspective on accelerated methods in optimization.\nAccelerated gradient methods play a central role in optimization, achieving optimal rates in many settings. Although many generalizations and extensions of Nesterov's original acceleration method have been proposed, it is not yet clear what is the natural scope of the acceleration concept. In this paper, we study accelerated methods from a continuous-time perspective. We show that there is a Lagrangian functional that we call the Bregman Lagrangian, which generates a large class of accelerated methods in continuous time, including (but not limited to) accelerated gradient descent, its non-Euclidean extension, and accelerated higher-order gradient methods. We show that the continuous-time limit of all of these methods corresponds to traveling the same curve in spacetime at different speeds. From this perspective, Nesterov's technique and many of its generalizations can be viewed as a systematic way to go from the continuous-time curves generated by the Bregman Lagrangian to a family of discrete-time accelerated algorithms.",
                    "score": 0.8526091575622559
                },
                {
                    "id": 22176742,
                    "contents": "Wang-Landau algorithm as stochastic optimization and its acceleration.\nWe show that the Wang-Landau algorithm can be formulated as a stochastic gradient descent algorithm minimizing a smooth and convex objective function, of which the gradient is estimated using Markov chain Monte Carlo iterations. The optimization formulation provides us another way to establish the convergence rate of the Wang-Landau algorithm, by exploiting the fact that almost surely the density estimates (on the logarithmic scale) remain in a compact set, upon which the objective function is strongly convex. The optimization viewpoint motivates us to improve the efficiency of the Wang-Landau algorithm using popular tools including the momentum method and the adaptive learning rate method. We demonstrate the accelerated Wang-Landau algorithm on a two-dimensional Ising model and a two-dimensional ten-state Potts model.",
                    "score": 0.8523989915847778
                },
                {
                    "id": 11565425,
                    "contents": "Generalized clausius inequality for nonequilibrium quantum processes.\nWe show that the nonequilibrium entropy production for a driven quantum system is larger than the Bures length, the geometric distance between its actual state and the corresponding equilibrium state. This universal lower bound generalizes the Clausius inequality to arbitrary nonequilibrium processes beyond linear response. We further derive a fundamental upper bound for the quantum entropy production rate and discuss its connection to the Bremermann-Bekenstein bound.",
                    "score": 0.852211594581604
                },
                {
                    "id": 18464950,
                    "contents": "Perspective: Maximum caliber is a general variational principle for dynamical systems.\nWe review here Maximum Caliber (Max Cal), a general variational principle for inferring distributions of paths in dynamical processes and networks. Max Cal is to dynamical trajectories what the principle of maximum entropy is to equilibrium states or stationary populations. In Max Cal, you maximize a path entropy over all possible pathways, subject to dynamical constraints, in order to predict relative path weights. Many well-known relationships of non-equilibrium statistical physics-such as the Green-Kubo fluctuation-dissipation relations, Onsager's reciprocal relations, and Prigogine's minimum entropy production-are limited to near-equilibrium processes. Max Cal is more general. While it can readily derive these results under those limits, Max Cal is also applicable far from equilibrium. We give examples of Max Cal as a method of inference about trajectory distributions from limited data, finding reaction coordinates in bio-molecular simulations, and modeling the complex dynamics of non-thermal systems such as gene regulatory networks or the collective firing of neurons. We also survey its basis in principle and some limitations.",
                    "score": 0.8521726727485657
                },
                {
                    "id": 19358685,
                    "contents": "The Hellmann-Feynman theorem: a perspective.\nThe Hellmann-Feynman theorem has, with a few exceptions, not been exploited to the degree that it merits. This is due, at least in part, to a widespread failure to recognize that its greatest value may be conceptual rather than numerical, i.e., in achieving insight into molecular properties and behavior. In this brief overview, we shall discuss three examples of significant concepts that have come out of the Hellmann-Feynman theorem: (1) The forces exerted upon the nuclei in molecules are entirely Coulombic in nature. (2) The total energies of atoms and molecules can be expressed rigorously in terms of just the electrostatic potentials at their nuclei that are produced by the electrons and other nuclei. (3) Dispersion forces are due to the attractions of nuclei to their own polarized electronic densities. To summarize, energy and force analyses should not be viewed as competitive but rather as complementary.",
                    "score": 0.8520702719688416
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_5",
        "question": "A household lightbulb is a blackbody radiator. Many lightbulbs use tungsten filaments that are heated by an electric current. What temperature is needed so that $\\lambda_{\\max }=550 \\mathrm{~nm}$ ?",
        "golden_answers": [
            " 5300"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 11477298,
                    "contents": "Light Sources in the 0.15-20-micro Spectral Range.\nThe different kinds of light sources available for the 0.15-20-micro spectral range are surveyed. Information was obtained from the published literature, unpublished reports, light source manufacturers, and also from individual persons. The aim has been to present sufficient information, where available, to show the relative advantages of different sources-intensity, stability, and output uniformity were of prime interest. Continuum and line sources are included but lasers and pulsed sources are omitted. The sources are described under the main headings: Arc Discharge Sources, Glow Discharge Sources, and Incandescent Sources, with another section, Miscellaneous Sources, to cover some which could not be included under the first three headings.",
                    "score": 0.8543431758880615
                },
                {
                    "id": 11252141,
                    "contents": "Probing Planck's law with incandescent light emission from a single carbon nanotube.\nWe present thermal and electron micrographs of an incandescent lamp constructed from a multiwalled carbon nanotube, and correlate the subwavelength optical information with the underlying nanoscopic structure. Remarkably, the heat equation and Planck's law together give a precise, quantitative description of the light intensity as a function of input power, even though the nanotube's small size places it outside the thermodynamic limit.",
                    "score": 0.8537077307701111
                },
                {
                    "id": 9961026,
                    "contents": "The new tungsten-filament lamp standards of total irradiance.\nThe National Bureau of Standards standard of total irradiance as presently issued in the form of a 50-W carbon filament lamp was originally calibrated more than fifty years ago. Recently, needs for higher accuracy and wider ranges of total irradiance have necessitated the setting up of three sizes (100 W, 500 W, and 1000 W) of tungsten-filament lamp standards of total irradiance. These standards operate at a higher temperature than was possible with the carbon-filament lamps, and are shielded, except for a narrow area of the bulb in front of the filament, so the reception of long wavelength flux from the lamps is reduced to a minimum. The new lamps were calibrated by the use of a blackbody at a known temperature together with a quartz plate whose spectral transmittance was accurately determined. The quartz plate limits the flux received from the blackbody to the spectral region below about 4.5 micro and thus reduces errors resulting from water vapor absorption at 6 micro and longer wavelengths. Comparisons sow the new standards to be in close agreement with the carbon-filament lamp standard.",
                    "score": 0.8517673015594482
                },
                {
                    "id": 19276363,
                    "contents": "LEDs for photons, physiology and food.\nLighting based on light-emitting diodes (LEDs) not only is more energy efficient than traditional lighting, but also enables improved performance and control. The colour, intensity and distribution of light can now be controlled with unprecedented precision, enabling light to be used both as a signal for specific physiological responses in humans and plants, and as an efficient fuel for fresh food production. Here we show how a broad and improved understanding of the physiological responses to light will facilitate greater energy savings and provide health and productivity benefits that have not previously been associated with lighting.",
                    "score": 0.8498961925506592
                },
                {
                    "id": 21799101,
                    "contents": "Standard of Spectral Radiance for the Region of 0.25 to 2.6 Microns.\nThis paper contains information relating to the setting up of standard blackbodies for use through the temperature range of about 1,400° to 2,400° K and their use in the calibration of tungsten strip lamps as laboratory standards of spectral radiance for the wavelength region of 0.25 to 2.6 microns. A graphite blackbody is described and representative data are given on the spectral characteristics of the new lamp standard as compared to blackbodies at several selected temperatures.",
                    "score": 0.849341094493866
                },
                {
                    "id": 8450807,
                    "contents": "[Artificial sources of light].\nThe artificial light sources are numerous. They emit a more or less delimited spectrum of wavelengths. Ultraviolet light dosimetry allows to control the amount of delivered energy.",
                    "score": 0.8482756614685059
                },
                {
                    "id": 9977481,
                    "contents": "Modified blackbody radiation spectrum of a selective emitter with application to incandescent light source design.\nUsing a selective emitter with high emissivity in the visible wavelength region and low emissivity in the infrared wavelength region, we reduced the infrared contribution to the blackbody radiation spectrum and shifted the peak emission to shorter wavelengths. We made precise measurements of thermal radiation loss. The conversion efficiency from input electric power to visible light radiation was quantitatively evaluated with high accuracy. Using the proposed selective emitter, the conversion efficiencies in excess of 95% could be produced. Our conclusions pave the way for the design of incandescent lamps with luminous efficiencies exceeding 400 lm/W.",
                    "score": 0.8479825258255005
                },
                {
                    "id": 11474384,
                    "contents": "Ablative light sources.\nElectrical and optical properties of ablative light sources are discussed. For the range of parameters studied, the energy balance shows that it is possible to obtain approximately one-third of the energy delivered to the lamp as radiative energy (in the 0.35-1.1-micro band); two-thirds are used in the buildup processes of the discharge. The over-all characteristics of ablative sources should permit useful technical applications.",
                    "score": 0.8404151797294617
                },
                {
                    "id": 10633791,
                    "contents": "Brighter light sources from black metal: significant increase in emission efficiency of incandescent light sources.\nBy applying the femtosecond laser blackening technique directly to a tungsten incandescent lamp filament, we dramatically brighten the tungsten lamp and enhance its emission efficiency to approach 100%. A comparison study of emission and absorption for the structured metal surfaces shows that Kirchhoff's law is applicable for the black metal. Furthermore, we demonstrate that we can even obtain partially polarized light as well as control the spectral range of the optimal light emission from the laser-blackened tungsten lamp.",
                    "score": 0.8388159871101379
                },
                {
                    "id": 13982924,
                    "contents": "[Near infrared light irradiator using halogen lamp].\nThe practical electric light bulb was invented by Thomas Alva Edison in 1879. Halogen lamp is the toughest and brightest electric light bulb. With light filter, it is used as a source of near infrared light. Super Lizer and Alphabeam are made as near infrared light irradiator using halogen lamp. The light emmited by Super Lizer is linear polarized near infrared light. The wave length is from 600 to 1,600 nm and strongest at about 1,000 nm. Concerning Super Lizer, there is evidence of analgesic effects and normalization of the sympathetic nervous system. Super Lizer has four types of probes. SG type is used for stellate ganglion irradiation. B type is used for narrow area irradiation. C and D types are for broad area irradiation. The output of Alphabeam is not polarized. The wave length is from 700 to 1,600 nm and the strongest length is about 1,000nm. Standard attachment is used for spot irradiation. Small attachment is used for stellate ganglion irradiation. Wide attachment is used for broad area irradiation. The effects of Alphabeam are thought to be similar to that of Super Lizer.",
                    "score": 0.8384494185447693
                },
                {
                    "id": 16198810,
                    "contents": "Tailoring high-temperature radiation and the resurrection of the incandescent source.\nIn solar cells, the mismatch between the Sun's emission spectrum and the cells' absorption profile limits the efficiency of such devices, while in incandescent light bulbs, most of the energy is lost as heat. One way to avoid the waste of a large fraction of the radiation emitted from hot objects is to tailor the thermal emission spectrum according to the desired application. This strategy has been successfully applied to photonic-crystal emitters at moderate temperatures, but is exceedingly difficult for hot emitters (&gt;1,000 K). Here, we show that a plain incandescent tungsten filament (3,000 K) surrounded by a cold-side nanophotonic interference system optimized to reflect infrared light and transmit visible light for a wide range of angles could become a light source that reaches luminous efficiencies (∼40%) surpassing existing lighting technologies, and nearing a limit for lighting applications. We experimentally demonstrate a proof-of-principle incandescent emitter with efficiency approaching that of commercial fluorescent or light-emitting diode bulbs, but with exceptional reproduction of colours and scalable power. The ability to tailor the emission spectrum of high-temperature sources may find applications in thermophotovoltaic energy conversion and lighting. ",
                    "score": 0.8369632959365845
                },
                {
                    "id": 14459578,
                    "contents": "Halogen head light-you can make it.\nHalogen head light can be made by removing the ordinary bulb and its attachments from the Clark's tike head light and replacing it with Halogen tube (12 volts 55 watts) along with its attachment. This Halogen tube needs 12 volts 5amp transformer for its maximum output.",
                    "score": 0.8352237939834595
                },
                {
                    "id": 11419744,
                    "contents": "Low Light Level TV Techniques.\nAs the science of low light level sensing becomes better understood, the demand for systems with this capability has increased considerably in recent years. Low light level television systems are part of these low light sensing devices in which interest has grown. Development of low light level TV systems has, in turn, stimulated technical advances in new tube types with improved performance, development of electronic techniques which enhance the over-all performance, and design techniques which make the system more versatile and adaptable. A general look at some of these developments and techniques gives insight into the versatility and adaptability of low light level TV.",
                    "score": 0.8342154622077942
                },
                {
                    "id": 16192933,
                    "contents": "Light in man's environment.\nLight in the form of solar radiation influenced early civilisations and resulted in the independent development of a number of sun-worshipping dieties. These were of particular importance as hunter gatherers transformed into settled agricultural societies. All artificial light sources were synonymous with fire, and early civilisations began to expand their visual day by burning brands, oil, and candles. Fire-based light sources extended for thousands of years and were still present in the era of gas lighting. Light meant fire risk. The advent of incandescent bulbs and the era of electric lighting really only expanded in the early part of the twentieth century. Fluorescent lighting became available in the 1940s, and today the drive for low energy has resulted in a plethora of novel light sources-in particular, light-emitting diodes (LEDs). Evolution governed the development of the eye in relation to roughly 12 h of light gradually changing to 12 h of darkness. Today almost daylight levels can be achieved abruptly at the flick of a switch. Many studies have demonstrated the spectral dependence of eye health, with the retinal hazard zone associated with wavelengths in the blue, peaking at 441 nm- many of today's low-energy sources peak in this region. Given the increased longevity and artificial light sources emitting at biologically unfriendly wavelengths, attention has to be directed towards light in man's environment as a risk factor in age-related ocular diseases. ",
                    "score": 0.8341184854507446
                },
                {
                    "id": 9972231,
                    "contents": "Power-by-light systems and their components: an evaluation.\nThis paper describes the testing of small sized systems and their components that use power-by-light (PBL) to transfer energy across a barrier. The PBL systems used improved high power laser diodes, large numerical aperture fibers, improved high efficient, high power solar cells, and low input-to-high output voltage dc-dc converters. The laser diodes emitted up to 3.6 W continuously by converting approximately 40% of its electrical power to light power into fibers that transmitted up to 92% of its incident energy flux. The specially fabricated solar cell converted 46% of its incident light power to electrical power at a fill factor of 89%. The most efficient 100- and 220-mJ PBL systems charged capacitors in 0.64 and 0.8 s for a total system efficiency of 3.4 and 5.5%. Expected improvements could yield system efficiencies of 12%.",
                    "score": 0.8330966234207153
                },
                {
                    "id": 15174347,
                    "contents": "What We Talk About When We Talk About Light.\nUNESCO (the United Nations Educational, Scientific, and Cultural Organization) has declared 2015 the \"International Year of Light and Light-Based Technologies\". In celebration of this proclamation, this Outlook provides a general history of light and its applications, from the earliest moments of the Big Bang through its present impact on all forms of life on the planet. Special emphasis is placed on fundamental advances in the generation and use of artificial light, as well as the harvesting and use of light from the Sun and other natural sources. During the past century, the role of light in the fields of physics, chemistry, and biology has expanded to include emerging fields such as environmental engineering, agriculture, materials science, and biomedicine. In this regard, future research challenges and new potential applications in these areas, in the context of \"the central science\", are presented and discussed. ",
                    "score": 0.832615852355957
                },
                {
                    "id": 7331943,
                    "contents": "The physics of light and sunlight.\nThe physical properties of light, both natural and artificial, play a significant role in its interaction with humans. Although there is a yet-to-be-explained duality between light as waves and light as photons, we do understand many of the characteristics of light that affect living things. Here I review the general history of light and its properties, especially those that affect human health.",
                    "score": 0.8304823637008667
                },
                {
                    "id": 1470563,
                    "contents": "A multi-purpose laboratory light box.\nA multi-purpose, inexpensive laboratory light box is described which can be used for observing and photographing results of a diversity of laboratory tests using either white or ultraviolet light.",
                    "score": 0.8295597434043884
                },
                {
                    "id": 12480323,
                    "contents": "Light-controlled tools.\nSpatial and temporal control over chemical and biological processes plays a key role in life, where the whole is often much more than the sum of its parts. Quite trivially, the molecules of a cell do not form a living system if they are only arranged in a random fashion. If we want to understand these relationships and especially the problems arising from malfunction, tools are necessary that allow us to design sophisticated experiments that address these questions. Highly valuable in this respect are external triggers that enable us to precisely determine where, when, and to what extent a process is started or stopped. Light is an ideal external trigger: It is highly selective and if applied correctly also harmless. It can be generated and manipulated with well-established techniques, and many ways exist to apply light to living systems--from cells to higher organisms. This Review will focus on developments over the last six years and includes discussions on the underlying technologies as well as their applications.",
                    "score": 0.8288860321044922
                },
                {
                    "id": 21507429,
                    "contents": "Lighting system bioinspired by Haworthia obtusa.\nElectricity plays an important role in modern societies, with lighting and illumination accounting for approximately one-fifth of the global demand for electricity. Haworthia obtusa has the remarkable ability to collect solar light through a so-called 'window' which allows it to photosynthesise in the dark. Inspired by this unique characteristic, we developed a novel lighting system that does not use electricity. The 'window' of H. obtusa is replicated using a scattering medium that collects solar light and guides it to an optical fibre. The optical fibre then carries the light indoors, where illumination is needed. The efficacy of this unique lighting system was confirmed both numerically and experimentally. The developed system should help in lowering energy consumption.",
                    "score": 0.8286201357841492
                },
                {
                    "id": 9714379,
                    "contents": "Note: design and characterization of an optical light source based on mixture of white and near-ultraviolet light emitting diode spectra.\nAn optical light source based on a solid-state lighting technology is designed. Main components of the light source are a phosphor-converted white and a near-ultraviolet (near-UV) light emitting diodes (LEDs), the spectral power distributions (SPDs) of which are mixed using a fiber optic combiner. The near-UV LED is used for improving insufficient SPDs of the white LED at shorter wavelengths of the visible radiation. Stable direct current power supplies are also designed and used to operate each of the LED separately. Three steps of the driving current can be selected by means of serial resistors altered with a commutator at nominal current values of ∼40%, ∼50%, and ∼69%. The light source can be used for many characteristic measurements within the scope of photometry and colorimetry.",
                    "score": 0.8284775018692017
                },
                {
                    "id": 19523829,
                    "contents": "Energy Harvesting Through Wasted Thermal Energy by Light Grid Sources.\nIn this study, emitted light energy and the recycling of thermal energy from the arrays of a light emitting diode system were investigated. A light grid system is composed of the array of high power LED chips, thermoelement and heat sink. High power LED source has an advantage of high luminous efficiency, which combined with wasted thermal energy. Thermal energy loss can be regarded wasted energy. However, this wasting thermal energy can be effectively converted to the electrical energy from thermoelement and heat sink of a light grid system. By introducing the light grid system, the optical energy and thermal energy can be more effectively managed. In particular, we have intensively studied energy conversion efficiency of light grid system and energy harvesting characteristic through thermal energy.",
                    "score": 0.8280580639839172
                },
                {
                    "id": 5398215,
                    "contents": "[The type testing of light-polymerization equipment, II: the 1998 status].\nIn this study 16 different light curing units, available on the Swiss market, were tested for their features, radiant power and light distribution across the face of the curing tip and components like integrated radiometer, timer and cooling device. The basis of this study was the test protocol published in the november edition (11/1999). The features of the light curing units differed from one another. The Optilux 500 had all conceivable features that it could be designated the standard in features. If all these technical options are necessary has to be decided by the consumer. However, the components such as the timer, radiometer and voltage stabilizer are important because they influence the time of irradiation and the radiant power. The radiant power (mW) i.e., the radiance (mW/cm2) were measured in 2 spectral areas which are important for visible light polymerisation. The absolute values for the standard curing tip at a voltage of 230 V lay between 143.4 and 389.7 mW for the wavelengths between 400-520 nm and between 17.7 and 41.8 mW for the wavelengths between 462-472 nm. The resultant specific radiance values were between 268.3 and 862.6 mW/cm2 in the broad spectrum of 400-520 nm and 33.5 and 95.4 mW/cm2 in the narrow spectrum of 462-472 nm. Where the standard curing tips were replaced by guides with other diameters, tips with larger entrances showed more radiant power, light guides with smaller exits also showed more radiance. Turbo tips have larger entrances than exits and therefore combine both positive effects. The intensity wasn't distributed equally across the face of the curing light guide. Characteristically there was a concentric distribution of the intensity, with the maximum found in the centre and a decrease to the margin. Corresponding to the radiance values, curing light tips with decreasing diameters showed more homogeneous distribution patterns. Only Turbo tips showed worse distribution. Comparing the light intensity at a voltage of 207 V and 244 V to the normal voltage of 230 V it was found that not all curing units had an integrated voltage stabilizer. Just 9 out of the 16 tested units had an integrated radiometer. Comparison of the evaluated radiance values to the values given by the integrated radiometer revealed an agreement in just two cases. The marginal values, programmed by the manufacturer varied between 70 and 300 mw/cm2 and lie therefore, too low.",
                    "score": 0.827451229095459
                },
                {
                    "id": 22572828,
                    "contents": "Measuring System for Determining the Quality of LED Light Sources and an Overview of LED Light Bulbs for Household Use.\nModern LED light sources have many advantages, as well as some disadvantages. One of the disadvantages is the pulsating luminous flux, which, in some cases, affects people's health and well-being negatively. The paper describes the design and making process of a measuring system for determining the quality of LED substitutes for conventional light bulbs and gives an overview of LED light bulbs for household use. The measurement system is controlled using the MATLAB software environment, in which data processing and plotting of the results are also performed. We acquired 59 different LED light bulbs from 37 manufacturers, and performed the measurements. The light bulbs are classified based on the percentage of fluctuations in the luminous flux, and the percentage of deviation of the measured luminous flux compared to the value stated on the packaging by the manufacturer.",
                    "score": 0.8263427019119263
                },
                {
                    "id": 11480086,
                    "contents": "A one-solar-constant irradiance standard.\nA new high-intensity standard of total and spectral irradiance has been developed recently at the National Bureau of Standards. The standard consists of a 1000-W tungsten-halogen lamp mounted in a ceramic reflector, the reflecting surface of which is coated with flame-sprayed Al(2)O(3). The lamp-reflector combination results in a source having a relatively small (3 cm x 5 cm) radiating area yielding a total irradiance, at a distance of 40 cm, of about 136 mW cm(-2). The total irradiance calibrations are based on the radiance of a 1400-K blackbody and have an estimated maximum systematic error of 0.9% and a maximum estimated standard error of 0.19%. The spectral measurements were made over the wavelength range of 0.3 microm to 2.5 microm relative to the NBS 1000-W tungsten-halogen irradiance standards. The estimated uncertainty in these measurements ranges from 4% in the visible and near ir to 8% in the uv.",
                    "score": 0.8261398077011108
                },
                {
                    "id": 15584815,
                    "contents": "Light: A Very Peculiar Reactant and Product.\nSee the light of day: Light is the fastest way of transferring energy and information through space, and in chemistry it can perform the dual role of reactant and product. Sunlight, a really unique reactant, represents our ultimate energy source. Chemists are engaged in designing systems for the conversion of light into electrical or chemical energy and vice versa to create a more sustainable way of life. ",
                    "score": 0.825819730758667
                },
                {
                    "id": 13863805,
                    "contents": "Whiteness metric for light sources of arbitrary color temperatures: proposal and application to light-emitting-diodes.\nWe study the quantification of whiteness perception under illumination from various light sources. We discuss an existing metric for sources with high correlated color temperature (CCT), CIE whiteness, and propose a procedure to adapt it to sources of any CCT. We illustrate our approach by comparing the ability of different warm-white sources to render whiteness. We show that a careful engineering of the spectrum -facilitated by the flexibility of light-emitting diode sources - is essential to render whiteness. ",
                    "score": 0.8252379894256592
                },
                {
                    "id": 14810966,
                    "contents": "Improved Photometric Standards and Calibration Procedures at NIST.\nNIST has recently established a detector-based luminous intensity unit (candela, cd), which is derived from the NIST absolute cryogenic radiometer. Subsequently, the luminous flux unit (lumen, lm) and the luminance unit (cd/m<sup2</sup) have been established based on the detector-based candela, and now all the NIST photometric units are tied to the cryogenic radiometer. The illuminance unit is realized and maintained on five standard photometers. The large dynamic range of the standard photometers eliminates the need for maintaining many working standard lamps of various wattages. The luminous intensities of lamps are determined from the illuminances measured with these photometers and the distances measured with a linear encoder system. Transfer photometers and illuminance meters are calibrated by direct comparison with the standard photometers with no distance measurements involved. The luminous flux unit is realized using an absolute integrating sphere method newly developed at NIST. The luminance unit is realized on an integrating sphere source, which is used for calibration of other luminance sources and luminance meters. These detector-based methods have made it possible to reduce the uncertainties of photometric calibrations and to provide more varieties of photometric calibration services at NIST.",
                    "score": 0.8245876431465149
                },
                {
                    "id": 16874822,
                    "contents": "Improved efficacy of warm-white light-emitting diode luminaires.\nWe present a novel approach to address one of the technical hurdles the current light-emitting diode (LED) lighting field faces: the packaged efficacy of warm-white LEDs is 20%-30% lower than that of cool-white LEDs depending on the color rendering index. With a differentiated luminaire design in combination with a new class of nano materials, we have greatly improved the efficacy of warm white by 15% at the luminaire system level, which translates to less energy being required to achieve the same light output, and thus offers a more energy-efficient solution. Reliability test of the luminaire shows no performance degradation within the tested period of more than 3000 h. A modeling has been developed to predict the optical performance of luminaires incorporating the nano materials, which agrees well with the experimental data and serves as a powerful tool for designing luminaires with targeted performance.",
                    "score": 0.8243569731712341
                },
                {
                    "id": 16664582,
                    "contents": "Development of a Tunable LED-Based Colorimetric Source.\nA novel, spectrally tunable light-source utilizing light emitting diodes (LEDs) for radiometric, photometric, and colorimetric applications is described. The tunable source can simulate standard sources and can be used as a transfer source to propagate photometric and colorimetric scales from calibrated reference instruments to test artifacts with minimal increase in uncertainty. In this prototype source, 40 LEDs with 10 different spectral distributions were mounted onto an integrating sphere. A voltage-to-current control circuit was designed and implemented, enabling independent control of the current sent to each set of four LEDs. The LEDs have been characterized for stability and dependence on drive current. The prototype source demonstrates the feasibility of development of a spectrally tunable LED source using LEDs with up to 40 different spectral distributions. Simulations demonstrate that such a source would be able to approximate standard light-source distributions over the visible spectral range-from 380 nm to 780 nm-with deviations on the order of 2 %. The tunable LED source can also simulate spectral distributions of special sources such as discharge lamps and display monitors. With this tunable source, a test instrument can be rapidly calibrated against a variety of different source distributions tailored to the anticipated uses of the artifact. Target uncertainties for the calibration of test artifacts are less than 2 % in luminance and 0.002 in chromaticity for any source distribution.",
                    "score": 0.8238847255706787
                },
                {
                    "id": 8972332,
                    "contents": "[Study on spectral emission characteristics of infrared lamps].\nThe spectral characteristics at wavelength ranges of 0.35-0.85 microm and 1.72-16.7 microm (5800-600 cm(-1)) for both domestic and imported infrared lamps used in scientific research, industry, medical service, home electrical appliance etc. have heen studied and compared. This paper has provided the theoreical and experimental bases for their applications and improvement in designs, technology of manufacture, quality and performance.",
                    "score": 0.823813796043396
                },
                {
                    "id": 14827727,
                    "contents": "Multi-function indoor light sources based on light-emitting diodes-a solution for healthy lighting.\nA solution for multi-functional indoor light sources is proposed to achieve the new concept of healthy lighting. A remotely controllable light source that embodies a quadruple-chip light-emitting diode and driven by pulse-width-modulation currents is designed. Therefore, spectral power distributions (SPDs) of the light source can be readily controlled. An algorithm, namely the optical power ratio algorithm, is developed to select all suitable SPDs adapted for various applications. Principles of selection are based on those traditional visual indices, as well as on some non-visual parameters such as circadian action factor, circadian efficacy of radiation and circadian illuminance. We investigate in detail the correlation among these parameters and provide SPDs with both decent visual and non-visual performances for three typical cases. The study suggests some fundamental principles for designing healthy light sources, and can be regarded as a guide for designing indoor light sources of the next generation.",
                    "score": 0.8234632611274719
                },
                {
                    "id": 11437023,
                    "contents": "Optics at westinghouse.\nPast and present work in optics at the Westinghouse Electric Corporation is surveyed. The areas discussed include lamps and illumination, industrial optical applications, television and imaging systems, and lasers and coherent optics.",
                    "score": 0.8234256505966187
                },
                {
                    "id": 11254293,
                    "contents": "Duplicating \"sunlight\" from simple WOLEDs for lighting applications.\nSimple single-dopant white organic light-emitting devices (WOLEDs) with optimized efficiency/color quality/brightness trade-offs are developed; the white light produced shows the best color quality ever exhibited by WOLEDs at very high brightness, and is even able to duplicate the natural sunlight source.",
                    "score": 0.8231939673423767
                },
                {
                    "id": 8220325,
                    "contents": "Luminous power efficiency optimization of a white organic light-emitting diode by tuning its spectrum and its extraction efficiency.\nWe show an increase of the luminous power efficiency of a white organic light-emitting diode (LED) with three emitters by optimizing its spectrum and its extraction efficiency. To calculate this efficiency we use a model with four parameters: the spectra, extraction efficiencies, internal quantum efficiencies of three emitters, and the driving voltage. This luminous power efficiency increases by 30% by use of a spectrum close to the spectrum of the MacAdam limit. This limit gives the highest luminous efficacy for a given chromaticity. We also show that a white organic LED with an inefficient deep blue emitter can give the same luminous power efficiency as a white organic LED with a more efficient light blue emitter, because of their different fractions in the radiant flux. Tuning the extraction efficiency with a microcavity to the spectrum also increases the luminous power efficiency by 10%.",
                    "score": 0.8229672312736511
                },
                {
                    "id": 10427784,
                    "contents": "Laser-pumped endoscopic illumination source.\nLight sources currently employed in endoscopy have a number of disadvantages including inefficiency, high temperature, non-uniform illumination, and the production of shadow-less images. In this paper, we present a novel endoscopic illumination source, based on the use of a blue-violet laser diode in combination with a yellow phosphor for the production of white light. By using this approach, the resulting illumination source is more compact and potentially more ergonomic than those currently used in endoscopy. Spectral measurements of the emitted light indicate that it has a colour similar to that of daylight, and images obtained under illumination with this light source indicate that it provides more uniform illumination and sharper shadows than standard endoscopic light sources.",
                    "score": 0.8227443099021912
                },
                {
                    "id": 16966771,
                    "contents": "Feature issue introduction: light, energy and the environment, 2015.\nThe feature issue highlights contributions from authors who presented their research at the OSA Light, Energy and the Environment Congress, held in Suzhou, China from 2 to 5 November, 2015. ",
                    "score": 0.8225195407867432
                },
                {
                    "id": 16149665,
                    "contents": "Thermal and optical design analyses, optimizations, and experimental verification for a novel glare-free LED lamp for household applications.\nLight-emitting diode (LED) technologies are undergoing very fast developments to enable household lamp products with improved energy efficiency and lighting properties at lower cost. Although many LED replacement lamps are claimed to provide similar or better lighting quality at lower electrical wattage compared with general-purpose incumbent lamps, certain lighting characteristics important to human vision are neglected in this comparison, which include glare-free illumination and omnidirectional or sufficiently broad light distribution with adequate homogeneity. In this paper, we comprehensively investigate the thermal and lighting performance and trade-offs for several commercial LED replacement lamps for the most popular Edison incandescent bulb. We present simulations and analyses for thermal and optical performance trade-offs for various LED lamps at the chip and module granularity levels. In addition, we present a novel, glare-free, and production-friendly LED lamp design optimized to produce very desirable light distribution properties as demonstrated by our simulation results, some of which are verified by experiments. ",
                    "score": 0.8222179412841797
                },
                {
                    "id": 13689922,
                    "contents": "A simple sub-nanosecond ultraviolet light pulse generator with high repetition rate and peak power.\nWe present a simple ultraviolet sub-nanosecond pulse generator using commercial ultraviolet light-emitting diodes with peak emission wavelengths of 290 nm, 318 nm, 338 nm, and 405 nm. The generator is based on step recovery diode, short-circuited transmission line, and current-shaping circuit. The narrowest pulses achieved have 630 ps full width at half maximum at repetition rate of 80 MHz. Optical pulse power in the range of several hundreds of microwatts depends on the applied bias voltage. The bias voltage dependences of the output optical pulse width and peak power are analysed and discussed. Compared to commercial UV sub-nanosecond generators, the proposed generator can produce much higher pulse repetition rate and peak power.",
                    "score": 0.8220533728599548
                },
                {
                    "id": 9491801,
                    "contents": "LIGHT AND VISION.\n[Abstract of an Address bySir John Parsonsto the Illuminatiñg Engineering Society on May 11, 1943. The Illuminating Engineering Society was founded by Mr. Leon Gaster in 1909 for the purpose of promoting \"good lighting,\" i.e. lighting \"adequate and suitable\" for the given performance. It was designed to represent all aspects of the subject, and its members include gas and electric light experts, physiologists, ophthalmologists, architects, and others. The writer is an original member, past president, and fellow of the Society.].",
                    "score": 0.8216521143913269
                },
                {
                    "id": 15631641,
                    "contents": "Feature issue introduction: Light, Energy and the Environment, 2014.\nThis feature issue highlights contributions from authors who presented their research at the OSA Light, Energy and the Environment Congress, held in Canberra, Australia from 2-5 December, 2014. ",
                    "score": 0.8214931488037109
                },
                {
                    "id": 17434869,
                    "contents": "Total internal reflection shell for light-emitting diode bulbs.\nA total internal reflection (TIR) shell capable of generating illuminating light with a wide-angle distribution from light-emitting diodes (LEDs) is proposed. The TIR shell can be used to create an LED light bulb with enclosed heat dissipaters to release the heat generated by the LEDs. The TIR shell has light-scattering areas on its inner surface and a mirror-polished free-form outer surface that can guide all rays emitted from the LEDs to the scattering areas by the TIR. The rays diffused by the light-scattering areas are emitted from the TIR shell in a wide-angle light distribution. A prototype of the LED light bulb with a metal shell for heat dissipation inside the TIR shell shows favorable features such as a half-intensity angle of 330°, lighting efficiency of 81%, and glare-free lighting emitted from the entire surface area of the TIR shell.",
                    "score": 0.8212798237800598
                },
                {
                    "id": 15531974,
                    "contents": "Let there be light--with gallium nitride: the 2014 Nobel Prize in Physics.\nSignificant gains in energy savings now underway can be traced to a single invention--the blue light-emitting diode. GaN-based blue LED technology not only resulted in efficient white light sources, but continues to enable a host of applications and scientific inquiries. The researchers primarily responsible for the development of the blue LED were awarded the 2014 Nobel Prize in Physics.",
                    "score": 0.8212381601333618
                },
                {
                    "id": 18878829,
                    "contents": "New Light for Phytochemicals.\nLight-emitting diode (LED) lighting technology with narrow-bandwidth illumination helps to reduce energy consumption on covered crops. Here, we discuss how this new technology, which provides flexible modification of light spectra, will open new avenues for natural modulation of medicinal and crop plant metabolomes for better colour, flavour, fragrance, and antioxidant properties.",
                    "score": 0.820275068283081
                },
                {
                    "id": 3859383,
                    "contents": "[Fluorescent lamps from the actinic viewpoint].\nFluorescent lamps for general lighting purposes cannot produce UV erythema or direct pigmentation whereas sun lamps used for tanning are comparable to the actinic effects of natural radiation at a clear summer day. Chronic effects due to fluorescent lighting have not been proved so far.",
                    "score": 0.820185661315918
                },
                {
                    "id": 11733714,
                    "contents": "Thin-film luminescent concentrators for integrated devices: a cookbook.\nA luminescent concentrator (LC) is a nonimaging optical device used for collecting light energy. As a result of its unique properties, a LC also offers the possibility of separating different portions of the spectrum and concentrating them at the same time. Hence, LC's can be applied to a whole range of problems requiring the collection, manipulation, and distribution or measurement of light. Further-more, as described in our previous research, thin-film LC elements can be deposited directly over sensor and processing electronics in the form of integrated LC devices. As an aid to further research, the materials and technology required to fabricate these thin-film LC elements through the use of an ultraviolet-curable photopolymer are documented in detail.",
                    "score": 0.8201274275779724
                },
                {
                    "id": 2355013,
                    "contents": "Luminescence research and its relation to ultraweak cell radiation.\nThe fundamental laws of photochemistry and the essential results of experimental research on ultraweak cell radiation are presented. By comparing all the facts it can be concluded that the phenomena discussed may arise from a variety of possible reactions and sources. Recombination reactions of certain radicals actually do release sufficient energy to generate UV-photons of the intensity under consideration. On the other hand, stimulated emission cannot be excluded in view of the distinct deviation of the radiation field from thermal equilibrium. There exist, however, various other candidates, such as direct emitters like flavins, indoles, porphyrins, carbonyl derivatives and aromatic compounds, and molecular oxygen and its various species, as well as collective molecular interactions, e.g. dimole or exciplex transitions, triplet-triplet annihilation, collective hydrolysis, electric field effects in membranes, etc. Careful biochemical and biophysical experiments are still necessary to find answers to all the questions that remain; not only individual problems have to be solved, but it is important to keep in mind the interrelationships between certain reactions.",
                    "score": 0.8199120759963989
                },
                {
                    "id": 11387815,
                    "contents": "Differential thermoluminescence (DTL) -a new instrument for measurement of thermoluminescence with suppression of blackbody radiation.\nA new instrumental technique for the determination of thermoluminescent glow curves, especially useful for investigation at high temperatures, is described. Two samples, identical in all respects except that one is preheated, are simultaneously heated. The light outputs from the samples are individually modulated at two different frequencies, fed to a single photomultiplier tube the output of which is amplified by two lock-in amplifiers. The selectively amplified signals are further fed to a differential amplifier which cancels out the undesirable blackbody radiation to give a signal due only to the luminophor. This technique conveniently extends the temperature range of thermoluminescence and further allows high-temperature investigation of emissions in the red region of the spectrum.",
                    "score": 0.8198248147964478
                },
                {
                    "id": 14810962,
                    "contents": "Developments for a New Spectral Irradiance Scale at the National Institute of Standards and Technology.\nRecent developments for a new spectral irradiance scale realization at the National Institute of Standards and Technology have been targeted to reduce the present relative expanded uncertainties of 0.67 % to 4.34 % (coverage factor of <ik</i = 2 and thus a 2 standard deviation estimate) in the spectral irradiance scale to 0.17 % for the range from 350 nm to 1100 nm. To accomplish this goal, a suite of filter radiometers calibrated using NIST's high accuracy cryogenic radiometer have been used to measure the temperature of a high-temperature black-body. A comparison of the filter radiometer calibrations with the spectral irradiance scale along with an evaluation of the black-body calibration technique have been performed. With the aid of a monochromator, the calibrated filter radiometers will then be utilized to calibrate primary and secondary spectral irradiance standard lamps at NIST.",
                    "score": 0.8196118474006653
                },
                {
                    "id": 18667335,
                    "contents": "Feature issue introduction: Light, Energy and the Environment, 2016.\nThis feature issue highlights contributions from authors who presented their research at the OSA Light, Energy and the Environment Congress, held in Leipzig, Germany from November 14 to 17, 2016.",
                    "score": 0.8187417984008789
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_6",
        "question": "Evaluate the series\r\n$$\r\nS=\\frac{1}{2}+\\frac{1}{4}+\\frac{1}{8}+\\frac{1}{16}+\\cdots\r\n$$\r\n",
        "golden_answers": [
            " 1"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 21453649,
                    "contents": "Improving series convergence: the simple pendulum and beyond.\nA simple and easy to implement method for improving the convergence of a power series is presented. We observe that the most obvious or analytically convenient point about which to make a series expansion is not always the most computationally efficient. Series convergence can be dramatically improved by choosing the center of the series expansion to be at or near the average value at which the series is to be evaluated. For illustration, we apply this method to the well-known simple pendulum and to the Mexican hat type of potential. Large performance gains are demonstrated. While the method is not always the most computationally efficient on its own, it is effective, straightforward, quite general, and can be used in combination with other methods.",
                    "score": 0.87392258644104
                },
                {
                    "id": 23389571,
                    "contents": "A fast algorithm for computing the Boys function.\nWe present a new fast algorithm for computing the Boys function using a nonlinear approximation of the integrand via exponentials. The resulting algorithms evaluate the Boys function with real and complex valued arguments and are competitive with previously developed algorithms for the same purpose.",
                    "score": 0.867024302482605
                },
                {
                    "id": 10299610,
                    "contents": "Algorithm for computation of Zernike polynomials expansion coefficients.\nA numerically efficient algorithm for expanding a function in a series of Zernike polynomials is presented. The algorithm evaluates the expansion coefficients through the standard 2-D integration formula derived from the Zernike polynomials' orthogonal properties. Quadratic approximations are used along with the function to be expanded to eliminate the computational problems associated with integrating the oscillatory behavior of the Zernike polynomials. This yields a procedure that is both fast and numerically accurate. Comparisons are made between the proposed scheme and a procedure using a nested 2-D Simpson's integration rule. The results show that typically at least a fourfold improvement in computational speed can be expected in practical use.",
                    "score": 0.8654088973999023
                },
                {
                    "id": 21421458,
                    "contents": "On powers that are sums of consecutive like powers.\nLet <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:mik</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn</mml:mrow </mml:math be even, and let <ir</i be a non-zero integer. We show that for almost all <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:mid</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn</mml:mrow </mml:math (in the sense of natural density), the equation <DispFormula <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow<mml:msup<mml:mix</mml:mi <mml:mik</mml:mi</mml:msup <mml:mo+</mml:mo <mml:msup<mml:mrow<mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo+</mml:mo <mml:mir</mml:mi <mml:mo)</mml:mo</mml:mrow <mml:mik</mml:mi</mml:msup <mml:mo+</mml:mo <mml:mo⋯</mml:mo <mml:mo+</mml:mo <mml:msup<mml:mrow<mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo+</mml:mo <mml:mrow<mml:mo(</mml:mo <mml:mid</mml:mi <mml:mo-</mml:mo <mml:mn1</mml:mn <mml:mo)</mml:mo</mml:mrow <mml:mir</mml:mi <mml:mo)</mml:mo</mml:mrow <mml:mik</mml:mi</mml:msup <mml:mo=</mml:mo <mml:msup<mml:miy</mml:mi <mml:min</mml:mi</mml:msup <mml:mo,</mml:mo <mml:mspace/ <mml:mix</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:miy</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:min</mml:mi <mml:mo∈</mml:mo <mml:miZ</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:min</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn <mml:mo,</mml:mo</mml:mrow </mml:math </DispFormula has no solutions.",
                    "score": 0.8652917742729187
                },
                {
                    "id": 22558670,
                    "contents": "Division of Power Series: Recursive and Non-Recursive Formulas.\nIn this paper we propose a new formula to divide power series. We develop two versions of the formula: a recursive and a non-recursive one, the latter aiming to reduce the computational cost for high-order series truncation. To use the non-recursive formula we define certain fundamental sets of summation indexes. Additional non-trivial information about effects of repetition of the indexes are needed and contabilized within a coefficient 𝛾 in the formula, we explain how to calculate the coefficient 𝛾 for each summation index by constructing appropriate mappings between the fundamental sets of indexes previous defined.",
                    "score": 0.8648902177810669
                },
                {
                    "id": 7634727,
                    "contents": "A unifying view of wiener and volterra theory and polynomial kernel regression.\nVolterra and Wiener series are perhaps the best-understood nonlinear system representations in signal processing. Although both approaches have enjoyed a certain popularity in the past, their application has been limited to rather low-dimensional and weakly nonlinear systems due to the exponential growth of the number of terms that have to be estimated. We show that Volterra and Wiener series can be represented implicitly as elements of a reproducing kernel Hilbert space by using polynomial kernels. The estimation complexity of the implicit representation is linear in the input dimensionality and independent of the degree of nonlinearity. Experiments show performance advantages in terms of convergence, interpretability, and system sizes that can be handled.",
                    "score": 0.863853931427002
                },
                {
                    "id": 15539424,
                    "contents": "On the additive properties of the fat-shattering dimension.\nThe properties of the VC-dimension under various compositions are well-understood, but this is much less the case for classes of continuous functions. In this brief, we show that a commonly used scale-sensitive dimension, Vγ, is much less well-behaved under Minkowski summation than its VC cousin, while the fat-shattering dimension retains some compositional similarity to the VC-dimension. As an application, we analyze the fat-shattering dimension of trigonometric functions and series.",
                    "score": 0.8617921471595764
                },
                {
                    "id": 9652484,
                    "contents": "Systematic series expansions for processes on networks.\nWe use series expansions to study dynamics of equilibrium and nonequilibrium systems on networks. This analytical method enables us to include detailed nonuniversal effects of the network structure. We show that even low order calculations produce results which compare accurately to numerical simulation, while the results can be systematically improved. We show that certain commonly accepted analytical results for the critical point on networks with a broad degree distribution need to be modified in certain cases due to disassortativity; the present method is able to take into account the assortativity at sufficiently high order, while previous results correspond to leading and second order approximations in this method. Finally, we apply this method to real-world data.",
                    "score": 0.8594302535057068
                },
                {
                    "id": 19031252,
                    "contents": "A series of sequences convergent to Euler's constant.\nIn this paper, using continued fraction, we provide a new quicker sequence convergent to Euler's constant. We demonstrate the superiority of our new convergent sequences over DeTemple's sequence, Mortici's sequences, Vernescu's sequence, and Lu's sequence.",
                    "score": 0.8590786457061768
                },
                {
                    "id": 20573763,
                    "contents": "The exponentiated generalized power series: Family of distributions: theory, properties and applications.\nWe propose a new generalized family of distributions called the exponentiated generalized power series (EGPS) family of distributions and study its sub-model, the exponentiated generalized logarithmic (EGL) class of distributions, in detail. The structural properties of the new model (EGPS) and its sub-model (EGL) distribution including moments, order statistics, Rényi entropy, and maximum likelihood estimates are derived. We used the method of maximum likelihood to estimate the parameters of this new family of distributions. Simulation study was carried out to examine the bias and the mean square error of the maximum likelihood estimators for each of the model's parameters. Finally, we showed real life data examples to illustrate the models' applicability, flexibility and usefulness.",
                    "score": 0.8581026196479797
                },
                {
                    "id": 17926147,
                    "contents": "A new type of Taylor series expansion.\nWe present a variant of the classical integration by parts to introduce a new type of Taylor series expansion and to present some closed forms for integrals involving Jacobi and Laguerre polynomials, which cannot be directly obtained by usual symbolic computation programs, i.e., only some very specific values can be computed by the mentioned programs. An error analysis is given in the sequel for the introduced expansion.",
                    "score": 0.8562421202659607
                },
                {
                    "id": 17462513,
                    "contents": "Beyond the LSD method for the partial sums of multiplicative functions.\nThe Landau-Selberg-Delange method gives an asymptotic formula for the partial sums of a multiplicative function <if</i whose prime values are <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miα</mml:mi</mml:math on average. In the literature, the average is usually taken to be <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miα</mml:mi</mml:math with a very strong error term, leading to an asymptotic formula for the partial sums with a very strong error term. In practice, the average at the prime values may only be known with a fairly weak error term, and so we explore here how good an estimate this will imply for the partial sums of <if</i, developing new techniques to do so.",
                    "score": 0.8556088209152222
                },
                {
                    "id": 23351778,
                    "contents": "A Class of Double Integrals Involving Gaussian and Trigonometric Factors.\nThe five parameter double integral <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow <mml:mrow<mml:msubsup<mml:mo∫</mml:mo <mml:mn0</mml:mn <mml:mi∞</mml:mi</mml:msubsup <mml:mid</mml:mi</mml:mrow <mml:miy</mml:mi <mml:mtextexp</mml:mtext <mml:mrow<mml:mo(</mml:mo <mml:mrow<mml:mo-</mml:mo <mml:msup<mml:mip</mml:mi <mml:mn2</mml:mn</mml:msup <mml:msup<mml:miy</mml:mi <mml:mn2</mml:mn</mml:msup </mml:mrow <mml:mo)</mml:mo</mml:mrow <mml:mtextsin</mml:mtext <mml:mo(</mml:mo <mml:miβ</mml:mi <mml:miy</mml:mi <mml:mo+</mml:mo <mml:miθ</mml:mi <mml:mo)</mml:mo</mml:mrow </mml:math times <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow <mml:mrow<mml:msubsup<mml:mo∫</mml:mo <mml:mn0</mml:mn <mml:miy</mml:mi</mml:msubsup <mml:mid</mml:mi</mml:mrow <mml:mix</mml:mi <mml:mtextexp</mml:mtext <mml:mrow<mml:mo(</mml:mo <mml:mrow<mml:mo-</mml:mo <mml:msup<mml:mix</mml:mi <mml:mn2</mml:mn</mml:msup </mml:mrow <mml:mo)</mml:mo</mml:mrow <mml:mtextcos</mml:mtext <mml:mo(</mml:mo <mml:miϵ</mml:mi <mml:miβ</mml:mi <mml:mix</mml:mi <mml:mo+</mml:mo <mml:miϕ</mml:mi <mml:mo)</mml:mo</mml:mrow </mml:math is evaluated in terms of Fourier transforms of exp(- <ix</i <sup2</sup)erfc(<iαx</i). Some new expressions for these transforms are obtained.",
                    "score": 0.8548378348350525
                },
                {
                    "id": 20650615,
                    "contents": "Approximate Entropy and Sample Entropy: A Comprehensive Tutorial.\nApproximate Entropy and Sample Entropy are two algorithms for determining the regularity of series of data based on the existence of patterns. Despite their similarities, the theoretical ideas behind those techniques are different but usually ignored. This paper aims to be a complete guideline of the theory and application of the algorithms, intended to explain their characteristics in detail to researchers from different fields. While initially developed for physiological applications, both algorithms have been used in other fields such as medicine, telecommunications, economics or Earth sciences. In this paper, we explain the theoretical aspects involving Information Theory and Chaos Theory, provide simple source codes for their computation, and illustrate the techniques with a step by step example of how to use the algorithms properly. This paper is not intended to be an exhaustive review of all previous applications of the algorithms but rather a comprehensive tutorial where no previous knowledge is required to understand the methodology.",
                    "score": 0.8547391891479492
                },
                {
                    "id": 7952328,
                    "contents": "Discrete sums for the rapid determination of exponential decay constants.\nSeveral computational methods are presented for the rapid extraction of decay time constants from discrete exponential data. Two methods are found to be comparably fast and highly accurate. They are corrected successive integration and a method involving the Fourier transform (FT) of the data and the application of an expression that does not assume continuous data. FT methods in the literature are found to introduce significant systematic error owing to the assumption that data are continuous. Corrected successive integration methods in the literature are correct, but we offer a more direct way of applying them which we call linear regression of the sum. We recommend the use of the latter over FT-based methods, as the FT methods are more affected by noise in the original data.",
                    "score": 0.8541327714920044
                },
                {
                    "id": 9617151,
                    "contents": "A Simple Proof of Siegel's Theorem.\nA brief and simple proof of Siegel's celebrated theorem that h(d) &gt;&gt; d(1/2-[unk]), as d --&gt; infinity, is given. Here h(d) denotes the class number of the quadratic field Q([unk]-d). Simple proofs that do not make use of algebraic number theory have been previously given by Estermann and Chowla.",
                    "score": 0.8531866073608398
                },
                {
                    "id": 17269017,
                    "contents": "Correction to: Explicit upper bound for the average number of divisors of irreducible quadratic polynomials.\n[This corrects the article DOI: 10.1007/s00605-017-1061-y.].",
                    "score": 0.8525610566139221
                },
                {
                    "id": 14094978,
                    "contents": "Estimation of the entropy based on its polynomial representation.\nEstimating entropy from empirical samples of finite size is of central importance for information theory as well as the analysis of complex statistical systems. Yet, this delicate task is marred by intrinsic statistical bias. Here we decompose the entropy function into a polynomial approximation function and a remainder function. The approximation function is based on a Taylor expansion of the logarithm. Given n observations, we give an unbiased, linear estimate of the first n power series terms based on counting sets of k coincidences. For the remainder function we use nonlinear Bayesian estimation with a nearly flat prior distribution on the entropy that was developed by Nemenman, Shafee, and Bialek. Our simulations show that the combined entropy estimator has reduced bias in comparison to other available estimators.",
                    "score": 0.8518989682197571
                },
                {
                    "id": 5937873,
                    "contents": "Fast algorithm for generating long self-affine profiles.\nWe introduce a fast algorithm for generating long self-affine profiles. The algorithm, which is based on the fast wavelet transform, is faster than the conventional Fourier filtering algorithm. In addition to increased performance for large systems, the algorithm, named the wavelet filtering algorithm, a priori gives rise to profiles for which the long-range correlation extends throughout the entire system independently of the length scale.",
                    "score": 0.8511680364608765
                },
                {
                    "id": 14718520,
                    "contents": "Universal series induced by approximate identities and some relevant applications.\nWe prove the existence of series [Formula: see text], whose coefficients [Formula: see text] are in [Formula: see text] and whose terms [Formula: see text] are translates by rational vectors in [Formula: see text] of a family of approximations to the identity, having the property that the partial sums are dense in various spaces of functions such as Wiener's algebra [Formula: see text], [Formula: see text], [Formula: see text], [Formula: see text], for every [Formula: see text], and the space of measurable functions. Applying this theory to particular situations, we establish approximations by such series to solutions of the heat and Laplace equations as well as to probability density functions.",
                    "score": 0.8499807715415955
                },
                {
                    "id": 9618297,
                    "contents": "Rational approximations to linear forms of exponentials and binomials.\nMahler proved the following quantitative result supplementing the Lindemann-Weierstrass theorem: Sigma(i=0) (n)C(i)e(ri) &gt; H(-n-epsilon) for any distinct rational numbers r(0),r(1),..., r(n) and rational integers C(0),C(1),...,C(n) with H = max(0&lt;/=i&lt;/=n) C(i). We improve Mahler's estimate by replacing exponentials e(ri) by linearly independent linear forms L(i) = Sigma L(ij)e(sij) with rational L(ij),s(ij)i = 0,1,...,n. Similar results are obtained for binomials (a/b)(ri) or Sigma L(ij)(a/b)(sij) with integers a,b and logb/loga &gt; 1 - epsilon. The simplest examples of new numbers with the irrationality exponent \"2 + epsilon\" are sinh 1 or sin 1.",
                    "score": 0.8499369621276855
                },
                {
                    "id": 8254968,
                    "contents": "Detrended cross-correlation analysis: a new method for analyzing two nonstationary time series.\nHere we propose a new method, detrended cross-correlation analysis, which is a generalization of detrended fluctuation analysis and is based on detrended covariance. This method is designed to investigate power-law cross correlations between different simultaneously recorded time series in the presence of nonstationarity. We illustrate the method by selected examples from physics, physiology, and finance.",
                    "score": 0.8497599959373474
                },
                {
                    "id": 9240028,
                    "contents": "Wavelet analysis and scaling properties of time series.\nWe propose a wavelet based method for the characterization of the scaling behavior of nonstationary time series. It makes use of the built-in ability of the wavelets for capturing the trends in a data set, in variable window sizes. Discrete wavelets from the Daubechies family are used to illustrate the efficacy of this procedure. After studying binomial multifractal time series with the present and earlier approaches of detrending for comparison, we analyze the time series of averaged spin density in the 2D Ising model at the critical temperature, along with several experimental data sets possessing multifractal behavior.",
                    "score": 0.8494539260864258
                },
                {
                    "id": 9691374,
                    "contents": "Fast algorithms for classical physics.\nSome of the recently developed fast summation methods that have arisen in scientific computing are described. These methods require an amount of work proportional to N or N log N to evaluate all pairwise interactions in an ensemble of N particles. Traditional methods, by contrast, require an amount of work proportional to N(2). As a result, largescale simulations can be carried out using only modest computer resources. In combination with supercomputers, it is possible to address questions that were previously out of reach. Problems from diffusion, gravitation, and wave propagation are considered.",
                    "score": 0.8493763208389282
                },
                {
                    "id": 15791453,
                    "contents": "Nonlinear time-series analysis revisited.\nIn 1980 and 1981, two pioneering papers laid the foundation for what became known as nonlinear time-series analysis: the analysis of observed data-typically univariate-via dynamical systems theory. Based on the concept of state-space reconstruction, this set of methods allows us to compute characteristic quantities such as Lyapunov exponents and fractal dimensions, to predict the future course of the time series, and even to reconstruct the equations of motion in some cases. In practice, however, there are a number of issues that restrict the power of this approach: whether the signal accurately and thoroughly samples the dynamics, for instance, and whether it contains noise. Moreover, the numerical algorithms that we use to instantiate these ideas are not perfect; they involve approximations, scale parameters, and finite-precision arithmetic, among other things. Even so, nonlinear time-series analysis has been used to great advantage on thousands of real and synthetic data sets from a wide variety of systems ranging from roulette wheels to lasers to the human heart. Even in cases where the data do not meet the mathematical or algorithmic requirements to assure full topological conjugacy, the results of nonlinear time-series analysis can be helpful in understanding, characterizing, and predicting dynamical systems. ",
                    "score": 0.8492617011070251
                },
                {
                    "id": 19477880,
                    "contents": "Correction: The complex dynamics of products and its asymptotic properties.\n[This corrects the article DOI: 10.1371/journal.pone.0177360.].",
                    "score": 0.8487621545791626
                },
                {
                    "id": 22388509,
                    "contents": "Extended Wang sum and associated products.\nThe Wang sum involving the exponential sums of Lerch's Zeta functions is extended to the finite sum of the Huwitz-Lerch Zeta function to derive sums and products involving cosine and tangent trigonometric functions. The general theorem used to derive these sums and products is in the form of the finite sum over positive integers of the Hurwitz-Lerch Zeta function where the associated parameters are general complex numbers. New Hurwitz-Lerch Zeta function recurrence identities with consecutive neighbours are derived. Some finite sum and product formulae examples involving cosine, tangent and the product of cosine and tangent functions are also derived and evaluated.",
                    "score": 0.8486143946647644
                },
                {
                    "id": 18129605,
                    "contents": "Fourier series of finite products of Bernoulli and Genocchi functions.\nIn this paper, we consider three types of functions given by products of Bernoulli and Genocchi functions and derive some new identities arising from Fourier series expansions associated with Bernoulli and Genocchi functions. Furthermore, we will express each of them in terms of Bernoulli functions.",
                    "score": 0.848412036895752
                },
                {
                    "id": 8058211,
                    "contents": "A computationally simple and robust method to detect determinism in a time series.\nWe present a new, simple, and fast computational technique, termed the incremental slope (IS), that can accurately distinguish between deterministic from stochastic systems even when the variance of noise is as large or greater than the signal, and remains robust for time-varying signals. The IS method is more accurate than the widely utilized Poincare plot analysis especially when the data are severely contaminated by noise. The efficacy of the IS is demonstrated with several simulated deterministic and stochastic signals.",
                    "score": 0.8480098843574524
                },
                {
                    "id": 18974547,
                    "contents": "Correction: Fitting power-laws in empirical data with estimators that work for all exponents.\n[This corrects the article DOI: 10.1371/journal.pone.0170920.].",
                    "score": 0.8471361398696899
                },
                {
                    "id": 20867802,
                    "contents": "Practical rules for summing the series of the Tweedie probability density function with high-precision arithmetic.\nFor some ranges of its parameters and arguments, the series for Tweedie probability density functions are sometimes exceedingly difficult to sum numerically. Existing numerical implementations utilizing inversion techniques and properties of stable distributions can cope with these problems, but no single one is successful in all cases. In this work we investigate heuristically the nature of the problem, and show that it is not related to the order of summation of the terms. Using a variable involved in the analytical proof of convergence of the series, the critical parameter for numerical non-convergence (\"alpha\") is identified, and an heuristic criterion is developed to avoid numerical non-convergence for a reasonably large sub-interval of the latter. With these practical rules, simple summation algorithms provide sufficiently robust results for the calculation of the density function and its definite integrals. These implementations need to utilize high-precision arithmetic, and are programmed in the Python programming language. A thorough comparison with existing R functions allows the identification of cases when the latter fail, and provide further guidance to their use.",
                    "score": 0.8470243215560913
                },
                {
                    "id": 21716799,
                    "contents": "Computing sums in terms of beta, polygamma, and Gauss hypergeometric functions.\nIn the paper, by virtue of the binomial inversion formula, a general formula of higher order derivatives for a ratio of two differentiable function, and other techniques, the authors compute several sums in terms of the beta function and its partial derivatives, polygamma functions, the Gauss hypergeometric function, and a determinant. These results generalize known ones in combinatorics.",
                    "score": 0.8460246324539185
                },
                {
                    "id": 4319805,
                    "contents": "TSAN: a package for time series analysis.\nMany biomedical data are in the form of time series. Analyses of these data include: (1) search for any biorhythm; (2) test of homogeneity of several time series; (3) assessment of stationarity; (4) test of normality of the time series histogram; (5) evaluation of dependence between data points. In this paper we present a subroutine package called TSAN. It is developed to accomplish these tasks. Computational methods, as well as flowcharts, for these subroutines are described. Two sample runs are demonstrated.",
                    "score": 0.8444123864173889
                },
                {
                    "id": 11867669,
                    "contents": "Secular series and renormalization group for amplitude equations.\nWe have developed a technique that circumvents the process of elimination of secular terms [L.-Y. Chen, N. Goldenfeld, and Y. Oono, Phys. Rev. E 54, 376 (1996)] and reproduces the uniformly valid approximations, amplitude equations, and first integrals. The technique is based on a rearrangement of secular terms and their grouping into the secular series that multiplies the constants of the asymptotic expansion. We illustrate the technique by deriving amplitude equations for standard nonlinear oscillator and boundary-layer problems.",
                    "score": 0.8440520763397217
                },
                {
                    "id": 9617233,
                    "contents": "Almost All Roots of zeta(s) = a Are Arbitrarily Close to sigma = 1/2.\nLet s = sigma + it. For any complex a, all but O(1/log log T) of the roots of zeta(s) = a in T &lt; t &lt; 2T lie in|sigma - 1/2| &lt; (log log T)(2)/log T. The results extend easily to other functions satisfying a functional equation such as the Dirichlet L-functions, the Lerch functions, etc.",
                    "score": 0.8440060019493103
                },
                {
                    "id": 16466790,
                    "contents": "Asymptotic formulae for the Lommel and Bessel functions and their derivatives.\nWe derive new approximate representations of the Lommel functions in terms of the Scorer function and approximate representations of the first derivative of the Lommel functions in terms of the derivative of the Scorer function. Using the same method, we obtain previously known approximate representations of the Nicholson type for Bessel functions and their first derivatives. We study also for what values of the parameters our representations have reasonable accuracy. ",
                    "score": 0.8439764976501465
                },
                {
                    "id": 9962175,
                    "contents": "Computing the multifractal spectrum from time series: an algorithmic approach.\nWe show that the existing methods for computing the f(alpha) spectrum from a time series can be improved by using a new algorithmic scheme. The scheme relies on the basic idea that the smooth convex profile of a typical f(alpha) spectrum can be fitted with an analytic function involving a set of four independent parameters. While the standard existing schemes [P. Grassberger et al., J. Stat. Phys. 51, 135 (1988); A. Chhabra and R. V. Jensen, Phys. Rev. Lett. 62, 1327 (1989)] generally compute only an incomplete f(alpha) spectrum (usually the top portion), we show that this can be overcome by an algorithmic approach, which is automated to compute the D(q) and f(alpha) spectra from a time series for any embedding dimension. The scheme is first tested with the logistic attractor with known f(alpha) curve and subsequently applied to higher-dimensional cases. We also show that the scheme can be effectively adapted for analyzing practical time series involving noise, with examples from two widely different real world systems. Moreover, some preliminary results indicating that the set of four independent parameters may be used as diagnostic measures are also included.",
                    "score": 0.8438934683799744
                },
                {
                    "id": 2667573,
                    "contents": "Further remarks on convergence of decomposition method.\nThe decomposition method solves a wide class of nonlinear functional equations. This method uses a series solution with rapid convergence. This paper is intended as a useful review and clarification of related issues.",
                    "score": 0.8434162735939026
                },
                {
                    "id": 6590341,
                    "contents": "Approximate entropy (ApEn) as a complexity measure.\nApproximate entropy (ApEn) is a recently developed statistic quantifying regularity and complexity, which appears to have potential application to a wide variety of relatively short (greater than 100 points) and noisy time-series data. The development of ApEn was motivated by data length constraints commonly encountered, e.g., in heart rate, EEG, and endocrine hormone secretion data sets. We describe ApEn implementation and interpretation, indicating its utility to distinguish correlated stochastic processes, and composite deterministic/ stochastic models. We discuss the key technical idea that motivates ApEn, that one need not fully reconstruct an attractor to discriminate in a statistically valid manner-marginal probability distributions often suffice for this purpose. Finally, we discuss why algorithms to compute, e.g., correlation dimension and the Kolmogorov-Sinai (KS) entropy, often work well for true dynamical systems, yet sometimes operationally confound for general models, with the aid of visual representations of reconstructed dynamics for two contrasting processes. (c) 1995 American Institute of Physics.",
                    "score": 0.8433268070220947
                },
                {
                    "id": 17427422,
                    "contents": "Some notes on Sonine-Gegenbauer integrals.\nWe provide an explicit formula for a Sonine-Gegenbauer integral, which seems to be unknown in the literature so far. For another type of these integrals, we show a dependence relation over the rational functions, including the explicit calculation of the coefficient functions.",
                    "score": 0.8426883220672607
                },
                {
                    "id": 7105543,
                    "contents": "A direct analytical demonstration of the essential equivalence of detrended fluctuation analysis and spectral analysis of RR interval variability.\nDetrended fluctuation analysis (DFA) of heart rate variability appears to yield improved prognostic power in cardiovascular disease, through calculation of the fractal scaling exponent alpha. We have recently used Taylor series approximations to propose that DFA is closely related to standard spectral analysis measures. We now present a direct analytical approach using integration and explicit expressions for the steps involved in DFA. This demonstrates clearly how DFA corresponds to standard spectral analysis.",
                    "score": 0.842195987701416
                },
                {
                    "id": 4725261,
                    "contents": "Deviations from uniform power law scaling in nonstationary time series.\nA classic problem in physics is the analysis of highly nonstationary time series that typically exhibit long-range correlations. Here we test the hypothesis that the scaling properties of the dynamics of healthy physiological systems are more stable than those of pathological systems by studying beat-to-beat fluctuations in the human heart rate. We develop techniques based on the Fano factor and Allan factor functions, as well as on detrended fluctuation analysis, for quantifying deviations from uniform power-law scaling in nonstationary time series. By analyzing extremely long data sets of up to N = 10(5) beats for 11 healthy subjects, we find that the fluctuations in the heart rate scale approximately uniformly over several temporal orders of magnitude. By contrast, we find that in data sets of comparable length for 14 subjects with heart disease, the fluctuations grow erratically, indicating a loss of scaling stability.",
                    "score": 0.8420693874359131
                },
                {
                    "id": 5249487,
                    "contents": "Calculating response functions in time domain with nonorthonormal basis sets\nWe extend the recently proposed order-N algorithms for calculating linear- and nonlinear-response functions in time domain to the systems described by nonorthonormal basis sets.",
                    "score": 0.8419954776763916
                },
                {
                    "id": 9391196,
                    "contents": "Bayesian wavelet networks for nonparametric regression.\nRadial wavelet networks have recently been proposed as a method for nonparametric regression. In this paper we analyze their performance within a Bayesian framework. We derive probability distributions over both the dimension of the networks and the network coefficients by placing a prior on the degrees of freedom of the model. This process bypasses the need to test or select a finite number of networks during the modeling process. Predictions are formed by mixing over many models of varying dimension and parameterization.We show that the complexity of the models adapts to the complexity of the data and produces good results on a number of benchmark test series.",
                    "score": 0.8418848514556885
                },
                {
                    "id": 13423303,
                    "contents": "Taylor's expansion for composite functions.\nWe build a Taylor's expansion for composite functions. Some applications are introduced, where the proposed technique allows the authors to obtain an asymptotic expansion of high order in many small parameters of solutions. ",
                    "score": 0.8418161869049072
                },
                {
                    "id": 23167501,
                    "contents": "Simple renormalization schemes for multiple scattering series expansions.\nA number of renormalization schemes for improving the convergence of multiple scattering series expansions are investigated. Numerical tests on a small Cu(111) cluster demonstrate their effectiveness, for example increasing the rate of convergence by up to a factor 2 or by transforming a divergent series into a convergent one. These techniques can greatly facilitate multiple scattering calculations, especially for spectroscopies such as photoelectron diffraction, Auger electron diffraction, low energy electron diffraction <ietc.</i, where an electron propagates with a kinetic energy of hundreds of eV in a cluster of hundreds of atoms.",
                    "score": 0.8414737582206726
                },
                {
                    "id": 22303189,
                    "contents": "On the Distribution of the Information Density of Gaussian Random Vectors: Explicit Formulas and Tight Approximations.\nBased on the canonical correlation analysis, we derive series representations of the probability density function (PDF) and the cumulative distribution function (CDF) of the information density of arbitrary Gaussian random vectors as well as a general formula to calculate the central moments. Using the general results, we give closed-form expressions of the PDF and CDF and explicit formulas of the central moments for important special cases. Furthermore, we derive recurrence formulas and tight approximations of the general series representations, which allow efficient numerical calculations with an arbitrarily high accuracy as demonstrated with an implementation in Python publicly available on GitLab. Finally, we discuss the (in)validity of Gaussian approximations of the information density.",
                    "score": 0.8414286971092224
                },
                {
                    "id": 4430364,
                    "contents": "Numerical operations on oscillatory functions.\nWe consider some typical numerical operations on functions (differentiation, integration, solving differential equations, interpolation) and show how the standard algorithms can be modified to become efficient when the functions are oscillatory, of the form y(x) = f1(x) sin(omega x) + f2(x) cos(omega x) where f1(x) and f2(x) are smooth functions. The expressions of the parameters of the new formulae are written in a way which makes them tuned also for functions of form y(x) =f1(x) sinh(lambda x) + f2(x) cosh(lambda x). Our formulae only require the values of y at some points and those of omega or lambda and they tend to the classical formulae when omega or lambda tends to zero. For the derivation we follow the exponential fitting technique introduced in a previous paper (L. Gr. Ixaru, Comput. Phys. Commun. 105 (1997), 1-19). We list the tuned expressions for the first and the second derivative, for the Simpson quadrature formula and for the Numerov algorithm to solve differential equations. We also show how the Gauss quadrature rule can be adapted and finally give a few tuned formulae for the interpolation. Numerical illustrations are presented for each case. Some open problems are also mentioned.",
                    "score": 0.8413944840431213
                },
                {
                    "id": 8654832,
                    "contents": "Self-Fourier functions and self-Fourier operators.\nThe concept of self-Fourier functions, i.e., functions that equal their Fourier transform, is almost always associated with specific functions, the most well known being the Gaussian and the Dirac delta comb. We show that there exists an infinite number of distinct families of these functions, and we provide an algorithm for both generating and characterizing their distinct classes. This formalism allows us to show the existence of these families of functions without actually evaluating any Fourier or other transform-type integrals, a task often challenging and frequently not even possible.",
                    "score": 0.8411461114883423
                },
                {
                    "id": 21339566,
                    "contents": "Evaluation of Abramowitz functions in the right half of the complex plane.\nA numerical scheme is developed for the evaluation of Abramowitz functions <iJ<subn</sub</i in the right half of the complex plane. For <in</i = - 1, … , 2, the scheme utilizes series expansions for ∣<iz</i∣ &lt; 1, asymptotic expansions for ∣<iz</i∣ &gt; <iR</i with <iR</i determined by the required precision, and least squares Laurent polynomial approximations on each sub-region in the intermediate region 1 ≤ ∣<iz</i∣ ≤ <iR</i. For <in</i &gt; 2, <iJ<subn</sub</i is evaluated via a forward recurrence relation. The scheme achieves nearly machine precision for <in</i = -1, … , 2 at a cost that is competitive as compared with software packages for the evaluation of other special functions in the complex domain.",
                    "score": 0.8410741090774536
                }
            ],
            "metric_score": {
                "retrieval_recall": 1,
                "retrieval_precision": 0.2
            }
        }
    },
    {
        "id": "test_7",
        "question": "Through what potential must a proton initially at rest fall so that its de Broglie wavelength is $1.0 \\times 10^{-10} \\mathrm{~m}$ ?",
        "golden_answers": [
            " 0.082"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 9695425,
                    "contents": "Is the proton stable.\nFor nearly 50 years there has been a strong belief that the proton is absolutely stable. The current experimental upper bound on its decay rate is less than one proton decay per 3 tons of matter per year, which corresponds to a mean lifetime of more than 10(30) years. Even more sensitive searches for proton decay are now in progress. These are partially motivated by the development of a class of models that combine the presently accepted theories of electromagnetic, weak, and strong inter-actions into an elegant unified form. Some of these theories predict a proton lifetime short enough for the decays to be detectable by the proposed experiments. If the proton is unstable, a plausible explanation can be given for the apparent excess of matter over antimatter in the universe.",
                    "score": 0.8750991821289062
                },
                {
                    "id": 14094154,
                    "contents": "Trouble with the Lorentz law of force: incompatibility with special relativity and momentum conservation.\nThe Lorentz law of force is the fifth pillar of classical electrodynamics, the other four being Maxwell's macroscopic equations. The Lorentz law is the universal expression of the force exerted by electromagnetic fields on a volume containing a distribution of electrical charges and currents. If electric and magnetic dipoles also happen to be present in a material medium, they are traditionally treated by expressing the corresponding polarization and magnetization distributions in terms of bound-charge and bound-current densities, which are subsequently added to free-charge and free-current densities, respectively. In this way, Maxwell's macroscopic equations are reduced to his microscopic equations, and the Lorentz law is expected to provide a precise expression of the electromagnetic force density on material bodies at all points in space and time. This Letter presents incontrovertible theoretical evidence of the incompatibility of the Lorentz law with the fundamental tenets of special relativity. We argue that the Lorentz law must be abandoned in favor of a more general expression of the electromagnetic force density, such as the one discovered by Einstein and Laub in 1908. Not only is the Einstein-Laub formula consistent with special relativity, it also solves the long-standing problem of \"hidden momentum\" in classical electrodynamics.",
                    "score": 0.8619006872177124
                },
                {
                    "id": 10273804,
                    "contents": "The size of the proton.\nThe proton is the primary building block of the visible Universe, but many of its properties-such as its charge radius and its anomalous magnetic moment-are not well understood. The root-mean-square charge radius, r(p), has been determined with an accuracy of 2 per cent (at best) by electron-proton scattering experiments. The present most accurate value of r(p) (with an uncertainty of 1 per cent) is given by the CODATA compilation of physical constants. This value is based mainly on precision spectroscopy of atomic hydrogen and calculations of bound-state quantum electrodynamics (QED; refs 8, 9). The accuracy of r(p) as deduced from electron-proton scattering limits the testing of bound-state QED in atomic hydrogen as well as the determination of the Rydberg constant (currently the most accurately measured fundamental physical constant). An attractive means to improve the accuracy in the measurement of r(p) is provided by muonic hydrogen (a proton orbited by a negative muon); its much smaller Bohr radius compared to ordinary atomic hydrogen causes enhancement of effects related to the finite size of the proton. In particular, the Lamb shift (the energy difference between the 2S(1/2) and 2P(1/2) states) is affected by as much as 2 per cent. Here we use pulsed laser spectroscopy to measure a muonic Lamb shift of 49,881.88(76) GHz. On the basis of present calculations of fine and hyperfine splittings and QED terms, we find r(p) = 0.84184(67) fm, which differs by 5.0 standard deviations from the CODATA value of 0.8768(69) fm. Our result implies that either the Rydberg constant has to be shifted by -110 kHz/c (4.9 standard deviations), or the calculations of the QED effects in atomic hydrogen or muonic hydrogen atoms are insufficient.",
                    "score": 0.8564254641532898
                },
                {
                    "id": 9667532,
                    "contents": "Physics.\nFrom massive quarks deep in the hearts of atomic nuclei to the catastrophic collapse of giant stars in the farthest reaches of the universe, from the partial realization of Einstein's dream of a unified theory of the forces of nature to the most practical applications in technology, medicine, and throughout contemporary society, physics continues to have a profound impact on man's view of the universe and on the quality of life. The author argues that the past few years, in terms of new discoveries, new insight-and the new questions-have been among the most productive in the history of the field and puts into context his selection of some of the most important new developments in this fundamental science.",
                    "score": 0.8547287583351135
                },
                {
                    "id": 13258630,
                    "contents": "Proton: the particle.\nThe purpose of this article is to review briefly the nature of protons: creation at the Big Bang, abundance, physical characteristics, internal components, and life span. Several particle discoveries by proton as the experimental tool are considered. Protons play important roles in science, medicine, and industry. This article was prompted by my experience in the curative treatment of cancer patients by protons and my interest in the nature of protons as particles. The latter has been stimulated by many discussions with particle physicists and reading related books and journals. Protons in our universe number ≈10(80). Protons were created at 10(-6) -1 second after the Big Bang at ≈1.37 × 10(10) years beforethe present. Proton life span has been experimentally determined to be ≥10(34) years; that is, the age of the universe is 10(-24)th of the minimum life span of a proton. The abundance of the elements is hydrogen, ≈74%; helium, ≈24%; and heavier atoms, ≈2%. Accordingly, protons are the dominant baryonic subatomic particle in the universe because ≈87% are protons. They are in each atom in our universe and thus involved in virtually every activity of matter in the visible universe, including life on our planet. Protons were discovered in 1919. In 1968, they were determined to be composed of even smaller particles, principally quarks and gluons. Protons have been the experimental tool in the discoveries of quarks (charm, bottom, and top), bosons (W(+), W(-), Z(0), and Higgs), antiprotons, and antineutrons. Industrial applications of protons are numerous and important. Additionally, protons are well appreciated in medicine for their role in radiation oncology and in magnetic resonance imaging. Protons are the dominant baryonic subatomic particle in the visible universe, comprising ≈87% of the particle mass. They are present in each atom of our universe and thus a participant in every activity involving matter.",
                    "score": 0.8537070155143738
                },
                {
                    "id": 15401399,
                    "contents": "Proton Momentum Distribution and Diffusion Coefficient in Water: Two Sides of the Same Coin?\nWater, the prototype of a liquid to ordinary people, is the most anomalous liquid to physicists, showing regions of the temperature-density (T,ρ) plane where its microscopic structure, diffusion coefficient, and density have anomalous behaviors. Structural anomalies occur over a broad bell-shaped T,ρ region. This region contains, as a matryoshka, two smaller regions, one delimiting dynamical and the other delimiting thermodynamic anomalies. Water anomalous behavior in each of these regions manifests itself as a decrease of order or an increase of the diffusion coefficient upon increasing pressure and as a decrease of density upon cooling. Here, we show that the radial momentum distribution of water protons and their mean kinetic energy have a peculiar, theoretically unpredicted anomaly in the region of dynamical anomalies. This anomaly can be rationalized as due to two distinct \"families\" of water protons, experiencing quite distinct local environments, leading to an enhancement of the momentum fluctuations along with an increase of kinetic energy. ",
                    "score": 0.8528962135314941
                },
                {
                    "id": 8185642,
                    "contents": "Stability of the proton-to-electron mass ratio.\nWe report a limit on the fractional temporal variation of the proton-to-electron mass ratio as 1/(m(P)/m(e)) partial differential/partial differential(t)(m(P)/m(e))=(-3.8+/-5.6) x 10(-14) yr(-1), obtained by comparing the frequency of a rovibrational transition in SF6 with the fundamental hyperfine transition in Cs. The SF6 transition was accessed using a CO2 laser to interrogate spatial 2-photon Ramsey fringes. The atomic transition was accessed using a primary standard controlled with a Cs fountain. This result is direct and model-free.",
                    "score": 0.8526180982589722
                },
                {
                    "id": 8320738,
                    "contents": "Ionization ranges of protons in water vapour in the energy range 1-100 keV.\nProjected ranges of protons in water vapour were experimentally determined for proton energies from 1 to 100 keV by counting the total number of ionizations produced by protons during their slow down. Using these experimental ranges and semiemprical detour factors, the stopping powers of water vapour for protons were derived and compared with semiempirical data.",
                    "score": 0.8514741063117981
                },
                {
                    "id": 20319978,
                    "contents": "Speed of sound from fundamental physical constants.\nTwo dimensionless fundamental physical constants, the fine structure constant α and the proton-to-electron mass ratio [Formula: see text], are attributed a particular importance from the point of view of nuclear synthesis, formation of heavy elements, planets, and life-supporting structures. Here, we show that a combination of these two constants results in a new dimensionless constant that provides the upper bound for the speed of sound in condensed phases, <iv<subu</sub</i We find that [Formula: see text], where <ic</i is the speed of light in vacuum. We support this result by a large set of experimental data and first-principles computations for atomic hydrogen. Our result expands the current understanding of how fundamental constants can impose new bounds on important physical properties.",
                    "score": 0.8475937247276306
                },
                {
                    "id": 14905633,
                    "contents": "Will a Decaying Atom Feel a Friction Force?\nWe show how a simple calculation leads to the surprising result that an excited two-level atom moving through a vacuum sees a tiny friction force of first order in v/c. At first sight this seems to be in obvious contradiction to other calculations showing that the interaction with the vacuum does not change the velocity of an atom. It is even more surprising that this change in the atom's momentum turns out to be a necessary result of energy and momentum conservation in special relativity.",
                    "score": 0.8474373817443848
                },
                {
                    "id": 4797063,
                    "contents": "Negative Poisson's ratios for extreme states of matter\nNegative Poisson's ratios are predicted for body-centered-cubic phases that likely exist in white dwarf cores and neutron star outer crusts, as well as those found for vacuumlike ion crystals, plasma dust crystals, and colloidal crystals (including certain virus crystals). The existence of this counterintuitive property, which means that a material laterally expands when stretched, is experimentally demonstrated for very low density crystals of trapped ions. At very high densities, the large predicted negative and positive Poisson's ratios might be important for understanding the asteroseismology of neutron stars and white dwarfs and the effect of stellar stresses on nuclear reaction rates. Giant Poisson's ratios are both predicted and observed for highly strained coulombic photonic crystals, suggesting possible applications of large, tunable Poisson's ratios for photonic crystal devices.",
                    "score": 0.846876859664917
                },
                {
                    "id": 12810006,
                    "contents": "Astronomical reach of fundamental physics.\nUsing basic physical arguments, we derive by dimensional and physical analysis the characteristic masses and sizes of important objects in the universe in terms of just a few fundamental constants. This exercise illustrates the unifying power of physics and the profound connections between the small and the large in the cosmos we inhabit. We focus on the minimum and maximum masses of normal stars, the corresponding quantities for neutron stars, the maximum mass of a rocky planet, the maximum mass of a white dwarf, and the mass of a typical galaxy. To zeroth order, we show that all these masses can be expressed in terms of either the Planck mass or the Chandrasekar mass, in combination with various dimensionless quantities. With these examples, we expose the deep interrelationships imposed by nature between disparate realms of the universe and the amazing consequences of the unifying character of physical law. ",
                    "score": 0.8468512296676636
                },
                {
                    "id": 8992347,
                    "contents": "Prethermalization.\nPrethermalization of the equation of state and the kinetic temperature to their equilibrium values occurs on time scales dramatically shorter than the thermal equilibration time. This is a crucial ingredient for the understanding of collisions of heavy nuclei or other nonequilibrium phenomena in complex quantum and classical many body systems. We also compare the chemical equilibration time with other characteristic time scales.",
                    "score": 0.8465142250061035
                },
                {
                    "id": 15832817,
                    "contents": "Revision of the thermodynamics of the proton in gas phase.\nProton transfer is ubiquitous in various physical/chemical processes, and the accurate determination of the thermodynamic parameters of the proton in the gas phase is useful for understanding and describing such reactions. However, the thermodynamic parameters of such a proton are usually determined by assuming the proton as a classical particle whatever the temperature. The reason for such an assumption is that the entropy of the quantum proton is not always soluble analytically at all temperatures. Thereby, we addressed this matter using a robust and reliable self-consistent iterative procedure based on the Fermi-Dirac formalism. As a result, the free proton gas can be assumed to be classical for temperatures higher than 200 K. However, it is worth mentioning that quantum effects on the gas phase proton motion are really significant at low temperatures (T ≤ 120 K). Although the proton behaves as a classical particle at high temperatures, we strongly recommend the use of quantum results at all temperatures, for the integrated heat capacity and the Gibbs free energy change. Therefore, on the basis of the thermochemical convention that ignores the proton spin, we recommend the following revised values for the integrated heat capacity and the Gibbs free energy change of the proton in gas phase and, at the standard pressure (1 bar): ΔH0→T = 6.1398 kJ mol(-1) and ΔG0→T = -26.3424 kJ mol(-1). Finally, it is important noting that the little change of the pressure from 1 bar to 1 atm affects notably the entropy and the Gibbs free energy change of the proton. ",
                    "score": 0.8453558683395386
                },
                {
                    "id": 11899697,
                    "contents": "Quantum corrections and bound-state effects in the energy relaxation of hot dense hydrogen.\nSimple analytic formulas for energy relaxation (ER) in electron-ion systems, with quantum corrections, ion dynamics, and RPA-type screening are presented. ER in the presence of bound electrons is examined in view of recent simulations for ER in hydrogen in the range 10{20}-10{24} electrons/cc.",
                    "score": 0.8449156284332275
                },
                {
                    "id": 17966374,
                    "contents": "Erratum: Simple Pendulum Determination of the Gravitational Constant [Phys. Rev. Lett. 105, 110801 (2010)].\nThis corrects the article DOI: 10.1103/PhysRevLett.105.110801.",
                    "score": 0.8448219299316406
                },
                {
                    "id": 9240963,
                    "contents": "Stellar stability by thermodynamic instability.\nFor gravity-dominated systems the three features shrinking &lt;=&gt; energy decrease &lt;=&gt; temperature increase are dynamically linked together. So are their inverses: expansion &lt;=&gt; energy increase &lt;=&gt; temperature decrease. We exhibit these features by one classical particle in a suitable environment, and by many particles with purely attractive interactions. We then show how the ensuing negative heat capacity tames an explosive energy input.",
                    "score": 0.8447542786598206
                },
                {
                    "id": 20670446,
                    "contents": "Proton transfer at subkelvin temperatures.\nWe demonstrate a novel method to ionize molecules or molecular clusters by proton transfer at temperatures below 1 K. The method yields nascent ions and largely eliminates secondary reactions, even for notoriously 'delicate' molecules. Protonation is achieved inside liquid helium nanodroplets (HNDs) and begins with the formation of (H2)mH+ ions as the proton donors. In a separate and subsequent step the HNDs are doped with a proton acceptor molecule, X. Proton transfer occurs between X and the cold proton donor ions inside a helium droplet, an approach that avoids the large excess energy that is released if HNDs are first doped and then ionized. Mass spectra, recorded after stripping excess helium and hydrogen in a collision cell, show that this method offers a new way to determine proton affinities of molecules and clusters by proton-transfer bracketing, to investigate astrochemically relevant ion-molecule reactions at sub-kelvin temperatures, and to prepare XH+ ions that are suitable for messenger-tagging action spectroscopy.",
                    "score": 0.8443887233734131
                },
                {
                    "id": 3594433,
                    "contents": "A prognosis for the proton.\nTwo different hypotheses in modern physics according to which protons might disappear are discussed: Gravitational collapse of matter into black holes, and proton decay according to Unified Gauge Theories. The latter might soon be observed in experiments in which sensitive detectors are placed in a mass of 1000 tons of matter (10(33) protons) in a deep tunnel or mine. One hundred observed decays per year would correspond to an \"expected lifetime\" of 10(31) years for an individual proton, as predicted by these theories.",
                    "score": 0.8441011905670166
                },
                {
                    "id": 13650562,
                    "contents": "Comment on \"Trouble with the Lorentz law of force: incompatibility with special relativity and momentum conservation\".\nA Comment on the Letter by M. Mansuripur, Phys. Rev. Lett. 108, 193901 (2012). The authors of the Letter offer a Reply.",
                    "score": 0.8437929153442383
                },
                {
                    "id": 13650561,
                    "contents": "Comment on \"Trouble with the Lorentz law of force: incompatibility with special relativity and momentum conservation\".\nA Comment on the Letter by M. Mansuripur, Phys. Rev. Lett. 108, 193901 (2012). The authors of the Letter offer a Reply.",
                    "score": 0.8437929153442383
                },
                {
                    "id": 13650560,
                    "contents": "Comment on \"Trouble with the Lorentz law of force: incompatibility with special relativity and momentum conservation\".\nA Comment on the Letter by M. Mansuripur, Phys. Rev. Lett. 108, 193901 (2012). The authors of the Letter offer a Reply.",
                    "score": 0.8437929153442383
                },
                {
                    "id": 13650559,
                    "contents": "Comment on \"Trouble with the Lorentz law of force: incompatibility with special relativity and momentum conservation\".\nA comment on the letter by M. Mansuripur, Phys. Rev. Lett. 108, 193901 (2012). The authors of the letter offer a reply.",
                    "score": 0.8437929153442383
                },
                {
                    "id": 14197097,
                    "contents": "Is the proton radius a player in the redefinition of the International System of Units?\nIt is now recognized that the International System of Units (SI units) will be redefined in terms of fundamental constants, even if the date when this will occur is still under debate. Actually, the best estimate of fundamental constant values is given by a least-squares adjustment, carried out under the auspices of the Committee on Data for Science and Technology (CODATA) Task Group on Fundamental Constants. This adjustment provides a significant measure of the correctness and overall consistency of the basic theories and experimental methods of physics using the values of the constants obtained from widely differing experiments. The physical theories that underlie this adjustment are assumed to be valid, such as quantum electrodynamics (QED). Testing QED, one of the most precise theories is the aim of many accurate experiments. The calculations and the corresponding experiments can be carried out either on a boundless system, such as the electron magnetic moment anomaly, or on a bound system, such as atomic hydrogen. The value of fundamental constants can be deduced from the comparison of theory and experiment. For example, using QED calculations, the value of the fine structure constant given by the CODATA is mainly inferred from the measurement of the electron magnetic moment anomaly carried out by Gabrielse's group. (Hanneke et al. 2008 Phys. Rev. Lett. 100, 120801) The value of the Rydberg constant is known from two-photon spectroscopy of hydrogen combined with accurate theoretical quantities. The Rydberg constant, determined by the comparison of theory and experiment using atomic hydrogen, is known with a relative uncertainty of 6.6×10(-12). It is one of the most accurate fundamental constants to date. A careful analysis shows that knowledge of the electrical size of the proton is nowadays a limitation in this comparison. The aim of muonic hydrogen spectroscopy was to obtain an accurate value of the proton charge radius. However, the value deduced from this experiment contradicts other less accurate determinations. This problem is known as the proton radius puzzle. This new determination of the proton radius may affect the value of the Rydberg constant . This constant is related to many fundamental constants; in particular, links the two possible ways proposed for the redefinition of the kilogram, the Avogadro constant N(A) and the Planck constant h. However, the current relative uncertainty on the experimental determinations of N(A) or h is three orders of magnitude larger than the 'possible' shift of the Rydberg constant, which may be shown by the new value of the size of the proton radius determined from muonic hydrogen. The proton radius puzzle will not interfere in the redefinition of the kilogram. After a short introduction to the properties of the proton, we will describe the muonic hydrogen experiment. There is intense theoretical activity as a result of our observation. A brief summary of possible theoretical explanations at the date of writing of the paper will be given. The contribution of the proton radius puzzle to the redefinition of SI-based units will then be examined.",
                    "score": 0.8432825803756714
                },
                {
                    "id": 7796550,
                    "contents": "W values of protons in liquid water.\nThe W values of protons in liquid water were calculated for energies from 0.1 keV to 10 MeV using the continuous slowing down approximation as well as three models for the calculation of the differential ionisation cross-sections of water for protons published in recent years. The W values determined by means of the three models differ only marginally from each other and lie between 25 and 26 eV at proton energies &gt;5 MeV. This high-energy W value is approximately 3 eV lower than that in water vapour.",
                    "score": 0.842707097530365
                },
                {
                    "id": 5390086,
                    "contents": "Quantum distribution of protons in solid molecular hydrogen at megabar pressures\nSolid hydrogen, a simple system consisting only of protons and electrons, exhibits a variety of structural phase transitions at high pressures. Experimental studies based on static compression up to about 230 GPa revealed three relevant phases of solid molecular hydrogen: phase I (high-temperature, low-pressure phase), phase II (low-temperature phase) and phase III (high-pressure phase). Spectroscopic data suggest that symmetry breaking, possibly related to orientational ordering, accompanies the transition into phases II and III. The boundaries dividing the three phases exhibit a strong isotope effect, indicating that the quantum-mechanical properties of hydrogen nuclei are important. Here we report the quantum distributions of protons in the three phases of solid hydrogen, obtained by a first-principles path-integral molecular dynamics method. We show that quantum fluctuations of protons effectively hinder molecular rotation--that is, a quantum localization occurs. The obtained crystal structures have entirely different symmetries from those predicted by the conventional simulations which treat protons classically.",
                    "score": 0.8411303758621216
                },
                {
                    "id": 9571502,
                    "contents": "Physicists polish one model while looking to the next.\nBRUSSELS, BELGIUM-High-energy physicists' current explanation for the behavior of subatomic particles and forces, known as the Standard Model, is doing just fine. That was the take-home message for the 800 delegates who gathered here from 27 July to 2 August for the International Europhysics Conference on High-Energy Physics. \"Mainly this was a conference of consolidation, steady progress, many very beautiful and detailed results,\" Christopher Llewellyn Smith, director general of CERN, the European particle physics laboratory, told Science. But while a multitude of presentations described ever more accurate tests and confirmations of the model, physicists also discussed hints that a whole new range of phenomena beyond the Standard Model is lurking just above the energies of current accelerators-and within range of the next generation of experiments.",
                    "score": 0.8410431146621704
                },
                {
                    "id": 9661028,
                    "contents": "Protons and Electrons in Jupiter's Magnetic Field: Results from the University of Chicago Experiment on Pioneer 10.\nFluxes of high energy electrons and protons are found to be highly concentrated near the magnetic equatorial plane from distances of ~ 30 to ~ 100 Jovian radii (R(J)). The 10-hour period of planetary rotation is observed as an intensity variation, which indicates that the equatorial zone of high particle fluxes is inclined with respect to the rotation axis of the planet. At radial distances [unknown] 20 R(J) the synchrotron-radiation-producing electrons with energies greater, similar 3 million electron volts rise steeply to a maximum intensity of ~ 5 x 10(8) electrons per square centimeter per second near the periapsis at 2.8 R(J). The flux of protons with energies greater, similar 30 million electron volts reaches a maximum intensity of ~ 4 x 10(6) protons per square centimeter per second at ~ 3.5 R(J) with the intensity decreasing inside this radial distance. Only for radial distances [unknown] 20 R(J) does the radiation behave in a manner which is similar to that at the earth. Burst of electrons with energies up to 30 million electron volts, each lasting about 2 days, were observed in interplanetary space beginning approximately 1 month before encounter. This radiation appears to have escaped from the Jovian bow shock or magnetosphere.",
                    "score": 0.8405091166496277
                },
                {
                    "id": 11115957,
                    "contents": "Essay: fifty years of condensed matter physics.\nSince the birth of Physical Review Letters fifty years ago, condensed matter physics has seen considerable growth, and both the journal and the field have flourished during this period. In this essay, I begin with some general comments about condensed matter physics and then give some personal views on the conceptual development of the field and list some highlights. The focus is mostly on theoretical developments.",
                    "score": 0.8400746583938599
                },
                {
                    "id": 4722588,
                    "contents": "The maximum momentum transfer in proton-hydrogen collisions.\nThe upper limit of momentum transfer by a proton to K-shell electrons is calculated in a restricted three-body classical model.  The model shows that the infinite upper limit used in practice, is generally good except for low energy protons passing through an extremely rarefied gas.",
                    "score": 0.8399016857147217
                },
                {
                    "id": 8185309,
                    "contents": "Dynamics of a charged particle.\nUsing physical arguments, I derive the physically correct equations of motion for a classical charged particle from the Lorentz-Abraham-Dirac equations (LAD) which are well known to be physically incorrect. Since a charged particle can classically not be a point particle because of the Coulomb field divergence, my derivation allows for that by imposing a basic condition on the external force. That condition ensures that the particle's finite size charge distribution appears as a point charge to the external force. Finite radius charge distributions are known not to lead to differential equations of motion. The present work is in agreement with the results by [H. Spohn, Europhys. Lett. 50, 287 (2000)] and by others. An example, uniform acceleration, demonstrates what the above basic condition entails. For clarity of the argument, I discuss the nonrelativistic case before the relativistic one.",
                    "score": 0.8397939801216125
                },
                {
                    "id": 22247840,
                    "contents": "There Is No Spooky Action at a Distance in Quantum Mechanics.\nEinstein became bothered by quantum mechanical action at a distance within two years of Schrödinger's introduction of his eponymous wave equation. If the wave function represents the \"real\" physical state of a particle, then the measurement of the particle's position would result in the instantaneous collapse of the wave function to the single, measured position. Such a process seemingly violates not only the Schrödinger equation but also special relativity. Einstein was not alone in this vexation; however, the dilemma eventually faded as physicists concentrated on using the Schrödinger equation to solve a plethora of pressing problems. For the next 30 years, wave function collapse, while occasionally discussed by physicists, was primarily a topic of interest for philosophers. That is, until 1964, when Bell introduced his famous inequality and maintained that its violation proved that quantum mechanics and, by implication, nature herself are nonlocal. Unfortunately, this brought the topic back to mainstream physics, where it has remained and continues to muddy the waters. To be sure, not all physicists are bothered by the apparent nonlocality of quantum mechanics. So where have those who embrace quantum nonlocality gone wrong? I argue that the answer is a gratuitous belief in the ontic nature of the quantum state.",
                    "score": 0.8397795557975769
                },
                {
                    "id": 8727599,
                    "contents": "Stiff stability of the hydrogen atom in dissipative Fokker electrodynamics.\nWe introduce an ad hoc electrodynamics with advanced and retarded Liénard-Wiechert interactions plus the dissipative Lorentz-Dirac self-interaction force. We study the covariant dynamical system of the electromagnetic two-body problem, i.e., the hydrogen atom. We perform the linear stability analysis of circular orbits for oscillations perpendicular to the orbital plane. In particular, we study the normal modes of the linearized dynamics that have an arbitrarily large imaginary eigenvalue. These large eigenvalues are fast frequencies that introduce a fast (stiff) time scale into the dynamics. As an application, we study the phenomenon of resonant dissipation, i.e., a motion where both particles recoil together in a drifting circular orbit (a bound state), while the atom dissipates center-of-mass energy only. This balancing of the stiff dynamics is established by the existence of a quartic resonant constant that locks the dynamics to the neighborhood of the recoiling circular orbit. The resonance condition quantizes the angular momenta in reasonable agreement with the Bohr atom. The principal result is that the emission lines of quantum electrodynamics agree with the prediction of our resonance condition within 1% average deviation.",
                    "score": 0.8397680521011353
                },
                {
                    "id": 8185085,
                    "contents": "Positive and negative effective mass of classical particles in oscillatory and static fields.\nA classical particle oscillating in an arbitrary high-frequency or static field effectively exhibits a modified rest mass m(eff) derived from the particle averaged Lagrangian. Relativistic ponderomotive and diamagnetic forces, as well as magnetic drifts, are obtained from the m(eff) dependence on the guiding center location and velocity. The effective mass is not necessarily positive and can result in backward acceleration when an additional perturbation force is applied. As an example, adiabatic dynamics with m||&gt;0 and m||&lt;0 is demonstrated for a wave-driven particle along a dc magnetic field, m|| being the effective longitudinal mass derived from m(eff). Multiple energy states are realized in this case, yielding up to three branches of m|| for a given magnetic moment and parallel velocity.",
                    "score": 0.8394687175750732
                },
                {
                    "id": 14213595,
                    "contents": "Momentum transfer in nonequilibrium steady states.\nWhen a Brownian object interacts with noninteracting gas particles under nonequilibrium conditions, energy dissipation associated with Brownian motion causes an additional force on the object as a \"momentum transfer deficit.\" This principle is demonstrated first by a new nonequilibrium steady state model and then applied to several known models such as an adiabatic piston for which a simple explanation has been lacking.",
                    "score": 0.8390072584152222
                },
                {
                    "id": 9146709,
                    "contents": "Quasiresonance: switching internal energy transfer on and off.\nQuasiresonance involves a slow \"external\" switching on and off of an interaction between internal degrees of freedom described by action-angle variables having approximate resonances. The resonances or near-resonances spawn slow coordinates that fail to be adiabatic, but the remaining coordinates may be fast enough to have conserved actions. The interaction either can be imposed externally as a time dependent coupling or can arise autonomously due to interactions with other degrees of freedom. A resonance transformation into slow and fast angles reveals the action corresponding to the fast angle is adiabatic and conserved to very high accuracy. This paper extends our work on quasiresonance to new systems and regimes, including the He-H2 system, collisions with a periodic lattice, perturbative interactions, and discussion of quasiresonance in higher dimensional systems.",
                    "score": 0.8387320041656494
                },
                {
                    "id": 20436548,
                    "contents": "Quantum Mechanics and Its Evolving Formulations.\nIn this paper, we discuss the time evolution of the quantum mechanics formalism. Starting from the heroic beginnings of Heisenberg and Schrödinger, we cover successively the rigorous Hilbert space formulation of von Neumann, the practical bra-ket formalism of Dirac, and the more recent rigged Hilbert space approach.",
                    "score": 0.8386591672897339
                },
                {
                    "id": 9667893,
                    "contents": "One hundred years of quantum physics.\nThis year marks the 100th anniversary of Max Planck's creation of the quantum concept, an idea so revolutionary that it took nearly 30 years for scientists to develop it into the theory that has transformed the way scientists view reality. In this month's essay, Daniel Kleppner and Roman Jackiw recount how quantum theory, which they rate as \"the most precisely tested and most successful theory in the history of science,\" came to be, how it changed the world, and how it might continue to evolve to make the dream of ultimate understanding of the universe come true.",
                    "score": 0.8385693430900574
                },
                {
                    "id": 10960933,
                    "contents": "Dissipative quantum systems and the heat capacity.\nWe present a detailed study of the quantum dissipative dynamics of a charged particle in a magnetic field. Our focus of attention is the effect of dissipation on the low- and high-temperature behaviors of the specific heat at constant volume. After providing a brief overview of two distinct approaches to the statistical mechanics of dissipative quantum systems, viz., the ensemble approach of Gibbs and the quantum Brownian motion approach due to Einstein, we present exact analyses of the specific heat. While the low-temperature expressions for the specific heat, based on the two approaches, are in conformity with power-law temperature dependence, predicted by the third law of thermodynamics, and the high-temperature expressions are in agreement with the classical equipartition theorem, there are surprising differences between the dependencies of the specific heat on different parameters in the theory, when calculations are done from these two distinct methods. In particular, we find puzzling influences of boundary confinement and the bath-induced spectral cutoff frequency. Further, when it comes to the issue of approach to equilibrium, based on the Einstein method, the way the asymptotic limit (t--&gt;infinity) is taken seems to assume significance.",
                    "score": 0.8380461931228638
                },
                {
                    "id": 16018592,
                    "contents": "Efimov physics: a review.\nThis article reviews theoretical and experimental advances in Efimov physics, an array of quantum few-body and many-body phenomena arising for particles interacting via short-range resonant interactions, that is based on the appearance of a scale-invariant three-body attraction theoretically discovered by Vitaly Efimov in 1970. This three-body effect was originally proposed to explain the binding of nuclei such as the triton and the Hoyle state of carbon-12, and later considered as a simple explanation for the existence of some halo nuclei. It was subsequently evidenced in trapped ultra-cold atomic clouds and in diffracted molecular beams of gaseous helium. These experiments revealed that the previously undetermined three-body parameter introduced in the Efimov theory to stabilise the three-body attraction typically scales with the range of atomic interactions. The few- and many-body consequences of the Efimov attraction have been since investigated theoretically, and are expected to be observed in a broader spectrum of physical systems.",
                    "score": 0.838032066822052
                },
                {
                    "id": 9097896,
                    "contents": "Gyroresonant surfing acceleration.\nWe discuss a new acceleration or energization mechanism of charged particles in space and astrophysical plasmas. In the presence of an electrostatic potential gradient and a circularly polarized electromagnetic monochromatic wave, particles are accelerated efficiently by keeping cyclotron resonance with the wave due to the electrostatic dragging force. In addition, particles can propagate against the electrostatic potential even if they have smaller parallel energy. This mechanism is potentially widely applicable, in terms of particle acceleration and transport, to various space and astrophysical phenomena, such as shock environment and short-large amplitude magnetic structures. We introduce the basic physical process of the acceleration or energization mechanism theoretically and numerically.",
                    "score": 0.8377572298049927
                },
                {
                    "id": 6330380,
                    "contents": "Casimir light: pieces of the action.\nMore realistic dynamics for the collapsing dielectric fluid are introduced in stages by adding contributions to the Lagrangian that forms the action. The elements are kinetic energy, Casimir potential energy, air pressure potential energy, and electromagnetic coupling to the moving dielectric. There are successful tests of partial collapse time and of minimum radius.",
                    "score": 0.8371212482452393
                },
                {
                    "id": 10611872,
                    "contents": "On the unreasonable effectiveness of the post-Newtonian approximation in gravitational physics.\nThe post-Newtonian approximation is a method for solving Einstein's field equations for physical systems in which motions are slow compared to the speed of light and where gravitational fields are weak. Yet it has proven to be remarkably effective in describing certain strong-field, fast-motion systems, including binary pulsars containing dense neutron stars and binary black hole systems inspiraling toward a final merger. The reasons for this effectiveness are largely unknown. When carried to high orders in the post-Newtonian sequence, predictions for the gravitational-wave signal from inspiraling compact binaries will play a key role in gravitational-wave detection by laser-interferometric observatories.",
                    "score": 0.8370363712310791
                },
                {
                    "id": 7746868,
                    "contents": "Thermal equilibrium and statistical thermometers in special relativity.\nThere is an intense debate in the recent literature about the correct generalization of Maxwell's velocity distribution in special relativity. The most frequently discussed candidate distributions include the Jüttner function as well as modifications thereof. Here we report results from fully relativistic one-dimensional molecular dynamics simulations that resolve the ambiguity. The numerical evidence unequivocally favors the Jüttner distribution. Moreover, our simulations illustrate that the concept of \"thermal equilibrium\" extends naturally to special relativity only if a many-particle system is spatially confined. They make evident that \"temperature\" can be statistically defined and measured in an observer frame independent way.",
                    "score": 0.8369609713554382
                },
                {
                    "id": 15687851,
                    "contents": "Is the angular momentum of an electron conserved in a uniform magnetic field?\nWe show that an electron moving in a uniform magnetic field possesses a time-varying \"diamagnetic\" angular momentum. Surprisingly this means that the kinetic angular momentum of the electron may vary with time, despite the rotational symmetry of the system. This apparent violation of angular momentum conservation is resolved by including the angular momentum of the surrounding fields. ",
                    "score": 0.8368289470672607
                },
                {
                    "id": 14095507,
                    "contents": "Efficient first-principles calculation of the quantum kinetic energy and momentum distribution of nuclei.\nLight nuclei at room temperature and below exhibit a kinetic energy which significantly deviates from the predictions of classical statistical mechanics. This quantum kinetic energy is responsible for a wide variety of isotope effects of interest in fields ranging from chemistry to climatology. It also furnishes the second moment of the nuclear momentum distribution, which contains subtle information about the chemical environment and has recently become accessible to deep inelastic neutron scattering experiments. Here, we show how, by combining imaginary time path integral dynamics with a carefully designed generalized Langevin equation, it is possible to dramatically reduce the expense of computing the quantum kinetic energy. We also introduce a transient anisotropic Gaussian approximation to the nuclear momentum distribution which can be calculated with negligible additional effort. As an example, we evaluate the structural properties, the quantum kinetic energy, and the nuclear momentum distribution for a first-principles simulation of liquid water.",
                    "score": 0.836381196975708
                },
                {
                    "id": 10961540,
                    "contents": "Biological proton pumping in an oscillating electric field.\nTime-dependent external perturbations provide powerful probes of the function of molecular machines. Here we study biological proton pumping in an oscillating electric field. The protein cytochrome c oxidase is the main energy transducer in aerobic life, converting chemical energy into an electric potential by pumping protons across a membrane. With the help of master-equation descriptions that recover the key thermodynamic and kinetic properties of this biological \"fuel cell,\" we show that the proton pumping efficiency and the electronic currents in steady state depend significantly on the frequency and amplitude of the applied field, allowing us to distinguish between different microscopic mechanisms of the machine. A spectral analysis reveals dominant reaction steps consistent with an electron-gated pumping mechanism.",
                    "score": 0.8363463282585144
                },
                {
                    "id": 21185230,
                    "contents": "On conservation laws in quantum mechanics.\nWe raise fundamental questions about the very meaning of conservation laws in quantum mechanics, and we argue that the standard way of defining conservation laws, while perfectly valid as far as it goes, misses essential features of nature and has to be revisited and extended.",
                    "score": 0.8361387252807617
                },
                {
                    "id": 8242448,
                    "contents": "Thermodynamics of an ideal generalized gas: I. Thermodynamic laws.\nThe equations of state for an ideal relativistic, or generalized, gas, like an ideal quantum gas, are expressed in terms of power laws of the temperature. In contrast to an ideal classical gas, the internal energy is a function of volume at constant temperature, implying that the ideal generalized gas will show either attractive or repulsive interactions. This is a necessary condition in order that the third law be obeyed and for matter to have an electromagnetic origin. The transition from an ideal generalized to a classical gas occurs when the two independent solutions of the subsidiary equation to Lagrange's equation coalesce. The equation of state relating the pressure to the internal energy encompasses the full range of cosmological scenarios, from the radiation to the matter dominated universes and finally to the vacuum energy, enabling the coefficient of proportionality, analogous to the Grüeisen ratio, to be interpreted in terms of the degrees of freedom related to the temperature exponents of the internal energy and the absolute temperature expressed in terms of a power of the empirical temperature. The limit where these exponents merge is shown to be the ideal classical gas limit. A corollary to Carnot's theorem is proved, asserting that the ratio of the work done over a cycle to the heat absorbed to increase the temperature at constant volume is the same for all bodies at the same volume. As power means, the energy and entropy are incomparable, and a new adiabatic potential is introduced by showing that the volume raised to a characteristic exponent is also the integrating factor for the quantity of heat so that the second law can be based on the property that power means are monotonically increasing functions of their order. The vanishing of the chemical potential in extensive systems implies that energy cannot be transported without matter and is equivalent to the condition that Clapeyron's equation be satisfied.",
                    "score": 0.8361150026321411
                },
                {
                    "id": 8616642,
                    "contents": "Equations-of-motion approach to quantum mechanics: application to a model phase transition.\nWe present a generalized equations-of-motion method that efficiently calculates energy spectra and matrix elements for algebraic models. The method is applied to a five-dimensional quartic oscillator that exhibits a quantum phase transition between vibrational and rotational phases. For certain parameters, 10 x 10 matrices give better results than obtained by diagonalizing 1000 x 1000 matrices.",
                    "score": 0.8360791802406311
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_8",
        "question": "Example 5-3 shows that a Maclaurin expansion of a Morse potential leads to\r\n$$\r\nV(x)=D \\beta^2 x^2+\\cdots\r\n$$\r\nGiven that $D=7.31 \\times 10^{-19} \\mathrm{~J} \\cdot$ molecule ${ }^{-1}$ and $\\beta=1.81 \\times 10^{10} \\mathrm{~m}^{-1}$ for $\\mathrm{HCl}$, calculate the force constant of $\\mathrm{HCl}$.",
        "golden_answers": [
            " 479"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 4411818,
                    "contents": "Modified Morse Potential for Diatomic Molecules.\nWe present a diatomic potential which closely resembles the standard Morse function but incorporates additional flexibility for fitting experimental vibrational energy-gap data. This flexibility is accommodated by introducing a continuously variable radially dependent change in the exponent of the Morse function, which in practice is adequately realized via a relatively small number of constant parameters. As an illustration, the method is applied to calculate the quantum vibrational levels of the X1Sigma+&lt;INF POS=\"STACK\"&gt;g ground electronic state of the N2 molecule. Copyright 1998 Academic Press.",
                    "score": 0.9033535718917847
                },
                {
                    "id": 2177174,
                    "contents": "A modification to the COSMIC parameterisation using ab initio constrained potential functions.\nThe H..H non-bonded potential employed in the current COSMIC force field has been contrasted with H..H potentials used in a number of other force fields. Initial conversion of the variety of functions to a Morse format, achieved using a simple graphical fitting procedure, allowed a direct comparison to be made, showing the COSMIC potential to differ considerably from the other potentials. This difference was reflected in the failure of COSMIC to reproduce ab initio and experimental energies for molecules with significant H..H interactions, with particular reference to the energy curves of benzophenone and diphenyl ether. Considerable improvement in these energies is produced by the use of a Morse function originally based on the H..H potential used in MM3.",
                    "score": 0.8898162841796875
                },
                {
                    "id": 16990884,
                    "contents": "Morse, Lennard-Jones, and Kratzer Potentials: A Canonical Perspective with Applications.\nCanonical approaches are applied to classic Morse, Lennard-Jones, and Kratzer potentials. Using the canonical transformation generated for the Morse potential as a reference, inverse transformations allow the accurate generation of the Born-Oppenheimer potential for the H<sub2</sub<sup+</sup ion, neutral covalently bound H<sub2</sub, van der Waals bound Ar<sub2</sub, and the hydrogen bonded one-dimensional dissociative coordinate in a water dimer. Similar transformations are also generated using the Lennard-Jones and Kratzer potentials as references. Following application of inverse transformations, vibrational eigenvalues generated from the Born-Oppenheimer potentials give significantly improved quantitative comparison with values determined from the original accurately known potentials. In addition, an algorithmic strategy based upon a canonical transformation to the dimensionless form applied to the force distribution associated with a potential is presented. The resulting canonical force distribution is employed to construct an algorithm for deriving accurate estimates for the dissociation energy, the maximum attractive force, and the internuclear separations corresponding to the maximum attractive force and the potential well.",
                    "score": 0.8841136693954468
                },
                {
                    "id": 22381144,
                    "contents": "Vibrational levels of a generalized Morse potential.\nA Generalized Morse Potential (GMP) is an extension of the Morse Potential (MP) with an additional exponential term and an additional parameter that compensate for MP's erroneous behavior in the long range part of the interaction potential. Because of the additional term and parameter, the vibrational levels of the GMP cannot be solved analytically, unlike the case for the MP. We present several numerical approaches for solving the vibrational problem of the GMP based on Galerkin methods, namely, the Laguerre Polynomial Method (LPM), the Symmetrized LPM, and the Polynomial Expansion Method (PEM), and apply them to the vibrational levels of the homonuclear diatomic molecules B<sub2</sub, O<sub2</sub, and F<sub2</sub, for which high level theoretical near full configuration interaction (CI) electronic ground state potential energy surfaces and experimentally measured vibrational levels have been reported. Overall, the LPM produces vibrational states for the GMP that are converged to within spectroscopic accuracy of 0.01 cm<sup-1</sup in between 1 and 2 orders of magnitude faster and with much fewer basis functions/grid points than the Colbert-Miller Discrete Variable Representation (CN-DVR) method for the three homonuclear diatomic molecules examined in this study. A Python library that fits and solves the GMP and similar potentials can be downloaded from https://gitlab.com/gds001uw/generalized-morse-solver.",
                    "score": 0.8732380867004395
                },
                {
                    "id": 16385195,
                    "contents": "Universal scaling of potential energy functions describing intermolecular interactions. I. Foundations and scalable forms of new generalized Mie, Lennard-Jones, Morse, and Buckingham exponential-6 potentials.\nBased on the formulation of the analytical expression of the potential V(r) describing intermolecular interactions in terms of the dimensionless variables r* = r/r(m) and ɛ* = V/ɛ, where r(m) is the separation at the minimum and ɛ the well depth, we propose more generalized scalable forms for the commonly used Mie, Lennard-Jones, Morse, and Buckingham exponential-6 potential energy functions. These new generalized forms have an additional parameter from the original forms and revert to the original ones for some choice of that parameter. In this respect, the original forms of those potentials can be considered as special cases of the more general forms that are introduced. We also propose a scalable, non-revertible to the original one, 4-parameter extended Morse potential.",
                    "score": 0.8701092004776001
                },
                {
                    "id": 7748825,
                    "contents": "An optimized algebraic basis for molecular potentials.\nThe computation of vibrational spectra of diatomic molecules through the exact diagonalization of algebraically determined matrices based on powers of Morse coordinates is made substantially more efficient by choosing a properly adapted quantum mechanical basis, specifically tuned to the molecular potential. A substantial improvement is achieved while still retaining the full advantage of the simplicity and numerical light-weightedness of an algebraic approach. In the scheme we propose, the basis is parametrized by two quantities which can be adjusted to best suit the molecular potential through a simple minimization procedure.",
                    "score": 0.8696095943450928
                },
                {
                    "id": 7497634,
                    "contents": "Modified Morse potential for unification of the pair interactions.\nWe designed a novel model potential that unifies the pair interactions including the well known Morse and Lennard-Jones potentials. Using two parameters, the interactions at the minimum, short range, and long range of the new model potential can be controlled separately, so the potential is very flexible to fit various systems. It is found that for potentials with similar range with the Lennard-Jones potential at the minimum, due to the difference at the short and long ranges, the favorite structures can be very different, and some previously unknown magic numbers are located.",
                    "score": 0.8685629367828369
                },
                {
                    "id": 9056912,
                    "contents": "Computational method for the quantum Hamilton-Jacobi equation: bound states in one dimension.\nAn accurate computational method for the one-dimensional quantum Hamilton-Jacobi equation is presented. The Mobius propagation scheme, which can accurately pass through singularities, is used to numerically integrate the quantum Hamilton-Jacobi equation for the quantum momentum function. Bound state wave functions are then synthesized from the phase integral using the antithetic cancellation technique. Through this procedure, not only the quantum momentum functions but also the wave functions are accurately obtained. This computational approach is demonstrated through two solvable examples: the harmonic oscillator and the Morse potential. The excellent agreement between the computational and the exact analytical results shows that the method proposed here may be useful for solving similar quantum mechanical problems.",
                    "score": 0.8675632476806641
                },
                {
                    "id": 8075165,
                    "contents": "Efficient computation of Morse-Smale complexes for three-dimensional scalar functions.\nThe Morse-Smale complex is an efficient representation of the gradient behavior of a scalar function, and critical points paired by the complex identify topological features and their importance. We present an algorithm that constructs the Morse-Smale complex in a series of sweeps through the data, identifying various components of the complex in a consistent manner. All components of the complex, both geometric and topological, are computed, providing a complete decomposition of the domain. Efficiency is maintained by representing the geometry of the complex in terms of point sets.",
                    "score": 0.8658564686775208
                },
                {
                    "id": 17946607,
                    "contents": "Anharmonic vibrational eigenfunctions and infrared spectra from semiclassical molecular dynamics.\nWe describe a new approach based on semiclassical molecular dynamics that allows simulating infrared absorption or emission spectra of molecular systems with inclusion of anharmonic intensities. This is achieved from semiclassical power spectra by computing first the vibrational eigenfunctions as a linear combination of harmonic states, and then the oscillator strengths associated with the vibrational transitions. We test the approach against a 1D Morse potential and apply it to the water molecule with results in excellent agreement with discrete variable representation quantum benchmarks. The method does not require any grid calculations, and it is directly extendable to high dimensional systems. The usual exponential scaling of the basis set size with the dimensionality of the system can be avoided by means of an appropriate truncation scheme. Furthermore, the approach has the advantage to provide IR spectra beyond the harmonic approximation without losing the possibility of an intuitive assignment of absorption peaks in terms of normal modes of vibration.",
                    "score": 0.8633750677108765
                },
                {
                    "id": 13571803,
                    "contents": "Equivalence of the Wei potential model and Tietz potential model for diatomic molecules.\nBy employing the dissociation energy and the equilibrium bond length for a diatomic molecule as explicit parameters, we generate improved expressions for the well-known Rosen-Morse, Manning-Rosen, Tietz, and Frost-Musulin potential energy functions. It is found that the well-known Tietz potential function that is conventionally defined in terms of five parameters [T. Tietz, J. Chem. Phys. 38, 3036 (1963)] actually only has four independent parameters. It is shown exactly that the Wei [Phys. Rev. A 42, 2524 (1990)] and the well-known Tietz potential functions are the same solvable empirical function. When the parameter h in the Tietz potential function has the values 0, +1, and -1, the Tietz potential becomes the standard Morse, Rosen-Morse, and Manning-Rosen potentials, respectively.",
                    "score": 0.8607532978057861
                },
                {
                    "id": 10666309,
                    "contents": "Formation of Schrödinger-cat states in the Morse potential: Wigner function picture.\nWe investigate the time evolution of Morse coherent states in the potential of the NO molecule. We present animated wave functions and Wigner functions of the system exhibiting spontaneous formation of Schrödinger-cat states at certain stages of the time evolution. These nonclassical states are coherent superpositions of two localized states corresponding to two di.erent positions of the center of mass. We analyze the degree of nonclassicality as the function of the expectation value of the position in the initial state. Our numerical calculations are based on a novel, essentially algebraic treatment of the Morse potential.",
                    "score": 0.8603219985961914
                },
                {
                    "id": 18331342,
                    "contents": "The topology of the Coulomb potential density. A comparison with the electron density, the virial energy density, and the Ehrenfest force density.\nThe topology of the Coulomb potential density has been studied within the context of the theory of Atoms in Molecules and has been compared with the topologies of the electron density, the virial energy density and the Ehrenfest force density. The Coulomb potential density is found to be mainly structurally homeomorphic with the electron density. The Coulomb potential density reproduces the non-nuclear attractor which is observed experimentally in the molecular graph of the electron density of a Mg dimer, thus, for the first time ever providing an alternative and energetic foundation for the existence of this critical point. © 2017 Wiley Periodicals, Inc.",
                    "score": 0.8586229681968689
                },
                {
                    "id": 10539692,
                    "contents": "Analytic dynamics of the Morse oscillator derived by semiclassical closures.\nThe quantized Hamilton dynamics methodology [O. V. Prezhdo and Y. V. Pereverzev, J. Chem. Phys. 113, 6557 (2000)] is applied to the dynamics of the Morse potential using the SU(2) ladder operators. A number of closed analytic approximations are derived in the Heisenberg representation by performing semiclassical closures and using both exact and approximate correspondence between the ladder and position-momentum variables. In particular, analytic solutions are given for the exact classical dynamics of the Morse potential as well as a second-order semiclassical approximation to the quantum dynamics. The analytic approximations are illustrated with the O-H stretch of water and a Xe-Xe dimer. The results are extended further to coupled Morse oscillators representing a linear triatomic molecule. The reported analytic expressions can be used to accelerate classical molecular dynamics simulations of systems containing Morse interactions and to capture quantum-mechanical effects.",
                    "score": 0.8553211688995361
                },
                {
                    "id": 8500962,
                    "contents": "Ab initio global potential-energy surface for H5(+) --&gt; H3(+) + H2.\nAn accurate global potential-energy surface (PES) is reported for H5(+) based on more than 100,000 CCSD(T)/aug-cc-pVTZ ab initio energies. This PES has full permutational symmetry with respect to interchange of H atoms and dissociates to H3(+) and H2. Ten known stationary points of H5(+) are characterized and compared to previous ab initio calculations. Quantum diffusion Monte Carlo calculations are performed on the PES to obtain the zero-point energy of H5(+) and the anharmonic dissociation energy (D0) of H5(+) --&gt; H3(+) + H2. The rigorous zero-point state of H4D+ is also calculated and discussed within the context of a strictly classical approach to obtain the branching ratio of the reaction H4D+ --&gt; H3(+) + HD and H2D+ + H2. Such an approach is taken using the PES and critiqued based on the properties of the quantum zero-point state. Finally, a simple procedure for adding the long range-interaction energy is described.",
                    "score": 0.8544849157333374
                },
                {
                    "id": 19014961,
                    "contents": "Matrix elements for anharmonic potentials: Application to I<sub>2</sub> morse oscillator.\nMany authors have contributed expressions for obtaining analytical matrix elements for Morse oscillators. In this work, we discuss the advantages of using these expressions. At the same time, we propose a full numerical method to calculate these matrix elements and we compare, for the I<sub2</sub system, the different results given by Gallas, Vasan, and Cross, and the variational method.",
                    "score": 0.8536117672920227
                },
                {
                    "id": 23761816,
                    "contents": "The <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mml:mi>γ</mml:mi></mml:math> function in quantum theory II. Mathematical challenges and paradoxa.\nWhile the square root of Dirac's <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miδ</mml:mi</mml:math is not defined in any standard mathematical formalism, postulating its existence with some further assumptions defines a generalized function called <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:miγ</mml:mi <mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo)</mml:mo</mml:mrow </mml:math which permits a quasi-classical treatment of simple systems like the H atom or the 1D harmonic oscillator for which accurate quantum mechanical energies were previously reported. The so-defined <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:miγ</mml:mi <mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo)</mml:mo</mml:mrow </mml:math is neither a traditional function nor a distribution, and it remains to be seen that any consistent mathematical approaches can be set up to deal with it rigorously. A straightforward use of <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:miγ</mml:mi <mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo)</mml:mo</mml:mrow </mml:math generates several paradoxical situations which are collected here. The help of the scientific community is sought to resolve these paradoxa.",
                    "score": 0.8532646894454956
                },
                {
                    "id": 9290082,
                    "contents": "A semiclassical study of wave packet dynamics in anharmonic potentials.\nClassical and semiclassical methods are developed to calculate and invert the wave packet motion measured in pump-probe experiments. With classical propagation of the Wigner distribution of the initial wave packet created by the pump pulse, we predict the approximate probe signal with slightly displaced recurrence peaks, and derive a set of first-order canonical perturbation expressions to relate the temporal features of the signal to the characteristics of the potential surface. A reduced dynamics scheme based on the Gaussian assumption leads to the correct center of mass motion but does not describe the evolution of the shape of the wave packet accurately. To incorporate the quantum interference into classical trajectories, we propose a final-value representation semiclassical method, specifically designed for the purpose of computing pump-probe signals, and demonstrate its efficiency and accuracy with a Morse oscillator and two kinetically coupled Morse oscillators. For the case of one-color pump probe, a simple phase-space quantization scheme is devised to reproduce the temporal profile at the left-turning point without actual wave packet propagation, revealing a quantum mechanical perspective of the nearly classical pump-probe signal.",
                    "score": 0.8528876304626465
                },
                {
                    "id": 5249715,
                    "contents": "Exact equilibrium statistical mechanics of two particles interacting via Lennard-Jones and Morse potentials.\nThe exact classical statistical phase-space volume is obtained for a finite system consisting of two particles interacting via both Lennard-Jones and Morse potentials and confined in a spherical volume. The case when the center of mass of the system is fixed at the center of the sphere is also considered. It is shown that the microcanonical caloric curve of the system can have properties similar to those of large clusters, and the equation of state of the system can have behavior similar to that of bulk systems. It is also shown that the fixing of the center of mass of the system can appreciably change the properties of the microcanonical caloric curve and the equation of state of the system.",
                    "score": 0.8525858521461487
                },
                {
                    "id": 9050245,
                    "contents": "The Morse oscillator under time-dependent external fields.\nA method to solve the equations for the Morse oscillator under intense time-dependent external fields is presented. Exact analytical formulas for the dipole matrix elements are calculated by the use of the hypergeometric algebra. The continuum is described by an expansion using Laguerre functions. The full algorithm for the calculation of wave functions can be controlled by the convergence of series and by the errors of a first order integration method. We apply our technique to the selective preparation of high overtones by femtosecond laser pulses. The population of the target state is optimized as a function of the intensity and frequency. Introducing a second simultaneous laser, we study the effects of relative frequency and phase over the target state population and dissociation channels. The calculations exhibit a rich interference pattern showing the enhancement and the suppression of the target population by varying the laser parameters.",
                    "score": 0.8520163893699646
                },
                {
                    "id": 20452362,
                    "contents": "Systematic Generation of the Dunham Coefficients Using Symbolic Mathematics Software.\nThe Dunham coefficients are an indispensable part of the analysis of the ro-vibrational spectrum of a diatomic molecule. They provide a direct connection between the ro-vibrational states observed and the interatomic potential that must exist in the molecule. One may deduce the interatomic potential from the spectrum or, alternatively, predict the spectrum from a theoretically generated interatomic potential. The coefficients result from a mathematical analysis of the Schrödinger equation for such a system. Dunham's derivation relied on the WKB approximation and, as such, was subject to the associated limitations. In this paper, the quantum condition is derived without any reliance on the WKB approximation, using only principles of complex analysis. This sidesteps the need for introducing an approximate function to join solutions and suggests that the expansion has a more fundamental basis. Also in this paper, a mathematical algorithm for generating the Dunham coefficients is elaborated in detail. Careful attention is paid to keeping these coefficients accurate to a specified order in the smallness parameter, τ<sub<ie</i</sub = <iB</i<sub<ie</i</sub/ω<sub<ie</i</sub. This algorithm is intended to be presented in a way that makes it amenable to incorporation into computer code and points where the efficiency can be improved are indicated. Coefficients have been generated and presented in the literature through the years. The current paper presents the coefficients explicitly to tenth order in the smallness parameter, far more than have been generated in any previous work.",
                    "score": 0.8516727685928345
                },
                {
                    "id": 11580199,
                    "contents": "Global minimum structures and structural phase diagrams of modified Morse clusters: 11 ≤ N ≤ 30.\nThe energetically favored structures of clusters are determined by the interactions among particles. Using the modified Morse pair potential, which has two parameters that can freely control the interactions at the minimum, short range, and long range, we systematically investigated how the interactions determines the global minimum structures of clusters and gave the structural phase diagram at 0 K for each cluster size at the range 11 ≤ N ≤ 30. Compared to the Morse potential, a number of new structures are found, and some of them are unexpected. The global minimum structures of modified Morse clusters can act as structural bank, which will be helpful in the optimization of certain real clusters.",
                    "score": 0.8514459729194641
                },
                {
                    "id": 21888161,
                    "contents": "From canyons to valleys: Numerically continuing sticky-hard-sphere clusters to the landscapes of smoother potentials.\nWe study the energy landscapes of particles with short-range attractive interactions as the range of the interactions increases. Starting with the set of local minima for 6≤N≤12 hard spheres that are \"sticky,\" i.e., they interact only when their surfaces are exactly in contact, we use numerical continuation to evolve the local minima (clusters) as the range of the potential increases, using both the Lennard-Jones and Morse families of interaction potentials. As the range increases, clusters merge, until at long ranges only one or two clusters are left. We compare clusters obtained by continuation with different potentials and find that for short and medium ranges, up to about 30% of particle diameter, the continued clusters are nearly identical, both within and across families of potentials. For longer ranges, the clusters vary significantly, with more variation between families of potentials than within a family. We analyze the mechanisms behind the merge events and find that most rearrangements occur when a pair of nonbonded particles comes within the range of the potential. An exception occurs for nonharmonic clusters, i.e., those that have a zero eigenvalue in their Hessian, which undergo a more global rearrangement.",
                    "score": 0.8514397144317627
                },
                {
                    "id": 11464714,
                    "contents": "Accurate potential energy surface for the 1(2)A' state of NH(2): scaling of external correlation versus extrapolation to the complete basis set limit.\nAn accurate single-sheeted double many-body expansion potential energy surface is reported for the title system which is suitable for dynamics and kinetics studies of the reactions of N(2D) + H2(X1Sigmag+) NH(a1Delta) + H(2S) and their isotopomeric variants. It is obtained by fitting ab initio energies calculated at the multireference configuration interaction level with the aug-cc-pVQZ basis set, after slightly correcting semiempirically the dynamical correlation using the double many-body expansion-scaled external correlation method. The function so obtained is compared in detail with a potential energy surface of the same family obtained by extrapolating the calculated raw energies to the complete basis set limit. The topographical features of the novel global potential energy surface are examined in detail and found to be in general good agreement with those calculated directly from the raw ab initio energies, as well as previous calculations available in the literature. The novel function has been built so as to become degenerate at linear geometries with the ground-state potential energy surface of A'' symmetry reported by our group, where both form a Renner-Teller pair.",
                    "score": 0.8500317335128784
                },
                {
                    "id": 5644518,
                    "contents": "A computationally efficient alternative to the Buckingham potential for molecular mechanics calculations.\nThis paper describes a (6-8) variant of the Lennard-Jones (6-12) potential, for computing the energy of non-bonded interactions in molecular mechanics calculations, which combines the overall precision of the Buckingham (6-exp) potential with the computational efficiency of the standard Lennard-Jones (6-12) potential. There is also a note on the radius of convergence of the full matrix Newton-Raphson optimization procedure.",
                    "score": 0.8498642444610596
                },
                {
                    "id": 13906081,
                    "contents": "Full-dimensional (15-dimensional) ab initio analytical potential energy surface for the H7+ cluster.\nFull-dimensional ab initio potential energy surface is constructed for the H(7)(+) cluster. The surface is a fit to roughly 160,000 interaction energies obtained with second-order MöllerPlesset perturbation theory and the cc-pVQZ basis set, using the invariant polynomial method [B. J. Braams and J. M. Bowman, Int. Rev. Phys. Chem. 28, 577 (2009)]. We employ permutationally invariant basis functions in Morse-type variables for all the internuclear distances to incorporate permutational symmetry with respect to interchange of H atoms into the representation of the surface. We describe how different configurations are selected in order to create the database of the interaction energies for the linear least squares fitting procedure. The root-mean-square error of the fit is 170 cm(-1) for the entire data set. The surface dissociates correctly to the H(5)(+) + H(2) fragments. A detailed analysis of its topology, as well as comparison with additional ab initio calculations, including harmonic frequencies, verify the quality and accuracy of the parameterized potential. This is the first attempt to present an analytical representation of the 15-dimensional surface of the H(7)(+) cluster for carrying out dynamics studies.",
                    "score": 0.8489134907722473
                },
                {
                    "id": 5290388,
                    "contents": "The unexplained accuracy of the Lagrange-mesh method.\nThe Lagrange-mesh method is an approximate variational calculation which resembles a mesh calculation because of the use of a Gauss quadrature. In order to analyze its accuracy, four different Lagrange-mesh calculations based on the zeros of Laguerre polynomials are compared with exact variational calculations based on the corresponding Laguerre basis. The comparison is performed for three solvable radial potentials: the Morse, harmonic-oscillator, and Coulomb potentials. The results show that the accuracies of the energies obtained for different partial waves with the different mesh approximations are very close to the variational accuracy, even in the presence of the centrifugal singularity. The same property holds for the approximate wave functions. This striking accuracy remains unexplained.",
                    "score": 0.8485856652259827
                },
                {
                    "id": 13449083,
                    "contents": "[Research on the universal analytic potential function applied to diatomic molecules].\nA new method on constructing analytical potential energy functions is presented, and from this a analytical potential energy function applied to both neutral diatomic molecules and charged diatomic molecular ions is obtained. In this paper, the potential energy function is examined by 21 examples of eight different basic kinds of diatomic molecules or ions--homonuclear ground-state for neutral diatomic molecule Na2-X1 sigma g+, homonuclear excitation-state for neutral diatomic molecule C2-A1 pi(u), homonuclear ground-state for charged diatomic molecular ion He2+ -X2 sigma u+, homonuclear excitation-state for charged diatomic molecular ion N2+ -B2 sigma(u), heteronuclear ground-state for neutral diatomic molecule NaLi-X1 sigma g+, heteronuclear excitation-state neutral diatomic molecule BH-B1 sigma+, heteronuclear ground-state for charged diatomic molecular ion (BC)- -X3 pi, and heteronuclear excitation-state for charged diatomic molecular ion (CS)+ -A2 pi etc. The theoretical values of the vibrational energy level of molecules calculated by the potential energy function are compared with RKR (Rydberg-Klein-Rees) or experimental data, and as a consequence, all the results are precisely consistent with RKR data.",
                    "score": 0.848532497882843
                },
                {
                    "id": 8999784,
                    "contents": "A combinatorial model for the Macdonald polynomials.\nWe introduce a polynomial C(mu)[Z; q, t], depending on a set of variables Z = z(1), z(2),..., a partition mu, and two extra parameters q, t. The definition of C(mu) involves a pair of statistics (maj(sigma, mu), inv(sigma, mu)) on words sigma of positive integers, and the coefficients of the z(i) are manifestly in N[q,t]. We conjecture that C(mu)[Z; q, t] is none other than the modified Macdonald polynomial H(mu)[Z; q, t]. We further introduce a general family of polynomials F(T)[Z; q, S], where T is an arbitrary set of squares in the first quadrant of the xy plane, and S is an arbitrary subset of T. The coefficients of the F(T)[Z; q, S] are in N[q], and C(mu)[Z; q, t] is a sum of certain F(T)[Z; q, S] times nonnegative powers of t. We prove F(T)[Z; q, S] is symmetric in the z(i) and satisfies other properties consistent with the conjecture. We also show how the coefficient of a monomial in F(T)[Z; q, S] can be expressed recursively. maple calculations indicate the F(T)[Z; q, S] are Schur-positive, and we present a combinatorial conjecture for their Schur coefficients when the set T is a partition with at most three columns.",
                    "score": 0.8477330207824707
                },
                {
                    "id": 10518778,
                    "contents": "Mori-Zwanzig formalism as a practical computational tool.\nAn operational procedure is presented to compute explicitly the different terms in the generalized Langevin equation (GLE) for a few relevant variables obtained within Mori-Zwanzig formalism. The procedure amounts to introducing an artificial controlled parameter which can be tuned in such a way that the so-called projected dynamics becomes explicit and the GLE reduces to a Markovian equation. The projected dynamics can be realised in practice by introducing constraints, and it is shown that the Green-Kubo formulae computed with these dynamics do not suffer from the plateau problem. The methodology is illustrated in the example of star polymer molecules in a melt using their center of mass as relevant variables. Through this example, we show that not only the effective potentials, but also the friction forces and the noise play a very important role in the dynamics.",
                    "score": 0.8476036787033081
                },
                {
                    "id": 10988033,
                    "contents": "Analytic Morse/long-range potential energy surfaces and predicted infrared spectra for CO2-H2.\nFive-dimensional ab initio potential energy surfaces (PESs) for CO(2)-H(2) that explicitly incorporate dependence on the Q(3) asymmetric-stretch normal-mode coordinate of the CO(2) monomer and are parametrically dependent on its Q(1) symmetric-stretch coordinate have been calculated. Analytic four-dimensional PESs are obtained by least-squares fitting vibrationally averaged interaction energies for v(3)(CO(2)) = 0, and 1 to the Morse/long-range potential function form. These fits to 23,113 points have root-mean-square (rms) deviations of 0.143 and 0.136 cm(-1), and require only 167 parameters. The resulting vibrationally averaged PESs provide good representations of the experimental infrared data: for infrared transitions of para- and ortho-H(2)-CO(2), the rms discrepancies are only 0.004 and 0.005 cm(-1), respectively. The calculated infrared band origin shifts associated with the nu(3) fundamental of CO(2) are -0.179 and -0.092 cm(-1) for para-H(2)-CO(2) and ortho-H(2)-CO(2), in good agreement with the (extrapolated) experimental values of -0.198 and -0.096 cm(-1).",
                    "score": 0.8471643924713135
                },
                {
                    "id": 13715364,
                    "contents": "The Ehrenfest force field: Topology and consequences for the definition of an atom in a molecule.\nThe Ehrenfest force is the force acting on the electrons in a molecule due to the presence of the other electrons and the nuclei. There is an associated force field in three-dimensional space that is obtained by the integration of the corresponding Hermitian quantum force operator over the spin coordinates of all of the electrons and the space coordinates of all of the electrons but one. This paper analyzes the topology induced by this vector field and its consequences for the definition of molecular structure and of an atom in a molecule. Its phase portrait reveals: that the nuclei are attractors of the Ehrenfest force, the existence of separatrices yielding a dense partitioning of three-dimensional space into disjoint regions, and field lines connecting the attractors through these separatrices. From the numerical point of view, when the Ehrenfest force field is obtained as minus the divergence of the kinetic stress tensor, the induced topology was found to be highly sensitive to choice of gaussian basis sets at long range. Even the use of large split valence and highly uncontracted basis sets can yield spurious critical points that may alter the number of attraction basins. Nevertheless, at short distances from the nuclei, in general, the partitioning of three-dimensional space with the Ehrenfest force field coincides with that induced by the gradient field of the electron density. However, exceptions are found in molecules where the electron density yields results in conflict with chemical intuition. In these cases, the molecular graphs of the Ehrenfest force field reveal the expected atomic connectivities. This discrepancy between the definition of an atom in a molecule between the two vector fields casts some doubts on the physical meaning of the integration of Ehrenfest forces over the basins of the electron density.",
                    "score": 0.8469693064689636
                },
                {
                    "id": 21099865,
                    "contents": "Towards a Holomorphic Density Functional Theory.\nSelf-consistent-field (SCF) approximations formulated using Hartree-Fock (HF) or Kohn-Sham density-functional theory (KS-DFT) have the potential to yield multiple solutions. However, the formal relationship between multiple solutions identified using HF or KS-DFT remains generally unknown. We investigate the connection between multiple SCF solutions for HF or KS-DFT by introducing a parameterized functional that scales between the two representations. Using the hydrogen molecule and a model of electron transfer, we continuously map multiple solutions from the HF potential to a KS-DFT description. We discover that multiple solutions can coalesce and vanish as the functional changes, forming a direct analogy with the disappearance of real HF solutions along a change in molecular structure. To overcome this disappearance of solutions, we develop a complex-analytic extension of DFT-the \"holomorphic DFT\" approach-that allows every SCF stationary state to be analytically continued across all molecular structures and exchange-correlation functionals.",
                    "score": 0.8465813398361206
                },
                {
                    "id": 8398301,
                    "contents": "Multidimensional reactive scattering with quantum trajectories: dynamics with Morse vibrational modes.\nThe reactive scattering of a wave packet is studied by the quantum trajectory method for a model system with up to 25 Morse vibrational modes. The equations of motion are formulated in curvilinear reaction path coordinates with the restriction to a planar reaction path. Spatial derivatives are evaluated by the least squares method using contracted basis sets. Dynamical results, including trajectory evolution and time-dependent reaction probabilities, are presented and analyzed. For the case of one Morse vibrational mode, the results are in good agreement with those derived through direct numerical integration of the time-dependent Schrodinger equation.",
                    "score": 0.846401572227478
                },
                {
                    "id": 14830297,
                    "contents": "Pushing the limit for the grid-based treatment of Schrödinger's equation: a sparse Numerov approach for one, two and three dimensional quantum problems.\nThe general Numerov method employed to numerically solve ordinary differential equations of second order was adapted with a special focus on solving Schrödinger's equation. By formulating a hierarchy of novel stencil expressions for the numerical treatment of the Laplace operator in one, two and three dimensions the method could not only be simplified over the standard Numerov scheme. The improved framework enables the natural use of matrix sparsity to reduce the memory demand and the associated computing time, thus enabling the application of the method to larger problems. The performance of the adapted method is demonstrated using exemplary harmonic and Morse problems in one and two dimensions. Furthermore, the vibrational frequencies of molecular hydrogen and water are calculated, inherently considering the influence of anharmonicity, mode-mode coupling and nuclear quantum effects. The estimation of the tunneling splitting in malonaldehyde serves as an example for a two-dimensional problem.",
                    "score": 0.8457348346710205
                },
                {
                    "id": 9667273,
                    "contents": "Potential Energy Surface Including Electron Correlation for F + H2 rarr FH + H: Refined Linear Surface.\nA priori quantum mechanical calculations have been carried out at about 150 linear geometries for the fluorine plus hydrogen molecule system. An extended basis set of Gaussian functions was used, and electron correlation was treated explicitly by configuration interaction. Comparison with the experimental activation energy and exothermicity suggests that the theoretical potential surface is quite realistic.",
                    "score": 0.8446431159973145
                },
                {
                    "id": 6433024,
                    "contents": "Potential functionals: dual to density functionals and solution to the v-representability problem.\nA functional of external potentials and its variational principle for the ground-state energy is constructed. This potential functional formulation is dual to the density functional approach and provides a solution to the v-representability problem in the original Hohenberg-Kohn theory. A second potential functional for Kohn-Sham noninteracting systems establishes the foundation for the optimized effective potential approach and results in efficient approaches for ensemble Kohn-Sham calculations.",
                    "score": 0.8444843292236328
                },
                {
                    "id": 11051700,
                    "contents": "Gaussian approximation potentials: the accuracy of quantum mechanics, without the electrons.\nWe introduce a class of interatomic potential models that can be automatically generated from data consisting of the energies and forces experienced by atoms, as derived from quantum mechanical calculations. The models do not have a fixed functional form and hence are capable of modeling complex potential energy landscapes. They are systematically improvable with more data. We apply the method to bulk crystals, and test it by calculating properties at high temperatures. Using the interatomic potential to generate the long molecular dynamics trajectories required for such calculations saves orders of magnitude in computational cost.",
                    "score": 0.8444823026657104
                },
                {
                    "id": 23307875,
                    "contents": "Morse potential specific heat with applications: an integral equations theory based.\nThe specific heat in its molar form or mass form is a significant thermal property in the study of the thermal capacity of the described system. There are two basic methods for the determination of the molar specific heat capacity, one of them is the experimental procedure and the other is the theoretical procedure. The present study deals with finding a formula of the molar specific heat capacity using the theory of the integral equations for Morse interaction which is a very important potential for the study of the general oscillations in the quantum mechanics. We use the approximation (Mean-Spherical) for finding the total energy of the compositions described by Morse interaction. We find two formulas of the heat capacity, one at a constant pressure and the other at a constant volume. We conclude that the Morse molar specific heat is temperature dependent via the inverse square low with respect to temperature. Besides, we find that the Morse molar specific heat is proportional to the square of the Morse interaction well depth. Also, we find that the Morse molar specific heat depends on the particles' diameter, the bond distance of Morse interaction, the width parameter of Morse interaction, and the volumetric density of the system. We apply the formula of the specific heat for finding the specific heat of the vibrational part for two dimer which are the lithium and caesium dimers and for the hydrogen fluoride, hydrogen chloride, nitrogen, and hydrogen molecules.",
                    "score": 0.8443622589111328
                },
                {
                    "id": 1619910,
                    "contents": "A note on the application of Morse theory to the study of the potential extrema of body surface potential maps.\nThe entire body may be approximated with a closed surface having the homotopy type of a sphere. The Morse inequalities then yield certain relationships between the local potential extrema and the saddle points appearing on body surface potential maps (BSPMs). In particular, a list of possible extremal configurations is presented.",
                    "score": 0.8442767262458801
                },
                {
                    "id": 11565032,
                    "contents": "Global optimization of additive potential energy functions: predicting binary Lennard-Jones clusters.\nWe present a method for minimizing additive potential-energy functions. Our hidden-force algorithm can be described as an intricate multiplayer tug-of-war game in which teams try to break an impasse by randomly assigning some players to drop their ropes while the others are still tugging until a partial impasse is reached, then, instructing the dropouts to resume tugging, for all teams to come to a new overall impasse. Utilizing our algorithm in a non-Markovian parallel Monte Carlo search, we found 17 new putative global minima for binary Lennard-Jones clusters in the size range of 90-100 particles. The method is efficient enough that an unbiased search was possible; no potential-energy surface symmetries were exploited. All new minima are comprised of three nested polyicosahedral or polytetrahedral shells when viewed as a nested set of Connolly surfaces (though the shell structure has previously gone unscrutinized, known minima are often qualitatively similar). Unlike known minima, in which the outer and inner shells are comprised of the larger and smaller atoms, respectively, in 13 of the new minima, the atoms are not as clearly separated by size. Furthermore, while some known minima have inner shells stabilized by larger atoms, four of the new minima have outer shells stabilized by smaller atoms.",
                    "score": 0.8441533446311951
                },
                {
                    "id": 18828377,
                    "contents": "Connecting the Dunham Expansion to the Dissociation Limit for Interatomic Potentials: Application to Lennard-Jones m- n Potentials.\nDunham generated the expansion for energy levels of a rotating, vibrating diatomic molecule from an expansion of the potential about the equilibrium position. For partition functions, however, the energy levels are needed all the way to dissociation. Analytic Morse oscillator energies are not very useful because the exponential decay of the Morse potential is much too short-ranged for any physical system. The longer-range Lennard-Jones 12-6 potential could be used, but quantum energies have not previously been conveniently fit. I show how Dunham coefficients begin a set of asymptotic functions for any interaction potential, one function arising from each successive term in the WKB expansion. I apply this to the family of Lennard-Jones m- n (LJ m- n) potentials with an R<sup-m</sup repulsive term and R<sup-n</sup attractive term ( m &gt; n) and demonstrate how m can be used as a parameter to adjust either the equilibrium distance or harmonic frequency. I present an empirical parametrization of LJ m- n vibrotor energies starting with Dunham coefficients generated from four terms in the WKB expansion. This information is combined with data from numerically solved energies and asymptotic limits to fit the functions all the way to dissociation. One can also treat exp-6 and similar model potentials with different repulsive parts using the same method because the expansion form is controlled by the long-range part of the potential.",
                    "score": 0.843747615814209
                },
                {
                    "id": 8248562,
                    "contents": "MMM1D: a method for calculating electrostatic interactions in one-dimensional periodic geometries.\nWe present a new method to accurately calculate the electrostatic energy and forces on charges in a system with periodic boundary conditions in one of three spatial dimensions. We transform the Coulomb sum via a convergence factor into a series of fast decaying functions similar to the Lekner method. Rigorous error bounds for the energies and the forces are derived and numerically verified. The method has a computational complexity of O(N(2)), but is faster and easier to use than previously reported methods.",
                    "score": 0.8435553908348083
                },
                {
                    "id": 11402447,
                    "contents": "The irreducible bundle: further structure in the kinetic energy distribution.\nModern molecular sciences are often concerned with the properties and dynamics of chemical bonds. With the ability to experimentally measure charge density, there is a pressing need to find the relationships between charge density and the properties of chemical bonds. Here we show molecules can be partitioned into unique bond volumes characterized by well defined properties. Moreover, this partitioning recovers unrecognized structure in the kinetic energy distribution.",
                    "score": 0.8434199690818787
                },
                {
                    "id": 14127598,
                    "contents": "On the use of big-bang method to generate low-energy structures of atomic clusters modeled with pair potentials of different ranges.\nThe efficiency of the so-called big-bang method for the optimization of atomic clusters is analysed in detail for Morse pair potentials with different ranges; here, we have used Morse potentials with four different ranges, from long- ρ = 3) to short-ranged ρ = 14) interactions. Specifically, we study the efficacy of the method in discovering low-energy structures, including the putative global minimum, as a function of the potential range and the cluster size. A new global minimum structure for long-ranged ρ = 3) Morse potential at the cluster size of n= 240 is reported. The present results are useful to assess the maximum cluster size for each type of interaction where the global minimum can be discovered with a limited number of big-bang trials.",
                    "score": 0.8423945903778076
                },
                {
                    "id": 20747175,
                    "contents": "Corrigendum: Recent progress in linear-scaling density functional calculations with plane waves and pseudopotentials: the ONETEP code (2008 J. Phys.: Condens. Matter 20 064209).\nN/A.",
                    "score": 0.8418652415275574
                },
                {
                    "id": 14003447,
                    "contents": "Soliton concepts and protein structure.\nStructural classification shows that the number of different protein folds is surprisingly small. It also appears that proteins are built in a modular fashion from a relatively small number of components. Here we propose that the modular building blocks are made of the dark soliton solution of a generalized discrete nonlinear Schrödinger equation. We find that practically all protein loops can be obtained simply by scaling the size and by joining together a number of copies of the soliton, one after another. The soliton has only two loop-specific parameters, and we compute their statistical distribution in the Protein Data Bank (PDB). We explicitly construct a collection of 200 sets of parameters, each determining a soliton profile that describes a different short loop. The ensuing profiles cover practically all those proteins in PDB that have a resolution which is better than 2.0 Å, with a precision such that the average root-mean-square distance between the loop and its soliton is less than the experimental B-factor fluctuation distance. We also present two examples that describe how the loop library can be employed both to model and to analyze folded proteins.",
                    "score": 0.8416983485221863
                },
                {
                    "id": 12655723,
                    "contents": "Structural and technical details of the Kirkwood-Buff integrals from the optimization of ionic force fields: focus on fluorides.\nResults on the structural details of Kirkwood-Buff integrals obtained from the optimization of ionic force fields are presented. We have proposed and make use of an optimization scheme for ionic force fields, which is based on the modification of the cation-anion mixing rules, the calculation of the thermodynamics properties of various monovalent salt solutions according to the Kirkwood-Buff theory of solutions and the comparison to relevant experimental findings. Here, we complete and extend our calculations and analysis as we focus on the technical details of this optimization procedure and the case of fluorides, which have been proven difficult to handle. Important insight is given on the dependence of the radial distribution functions, the short-ranged potentials of mean force, and the Kirkwood-Buff integrals of the salt solutions on the different scaling factors in the mixing rules. Specifically, the way the structural details and inherent characteristics of the above properties are affected by the quantitative and qualitative differences in the mixing rules for a variety of common biologically relevant monovalent salts is mainly addressed. We conclude on the efficiency of this scheme, again with a focus on the fluorides. In the end, we provide a variation of the ion-pair mixing rules scaling factors with salt concentration to identify regimes for which different mixing rules prefactors lead to well-optimized force fields. All results are obtained through Molecular Dynamics simulations using previously optimized force fields for the monovalent ions.",
                    "score": 0.8416190147399902
                },
                {
                    "id": 16111027,
                    "contents": "Exploring the potential energy landscape of the Thomson problem via Newton homotopies.\nLocating the stationary points of a real-valued multivariate potential energy function is an important problem in many areas of science. This task generally amounts to solving simultaneous nonlinear systems of equations. While there are several numerical methods that can find many or all stationary points, they each exhibit characteristic problems. Moreover, traditional methods tend to perform poorly near degenerate stationary points with additional zero Hessian eigenvalues. We propose an efficient and robust implementation of the Newton homotopy method, which is capable of quickly sampling a large number of stationary points of a wide range of indices, as well as degenerate stationary points. We demonstrate our approach by applying it to the Thomson problem. We also briefly discuss a possible connection between the present work and Smale's 7th problem. ",
                    "score": 0.8412039279937744
                },
                {
                    "id": 6589673,
                    "contents": "Comparison between phase space structures in coupled Morse systems and in various su(2) approximations.\nWhile Hamiltonians written in terms of position and momentum provide a transparent picture of the motion of a system, Hamiltonians written in terms of Lie algebras are easier to handle quantum mechanically. Therefore we are interested to know how to transform one into the other. Since the exact transformation often leads to complicated expressions, we look for approximations which preserve the essential features. As basic criterion we look for the degree of equality of the classical phase space structures. We illustrate our ideas for the case of two coupled Morse systems and its approximation in terms of the Lie algebra su(2), which is relevant to anharmonic models of molecular spectroscopy. (c) 2001 American Institute of Physics.",
                    "score": 0.8408905267715454
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_9",
        "question": "A line in the Lyman series of hydrogen has a wavelength of $1.03 \\times 10^{-7} \\mathrm{~m}$. Find the original energy level of the electron.",
        "golden_answers": [
            " 3"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 13270175,
                    "contents": "Fundamental vibration of molecular hydrogen.\nThe fundamental ground tone vibration of H(2), HD, and D(2) is determined to an accuracy of 2×10(-4) cm(-1) from Doppler-free laser spectroscopy in the collisionless environment of a molecular beam. This rotationless vibrational splitting is derived from the combination difference between electronic excitation from the X(1)Σ(g)(+), v=0, and v=1 levels to a common EF(1)Σ(g)(+), v=0 level. Agreement within 1σ between the experimental result and a full ab initio calculation provides a stringent test of quantum electrodynamics in a chemically bound system.",
                    "score": 0.8747971653938293
                },
                {
                    "id": 22067069,
                    "contents": "Spectroscopy of Highly Excited States of the Hydrogen Atom.\nIn this contribution, we describe the status of the development of a precision-spectroscopic experiment aimed at measuring transitions to states of high principal quantum number <in</i of the hydrogen atom (H). These states form series (called Rydberg series) which converge for <in</i → ∞ to the ionization threshold of H. The ionization energy of H can thus be determined directly by measuring the frequencies of transitions to high-<in</i states and extrapolating the Rydberg series to <in</i → ∞.",
                    "score": 0.8653110861778259
                },
                {
                    "id": 15302155,
                    "contents": "Probing QED and fundamental constants through laser spectroscopy of vibrational transitions in HD(.).\nThe simplest molecules in nature, molecular hydrogen ions in the form of H2(+) and HD(+), provide an important benchmark system for tests of quantum electrodynamics in complex forms of matter. Here, we report on such a test based on a frequency measurement of a vibrational overtone transition in HD(+) by laser spectroscopy. We find that the theoretical and experimental frequencies are equal to within 0.6(1.1) parts per billion, which represents the most stringent test of molecular theory so far. Our measurement not only confirms the validity of high-order quantum electrodynamics in molecules, but also enables the long predicted determination of the proton-to-electron mass ratio from a molecular system, as well as improved constraints on hypothetical fifth forces and compactified higher dimensions at the molecular scale. With the perspective of comparisons between theory and experiment at the 0.01 part-per-billion level, our work demonstrates the potential of molecular hydrogen ions as a probe of fundamental physical constants and laws. ",
                    "score": 0.8639993071556091
                },
                {
                    "id": 8440441,
                    "contents": "Reference wavelengths for strong lines of atomic hydrogen and deuterium.\nWavelengths of the individual fine-structure components of the n = 1-2 (Ly(alpha)), n = 1-3 (Ly(beta)), n = 1-4 (Ly(gamma)), n = 1-5 (Ly(delta)), n = 1-6 (Ly(epsilon)), n = 1-7 (Ly(zeta)), n = 2-3 (H(alpha)), n = 2-4 (H(beta)), n = 2-5 (H(gamma)), n = 2-6 (H(delta)), and n = 2-7 (H(epsilon)) transitions of H and D are determined from theoretical values for the binding energies. Theoretical line strengths are used to obtain recommended values for the peaks of unresolved blends of these components as likely to be observed with discharge light sources and spectrometers with low to moderate resolution.",
                    "score": 0.862833559513092
                },
                {
                    "id": 17587862,
                    "contents": "Dissociation Energy of the Hydrogen Molecule at 10^{-9} Accuracy.\nThe ionization energy of ortho-H_{2} has been determined to be E_{I}^{o}(H_{2})/(hc)=124 357.238 062(25)  cm^{-1} from measurements of the GK(1,1)-X(0,1) interval by Doppler-free, two-photon spectroscopy using a narrow band 179-nm laser source and the ionization energy of the GK(1,1) state by continuous-wave, near-infrared laser spectroscopy. E_{I}^{o}(H_{2}) was used to derive the dissociation energy of H_{2}, D_{0}^{N=1}(H_{2}), at 35 999.582 894(25)  cm^{-1} with a precision that is more than one order of magnitude better than all previous results. The new result challenges calculations of this quantity and represents a benchmark value for future relativistic and QED calculations of molecular energies.",
                    "score": 0.8626071214675903
                },
                {
                    "id": 15379292,
                    "contents": "Schrödinger equation solved for the hydrogen molecule with unprecedented accuracy.\nThe hydrogen molecule can be used for determination of physical constants, including the proton charge radius, and for improved tests of the hypothetical long range force between hadrons, which require a sufficiently accurate knowledge of the molecular levels. In this work, we perform the first step toward a significant improvement in theoretical predictions of H2 and solve the nonrelativistic Schrödinger equation to the unprecedented accuracy of 10(-12). We hope that it will inspire a parallel progress in the spectroscopy of the molecular hydrogen. ",
                    "score": 0.8592865467071533
                },
                {
                    "id": 848577,
                    "contents": "Low-frequency parameterization of hydrogen bonding.\nWe review the model of the hydrogen bond developed by Lippincott and Schroeder and discuss the frequency range in which it is valid, specifically in the optical and near infrared range. We then show why and how to modify the Lippincott and Schroeder formulate to apply to the far infrared and lower ranges. The contrasts between the old and modified systems, particularly with respect to the effective force constants are worked out and plotted for an example.",
                    "score": 0.8581591248512268
                },
                {
                    "id": 19925184,
                    "contents": "Classical Path Methods in Line Broadening. II. Application to the Lyman Series of Hydrogen.\nThe use of the classical path approximation in line broadening theory is illustrated in a development of the familiar impact and one-electron theories. The one-electron theory which is presented is an improved version of the usual one-electron theory; this improved version of the theory provides a consistent description of a line profile from the halfwidth to the quasi-static wings. The validity criteria for the impact and one-electron theories are discussed in detail and a comparison of the theories is made with a view toward the development of a more general theory containing elements of both. To avoid unnecessary mathematical complications and to provide a more transparent comparison of the theories, the Stark broadening of the Lyman series in hydrogen is used as a specific example.",
                    "score": 0.8562989830970764
                },
                {
                    "id": 5980535,
                    "contents": "Lambda-Splittings and Line Intensities in the 3 &lt;-- 1 Hot Band of 14N16O: The Spectrum of Nitric Oxide in the First Overtone Region\nIntensities and Lambda-splittings have been measured for lines belonging to the 3 &lt;-- 1 hot band of 14N16O. The vibrational transition moment and the Herman-Wallis coefficient have been determined. Hamiltonian constants have been calculated for the four vibrational states v = 0, 1, 2, and 3, and a synthetic spectrum has been generated in the first overtone region of NO, taking into account the hyperfine structure for the 2 &lt;-- 0 band. Copyright 1998 Academic Press. Copyright 1998Academic Press",
                    "score": 0.8552550673484802
                },
                {
                    "id": 5825730,
                    "contents": "Infrared Absorption Spectroscopy of HNC in the Region 2.6 to 3.1 &amp;mgr;m\nThe HNC molecule was generated by the reaction of translationally hot H atoms with either ClCN or BrCN. The energetically rich HNC products were probed by time-resolved infrared laser absorption spectroscopy. This allowed for the spectroscopic analysis of 16 vibrational bands in the wavelength region 2.6 to 3.1 &amp;mgr;m and the identification of 8 new bands for HNC. The dependence of Gv, Bv, and Dv was fit to appropriate polynomials in the vibrational quantum numbers and l. No bands were identified in which the bend, nu2, and CN stretch, nu3, were simultaneously excited so that the spectroscopic constants depending on the interaction between these two vibrations could not be experimentally measured. Nevertheless, the observations of this work allow for an almost complete experimental determination of the quadratic spectroscopic constants of this simple but important molecule. Copyright 1997 Academic Press. Copyright 1997Academic Press",
                    "score": 0.8548709154129028
                },
                {
                    "id": 15698044,
                    "contents": "Communication: Visible line intensities of the triatomic hydrogen ion from experiment and theory.\nThe visible spectrum of H3(+) is studied using high-sensitivity action spectroscopy in a cryogenic radiofrequency multipole trap. Advances are made to measure the weak ro-vibrational transitions from the lowest rotational states of H3(+) up to high excitation energies providing visible line intensities and, after normalisation to an infrared calibration line, the corresponding Einstein B coefficients. Ab initio predictions for the Einstein B coefficients are obtained from a highly precise dipole moment surface of H3(+) and found to be in excellent agreement, even in the region where states have been classified as chaotic.",
                    "score": 0.8541061878204346
                },
                {
                    "id": 15821003,
                    "contents": "Accurate lineshape spectroscopy and the Boltzmann constant.\nSpectroscopy has an illustrious history delivering serendipitous discoveries and providing a stringent testbed for new physical predictions, including applications from trace materials detection, to understanding the atmospheres of stars and planets, and even constraining cosmological models. Reaching fundamental-noise limits permits optimal extraction of spectroscopic information from an absorption measurement. Here, we demonstrate a quantum-limited spectrometer that delivers high-precision measurements of the absorption lineshape. These measurements yield a very accurate measurement of the excited-state (6P1/2) hyperfine splitting in Cs, and reveals a breakdown in the well-known Voigt spectral profile. We develop a theoretical model that accounts for this breakdown, explaining the observations to within the shot-noise limit. Our model enables us to infer the thermal velocity dispersion of the Cs vapour with an uncertainty of 35 p.p.m. within an hour. This allows us to determine a value for Boltzmann's constant with a precision of 6 p.p.m., and an uncertainty of 71 p.p.m.",
                    "score": 0.8505310416221619
                },
                {
                    "id": 9611026,
                    "contents": "Atomic regime in which the magnetic interaction dominates the coulomb interaction for highly excited States of hydrogen.\nThe atomic regime in which the interaction of the electron with an external magnetic field dominates the Coulomb interaction with the nucleus, relevant to pulsars, can be realized at laboratory magnetic fields for discrete autoionized states of hydrogen, at energies above the ionization limit. Approximate wave functions, energy levels, and electric dipole transition probabilities are presented for hydrogen, and an atomic beam absorption spectroscopy experiment at 50 kG is proposed to study this new regime.",
                    "score": 0.849736213684082
                },
                {
                    "id": 14197692,
                    "contents": "Experimental ionization of atomic hydrogen with few-cycle pulses.\nWe present experimental data on strong-field ionization of atomic hydrogen by few-cycle laser pulses. We obtain quantitative agreement at the 10% level between the data and an ab initio simulation over a wide range of laser intensities and electron energies.",
                    "score": 0.8492752909660339
                },
                {
                    "id": 20319978,
                    "contents": "Speed of sound from fundamental physical constants.\nTwo dimensionless fundamental physical constants, the fine structure constant α and the proton-to-electron mass ratio [Formula: see text], are attributed a particular importance from the point of view of nuclear synthesis, formation of heavy elements, planets, and life-supporting structures. Here, we show that a combination of these two constants results in a new dimensionless constant that provides the upper bound for the speed of sound in condensed phases, <iv<subu</sub</i We find that [Formula: see text], where <ic</i is the speed of light in vacuum. We support this result by a large set of experimental data and first-principles computations for atomic hydrogen. Our result expands the current understanding of how fundamental constants can impose new bounds on important physical properties.",
                    "score": 0.8486189842224121
                },
                {
                    "id": 15581306,
                    "contents": "Communication: Test of quantum chemistry in vibrationally hot hydrogen molecules.\nPrecision measurements are performed on highly excited vibrational quantum states of molecular hydrogen. The v = 12, J = 0 - 3 rovibrational levels of H2 (X(1)Σg (+)), lying only 2000 cm(-1) below the first dissociation limit, were populated by photodissociation of H2S and their level energies were accurately determined by two-photon Doppler-free spectroscopy. A comparison between the experimental results on v = 12 level energies with the best ab initio calculations shows a good agreement, where the present experimental accuracy of 3.5 × 10(-3) cm(-1) is more precise than theory, hence providing a gateway to further test theoretical advances in this benchmark quantum system. ",
                    "score": 0.8471113443374634
                },
                {
                    "id": 4877632,
                    "contents": "Water on the sun: line assignments based on variational calculations.\nThe infrared spectrum of hot water observed in a sunspot has been assigned. The high temperature of the sunspot (3200 K) gave rise to a highly congested pure rotational spectrum in the 10-micrometer region that involved energy levels at least halfway to dissociation. Traditional spectroscopy, based on perturbation theory, is inadequate for this problem. Instead, accurate variational solutions of the vibration-rotation Schrödinger equation were used to make assignments, revealing unexpected features, including rotational difference bands and fewer degeneracies than anticipated. These results indicate that a shift away from perturbation theory to first principles calculations is necessary in order to assign spectra of hot polyatomic molecules such as water.",
                    "score": 0.846315324306488
                },
                {
                    "id": 15087529,
                    "contents": "Accurate adiabatic correction in the hydrogen molecule.\nA new formalism for the accurate treatment of adiabatic effects in the hydrogen molecule is presented, in which the electronic wave function is expanded in the James-Coolidge basis functions. Systematic increase in the size of the basis set permits estimation of the accuracy. Numerical results for the adiabatic correction to the Born-Oppenheimer interaction energy reveal a relative precision of 10(-12) at an arbitrary internuclear distance. Such calculations have been performed for 88 internuclear distances in the range of 0 &lt; R ⩽ 12 bohrs to construct the adiabatic correction potential and to solve the nuclear Schrödinger equation. Finally, the adiabatic correction to the dissociation energies of all rovibrational levels in H2, HD, HT, D2, DT, and T2 has been determined. For the ground state of H2 the estimated precision is 3 × 10(-7) cm(-1), which is almost three orders of magnitude higher than that of the best previous result. The achieved accuracy removes the adiabatic contribution from the overall error budget of the present day theoretical predictions for the rovibrational levels. ",
                    "score": 0.8457990884780884
                },
                {
                    "id": 4766640,
                    "contents": "The Far Infrared Spectrum of HOCl: Line Positions and Intensities.\nThe far infrared spectrum of HOCl has been recorded at high resolution between 20 and 360 cm-1 by means of Fourier transform spectroscopy, and it was possible to observe pure rotation lines involving rotational levels with high Ka quantum numbers (up to Ka = 9). These lines combined with microwave and tunable far infrared data available in the literature were least squares fitted using a Watson-type Hamiltonian. The fitting leads to precise sets of rotational and centrifugal distortion constants for the ground states of both isotopomers HO35Cl and HO37Cl. Also relative line intensities were measured and their fitting allowed the determination of rotational corrections to the b-component of the permanent transition moment. Finally, to get Hamiltonian constants consistent with the newly determined ground state constants for the (100), (010), (001) vibrational states, available data concerning the nu1, nu2, and nu3 bands were refitted. Three interesting points are to be stressed. For the (001) state, we were able to complete the existing data with rotation lines observed in our spectra up to rather high Ka values (Ka = 7). For HO35Cl, we were able to show that some (010) and (100) levels are perturbed by levels of the (002) and (030) states, respectively, through Coriolis-type interactions. This allows the determination of the band centers of these two dark states. Copyright 1998 Academic Press.",
                    "score": 0.8456016182899475
                },
                {
                    "id": 7053073,
                    "contents": "Two-loop Bethe-logarithm correction in hydrogenlike atoms.\nWe calculate the two-loop Bethe logarithm correction to atomic energy levels in hydrogenlike systems. The two-loop Bethe logarithm is a low-energy quantum electrodynamic (QED) effect involving multiple summations over virtual excited atomic states. Although much smaller in absolute magnitude than the well-known one-loop Bethe logarithm, the two-loop analog is quite significant when compared to the current experimental accuracy of the 1S-2S transition: It contributes -8.19 and -0.84 kHz for the 1S and the 2S state, respectively. The two-loop Bethe logarithm has been the largest unknown correction to the hydrogen Lamb shift to date. Together with the ongoing measurement of the proton charge radius at the Paul Scherrer Institute, its calculation will bring theoretical and experimental accuracy for the Lamb shift in atomic hydrogen to the level of 10(-7).",
                    "score": 0.8436315059661865
                },
                {
                    "id": 13873611,
                    "contents": "A fresh look at dense hydrogen under pressure. I. an introduction to the problem, and an index probing equalization of H-H distances.\nIn the first of a series of four papers on hydrogen under pressure, and its transitions from an initiating molecular state, we begin by defining carefully the problem, and setting the distance scale of interactions of protons and electrons in molecular aggregates of the first of the elements. Following a review of the experimental situation, in particular the phase diagram of hydrogen, in as much as it is known, and the behavior of its vibrons and rotons, we move onto the setting up of a numerical laboratory for probing the underlying physics and chemistry of interactions in hydrogen as the pressure increases. The laboratory consists of the preferred static structures emerging from calculations on the system in the range of 1 atm to 500 GPa, those of Pickard and Needs. The intermolecular (inter-pair) H···H separations naturally decrease with increasing pressure, first rapidly so, then more slowly. The intramolecular (intra-pair) H-H distances vary over a much smaller scale (0.05 Å) as the pressure increases, first decreasing, then increasing, and finally decreasing. We define an equalization function to gauge the approach to equality of the first neighbor and shortest next neighbor H (proton) separations in this numerical laboratory. And we find that metallization is likely to occur before bond equalization.",
                    "score": 0.8433340787887573
                },
                {
                    "id": 9695221,
                    "contents": "Hydrogen Energy Levels: Perturbation Caused by Proton Structure.\nThe shifts in the lowest electronic energy levels of the hydrogen atom caused by the extended charge distribution of the proton have been calculated and found to be of the order of the unexplained portion of the Lamb shift for these levels.",
                    "score": 0.8430648446083069
                },
                {
                    "id": 10727751,
                    "contents": "Observation of a Rydberg series in H+H-: a heavy Bohr atom.\nWe report on the realization of a heavy \"Bohr atom,\" through the spectroscopic observation of a Rydberg series of bound quantum states at principal quantum numbers n=140 to 230. The system is made heavy by replacing an electron inside a hydrogen atom by a composite H- particle, thus forming a H+H- Coulombically bound system obeying the physical laws of a generalized atom with appropriate mass scaling.",
                    "score": 0.8430460691452026
                },
                {
                    "id": 20105326,
                    "contents": "Simplify your life.\nWithin the Hartree atomic unit systems, the Schrödinger equation becomes parameter free. But there's more to it than making a student's life easier, as Gordon Drake and Eite Tiesinga recount.",
                    "score": 0.8429574966430664
                },
                {
                    "id": 11252316,
                    "contents": "Measurement of the 2S hyperfine interval in atomic hydrogen.\nAn optical measurement of the 2S hyperfine interval in atomic hydrogen using two-photon spectroscopy of the 1S-2S transition gives a value of 177 556 834.3(6.7) Hz. The uncertainty is 2.4 times smaller than achieved by our group in 2003 and more than 4 times smaller than for any independent radio-frequency measurement. The specific combination of the 2S and 1S hyperfine intervals predicted by QED theory 8fHFS(2S)-fHFS(1S)=48 953(3) Hz is in good agreement with the value of 48 923(54) Hz obtained from this experiment.",
                    "score": 0.84291672706604
                },
                {
                    "id": 16277601,
                    "contents": "Zeeman effect induced by intense laser light.\nWe analyze spectral line shapes of hydrogenlike species subjected to fields of electromagnetic waves. It is shown that the magnetic component of an electromagnetic wave may significantly influence the spectra. In particular, the Zeeman effect induced by a visible or infrared light can be experimentally observed using present-day powerful lasers. In addition, the effect may be used for diagnostics of focused beam intensities achieved at existing and newly built laser facilities. ",
                    "score": 0.8425320386886597
                },
                {
                    "id": 5722700,
                    "contents": "Laser Spectroscopy of Vibration-Rotation Lines in the 3 &lt;-- 0, 5 &lt;-- 0, and 6 &lt;-- 0 Overtones of HBr\nThe Doppler-limited vibration-rotation absorption spectrum of HBr in the near infrared wavelength region was measured using a GaAs semiconductor laser and a ring-type titanium sapphire laser. About 100 lines in the v = 3 &lt;-- 0, 5 &lt;-- 0, and 6 &lt;-- 0 bands were assigned and 16 Dunham coefficients Y10-Y50, Y01-Y41, Y02-Y22, Y03-Y13, and Y04 for H79Br and H81Br species were determined by a global least-squares fit using the v = 0, v = 1 --&gt; 0, and v = 2 --&gt; 1 lines by V. Braun and P. F. Bernath (J. Mol. Spectrosc. 167, 282-287, 1994), the v = 7 &lt;-- 0 lines by P. Bernage and P. Niay (C. R. Acad. Sci. Paris Ser. B 282, 243-245, 1976), and the v = 3 &lt;-- 0, v = 5 &lt;-- 0, and v = 6 &lt;-- 0 lines by this work. Copyright 1997Academic Press",
                    "score": 0.8421810865402222
                },
                {
                    "id": 13326812,
                    "contents": "Precision measurements of ionization and dissociation energies by extrapolation of Rydberg series: from H2 to larger molecules.\nRecent experiments are reviewed which have led to the determination of the ionization and dissociation energies of molecular hydrogen with a precision of 0.0007 cm(-)1 (8 mJ/mol or 20 MHz) using a procedure based on high-resolution spectroscopic measurements of high Rydberg states and the extrapolation of the Rydberg series to the ionization thresholds. Molecular hydrogen, with only two protons and two electrons, is the simplest molecule with which all aspects of a chemical bond, including electron correlation effects, can be studied. Highly precise values of its ionization and dissociation energies provide stringent tests of the precision of molecular quantum mechanics and of quantum-electrodynamics calculations in molecules. The comparison of experimental and theoretical values for these quantities enable one to quantify the contributions to a chemical bond that are neglected when making the Born-Oppenheimer approximation, i.e. adiabatic, nonadiabatic, relativistic, and radiative corrections. Ionization energies of a broad range of molecules can now be determined experimentally with high accuracy (i.e. about 0.01 cm(-1)). Calculations at similar accuracies are extremely challenging for systems containing more than two electrons. The combination of precision measurements of molecular ionization energies with highly accurateab initio calculations has the potential to provide, in future, fully reliable sets of thermochemical quantities for gas-phase reactions.",
                    "score": 0.8412171602249146
                },
                {
                    "id": 18393988,
                    "contents": "Deep-Ultraviolet Frequency Metrology of H_{2} for Tests of Molecular Quantum Theory.\nMolecular hydrogen and its isotopic and ionic species are benchmark systems for testing quantum chemical theory. Advances in molecular energy structure calculations enable the experimental verification of quantum electrodynamics and potentially a determination of the proton charge radius from H_{2} spectroscopy. We measure the ground state energy in ortho-H_{2} relative to the first electronically excited state by Ramsey-comb laser spectroscopy on the EF^{1}Σ_{g}^{+}-X^{1}Σ_{g}^{+}(0,0) Q1 transition. The resulting transition frequency of 2 971 234 992 965(73) kHz is 2 orders of magnitude more accurate than previous measurements. This paves the way for a considerably improved determination of the dissociation energy (D_{0}) for fundamental tests with molecular hydrogen.",
                    "score": 0.8408435583114624
                },
                {
                    "id": 5737097,
                    "contents": "Line Positions and Strengths of HDO between 6000 and 7700 cm-1\nHigh-resolution spectra of gas sample mixtures of HDO, D2O, and H2O were obtained with a Fourier-transform spectrometer at resolutions of 0.01 and 0.02 cm-1. The spectra were analyzed to obtain line positions and strengths of HDO transitions covering the region from 6000 to 7700 cm-1. The analysis included 2445 lines involving the (101)-(000), (021)-(000), (210)-(000), and (002)-(000) bands; this is the first report of assignments in the (210)-(000) and (002)-(000) bands as well as line strength measurements of any HDO transitions in this spectral interval. Copyright 1997 Academic Press. Copyright 1997Academic Press",
                    "score": 0.8408042192459106
                },
                {
                    "id": 6545027,
                    "contents": "Spectroscopy of highly excited vibrational states of HCN in its ground electronic state.\nAn experimental technique based on a scheme of vibrationally mediated photodissociation has been developed and applied to the spectroscopic study of highly excited vibrational states in HCN, with energies between 29,000 and 30,000 cm(-1). The technique consists of four sequential steps: in the first one, a high power laser is used to vibrationally excite the sample to an intermediate state, typically (0,0,4), the nu3 mode being approximately equivalent to the C-H stretching vibration. Then a second laser is used to search for transitions between this intermediate state and highly vibrationally excited states. When one of these transitions is found, HCN molecules are transferred to a highly excited vibrational state. Third, a ultraviolet laser photodissociates the highly excited molecules to produce H and CN radicals in its A 2Pi electronic state. Finally, a fourth laser (probe) detects the presence of the CN(A) photofragments by means of an A--&gt;B--&gt;X laser induced fluorescence scheme. The spectra obtained with this technique, consisting of several rotationally resolved vibrational bands, have been analyzed. The positions and rotational parameters of the states observed are presented and compared with the results of a state-of-the-art variational calculation.",
                    "score": 0.8403737545013428
                },
                {
                    "id": 13553588,
                    "contents": "Ultracold hydrogen atoms: a versatile coolant to produce ultracold molecules.\nWe show theoretically that ultracold hydrogen atoms have very favorable properties for sympathetic cooling of molecules to microkelvin temperatures. We calculate the potential energy surfaces for spin-polarized interactions of H atoms with the prototype molecules NH(3Σ-) and OH(2Π) and show that they are shallow (50 to 80  cm(-1)) and only weakly anisotropic. We carry out quantum collision calculations on H+NH and H+OH and show that the ratio of elastic to inelastic cross sections is high enough to allow sympathetic cooling from temperatures well over 1 K for NH and around 250 mK for OH.",
                    "score": 0.840238630771637
                },
                {
                    "id": 5150780,
                    "contents": "Asymmetry of the natural line profile for the hydrogen atom.\nThe asymmetry of the natural line profile for transitions in hydrogenlike atoms is evaluated within a QED framework. For the Lyman- alpha 1s-2p absorption transition in neutral hydrogen this asymmetry results in an additional energy shift of 2.929 856 Hz. For the 2s(1/2)-2p(3/2) transition it amounts to -1.512 674 Hz. As a new feature this correction turns out to be process dependent. The quoted numbers refer to the Compton-scattering process.",
                    "score": 0.839745283126831
                },
                {
                    "id": 12729844,
                    "contents": "Communication: Spectral representation of the Lamb shift for atomic and molecular calculations.\nA spectral representation of the self-energy based on hydrogenic atomic data is examined for its usefulness to evaluate the self-energy of many-electron atoms, and thus its potential for molecular calculations. Use of the limited hydrogenic data with a diagonal projection overestimates the valence self-energy by an order of magnitude. The same diagonal projection for the vacuum polarization produces a similar overestimate, but a full projection produces values that are within a factor of 2 of the exact value, as does a density-fitting procedure. ",
                    "score": 0.8394675254821777
                },
                {
                    "id": 13804041,
                    "contents": "Application of the quasi-variational coupled cluster method to the nonlinear optical properties of model hydrogen systems.\nWe present a pilot application of the recently proposed quasi-variational coupled cluster method to the energies, polarizabilities, and second hyperpolarizabilities of model hydrogen chains. Relative to other single-reference methods of equivalent computational complexity, we demonstrate this method to be highly robust and especially useful when traditional coupled cluster theory fails to perform adequately. In particular, our results indicate it to be a suitable method for the black-box treatment of multiradicals, making it of widespread general interest and applicability.",
                    "score": 0.8389037847518921
                },
                {
                    "id": 9037032,
                    "contents": "Resolved: electronic states underneath broad absorptions.\nThe far UV absorption spectra of many polyatomic molecules show featureless, broad bands, even though the lifetimes of the underlying electronic states can be long enough to render the states observable. Using photoionization from Rydberg states we measure electron binding energies, thereby referencing the electronic spectra to the adiabatic ionization energy. In trimethylamine, we find that the 3s, the 3p(x,y), and the 3p(z) Rydberg states have binding energies of 3.087, 2.251, and 2.204 eV, respectively. Vibrational motions excited while preparing the Rydberg states do not interfere with the spectra.",
                    "score": 0.8387802243232727
                },
                {
                    "id": 14122005,
                    "contents": "The absorption spectrum of H2: CRDS measurements of the (2-0) band, review of the literature data and accurate ab initio line list up to 35000 cm(-1).\nFive very weak transitions-O(2), O(3), O(4), O(5) and Q(5)-of the first overtone band of H(2) are measured by very high sensitivity CW-Cavity Ring Down Spectroscopy (CRDS) between 6900 and 7920 cm(-1). The noise equivalent absorption of the recordings is on the order of α(min)≈ 5 × 10(-11) cm(-1) allowing for the detection of the O(5) transition with an intensity of 1.1 × 10(-30) cm per molecule, the smallest intensity value measured so far for an H(2) absorption line. A Galatry profile was used to reproduce the measured line shape and derive the line strengths. The pressure shift of the O(2) and O(3) lines was accurately determined from a series of recordings with pressure ranging between 10 and 700 Torr. From an exhaustive review of the literature data, the list of H(2) absorption lines detected so far has been constructed. It includes a total of 39 transitions ranging from the S(0) pure rotational line near 354 cm(-1) up to the S(1) transition of the (5-0) band near 18,908 cm(-1). These experimental values are compared to a highly accurate theoretical line list constructed for pure H(2) at 296 K (0-35,000 cm(-1), intensity cut off of 1 × 10(-34) cm per molecule). The energy levels and transition moments were computed from high level quantum mechanics calculations. The overall agreement between the theoretical and experimental values is found to be very good for the line positions. Some deviations for the intensities of the high overtone bands (V &gt; 2) are discussed in relation with possible pressure effects affecting the retrieved intensity values. We conclude that the hydrogen molecule is probably a unique case in rovibrational spectroscopy for which first principles theory can provide accurate spectroscopic parameters at the level of the performances of the state of the art experimental techniques.",
                    "score": 0.8387501239776611
                },
                {
                    "id": 13131488,
                    "contents": "Measurement of a wavelength of light for which the energy shift for an atom vanishes.\nLight at a magic-zero wavelength causes a zero energy shift for an atom. We measured the longest magic-zero wavelength for ground state potassium atoms to be λ(zero)=768.9712(15) nm, and we show how this measurement provides an improved experimental benchmark for atomic structure calculations. This λ(zero) measurement determines the ratio of the potassium atom D1 and D2 line strengths with record precision. It also demonstrates a new application for atom interferometry, and we discuss how decoherence will fundamentally limit future measurements of magic-zero wavelengths.",
                    "score": 0.8382848501205444
                },
                {
                    "id": 5364488,
                    "contents": "\"Strong\" hydrogen bonds in chemistry and biology.\nHydrogen bonds are a key feature of chemical structure and reactivity. Recently there has been much interest in a special class of hydrogen bonds called \"strong\" or \"low-barrier\" and characterized by great strength, short distances, a low or vanishing barrier to hydrogen transfer, and distinctive features in the NMR spectrum. Although the energy of an ordinary hydrogen bond is ca 5 kcal mol-1, the strength of these hydrogen bonds may be &gt; or = 10 kcal mol-1. The properties of these hydrogen bonds have been investigated by many experimental techniques, as well as by calculation and by correlations among those properties. Although it has been proposed that strong, short, low-barrier hydrogen bonds are important in enzymatic reactions, it is concluded that the evidence for them in small molecules and in biomolecules is inconclusive.",
                    "score": 0.8375165462493896
                },
                {
                    "id": 9707366,
                    "contents": "Hot hydrogen atoms: initiators of reactions of interest in interstellar chemistry and evolution.\nPhotochemically generated hot hydrogen atoms initiate reactions with simple molecular substrates including methane to produce organic alcohols, amines, acids, amino acids, and other compounds. The typical quantum yields for the formation of amino acids are 2 x 10(-5) to 4 x 10(-5). Hot hydrogen atoms may be important initiators of reactions in interstellar space and in planetary atmospheres.",
                    "score": 0.8372774720191956
                },
                {
                    "id": 13093724,
                    "contents": "Relations between harmonic frequencies of diatomic molecules.\nThe relations between the harmonic frequencies of different molecules are revealed with the aid of the spring constants of atoms in molecules. Using the atomic spring constants in the related molecules, the force constants for a new molecule can be estimated. The simplest scheme to obtain the force constant of a given molecule is similar to a simple chemical reaction formula, such as A(2) + B(2)    → AB, and the corresponding relation between the molecular force constants is k(AB)(-1) = (2k(A(2)))(-1) + (2k(B(2)))(-1). For a given molecule, one can design numerous schemes to obtain its force constant from the atomic spring constants in other molecules. A high degree of periodical regularity appears in the application of different kinds of schemes to the ground states. The reliable schemes for the ground electronic states can be adopted for the excited states. Over two hundred molecules with experimental data available for comparison have been tested. The discrepancies between the calculated and the experimental harmonic frequencies can reach 1% and better; the results show that the present approach is simple in theory and handy to use. The harmonic frequencies for dozens of hetero-nuclear molecules of the transition-metal elements are also predicted.",
                    "score": 0.8368773460388184
                },
                {
                    "id": 2764698,
                    "contents": "The Rotational Spectrum of H2Te\nIn the present work, we study the spectrum of the H2Te molecule in the submillimeter-wave and far infrared region. An important aim of this investigation is the further experimental characterization of the anomalous \"four-fold cluster effect\" exhibited by the rotational energy levels in the vibrational ground state of H2Te. The spectrum in the region 90-472 GHz was measured with a source-modulated millimeter-wave spectrometer and that between 600 and 1600 GHz with a far-infrared sideband spectrometer. The far infrared spectrum from 30 to 360 cm-1 was measured with a Bruker IFS 120 HR interferometer attached to a 3 m long cell. We have assigned 224 submillimeter-wave lines and 1695 FIR lines. These observed data were supplemented by a large number of ground state combination differences derived from rotation-vibration bands of H2Te, and the resulting large data set was analyzed by means of a modified Watson Hamiltonian. Accurate sets of rotational and centrifugal distortion constants for all eight tellurium isotopomers were obtained.",
                    "score": 0.8365933895111084
                },
                {
                    "id": 6028984,
                    "contents": "Breakthrough of the year. The runners-up.\nScience recognizes nine other major discoveries on scales ranging from the cosmic to the quantum: Ribosome Revelations Fossil Find One Word--Organics New Cells for Old Water, Water, Everywhere Cosmic BOOMERANG Good Reception So NEAR ... Quantum Curiosities",
                    "score": 0.8364099860191345
                },
                {
                    "id": 6345415,
                    "contents": "The 0 --&gt; 3 Overtone Band of CO: Precise Linestrengths and Broadening Parameters.\nLinestrengths and self-broadening parameters are determined with a standard uncertainty of 1% for 21 lines in the R branch of the 0 --&gt; 3 overtone band of CO around 1.57 µm. The values are lower than those given in the Hitran database by 6-8% for the linestrengths and 1-5% for the collision broadening parameters, and they agree within 0-2% with more recent results obtained with FTIR. Also, results are given for foreign gas broadening by N2 and H2O. The line profiles show clear evidence for collisional narrowing with deviations corresponding to those expected for a Galatry profile. When analyzed in terms of a Voigt profile, this effect causes a reduction in effective Doppler width of about 5%. The linestrengths determined for gas mixtures are used for producing independent values for the CO concentrations. These results are derived without reference to any certified gas standard, and it is suggested that optical spectroscopy satisfies the criteria of a primary method set up by the Consultative Committee for Quantity of Matter (CCQM). Copyright 1999 Academic Press.",
                    "score": 0.8363375067710876
                },
                {
                    "id": 4345174,
                    "contents": "Hydrogen atom spectrum and the lamb shift in noncommutative QED.\nWe have calculated the energy levels of the hydrogen atom as well as the Lamb shift within the noncommutative quantum electrodynamics theory. The results show deviations from the usual QED both on the classical and the quantum levels. On both levels, the deviations depend on the parameter of space/space noncommutativity.",
                    "score": 0.8360775113105774
                },
                {
                    "id": 16753787,
                    "contents": "High-Resolution Rotational Spectrum, Dunham Coefficients, and Potential Energy Function of NaCl.\nWe report laboratory spectroscopy for the first time of the <iJ</i = 1-0 and <iJ</i = 2-1 lines of Na<sup35</supCl and Na<sup37</supCl in several vibrational states. The hyperfine structure has been resolved in both transitions for all vibrational levels, which permit us to predict with high accuracy the hyperfine splitting of the rotational transitions of the two isotopologues at higher frequencies. The new data have been merged with all previous works at microwave, millimeter, and infrared wavelengths and fitted to a series of mass-independent Dunham parameters and to a potential energy function. The obtained parameters have been used to compute a new dipole moment function, from which the dipole moment for infrared transitions up to Δ<iv</i = 8 has been derived. Frequency and intensity predictions are provided for all rovibrational transitions up to <iJ</i = 150 and <iv</i = 8, from which the ALMA data of evolved stars can be modeled and interpreted.",
                    "score": 0.8357038497924805
                },
                {
                    "id": 7994316,
                    "contents": "Chemistry and cosmology.\nThe simplest elements, hydrogen and helium, offer a remarkably rich chemistry, which has controlled crucial features of the early evolution of the universe. Theoretical models of the origin of structure (stars, galaxies, clusters of galaxies, etc.) now incorporate this chemistry in some detail. In addition to the origin of structure, cosmologists are concerned with observational tests of competing world models. Primordial chemistry may give rise to some of the earliest departures from thermodynamic equilibrium in the universe. These effects may be observable as broad-band spectroscopic distortions of the cosmic background radiation, which otherwise exhibits a nearly perfect blackbody spectrum. The chemical history of the expanding universe is followed through a detailed calculation of the evolution of the abundances of H, H+, H-, H2, H2+, H3+, and other minor species. It is shown that continuous absorption by the small concentration of H- can produce a distortion in the cosmic background spectrum with a maximum at a frequency near nu/c = 9 cm-1 (wavelength 1.1 mm). The predicted effect lies only a factor of 5 below current limits. Its detection would provide an important test of our understanding of the recombination epoch of the universe.",
                    "score": 0.8353111147880554
                },
                {
                    "id": 9667532,
                    "contents": "Physics.\nFrom massive quarks deep in the hearts of atomic nuclei to the catastrophic collapse of giant stars in the farthest reaches of the universe, from the partial realization of Einstein's dream of a unified theory of the forces of nature to the most practical applications in technology, medicine, and throughout contemporary society, physics continues to have a profound impact on man's view of the universe and on the quality of life. The author argues that the past few years, in terms of new discoveries, new insight-and the new questions-have been among the most productive in the history of the field and puts into context his selection of some of the most important new developments in this fundamental science.",
                    "score": 0.8350613117218018
                },
                {
                    "id": 4888650,
                    "contents": "The nu(1) + nu(5) Band of HCCN: Determination of the nu(5) Vibrational Energy.\nThe high-resolution infrared spectrum of HCCN in the region 3323-3383 cm(-1) was observed by infrared kinetic spectroscopy. The band observed is assigned as nu(1) + nu(5) of the quasilinear molecule HCCN with its origin at 3355.500(2) cm(-1). Combining this number with the band origin of the previously investigated nu(1) + nu(5) - nu(5) spectrum, the energy of the lowest excited state with angular momentum about the a axis, nu(5), is determined to be 128.907(2) cm(-1). This value is lower than the results obtained by means of relative intensity measurements on the millimeter-wave spectra (145 +/- 15 cm(-1)) or from similar relative intensity measurements on the IR spectra (187 +/- 20 cm(-1)). The present value of the energy of nu(5) predicts a barrier to linearity of 300 cm(-1) similar to 280 cm(-1) obtained from the corresponding band of DCCN and comparable to 277 cm(-1) from the quantum chemistry calculation by Seidl and Schaefer [J. Chem. Phys. 96, 4449-4452 (1992)]. Copyright 1999 Academic Press.",
                    "score": 0.834504246711731
                },
                {
                    "id": 17922043,
                    "contents": "New Measurement of the 1S-3S Transition Frequency of Hydrogen: Contribution to the Proton Charge Radius Puzzle.\nWe present a new measurement of the 1S-3S two-photon transition frequency of hydrogen, realized with a continuous-wave excitation laser at 205 nm on a room-temperature atomic beam, with a relative uncertainty of 9×10^{-13}. The proton charge radius deduced from this measurement, r_{p}=0.877(13)  fm, is in very good agreement with the current CODATA-recommended value. This result contributes to the ongoing search to solve the proton charge radius puzzle, which arose from a discrepancy between the CODATA value and a more precise determination of r_{p} from muonic hydrogen spectroscopy.",
                    "score": 0.8344248533248901
                }
            ],
            "metric_score": {
                "retrieval_recall": 1,
                "retrieval_precision": 0.4
            }
        }
    },
    {
        "id": "test_10",
        "question": "A helium-neon laser (used in supermarket scanners) emits light at $632.8 \\mathrm{~nm}$. Calculate the frequency of this light.",
        "golden_answers": [
            " 4.738"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 5718426,
                    "contents": "Laser physics and physiology.\nLaser light begins when an excited and unstable electron moves from its unstable state back to a more stable state producing energy in the form of a photon. Laser light is coherent which means that the light waves move in phase together in space and time. Laser light is monochromatic which means it is comprised of only one color or wavelength. Laser light is also collimated which means it is perfectly parallel and travels in a single direction with very little divergence. Medical lasers fall in the infrared and visible as well as ultraviolet portion of the electromagnetic spectrum and are available at different wavelengths. The wavelength of each laser partially determines the effect it will have on tissue. A specific wavelength or color can be used to selectively target a specific tissue such as hemoglobin, water, or melanin. Heat is produced by the laser, destroying the targeted tissues.",
                    "score": 0.8519514203071594
                },
                {
                    "id": 10672785,
                    "contents": "The rise of the laser. Interview by Joerg Heber.\nIt was the realization of semiconductor lasers that led to the commercial success of lasers. Herbert Kroemer explains to Nature Materials his contributions to the design principle of these lasers, for which he shared the 2000 Nobel Prize in Physics.",
                    "score": 0.8408508896827698
                },
                {
                    "id": 6195826,
                    "contents": "[Characteristics of laser light].\nLaser is one of the greatest technical discoveries of the 20th century. It is important in basic sciences, but particularly in diagnosis and therapy of various pathologic conditions of human organism. It is electromagnetic radiation, not X-irradiation and, as such, it is not expected to produce new generation of iatrogenic malignancies. Laser falls between infrared and ultraviolet on the spectrum mainly in the visible light spectrum. Properties of laser light are: monochromacity (the same color), coherence (all of the light waves are in phase both spatially and temporally), collimation (all rays are parallel to each other and do not diverge significantly even over long distances). Lasers were first conceived by Einstein in 1917 when he wrote his \"Zur Quantum Theorie der Strahlung\" (the quantum theory of radiation) which enumerated concepts of stimulated and spontaneous emission and absorption. Drs. Arthur Schawlow and Charles Townes, in 1956, extended lasers into the optical frequency range and Maiman, in 1960, operated the first laser using ruby as the active medium (ruby laser). Laser is an acronym for Light Amplification by Stimulated Emission of Radiation. To understand the acronym, it is necessary to understand the basic physics of the atom. However, if the atom that is in the excited state is struck by another photon of energy before it returns to the ground state, two photons of equal frequency and energy, travelling in the same direction and in perfect spatial and temporal harmony, are produced. This phenomenon is termed stimulated emission of radiation. An external power source hyperexcites the atoms in the laser medium so that the number of atoms possessing upper energy levels exceeds the number of atoms in a power energy level, a condition termed a population inversion. This \"pumping system\" which imparts additional energy to the atoms may be optical, mechanical, or chemical. These atoms in a hyperexcited state spontaneously emit photons of light. The laser chamber or optical cavity contains an active lasing medium which usually determines the name of each laser. There are four types of lasing material commonly employed. Solid state lasers use a solid matrix material such as a ruby crystal. Gas lasers use a gas or mixture of gases such as helium, argon, and CO2. Dye lasers employ a complex organic dye in liquid solution or suspension such as rhodamine. Semiconductor lasers use two layers of semiconductor substances such as gallium arsenide.",
                    "score": 0.8353809118270874
                },
                {
                    "id": 10185904,
                    "contents": "A short history of laser development.\nHalf a century has passed since Theodore Maiman's small ruby rod crossed the threshold of laser emission. The breakthrough demonstration earned headlines, but in the early years the laser was called \"a solution looking for a problem,\" and there was a germ of truth in the joke. Years of development since then have vastly improved laser performance,and tremendously increased their variety, earning lasers important roles in scientific research, consumer products, telecommunications,engineering, medicine, materials working, and a host of other applications. This article reviews the highlights of those developments and puts them into context, showing how laser technology has evolved to meet application requirements.",
                    "score": 0.8346590399742126
                },
                {
                    "id": 5586578,
                    "contents": "Laser light: waves of the future.\nThe use of lasers is becoming more prevalent in the health care arena. Lasers can perform functions from lightening spider veins to correcting nearsightedness. Nurses must become familiar with lasers as 21st century medicine becomes a reality.",
                    "score": 0.8319027423858643
                },
                {
                    "id": 993219,
                    "contents": "[General principles and applications of the laser].\nThis article defins the laser radiation, compares it with the sunlight and studies its production, describing the general principles of the laser. The different types of lasers are considered as well as their respectives applications which derive from the four ways of tissues interactions: photothermical, photochemical, photophysical and photobiological. A three laser system (CO2 laser, Helium-Neon laser and Argon laser) is proposed to the dental surgeon.",
                    "score": 0.8318384289741516
                },
                {
                    "id": 9699417,
                    "contents": "Some emerging applications of lasers.\nNew laser applications are emerging in almost every field of science. Many of them show both a high degree of technical sophistication and broad practical utility. The progress being made is illustrated by specific applications in three areas: laser microchemistry, optical disk data storage, and remote sensing.",
                    "score": 0.8313143253326416
                },
                {
                    "id": 10185905,
                    "contents": "Lasers: the first fifty years.\nThis year marks the 50th anniversary of the invention of the laser. The Optical Society of America is publishing this feature issue to celebrate this auspicious birthday.",
                    "score": 0.830335795879364
                },
                {
                    "id": 6356493,
                    "contents": "Principles of lasers.\nThe physics of lasers is described: a laser is light amplication by stimulation of emitted radiation. The laser beam is monochromatic, highly collimated, and delivers very high energy.",
                    "score": 0.8281533122062683
                },
                {
                    "id": 5259793,
                    "contents": "Introduction to concepts in laser technology for glucose monitoring.\nLasers are important tools in many diabetes-related applications, both diagnostic and therapeutic. Despite its wide range of uses, the laser derives all of its advantages over more conventional light sources from a few basic principles. A brief introduction to the fundamental properties of lasers emphasizes these points and suggests ways in which they can be exploited in experiments. Short descriptions of particular laser-based methods for monitoring glucose and related molecules provide introductions to research articles on these subjects.",
                    "score": 0.8262155055999756
                },
                {
                    "id": 11441586,
                    "contents": "Chemical lasers: a comprehensive literature survey.\nA bibliography of chemical laser publications covering the period 1964 through 1971 has been compiled. The chronologically listed references are followed by tables showing the chemical systems exhibiting laser action and by an alphabetical author index.",
                    "score": 0.8256902694702148
                },
                {
                    "id": 4040514,
                    "contents": "The medical laser: an indispensable tool of the physician and surgeon.\nThe enormous proliferation of developments in the field of lasers has brought many changes and improvements to medicine. Lasers generate electromagnetic radiation unique in nature: Their light is coherent, collimated, and monochromatic. Because of these qualities, laser rays can be focused to very small spots of enormous power density. The wavelengths produced by a particular type of laser are determined by the characteristic energy levels of the emitting elements in the laser medium. The wavelengths of lasers currently used in therapy and surgery range from about 400 nm to 10,600 nm; at surgical power densities and at these wavelengths, because photonic ionization of atoms does not take place, laser rays are not oncogenic. Lasers can be used for converting radiant energy into heat in living tissues, for stimulating or moderating chemical reactions, or for mechanically disrupting histologic structure. Argon-ion, carbon dioxide, helium-neon, neodymium-doped yttrium-aluminum-garnet, ruby, organic-dye, and krypton-ion lasers are frequently used in medicine for therapeutic, analytical, or surgical applications. Laser use in medicine will increase as new developments bring forth new applications.",
                    "score": 0.825272798538208
                },
                {
                    "id": 6412205,
                    "contents": "Photons, physiatrics, and physicians: a practical guide to understanding laser light interaction with living tissue, part I.\nIn the past 32 years, lasers have progressed from interesting curiosities to important instruments in medicine and surgery, with a wide variety of wavelengths and medical-surgical applications.  Today's physician is faced with a bewildering array of laser types, each touted by its manufacturer as the ultimate surgical tool.  This article sets forth in simple, understandable prose, the basic principles of the interaction of laser light with living tissue, so that the physician can decide which type of laser is best suited to a given application, without relying on the manufacturer's sales literature.  The topics discussed are the nature of light; reflection, absorption, scattering, and attenuation in living tissue; physical processes by which laser light destroys tissue; relative importance of the three unique properties of laser light in surgery and therapy; temporal modes of lasers; means of delivering laser beams to their targets; and considerations in the selection of laser systems.",
                    "score": 0.82393479347229
                },
                {
                    "id": 9757157,
                    "contents": "[Theory of lasers and lamps].\nLasers emit a coherent and monochromatic light beam, whereas pulsed lights produce a polychromatic light whose bandwidth is selected by adapted filters. The skin's chromophores are made up of water, hemoglobin, and melanin, to which must be added the exogenous pigments of tattoos. Each chromophore has its specific absorption spectrum. Lasers' main mechanisms of action are the photothermal effect and the photomechanical effect.",
                    "score": 0.8236769437789917
                },
                {
                    "id": 8170886,
                    "contents": "[Theory of lasers and lamps].\nLasers emit a coherent and monochromatic light beam, whereas pulsed lights produce a polychromatic light whose bandwidth is selected by adapted filters. The skin's chromophores are made up of water, hemoglobin, and melanin, to which must be added the exogenous pigments of tattoos. Each chromophore has its specific absorption spectrum. Lasers' main mechanisms of action are the photothermal effect and the photomechanical effect.",
                    "score": 0.8236769437789917
                },
                {
                    "id": 18435926,
                    "contents": "Publisher Correction: Measurement of the emission spectrum of a semiconductor laser using laser-feedback interferometry.\nA correction to this article has been published and is linked from the HTML and PDF versions of this paper. The error has been fixed in the paper.",
                    "score": 0.8235810399055481
                },
                {
                    "id": 4775882,
                    "contents": "[Lasers in medicine].\nLaser systems are widely spread in the field of medicine. The applications are divided into therapeutical and diagnostic applications. The main field however are therapeutical procedures. Depending on the indication lasers were used for removing and cutting of smooth and hard tissue or for coagulation. A relative new procedure is the photodynamic therapy. Substances--mostly dyes--are applied to the body and stay for a certain time in tumorous tissue. After an interval it is possible to irradiate this tissue. Only the cells with the incorporated substances react with a cell death.",
                    "score": 0.8232908844947815
                },
                {
                    "id": 9573783,
                    "contents": "MATERIALS SCIENCE: Long-Wavelength Lasers Sniff Out New Uses.\nJust a few weeks after two physicists won the Nobel Prize for figuring out how to make lasers out of semiconductors, researchers announced that they have made those lasers much more useful. A new technique permits the lasers to shine light in regions of the infrared spectrum previously inaccessible to similar devices. The advance may open the door to cheap devices to sniff explosives and other robotic sensors.",
                    "score": 0.8229946494102478
                },
                {
                    "id": 3623447,
                    "contents": "Absorbance measurement with a helium-neon laser for chemical dosimetry.\nA laser-based system for absorbance measurement has been developed for use in chemical dosimetry as an alternative to the spectrophotometer. The system incorporating a Helium-Neon laser operating at 543.5 nm is designed specifically for measurement of absorbed doses below 10 Gy with the ferrous sulphate-benzoic acid-xylenol orange (FBX) dosimeter. Absorbance measurement for the FBX dosimeter is normally carried out at 540 nm with a spectrophotometer. The performance of the laser-based system in measurement of absorbance is comparable to that of a standard spectrophotometer and it is concluded that the absorbance measurement technique is not the limiting factor in the sensitivity of the FBX dosimeter for absorbed doses below 1 Gy.",
                    "score": 0.822598934173584
                },
                {
                    "id": 11432652,
                    "contents": "Laser-millimeter wave techniques.\nThe use of millimeter techniques with lasers has resulted in the stabilization of a laser to an absolute frequency standard. Also, a high resolution infrared spectrometer with the characteristics of a microwave spectrometer has been developed.",
                    "score": 0.8223262429237366
                },
                {
                    "id": 7757991,
                    "contents": "Absolute wavelength calibration of pulsed lasers by use of machine vision.\nWe developed a new absolute wavelength calibration system that uses machine vision for measurement of low-repetition-rate, short-pulse-duration (10-Hz, 5-ns) tunable lasers. Weak fluorescence from an iodine cell was measured by use of machine vision as a spatially gated integrator, and a pulsed dye-laser wavelength was calibrated with an accuracy of +/-0.005 nm , which is precise enough for differential absorption lidar application.",
                    "score": 0.822150468826294
                },
                {
                    "id": 3630053,
                    "contents": "Lasers in medicine--a review.\nLaser systems permit very high energy radiation of a single wavelength to be focused on a tiny spot, and have found application in many areas of engineering. They are also currently used in many branches of medicine. The fields reviewed here are ophthalmology, gynaecology, dermatology, otolaryngology, gastroenterology and physiotherapy. Lasers which are in wide use for medical applications include argon, YAG and carbon dioxide types. In many areas, lasers have been found to be more effective than conventional treatment methods with advantages including less blood loss, more accurate removal of unwanted tissue, shorter operating time and less postoperative pain. It is expected that the next decade will see the laser as an everyday tool in many more medical applications.",
                    "score": 0.8221068382263184
                },
                {
                    "id": 12069968,
                    "contents": "[Application of mid-infrared wavelength tunable laser in glucose determination].\nThe authors proposed a method of control and stabilization for laser emission wavelengths and power, and presented the mid-infrared wavelength tunable laser with broad emission spectrum band of 9.19-9.77 microm, half wave width of 4 cm(-1), spectral resolution of 2.7 x 10(4) and max power of 800 mW with fluctuation &lt; 0.8% in the present paper. The tunable laser was employed as the light source in combination with ATR sensor for glucose measurement in PBS solution. In our experiments, absorbance at the five laser emission wavelengths, including 1 081, 1 076, 1 051, 1 041 and 1 037 cm(-1) in the 9R and 9P band of the laser emission spectrum, all correlates well with the glucose concentration (R2 &gt; 0.99, SD &lt; 0.0004, P &lt; 0.000 1). Especially, the sensitivity of this laser spectroscopy system is about 4 times as high as that of traditional FTIR spectrometer.",
                    "score": 0.8211979269981384
                },
                {
                    "id": 21807412,
                    "contents": "Cost-efficient open source laser engine for microscopy.\nScientific-grade lasers are costly components of modern microscopes. For high-power applications, such as single-molecule localization microscopy, their price can become prohibitive. Here, we present an open-source high-power laser engine that can be built for a fraction of the cost. It uses affordable, yet powerful laser diodes at wavelengths of 405 nm, 488 nm and 638 nm and optionally a 561 nm diode-pumped solid-state laser. The light is delivered to the microscope via an agitated multimode fiber in order to suppress speckles. We provide the parts list, CAD files and detailed descriptions, allowing any research group to build their own laser engine.",
                    "score": 0.8187000751495361
                },
                {
                    "id": 11419952,
                    "contents": "Stable single-frequency he-ne laser.\nA simple single-frequency He-Ne laser is described in which the cavity ength is designed to be of high stability. The components are precision-made by standard workshop methods so that the laser requires no adjustments after assembly and the reflectors and capillary plasma tube are readily replaceable. Over a period of hours, frequency stability was within 0.01 ppm, with the krypton-86 primary wavelength standard as reference.",
                    "score": 0.8171966671943665
                },
                {
                    "id": 10672783,
                    "contents": "Fifty brilliant years.\nThe first demonstration of the laser has not only led to a myriad of commercial applications, but fifty years on basic research continues to rejuvenate the fundamental physics of the laser.",
                    "score": 0.8171283006668091
                },
                {
                    "id": 11442011,
                    "contents": "Dye Lasers--a Classified Bibliography 1966-1972.\nA bibliography of dye lasers has been compiled starting with the year 1966, when the first definitive report of a dye laser was published by Sorokin et al., and continuing through 1972.",
                    "score": 0.8170851469039917
                },
                {
                    "id": 1797332,
                    "contents": "The clinical use of laser-excited fluorometry.\nMany areas of spectroscopy have benefited from the use of laser radiation sources. I present a discussion of the basic properties of the laser and how these properties can be advantageous when laser excitation is used in fluorometry. Although the laser has not yet been accepted as a routine instrument in the clinical laboratory, its unique properties have rendered it useful in several analytical methodologies that are based on fluorometry and used in the clinical or biological fields. Accordingly, I briefly review the practical aspects of some clinical applications of laser-excited fluorometry.",
                    "score": 0.8170119524002075
                },
                {
                    "id": 9013519,
                    "contents": "The excimer lasers.\nThe excimer lasers are a group of lasers that have found wide application in a variety of medical fields including dermatology, cardiology, ophthalmology, and orthopedics. The word excimer refers to excited dimer. These lasers operate in the ultraviolet range, and examples include the 193 nm argon-fluroide, 248 nm krypton-fluoride, 351 nm xenon-fluoride, and of particular interest to dermatology, the 308 nm xenon-chloride. These lasers utilize a mixture of a noble gas and a halogen as a lasing material. They were first used in medicine for their ability to produce cold tissue ablation, but more recently have been used in dermatology as a method of non-ablative phototherapy.",
                    "score": 0.8168139457702637
                },
                {
                    "id": 11845624,
                    "contents": "Photochemistry: role of lasers.\nThis Technology editorial originally appeared in the Business Section of The New York Times, 21 May edition. It is reprinted here by permission.",
                    "score": 0.8165189623832703
                },
                {
                    "id": 1391647,
                    "contents": "Laser medical instrumentation.\nIn spite of inadequate budgets, significant research and development studies have been made on laser medical instrumentation applications for both diagnosis and treatment. Diagnostic instrumentation includes the laser microprobe for cation microanalyses, cytofluorometry, interferometry, transillumination, holography and acoustical holography, and communications and information handling. Laser investigative surgical instrumentation includes lasers of argon, carbon dioxide, neodymium-YAG, and ruby, which are used as optical scalpels. Advantages of laser surgical instrumentation include precision, color absorption for lasers in the visible light range, and hemostasis.",
                    "score": 0.8164017200469971
                },
                {
                    "id": 7047980,
                    "contents": "Applications for nuclear phenomena generated by ultra-intense lasers.\nThe amplification of laser light to generate powers large enough to affect the nucleus has been the desire of scientists since the invention of the laser 40 years ago. Many lasers, including tabletop varieties, now have pulse powers greater than the electrical power generated by all the world's power plants combined. When this power is focused to dimensions of a few microns, laser-driven nuclear phenomena can occur. Here we review the developments in this research field and describe the potential of laser produced proton, neutron, and heavy ion beams, together with isotope and isomer production.",
                    "score": 0.8162072896957397
                },
                {
                    "id": 16672603,
                    "contents": "Mid-infrared laser-spectroscopic sensing of chemical species.\nThis letter reports on mid-infrared laser-based detection and analysis of chemical species. Emphasis is put on broadly tunable laser sources and sensitive detection schemes. Selected examples from our lab illustrate the performance and potential of such systems in various areas including environmental and medical sensing. ",
                    "score": 0.8157918453216553
                },
                {
                    "id": 3502530,
                    "contents": "Laser-induced fluorescence spectroscopy.\nLasers have been a part of medicine and surgery since the late 1960s. In the past 5 years, however, there has been growing interest in using lasers as diagnostic devices, an area of research that has been termed optical diagnostics. Optical diagnostic techniques seek to provide diagnostic information about tissue by using light in a probing, yet nondestructive fashion. A large number of optical methods are available to endoscopists, but to date, only laser-induced fluorescence has been investigated in any detail.",
                    "score": 0.8148625493049622
                },
                {
                    "id": 13940746,
                    "contents": "Intense pulsed light.\nIn addition to lasers, intense pulsed light (IPL) sources are widely used in medicine to treat various indications, such as vascular lesions, irregular pigmentation and hypertrichosis. In contrast to lasers, IPL systems are broadband flash lamps that emit polychromatic incoherent light ranging from visible to infrared (500-1,300 nm). Optical filters are used to tailor the polychromatic light to specific needs. As a broad range of wavelengths are delivered, treatment of multiple chromophores--including melanin, hemoglobin, water and collagen--within the same exposure is possible.",
                    "score": 0.8142417669296265
                },
                {
                    "id": 929380,
                    "contents": "[The use of lasers in medicine].\nThe paper provides information concerning basic types of lasers used in medicine. Their most frequent indications are summarized and advantages of single types of apparatus are described.",
                    "score": 0.8134818077087402
                },
                {
                    "id": 9961023,
                    "contents": "Laser probe excitation in spectrochemical analysis.I: characteristics of the source.\nA modified laser probe for spectrochemical analysis is described. A high energy laser beam is focused onto a specimen to vaporize a sample from a small area, and the vapor thus formed is further excited by a spark discharge. The characteristics of emission spectra with and without auxiliary spark excitation are compared. Spectrograph illuminating systems for qualitative and quantitative analysis were investigated. Some difficulties were encountered with the laser probe, and modifications were made to the instrument to alleviate some of these problems. Some typical analytical applications are discussed.",
                    "score": 0.813190221786499
                },
                {
                    "id": 716287,
                    "contents": "Lasers in dermatology.\nA laser is a device that produces a parallel bundle of photons of equal wavelength that are temporally and spacially in phase. The laser light can be focused to produce high energy in very small spots. The pulsed dye laser, the argon laser and the carbon dioxide laser are commonly used in dermatology. The pulsed dye laser and the argon laser are especially effective for cutaneous vascular lesions such as port-wine hemangiomas. It is important for the physician to be knowledgeable about laser-tissue interaction and laser safety to avoid laser accidents.",
                    "score": 0.812411904335022
                },
                {
                    "id": 14149539,
                    "contents": "Current trends in intense pulsed light.\nIntense pulsed light technologies have evolved significantly since their introduction to the medical community 20 years ago. Now such devices can be used safely and effectively for the cosmetic treatment of many vascular lesions, unwanted hair, and pigmented lesions. Newer technologies often give results equal to those of laser treatments.",
                    "score": 0.8118600845336914
                },
                {
                    "id": 10549448,
                    "contents": "[Lasers: principles, characteristics and tissue interactions].\nSince their appearance in 1960, lasers have been considered useful light sources for medical applications. Laser light is monochromatic, the bundle is parallel and can be directed and focussed, as a result of which very high energy densities can be achieved. Several applications in dentistry have been investigated over the past decades. This article describes the physics behind lasers, the characteristics of the laser beam and overviews the laser wavelengths currently used in dentistry. The different interactions between the laser beam and the target are explained.",
                    "score": 0.8117362260818481
                },
                {
                    "id": 2850103,
                    "contents": "Low-power lasers in medicine. A report by the Australian Health Technology Advisory Committee (AHTAC) June 1994.\nLow-power lasers are those that deliver an output power in the milliwatt (mW) range. Output is typically between 1 and 30 mW, but can be up to 100 mW; It has been suggested that low power lasers cause biostimulation--a photochemical response to laser light inducing biochemical alterations in cells. However, there is no universally agreed theory to explain the mechanism of the claimed effects of treatment; The wavelengths, treatment protocols and conditions to be treated are not established; Low-power lasers are in widespread use for the treatment, in the main, of a range of musculoskeletal problems, despite little published evidence of efficacy; Evidence from controlled trials is inconclusive and conflicting; The Australian Health Technology Advisory Committee considers that the efficacy of low-power lasers in the treatment of musculoskeletal and other conditions is not established. The Committee therefore recommends that; those who use this technology should take steps to obtain unequivocal evidence of benefit from appropriately designed and conducted trials; and in any clinical use of such lasers, the treatment protocols should be clearly defined.",
                    "score": 0.811693549156189
                },
                {
                    "id": 1892333,
                    "contents": "Lasers for use in medicine.\nDuring the last quarter century the use of directed energy from lasers has become very important in medicine. Directed energy from lasers has been used to cut tissue, to cauterize bleeding, to drill small pressure relief holes and to selectively destroy tissue growths. In this paper lasers of interest in such applications are described and compared.",
                    "score": 0.8109915852546692
                },
                {
                    "id": 5434531,
                    "contents": "Basic laser principles.\nSkin diseases have been treated with lasers since the early 1960s. The three principal chromophores in the skin--hemoglobin, melanin, and water--have different absorption spectra that selectively absorb certain wavelengths of electromagnetic radiation. A given wavelength and pulse duration will selectively treat a target containing a chromophore. The wide variety of lasers and their applications are discussed.",
                    "score": 0.8106223940849304
                },
                {
                    "id": 962020,
                    "contents": "[Laser qualities and areas of application, current status and perspectives].\nLaser beams are used in a variety of surgical applications and promise to become even more meaning in the next years with the advent of new technology. Depending on the energy density, application time and wavelength of the laser beam, a variety of interactions takes place with tissue. Some of these are now standard procedures for cutting, welding and coagulating. Other interaction are being used experimentally in therapeutic and diagnostic procedures, e.g. stone destruction and angioplasty. Laser induced fluorescence and holography have opened a wide range of spectroscopic analysis. Raman-spectroscopy will allow respiratory gas analysis in a split second. Photoablation holds great promise for athermic cutting, angioplasty and the spectroscopic differentiation of tissue.",
                    "score": 0.8106070756912231
                },
                {
                    "id": 1197270,
                    "contents": "Medical lasers.\nIn this short article it has only been possible to outline the use of lasers in medical applications. As you will have gathered there is still a considerable amount of research and development taking place and new types of lasers are appearing all the time, many of which may prove to be clinically useful.",
                    "score": 0.8102207183837891
                },
                {
                    "id": 5553267,
                    "contents": "Laser physics and physiology.\nLaser light is a controlled, disciplined energy source that can rejuvenate skin efficiently. The carbon dioxide laser is the standard of skin rejuvenation because of its selective effect on water and skin. Understanding laser physics and tissue interaction allows the operator to use the laser effectively and safely to ablate actinic damage, wrinkles, and scars from the skin.",
                    "score": 0.8100507259368896
                },
                {
                    "id": 6386828,
                    "contents": "Laser products; amendments to performance standard--FDA. Final rule.\nThe Food and Drug Administration (FDA) is amending the performance standard for laser products to widen the wavelength range that defines laser radiation, to establish a new \"Class IIIa\" laser product, and to add new reporting and recordkeeping requirements for sales of original equipment manufacturer (OEM) components. The amendments relax the current performance requirements for safety interlocks, viewing optics, remote control connectors, emission delay, key controls, and beam attenuators. Also, the amendments simplify and make clear the protective housing requirements for any laser product, the definitions for \"human access,\" and the existing laser product classes. Additionally, FDA is modifying the requirements for certain radiation measurement parameters, scanning failure safeguards, manual reset mechanisms, and emission indicators on certain laser products. FDA's experience in administering the laser product standard has shown the need to implement these changes.",
                    "score": 0.8098950982093811
                },
                {
                    "id": 10311505,
                    "contents": "Continuously tunable laser emission from the deep ultraviolet to the near infrared generated by a single optical system.\nA two-color laser beam separated by 587 cm(-1)is focused into a Raman cell pressurized with hydrogen. More than fifty rotational and vibrational lines are generated by a four-wave mixing-assisted stimulated Raman effect. By synchronously changing the laser frequencies, the overall tuning range is extended from the deep ultraviolet (247 nm) to the near infrared (771 nm) without any frequency gaps.",
                    "score": 0.8095215559005737
                },
                {
                    "id": 9667320,
                    "contents": "Scenes from a marriage--of optics and electronics.\nBALTIMORE-Exploring the common ground between optics and electronics, more than 6800 physicists, spectroscopists, and engineers gathered here from 21 to 26 May at the joint meetings of the Conference on Lasers and Electro-Optics and the Quantum Electronics and Laser Science conference. Participants unveiled new technologies that have sprung up on this common ground, such as an imaging technique that can gauge the chemical composition of materials. They also described ways to broaden that ground, such as a novel approach for integrating lasers and silicon chips-a challenge that has slowed progress toward a new generation of high-speed computers and communications.",
                    "score": 0.8094867467880249
                },
                {
                    "id": 11262794,
                    "contents": "Generating green to red light with semiconductor lasers.\nDiode lasers enable one to continuously cover the 730 to 1100 nm range as well as the 370 to 550 nm range by frequency doubling, but a large part of the electro-magnetic spectrum spanning from green to red remains accessible only through expensive and unpractical optically pumped dye lasers. Here we devise a method to multiply the frequency of optical waves by a factor 3/2 with a conversion that is phase-coherent and highly efficient. Together with harmonic generation, it will enable one to cover the visible spectrum with semiconductor lasers, opening new avenues in important fields such as laser spectroscopy and optical metrology.",
                    "score": 0.8090822100639343
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_11",
        "question": "What is the uncertainty of the momentum of an electron if we know its position is somewhere in a $10 \\mathrm{pm}$ interval?",
        "golden_answers": [
            " 6.6"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 8655685,
                    "contents": "Quasi-intrinsic angular momentum and the measurement of its spectrum.\nWe introduce the concept of quasi-intrinsic angular momentum to denote fields for which the mean value of the angular momentum is unaltered by a lateral shift of the rotation axis but the spectrum changes. This property is exemplified by the orbital angular momentum of a beam of light about its propagation direction. We propose an interferometric experiment to measure efficiently the exact angular momentum spectrum and variance for light beams with any arbitrary spatial distribution.",
                    "score": 0.8745840787887573
                },
                {
                    "id": 22649542,
                    "contents": "Uncertainty Relations in the Madelung Picture.\nMadelung showed how the complex Schrödinger equation can be rewritten in terms of two real equations, one for the phase and one for the amplitude of the complex wave function, where both equations are not independent of each other, but coupled. Although these equations formally look like classical hydrodynamic equations, they contain all the information about the quantum system. Concerning the quantum mechanical uncertainties of position and momentum, however, this is not so obvious at first sight. We show how these uncertainties are related to the phase and amplitude of the wave function in position and momentum space and, particularly, that the contribution from the phase essentially depends on the position-momentum correlations. This will be illustrated explicitly using generalized coherent states as examples.",
                    "score": 0.8729116916656494
                },
                {
                    "id": 10402805,
                    "contents": "Position measurements obeying momentum conservation.\nWe present a hitherto unknown fundamental limitation to a basic measurement: that of the position of a quantum object when the total momentum of the object and apparatus is conserved. This result extends the famous Wigner-Araki-Yanase theorem, and shows that accurate position measurements are only practically feasible if there is a large momentum uncertainty in the apparatus.",
                    "score": 0.8696631789207458
                },
                {
                    "id": 15687851,
                    "contents": "Is the angular momentum of an electron conserved in a uniform magnetic field?\nWe show that an electron moving in a uniform magnetic field possesses a time-varying \"diamagnetic\" angular momentum. Surprisingly this means that the kinetic angular momentum of the electron may vary with time, despite the rotational symmetry of the system. This apparent violation of angular momentum conservation is resolved by including the angular momentum of the surrounding fields. ",
                    "score": 0.8696234226226807
                },
                {
                    "id": 19141140,
                    "contents": "Publisher Correction: Electron momentum densities near Dirac cones: Anisotropic Umklapp scattering and momentum broadening.\nA correction to this article has been published and is linked from the HTML version of this paper. The error has been fixed in the paper.",
                    "score": 0.8629879951477051
                },
                {
                    "id": 20136645,
                    "contents": "Time-dependent momentum expectation values from different quantum probability and flux densities.\nBased on the Ehrenfest theorem, the time-dependent expectation value of a momentum operator can be evaluated equivalently in two ways. The integrals appearing in the expressions are taken over two different functions. In one case, the integrand is the quantum mechanical flux density j̲, and in the other, a different quantity j̲̃ appears, which also has the units of a flux density. The quantum flux density j̲ is related to the probability density ρ via the continuity equation, and j̲̃ may as well be used to define a density ρ̃ that fulfills a continuity equation. Employing a model for the coupled dynamics of an electron and a proton, we document the properties of the densities and flux densities. It is shown that although the mean momentum derived from the two quantities is identical, the various functions exhibit a very different coordinate and time-dependence. In particular, it is found that the flux density j̲̃ directly monitors temporal changes in the probability density, and the density ρ̃ carries information about wave packet dispersion occurring in different spatial directions.",
                    "score": 0.8610702157020569
                },
                {
                    "id": 11440558,
                    "contents": "The enigma of optical momentum in a medium.\nIt is 100 years since Minkowski and Abraham first gave rival expressions for the momentum of light in a material medium. At the single-photon level, these correspond, respectively, either to multiplying or dividing the free-space value (symbol:see text) by the refractive index (n). The debate that this work started has continued till the present day, punctuated by the occasional publication of 'decisive' experimental demonstrations supporting one or other of these values. We review the compelling arguments made in support of the Minkowski and Abraham forms and are led to the conclusion that both momenta are correct. We explain why two distinct momenta are needed to describe light in a medium and why each appears as the natural, and experimentally observed, momentum in appropriate situations.",
                    "score": 0.8586488962173462
                },
                {
                    "id": 10962019,
                    "contents": "Resolution of the abraham-minkowski dilemma.\nThe dilemma of identifying the correct form for the momentum of light in a medium has run for a century and has been informed by many distinguished contributions, both theoretical and experimental. We show that both the Abraham and Minkowski forms of the momentum density are correct, with the former being the kinetic momentum and the latter the canonical momentum. This identification allows us to explain why the experiments supporting each of the rival momenta gave the results that they did. The inclusion of dispersion and absorption provides an interesting subtlety, but does not change our conclusion.",
                    "score": 0.857429027557373
                },
                {
                    "id": 9667893,
                    "contents": "One hundred years of quantum physics.\nThis year marks the 100th anniversary of Max Planck's creation of the quantum concept, an idea so revolutionary that it took nearly 30 years for scientists to develop it into the theory that has transformed the way scientists view reality. In this month's essay, Daniel Kleppner and Roman Jackiw recount how quantum theory, which they rate as \"the most precisely tested and most successful theory in the history of science,\" came to be, how it changed the world, and how it might continue to evolve to make the dream of ultimate understanding of the universe come true.",
                    "score": 0.8571916222572327
                },
                {
                    "id": 20827820,
                    "contents": "Retrodiction beyond the Heisenberg uncertainty relation.\nIn quantum mechanics, the Heisenberg uncertainty relation presents an ultimate limit to the precision by which one can predict the outcome of position and momentum measurements on a particle. Heisenberg explicitly stated this relation for the prediction of \"hypothetical future measurements\", and it does not describe the situation where knowledge is available about the system both earlier and later than the time of the measurement. Here, we study what happens under such circumstances with an atomic ensemble containing 10<sup11</sup rubidium atoms, initiated nearly in the ground state in the presence of a magnetic field. The collective spin observables of the atoms are then well described by canonical position and momentum observables, [Formula: see text] and [Formula: see text] that satisfy [Formula: see text]. Quantum non-demolition measurements of [Formula: see text] before and of [Formula: see text] after time t allow precise estimates of both observables at time t. By means of the past quantum state formalism, we demonstrate that outcomes of measurements of both the [Formula: see text] and [Formula: see text] observables can be inferred with errors below the standard quantum limit. The capability of assigning precise values to multiple observables and to observe their variation during physical processes may have implications in quantum state estimation and sensing.",
                    "score": 0.8535681962966919
                },
                {
                    "id": 12752651,
                    "contents": "Proof of Heisenberg's error-disturbance relation.\nWhile the slogan \"no measurement without disturbance\" has established itself under the name of the Heisenberg effect in the consciousness of the scientifically interested public, a precise statement of this fundamental feature of the quantum world has remained elusive, and serious attempts at rigorous formulations of it as a consequence of quantum theory have led to seemingly conflicting preliminary results. Here we show that despite recent claims to the contrary [L. Rozema et al, Phys. Rev. Lett. 109, 100404 (2012)], Heisenberg-type inequalities can be proven that describe a tradeoff between the precision of a position measurement and the necessary resulting disturbance of momentum (and vice versa). More generally, these inequalities are instances of an uncertainty relation for the imprecisions of any joint measurement of position and momentum. Measures of error and disturbance are here defined as figures of merit characteristic of measuring devices. As such they are state independent, each giving worst-case estimates across all states, in contrast to previous work that is concerned with the relationship between error and disturbance in an individual state.",
                    "score": 0.8532354831695557
                },
                {
                    "id": 18169901,
                    "contents": "A catalogue of hidden momenta.\nElectromagnetic fields carry momentum: [Formula: see text] But if the centre of energy of a (localized) system is at rest, its <itotal</i momentum must be zero. The compensating term has come to be called 'hidden' momentum: <bP</b <subh</sub =  - <bP</b <subem</sub It is (typically) ordinary <imechanical</i momentum, relativistic in nature, and is 'hidden' only in the sense that it is not associated with motion of the system as a whole-only with that of its constituent parts. This article develops a catalogue of field momenta and hidden momenta for ideal electric and magnetic dipoles-both the 'standard' variety made from electric charges and currents and the 'anomalous' variety made from hypothetical magnetic monopoles and their currents-in the presence of electric and magnetic fields (which themselves may be produced by 'standard' or 'anomalous' sources).This article is part of the theme issue 'Celebrating 125 years of Oliver Heaviside's 'Electromagnetic Theory''.",
                    "score": 0.8530750274658203
                },
                {
                    "id": 14055935,
                    "contents": "Uncertainty in quantum mechanics: faith or fantasy?\nThe word 'uncertainty', in the context of quantum mechanics, usually evokes an impression of an essential unknowability of what might actually be going on at the quantum level of activity, as is made explicit in Heisenberg's uncertainty principle, and in the fact that the theory normally provides only probabilities for the results of quantum measurement. These issues limit our ultimate understanding of the behaviour of things, if we take quantum mechanics to represent an absolute truth. But they do not cause us to put that very 'truth' into question. This article addresses the issue of quantum 'uncertainty' from a different perspective, raising the question of whether this term might be applied to the theory itself, despite its unrefuted huge success over an enormously diverse range of observed phenomena. There are, indeed, seeming internal contradictions in the theory that lead us to infer that a total faith in it at all levels of scale leads us to almost fantastical implications.",
                    "score": 0.852287769317627
                },
                {
                    "id": 14749013,
                    "contents": "Analogies between optical and quantum mechanical angular momentum.\nThe insight that a beam of light can carry orbital angular momentum (AM) in its propagation direction came up in 1992 as a surprise. Nevertheless, the existence of momentum and AM of an electromagnetic field has been well known since the days of Maxwell. We compare the expressions for densities of AM in general three-dimensional modes and in paraxial modes. Despite their classical nature, these expressions have a suggestive quantum mechanical appearance, in terms of linear operators acting on mode functions. In addition, paraxial wave optics has several analogies with real quantum mechanics, both with the wave function of a free quantum particle and with a quantum harmonic oscillator. We discuss how these analogies can be applied.This article is part of the themed issue 'Optical orbital angular momentum'.",
                    "score": 0.8518756031990051
                },
                {
                    "id": 18377746,
                    "contents": "Experimental Demonstration of Uncertainty Relations for the Triple Components of Angular Momentum.\nThe uncertainty principle is considered to be one of the most striking features in quantum mechanics. In the textbook literature, uncertainty relations usually refer to the preparation uncertainty which imposes a limitation on the spread of measurement outcomes for a pair of noncommuting observables. In this work, we study the preparation uncertainty for the angular momentum, especially for spin-1/2. We derive uncertainty relations encompassing the triple components of angular momentum and show that, compared with the relations involving only two components, a triple constant 2/sqrt[3] often arises. Intriguingly, this constant is the same for the position and momentum case. Experimental verification is carried out on a single spin in diamond, and the results confirm the triple constant in a wide range of experimental parameters.",
                    "score": 0.8499066233634949
                },
                {
                    "id": 14094154,
                    "contents": "Trouble with the Lorentz law of force: incompatibility with special relativity and momentum conservation.\nThe Lorentz law of force is the fifth pillar of classical electrodynamics, the other four being Maxwell's macroscopic equations. The Lorentz law is the universal expression of the force exerted by electromagnetic fields on a volume containing a distribution of electrical charges and currents. If electric and magnetic dipoles also happen to be present in a material medium, they are traditionally treated by expressing the corresponding polarization and magnetization distributions in terms of bound-charge and bound-current densities, which are subsequently added to free-charge and free-current densities, respectively. In this way, Maxwell's macroscopic equations are reduced to his microscopic equations, and the Lorentz law is expected to provide a precise expression of the electromagnetic force density on material bodies at all points in space and time. This Letter presents incontrovertible theoretical evidence of the incompatibility of the Lorentz law with the fundamental tenets of special relativity. We argue that the Lorentz law must be abandoned in favor of a more general expression of the electromagnetic force density, such as the one discovered by Einstein and Laub in 1908. Not only is the Einstein-Laub formula consistent with special relativity, it also solves the long-standing problem of \"hidden momentum\" in classical electrodynamics.",
                    "score": 0.8495433330535889
                },
                {
                    "id": 22174509,
                    "contents": "Overcoming standard quantum limit using a momentum measuring interferometer: publisher's note.\nThis publisher's note contains corrections to Opt. Lett.45, 1256 (2020)OPLEDP0146-959210.1364/OL.385092.",
                    "score": 0.8488068580627441
                },
                {
                    "id": 14749015,
                    "contents": "Orbital angular momentum: a personal memoir.\nA definitive statement of the model used to describe orbital angular momentum is essentially now available. Its early history, and the interaction of those who played key roles in its development over 20 years ago in its development, is outlined in this Memoir.This article is part of the themed issue 'Optical orbital angular momentum'.",
                    "score": 0.848789632320404
                },
                {
                    "id": 7947443,
                    "contents": "Quantum information matters.\nThis Perspective discusses the role that quantum information plays in determining the quantum-mechanical aspects of matter. Beginning with the entwined concepts of information and entropy, the article discusses how quantum information theory can supply us with novel concepts and techniques for understanding how matter behaves at the most microscopic of levels.",
                    "score": 0.8485437035560608
                },
                {
                    "id": 10654106,
                    "contents": "Action on pulse position and momentum using dispersion and phase modulation.\nThe timing jitter and frequency jitter of quantized optical pulses obey Heisenberg's uncertainty principle. We show how one jitter may be reduced at the expense of the other, using dispersion and phase modulation.",
                    "score": 0.8478411436080933
                },
                {
                    "id": 12813842,
                    "contents": "Comments on quantum probability theory.\nQuantum probability theory (QP) is the best formal representation available of the most common form of judgment involving attribute comparison (inside judgment). People are capable, however, of judgments that involve proportions over sets of instances (outside judgment). Here, the theory does not do so well. I discuss the theory both in terms of descriptive adequacy and normative appropriateness. ",
                    "score": 0.8473385572433472
                },
                {
                    "id": 12260049,
                    "contents": "Wide-angle energy-momentum spectroscopy.\nLight emission is defined by its distribution in energy, momentum, and polarization. Here, we demonstrate a method that resolves these distributions by means of wide-angle energy-momentum spectroscopy. Specifically, we image the back focal plane of a microscope objective through a Wollaston prism to obtain polarized Fourier-space momentum distributions, and disperse these two-dimensional radiation patterns through an imaging spectrograph without an entrance slit. The resulting measurements represent a convolution of individual radiation patterns at adjacent wavelengths, which can be readily deconvolved using any well-defined basis for light emission. As an illustrative example, we use this technique with the multipole basis to quantify the intrinsic emission rates for electric and magnetic dipole transitions in europium-doped yttrium oxide (Eu³⁺:Y₂O₃) and chromium-doped magnesium oxide (Cr³⁺:MgO). Once extracted, these rates allow us to reconstruct the full, polarized, two-dimensional radiation patterns at each wavelength.",
                    "score": 0.8471440076828003
                },
                {
                    "id": 11357090,
                    "contents": "On the local representation of the electronic momentum operator in atomic systems.\nThe local quantum theory is applied to the study of the momentum operator in atomic systems. Consequently, a quantum-based local momentum expression in terms of the single-electron density is determined. The limiting values of this function correctly obey two fundamental theorems: Kato's cusp condition and the Hoffmann-Ostenhof and Hoffmann-Ostenhof exponential decay. The local momentum also depicts the electron shell structure in atoms as given by its local maxima and inflection points. The integration of the electron density in a shell gives electron populations that are in agreement with the ones expected from the Periodic Table of the elements. The shell structure obtained is in agreement with the higher level of theory computations, which include the Kohn-Sham kinetic energy density. The average of the local kinetic energy associated with the local momentum is the Weizsacker kinetic energy. In conclusion, the local representation of the momentum operator provides relevant information about the electronic properties of the atom at any distance from the nucleus.",
                    "score": 0.8466676473617554
                },
                {
                    "id": 18632313,
                    "contents": "There are many ways to spin a photon: Half-quantization of a total optical angular momentum.\nThe angular momentum of light plays an important role in many areas, from optical trapping to quantum information. In the usual three-dimensional setting, the angular momentum quantum numbers of the photon are integers, in units of the Planck constant <iħ</i. We show that, in reduced dimensions, photons can have a half-integer total angular momentum. We identify a new form of total angular momentum, carried by beams of light, comprising an unequal mixture of spin and orbital contributions. We demonstrate the half-integer quantization of this total angular momentum using noise measurements. We conclude that for light, as is known for electrons, reduced dimensionality allows new forms of quantization.",
                    "score": 0.8464636206626892
                },
                {
                    "id": 22566405,
                    "contents": "Quantum Mechanics: Statistical Balance Prompts Caution in Assessing Conceptual Implications.\nThroughout quantum mechanics there is statistical balance, in the collective response of an ensemble of systems to differing measurement types. Statistical balance is a core feature of quantum mechanics, underlying quantum mechanical states, and not yet explained. The concept of \"statistical balance\" is here explored, comparing its meaning since 2019 with its original meaning in 2001. Statistical balance now refers to a feature of contexts in which: (a) there is a prescribed probability other than 0 or 1 for the collective response of an ensemble to one measurement type; and (b) the collective response of the same ensemble to another measurement type demonstrates that no well-defined value can be attributed, for the property relevant to the original measurement type, to individual members of the ensemble. In some unexplained way, the outcomes of single runs of a measurement of the original type \"balance\" each other to give an overall result in line with the prescribed probability. Unexplained statistical balance prompts caution in assessing the conceptual implications of entanglement, measurement, uncertainty, and two-slit and Bell-type analyses. Physicists have a responsibility to the wider population to be conceptually precise about quantum mechanics, and to make clear that many possible conceptual implications are uncertain.",
                    "score": 0.8460772037506104
                },
                {
                    "id": 23880271,
                    "contents": "Erratum: Elastic Orbital Angular Momentum [Phys. Rev. Lett. 128, 064301 (2022)].\nThis corrects the article DOI: 10.1103/PhysRevLett.128.064301.",
                    "score": 0.8447994589805603
                },
                {
                    "id": 15586619,
                    "contents": "Physics, philosophy, and the nature of reality.\nBoth science and philosophy have been characterized as seeking to understand the nature of reality. They are sometimes even pitted against each other, suggesting that the success of science undermines the relevance of philosophy. But attending to the sort of understanding or explanation being sought offers a different picture: contemporary physics as practiced sometimes fails to provide a clear physical account of the world. This lies at the root of the dissatisfaction with standard quantum theory expressed by Einstein, Schrödinger, and John Bell. As an example, close consideration of Schrödinger's famous cat example suggests that physicists often have missed his point. What a philosophical disposition can contribute is not alternative physics, but rather the sort of careful attention to argument needed to extract a physical picture from a mathematical formalism. ",
                    "score": 0.8447005748748779
                },
                {
                    "id": 22035819,
                    "contents": "The Angular Momentum Dilemma and Born-Jordan Quantization.\nThe rigorous equivalence of the Schrödinger and Heisenberg pictures requires that one uses Born-Jordan quantization in place of Weyl quantization. We confirm this by showing that the much discussed \" angular momentum dilemma\" disappears if one uses Born-Jordan quantization. We argue that the latter is the only physically correct quantization procedure. We also briefly discuss a possible redefinition of phase space quantum mechanics, where the usual Wigner distribution has to be replaced with a new quasi-distribution associated with Born-Jordan quantization, and which has proven to be successful in time-frequency analysis.",
                    "score": 0.8438224196434021
                },
                {
                    "id": 10853917,
                    "contents": "Momentum Exchange between Light and a Single Atom: Abraham or Minkowski?\nWe consider forces on an atom due to a plane-wave light pulse. The standard view of the optical dipole force indicates that red-detuned light should attract the atom towards high intensity. While the atom is inside the pulse, this would increase the average momentum per photon from p_{0} to p_{0}n, where n is the average refractive index due to the presence of the atom. We show, however, that this is the wrong conclusion and that the dispersive forces repel the atom from the light in this particular case, giving the photons a momentum p_{0}/n. This leads us to identify Abraham's optical momentum with the kinetic momentum transfer. The form due to Minkowski is similarly associated with the canonical momentum. We consider the possibility of demonstrating this in the laboratory, and we note an unexpected connection with the Aharonov-Casher effect.",
                    "score": 0.8437593579292297
                },
                {
                    "id": 18024125,
                    "contents": "Making better sense of quantum mechanics.\nWe still lack any consensus about what one is actually talking about as one uses quantum mechanics. There is a gap between the abstract terms in which the theory is couched and the phenomena the theory enables each of us to account for so well. Because it has no practical consequences for how we each use quantum mechanics to deal with physical problems, this cognitive dissonance has managed to coexist with the quantum theory from the very beginning. The absence of conceptual clarity for almost a century suggests that the problem might lie in some implicit misconceptions about the nature of scientific explanation that are deeply held by virtually all physicists, but are rarely explicitly acknowledged. I describe here such unvoiced but widely shared assumptions. Rejecting them clarifies and unifies a range of obscure remarks about quantum mechanics made almost from the beginning by some of the giants of physics, many of whom are held to be in deep disagreement. This new view of physics requires physicists to think about science in an unfamiliar way. My primary purpose is to explain the new perspective and urge that it be taken seriously. My secondary aims are to explain why this perspective differs significantly from what Bohr, Heisenberg, and Pauli had been saying from the very beginning, and why it is not solipsism, as some have maintained. To emphasize that this is a general view of science, and not just of quantum mechanics, I apply it to a long-standing puzzle in classical physics: the apparent inability of physics to give any meaning to 'Now'-the present moment.",
                    "score": 0.8434674739837646
                },
                {
                    "id": 9592302,
                    "contents": "Interpretation of quantum and classical angular momentum polarization moments.\nThis Letter presents a derivation of the relationship between the quantum and classical descriptions of angular momentum polarization. The results involve an \"uncertainty broadening\" term that directly expresses the restrictions imposed by the uncertainty principle. It is argued that neglect of this term can lead to error in the interpretation of theoretical or experimental angular momentum polarization data. Functions that take the uncertainty broadening into account, appropriate for use in quantum or quasiclassical descriptions of spatial distributions of angular momenta, are defined.",
                    "score": 0.8430726528167725
                },
                {
                    "id": 20432455,
                    "contents": "What Bohr wanted Carnap to learn from quantum mechanics.\nNiels Bohr's interpretation of quantum mechanics is often cast as positivist and sometimes explicitly claimed to be influenced by logical positivists due to some similarities in their thinking. While it is certainly the case that some logical positivists attempted to recruit Bohr, this paper argues that Bohr had interests of his own in the logical positivists. Bohr's interpretation of quantum mechanics focuses on observation, the use of classical concepts in quantum mechanics, and indeterminacy of quantum processes as opposed to uncertainty of measurement. His view thereby shares some common ground with the logical positivists' views on verification, the observation language, and anti-metaphysics. But Bohr also emphasized complementarity: that certain pairs of concepts - such as position and momentum - are mutually exclusive in quantum mechanics since they, according to Bohr, are only meaningful relative to different experimental arrangements. Bohr believed that complementary brought a general epistemological lesson for all of science that an objective description of nature is not separable from the observational and experimental conditions under which we explore nature. Motivated by the common ground between himself and logical positivism, Bohr tried to persuade the logical positivists and Carnap in particular to adopt and champion complementarity as well as part of their unity of science program. Though his efforts ultimately proved in vain, Bohr's attempts to influence logical positivism disprove the claim that his engagement with them was reluctant and purposefully limited.",
                    "score": 0.8426386117935181
                },
                {
                    "id": 20436548,
                    "contents": "Quantum Mechanics and Its Evolving Formulations.\nIn this paper, we discuss the time evolution of the quantum mechanics formalism. Starting from the heroic beginnings of Heisenberg and Schrödinger, we cover successively the rigorous Hilbert space formulation of von Neumann, the practical bra-ket formalism of Dirac, and the more recent rigged Hilbert space approach.",
                    "score": 0.8425652980804443
                },
                {
                    "id": 22986310,
                    "contents": "The Elementary Particles of Quantum Fields.\nThe elementary particles of relativistic quantum field theory are not simple field quanta, as has long been assumed. Rather, they supplement quantum fields, on which they depend on but to which they are not reducible, as shown here with particles defined instead as a unified collection of properties that appear in both physical symmetry group representations and field propagators. This notion of particle provides consistency between the practice of particle physics and its basis in quantum field theory.",
                    "score": 0.8423629999160767
                },
                {
                    "id": 20846822,
                    "contents": "Primer on quantum cognition.\nQuantum cognition is a new field in psychology, which is characterized by the application of quantum probability theory to human judgment and decision making behavior. This article provides an introduction that presents several examples to illustrate in a simple and concrete manner how to apply these principles to interesting psychological phenomena. Following each simple example, we present the general mathematical derivations and new predictions related to these applications.",
                    "score": 0.8421072959899902
                },
                {
                    "id": 12259605,
                    "contents": "Optical angular momentum in a rotating frame.\nIt is well established that light carrying orbital angular momentum (OAM) can be used to induce a mechanical torque causing an object to spin. We consider the complementary scenario: will an observer spinning relative to the beam axis measure a change in OAM as a result of their rotational velocity? Remarkably, although a linear Doppler shift changes the linear momentum of a photon, the angular Doppler shift induces no change in the angular momentum. Further, we examine the rotational Doppler shift in frequency imparted to the incident light due to the relative motion of the beam with respect to the observer and consider what must happen to the measured wavelength if the speed of light c is to remain constant. We show specifically that the OAM of the incident beam is not affected by the rotating observer and that the measured wavelength is shifted by a factor equal and opposite to that of the frequency shift induced by the rotational Doppler effect. ",
                    "score": 0.8413410186767578
                },
                {
                    "id": 4792717,
                    "contents": "Inferring the statistical interpretation of quantum mechanics from the classical limit\nIt is widely believed that the statistical interpretation of quantum mechanics cannot be inferred from the Schrodinger equation itself, and must be stated as an additional independent axiom. Here I propose that the situation is not so stark. For systems that have both continuous and discrete degrees of freedom (such as coordinates and spin respectively), the statistical interpretation for the discrete variables is implied by requiring that the system's gross motion can be classically described under circumstances specified by the Schrodinger equation. However, this is not a full-fledged derivation of the statistical interpretation because it does not apply to the continuous variables of classical mechanics.",
                    "score": 0.8411983251571655
                },
                {
                    "id": 20648919,
                    "contents": "On Bohmian Mechanics, Particle Creation, and Relativistic Space-Time: Happy 100th Birthday, David Bohm!\nThe biggest and most lasting among David Bohm's (1917-1992) many achievements is to have proposed a picture of reality that explains the empirical rules of quantum mechanics. This picture, known as pilot wave theory or Bohmian mechanics among other names, is still the simplest and most convincing explanation available. According to this theory, electrons are point particles in the literal sense and move along trajectories governed by Bohm's equation of motion. In this paper, I describe some more recent developments and extensions of Bohmian mechanics, concerning in particular relativistic space-time and particle creation and annihilation.",
                    "score": 0.8410831689834595
                },
                {
                    "id": 18323679,
                    "contents": "Angular momentum-scattering angle quantum correlation: a generalized deflection function.\nA natural generalization of the classical deflection function, the functional dependence of the deflection angle on the angular momentum (or the impact parameter), is the joint probability density function of these two quantities, revealing the correlation between them. It provides, at a glance, detailed information about the reaction mechanisms and how changes in the impact parameter affect the product angular distribution. It is also useful to predict the presence of quantum phenomena such as interference. However, the classical angular momentum-scattering angle correlation function has a limited use whenever quantum effects become important. Rigorously speaking, there is not a quantum equivalent of the classical joint distribution, as the differential cross section depends on the coherences between the different values of <iJ</i caused by the cross terms in the expansion of partial waves. In this article, we present a simple method to calculate a quantum analog of this correlation, a generalized deflection function that can shed light onto the reaction mechanism using just quantum mechanical results. Our results show that there is a very good agreement between the quantum and classical correlation functions as long as quantum effects are not all relevant. When this is not the case, it will also be shown that the quantum correlation function is most useful to observe the extent of quantum effects such as interference among different reaction mechanisms.",
                    "score": 0.8405371904373169
                },
                {
                    "id": 20648838,
                    "contents": "Observables and Unobservables in Quantum Mechanics: How the No-Hidden-Variables Theorems Support the Bohmian Particle Ontology.\nThe paper argues that far from challenging-or even refuting-Bohm's quantum theory, the no-hidden-variables theorems in fact support the Bohmian ontology for quantum mechanics. The reason is that (i) all measurements come down to position measurements; and (ii) Bohm's theory provides a clear and coherent explanation of the measurement outcome statistics based on an ontology of particle positions, a law for their evolution and a probability measure linked with that law. What the no-hidden-variables theorems teach us is that (i) one cannot infer the properties that the physical systems possess from observables; and that (ii) measurements, being an interaction like other interactions, change the state of the measured system.",
                    "score": 0.8402350544929504
                },
                {
                    "id": 20648878,
                    "contents": "Developments in Quantum Probability and the Copenhagen Approach.\nIn the Copenhagen approach to quantum mechanics as characterized by Heisenberg, probabilities relate to the statistics of measurement outcomes on ensembles of systems and to individual measurement events via the actualization of quantum potentiality. Here, brief summaries are given of a series of key results of different sorts that have been obtained since the final elements of the Copenhagen interpretation were offered and it was explicitly named so by Heisenberg-in particular, results from the investigation of the behavior of quantum probability since that time, the mid-1950s. This review shows that these developments have increased the value to physics of notions characterizing the approach which were previously either less precise or mainly symbolic in character, including complementarity, indeterminism, and unsharpness.",
                    "score": 0.839503824710846
                },
                {
                    "id": 5227450,
                    "contents": "Measuring the orbital angular momentum of a single photon.\nWe propose an interferometric method for measuring the orbital angular momentum of single photons. We demonstrate its viability by sorting four different orbital angular momentum states, and are thus able to encode two bits of information on a single photon. This new approach has implications for entanglement experiments, quantum cryptography and high density information transfer.",
                    "score": 0.8389973640441895
                },
                {
                    "id": 16614292,
                    "contents": "Correlations between detectors allow violation of the Heisenberg noise-disturbance principle for position and momentum measurements.\nHeisenberg formulated a noise-disturbance principle stating that there is a tradeoff between noise and disturbance when a measurement of position and a measurement of momentum are performed sequentially, and another principle imposing a limitation on the product of the uncertainties in a joint measurement of position and momentum. We prove that the former, the Heisenberg sequential noise-disturbance principle, holds when the detectors are assumed to be initially uncorrelated from each other, but that it can be violated for some properly correlated initial preparations of the detectors. ",
                    "score": 0.8385486602783203
                },
                {
                    "id": 22247840,
                    "contents": "There Is No Spooky Action at a Distance in Quantum Mechanics.\nEinstein became bothered by quantum mechanical action at a distance within two years of Schrödinger's introduction of his eponymous wave equation. If the wave function represents the \"real\" physical state of a particle, then the measurement of the particle's position would result in the instantaneous collapse of the wave function to the single, measured position. Such a process seemingly violates not only the Schrödinger equation but also special relativity. Einstein was not alone in this vexation; however, the dilemma eventually faded as physicists concentrated on using the Schrödinger equation to solve a plethora of pressing problems. For the next 30 years, wave function collapse, while occasionally discussed by physicists, was primarily a topic of interest for philosophers. That is, until 1964, when Bell introduced his famous inequality and maintained that its violation proved that quantum mechanics and, by implication, nature herself are nonlocal. Unfortunately, this brought the topic back to mainstream physics, where it has remained and continues to muddy the waters. To be sure, not all physicists are bothered by the apparent nonlocality of quantum mechanics. So where have those who embrace quantum nonlocality gone wrong? I argue that the answer is a gratuitous belief in the ontic nature of the quantum state.",
                    "score": 0.8385025262832642
                },
                {
                    "id": 10686401,
                    "contents": "My 50 years of research in particle physics.\nSome of my work of the last 50 years in the field of theoretical particle physics is described with particular emphasis on the motivation, the process of investigation, relationship to the work of others, and its impact. My judgment is unavoidably subjective, although I do present the comments of other researchers as much as possible.",
                    "score": 0.8383083939552307
                },
                {
                    "id": 20680025,
                    "contents": "Measuring correlated electron motion in atoms with the momentum-balance density.\nThree new measures of relative electron motion are introduced: equimomentum, antimomentum, and momentum-balance. The equimomentum is the probability that two electrons have the exact same momentum, whereas the antimomentum is the probability that their momenta are the exact opposite. Momentum-balance (MB) is the difference between the equimomentum and antimomentum and, therefore, indicates if equal or opposite momentum is more probable in a system of electrons. The equimomentum, antimomentum, and MB densities are also introduced, which are the local contribution to each quantity. The MB and MB density of the extrapolated-full configuration interaction wave functions of atoms of the first three rows of the periodic table are analyzed, with a particular focus on contrasting the correlated motion of electrons with opposite-spin and parallel-spin. Coulomb correlation between opposite-spin electrons leads to a higher probability of equimomentum, whereas Fermi correlation between parallel-spin electrons leads to a higher probability of antimomentum. The local contribution to MB, given an electron is present, is a minimum at the nucleus and generally increases as the distance from the nucleus increases. There are also interesting similarities between the effects of Fermi correlation and Coulomb correlation (of opposite-spin electrons) on MB.",
                    "score": 0.8381368517875671
                },
                {
                    "id": 19119242,
                    "contents": "Quantum mechanics as classical statistical mechanics with an ontic extension and an epistemic restriction.\nWhere does quantum mechanics part ways with classical mechanics? How does quantum randomness differ fundamentally from classical randomness? We cannot fully explain how the theories differ until we can derive them within a single axiomatic framework, allowing an unambiguous account of how one theory is the limit of the other. Here we derive non-relativistic quantum mechanics and classical statistical mechanics within a common framework. The common axioms include conservation of average energy and conservation of probability current. But two axioms distinguish quantum mechanics from classical statistical mechanics: an \"ontic extension\" defines a nonseparable (global) random variable that generates physical correlations, and an \"epistemic restriction\" constrains allowed phase space distributions. The ontic extension and epistemic restriction, with strength on the order of Planck's constant, imply quantum entanglement and uncertainty relations. This framework suggests that the wave function is epistemic, yet it does not provide an ontic dynamics for individual systems.",
                    "score": 0.8380962610244751
                },
                {
                    "id": 9695620,
                    "contents": "Max Born's Statistical Interpretation of Quantum Mechanics.\nIn the summer of 1926, a statistical element was introduced for the first time in the fundamental laws of physics in two papers by Born. After a brief account of Born's earlier involvements with quantum physics, including his bringing the new mechanics to the United States, the motivation for and contents of Born's two papers are discussed. The reaction of his colleagues is described.",
                    "score": 0.8379837274551392
                },
                {
                    "id": 14055926,
                    "contents": "Curious and sublime: the connection between uncertainty and probability in physics.\nFrom its first significant appearance in physics, the notion of probability has been linked in the minds of physicists with the notion of uncertainty. But the link may prove to be tenuous, if quantum mechanics, construed in terms of the Everett interpretation, is anything to go by.",
                    "score": 0.8377342224121094
                },
                {
                    "id": 8630126,
                    "contents": "Minimum uncertainty measurements of angle and angular momentum.\nWe present an accurate description of the conjugate pair angle-angular momentum in terms of the exponential of the angle instead of the angle itself, which leads to dispersion as a natural measure of resolution. Intelligent states minimizing the uncertainty product under the constraint of a given uncertainty in angle or in angular momentum turn out to be given by Mathieu wave functions. We discuss Gaussian approximations to these optimal states in terms of von Mises distributions. The theory is successfully applied to the spatial degrees of freedom of a photon and verified in an experiment that employs computer-controlled spatial light modulators at both the state preparation and the analyzing stages.",
                    "score": 0.8375641107559204
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_12",
        "question": "Using the Bohr theory, calculate the ionization energy (in electron volts and in $\\mathrm{kJ} \\cdot \\mathrm{mol}^{-1}$ ) of singly ionized helium.",
        "golden_answers": [
            " 54.394"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 15230135,
                    "contents": "First-Principles Calculation of the Third Virial Coefficient of Helium.\nKnowledge of the pair and three-body potential-energy surfaces of helium is now sufficient to allow calculation of the third density virial coefficient, C(T), with significantly smaller uncertainty than that of existing experimental data. In this work, we employ the best available pair and three-body potentials for helium and calculate C(T) with path-integral Monte Carlo (PIMC) calculations supplemented by semiclassical calculations. The values of C(T) presented extend from 24.5561 K to 10 000 K. In the important metrological range of temperatures near 273.16 K, our uncertainties are smaller than the best experimental results by approximately an order of magnitude, and the reduction in uncertainty at other temperatures is at least as great. For convenience in calculation of C(T) and its derivatives, a simple correlating equation is presented.",
                    "score": 0.8689104914665222
                },
                {
                    "id": 15060803,
                    "contents": "Transport coefficients of He(+) ions in helium.\nThis paper demonstrates that the transport coefficients of (4)He(+) in (4)He can be calculated over wide ranges of E/N, the ratio of the electrostatic field strength to the gas number density, with the same level of precision as can be obtained experimentally if sufficiently accurate potential energy curves are available for the X(2)Σu (+) and A(2)Σg (+) states and one takes into account resonant charge transfer. We start by computing new potential energy curves for these states and testing their accuracy by calculating spectroscopic values for the separate states. It is established that the potentials obtained by extrapolation of results from d-aug-cc-pVXZ (X = 6, 7) basis sets using the CASSCF+MRCISD approach are each in exceptionally close agreement with the best potentials available and with experiment. The potentials are then used in a new computer program to determine the semi-classical phase shifts and the transport cross sections, and from these the gaseous ion transport coefficients are determined. In addition, new experimental values are reported for the mobilities of (4)He(+) in (4)He at 298.7 K, as a function of E/N, where careful consideration is given to minimizing various sources of uncertainty. Comparison with previously measured values establishes that only one set of previous data is reliable. Finally, the experimental and theoretical ion transport coefficients are shown to be in very good to excellent agreement, once corrections are applied to account for quantum-mechanical effects. ",
                    "score": 0.8676334023475647
                },
                {
                    "id": 4522799,
                    "contents": "Ionization potential of the helium atom.\nThe ground-state ionization potential of the He4 atom is found to be 5 945 204 223 (42) MHz. Along with lower-order contributions, this result includes all effects of relative order alpha4, alpha(3)m(e)/m(alpha), and alpha(5)ln(2)alpha. Effective operators derived in dimensionally regularized nonrelativistic quantum electrodynamics are employed. The average values of these operators are evaluated using a high-accuracy variational wave function constructed in an exponential basis.",
                    "score": 0.8673614859580994
                },
                {
                    "id": 15379292,
                    "contents": "Schrödinger equation solved for the hydrogen molecule with unprecedented accuracy.\nThe hydrogen molecule can be used for determination of physical constants, including the proton charge radius, and for improved tests of the hypothetical long range force between hadrons, which require a sufficiently accurate knowledge of the molecular levels. In this work, we perform the first step toward a significant improvement in theoretical predictions of H2 and solve the nonrelativistic Schrödinger equation to the unprecedented accuracy of 10(-12). We hope that it will inspire a parallel progress in the spectroscopy of the molecular hydrogen. ",
                    "score": 0.8668504953384399
                },
                {
                    "id": 5245149,
                    "contents": "Intense-field double ionization of helium: identifying the mechanism\nWe present quantum mechanical calculations of the electron and ion momentum distributions following double ionization of a one-dimensional helium atom by ultrashort laser pulses (780 nm) at various intensities. The two-electron momentum distributions exhibit a clear transition from nonsequential to sequential double ionization. We provide strong evidence that rescattering is responsible for nonsequential ionization by calculating the momentum spectrum of the He2+ recoil ions-which we find in excellent agreement with recent experiments-and by analyzing the electronic center-of-mass motion via Wigner transforms.",
                    "score": 0.8652759194374084
                },
                {
                    "id": 15981153,
                    "contents": "Improved First-Principles Calculation of the Third Virial Coefficient of Helium.\nWe employ state-of-the-art pair and three-body potentials with path-integral Monte Carlo (PIMC) methods to calculate the third density virial coefficient C(T) for helium. The uncertainties are much smaller than those of the best experimental results, and approximately one-fourth the uncertainty of our previous work. We have extended our results in temperature down to 2.6 K, incorporating the effect of spin statistics that become important below approximately 7 K. Results are given for both the (3)He and (4)He isotopes. We have also performed PIMC calculations of the third acoustic virial coefficient γ a; our calculated values compare well with the limited experimental data available. A correlating equation for C(T) of (4)He is presented; differentiation of this equation provides a reliable and simpler way of calculating γ a.",
                    "score": 0.8646765947341919
                },
                {
                    "id": 21640373,
                    "contents": "Kinetic Isotope Effect in Low-Energy Collisions between Hydrogen Isotopologues and Metastable Helium Atoms: Theoretical Calculations Including the Vibrational Excitation of the Molecule.\nWe present very accurate theoretical results of Penning ionization rate coefficients of the excited metastable helium atoms (<sup4</supHe(2<sup3</supS) and <sup3</supHe(2<sup3</supS)) colliding with the hydrogen isotopologues (H<sub2</sub, HD, D<sub2</sub) in the ground and first excited rotational and vibrational states at subkelvin regime. The calculations are performed using the current best <iab initio</i interaction energy surface, which takes into account the nonrigidity effects of the molecule. The results confirm a recently observed substantial quantum kinetic isotope effect (<iNat. Chem</i. 2014, 6, 332-335) and reveal that the change of the rotational or vibrational state of the molecule can strongly enhance or suppress the reaction. Moreover, we demonstrate the mechanism of the appearance and disappearance of resonances in Penning ionization. The additional model computations, with the morphed interaction energy surface and mass, give better insight into the behavior of the resonances and thereby the reaction dynamics under study. Our theoretical findings are compared with all available measurements, and comprehensive data for prospective experiments are provided.",
                    "score": 0.8593616485595703
                },
                {
                    "id": 6123500,
                    "contents": "Helium-antihydrogen interaction: the Born-Oppenheimer potential energy curve.\nThe interaction of atomic antihydrogen with helium has been studied within the Born-Oppenheimer approximation. The linear combination of explicitly correlated Gaussian functions was used as the ansatz for the wave function of light particles. The potential energy curve with the minimum at 3.63 bohr and the barrier at 2.42 bohr has been obtained.",
                    "score": 0.8560489416122437
                },
                {
                    "id": 17368660,
                    "contents": "Chemical Bond Mechanism for Helium Revealed by Electronic Excitation.\nHelium chemistry is notoriously very impervious. It is therefore certainly no surprise that, for example, beryllium and helium atoms, in their ground state, do not bind. Full configuration-interaction calculations show that the same turns out to be true, save for a long-range shallow attraction, for the Be<sup+</sup + He system. However, quite astonishingly, when one electron is re-added to Be<sup+</sup in an excited 2p<subπ</sub or 3s orbital (Be <sup1</supP or <sup1</supS), a bound adduct with He is formed, at an interatomic separation as short as 1.5 Å. Understanding why this happens reveals an unsuspected chemical mechanism that stabilizes helium compounds at the molecular level.",
                    "score": 0.8554484844207764
                },
                {
                    "id": 12354630,
                    "contents": "mα(7)-order corrections in the hydrogen molecular ions and antiprotonic helium.\nWe present a calculation of the complete set of QED corrections of order mα7 for one-electron two-center systems. Leading corrections of order mα8 are also considered, which allows us to estimate the magnitude of yet uncalculated contributions. The theoretical uncertainty on the frequencies of rovibrational transitions in the hydrogen molecular ions H2+ and HD+, and of two-photon transition in antiprotonic helium is reduced by about 1 order of magnitude, down to (3-4)×10-11 and 10-10, respectively. These results open new perspectives for improved determination of the proton- and antiproton-to-electron mass ratios by precision spectroscopy experiments. ",
                    "score": 0.8551878929138184
                },
                {
                    "id": 11479547,
                    "contents": "Spectroscopy of antiprotonic helium atoms and its contribution to the fundamental physical constants.\nAntiprotonic helium atom, a metastable neutral system consisting of an antiproton, an electron and a helium nucleus, was serendipitously discovered, and has been studied at CERN's antiproton decelerator facility. Its transition frequencies have recently been measured to nine digits of precision by laser spectroscopy. By comparing these experimental results with three-body QED calculations, the antiproton-to-electron massratio was determined as 1836.152674(5). This result contributed to the CODATA recommended values of the fundamental physical constants",
                    "score": 0.8542422652244568
                },
                {
                    "id": 21397732,
                    "contents": "Complexes of helium with neutral molecules: Progress toward a quantitative scale of bonding character.\nThe complexes of helium with nearly 30 neutral molecules (M) were investigated by various techniques of bonding analysis and symmetry-adapted perturbation theory (SAPT). The main investigated function was the local electron energy density H(r), analyzed, in particular, so to estimate the degree of polarization (DoP) of He in the various He(M). As we showed recently (Borocci et al., J. Comput. Chem., 2019, 40, 2318-2328), the DoP is a quantitative index that is generally informative about the role of polarization (induction plus charge transfer [CT]) and dispersion in noncovalent noble gas complexes. As further evidence in this regard, we presently ascertained quantitative correlations between the DoP(He) of the He(M) and indices based on the electron density ρ(r), including the molecular electrostatic potential at the HeM bond critical point, as well as the percentage contributions of induction and dispersion to the SAPT binding energies. Based also on the explicit evaluation of the CT, accomplished through the study of the charge-displacement function, we derived a quantitative scale that ranks the He(M) according to their dispersive, inductive, and CT bonding character. Our taken approach could be conceivably extended to other types of noncovalent complexes.",
                    "score": 0.8541750907897949
                },
                {
                    "id": 7915482,
                    "contents": "Solving the Schrodinger equation for helium atom and its isoelectronic ions with the free iterative complement interaction (ICI) method.\nThe Schrodinger equation was solved very accurately for helium atom and its isoelectronic ions (Z=1-10) with the free iterative complement interaction (ICI) method followed by the variational principle. We obtained highly accurate wave functions and energies of helium atom and its isoelectronic ions. For helium, the calculated energy was -2.903,724,377,034,119,598,311,159,245,194,404,446,696,905,37 a.u., correct over 40 digit accuracy, and for H(-), it was -0.527,751,016,544,377,196,590,814,566,747,511,383,045,02 a.u. These results prove numerically that with the free ICI method, we can calculate the solutions of the Schrodinger equation as accurately as one desires. We examined several types of scaling function g and initial function psi(0) of the free ICI method. The performance was good when logarithm functions were used in the initial function because the logarithm function is physically essential for three-particle collision area. The best performance was obtained when we introduce a new logarithm function containing not only r(1) and r(2) but also r(12) in the same logarithm function.",
                    "score": 0.8540092706680298
                },
                {
                    "id": 9315140,
                    "contents": "Electron-impact ionization and excitation of helium to the n=1-4 ionic states.\nWe present high-precision (e,2e) measurements and calculations for the e-He four-body Coulomb breakup problem. Cross-section ratios for ionization and excitation of the first three excited states of He+ relative to the ground state have been measured for incident energies between 112 and 319 eV. Comparing the data with predictions from a state-of-the-art hybrid distorted-wave+convergent R matrix with pseudostates (close coupling) approach shows that treating the projectile-target interaction at least to second order is crucial to obtain reasonable agreement between theory and experiment. Nevertheless, our benchmark studies reveal significant theoretical problems for the symmetric energy-sharing cases, thus indicating the need for further improvement.",
                    "score": 0.8534054756164551
                },
                {
                    "id": 18646724,
                    "contents": "Helium Atom Excitations by the GW and Bethe-Salpeter Many-Body Formalism.\nThe helium atom is the simplest many-body electronic system provided by nature. The exact solution to the Schrödinger equation is known for helium ground and excited states, and it represents a benchmark for any many-body methodology. Here, we check the ab initio many-body GW approximation and the Bethe-Salpeter equation (BSE) against the exact solution for helium. Starting from the Hartree-Fock method, we show that the GW and the BSE yield impressively accurate results on excitation energies and oscillator strength, systematically improving the time-dependent Hartree-Fock method. These findings suggest that the accuracy of the BSE and GW approximations is not significantly limited by self-interaction and self-screening problems even in this few electron limit. We further discuss our results in comparison to those obtained by time-dependent density-functional theory.",
                    "score": 0.8493010401725769
                },
                {
                    "id": 7956891,
                    "contents": "Exact, Born-Oppenheimer, and quantum-chemistry-like calculations in helium clusters doped with light molecules: The He2N2(X) system.\nHelium clusters doped with diatomic molecules, He(N)-BC, have been recently studied by means of a quantum-chemistry-like approach. The model treats He atoms as \"electrons\" and dopants as \"nuclei\" in standard electronic structure calculations. Due to the large mass difference between He atoms and electrons, and to the replacement of Coulomb interactions by intermolecular potentials, it is worth assessing up to what extent are the approximations involved in this model, i.e., decoupling of the BC rotation from the He-atom orbital angular momenta and Born-Oppenheimer separation of the BC stretch versus the He motions, accurate enough. These issues have been previously tackled elsewhere for the (4)He(2)-Br(2)(X) system, which contains a heavy dopant [Roncero et al., Int. J. Quantum Chem. 107, 2756 (2007)]. Here, we consider a similar cluster but with a much lighter dopant such as N(2)(X). Although the model does not provide the correct energy levels for the cluster, positions and intensities of the main detectable lines of the vibrotational Raman spectrum at low temperature are accurately reproduced.",
                    "score": 0.8479756116867065
                },
                {
                    "id": 9240445,
                    "contents": "Relativistic electron correlation, quantum electrodynamics, and the lifetime of the 1s(2)2s(2)2p2p0(3/2) level in boronlike argon.\nThe lifetime of the Ar13+ 1s(2)2s(2)2p2p0(3/2) metastable level was determined at the Heidelberg Electron Beam Ion Trap to be 9.573(4)(5). The accuracy level of one per thousand makes this measurement sensitive to quantum electrodynamic effects like the electron anomalous magnetic moment (EAMM) and to relativistic electron-electron correlation effects like the frequency-dependent Breit interaction. Theoretical predictions, adjusted for the EAMM, cluster about a lifetime that is approximately shorter than our experimental result.",
                    "score": 0.8476213216781616
                },
                {
                    "id": 15612635,
                    "contents": "Investigation of the RbCa molecule: Experiment and theory.\nWe present a thorough theoretical and experimental study of the electronic structure of RbCa. The mixed alkali-alkaline earth molecule RbCa was formed on superfluid helium nanodroplets. Excited states of the molecule in the range of 13 000-23 000 cm<sup-1</sup were recorded by resonance enhanced multi-photon ionization time-of-flight spectroscopy. The experiment is accompanied by high level <iab initio</i calculations of ground and excited state properties, utilizing a multireference configuration interaction method based on multiconfigurational self consistent field calculations. With this approach the potential energy curves and permanent electric dipole moments of 24 electronic states were calculated. In addition we computed the transition dipole moments for transitions from the ground into excited states. The combination of experiment and theory allowed the assignment of features in the recorded spectrum to the excited [Formula: see text], [Formula: see text], [Formula: see text], [Formula: see text], [Formula: see text], [Formula: see text], [Formula: see text], and [Formula: see text] states, where the experiment allowed to benchmark the calculation. This is the first experimental work giving insight into the previously unknown RbCa molecule, which offers great prospects in ultracold molecular physics due to its magnetic and electronic dipole moment in the [Formula: see text] ground state.",
                    "score": 0.8474105596542358
                },
                {
                    "id": 21938703,
                    "contents": "Ab Initio Interatomic Potentials and the Classical Molecular Simulation Prediction of the Thermophysical Properties of Helium.\nThe ability of modern ab initio potentials to predict the thermophysical properties of helium is investigated. A new interatomic potential for helium is reported that is based on the latest available ab initio data and that is much more computationally efficient than other ab initio potentials, without sacrificing accuracy. The role of both two-body and three-body interactions is evaluated using classical Monte Carlo and molecular dynamics simulations. Data are reported for the second virial coefficient, vapor-liquid equilibria, acentric factor, compressibility factor, enthalpy, speed of sound, and isobaric heat capacity. Three-body interactions have a minor influence on the properties of helium with the exception of the estimated critical properties. The influence of quantum particle behavior is relevant at temperatures typically below 200 K. For example, the experimental maximum in the isobaric heat capacities (along isobars) of helium is not observed in the classical simulations and can be attributed to quantum particle behavior. However, above this temperature, helium behaves like a classical fluid and its thermodynamic properties can be adequately predicted by determining only two-body interactions.",
                    "score": 0.8468950986862183
                },
                {
                    "id": 13906082,
                    "contents": "Effects of adiabatic, relativistic, and quantum electrodynamics interactions on the pair potential and thermophysical properties of helium.\nThe adiabatic, relativistic, and quantum electrodynamics (QED) contributions to the pair potential of helium were computed, fitted separately, and applied, together with the nonrelativistic Born-Oppenheimer (BO) potential, in calculations of thermophysical properties of helium and of the properties of the helium dimer. An analysis of the convergence patterns of the calculations with increasing basis set sizes allowed us to estimate the uncertainties of the total interaction energy to be below 50 ppm for interatomic separations R smaller than 4 bohrs and for the distance R = 5.6 bohrs. For other separations, the relative uncertainties are up to an order of magnitude larger (and obviously still larger near R = 4.8 bohrs where the potential crosses zero) and are dominated by the uncertainties of the nonrelativistic BO component. These estimates also include the contributions from the neglected relativistic and QED terms proportional to the fourth and higher powers of the fine-structure constant α. To obtain such high accuracy, it was necessary to employ explicitly correlated Gaussian expansions containing up to 2400 terms for smaller R (all R in the case of a QED component) and optimized orbital bases up to the cardinal number X = 7 for larger R. Near-exact asymptotic constants were used to describe the large-R behavior of all components. The fitted potential, exhibiting the minimum of -10.996 ± 0.004 K at R = 5.608 0 ± 0.000 1 bohr, was used to determine properties of the very weakly bound (4)He(2) dimer and thermophysical properties of gaseous helium. It is shown that the Casimir-Polder retardation effect, increasing the dimer size by about 2 Å relative to the nonrelativistic BO value, is almost completely accounted for by the inclusion of the Breit-interaction and the Araki-Sucher contributions to the potential, of the order α(2) and α(3), respectively. The remaining retardation effect, of the order of α(4) and higher, is practically negligible for the bound state, but is important for the thermophysical properties of helium. Such properties computed from our potential have uncertainties that are generally significantly smaller (sometimes by nearly two orders of magnitude) than those of the most accurate measurements and can be used to establish new metrology standards based on properties of low-density helium.",
                    "score": 0.8466346263885498
                },
                {
                    "id": 11051953,
                    "contents": "Relativistic and quantum electrodynamics effects in the helium pair potential.\nThe helium pair potential was computed including relativistic and quantum electrodynamics contributions as well as improved accuracy adiabatic ones. Accurate asymptotic expansions were used for large distances R. Error estimates show that the present potential is more accurate than any published to date. The computed dissociation energy and the average R for the (4)He(2) bound state are 1.62+/-0.03 mK and 47.1+/-0.5 A. These values can be compared with the measured ones: 1.1(-0.2)(+0.3) mK and 52+/-4 A [R. E. Grisenti, Phys. Rev. Lett. 85, 2284 (2000)].",
                    "score": 0.8463404774665833
                },
                {
                    "id": 9240829,
                    "contents": "Relativistic correction to the helium dimer interaction energy.\nThe lowest-order relativistic correction to the helium-helium interaction energy has been calculated for the first time, using two independent methods based on expansions in explicitly correlated Gaussian functions. At the equilibrium interatomic distance of 5.6 bohr, this correction amounts to +15.4 +/- 0.6 mK. As a by-product, a new upper bound of -10.9985 K for the nonrelativistic Born-Oppenheimer interaction energy has been obtained.",
                    "score": 0.8463265895843506
                },
                {
                    "id": 6751715,
                    "contents": "Role of the ground state in electron-atom double ionization.\nRecently, absolute measurements have been reported for double ionization of helium by 5.6 keV electron-impact. At this high energy, one would think that the first Born approximation for the interaction of the projectile with the atom would be valid. However, on the basis of a lowest-order implementation of a Faddeev-type approach, Berakdar [Phys. Rev. Lett. 85, 4036 (2000)]] concluded that the approximation was not valid. Here we argue that (i) it is valid at this energy and (ii) the previous discrepancy between calculations in the first Born approximation and the overall magnitude of the measurements was due to a poor description of the ground state.",
                    "score": 0.8460119962692261
                },
                {
                    "id": 5841997,
                    "contents": "Improved result for helium 2(3)S1 ionization energy\nA complete calculation of relativistic and quantum electrodynamic effects to order malpha(6) on the energy of the 2(3)S1 state in helium is presented. The result, beyond the previously known radiative corrections, amounts to -3.00(1) MHz, and significantly reduces the theoretical uncertainty. The improved theoretical predictions are compared to the best available experimental result for the 2(3)S1 state.",
                    "score": 0.8457803130149841
                },
                {
                    "id": 13326812,
                    "contents": "Precision measurements of ionization and dissociation energies by extrapolation of Rydberg series: from H2 to larger molecules.\nRecent experiments are reviewed which have led to the determination of the ionization and dissociation energies of molecular hydrogen with a precision of 0.0007 cm(-)1 (8 mJ/mol or 20 MHz) using a procedure based on high-resolution spectroscopic measurements of high Rydberg states and the extrapolation of the Rydberg series to the ionization thresholds. Molecular hydrogen, with only two protons and two electrons, is the simplest molecule with which all aspects of a chemical bond, including electron correlation effects, can be studied. Highly precise values of its ionization and dissociation energies provide stringent tests of the precision of molecular quantum mechanics and of quantum-electrodynamics calculations in molecules. The comparison of experimental and theoretical values for these quantities enable one to quantify the contributions to a chemical bond that are neglected when making the Born-Oppenheimer approximation, i.e. adiabatic, nonadiabatic, relativistic, and radiative corrections. Ionization energies of a broad range of molecules can now be determined experimentally with high accuracy (i.e. about 0.01 cm(-1)). Calculations at similar accuracies are extremely challenging for systems containing more than two electrons. The combination of precision measurements of molecular ionization energies with highly accurateab initio calculations has the potential to provide, in future, fully reliable sets of thermochemical quantities for gas-phase reactions.",
                    "score": 0.8457655310630798
                },
                {
                    "id": 12846840,
                    "contents": "Rydberg states of triatomic hydrogen and deuterium.\nThe triatomic hydrogen ion (H3(+)) has spurred tremendous interest in astrophysics in recent decades, and Rydberg states of H3 have also maintained an important role for understanding H3(+) experiments. In a previous study (J. Chem. Phys. 2010, 133, 234302), radiative transitions between neutral H3 Rydberg states were calculated at wavelengths near 7 μm and could be compared with mid-infrared laser lines observed in hydrogen/rare gas discharges. The present study extends the investigation to wavelengths near 10–13 μm. Rydberg states of D3 are also treated.",
                    "score": 0.8455777764320374
                },
                {
                    "id": 15248410,
                    "contents": "The realization of the dipole (γ, γ) method and its application to determine the absolute optical oscillator strengths of helium.\nThe dipole (γ, γ) method, which is the inelastic x-ray scattering operated at a negligibly small momentum transfer, is proposed and realized to determine the absolute optical oscillator strengths of the vanlence-shell excitations of atoms and molecules. Compared with the conventionally used photoabsorption method, this new method is free from the line saturation effect, which can seriously limit the accuracies of the measured photoabsorption cross sections for discrete transitions with narrow natural linewidths. Furthermore, the Bethe-Born conversion factor of the dipole (γ, γ) method varies much more slowly with the excitation energy than does that of the dipole (e, e) method. Absolute optical oscillator strengths for the excitations of 1s(2) → 1 snp(n = 3-7) of atomic helium have been determined using the high-resolution dipole (γ, γ) method, and the excellent agreement of the present measurements with both those measured by the dipole (e, e) method and the previous theoretical calculations indicates that the dipole (γ, γ) method is a powerful tool to measure the absolute optical oscillator strengths of the valence-shell excitations of atoms and molecules.",
                    "score": 0.8450029492378235
                },
                {
                    "id": 5794657,
                    "contents": "Density shift and broadening of transition lines in antiprotonic helium\nThe density shift and broadening of the transition lines of antiprotonic helium have been evaluated in the impact approximation using an interatomic potential calculated ab initio with the symmetry-adapted perturbation theory. The results help to remove an uncertainty of up to 10 ppm in the laser spectroscopy data on antiprotonic helium and are of importance in experimental tests of bound state QED and CPT invariance.",
                    "score": 0.8444834351539612
                },
                {
                    "id": 9240897,
                    "contents": "Partial photoionization cross sections and angular distributions for double excitation of helium up to the N = 13 threshold.\nPartial photoionization cross sections sigmaN(Egamma) and photoelectron angular distributions betaN(Egamma) were measured for the final ionic states He+ (N &gt; 4) in the region between the N = 8 and N = 13 thresholds (Egamma &gt; 78.155 eV) using the cold target recoil ion momentum spectroscopy technique (COLTRIMS). Comparison of the experimental data with two independent sets of theoretical predictions reveals disagreement for the branching ratios to the various HeN(+) states. The angular distributions just below the double ionization threshold suggest an excitation process for highly excited N states similar to the Wannier mechanism for double ionization.",
                    "score": 0.8443125486373901
                },
                {
                    "id": 16474603,
                    "contents": "Frequency-dependent polarizability of helium including relativistic effects with nuclear recoil terms.\nFuture metrology standards will be partly based on physical quantities computed from first principles rather than measured. In particular, a new pressure standard can be established if the dynamic polarizability of helium can be determined from theory with an uncertainty smaller than 0.2 ppm. We present calculations of the frequency-dependent part of this quantity including relativistic effects with full account of leading nuclear recoil terms and using highly optimized explicitly correlated basis sets. A particular emphasis is put on uncertainty estimates. At the He-Ne laser wavelength of 632.9908 nm, the computed polarizability value of 1.39181141 a.u. has uncertainty of 0.1 ppm that is 2 orders of magnitude smaller than those of the most accurate polarizability measurements. We also obtained an accurate expansion of the helium refractive index in powers of density. ",
                    "score": 0.8440049886703491
                },
                {
                    "id": 16710277,
                    "contents": "Comparison of classical and quantal calculations of helium three-body recombination.\nA general method to study classical scattering in n-dimension is developed. Through classical trajectory calculations, the three-body recombination is computed as a function of the collision energy for helium atoms, as an example. Quantum calculations are also performed for the J(Π) = 0(+) symmetry of the three-body recombination rate in order to compare with the classical results, yielding good agreement for E ≳ 1 K. The classical threshold law is derived and numerically confirmed for the Newtonian three-body recombination rate. Finally, a relationship is found between the quantum and classical three-body hard hypersphere elastic cross sections which is analogous to the well-known shadow scattering in two-body collisions. ",
                    "score": 0.8439229726791382
                },
                {
                    "id": 13708675,
                    "contents": "Multielectron transitions induced by neutron impact on helium.\nWe explore excitation and ionization by neutron impact as a novel tool for the investigation of electron-electron correlations in helium. We present single- and double-ionization spectra calculated in accurate numerical ab initio simulations for incoming neutrons with kinetic energies of up to 150 keV. The resulting electron spectra are found to be fundamentally different from photoionization or charged particle impact due to the intrinsic many-body character of the interaction. In particular, doubly excited resonances that are strongly suppressed in electron or photon impact become prominent. The ratio of double to single ionization is found to differ significantly from those of photon and charged-particle impact.",
                    "score": 0.8437280058860779
                },
                {
                    "id": 15084755,
                    "contents": "Towards a spectroscopically accurate set of potentials for heavy hydride laser cooling candidates: Effective core potential calculations of BaH.\nBaH (and its isotopomers) is an attractive molecular candidate for laser cooling to ultracold temperatures and a potential precursor for the production of ultracold gases of hydrogen and deuterium. The theoretical challenge is to simulate the laser cooling cycle as reliably as possible and this paper addresses the generation of a highly accurate ab initio (2)Σ(+) potential for such studies. The performance of various basis sets within the multi-reference configuration-interaction (MRCI) approximation with the Davidson correction is tested and taken to the Complete Basis Set (CBS) limit. It is shown that the calculated molecular constants using a 46 electron effective core-potential and even-tempered augmented polarized core-valence basis sets (aug-pCVnZ-PP, n = 4 and 5) but only including three active electrons in the MRCI calculation are in excellent agreement with the available experimental values. The predicted dissociation energy De for the X(2)Σ(+) state (extrapolated to the CBS limit) is 16,895.12 cm(-1) (2.094 eV), which agrees within 0.1% of a revised experimental value of &lt;16,910.6 cm(-1), while the calculated re is within 0.03 pm of the experimental result.",
                    "score": 0.8430564403533936
                },
                {
                    "id": 13238940,
                    "contents": "Excitation of helium Rydberg states and doubly excited resonances in strong extreme ultraviolet fields: full-dimensional quantum dynamics using exponentially tempered Gaussian basis sets.\nRecently optimized exponentially tempered Gaussian basis sets [P. R. Kapralova-Zdanska and J. Smydke, J. Chem. Phys. 138, 024105 (2013)] are employed in quantitative simulations of helium absorption cross-sections and two-photon excitation yields of doubly excited resonances. Linearly polarized half-infinite and Gaussian laser pulses at wavelengths 38-58 nm and large intensities up to 100 TW/cm(2) are considered. The emphasis is laid on convergence of the results with respect to the quality of the Gaussian basis sets (typically limited by a number of partial waves, density, and spatial extent of the basis functions) as well as to the quality of the basis set of field-free states (typically limited by the maximum rotational quantum number and maximum excitation of the lower electron). Particular attention is paid to stability of the results with respect to varying complex scaling parameter. Moreover, the study of the dynamics is preceded by a thorough check of helium energies and oscillator strengths as they are obtained with the exponentially tempered Gaussian basis sets, being also compared with yet unpublished emission wavelengths measured in electric discharge experiments. ",
                    "score": 0.8425487279891968
                },
                {
                    "id": 8762235,
                    "contents": "(e,3e) on helium at low impact energy: the strongly correlated three-electron continuum.\nDouble ionization of the helium atom by slow electron impact (E(0)=106 eV) is studied in a kinematically complete experiment. Because of a low excess energy E(exc)=27 eV above the double ionization threshold, a strongly correlated three-electron continuum is realized. This is demonstrated by measuring and calculating the fully differential cross sections for equal energy sharing of the final-state electrons. While the electron emission is dominated by a strong Coulomb repulsion, also signatures of more complex dynamics of the full four-body system are identified.",
                    "score": 0.8423529863357544
                },
                {
                    "id": 13625393,
                    "contents": "Cationic complexes of hydrogen with helium.\nHigh-resolution mass spectra of helium nanodroplets doped with hydrogen or deuterium reveal that copious amounts of helium can be bound to H(+), H(2)(+), H(3)(+), and larger hydrogen-cluster ions. All conceivable He(n)H(x)(+) stoichiometries are identified if their mass is below the limit of ≈120 u set by the resolution of the spectrometer. Anomalies in the ion yields of He(n)H(x)(+) for x=1, 2, or 3, and n≤30 reveal particularly stable cluster ions. Our results for He(n)H(1)(+) are consistent with conclusions drawn from previous experimental and theoretical studies which were limited to smaller cluster ions. The He(n)H(3)(+) series exhibits a pronounced anomaly at n=12 which was outside the reliable range of earlier experiments. Contrary to findings reported for other diatomic dopant molecules, the monomer ion (i.e. H(2)(+)) retains helium with much greater efficiency than hydrogen-cluster ions.",
                    "score": 0.8422768115997314
                },
                {
                    "id": 8785726,
                    "contents": "Ab initio calculation of the double ionization of helium in a few-cycle laser pulse beyond the one-dimensional approximation.\nWe present ab initio computations of the ionization of two-electron atoms by short pulses of intense linearly polarized Ti:sapphire laser radiation beyond the one-dimensional approximation. In the model the electron correlation is included in its full dimensionality, while the center-of-mass motion is restricted along the polarization axis. Our results exhibit a rich double ionization quantum dynamics in the direction transversal to the field polarization, which is neglected in the previous models based on the one-dimensional approximation.",
                    "score": 0.8418226838111877
                },
                {
                    "id": 3219033,
                    "contents": "W values for helium particles in nitrogen and argon in the energy range from 10 keV to 10 MeV.\nAn analytical model is presented that facilitates the calculation of the mean energy W expended to produce an ion pair upon complete slow-down for heavy particles in gases. This model is applied to the calculation of the W values for helium beams of energies from 10 keV to 10 MeV in argon and nitrogen gas. Good agreement of the theoretical W values with the experimental ones is found in the case of nitrogen. The theoretical results for argon are about 15% higher than the experimental values throughout the entire energy range. However, they show a similar energy dependence. The theoretical and the experimental W values for nitrogen exhibit an extraordinary energy dependence at energies around 300 keV, at which the cross-section for charge exchange cycles reaches the maximal value. Such a phenomenon was also observed in the case of the W values for protons, which show a clear minimum at the energy of the maximal cross-section for charge exchange cycles.",
                    "score": 0.8414325714111328
                },
                {
                    "id": 19348065,
                    "contents": "Ultrahigh-Precision Measurement of the n=2 Triplet P Fine Structure of Atomic Helium Using Frequency-Offset Separated Oscillatory Fields.\nFor decades, improved theory and experiment of the n=2 ^{3}P fine structure of helium have allowed for increasingly precise tests of quantum electrodynamics, determinations of the fine-structure constant α, and limitations on possible beyond-the-standard-model physics. Here we use the new frequency-offset separated-oscillatory-fields technique to measure the 2^{3}P_{2}→2^{3}P_{1} interval. Our result of 2 291 176 590(25) Hz represents a major step forward in precision for helium fine-structure measurements.",
                    "score": 0.841177225112915
                },
                {
                    "id": 18910643,
                    "contents": "Kinetic energy partition method applied to ground state helium-like atoms.\nWe have used the recently developed kinetic energy partition (KEP) method to solve the quantum eigenvalue problems for helium-like atoms and obtain precise ground state energies and wave-functions. The key to treating properly the electron-electron (repulsive) Coulomb potential energies for the KEP method to be applied is to introduce a \"negative mass\" term into the partitioned kinetic energy. A Hartree-like product wave-function from the subsystem wave-functions is used to form the initial trial function, and the variational search for the optimized adiabatic parameters leads to a precise ground state energy. This new approach sheds new light on the all-important problem of solving many-electron Schrödinger equations and hopefully opens a new way to predictive quantum chemistry. The results presented here give very promising evidence that an effective one-electron model can be used to represent a many-electron system, in the spirit of density functional theory.",
                    "score": 0.8407753705978394
                },
                {
                    "id": 17993836,
                    "contents": "Benchmarking Theory with an Improved Measurement of the Ionization and Dissociation Energies of H_{2}.\nThe dissociation energy of H_{2} represents a benchmark quantity to test the accuracy of first-principles calculations. We present a new measurement of the energy interval between the EF ^{1}Σ_{g}^{+}(v=0,N=1) state and the 54p1_{1} Rydberg state of H_{2}. When combined with previously determined intervals, this new measurement leads to an improved value of the dissociation energy D_{0}^{N=1} of ortho-H_{2} that has, for the first time, reached a level of uncertainty that is 3 times smaller than the contribution of about 1 MHz resulting from the finite size of the proton. The new result of 35 999.582 834(11)  cm^{-1} is in remarkable agreement with the theoretical result of 35 999.582 820(26)  cm^{-1} obtained in calculations including high-order relativistic and quantum-electrodynamics corrections, as reported in the following Letter [M. Puchalski, J. Komasa, P. Czachorowski, and K. Pachucki, Phys. Rev. Lett. 122, 103003 (2019)PRLTAO0031-900710.1103/PhysRevLett.122.103003]. This agreement resolves a recent discrepancy between experiment and theory that had hindered a possible use of the dissociation energy of H_{2} in the context of the current controversy on the charge radius of the proton.",
                    "score": 0.8400029540061951
                },
                {
                    "id": 18243825,
                    "contents": "Fundamental Transitions and Ionization Energies of the Hydrogen Molecular Ions with Few ppt Uncertainty.\nWe calculate ionization energies and fundamental vibrational transitions for H_{2}^{+}, D_{2}^{+}, and HD^{+} molecular ions. The nonrelativistic quantum electrodynamics expansion for the energy in terms of the fine structure constant α is used. Previous calculations of orders mα^{6} and mα^{7} are improved by including second-order contributions due to the vibrational motion of nuclei. Furthermore, we evaluate the largest corrections at the order mα^{8}. That allows us to reduce the fractional uncertainty to the level of 7.6×10^{-12} for fundamental transitions and to 4.5×10^{-12} for the ionization energies.",
                    "score": 0.8396920561790466
                },
                {
                    "id": 17614168,
                    "contents": "Hydrogen molecular ions: H<sub>3</sub><sup>+</sup>, H<sub>5</sub><sup>+</sup> and beyond.\nThree decades after the spectroscopic detection of H<sub3</sub<sup+</sup in space, the inspiring developments in physics, chemistry and astronomy of H<subn</sub<sup+</sup (n = 3, 5, 7) systems, which led to this Royal Society Discussion Meeting, are reviewed, the present state of the art as represented by the meeting surveyed and future lines of research considered. This article is part of a discussion meeting issue 'Advances in hydrogen molecular ions: H<sub3</sub<sup+</sup, H<sub5</sub<sup+</sup and beyond'.",
                    "score": 0.839429497718811
                },
                {
                    "id": 13804023,
                    "contents": "Communication: Barium ions and helium nanodroplets: solvation and desolvation.\nThe solvation of Ba(+) ions created by the photoionization of barium atoms located on the surface of helium nanodroplets has been investigated. The excitation spectra corresponding to the 6p (2)P(1/2) ← 6s (2)S(1/2) and 6p (2)P(3/2) ← 6s (2)S(1/2) transitions of Ba(+) are found to be identical to those recorded in bulk He II [H. J. Reyher, H. Bauer, C. Huber, R. Mayer, A. Schafer, and A. Winnacker, Phys. Lett. A 115, 238 (1986)], indicating that the ions formed at the surface of the helium droplets become fully solvated by the helium. Time-of-flight mass spectra suggest that following the excitation of the solvated Ba(+) ions, these are being ejected from the helium droplets either as bare Ba(+) ions or as small Ba(+)He(n) (n &lt; 20) complexes.",
                    "score": 0.8392688035964966
                },
                {
                    "id": 11231654,
                    "contents": "Solving the Schrödinger equation of helium and its isoelectronic ions with the exponential integral (Ei) function in the free iterative complement interaction method.\nWe introduce here the exponential integral (Ei) function for variationally solving the Schrödinger equation of helium and its isoelectronic ions with the free iterative complement interaction (ICI) method. In our previous study [J. Chem. Phys., 2007, 127, 224104], we could calculate very accurate energies of these atoms by using the logarithmic function as the starting function of the free ICI calculation. The Ei function has a weak singularity at the origin, similarly to the logarithmic function, which is important for accurately describing the three-particle coalescence region. The logarithmic function, however, has a node and a maximum along the radial coordinate which may be physically meaningless. In contrast, the Ei function does not have such unphysical behaviors and so would provide an improvement over the logarithmic function. Actually, using the Ei function, instead of the logarithmic function, we obtained the energy, E= -2.903 724 377 034 119 598 311 159 245 194 404 446 696 924 865 a.u. for the helium ground state with 21 035 functions, which is a slight improvement over our previous result (the bold face shows the digits that are believed to have converged). This result supports the suggestion that the Ei function is better than the logarithmic function for describing the three-particle coalescence region.",
                    "score": 0.8391595482826233
                },
                {
                    "id": 14142311,
                    "contents": "Prediction of the existence of the N2H- molecular anion.\nWe predict the existence of the N(2)H(-) anion from first principle calculations. We present the three-dimensional potential energy surface and the bound states of the N(2)H(-)/D(-) van der Waals anion. The electronic calculations were performed using state-of-the-art ab initio methods and the nuclear motions were solved using a quantum close-coupling scattering theory. A T-shaped equilibrium structure was found, with a well depth of 349.1 cm(-1), where 18 bound states have been located for N(2)H(-) and 25 for N(2)D(-) for total angular momentum J = 0. We also present the absorption spectra of the N(2)H(-) complex. This anion could be formed after low energy collisions between N(2) and H(-) through radiative association. The importance of this prediction in astrophysics and the possible use of N(2)H(-) as a tracer of N(2) and H(-) in the interstellar medium is discussed.",
                    "score": 0.8390485644340515
                },
                {
                    "id": 9377718,
                    "contents": "Experimental determination of the helium 2(3)P(1)-1(1)S0 transition rate.\nWe present the first experimental determination of the 2(3)P(1)-1(1)S0 transition rate in helium and compare this measurement with theoretical quantum-electrodynamic predictions. The experiment exploits the very long (approximately 1 minute) confinement times obtained for atoms magneto-optically trapped in an apparatus used to create a Bose-Einstein condensate of metastable (2(3)S1) helium. The 2(3)P(1)-1(1)S0 transition rate is measured directly from the decay rate of the cold atomic cloud following 1083 nm laser excitation from the 2(3)S1 to the 2(3)P1 state, and from accurate knowledge of the 2(3)P1 population. The value obtained is 177+/-8 s(-1), which agrees very well with theoretical predictions, and has an accuracy that compares favorably with measurements for the same transition in heliumlike ions higher in the isoelectronic sequence.",
                    "score": 0.8389235734939575
                },
                {
                    "id": 7875077,
                    "contents": "Electron collisions with laser cooled and trapped metastable helium atoms: total scattering cross sections.\nAbsolute measurements of total scattering cross sections for low energy (5-70 eV) electrons by metastable helium (2(3)S) atoms are presented. The measurements are performed using a magneto-optical trap which is loaded from a laser-cooled, bright beam of slow He(2(3)S) atoms. The data are compared with predictions from convergent close coupling and R matrix with pseudostate calculations, and we find good agreement between experiment and theory.",
                    "score": 0.8389127254486084
                },
                {
                    "id": 8771676,
                    "contents": "Oscillator strengths of helium computed using Monte Carlo methods.\nWe have optimized trial wave functions for the three lowest states of the helium atom with symmetry 1S, 1P, 1D, 3S, 3P, and 3D using variational Monte Carlo methods. With these wave functions we then computed dipole oscillator strengths for the 1S-1P, 1P-1D, 3S-3P, and 3P-3D transitions using the length, velocity, and acceleration forms. Our values are in good agreement with the best results found in the literature.",
                    "score": 0.8386563062667847
                },
                {
                    "id": 10807852,
                    "contents": "Excited electron-bubble states in superfluid 4He: a time-dependent density functional approach.\nWe present a systematic study on the excited electron-bubble states in superfluid (4)He using a time-dependent density functional approach. For the evolution of the 1P bubble state, two different functionals accompanied with two different time-development schemes are used, namely an accurate finite-range functional for helium with an adiabatic approximation for electron versus an efficient zero-range functional for helium with a real-time evolution for electron. We make a detailed comparison between the quantitative results obtained from the two methods, which allow us to employ with confidence the optimal method for suitable problems. Based on this knowledge, we use the finite-range functional to calculate the time-resolved absorption spectrum of the 1P bubble, which in principle can be experimentally determined, and we use the zero-range functional to real-time evolve the 2P bubble for several hundreds of picoseconds, which is theoretically interesting due to the break down of adiabaticity for this state. Our results discard the physical realization of relaxed, metastable configurations above the 1P state.",
                    "score": 0.8383996486663818
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_13",
        "question": "When an excited nucleus decays, it emits a $\\gamma$ ray. The lifetime of an excited state of a nucleus is of the order of $10^{-12} \\mathrm{~s}$. What is the uncertainty in the energy of the $\\gamma$ ray produced?",
        "golden_answers": [
            " 0.527"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 7081811,
                    "contents": "Excited levels in 149Pm from the decay of 149Nd.\nThe level structure of 149Pm has been investigated by studying the gamma rays emitted following the beta(-) decay of 149Nd (T(1/2)=1.7h). The singles and the gammagamma coincidence spectra were taken using HPGe detectors with high energy resolution. The energy and relative intensities of 198 gamma rays have been determined, 45 for the first time and several multiplets were resolved using bidimensional data analysis. A decay scheme with 51 levels has been proposed. This includes 6 new levels, at 1407, 1368, 1364, 1329, 1293 and 1181keV. The present results permitted assignments of spin and parity for a number of these levels.",
                    "score": 0.8754201531410217
                },
                {
                    "id": 9694477,
                    "contents": "Nuclear decay techniques in ion chemistry.\nThe spontaneous decay of chemically bound radioactive atoms affords a route to ions of well-defined structure and charge location, free of counterions. The nuclear nature of the ionization process makes it insensitive to environmental effects, so that exactly the same charged species can be generated, and its reactivity investigated, in widely varying media, from low-pressure gases to liquids and solids. Techniques based on nuclear decay are used in studies of the production of otherwise inaccessible species, the structural characterization of free ions, and the comparative evaluation of their reactivity in different environments, in particular, gas phase and solution.",
                    "score": 0.875247597694397
                },
                {
                    "id": 9694622,
                    "contents": "Exotic nuclei and their decay.\nRecent advances in nuclear accelerators and experimental techniques have led to an increased ability to synthesize new isotopes. As isotopes are produced with more and more extreme combinations of neutrons and protons in their nuclei, new phenomena are observed, and the versatility of the nucleus is increased as a laboratory for studying fundamental forces. Among the newly discovered decay modes are (i) proton radioactivity, (ii) triton, two-proton, two-neutron, and three-neutron decays that are beta-delayed, as well as (iii)(14)C emission in radioactive decay. Precise tests of the properties of the weak force have also been achieved.",
                    "score": 0.8674004673957825
                },
                {
                    "id": 14700848,
                    "contents": "Single Photon Thermal Ionization of C_{60}.\nWe report on experiments which show that C_{60} can ionize in an indirect, quasithermal boiloff process after absorption of a single photon. The process involves a large number of incoherently excited valence electrons and yields electron spectra with a Boltzmann distribution with temperatures exceeding 10^{4}  K. It is expected to be present for other molecules and clusters with a comparatively large number of valence electrons. The astrophysical consequences are briefly discussed.",
                    "score": 0.8650476932525635
                },
                {
                    "id": 4416868,
                    "contents": "Decay of a Resonance in 18Ne by the Simultaneous Emission of Two Protons.\nRadioactive ion beams of 17F were used to study several resonance states in 18Ne. Clear evidence for simultaneous two-proton emission from the 6.15 MeV state (Jpi = 1(-)) in 18Ne has been observed with the reaction 17F+1H. Because of limited angular coverage, the data did not differentiate between the two possible mechanisms of simultaneous decay, diproton (2He) emission or direct three-body decay. The two-proton partial width was found to be 21+/-3 eV assuming 2He emission and 57+/-6 eV assuming three-body decay. The total width of the 1(-) state was measured to be 50+/-5 keV. Several additional resonances that decay by single proton emission were also studied.",
                    "score": 0.864890992641449
                },
                {
                    "id": 7520241,
                    "contents": "Effect of a triaxial nuclear shape on proton tunneling: the decay and structure of 145Tm.\nGamma rays deexciting states in the proton emitter 145Tm were observed using the recoil-decay tagging method. The 145Tm ground-state rotational band was found to exhibit the properties expected for an h{11/2} proton decoupled band. In addition, coincidences between protons feeding the 2{+} state in 144Er and the 2{+}--&gt;0{+} gamma-ray transition were detected, the first measurement of this kind, leading to a more precise value for the 2{+} excitation energy of 329(1) keV. Calculations with the particle-rotor model and the core quasiparticle coupling model indicate that the properties of the pi{11/2} band and the proton-decay rates in 145Tm are consistent with the presence of triaxiality with an asymmetry parameter gamma approximately 20 degrees .",
                    "score": 0.862999677658081
                },
                {
                    "id": 7745141,
                    "contents": "Electron-gamma spectroscopic measurements in 131 Cs.\nThe decay of 131 Ba to levels of 131 Cs has been studied using an HPGe detector for gamma-ray and a mini-orange electron spectrometer for conversion electron measurements. Our experiment identifies 76 gamma transitions in this decay, including 15 new gamma rays and 6 new K-conversion electron lines. The results also include M2 multipolarity assignment for the 269 keV transition, E2 assignment to two newly observed transitions, M1 + E2 for the 406 and 417 keV transitions and M3 for the 533.67 keV transition. A revised 131 Cs level scheme is proposed. While confirming the existence of 15 well-established levels, we present strong evidence from our beta decay study for five levels at 496, 764, 775, 1044 and 1258 keV which were earlier observed in reaction studies. Spin-parity assignments to a few other levels are also suggested. The level structure of 131 Cs is discussed in the light of the intermediate coupling model.",
                    "score": 0.8620368242263794
                },
                {
                    "id": 15824245,
                    "contents": "Observation of the competitive double-gamma nuclear decay.\nThe double-gamma (γγ)-decay of a quantum system in an excited state is a fundamental second-order process of quantum electrodynamics. In contrast to the well-known single-gamma (γ)-decay, the γγ-decay is characterized by the simultaneous emission of two γ quanta, each with a continuous energy spectrum. In nuclear physics, this exotic decay mode has only been observed for transitions between states with spin-parity quantum numbers J(π) = 0(+) (refs 1-3). Single-gamma decays-the main experimental obstacle to observing the γγ-decay-are strictly forbidden for these 0(+) → 0(+) transitions. Here we report the observation of the γγ-decay of an excited nuclear state (J(π) = 11/2(-)) that is directly competing with an allowed γ-decay (to ground state J(π) = 3/2(+)). The branching ratio of the competitive γγ-decay of the 11/2(-) isomer of (137)Ba to the ground state relative to its single γ-decay was determined to be (2.05 ± 0.37) × 10(-6). From the measured angular correlation and the shape of the energy spectra of the individual γ-rays, the contributing combinations of multipolarities of the γ radiation were determined. Transition matrix elements calculated using the quasiparticle-phonon model reproduce our measurements well. The γγ-decay rate gives access to so far unexplored important nuclear structure information, such as the generalized (off-diagonal) nuclear electric polarizabilities and magnetic susceptibilities.",
                    "score": 0.8619304895401001
                },
                {
                    "id": 4762253,
                    "contents": "Radioactive decay.\nWhen a parent radionuclide decays to its daughter radionuclide by means of alpha, beta, or isomeric transition, the decay follows an exponential form, which is characterized by the decay constant lambda. The decay constant represents the probability per unit time that a single radioatom will decay. The decay equation can be used to provide a useful expression for radionuclide decay, the half-life, the time when 50% of the radioatoms present will have decayed. Radiotracer half-life has direct implications in nuclear imaging, radiation therapy, and radiation safety because radionuclide half-life affects the ability to evaluate tracer kinetics and create appropriate nuclear images and also affects organ, tumor, and whole-body radiation dose. The number of radioatoms present in a sample is equal to the activity, defined as the number of transitions per unit time, divided by the decay constant; the mass of radioatoms present in a sample can be calculated to determine the specific activity (activity per unit mass). The dynamic relationship between the number of parent and daughter atoms present over time may lead to radioactive equilibrium, which takes two forms--secular and transient--and has direct relevance to generator-produced radionuclides.",
                    "score": 0.8611396551132202
                },
                {
                    "id": 7784039,
                    "contents": "Energy splitting of the ground-state doublet in the nucleus 229Th.\nThe energy splitting of the 229Th ground-state doublet is measured to be 7.6+/-0.5 eV, significantly greater than earlier measurements. Gamma rays produced following the alpha decay of 233U (105 muCi) were counted in the NASA/electron beam ion trap x-ray microcalorimeter spectrometer with an experimental energy resolution of 26 eV (FWHM). A difference technique was applied to the gamma-ray decay of the 71.82 keV level that populates both members of the doublet. A positive correction amounting to 0.6 eV was made for the unobserved interband decay of the 29.19 keV state (29.19--&gt;0 keV).",
                    "score": 0.8599759936332703
                },
                {
                    "id": 11252313,
                    "contents": "Gamma-ray spectroscopy at the limits: first observation of rotational bands in 255Lr.\nThe rotational band structure of 255Lr has been investigated using advanced in-beam gamma-ray spectroscopic techniques. To date, 255Lr is the heaviest nucleus to be studied in this manner. One rotational band has been unambiguously observed and strong evidence for a second rotational structure was found. The structures are tentatively assigned to be based on the 1/2-[521] and 7/2-[514] Nilsson states, consistent with assignments from recently obtained alpha decay data. The experimental rotational band dynamic moment of inertia is used to test self-consistent mean-field calculations using the Skyrme SLy4 interaction and a density-dependent pairing force.",
                    "score": 0.8586994409561157
                },
                {
                    "id": 11608265,
                    "contents": "Cosmic-ray electron injection from the ionization of nuclei.\nWe show that the secondary electrons ejected from the ionization of heavy ions can be injected into the acceleration process that occurs at supernova remnant shocks. This electron injection mechanism works since ions are ionized during the acceleration when they move already with relativistic speed, just like ejected electrons do. Using the abundances of heavy nuclei measured in cosmic rays measured at the Earth, we estimate the electron/proton ratio at the source to be approximately 10;{-4}, big enough to account for the nonthermal synchrotron emission observed in young supernova remnants. We also show that the ionization process can limit the maximum energy that heavy ions can reach.",
                    "score": 0.8582262396812439
                },
                {
                    "id": 4344994,
                    "contents": "Measurement of the B(e2) of (7)(lambda)Li and shrinkage of the hypernuclear size.\nWe report on the first measurement of a hypernuclear gamma-transition probability. gamma rays emitted in the E2(5/2(+)--&gt;1/2(+)) transition of (7)(Lambda)Li were detected by a large-acceptance germanium detector array (Hyperball), and the lifetime of the parent state ( 5/2(+)) was determined by the Doppler shift attenuation method. The obtained result, 5.8(+0.9)(-0.7)+/-0.7 ps, was then converted into the reduced transition probability [ B(E2)] to be B(E2;5/2(+)--&gt;1/2(+)) = 3.6+/-0.5(+0.5)(-0.4) e(2) fm(4). Compared with the B(E2) of the corresponding E2(3(+)--&gt;1(+)) transition in the 6Li nucleus, our result gives evidence that the size of the 6Li core in (7)(Lambda)Li is smaller than the 6Li nucleus in the free space.",
                    "score": 0.8577208518981934
                },
                {
                    "id": 11251934,
                    "contents": "Discovery of a new broad resonance in 19Ne: implications for the destruction of the cosmic gamma-ray emitter 18F.\nSix proton-emitting states in 19Ne were studied through the inelastic scattering reaction H(19Ne,p);{19}Ne; (p)18F. Their energies and widths were derived from the protons detected at zero degree, while proton-proton angular correlations between the detector at zero degree and a segmented annular detector were used to determine their spin value. In addition to the known states, a new broad J=1/2 resonance has been evidenced at E_{x} approximately 7.9 MeV, approximately 1.45 MeV above the proton emission threshold. By introducing this resonance, the 18F(p,alpha)15O destruction rate in novae is significantly enhanced. This reduces the chance to observe the cosmic gamma-ray emission of 18F from novae in space telescopes.",
                    "score": 0.8573573231697083
                },
                {
                    "id": 7128347,
                    "contents": "Conversion electron cascades in 254(102)No.\nThe spectrum of prompt conversion electrons emitted by excited 254No nuclei has been measured, revealing discrete lines arising from transitions within the ground state band. A striking feature is a broad distribution that peaks near 100 keV and comprises high multiplicity electron cascades, probably originating from M1 transitions within rotational bands built on high K states.",
                    "score": 0.8560963869094849
                },
                {
                    "id": 8728324,
                    "contents": "Quantum electrodynamics in strong electric fields: the ground-state Lamb shift in hydrogenlike uranium.\nX-ray spectra following radiative recombination of free electrons with bare uranium ions (U92+) were measured at the electron cooler of the ESR storage ring. The most intense lines observed in the spectra can be attributed to the characteristic Lyman ground-state transitions and to the recombination of free electrons into the K shell of the ions. Our experiment was carried out by utilizing the deceleration technique which leads to a considerable reduction of the uncertainties associated with Doppler corrections. This, in combination with the 0 degree observation geometry, allowed us to determine the ground-state Lamb shift in hydrogenlike uranium (U91+) from the observed x-ray lines with an accuracy of 1%. The present result is about 3 times more precise than the most accurate value available up to now and provides the most stringent test of bound-state quantum electrodynamics for one-electron systems in the strong-field regime.",
                    "score": 0.8553999662399292
                },
                {
                    "id": 4648089,
                    "contents": "Decay scheme of 67Ga\nA review of the 67Ga decay data from various evaluations reveals uncertainty as to whether or not there is an electron-capture (EC) branch decaying directly to the ground state of 67Zn. Measurements made at NAC and elsewhere of the intensity of the conversion electrons from the 93 keV transition (extracted from the standardization of 67Ga by coincidence counting techniques), place a fairly stringent restriction on the decay scheme that suggests that the ground-state branch is nonzero. Decay parameter values are proposed that are consistent with available data. Analysis indicates an EC branching ratio to the ground state of (4.01+/-0.27)%.",
                    "score": 0.8552806973457336
                },
                {
                    "id": 7297770,
                    "contents": "Multiple ionization of atom clusters by intense soft X-rays from a free-electron laser.\nIntense radiation from lasers has opened up many new areas of research in physics and chemistry, and has revolutionized optical technology. So far, most work in the field of nonlinear processes has been restricted to infrared, visible and ultraviolet light, although progress in the development of X-ray lasers has been made recently. With the advent of a free-electron laser in the soft-X-ray regime below 100 nm wavelength, a new light source is now available for experiments with intense, short-wavelength radiation that could be used to obtain deeper insights into the structure of matter. Other free-electron sources with even shorter wavelengths are planned for the future. Here we present initial results from a study of the interaction of soft X-ray radiation, generated by a free-electron laser, with Xe atoms and clusters. We find that, whereas Xe atoms become only singly ionized by the absorption of single photons, absorption in clusters is strongly enhanced. On average, each atom in large clusters absorbs up to 400 eV, corresponding to 30 photons. We suggest that the clusters are heated up and electrons are emitted after acquiring sufficient energy. The clusters finally disintegrate completely by Coulomb explosion.",
                    "score": 0.8539939522743225
                },
                {
                    "id": 15084746,
                    "contents": "The ionization energy of C2.\nResonant two-photon threshold ionization spectroscopy is employed to determine the ionization energy of C2 to 5 meV precision, about two orders of magnitude more precise than the previously accepted value. Through exploration of the ionization threshold after pumping the 0-3 band of the newly discovered 4(3)Πg ← a(3)Πu band system of C2, the ionization energy of the lowest rovibronic level of the a(3)Πu state was determined to be 11.791(5) eV. Accounting for spin-orbit and rotational effects, we calculate that the ionization energy of the forbidden origin of the a(3)Πu state is 11.790(5) eV, in excellent agreement with quantum thermochemical calculations which give 11.788(10) eV. The experimentally derived ionization energy of X(1)Σg(+) state C2 is 11.866(5) eV.",
                    "score": 0.8537321090698242
                },
                {
                    "id": 14625992,
                    "contents": "Experimental Investigation of the ^{19}Ne(p,γ)^{20}Na Reaction Rate and Implications for Breakout from the Hot CNO Cycle.\nThe ^{19}Ne(p,γ)^{20}Na reaction is the second step of a reaction chain which breaks out from the hot CNO cycle, following the ^{15}O(α,γ)^{19}Ne reaction at the onset of x-ray burst events. We investigate the spectrum of the lowest proton-unbound states in ^{20}Na in an effort to resolve contradictions in spin-parity assignments and extract reliable information about the thermal reaction rate. The proton-transfer reaction ^{19}Ne(d,n)^{20}Na is measured with a beam of the radioactive isotope ^{19}Ne at an energy around the Coulomb barrier and in inverse kinematics. We observe three proton resonances with the ^{19}Ne ground state, at 0.44, 0.66, and 0.82 MeV c.m. energies, which are assigned 3^{+}, 1^{+}, and (0^{+}), respectively. In addition, we identify two resonances with the first excited state in ^{19}Ne, one at 0.20 MeV and one, tentatively, at 0.54 MeV. These observations allow us for the first time to experimentally quantify the astrophysical reaction rate on an excited nuclear state. Our experiment shows an efficient path for thermal proton capture in ^{19}Ne(p,γ)^{20}Na, which proceeds through ground state and excited-state capture in almost equal parts and eliminates the possibility for this reaction to create a bottleneck in the breakout from the hot CNO cycle.",
                    "score": 0.8532829284667969
                },
                {
                    "id": 4416832,
                    "contents": "Unexpected x-ray emission due to formation of bound doubly excited states.\nA strong emission of characteristic M x rays is observed, without an M vacancy initially present, when slow highly charged ions (Ta(q+), q = 39--48) capture a single electron in single collisions with rare gas atoms (He). This is explained by the formation of bound doubly excited states through electron correlation. An elaborate theoretical treatment shows that bound doubly excited states are mixed with states where a Rydberg electron is bound in the core of a highly charged ion. It is striking that this occurs with a large probability (close to unity), and one needs to assume that higher Rydberg states are populated than predicted by the overbarrier model in order to explain the experimental results.",
                    "score": 0.8528236746788025
                },
                {
                    "id": 4724680,
                    "contents": "NUCFRG2: a semiempirical nuclear fragmentation model.\nThe semiempirical abrasion/ablation model has been successful in generating a large nuclear data base for use in the study of high charge and energy (HZE) ion beams, radiation physics and galactic cosmic ray shielding. The cross sections generated agree with the measured HZE fragmentation data to the degree that different experimental groups agree among themselves. Several improvements in the model have been made including a Coulomb trajectory correction, an improved treatment of nuclear attenuation factors, an improved second order correction to the spectator fragment excitation spectrum, a pre-equilibrium emission process, and competitive equilibrium emission of additional hydrogen and helium isotope fragments.",
                    "score": 0.8527974486351013
                },
                {
                    "id": 13178575,
                    "contents": "Laser-nucleus reactions: population of states far above yrast and far from stability.\nNuclear reactions induced by a strong zeptosecond laser pulse are studied theoretically in the quasiadiabatic regime where the photon absorption rate is comparable to the nuclear equilibration rate. We find that multiple photon absorption leads to the formation of a compound nucleus in the so-far unexplored regime of excitation energies several hundred MeV above the yrast line. At these energies, further photon absorption is limited by neutron decay and/or induced nucleon emission. With a laser pulse of ≈ 50 zs duration, proton-rich nuclei far off the line of stability are produced.",
                    "score": 0.8524342775344849
                },
                {
                    "id": 14226596,
                    "contents": "Ultrafast absorption of intense x rays by nitrogen molecules.\nWe devise a theoretical description for the response of nitrogen molecules (N(2)) to ultrashort and intense x rays from the free electron laser Linac Coherent Light Source (LCLS). We set out from a rate-equation description for the x-ray absorption by a nitrogen atom. The equations are formulated using all one-x-ray-photon absorption cross sections and the Auger and radiative decay widths of multiply-ionized nitrogen atoms. Cross sections are obtained with a one-electron theory and decay widths are determined from ab initio computations using the Dirac-Hartree-Slater (DHS) method. We also calculate all binding and transition energies of nitrogen atoms in all charge states with the DHS method as the difference of two self-consistent field (SCF) calculations (ΔSCF method). To describe the interaction with N(2), a detailed investigation of intense x-ray-induced ionization and molecular fragmentation are carried out. As a figure of merit, we calculate ion yields and the average charge state measured in recent experiments at the LCLS. We use a series of phenomenological models of increasing sophistication to unravel the mechanisms of the interaction of x rays with N(2): a single atom, a symmetric-sharing model, and a fragmentation-matrix model are developed. The role of the formation and decay of single and double core holes, the metastable states of N(2)(2+), and molecular fragmentation are explained.",
                    "score": 0.8521595001220703
                },
                {
                    "id": 8254613,
                    "contents": "Many-body ionization in a frozen Rydberg gas.\nIn a dense gas of 300 microK 85Rb atoms of n approximately 50 ionization occurs on a 100 ns time scale, far too fast to be explained by the motion of the atoms or photoionization by 300 K blackbody radiation. Rapid ionization is accompanied by spectral broadening, with the spectrum becoming continuous at n=88 at a density of 5x10(10)cm(-3). The atomic transitions broaden both smoothly and by the emergence of new features, which we attribute to multiple atom absorptions. We attribute the rapid ionization to a sequence of near resonant dipole-dipole transitions through virtual states in this intrinsically many-body system, culminating in the ionization of some of the atoms.",
                    "score": 0.8514366149902344
                },
                {
                    "id": 7052844,
                    "contents": "Chronology of particle emission from the E/A=61 MeV 36Ar+27Al reaction.\nThe emission time chronology of neutrons, protons, and deuterons from the E/A=61 MeV 36Ar+27Al reaction is deduced from two-particle correlation functions.",
                    "score": 0.8505030870437622
                },
                {
                    "id": 8655933,
                    "contents": "Systematics of proton emission.\nA very simple formula is presented that relates the logarithm of the half-life, corrected by the centrifugal barrier, with the Coulomb parameter in proton decay processes. The corresponding experimental data lie on two straight lines which appear as a result of a sudden change in the nuclear shape marking two regions of deformation independently of the angular momentum of the outgoing proton. This feature provides a powerful tool to assign experimentally quantum numbers in proton emitters.",
                    "score": 0.8500704765319824
                },
                {
                    "id": 9617744,
                    "contents": "Do energetic heavy nuclei penetrate deeply into Earth's atmosphere?\nWe calculate the expected fluxes of cosmic ray nuclei with charge 5 &lt;/= Z &lt;/= 28 at various depths in the earth's atmosphere, taking into account the initial charge distribution, ionization loss, and various modes of fragmentation. The flux of surviving heavy nuclei is too low by a factor approximately 10(-10) to account for the ultra-high-energy Centauro events. We describe an experiment to search for highly ionizing particles that may or may not be nuclei.",
                    "score": 0.8497918844223022
                },
                {
                    "id": 12632450,
                    "contents": "Measurement of the first ionization potential of astatine by laser ionization spectroscopy.\nThe radioactive element astatine exists only in trace amounts in nature. Its properties can therefore only be explored by study of the minute quantities of artificially produced isotopes or by performing theoretical calculations. One of the most important properties influencing the chemical behaviour is the energy required to remove one electron from the valence shell, referred to as the ionization potential. Here we use laser spectroscopy to probe the optical spectrum of astatine near the ionization threshold. The observed series of Rydberg states enabled the first determination of the ionization potential of the astatine atom, 9.31751(8) eV. New ab initio calculations are performed to support the experimental result. The measured value serves as a benchmark for quantum chemistry calculations of the properties of astatine as well as for the theoretical prediction of the ionization potential of superheavy element 117, the heaviest homologue of astatine.",
                    "score": 0.8491164445877075
                },
                {
                    "id": 19966005,
                    "contents": "Intensities of the strongest γ-ray transitions originating from the <sup>112g</sup>In decay determined via photoactivation yield measurements.\nAnalyzing the γ-ray spectra of the decay of the <sup112m,g</supIn isomer pair produced by the (γ, n)-reaction the intensities of strongest 606.8, 617.5, 851.2, 1253.5, and 1468.8 keV radiation transitions following the ground state decay were correctly determined. They amounted to 0.87(9), 3.9(4), 0.12(2), 0.17(3), and 0.076(12), respectively, and differ from those given in the current databases.",
                    "score": 0.8488756418228149
                },
                {
                    "id": 6143137,
                    "contents": "Floating Bands in Nuclear Spectroscopy.\nThe methods of heavy ion nuclear reaction spectroscopy are discussed. When combined with large gamma ray arrays and charged particle selection methods, vast amounts of nuclear data are collected and complex nuclear level schemes approaching the extremes of angular momentum result. Often, bands of levels associated with particular nuclei cannot be specifically tied down in the nucleus. Examples of these floating bands are given for (135)Pm and (152)Dy. A correlation of the level schemes of (219)Ra, observed in (223)Th alpha decay and the nuclear reaction (208)Pb((14)C,3n), suggests that the ground state of (219)Ra has not been observed in the nuclear reaction study. The resultant levels in (219)Ra are then interpreted in terms of a reflection asymmetric nuclear model.",
                    "score": 0.8488166332244873
                },
                {
                    "id": 21445458,
                    "contents": "Towards the Limits of Existence of Nuclear Structure: Observation and First Spectroscopy of the Isotope ^{31}K by Measuring Its Three-Proton Decay.\nThe most remote isotope from the proton dripline (by 4 atomic mass units) has been observed: ^{31}K. It is unbound with respect to three-proton (3p) emission, and its decays have been detected in flight by measuring the trajectories of all decay products using microstrip detectors. The 3p emission processes have been studied by the means of angular correlations of ^{28}S+3p and the respective decay vertices. The energies of the previously unknown ground and excited states of ^{31}K have been determined. This provides its 3p separation energy value S_{3p} of -4.6(2)  MeV. Upper half-life limits of 10 ps of the observed ^{31}K states have been derived from distributions of the measured decay vertices.",
                    "score": 0.8484591245651245
                },
                {
                    "id": 7874711,
                    "contents": "Direct observation of the ... 4+-to-2+ ... [corrected] gamma transition in 8Be.\nElectromagnetic transition rates provide an important test for nuclear structure models. The nucleus 8Be exhibits a pronounced alpha-cluster structure and is a building block for more complex cluster nuclei. Here we report on the first observation of the gamma transition between the 4(+) and 2(+) states of 8Be in the 4He+4He reaction. The measured on-resonance cross section of 165+/-54 nb leads to a B(E2) of25+/-8e(2) fm(4), in good agreement with alpha-cluster models and sophisticated ab initio structure calculations.",
                    "score": 0.8483420610427856
                },
                {
                    "id": 11565595,
                    "contents": "Decoherence due to elastic Rayleigh scattering.\nWe present theoretical and experimental studies of the decoherence of hyperfine ground-state superpositions due to elastic Rayleigh scattering of light off resonant with higher lying excited states. We demonstrate that under appropriate conditions, elastic Rayleigh scattering can be the dominant source of decoherence, contrary to previous discussions in the literature. We show that the elastic-scattering decoherence rate of a two-level system is given by the square of the difference between the elastic-scattering amplitudes for the two levels, and that for certain detunings of the light, the amplitudes can interfere constructively even when the elastic-scattering rates from the two levels are equal. We confirm this prediction through calculations and measurements of the total decoherence rate for a superposition of the valence electron spin levels in the ground state of 9Be+ in a 4.5 T magnetic field.",
                    "score": 0.8475825190544128
                },
                {
                    "id": 11389488,
                    "contents": "Photon emissions observed in the decay of 233Th.\nStock solutions of (233)Th were produced by the (232)Th(n,gamma) reaction and multiple purifications were used to obtain relative intensities of weak transitions. Liquid scintillation counting (absolute disintegration rates) and gamma-ray spectroscopy with HPGe detectors yielded absolute photon intensities. Absolute intensities in % (with statistical uncertainties) of prominent radiations (L and K X-rays; 29, 86, and 459 keV gamma-rays) are 8.23(8), 1.32(10), 2.17(1), 1.843(2), and 0.989(2), respectively. These intensities are more precise and approximately 30% lower than previous results.",
                    "score": 0.8475375175476074
                },
                {
                    "id": 17707860,
                    "contents": "X-ray Emission Spectroscopy at X-ray Free Electron Lasers: Limits to Observation of the Classical Spectroscopic Response for Electronic Structure Analysis.\nX-ray free electron lasers (XFELs) provide ultrashort intense X-ray pulses suitable to probe electron dynamics but can also induce a multitude of nonlinear excitation processes. These affect spectroscopic measurements and interpretation, particularly for upcoming brighter XFELs. Here we identify and discuss the limits to observing classical spectroscopy, where only one photon is absorbed per atom for a Mn<sup2+</sup in a light element (O, C, H) environment. X-ray emission spectroscopy (XES) with different incident photon energies, pulse intensities, and pulse durations is presented. A rate equation model based on sequential ionization and relaxation events is used to calculate populations of multiply ionized states during a single pulse and to explain the observed X-ray induced spectral lines shifts. This model provides easy estimation of spectral shifts, which is essential for experimental designs at XFELs and illustrates that shorter X-ray pulses will not overcome sequential ionization but can reduce electron cascade effects.",
                    "score": 0.8471542596817017
                },
                {
                    "id": 10961121,
                    "contents": "Precise electromagnetic tests of ab initio calculations of light nuclei: states in 10Be.\nIn order to test ab initio calculations of light nuclei, we have remeasured lifetimes in 10Be using the Doppler shift attenuation method (DSAM) following the 7Li(7Li,alpha)10Be reaction at 8 and 10 MeV. The new experiments significantly reduce systematic uncertainties in the DSAM technique. The J(pi) = 2(1)(+) state at 3.37 MeV has tau = 205 +/- (5)(stat) +/- (7)(sys) fs corresponding to a B(E2 down) of 9.2(3)e(2) fm(4) in broad agreement with many calculations. The J(pi) = 2(2)(+) state at 5.96 MeV was found to have a B(E2 down) of 0.11(2)e(2) fm(4) and provides a more discriminating test of nuclear models. New Green's function Monte Carlo calculations for these states and transitions with a number of Hamiltonians are also reported and compared to experiment.",
                    "score": 0.8468494415283203
                },
                {
                    "id": 23498592,
                    "contents": "Searching for the Radiative Decay of the Cosmic Neutrino Background with Line-Intensity Mapping.\nWe study the possibility to use line-intensity mapping (LIM) to seek photons from the radiative decay of neutrinos in the cosmic neutrino background. The Standard Model prediction for the rate for these decays is extremely small, but it can be enhanced if new physics increases the neutrino electromagnetic moments. The decay photons will appear as an interloper of astrophysical spectral lines. We propose that the neutrino-decay line can be identified with anisotropies in LIM clustering and also with the voxel intensity distribution. Ongoing and future LIM experiments will have-depending on the neutrino hierarchy, transition, and experiment considered-a sensitivity to an effective electromagnetic transition moment ∼10^{-12}-10^{-8}(m_{i}c^{2}/0.1  eV)^{3/2}μ_{B}, where m_{i} is the mass of the decaying neutrino and μ_{B} is the Bohr magneton. This will be significantly more sensitive than cosmic microwave background spectral distortions, and it will be competitive with stellar cooling studies. As a by-product, we also report an analytic form of the one-point probability distribution function for neutrino-density fluctuations, obtained from the quijote simulations using symbolic regression.",
                    "score": 0.8464038372039795
                },
                {
                    "id": 18538188,
                    "contents": "Nuclear Physics Meets the Sources of the Ultra-High Energy Cosmic Rays.\nThe determination of the injection composition of cosmic ray nuclei within astrophysical sources requires sufficiently accurate descriptions of the source physics and the propagation - apart from controlling astrophysical uncertainties. We therefore study the implications of nuclear data and models for cosmic ray astrophysics, which involves the photo-disintegration of nuclei up to iron in astrophysical environments. We demonstrate that the impact of nuclear model uncertainties is potentially larger in environments with non-thermal radiation fields than in the cosmic microwave background. We also study the impact of nuclear models on the nuclear cascade in a gamma-ray burst radiation field, simulated at a level of complexity comparable to the most precise cosmic ray propagation code. We conclude with an isotope chart describing which information is in principle necessary to describe nuclear interactions in cosmic ray sources and propagation.",
                    "score": 0.8462122678756714
                },
                {
                    "id": 5841874,
                    "contents": "Observation of the 11N ground state\nThe ground state of the proton-rich, unbound nucleus 11N was observed, together with six excited states using the multinucleon transfer reaction 10B(14N,13B)11N at 30A MeV incident energy at Grand Accelerateur National d'Ions Lourds. Levels of 11N are observed as well defined resonances in the spectrum of the 13B ejectiles. They are localized at 1.63(5), 2.16(5), 3.06(8), 3.61(5), 4.33(5), 5.98(10), and 6.54(10) MeV above the 10C+p threshold. The ground-state resonance has a mass excess of 24.618(50) MeV; the experimental width is smaller than theoretical predictions.",
                    "score": 0.8461886644363403
                },
                {
                    "id": 8494627,
                    "contents": "Observation of strong low-lying E1 strength in the two-neutron halo nucleus 11Li.\nAn exclusive measurement has been made of the Coulomb dissociation of the two-neutron halo nucleus 11Li at 70 MeV/nucleon at RIKEN. Strong low-energy (soft) E1 excitation is observed, peaked at about Ex = 0.6 MeV with B(E1) = 1.42(18) e2fm2 for Erel &lt; or = 3 MeV, which was largely missed in previous measurements. This excitation represents the strongest E1 transition ever observed at such low excitation energies. The spectrum is reproduced well by a three-body model with a strong two-neutron correlation, which is further supported by the E1 non-energy-weighted cluster sum rule.",
                    "score": 0.8460906744003296
                },
                {
                    "id": 7783885,
                    "contents": "TeV gamma rays from photodisintegration and daughter deexcitation of cosmic-ray nuclei.\nIt is commonly assumed that high-energy gamma rays are made via either purely electromagnetic processes or the hadronic process of pion production, followed by decay. We investigate astrophysical contexts where a third process (A*) would dominate: namely, the photodisintegration of highly boosted nuclei followed by daughter deexcitation. Starburst regions such as Cygnus OB2 appear to be promising sites for TeV gamma-ray emission via this mechanism. A unique feature of the A* process is a sharp flattening of the energy spectrum below approximately 10 TeV/(T/eV) for gamma-ray emission from a thermal region of temperature T. The A* mechanism described herein offers an important contribution to gamma-ray astronomy in the era of intense observational activity.",
                    "score": 0.84591144323349
                },
                {
                    "id": 17595640,
                    "contents": "Communication: Heavy-Rydberg states of HD and the electron affinity of the deuterium atom.\nThe electron affinity of the deuterium atom has been determined to be 6086.81(27) cm<sup-1</sup from a measurement of the difference between the D<sup+</sup + H<sup-</sup and H<sup+</sup + D<sup-</sup ion-pair dissociation energies and a thermochemical cycle involving the electron affinity of H and the ionization energies of H and D. Heavy-Rydberg states and the ion-pair dissociation thresholds of HD were accessed with good efficiency using a three-photon excitation sequence through the B Σu+1 (v = 22, N = 1) and H¯ Σg+1 (v = 9, N = 0) intermediate levels and the threshold positions were determined using the method of threshold-ion-pair-production spectroscopy.",
                    "score": 0.845718502998352
                },
                {
                    "id": 6207948,
                    "contents": "Feeding of the 232Th levels from the decay of 236U.\nPopulation of the 6+ 332 keV level in 232Th from the decay of 236U was observed for the first time. The 49, 112, and 171 keV gamma-ray energies and relative intensities from the decay of 236U were measured.",
                    "score": 0.845556378364563
                },
                {
                    "id": 23334071,
                    "contents": "Lifetime of the ^{2}F_{7/2} Level in Yb^{+} for Spontaneous Emission of Electric Octupole Radiation.\nWe report a measurement of the radiative lifetime of the ^{2}F_{7/2} level of ^{171}Yb^{+} that is coupled to the ^{2}S_{1/2} ground state via an electric octupole transition. The radiative lifetime is determined to be 4.98(25)×10^{7}  s, corresponding to 1.58(8) yr. The result reduces the relative uncertainty in this exceptionally long excited state lifetime by 1 order of magnitude with respect to previous experimental estimates. Our method is based on the coherent excitation of the corresponding transition and avoids limitations through competing decay processes. The explicit dependence on the laser intensity is eliminated by simultaneously measuring the resonant Rabi frequency and the induced quadratic Stark shift. Combining the result with information on the dynamic differential polarizability permits a calculation of the transition matrix element to infer the radiative lifetime.",
                    "score": 0.8454896807670593
                },
                {
                    "id": 4499140,
                    "contents": "Effects of high-energy electrons and gamma rays directly on protein molecules.\nHigh-energy electrons and gamma rays ionize molecules at random along their trajectories. In each event, chemical bonds are ruptured, releasing radiolytic products that diffuse away. A solution of macromolecules is mostly water whose principal radiation products are H(+) and OH(-). These can diffuse to and react with macromolecules; this indirect action of radiation is responsible for 99.9% of the damage to proteins. In frozen samples, the ionizations still occur randomly and water is still the principle molecular target, but diffusion of radiation products is limited to only a very small distance. At very low temperatures, essentially all the radiation damage to macromolecules is due to primary ionizations occurring directly in those molecules. Therefore, proteins in frozen solutions are only 10(-3) to 10(-4) as sensitive to radiation as in the liquid state. Every molecule that suffered a direct ionization is destroyed; the only surviving molecules are those that escaped ionization. The survival of frozen proteins after irradiation is a direct measure of the mass of the active structures and independent of the presence of other proteins.",
                    "score": 0.8451065421104431
                },
                {
                    "id": 19230915,
                    "contents": "Oscillator strengths and integral cross sections for the valence-shell excitations of nitric oxide studied by fast electron impact.\nThe generalized oscillator strengths for the valence-shell excitations of A<sup2</supΣ<sup+</sup, C<sup2</supΠ, and D<sup2</supΣ<sup+</sup electronic-states of nitric oxide have been determined at an incident electron energy of 1500 eV with an energy resolution of 70 meV. The optical oscillator strengths for these transitions have been obtained by extrapolating the generalized oscillator strengths to the limit that the squared momentum transfer approaches to zero, which give an independent cross-check to the previous experimental and theoretical results. The integral cross sections for the valence-shell excitations of nitric oxide have been determined systematically from the threshold to 2500 eV with the aid of the newly developed BE-scaling method for the first time. The present optical oscillator strengths and integral cross sections of the valence-shell excitations of nitric oxide play an important role in understanding many physics and chemistry of the Earth's upper atmosphere such as the radiative cooling, ozone destruction, day glow, aurora, and so on.",
                    "score": 0.8448220491409302
                },
                {
                    "id": 21615696,
                    "contents": "Can Extreme Electromagnetic Fields Accelerate the α Decay of Nuclei?\nThe possibility to control the α decay channel of atomic nuclei with electromagnetic fields of extreme intensities envisaged for the near future at multipetawatt and exawatt laser facilities is investigated theoretically. Using both analytic arguments based on the Wentzel-Kramers-Brillouin approximation and numerical calculations for the imaginary time method applied in the framework of the α decay precluster model, we show that no experimentally detectable modification of the α decay rate can be observed with super-intense lasers at any so-far-available wavelength. Comparing our predictions with those reported in several recent publications, where a considerable or even giant laser-induced enhancement of the decay rate has been claimed, we identify there the misuse of a standard approximation.",
                    "score": 0.8448208570480347
                },
                {
                    "id": 15698577,
                    "contents": "Theoretical tracking of resonance-enhanced multiple ionization pathways in X-ray free-electron laser pulses.\nWe present an extended Monte Carlo rate equation approach to examine the inner-shell ionization dynamics of atoms in an intense x-ray free-electron laser (XFEL) pulse. In addition to photoionization, Auger decay, and fluorescence processes, we include bound-to-bound transitions in the rate equation calculations. Using an efficient computational scheme, we account for \"hidden resonances\" unveiled during the course of an XFEL pulse. For Ar, the number of possible electron configurations is increased ten-billion-fold over that required under nonresonant conditions. We investigated the complex ionization dynamics of Ar atoms exposed to an 480-eV XFEL pulse, where production of ions above charge state 10+ is not allowed via direct one-photon ionization. We found that resonance-enhanced x-ray multiple ionization pathways play a dominant role in producing these nominally inaccessible charge states. Our calculated results agree with the measured Ar ion yield and pulse-duration dependence. We also predict the surprising ion yields reported earlier for Kr and Xe. The Monte Carlo rate equation method enables theoretical exploration of the complex dynamics of resonant high-intensity x-ray processes. ",
                    "score": 0.8436020016670227
                },
                {
                    "id": 16008470,
                    "contents": "Nuclear Structure-The Future With Radioactive Beams.\nSome examples of new phenomena expected at extreme values of neutron and proton number are discussed, including soft dipole modes and neutron-proton pairing. First results on the N = Z nucleus (62)Ga are presented in the context of the competition between T = 0 and 1 states in odd-odd, self-conjugate nuclei.",
                    "score": 0.8435869216918945
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_14",
        "question": "Calculate the wavelength and the energy of a photon associated with the series limit of the Lyman series.",
        "golden_answers": [
            " 2.18"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 9617205,
                    "contents": "Photon propagation function: a comparison of asymptotic functions.\nAn earlier paper asserts the logarithmic asymptotic identity of various asymptotic functions associated with the photon propagation function, including the spectral weight function and the Gell-Mann-Low function. This note exhibits explicit expressions for the deviations between pairs of functions. It is emphasized that the differences are quantitatively small, and that the various functions have common qualitative characteristics. The discussion refers to a particular method for comparing the functions, which has no special physical status. When that restriction is removed, it becomes possible to prove the general existence of a transformation of variable that will produce the Gell-Mann-Low function from the spectral weight function. This supplies a physical interpretation that has otherwise been missing in the Gell-Mann-Low approach.",
                    "score": 0.896173357963562
                },
                {
                    "id": 9611020,
                    "contents": "Photon propagation function: spectral analysis of its asymptotic form.\nThe physical attitudes of source theory, displacing those of renormalized, perturbative, operator field theory, are used in a simple discussion of the asymptotic behavior of the photon propagation function. A guiding principle is the elementary consistency requirement that, under circumstances where a physical parameter cannot be accurately measured, no sensitivity to its precise value can enter the description of those circumstances. The mathematical tool is the spectral representation of the propagation function, supplemented by an equivalent phase representation. The Gell-Mann-Low equation is recovered, but with their function now interpreted physically as the spectral weight function. A crude inequality is established for the latter, which helps in interpolating between the initial rising behavior and the ultimate zero at infinite mass. There is a brief discussion of the aggressive source theory viewpoint that denies the existence of a \"bare charge\".",
                    "score": 0.8882676362991333
                },
                {
                    "id": 11469371,
                    "contents": "The development of soviet optics and spectroscopy during the past fifty years.\nA history of Soviet spectroscopy is given, with special emphasis on various areas indicating the earliest workers in each specialty and their principal successors; for example, the work of Rozhdestvenskii (anomalous dispersion); Fok (self-consistant field calculations), Terenin (photochemistry, atomic beams), Mandelstam (combination scattering), Vavilov (luminescence, quantum properties of light), Cerenkov (radiation), Chaika (atomic lifetimes), Gross (excitons), and Volkenstein (molecular vibrations).",
                    "score": 0.8758043050765991
                },
                {
                    "id": 11109051,
                    "contents": "Nonlinear optics: the next decade.\nThis paper concludes the Focus Serial assembled of invited papers in key areas of nonlinear optics (Editors: J.M. Dudley and R.W. Boyd), and it discusses new directions for future research in this field.",
                    "score": 0.8751804232597351
                },
                {
                    "id": 10516366,
                    "contents": "Rayleigh centennial.\nThis brief sketch of the contributions of the fourth Baron Rayleigh is intended to supplement the biographical material contained in the October 1964 issue of Applied Optics.",
                    "score": 0.8734971880912781
                },
                {
                    "id": 8657344,
                    "contents": "Photon correlation and scattering: introduction to the feature issue.\nThis special issue of Applied Optics contains research papers on photon correlation and scattering, many of which were presented at the OSA Topical Meeting that was held 16-18 August 2004.",
                    "score": 0.8691038489341736
                },
                {
                    "id": 21057275,
                    "contents": "Author Correction: Analysis of laser radiation using the Nonlinear Fourier transform.\nAn amendment to this paper has been published and can be accessed via a link at the top of the paper.",
                    "score": 0.8683184385299683
                },
                {
                    "id": 4203003,
                    "contents": "The tracks of the Compton effect.\nThe observation of scattered radiations of larger wavelength than the primary had been repeatedly rejected or explained away by many researchers, including Compton. After years of vacillations, he recognized the effect named after him and was the first to develop a quantal equation predicting the wavelength of scattered radiation. It became one of the most significant contributions to modern radiation physics, opening the doors of quantum mechanics.",
                    "score": 0.8661394119262695
                },
                {
                    "id": 7765322,
                    "contents": "Exponentially convergent lattice sums.\nFor any oblique incidence and arbitrarily high order, lattice sums for one-dimensional gratings can be expressed in terms of exponentially convergent series. The scattering Green's function can be efficiently evaluated also in the grating plane. Numerical implementation of the method is 200 times faster than for the previous best result.",
                    "score": 0.8657640218734741
                },
                {
                    "id": 10554651,
                    "contents": "Photon-correlation spectroscopy in the near ultraviolet.\nWe describe the first reported photon-correlation spectroscopy experiments in the ultraviolet (363.8 nm) and briefly discuss the use of this technique to study the short-wavelength relaxation of the internal modes of large, flexible macromolecules, in particular, DNA.",
                    "score": 0.8656319975852966
                },
                {
                    "id": 6716550,
                    "contents": "Inverse scattering theory: renormalization of the Lippmann-Schwinger equation for acoustic scattering in one dimension.\nThe most robust treatment of the inverse acoustic scattering problem is based on the reversion of the Born-Neumann series solution of the Lippmann-Schwinger equation. An important issue for this approach to inversion is the radius of convergence of the Born-Neumann series for Fredholm integral kernels, and especially for acoustic scattering for which the interaction depends on the square of the frequency. By contrast, it is well known that the Born-Neumann series for the Volterra integral equations in quantum scattering are absolutely convergent, independent of the strength of the coupling characterizing the interaction. The transformation of the Lippmann-Schwinger equation from a Fredholm to a Volterra structure by renormalization has been considered previously for quantum scattering calculations and electromagnetic scattering. In this paper, we employ the renormalization technique to obtain a Volterra equation framework for the inverse acoustic scattering series, proving that this series also converges absolutely in the entire complex plane of coupling constant and frequency values. The present results are for acoustic scattering in one dimension, but the method is general. The approach is illustrated by applications to two simple one-dimensional models for acoustic scattering.",
                    "score": 0.8629218935966492
                },
                {
                    "id": 9667893,
                    "contents": "One hundred years of quantum physics.\nThis year marks the 100th anniversary of Max Planck's creation of the quantum concept, an idea so revolutionary that it took nearly 30 years for scientists to develop it into the theory that has transformed the way scientists view reality. In this month's essay, Daniel Kleppner and Roman Jackiw recount how quantum theory, which they rate as \"the most precisely tested and most successful theory in the history of science,\" came to be, how it changed the world, and how it might continue to evolve to make the dream of ultimate understanding of the universe come true.",
                    "score": 0.8604189157485962
                },
                {
                    "id": 10018921,
                    "contents": "Simple dispersion law for arbitrary sequences of dispersive optics.\nWe give a simple general formula for the total angular dispersion due to multiple arbitrary dispersive elements in a series. It is simply the sum of the individual elements' angular dispersions but with each divided by the total spatial magnification afterward (or, equivalently, multiplied by the total angular magnification afterward).",
                    "score": 0.8586061596870422
                },
                {
                    "id": 8679229,
                    "contents": "Photon correlation and scattering: introduction to the feature issue.\nThis feature issue of Applied Optics contains 25 research papers on photon correlation and scattering. Many of the papers in this volume were presented at an OSA Topical Meeting that was held 21-24 August 1996 in Capri, Italy. The focus of these papers is research in dynamic light scattering, surface light scattering, photon correlation, laser velocimetry, and their applications to biological, chemical, and physical processes.",
                    "score": 0.8581752181053162
                },
                {
                    "id": 7103305,
                    "contents": "Resurgence in quasiclassical scattering.\nIn quasiclassical spectral theory, \"resurgence\" means that long periodic orbits can be expressed by short ones in such a way that the spectral determinant is real. The question has thus long been posed whether long scattering orbits can be expressed by short orbits in such a way as to make the quasiclassical scattering matrix unitary. We here find a resurgent and manifestly Hermitean expression for Wigner's R matrix, implying a unitary scattering matrix. The result is particularly important if the average resonance width is comparable with the average resonance spacing.",
                    "score": 0.85802161693573
                },
                {
                    "id": 11899693,
                    "contents": "Fundamental quantum limit to the multiphoton absorption rate for monochromatic light.\nThe local multiphoton absorption rate for an arbitrary quantum state of monochromatic light, taking into account the photon number, momentum, and polarization degrees of freedom, is shown to have an upper bound that can be reached by coherent fields. This surprising result rules out any quantum enhancement of the multiphoton absorption rate by momentum entanglement.",
                    "score": 0.8574761152267456
                },
                {
                    "id": 6502806,
                    "contents": "Theory of the Kapitza-Dirac diffraction effect.\nWe treat the Kapitza-Dirac diffraction effect observed recently by Batelaan et al. using a newly developed nonperturbative quantum-field scattering theory. Our theory shows that an electron beam passing perpendicularly through a focused standing light wave can produce diffraction patterns. Our theory predicts (1) the minimum value of the ponderomotive energy is (Planck's over 2 pi omega)(2)/m(e)c(2), (2) the critical laser intensity above which the first pair of electron diffraction peaks will occur, and (3) the existence of sidebands in the electron spectra separated far from the central band by a momentum of several hundred photons. Our theory provides a unified explanation of the experimental results of Bucksbaum et al. and Batelaan et al.",
                    "score": 0.857369065284729
                },
                {
                    "id": 6490066,
                    "contents": "The exact electromagnetic field description of photon emission, absorption, and radiation pattern. II.\nThis is the second of two articles, the first of which contains a proposed explanation of quantum theory based upon electron nonlocality and classical electrodynamics. In this second article classical field theory is used to describe a unique field set for exchange of radiation between an atomic eigenstate and the far field. The radiation satisfies the thermodynamic condition of reversibility as described by Boltzmann, Planck, and Einstein. The exchanged radiation supports the kinematic properties of photons, and it can be emitted or absorbed by a vanishingly small volume.",
                    "score": 0.8567761182785034
                },
                {
                    "id": 14262614,
                    "contents": "Optical Thomas-Reiche-Kuhn sum rules.\nThe Thomas-Reiche-Kuhn sum rule is a fundamental consequence of the position-momentum commutation relation for an atomic electron and it provides an important constraint on the transition matrix elements for an atom. Analogously, the commutation relations for the electromagnetic field operators in a magnetodielectric medium constrain the properties of the dispersion relations for the medium through four sum rules for the allowed phase and group velocities for polaritons propagating through the medium. These rules apply to all bulk media including the metamaterials designed to provide negative refractive indices. An immediate consequence of this is that it is not possible to construct a medium in which all the polariton modes for a given wavelength lie in the negative-index region.",
                    "score": 0.8566308617591858
                },
                {
                    "id": 21110439,
                    "contents": "On the asymptotic properties of a canonical diffraction integral.\nWe introduce and study a new canonical integral, denoted <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:msubsup<mml:miI</mml:mi <mml:mrow<mml:mo+</mml:mo <mml:mo-</mml:mo</mml:mrow <mml:mrow<mml:miε</mml:mi</mml:mrow </mml:msubsup </mml:math , depending on two complex parameters <iα</i <sub1</sub and <iα</i <sub2</sub. It arises from the problem of wave diffraction by a quarter-plane and is heuristically constructed to capture the complex field near the tip and edges. We establish some region of analyticity of this integral in <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:msup<mml:mrow<mml:miC</mml:mi</mml:mrow <mml:mrow<mml:mn2</mml:mn</mml:mrow </mml:msup </mml:math , and derive its rich asymptotic behaviour as |<iα</i <sub1</sub | and |<iα</i <sub2</sub | tend to infinity. We also study the decay properties of the function obtained from applying a specific double Cauchy integral operator to this integral. These results allow us to show that this integral shares all of the asymptotic properties expected from the key unknown function <iG</i <sub+-</sub arising when the quarter-plane diffraction problem is studied via a two-complex-variables Wiener-Hopf technique (see Assier &amp; Abrahams, <iSIAM J. Appl. Math.</i, in press). As a result, the integral <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:msubsup<mml:miI</mml:mi <mml:mrow<mml:mo+</mml:mo <mml:mo-</mml:mo</mml:mrow <mml:mrow<mml:miε</mml:mi</mml:mrow </mml:msubsup </mml:math can be used to mimic the unknown function <iG</i <sub+-</sub and to build an efficient 'educated' approximation to the quarter-plane problem.",
                    "score": 0.855849027633667
                },
                {
                    "id": 10578126,
                    "contents": "Comment on the expression of a distributed index.\nThe expression of a distributed index by way of power series expansion is commented on from the viewpoints of wave optics and ray optics. A 3-D expression is also proposed.",
                    "score": 0.8558210134506226
                },
                {
                    "id": 21657401,
                    "contents": "On special relativistic effects via classical physics.\nWe present an analytic study of light propagation in a simple Michelson-Morley interferometer as observed by inertial observers to understand any connections among classical physics, optical physics, and special relativity. To that end, we develop coordinate transformations of wave propagation as observed in inertial frames (i.e., non-accelerating reference frames). We find that relativistic and other effects appear naturally as a result of finite light speed. Such effects include wavefront tilt relative to the normal of energy flow with the wavefront normal tilting relative to the Poynting vector.",
                    "score": 0.8552318811416626
                },
                {
                    "id": 10456023,
                    "contents": "Ludvig Lorenz and nineteenth century optical theory: the work of a great Danish scientist.\nThe career of the Danish physicist Ludvig V. Lorenz (1829-1891) is outlined and his contributions to optical theory between 1860 and 1891 are discussed: the elastic theory of light (1860-1861), the phenomenological wave equation (1862-1864), the electrodynamic theory of light (1867), the Lorenz-Lorentz refraction theory (1869), and the theory of scattering of plane waves by spherical particles (1890). The differences between the Lorenz and the Maxwell theories of light are pointed out, and it is argued that Lorenz's phenomenological attitude and indifference to Maxwellian theory were the main reasons why his mature works in optics exerted little influence.",
                    "score": 0.8549781441688538
                },
                {
                    "id": 9097437,
                    "contents": "Systematic perturbation calculation of integrals with applications to physics.\nIn this paper we generalize and improve a method for calculating the period of a classical oscillator and other integrals of physical interest, which was recently developed by some of the authors. We derive analytical expressions that prove to be more accurate than those commonly found in the literature, and test the convergence of the series produced by the approach.",
                    "score": 0.8549211025238037
                },
                {
                    "id": 21421458,
                    "contents": "On powers that are sums of consecutive like powers.\nLet <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:mik</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn</mml:mrow </mml:math be even, and let <ir</i be a non-zero integer. We show that for almost all <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:mid</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn</mml:mrow </mml:math (in the sense of natural density), the equation <DispFormula <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow<mml:msup<mml:mix</mml:mi <mml:mik</mml:mi</mml:msup <mml:mo+</mml:mo <mml:msup<mml:mrow<mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo+</mml:mo <mml:mir</mml:mi <mml:mo)</mml:mo</mml:mrow <mml:mik</mml:mi</mml:msup <mml:mo+</mml:mo <mml:mo⋯</mml:mo <mml:mo+</mml:mo <mml:msup<mml:mrow<mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo+</mml:mo <mml:mrow<mml:mo(</mml:mo <mml:mid</mml:mi <mml:mo-</mml:mo <mml:mn1</mml:mn <mml:mo)</mml:mo</mml:mrow <mml:mir</mml:mi <mml:mo)</mml:mo</mml:mrow <mml:mik</mml:mi</mml:msup <mml:mo=</mml:mo <mml:msup<mml:miy</mml:mi <mml:min</mml:mi</mml:msup <mml:mo,</mml:mo <mml:mspace/ <mml:mix</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:miy</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:min</mml:mi <mml:mo∈</mml:mo <mml:miZ</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:min</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn <mml:mo,</mml:mo</mml:mrow </mml:math </DispFormula has no solutions.",
                    "score": 0.8547986149787903
                },
                {
                    "id": 10443635,
                    "contents": "Optical aberrations described by an alternative series expansion.\nAberrations of optical systems are usually analyzed by decomposing the wavefront aberration at a pupil into a series of terms. The Seidel and Zernike series are two common examples, each with its own strengths and weaknesses. A new aberration series is proposed that combines some of the strengths of each. The new series is consistent with the traditional system of aberration types but enables the straightforward characterization and comparison of different optical systems, independent of pupil size or shape. Expressions for the conversion between the new and common aberration series are given, and the physical interpretations of the different aberrations are discussed.",
                    "score": 0.8547221422195435
                },
                {
                    "id": 23100934,
                    "contents": "Photons think inside the box.\nLight confined to a sheet offers a glimpse into low-dimensional quantum gases.",
                    "score": 0.8546048998832703
                },
                {
                    "id": 6369294,
                    "contents": "A study of the secular equation for rayleigh waves using the root locus method.\nIn a recent note Rahman and Barber [Trans. ASME 62 (1995) 250] proposed an exact expression for the roots of the secular equation for the Rayleigh waves in an isotropic half-space. Using the root locus method, we describe in a very simpler manner the evolution of the roots versus the Poisson's ratio and we derive easily the critical value for which the nature of the roots changes.",
                    "score": 0.854159414768219
                },
                {
                    "id": 8707230,
                    "contents": "Fundamental limits of the dispersion of the two-photon absorption cross section.\nWe rigorously apply the sum rules to the sum-over-states expression to calculate the fundamental limits of the dispersion of the two-photon absorption cross section. A comparison of the theory with the data suggests that the truncated sum rules in the three-level model give a reasonable fundamental limit. Furthermore, we posit that the two-photon absorption cross section near the limit must have only three dominant states, so by default, the three-level model is appropriate. This ansatz is supported by a rigorous analytical calculation that the resonant term gets smaller as more states are added. We also find that the contributions of the nonexplicitly resonant terms cannot be neglected when analyzing real molecules with many excited states, even near resonance. However, puzzling as it may be, extrapolating an off-resonant result to resonance using only the resonant term of the three-level model is shown to be consistent with the exact result. In addition, the off-resonant approximation is shown to scale logarithmically when compared with the full three-level model. This scaling can be used to simplify the analysis of measurements. We find that existing molecules are still far from the fundamental limit; so, there is room for improvement. But, reaching the fundamental limit would require precise control of the energy-level spacing, independently of the transition dipole moments-a task that does not appear possible using today's synthetic approaches. So, we present alternative methods that can still lead to substantial improvements which only require the control of the transition moment to the first excited state. While it is best to normalize measured two-photon absorption cross sections to the fundamental limits when comparing molecules, we show that simply dividing by the square of the number of electrons per molecule yields a good metric for comparison.",
                    "score": 0.8540920615196228
                },
                {
                    "id": 8183925,
                    "contents": "Ray-based propagation of the cross-spectral density.\nWe explore the propagation of the cross-spectral density for scalar and electromagnetic fields based on generalized radiances that are exactly conserved along rays. Two formulas are derived: The first uses all rays to calculate the cross-spectral density exactly, while the second uses only the subset of those rays that pass through a single spatial point to construct an infinite series expression for the cross-spectral density. The evaluation of the truncated series is examined numerically for a variety of fields of varying angular width and coherence and is found to exhibit better convergence to the cross-spectral density when the rays through the centroid between the two observation points are used, when the fields are less coherent, and when the fields are more paraxial. In generalizing the series formula, two new cross-spectral correlations associated with the flux and energy density are examined.",
                    "score": 0.8530914783477783
                },
                {
                    "id": 5250255,
                    "contents": "Analog of the wigner-moyal equation for the electromagnetic field\nThe evolution equation for the Wigner distribution of the classical electromagnetic field is derived for a nonstationary and inhomogeneous optical medium, which is formally similar to the Wigner-Moyal equation for a quantum system. The geometric optics approximation is discussed in detail, and the conservation equation for the number of photons is justified. The influence of dispersion is also considered.",
                    "score": 0.8530257940292358
                },
                {
                    "id": 22566476,
                    "contents": "First-Principle Derivation of Single-Photon Entropy and Maxwell-Jüttner Velocity Distribution.\nThis work is devoted to deriving the entropy of a single photon in a beam of light from first principles. Based on the quantum processes of light-matter interaction, we find that, if the light is not in equilibrium, there are two different ways, depending on whether the photon is being added or being removed from the light, of defining the single-photon entropy of this light. However, when the light is in equilibrium at temperature <iT</i, the two definitions are equivalent and the photon entropy of this light is hν/T. From first principles, we also re-derive the Jüttner velocity distribution showing that, even without interatomic collisions, two-level atoms will relax to the state satisfying the Maxwell-Jüttner velocity distribution when they are moving in blackbody radiation fields.",
                    "score": 0.8528444170951843
                },
                {
                    "id": 23167501,
                    "contents": "Simple renormalization schemes for multiple scattering series expansions.\nA number of renormalization schemes for improving the convergence of multiple scattering series expansions are investigated. Numerical tests on a small Cu(111) cluster demonstrate their effectiveness, for example increasing the rate of convergence by up to a factor 2 or by transforming a divergent series into a convergent one. These techniques can greatly facilitate multiple scattering calculations, especially for spectroscopies such as photoelectron diffraction, Auger electron diffraction, low energy electron diffraction <ietc.</i, where an electron propagates with a kinetic energy of hundreds of eV in a cluster of hundreds of atoms.",
                    "score": 0.8527682423591614
                },
                {
                    "id": 9960962,
                    "contents": "Nonlinear optics.\nRecent advances in the field of nonlinear optical phenomena are reviewed with particular emphasis placed on such topics as parametric oscillation, self-focusing and trapping of laser beams, and stimulated Raman, Rayleigh, and Brillouin scattering. The optical frequency radiation is treated classically in terms of the amplitudes and phases of the electromagnetic fields. The interactions of light waves in a material are then formulated in terms of Maxwell's equations and the electric dipole approximation. In this method, non-linear susceptibility tensors are introduced which relate the induced dipole moment to a power series expansion in field strengths. The tensor nature and the frequency dependence of the nonlinearity coefficients are considered. The various experimental observations are described and interpreted in terms of this formalism.",
                    "score": 0.8525646924972534
                },
                {
                    "id": 9617677,
                    "contents": "The zero dispersion limit for the Korteweg-deVries KdV equation.\nWe use the inverse scattering method to determine the weak limit of solutions of the Korteweg-deVries equation as dispersion tends to zero. The limit, valid for all time, is characterized in terms of a quadratic programming problem which can be solved with the aid of function theoretic methods. For large t, the solutions satisfy Whitham's averaged equations at some times and the equations found by Flaschka et al. at other times.",
                    "score": 0.852260947227478
                },
                {
                    "id": 6973023,
                    "contents": "Kramers-Kronig relations and sum rules in nonlinear optical spectroscopy.\nThe full potential of the Kramers-Kronig relations and sum rules for nonlinear susceptibilities has unfortunately drawn relatively little attention in nonlinear optical spectra analysis. In this feature article a simple treatment of an anharmonic oscillator model in description of the nonlinear susceptibility of media and holomorphic properties of the nonlinear susceptibility were utilized. Using such concepts, conventional Kramers-Kronig, multiply-subtractive Kramers-Kronig, and generalized Kramers-Kronig dispersion relations can be derived. We demonstrate how in practice the variety of different Kramers-Kronig relations mentioned above, as well as various sum rules, can be applied in nonlinear optical spectra analysis. As an example we treat the third-harmonic wave generation spectrum from a polymer.",
                    "score": 0.8517031073570251
                },
                {
                    "id": 8261280,
                    "contents": "Photon correlation and scattering: introduction to the feature issue.\nThis feature issue of Applied Optics contains 31 research papers on photon correlation and scattering, many of which were presented at an OSA Topical Meeting that was held 21-23 August 2000 in Whistler, British Columbia, Canada. These papers focus on research in dynamic light scattering, surface light scattering, photon correlation, and laser velocimetry and their applications to physical, chemical, and biological processes.",
                    "score": 0.8516877293586731
                },
                {
                    "id": 10214933,
                    "contents": "On the Lorentz-Lorenz formula and the Lorentz model of dielectric dispersion: addendum.\nThe approximate equivalence relation equating the frequency dispersion of the Lorentz model alone with that modified by the Lorentz-Lorenz formula is shown to also equate the branch points appearing in each of these two descriptions.",
                    "score": 0.851257860660553
                },
                {
                    "id": 11738323,
                    "contents": "High-accuracy calculations of the refractive indices of optical materials in a wide spectral range.\nThe interaction between light and matter is studied thoroughly by means of the quantum theory. On the basis of it, the refractive indices of types of optical materials are calculated by several formerly experienced formulas. Finally,anew, tested approximate formula with the highest calculated accuracy is obtained, and some groups of valuable parameters are given.",
                    "score": 0.8509007096290588
                },
                {
                    "id": 9066370,
                    "contents": "Fast causal information transmission in a medium with a slow group velocity.\nIt is widely believed that the velocity of information upsiloni encoded on an optical pulse is equal to the group velocity upsilong, at least when upsilong is less than the speed of light in vacuum c. On the other hand, several authors suggest that upsiloni=c, although the size of the signal traveling at this velocity may be small, thereby making it difficult to measure. Here, we measure upsiloni for pulses propagating through a resonant \"slow-light\" medium where upsilong approximately 0.006c. We find upsiloni=1.03c(+0.49c)-0.25c, or that upsiloni approximately 168upsilong, clearly demonstrating that the speed of information cannot be generally described by upsilong, but is characterized by its own velocity.",
                    "score": 0.850763201713562
                },
                {
                    "id": 6490065,
                    "contents": "Electromagnetic fields on a quantum scale. I.\nThis is the first in a series of two articles, the second of which provides an exact electro-magnetic field description of photon emission, absorption, and radiation pattern. Photon energy exchanges are analyzed and shown to be the triggered, regenerative response of a non-local eigenstate electron. This first article presents a model-based, hidden variable analysis of quantum theory that provides the statistical nature of wave functions. The analysis uses the equations of classical electro-magnetism and conservation of energy while modeling an eigenstate electron as a nonlocal entity. Essential to the analysis are physical properties that were discovered and analyzed only after the historical interpretation of quantum mechanics was established: electron non-locality and the standing electro-magnetic energy that accompanies and encompasses an active, electrically small volume. The standing energy produces a driving radiation reaction force that, under certain circumstances, is many orders of magnitude larger than currently accepted values. These properties provide a sufficient basis for the Schrödinger equation as a descriptor of non-relativistic eigenstate electrons in or near equilibrium. The uncertainty principle follows, as does the exclusion principle. The analysis leads to atomic stability and causality in the sense that the status of physical phenomena at any instant specifies the status an instant later.",
                    "score": 0.8506677150726318
                },
                {
                    "id": 7909722,
                    "contents": "Mode analysis in optics through fractional transforms.\nThe relationship between the mode content and the fractional Fourier and fractional Hankel transforms of a function is established. It is shown that the Laguerre-Gauss spectrum of a rotationally symmetric wave front can be determined from the wave front's fractional Hankel transforms taken at the optical axis.",
                    "score": 0.8506669402122498
                },
                {
                    "id": 16803276,
                    "contents": "Relation of the cyclotomic equation with the harmonic and derived series.\nWe associate some (old) convergent series related to definite integrals with the cyclotomic equation x (m) - 1 = 0, for several natural numbers m; for example, for m = 3, x(3) - 1 = (x - 1)(1 + x + x (2)) leads to ∫(1)0 dx(1/(1 +x + x2)) = π/(3√3) = (1 - 1/2) + (1/4 - 1/5) + (1/7 - 1/8) + ... . In some cases, we express the results in terms of the Dirichlet characters. Generalizations for arbitrary m are well defined but do imply integrals and/or series summations rather involved.",
                    "score": 0.8506150245666504
                },
                {
                    "id": 10792390,
                    "contents": "A limit on the variation of the speed of light arising from quantum gravity effects.\nA cornerstone of Einstein's special relativity is Lorentz invariance-the postulate that all observers measure exactly the same speed of light in vacuum, independent of photon-energy. While special relativity assumes that there is no fundamental length-scale associated with such invariance, there is a fundamental scale (the Planck scale, l(Planck) approximately 1.62 x 10(-33) cm or E(Planck) = M(Planck)c(2) approximately 1.22 x 10(19) GeV), at which quantum effects are expected to strongly affect the nature of space-time. There is great interest in the (not yet validated) idea that Lorentz invariance might break near the Planck scale. A key test of such violation of Lorentz invariance is a possible variation of photon speed with energy. Even a tiny variation in photon speed, when accumulated over cosmological light-travel times, may be revealed by observing sharp features in gamma-ray burst (GRB) light-curves. Here we report the detection of emission up to approximately 31 GeV from the distant and short GRB 090510. We find no evidence for the violation of Lorentz invariance, and place a lower limit of 1.2E(Planck) on the scale of a linear energy dependence (or an inverse wavelength dependence), subject to reasonable assumptions about the emission (equivalently we have an upper limit of l(Planck)/1.2 on the length scale of the effect). Our results disfavour quantum-gravity theories in which the quantum nature of space-time on a very small scale linearly alters the speed of light.",
                    "score": 0.8503972291946411
                },
                {
                    "id": 10962019,
                    "contents": "Resolution of the abraham-minkowski dilemma.\nThe dilemma of identifying the correct form for the momentum of light in a medium has run for a century and has been informed by many distinguished contributions, both theoretical and experimental. We show that both the Abraham and Minkowski forms of the momentum density are correct, with the former being the kinetic momentum and the latter the canonical momentum. This identification allows us to explain why the experiments supporting each of the rival momenta gave the results that they did. The inclusion of dispersion and absorption provides an interesting subtlety, but does not change our conclusion.",
                    "score": 0.8503631949424744
                },
                {
                    "id": 9000508,
                    "contents": "A variational principle in optics.\nWe derive a new variational principle in optics. We first formulate the principle for paraxial waves and then generalize it to arbitrary waves. The new principle, unlike the Fermat principle, concerns both the phase and the intensity of the wave. In particular, the principle provides a method for finding the ray mapping between two surfaces in space from information on the wave's intensity there. We show how to apply the new principle to the problem of phase reconstruction from intensity measurements.",
                    "score": 0.84998619556427
                },
                {
                    "id": 7105910,
                    "contents": "High-order variational calculation for the frequency of time-periodic solutions.\nWe develop a convergent variational perturbation theory for the frequency of time-periodic solutions of nonlinear dynamical systems. The power of the theory is illustrated by applying it to the Duffing oscillator.",
                    "score": 0.8499440550804138
                },
                {
                    "id": 11477337,
                    "contents": "Opticsat the naional physical laboratory.\nOptics is spread widely in the National Physical Laboratory, anda condensed account is given of some of the highlights.",
                    "score": 0.8496734499931335
                },
                {
                    "id": 8532142,
                    "contents": "Happy centenary, photon.\nOne hundred years ago Albert Einstein introduced the concept of the photon. Although in the early years after 1905 the evidence for the quantum nature of light was not compelling, modern experiments--especially those using photon pairs--have beautifully confirmed its corpuscular character. Research on the quantum properties of light (quantum optics) triggered the evolution of the whole field of quantum information processing, which now promises new technology, such as quantum cryptography and even quantum computers.",
                    "score": 0.849604070186615
                },
                {
                    "id": 8988048,
                    "contents": "Calculation of the Rayleigh-Sommerfeld diffraction integral by exact integration of the fast oscillating factor.\nWe describe a numerical method that can be used to calculate the propagation of light in a medium of constant (possibly complex) index of refraction n. The method integrates the Rayleigh-Sommerfeld diffraction integral numerically. After an appropriate change of integration variables, the integrand of the diffraction integral is split into a slowly varying and an (often fast) oscillating quadratic factor. The slowly varying factor is approximated by a spline fit, and the resulting Fresnel integrals are subsequently integrated exactly. Although the method is not as fast as methods involving a fast Fourier transform, such as plane-wave propagation or Fresnel approximation, it is accurate over a greater range than these methods.",
                    "score": 0.849140465259552
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_15",
        "question": "Another application of the relationship given in Problem $1-48$ has to do with the excitedstate energies and lifetimes of atoms and molecules. If we know that the lifetime of an excited state is $10^{-9} \\mathrm{~s}$, then what is the uncertainty in the energy of this state?\r\n",
        "golden_answers": [
            " 7"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 9611041,
                    "contents": "On the lifetime-width relation for a decaying state and the uncertainty principle.\nA new formulation of the uncertainty relation of position and momentum, and of energy and time, is presented. The connection between the lifetime of excited states and the energy width of these states, which does not follow from the usual uncertainty relation, is shown to be a consequence of the expression here derived.",
                    "score": 0.8801239728927612
                },
                {
                    "id": 16097319,
                    "contents": "Maximum entropy principle for stationary states underpinned by stochastic thermodynamics.\nThe selection of an equilibrium state by maximizing the entropy of a system, subject to certain constraints, is often powerfully motivated as an exercise in logical inference, a procedure where conclusions are reached on the basis of incomplete information. But such a framework can be more compelling if it is underpinned by dynamical arguments, and we show how this can be provided by stochastic thermodynamics, where an explicit link is made between the production of entropy and the stochastic dynamics of a system coupled to an environment. The separation of entropy production into three components allows us to select a stationary state by maximizing the change, averaged over all realizations of the motion, in the principal relaxational or nonadiabatic component, equivalent to requiring that this contribution to the entropy production should become time independent for all realizations. We show that this recovers the usual equilibrium probability density function (pdf) for a conservative system in an isothermal environment, as well as the stationary nonequilibrium pdf for a particle confined to a potential under nonisothermal conditions, and a particle subject to a constant nonconservative force under isothermal conditions. The two remaining components of entropy production account for a recently discussed thermodynamic anomaly between over- and underdamped treatments of the dynamics in the nonisothermal stationary state. ",
                    "score": 0.8753068447113037
                },
                {
                    "id": 8785359,
                    "contents": "A quantum violation of the second law?\nAn apparent violation of the second law of thermodynamics occurs when an atom coupled to a zero-temperature bath, being necessarily in an excited state, is used to extract work from the bath. Here the fallacy is that it takes work to couple the atom to the bath and this work must exceed that obtained from the atom. For the example of an oscillator coupled to a bath described by the single relaxation time model, the mean oscillator energy and the minimum work required to couple the oscillator to the bath are both calculated explicitly and in closed form. It is shown that the minimum work always exceeds the mean oscillator energy, so there is no violation of the second law.",
                    "score": 0.8702036142349243
                },
                {
                    "id": 8616642,
                    "contents": "Equations-of-motion approach to quantum mechanics: application to a model phase transition.\nWe present a generalized equations-of-motion method that efficiently calculates energy spectra and matrix elements for algebraic models. The method is applied to a five-dimensional quartic oscillator that exhibits a quantum phase transition between vibrational and rotational phases. For certain parameters, 10 x 10 matrices give better results than obtained by diagonalizing 1000 x 1000 matrices.",
                    "score": 0.8676780462265015
                },
                {
                    "id": 17039001,
                    "contents": "An Efficient Variational Principle for the Direct Optimization of Excited States.\nWe present a variational principle that enables systematically improvable predictions for individual excited states through an efficient Monte Carlo evaluation. We demonstrate its compatibility with different ansatzes and with both real space and Fock space sampling and discuss its potential for use in the solid state. In numerical demonstrations for challenging molecular excitations, the method rivals or surpasses the accuracy of very high level methods using drastically more compact wave function approximations. ",
                    "score": 0.8623085618019104
                },
                {
                    "id": 14855842,
                    "contents": "Computing the optimal path in stochastic dynamical systems.\nIn stochastic systems, one is often interested in finding the optimal path that maximizes the probability of escape from a metastable state or of switching between metastable states. Even for simple systems, it may be impossible to find an analytic form of the optimal path, and in high-dimensional systems, this is almost always the case. In this article, we formulate a constructive methodology that is used to compute the optimal path numerically. The method utilizes finite-time Lyapunov exponents, statistical selection criteria, and a Newton-based iterative minimizing scheme. The method is applied to four examples. The first example is a two-dimensional system that describes a single population with internal noise. This model has an analytical solution for the optimal path. The numerical solution found using our computational method agrees well with the analytical result. The second example is a more complicated four-dimensional system where our numerical method must be used to find the optimal path. The third example, although a seemingly simple two-dimensional system, demonstrates the success of our method in finding the optimal path where other numerical methods are known to fail. In the fourth example, the optimal path lies in six-dimensional space and demonstrates the power of our method in computing paths in higher-dimensional spaces.",
                    "score": 0.858344316482544
                },
                {
                    "id": 20999235,
                    "contents": "A Generalized Variational Principle with Applications to Excited State Mean Field Theory.\nWe present a generalization of the variational principle that is compatible with any Hamiltonian eigenstate that can be specified uniquely by a list of properties. This variational principle appears to be compatible with a wide range of electronic structure methods, including mean field theory, density functional theory, multireference theory, and quantum Monte Carlo. Like the standard variational principle, this generalized variational principle amounts to the optimization of a nonlinear function that, in the limit of an arbitrarily flexible wave function, has the desired Hamiltonian eigenstate as its global minimum. Unlike the standard variational principle, it can target excited states and select individual states in cases of degeneracy or near-degeneracy. As an initial demonstration of how this approach can be useful in practice, we employ it to improve the optimization efficiency of excited state mean field theory by an order of magnitude. With this improved optimization, we are able to demonstrate that the accuracy of the corresponding second-order perturbation theory rivals that of singles-and-doubles equation-of-motion coupled cluster in a substantially broader set of molecules than could be explored by our previous optimization methodology.",
                    "score": 0.857856810092926
                },
                {
                    "id": 22499973,
                    "contents": "Some minimal notes on notation and minima: A comment on \"How particular is the physics of the free energy principle?\" by Aguilera, Millidge, Tschantz, and Buckley.\nWe comment on a technical critique of the free energy principle in linear systems by Aguilera, Millidge, Tschantz, and Buckley, entitled \"How Particular is the Physics of the Free Energy Principle?\" Aguilera and colleagues identify an ambiguity in the flow of the mode of a system, and we discuss the context for this ambiguity in earlier papers, and their proposal of a more adequate interpretation of these equations. Following that, we discuss a misinterpretation in their treatment of surprisal and variational free energy, especially with respect to their gradients and their minima. In sum, we argue that the results in the target paper are accurate and stand up to rigorous scrutiny; we also highlight that they, nonetheless, do not undermine the FEP.",
                    "score": 0.857358455657959
                },
                {
                    "id": 16077452,
                    "contents": "Anharmonic densities of states: A general dynamics-based solution.\nDensity of states is a fundamental physical characteristic that lies at the foundation of statistical mechanics and theoretical constructs that derive from them (e.g., kinetic rate theories, phase diagrams, and others). Even though most real physical systems are anharmonic, the vibrational density of states is customarily treated within the harmonic approximation, or with some partial, often limited, account for anharmonicity. The reason for this is that the problem of anharmonic densities of states stubbornly resisted a general and exact, yet convenient and straightforward in applications, solution. Here we formulate such a solution within both classical and quantum mechanics. It is based on actual dynamical behavior of systems as a function of energy and as observed, or monitored, on a chosen time scale, short or long. As a consequence, the resulting anharmonic densities of states are fully dynamically informed and, in general, time-dependent. As such, they lay the ground for formulation of new statistical mechanical frameworks that incorporate time and are ergodic, by construction, with respect to actual dynamical behavior of systems. ",
                    "score": 0.8571152687072754
                },
                {
                    "id": 19788122,
                    "contents": "Some Interesting Observations on the Free Energy Principle.\nBiehl et al. (2021) present some interesting observations on an early formulation of the free energy principle. We use these observations to scaffold a discussion of the technical arguments that underwrite the free energy principle. This discussion focuses on solenoidal coupling between various (subsets of) states in sparsely coupled systems that possess a Markov blanket-and the distinction between exact and approximate Bayesian inference, implied by the ensuing Bayesian mechanics.",
                    "score": 0.8561128973960876
                },
                {
                    "id": 10899338,
                    "contents": "Weisskopf-Wigner decay of excited oscillator states.\nWe investigate the analogy between exponential decay of a quantum system into a continuum, and laser-induced excitation of a molecular wave packet. We find that the analogy exists, but it is not as clear-cut for the excited vibrational states of the electronic molecular ground state, as it is for the corresponding vibrational ground state.",
                    "score": 0.8554291129112244
                },
                {
                    "id": 15934738,
                    "contents": "State-Selective Excitation of Quantum Systems via Geometrical Optimization.\nWe lay out the foundations of a general method of quantum control via geometrical optimization. We apply the method to state-selective population transfer using ultrashort transform-limited pulses between manifolds of levels that may represent, e.g., state-selective transitions in molecules. Assuming that certain states can be prepared, we develop three implementations: (i) preoptimization, which implies engineering the initial state within the ground manifold or electronic state before the pulse is applied; (ii) postoptimization, which implies engineering the final state within the excited manifold or target electronic state, after the pulse; and (iii) double-time optimization, which uses both types of time-ordered manipulations. We apply the schemes to two important dynamical problems: To prepare arbitrary vibrational superposition states on the target electronic state and to select weakly coupled vibrational states. Whereas full population inversion between the electronic states only requires control at initial time in all of the ground vibrational levels, only very specific superposition states can be prepared with high fidelity by either pre- or postoptimization mechanisms. Full state-selective population inversion requires manipulating the vibrational coherences in the ground electronic state before the optical pulse is applied and in the excited electronic state afterward, but not during all times. ",
                    "score": 0.8545578122138977
                },
                {
                    "id": 9652577,
                    "contents": "Violation of the exponential-decay law at long times.\nFirst-principles quantum mechanical calculations show that the exponential-decay law for any metastable state is only an approximation and predict an asymptotically algebraic contribution to the decay for sufficiently long times. In this Letter, we measure the luminescence decays of many dissolved organic materials after pulsed laser excitation over more than 20 lifetimes and obtain the first experimental proof of the turnover into the nonexponential decay regime. As theoretically expected, the strength of the nonexponential contributions scales with the energetic width of the excited state density distribution whereas the slope indicates the broadening mechanism.",
                    "score": 0.8542588949203491
                },
                {
                    "id": 14457361,
                    "contents": "The calculations of excited-state properties with Time-Dependent Density Functional Theory.\nIn this tutorial review, we show how Time-Dependent Density Functional Theory (TD-DFT) has become a popular tool for computing the signatures of electronically excited states, and more specifically, the properties directly related to the optical (absorption and emission) spectra of molecules. We discuss the properties that can be obtained with widely available programs as well as how to account for the environmental effects (solvent and surfaces) and present recent applications in these fields. We next expose the transformation of the TD-DFT results into chemically intuitive parameters (colours as well as charge-transfer distances). Eventually, the non-specialised reader will find a series of advices and warnings necessary to perform her/his first TD-DFT calculations.",
                    "score": 0.8534494638442993
                },
                {
                    "id": 23259394,
                    "contents": "How particular is the physics of the free energy principle?\nThe free energy principle (FEP) states that any dynamical system can be interpreted as performing Bayesian inference upon its surrounding environment. Although, in theory, the FEP applies to a wide variety of systems, there has been almost no direct exploration or demonstration of the principle in concrete systems. In this work, we examine in depth the assumptions required to derive the FEP in the simplest possible set of systems - weakly-coupled non-equilibrium linear stochastic systems. Specifically, we explore (i) how general the requirements imposed on the statistical structure of a system are and (ii) how informative the FEP is about the behaviour of such systems. We discover that two requirements of the FEP - the Markov blanket condition (i.e. a statistical boundary precluding direct coupling between internal and external states) and stringent restrictions on its solenoidal flows (i.e. tendencies driving a system out of equilibrium) - are only valid for a very narrow space of parameters. Suitable systems require an absence of perception-action asymmetries that is highly unusual for living systems interacting with an environment. More importantly, we observe that a mathematically central step in the argument, connecting the behaviour of a system to variational inference, relies on an implicit equivalence between the dynamics of the average states of a system with the average of the dynamics of those states. This equivalence does not hold in general even for linear stochastic systems, since it requires an effective decoupling from the system's history of interactions. These observations are critical for evaluating the generality and applicability of the FEP and indicate the existence of significant problems of the theory in its current form. These issues make the FEP, as it stands, not straightforwardly applicable to the simple linear systems studied here and suggest that more development is needed before the theory could be applied to the kind of complex systems that describe living and cognitive processes.",
                    "score": 0.8533742427825928
                },
                {
                    "id": 8322155,
                    "contents": "Statistical mechanical theory for steady state systems. VI. Variational principles.\nSeveral variational principles that have been proposed for nonequilibrium systems are analyzed. These include the principle of minimum rate of entropy production due to Prigogine [Introduction to Thermodynamics of Irreversible Processes (Interscience, New York, 1967)], the principle of maximum rate of entropy production, which is common on the internet and in the natural sciences, two principles of minimum dissipation due to Onsager [Phys. Rev. 37, 405 (1931)] and to Onsager and Machlup [Phys. Rev. 91, 1505 (1953)], and the principle of maximum second entropy due to Attard [J. Chem.. Phys. 122, 154101 (2005); Phys. Chem. Chem. Phys. 8, 3585 (2006)]. The approaches of Onsager and Attard are argued to be the only viable theories. These two are related, although their physical interpretation and mathematical approximations differ. A numerical comparison with computer simulation results indicates that Attard's expression is the only accurate theory. The implications for the Langevin and other stochastic differential equations are discussed.",
                    "score": 0.8516950607299805
                },
                {
                    "id": 13058808,
                    "contents": "A derivation of the master equation from path entropy maximization.\nThe master equation and, more generally, Markov processes are routinely used as models for stochastic processes. They are often justified on the basis of randomization and coarse-graining assumptions. Here instead, we derive nth-order Markov processes and the master equation as unique solutions to an inverse problem. We find that when constraints are not enough to uniquely determine the stochastic model, an nth-order Markov process emerges as the unique maximum entropy solution to this otherwise underdetermined problem. This gives a rigorous alternative for justifying such models while providing a systematic recipe for generalizing widely accepted stochastic models usually assumed to follow from the first principles.",
                    "score": 0.8516834378242493
                },
                {
                    "id": 8655835,
                    "contents": "Time-optimal quantum evolution.\nWe present a general framework for finding the time-optimal evolution and the optimal Hamiltonian for a quantum system with a given set of initial and final states. Our formulation is based on the variational principle and is analogous to that for the brachistochrone in classical mechanics. We reduce the problem to a formal equation for the Hamiltonian which depends on certain constraint functions specifying the range of available Hamiltonians. For some simple examples of the constraints, we explicitly find the optimal solutions.",
                    "score": 0.8508502244949341
                },
                {
                    "id": 8661642,
                    "contents": "Transformation of time-resolved spectra to lifetime-resolved spectra by maximum entropy inversion of the laplace transform.\nWe present a method for the analysis of time-resolved spectroscopic data following first-order kinetics. The time traces at all the available spectroscopic channels (e.g., wavelength or wavenumber) are inverse Laplace transformed. The transformation is stabilized by the maximum entropy method generalized for solutions without sign-restriction. In this way, time-resolved spectra can be converted to lifetime-resolved spectra, where bands appear at coordinates corresponding to their spectroscopic maxima and time constant of appearance (negative amplitude) or disappearance (positive amplitude). From the lifetime-resolved spectra, the number of exponentially decaying components, their time constants, and their decay-associated spectra are readily available. Moreover, since bands are spread in two dimensions extra band-resolution is possible. We named this method of transforming time-resolved spectra into lifetime-resolved spectra multi-spectroscopic channel maximum entropy inversion of the Laplace transform (M-MaxEnt-iLT). The basis of M-MaxEnt-iLT is presented in detail and its properties and limitations are thoroughly discussed. We also show how the combination of M-MaxEnt-iLT with spectral smoothing or deconvolution can improve the appearance and/or band resolution of the obtained lifetime-resolved spectra.",
                    "score": 0.8507103323936462
                },
                {
                    "id": 5275615,
                    "contents": "Unstable decay and state selection.\nThe decay of unstable states when several metastable states are available for occupation is investigated using path-integral techniques. Specifically, a method is described that enables the probabilities with which the metastable states are occupied to be calculated by finding optimal paths, and fluctuations about them, in the weak-noise limit. The method is illustrated on a system described by two coupled Langevin equations, which are found in the study of instabilities in fluid dynamics and superconductivity. The problem involves a subtle interplay between nonlinearities and noise, and a naive approximation scheme that does not take this into account is shown to be unsatisfactory. The use of optimal paths is briefly reviewed and then applied to finding the conditional probability of ending up in one of the metastable states, having begun in the unstable state. There are several aspects of the calculation that distinguish it from most others involving optimal paths: (i) the paths do not begin and end on an attractor, and moreover, the final point is to a large extent arbitrary, (ii) the interplay between the fluctuations and the leading-order contribution are at the heart of the method, and (iii) the final result involves quantities that are not exponentially small in the noise strength. This final result, which gives the probability of a particular state being selected in terms of the parameters of the dynamics, is remarkably simple and agrees well with the results of numerical simulations. The method should be applicable to similar problems in a number of other areas, such as state selection in lasers, activationless chemical reactions, and population dynamics in fluctuating environments.",
                    "score": 0.8507054448127747
                },
                {
                    "id": 6975629,
                    "contents": "Optimal paths and the calculation of state selection probabilities.\nThe addition of noise to a dynamical system means that initial states near points of instability may no longer decay to a unique stable state. A common example of this behavior occurs in a dynamical system with two degrees of freedom and with two or more stable states. If the initial state of the system is near the separatrices bounding the basins of attraction of these stable states, then the addition of noise to the system means that there is a nonzero probability that the stable state selected is in a different basin of attraction to that of the initial state. We discuss a method of calculating these state-selection probabilities based on a path-integral representation of the stochastic dynamics. The relationship of this approach to a method based on the solution of the backward Fokker-Planck equation is particularly stressed, since this was used in previous studies of problems of this type. However, while the method based on the backward Fokker-Planck equation is a powerful one for systems with one degree of freedom, in systems with more degrees of freedom it is much less useful. Since the standard method of solution in this case involves a series of mappings onto a deterministic dynamics which is simply the classical dynamics associated with the path-integral formulation, we argue that for systems with more than one degree of freedom, the path-integral method is a very natural way of calculating state-selection probabilities. We illustrate this on a simple example taken from population biology, and find that the state-selection probabilities are in excellent agreement with Monte Carlo simulations.",
                    "score": 0.85044264793396
                },
                {
                    "id": 7311266,
                    "contents": "Decay rates and survival probabilities in open quantum systems.\nWe provide the first statistical analysis of the decay rates of strongly driven 3D atomic Rydberg states. The distribution of the rates exhibits universal features due to Anderson localization, while universality of the time dependent decay requires particular initial conditions.",
                    "score": 0.8503457903862
                },
                {
                    "id": 13699129,
                    "contents": "Optimal control theory--closing the gap between theory and experiment.\nOptimal control theory and optimal control experiments are state-of-the-art tools to control quantum systems. Both methods have been demonstrated successfully for numerous applications in molecular physics, chemistry and biology. Modulated light pulses could be realized, driving these various control processes. Next to the control efficiency, a key issue is the understanding of the control mechanism. An obvious way is to seek support from theory. However, the underlying search strategies in theory and experiment towards the optimal laser field differ. While the optimal control theory operates in the time domain, optimal control experiments optimize the laser fields in the frequency domain. This also implies that both search procedures experience a different bias and follow different pathways on the search landscape. In this perspective we review our recent developments in optimal control theory and their applications. Especially, we focus on approaches, which close the gap between theory and experiment. To this extent we followed two ways. One uses sophisticated optimization algorithms, which enhance the capabilities of optimal control experiments. The other is to extend and modify the optimal control theory formalism in order to mimic the experimental conditions.",
                    "score": 0.850136399269104
                },
                {
                    "id": 9964818,
                    "contents": "A time-dependent semiempirical approach to determining excited states.\nWe study a time-dependent semiempirical method to determine excitation energies, TD-PM3. This semiempirical method allows large molecules to be treated. A Linear-response Chebyshev approach yields the TD-PM3 spectrum very efficiently. Spectra and excitation energies were tested by comparing it with the results obtained using TD-DFT (Time Dependent-Density Functional Theory), using both small and large basis sets. They were also compared to PM3-CI, Time Dependent-Hartree Fock using the STO-3G basis set, and to experiment. TD-PM3 results generally match better the large-basis set calculations than the small-basis TD-DFT do; excitation energies are almost always accurate to within about 20% or less, except for a few small molecules. Accuracy improves as the molecules get larger.",
                    "score": 0.8501177430152893
                },
                {
                    "id": 6204137,
                    "contents": "Analysis of kinetics using a hybrid maximum-entropy/nonlinear-least-squares method: application to protein folding.\nA hybrid analysis that combines the maximum entropy method (MEM) with nonlinear least squares (NLS) fitting has been developed to interpret a general time-dependent signal. Data that include processes of opposite sign and a slow baseline drift can be inverted to obtain both a continuous distribution of lifetimes and a sum of discrete exponentials. Fits by discrete exponentials are performed with initial parameters determined from the distribution of lifetimes obtained with the MEM. The regularization of the parameter space achieved by the MEM stabilizes the introduction of each successive exponential in the NLS fits. This hybrid approach is particularly useful when fitting by a large number of exponentials. Revision of the MEM \"prior\" based on features in the data can improve the lifetime distribution obtained. Standard errors in the mean are estimated automatically for raw data. The results presented for simulated data and for fluorescence measurements of protein folding illustrate the utility and accuracy of the hybrid algorithm. Analysis of the folding of dihydrofolate reductase reveals six kinetic processes, one more than previously reported.",
                    "score": 0.8492588996887207
                },
                {
                    "id": 18953521,
                    "contents": "Excitation Number: Characterizing Multiply Excited States.\nHow many electrons are excited in an electronic transition? In this Letter, we introduce the excitation number η to answer this question when the initial and final states are each modeled by a single-determinant wave function. We show that calculated η values lie close to positive integers, leading to unambiguous assignments of the number of excited electrons. This contrasts with previous definitions of excitation quantities which can lead to mis-assignments. We consider several examples where η provides improved excited-state characterizations.",
                    "score": 0.849115252494812
                },
                {
                    "id": 10826683,
                    "contents": "An efficient method for computing steady state solutions with Gillespie's direct method.\nGillespie's direct method is a stochastic simulation algorithm that may be used to calculate the steady state solution of a chemically reacting system. Recently the all possible states method was introduced as a way of accelerating the convergence of the simulations. We demonstrate that while the all possible states (APS) method does reduce the number of required trajectories, it is actually much slower than the original algorithm for most problems. We introduce the elapsed time method, which reformulates the process of recording the species populations. The resulting algorithm yields the same results as the original method, but is more efficient, particularly for large models. In implementing the elapsed time method, we present robust methods for recording statistics and empirical probability distributions. We demonstrate how to use the histogram distance to estimate the error in steady state solutions.",
                    "score": 0.8488268852233887
                },
                {
                    "id": 11626417,
                    "contents": "Current trends in finite-time thermodynamics.\nThe cornerstone of finite-time thermodynamics is all about the price of haste and how to minimize it. Reversible processes may be ultimately efficient, but they are unrealistically slow. In all situations-chemical, mechanical, economical-we pay extra to get the job done quickly. Finite-time thermodynamics can be used to develop methods to limit that extra expenditure, be it in energy, entropy production, money, or something entirely different. Finite-time thermodynamics also includes methods to calculate the optimal path or mode of operation to achieve this minimal expenditure. The concept is to place the system of interest in contact with a time-varying environment which will coax the system along the desired path, much like guiding a horse along by waving a carrot in front of it.",
                    "score": 0.8488023281097412
                },
                {
                    "id": 8024408,
                    "contents": "Bayesian maximum entropy (two-dimensional) lifetime distribution reconstruction from time-resolved spectroscopic data.\nTime-resolved spectroscopy is often used to monitor the relaxation processes (or reactions) of physical, chemical, and biochemical systems after some fast physical or chemical perturbation. Time-resolved spectra contain information about the relaxation kinetics, in the form of macroscopic time constants of decay and their decay associated spectra. In the present paper we show how the Bayesian maximum entropy inversion of the Laplace transform (MaxEnt-iLT) can provide a lifetime distribution without sign-restrictions (or two-dimensional (2D)-lifetime distribution), representing the most probable inference given the data. From the reconstructed (2D) lifetime distribution it is possible to obtain the number of exponentials decays, macroscopic rate constants, and exponential amplitudes (or their decay associated spectra) present in the data. More importantly, the obtained (2D) lifetime distribution is obtained free from pre-conditioned ideas about the number of exponential decays present in the data. In contrast to the standard regularized maximum entropy method, the Bayesian MaxEnt approach automatically estimates the regularization parameter, providing an unsupervised and more objective analysis. We also show that the regularization parameter can be automatically determined by the L-curve and generalized cross-validation methods, providing (2D) lifetime reconstructions relatively close to the Bayesian best inference. Finally, we propose the use of MaxEnt-iLT for a more objective discrimination between data-supported and data-unsupported quantitative kinetic models, which takes both the data and the analysis limitations into account. All these aspects are illustrated with realistic time-resolved Fourier transform infrared (FT-IR) synthetic spectra of the bacteriorhodopsin photocycle.",
                    "score": 0.8486752510070801
                },
                {
                    "id": 20455334,
                    "contents": "Excited states in variational Monte Carlo using a penalty method.\nIn this article, the authors present a technique using variational Monte Carlo to solve for excited states of electronic systems. This technique is based on enforcing orthogonality to lower energy states, which results in a simple variational principle for the excited states. Energy optimization is then used to solve for the excited states. This technique is applied to the well-characterized benzene molecule, in which ∼10 000 parameters are optimized for the first 12 excited states. Agreement within ∼0.2 eV is obtained with higher scaling coupled cluster methods; small disagreements with experiment are likely due to vibrational effects.",
                    "score": 0.8484846949577332
                },
                {
                    "id": 7572509,
                    "contents": "Maximum Caliber: a variational approach applied to two-state dynamics.\nWe show how to apply a general theoretical approach to nonequilibrium statistical mechanics, called Maximum Caliber, originally suggested by E. T. Jaynes [Annu. Rev. Phys. Chem. 31, 579 (1980)], to a problem of two-state dynamics. Maximum Caliber is a variational principle for dynamics in the same spirit that Maximum Entropy is a variational principle for equilibrium statistical mechanics. The central idea is to compute a dynamical partition function, a sum of weights over all microscopic paths, rather than over microstates. We illustrate the method on the simple problem of two-state dynamics, A&lt;--&gt;B, first for a single particle, then for M particles. Maximum Caliber gives a unified framework for deriving all the relevant dynamical properties, including the microtrajectories and all the moments of the time-dependent probability density. While it can readily be used to derive the traditional master equation and the Langevin results, it goes beyond them in also giving trajectory information. For example, we derive the Langevin noise distribution rather than assuming it. As a general approach to solving nonequilibrium statistical mechanics dynamical problems, Maximum Caliber has some advantages: (1) It is partition-function-based, so we can draw insights from similarities to equilibrium statistical mechanics. (2) It is trajectory-based, so it gives more dynamical information than population-based approaches like master equations; this is particularly important for few-particle and single-molecule systems. (3) It gives an unambiguous way to relate flows to forces, which has traditionally posed challenges. (4) Like Maximum Entropy, it may be useful for data analysis, specifically for time-dependent phenomena.",
                    "score": 0.8482524156570435
                },
                {
                    "id": 15727809,
                    "contents": "Improved maximum entropy method for the analysis of fluorescence spectroscopy data: evaluating zero-time shift and assessing its effect on the determination of fluorescence lifetimes.\nA new algorithm based on the Maximum Entropy Method (MEM) is proposed for recovering both the lifetime distribution and the zero-time shift from time-resolved fluorescence decay intensities. The developed algorithm allows the analysis of complex time decays through an iterative scheme based on entropy maximization and the Brent method to determine the minimum of the reduced chi-squared value as a function of the zero-time shift. The accuracy of this algorithm has been assessed through comparisons with simulated fluorescence decays both of multi-exponential and broad lifetime distributions for different values of the zero-time shift. The method is capable of recovering the zero-time shift with an accuracy greater than 0.2% over a time range of 2000 ps. The center and the width of the lifetime distributions are retrieved with relative discrepancies that are lower than 0.1% and 1% for the multi-exponential and continuous lifetime distributions, respectively. The MEM algorithm is experimentally validated by applying the method to fluorescence measurements of the time decays of the flavin adenine dinucleotide (FAD). ",
                    "score": 0.8481364250183105
                },
                {
                    "id": 18928894,
                    "contents": "Linear-Response Time-Dependent Embedded Mean-Field Theory.\nWe present a time-dependent (TD) linear-response description of excited electronic states within the framework of embedded mean-field theory (EMFT). TD-EMFT allows for subsystems to be described at different mean-field levels of theory, enabling straightforward treatment of excited states and transition properties. We provide benchmark demonstrations of TD-EMFT for both local and nonlocal excitations in organic molecules, as well as applications to chlorophyll a, solvatochromic shifts of a dye in solution, and sulfur K-edge X-ray absorption spectroscopy (XAS). It is found that mixed-basis implementations of TD-EMFT lead to substantial errors in terms of transition properties; however, as previously found for ground-state EMFT, these errors are largely eliminated with the use of Fock-matrix corrections. These results indicate that TD-EMFT is a promising method for the efficient, multilevel description of excited-state electronic structure and dynamics in complex systems.",
                    "score": 0.8479721546173096
                },
                {
                    "id": 17475916,
                    "contents": "The Right Answer for the Right Reason: My Personal Goal for Quantum Chemistry.\nA brief history of quantum theory is given to illustrate the barriers to progress caused by preconceived ideas. The biases in my own thinking which I had to overcome to approach the right answer for the right reason are discussed. This is followed by a personal autobiography illustrating how I have led a life of serendipity with no real sense of purpose. Chance events have shaped my life. The algorithms for which I am best known are briefly discussed. Then highlights from the many applications of theory to excited states, bonding in ice, spin properties and magnetism, (e,2e) shake-up spectra, and organic reactions are mentioned. This wide range of applications is mostly due to accidental collaboration with colleagues who sought my help. My real interest was in developing methods which could address these problems.",
                    "score": 0.8478958606719971
                },
                {
                    "id": 16958470,
                    "contents": "Equation of Motion Theory for Excited States in Variational Monte Carlo and the Jastrow Antisymmetric Geminal Power in Hilbert Space.\nAn equation of motion formalism for excited states in variational Monte Carlo is derived, and a pilot implementation for the Jastrow-modified antisymmetric geminal power is tested. In single excitations across a range of small molecules, this combination is shown to be intermediate in accuracy between configuration interaction singles and equation of motion coupled cluster with singles and doubles. For double excitations, energy errors are found to be similar to those for coupled cluster. ",
                    "score": 0.8470940589904785
                },
                {
                    "id": 16344399,
                    "contents": "Algorithms for optimized maximum entropy and diagnostic tools for analytic continuation.\nAnalytic continuation of numerical data obtained in imaginary time or frequency has become an essential part of many branches of quantum computational physics. It is, however, an ill-conditioned procedure and thus a hard numerical problem. The maximum-entropy approach, based on Bayesian inference, is the most widely used method to tackle that problem. Although the approach is well established and among the most reliable and efficient ones, useful developments of the method and of its implementation are still possible. In addition, while a few free software implementations are available, a well-documented, optimized, general purpose, and user-friendly software dedicated to that specific task is still lacking. Here we analyze all aspects of the implementation that are critical for accuracy and speed and present a highly optimized approach to maximum entropy. Original algorithmic and conceptual contributions include (1) numerical approximations that yield a computational complexity that is almost independent of temperature and spectrum shape (including sharp Drude peaks in broad background, for example) while ensuring quantitative accuracy of the result whenever precision of the data is sufficient, (2) a robust method of choosing the entropy weight α that follows from a simple consistency condition of the approach and the observation that information- and noise-fitting regimes can be identified clearly from the behavior of χ^{2} with respect to α, and (3) several diagnostics to assess the reliability of the result. Benchmarks with test spectral functions of different complexity and an example with an actual physical simulation are presented. Our implementation, which covers most typical cases for fermions, bosons, and response functions, is available as an open source, user-friendly software. ",
                    "score": 0.8468945622444153
                },
                {
                    "id": 11877920,
                    "contents": "Molecular-orbital-free algorithm for excited states in time-dependent perturbation theory.\nA nonlinear conjugate gradient optimization scheme is used to obtain excitation energies within the random phase approximation (RPA). The solutions to the RPA eigenvalue equation are located through a variational characterization using a modified Thouless functional, which is based upon an asymmetric Rayleigh quotient, in an orthogonalized atomic orbital representation. In this way, the computational bottleneck of calculating molecular orbitals is avoided. The variational space is reduced to the physically-relevant transitions by projections. The feasibility of an RPA implementation scaling linearly with system size N is investigated by monitoring convergence behavior with respect to the quality of initial guess and sensitivity to noise under thresholding, both for well- and ill-conditioned problems. The molecular-orbital-free algorithm is found to be robust and computationally efficient, providing a first step toward large-scale, reduced complexity calculations of time-dependent optical properties and linear response. The algorithm is extensible to other forms of time-dependent perturbation theory including, but not limited to, time-dependent density functional theory.",
                    "score": 0.8467912673950195
                },
                {
                    "id": 14238833,
                    "contents": "Progress in time-dependent density-functional theory.\nThe classic density-functional theory (DFT) formalism introduced by Hohenberg, Kohn, and Sham in the mid-1960s is based on the idea that the complicated N-electron wave function can be replaced with the mathematically simpler 1-electron charge density in electronic structure calculations of the ground stationary state. As such, ordinary DFT cannot treat time-dependent (TD) problems nor describe excited electronic states. In 1984, Runge and Gross proved a theorem making TD-DFT formally exact. Information about electronic excited states may be obtained from this theory through the linear response (LR) theory formalism. Beginning in the mid-1990s, LR-TD-DFT became increasingly popular for calculating absorption and other spectra of medium- and large-sized molecules. Its ease of use and relatively good accuracy has now brought LR-TD-DFT to the forefront for this type of application. As the number and the diversity of applications of TD-DFT have grown, so too has our understanding of the strengths and weaknesses of the approximate functionals commonly used for TD-DFT. The objective of this article is to continue where a previous review of TD-DFT in Volume 55 of the Annual Review of Physical Chemistry left off and highlight some of the problems and solutions from the point of view of applied physical chemistry. Because doubly-excited states have a particularly important role to play in bond dissociation and formation in both thermal and photochemistry, particular emphasis is placed on the problem of going beyond or around the TD-DFT adiabatic approximation, which limits TD-DFT calculations to nominally singly-excited states.",
                    "score": 0.8465460538864136
                },
                {
                    "id": 9124104,
                    "contents": "Transition state theory: variational formulation, dynamical corrections, and error estimates.\nTransition state theory (TST) is revisited, as well as evolutions upon TST such as variational TST in which the TST dividing surface is optimized so as to minimize the rate of recrossing through this surface and methods which aim at computing dynamical corrections to the TST transition rate constant. The theory is discussed from an original viewpoint. It is shown how to compute exactly the mean frequency of transition between two predefined sets which either partition phase space (as in TST) or are taken to be well-separated metastable sets corresponding to long-lived conformation states (as necessary to obtain the actual transition rate constants between these states). Exact and approximate criterions for the optimal TST dividing surface with minimum recrossing rate are derived. Some issues about the definition and meaning of the free energy in the context of TST are also discussed. Finally precise error estimates for the numerical procedure to evaluate the transmission coefficient kappaS of the TST dividing surface are given, and it is shown that the relative error on kappaS scales as 1/square root(kappaS) when kappaS is small. This implies that dynamical corrections to the TST rate constant can be computed efficiently if and only if the TST dividing surface has a transmission coefficient kappaS which is not too small. In particular, the TST dividing surface must be optimized upon (for otherwise kappaS is generally very small), but this may not be sufficient to make the procedure numerically efficient (because the optimal dividing surface has maximum kappaS, but this coefficient may still be very small).",
                    "score": 0.8463351726531982
                },
                {
                    "id": 4491232,
                    "contents": "Relaxation, the Boltzmann-Jeans conjecture, and chaos.\nSlow (logarithmic) relaxation from a highly excited state is studied in a Hamiltonian system with many degrees of freedom. The relaxation time is shown to increase as the exponential of the square root of the energy of excitation, in agreement with the Boltzmann-Jeans conjecture, while it is found to be inversely proportional to residual Kolmogorov-Sinai entropy, introduced in this Rapid Communication. The increase of the thermodynamic entropy through this relaxation process is found to be proportional to this quantity.",
                    "score": 0.8462626934051514
                },
                {
                    "id": 8762868,
                    "contents": "Piecewise adiabatic passage with a series of femtosecond pulses.\nWe develop a method of executing complete population transfers between quantum states in a piecewise manner using a series of femtosecond laser pulses. The method can be applied to a large class of problems as it benefits from the high peak powers and large spectral bandwidths afforded by femtosecond pulses. The degree of population transfer is robust to a wide variation in the absolute and relative intensities, durations, and time ordering of the pulses. The method is studied in detail for atomic sodium where piecewise adiabatic population transfer, as well as the induction of Ramsey-type interferences, is demonstrated.",
                    "score": 0.8457049131393433
                },
                {
                    "id": 23761738,
                    "contents": "The Time-Evolution of States in Quantum Mechanics according to the <i>ETH</i>-Approach.\nIt is argued that the Schrödinger equation does not yield a correct description of the quantum-mechanical time evolution of states of isolated physical systems featuring events. A general statistical law replacing unitary Schrödinger evolution of states is then formulated within the so-called <iETH</i-Approach to Quantum Mechanics. This law eliminates the infamous \"measurement problem.\" Our general concepts and results are illustrated by an analysis of simple models describing a very heavy atom coupled to the quantized radiation field. In the limit where the speed of light tends to infinity these models can be treated quite explicitly.",
                    "score": 0.8456861972808838
                },
                {
                    "id": 4416759,
                    "contents": "Hierarchy of local minimum solutions of Heisenberg's uncertainty principle.\nWe derive a new hierarchy of local minimum Heisenberg-uncertainty states by introducing a superposition of \"small waves\" onto some initial state. Our objective is to increase the resolution in one observable, with the least decrease in the resolution in the conjugate observable. This leads to a constrained minimization which in a well-defined sense yields the best possible way of achieving this goal. The results are relevant to many topics (e.g., quantum optics and control, Bose-Einstein condensation, path integration, etc.).",
                    "score": 0.8456168174743652
                },
                {
                    "id": 12254550,
                    "contents": "A quantum algorithm for obtaining the energy spectrum of a physical system without guessing its eigenstates.\nWe present a quantum algorithm that provides a general approach for obtaining the energy spectrum of a physical system without making a guess on its eigenstates. In this algorithm, a probe qubit is coupled to a quantum register R which consists of one ancilla qubit and an n-qubit register that represents the system. R is prepared in a general reference state, and a general excitation operator that acts on R is constructed. The probe exhibits a dynamical response only when it is resonant with a transition from the reference state to an excited state of R which contains the eigenstates of the system. By varying the probe's frequency, the energy spectrum and the eigenstates of the system can be obtained. ",
                    "score": 0.845603346824646
                },
                {
                    "id": 9240029,
                    "contents": "Escape or switching at short times.\nIn the standard Arrhenius picture [S. Arrhenius, Z. Phys. Chem., Stoechiom. Verwandtschaftsl. 4, 226 (1889); L. Néel, Ann. Geophys. (C.N.R.S.) 5, 99 (1949)] of thermal switching or escape from a metastable to a stable state, the escape probability per unit time P(s)(t) decreases monotonically with time t as P(s)(t) approximately e(-t/tau(D)), where the decay time tau(D) = tau0e(U/k(B)T), with U the energy barrier, k(B)T the thermal energy, and tau0 the time between escape attempts. Here, we extend the Arrhenius picture to shorter times by deriving general conditions under which P(s)(t) is peaked rather than monotonic, and showing that in the simplest scenario the peak time tau(P) diverges with tau(D) as ln(tau(D)).",
                    "score": 0.8455047607421875
                },
                {
                    "id": 11980949,
                    "contents": "KOALA: a program for the processing and decomposition of transient spectra.\nExtracting meaningful kinetic traces from time-resolved absorption spectra is a non-trivial task, particularly for solution phase spectra where solvent interactions can substantially broaden and shift the transition frequencies. Typically, each spectrum is composed of signal from a number of molecular species (e.g., excited states, intermediate complexes, product species) with overlapping spectral features. Additionally, the profiles of these spectral features may evolve in time (i.e., signal nonlinearity), further complicating the decomposition process. Here, we present a new program for decomposing mixed transient spectra into their individual component spectra and extracting the corresponding kinetic traces: KOALA (Kinetics Observed After Light Absorption). The software combines spectral target analysis with brute-force linear least squares fitting, which is computationally efficient because of the small nonlinear parameter space of most spectral features. Within, we demonstrate the application of KOALA to two sets of experimental transient absorption spectra with multiple mixed spectral components. Although designed for decomposing solution-phase transient absorption data, KOALA may in principle be applied to any time-evolving spectra with multiple components. ",
                    "score": 0.8454136848449707
                },
                {
                    "id": 7351113,
                    "contents": "Analytic solution for the nondegenerate quantum control problem.\nWe present an analytic solution for the nondegenerate quantum control problem, i.e., the transfer of a deliberate amount of population, 0%-100%, between arbitrary initial Psi(t)&gt; and final Psi'(t)&gt; states, which can be expanded in terms of nondegenerate energy eigenstates k&gt;. The solution constitutes a robust two-photon multicomponent adiabatic passage, via an intermediate eigenstate 0&gt;, which relies on three types of \"null states.\"",
                    "score": 0.8454123139381409
                },
                {
                    "id": 10321225,
                    "contents": "An equivalent condition for a sequence to be the sequence of partial entropies.\nWe show that a sequence is the sequence of partial entropies of some dynamical system with respect to a partition of the phase space if and only if it is non-negative, increasing, and has decreasing increments.",
                    "score": 0.8453270196914673
                },
                {
                    "id": 10116099,
                    "contents": "Solving the spectroscopic phase: imaging excited wave packets and extracting excited state potentials from fluorescence data.\nWe develop an inversion scheme for obtaining the signs of transition-dipole amplitudes from fluorescence line intensities. Using the amplitudes thus obtained we show how to extract highly accurate excited state potential(s) and the transition-dipole(s) as a function of inter-nuclear displacements. The same dipole amplitudes can also be used to extract the phase and amplitude of unknown time-evolving wave packets, in essentially a quantum non-demolition manner. The procedure, which is demonstrated for the A((1)∑) and B((1)Π(u)) states of the Na(2) molecule, is shown to yield reliable results even when we are given incomplete or uncertain data. We also demonstrate the success of our approach in extracting double minimum potentials. The inversion scheme is in principle applicable to any polyatomic molecule.",
                    "score": 0.8449928760528564
                },
                {
                    "id": 18403029,
                    "contents": "Connection between nonlinear energy optimization and instantons.\nHow systems transit between different stable states under external perturbation is an important practical issue. We discuss here how a recently developed energy optimization method for identifying the minimal disturbance necessary to reach the basin boundary of a stable state is connected to the instanton trajectory from large deviation theory of noisy systems. In the context of the one-dimensional Swift-Hohenberg equation, which has multiple stable equilibria, we first show how the energy optimization method can be straightforwardly used to identify minimal disturbances-minimal seeds-for transition to specific attractors from the ground state. Then, after generalizing the technique to consider multiple, equally spaced-in-time perturbations, it is shown that the instanton trajectory is indeed the solution of the energy optimization method in the limit of infinitely many perturbations provided a specific norm is used to measure the set of discrete perturbations. Importantly, we find that the key features of the instanton can be captured by a low number of discrete perturbations (typically one perturbation per basin of attraction crossed). This suggests a promising new diagnostic for systems for which it may be impractical to calculate the instanton.",
                    "score": 0.8448347449302673
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_16",
        "question": "One of the most powerful modern techniques for studying structure is neutron diffraction. This technique involves generating a collimated beam of neutrons at a particular temperature from a high-energy neutron source and is accomplished at several accelerator facilities around the world. If the speed of a neutron is given by $v_{\\mathrm{n}}=\\left(3 k_{\\mathrm{B}} T / m\\right)^{1 / 2}$, where $m$ is the mass of a neutron, then what temperature is needed so that the neutrons have a de Broglie wavelength of $50 \\mathrm{pm}$ ?",
        "golden_answers": [
            " 2500"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 633774,
                    "contents": "Neutron scattering: progress and prospects.\nOver the last decade the unique properties of neutrons have proven useful in a growing number of scientific disciplines. Neutron scattering, traditionally the probe of choice for many magnetic and spectroscopic studies, is now firmly established as an invaluable complement to x-ray scattering for structural and dynamic studies within many other areas of the material sciences, chemistry, and biology. In recent years the instruments and techniques have matured to the point where they are of increasing relevance to the understanding and design of improved practical, everyday materials.",
                    "score": 0.9325442314147949
                },
                {
                    "id": 14363003,
                    "contents": "The early development of neutron diffraction: science in the wings of the Manhattan Project.\nAlthough neutron diffraction was first observed using radioactive decay sources shortly after the discovery of the neutron, it was only with the availability of higher intensity neutron beams from the first nuclear reactors, constructed as part of the Manhattan Project, that systematic investigation of Bragg scattering became possible. Remarkably, at a time when the war effort was singularly focused on the development of the atomic bomb, groups working at Oak Ridge and Chicago carried out key measurements and recognized the future utility of neutron diffraction quite independent of its contributions to the measurement of nuclear cross sections. Ernest O. Wollan, Lyle B. Borst and Walter H. Zinn were all able to observe neutron diffraction in 1944 using the X-10 graphite reactor and the CP-3 heavy water reactor. Subsequent work by Wollan and Clifford G. Shull, who joined Wollan's group at Oak Ridge in 1946, laid the foundations for widespread application of neutron diffraction as an important research tool.",
                    "score": 0.9263914823532104
                },
                {
                    "id": 11233021,
                    "contents": "Neutron crystallography: opportunities, challenges, and limitations.\nNeutron crystallography has had an important, but relatively small role in structural biology over the years. In this review of recently determined neutron structures, a theme emerges of a field currently expanding beyond its traditional boundaries, to address larger and more complex problems, with smaller samples and shorter data collection times, and employing more sophisticated structure determination and refinement methods. The origin of this transformation can be found in a number of advances including first, the development of neutron image-plates and quasi-Laue methods at nuclear reactor neutron sources and the development of time-of-flight Laue methods and electronic detectors at spallation neutron sources; second, new facilities and methods for sample perdeuteration and crystallization; third, new approaches and computational tools for structure determination.",
                    "score": 0.9234020709991455
                },
                {
                    "id": 9691426,
                    "contents": "Slow neutron scattering experiments.\nNeutron scattering is a versatile technique that has been successfully applied to condensed-matter physics, biology, polymer science, chemistry, and materials science. The United States lost its leadership role in this field to Western Europe about 10 years ago. Recently, a modest investment in the United States in new facilities and a positive attitude on the part of the national laboratories toward outside users have resulted in a dramatic increase in the number of U.S. scientists involved in neutron scattering research. Plans are being made for investments in new and improved facilities that could return the leadership role to the United States.",
                    "score": 0.9213672876358032
                },
                {
                    "id": 4384992,
                    "contents": "Neutrons expand the field of structural biology.\nNeutron protein crystallography aids the identification of all the hydrogen atoms in biological macromolecules and has helped to establish hydration patterns in proteins. Recent technical innovations, such as the development of the neutron imaging plate, have made it possible to shorten the prohibitively long amount of time required to collect a full diffraction data set. These instrumental advances have been applied to Laue diffractometry, as well as to more conventional data collection techniques, such as those using monochromatized neutron beams.",
                    "score": 0.9194479584693909
                },
                {
                    "id": 14736579,
                    "contents": "Outline of Neutron Scattering Formalism.\nNeutron scattering formalism is briefly surveyed. Topics touched upon include coherent and incoherent scattering, bound and free cross-sections, the Van Hove formalism, magnetic scattering, elastic scattering, the static approximation, sum rules, small angle scattering, inelastic scattering, thermal diffuse scattering, quasielastic scattering, and neutron optics.",
                    "score": 0.9115505814552307
                },
                {
                    "id": 6668040,
                    "contents": "Chemical applications of neutron scattering.\nNeutron scattering represents a versatile technique for chemists, as it explores the structure and dynamics of materials at the atomic scale. This review gives an outline of the neutron scattering formalism and describes diffraction and inelastic and quasielastic scattering techniques. Applications to chemistry are illustrated by examples from recent work on crystalline and liquid organic materials, including heterogeneous systems, bulk polymers and polymer solutions. There is particular emphasis on systems where hydrogen bonding plays a significant role. With more powerful sources and improved instrumentation in prospect, there is considerable potential for future extension of these methods to increasingly complex materials.",
                    "score": 0.9108710289001465
                },
                {
                    "id": 9670424,
                    "contents": "Neutron protein crystallography: beyond the folding structure of biological macromolecules.\nNeutron diffraction provides an experimental method of directly locating H atoms in proteins, a technique complementary to ultra-high-resolution X-ray diffraction. Three different types of neutron diffractometers for biological macromolecules have been constructed in Japan, France and the USA, and they have been used to determine the crystal structures of proteins up to resolution limits of 1.5-2.5 A. Results relating to H-atom positions and hydration patterns in proteins have been obtained from these studies. Examples include the geometrical details of hydrogen bonds, the role of H atoms in enzymatic activity, CH3 configuration, H/D exchange in proteins and oligonucleotides, and the dynamical behavior of hydration structures, all of which have been extracted from these structural results and reviewed. Other techniques, such as the growth of large single crystals and a database of hydrogen and hydration in proteins, are described.",
                    "score": 0.9092358350753784
                },
                {
                    "id": 11719079,
                    "contents": "A history of neutrons in biology: the development of neutron protein crystallography at BNL and LANL.\nThe first neutron diffraction data were collected from crystals of myoglobin almost 42 years ago using a step-scan diffractometer with a single detector. Since then, major advances have been made in neutron sources, instrumentation and data collection and analysis, and in biochemistry. Fundamental discoveries about enzyme mechanisms, biological complex structures, protein hydration and H-atom positions have been and continue to be made using neutron diffraction. The promise of neutrons has not changed since the first crystal diffraction data were collected. Today, with the developments of beamlines at spallation neutron sources and the use of the Laue method for data collection, the field of neutrons in structural biology has renewed vitality.",
                    "score": 0.906528115272522
                },
                {
                    "id": 12079264,
                    "contents": "Seeing the chemistry in biology with neutron crystallography.\nNew developments in macromolecular neutron crystallography have led to an increasing number of structures published over the last decade. Hydrogen atoms, normally invisible in most X-ray crystal structures, become visible with neutrons. Using X-rays allows one to see structure, while neutrons allow one to reveal the chemistry inherent in these macromolecular structures. A number of surprising and sometimes controversial results have emerged; because it is difficult to see or predict hydrogen atoms in X-ray structures, when they are seen by neutrons they can be in unexpected locations with important chemical and biological consequences. Here we describe examples of chemistry seen with neutrons for the first time in biological macromolecules over the past few years. ",
                    "score": 0.9049370288848877
                },
                {
                    "id": 15948525,
                    "contents": "Neutron protein crystallography: A complementary tool for locating hydrogens in proteins.\nNeutron protein crystallography is a powerful tool for investigating protein chemistry because it directly locates hydrogen atom positions in a protein structure. The visibility of hydrogen and deuterium atoms arises from the strong interaction of neutrons with the nuclei of these isotopes. Positions can be unambiguously assigned from diffraction at resolutions typical of protein crystals. Neutrons have the additional benefit to structural biology of not inducing radiation damage in protein crystals. The same crystal could be measured multiple times for parametric studies. Here, we review the basic principles of neutron protein crystallography. The information that can be gained from a neutron structure is presented in balance with practical considerations. Methods to produce isotopically-substituted proteins and to grow large crystals are provided in the context of neutron structures reported in the literature. Available instruments for data collection and software for data processing and structure refinement are described along with technique-specific strategies including joint X-ray/neutron structure refinement. Examples are given to illustrate, ultimately, the unique scientific value of neutron protein crystal structures. ",
                    "score": 0.9048511981964111
                },
                {
                    "id": 4944557,
                    "contents": "Geometrical effects in diffraction analysis.\nThe use of X-ray and neutron scattering as a tool to study phase transitions is well established. As techniques improve and experiments are made under successively higher resolution, the need to consider the role of both the distribution of diffracting length scales and the incident-beam coherence volume is emphasized. The interplay of diffracting length scales and the beam coherence volume no longer permits calculation of diffraction profiles in terms of the sample intensity response convolved with an instrumental resolution function. Rather, the probe and sample now enter the calculation on an equal footing at the level of the scattering amplitudes. Under these conditions, it is found that the summation of coherent scattering amplitudes leads to characteristic profiles in wave-vector and, in the case of resonant X-ray scattering, energy space. In this latter case, in the vicinity of strong absorption edges, as used for example in resonant magnetic X-ray diffraction, the energy dependence of diffraction profiles may uniquely allow spatial localization of the scattering volume below the sample surface. This observation may considerably augment the range and power of resonant X-ray scattering.",
                    "score": 0.9033832550048828
                },
                {
                    "id": 12838307,
                    "contents": "Neutron scattering techniques and applications in structural biology.\nNeutron scattering is exquisitely sensitive to the position, concentration, and dynamics of hydrogen atoms in materials and is a powerful tool for the characterization of structure-function and interfacial relationships in biological systems. Modern neutron scattering facilities offer access to a sophisticated, nondestructive suite of instruments for biophysical characterization that provides spatial and dynamic information spanning from Ångstroms to microns and from picoseconds to microseconds, respectively. Applications in structural biology range from the atomic-resolution analysis of individual hydrogen atoms in enzymes through to meso- and macro-scale analysis of complex biological structures, membranes, and assemblies. The large difference in neutron scattering length between hydrogen and deuterium allows contrast variation experiments to be performed and enables H/D isotopic labeling to be used for selective and systematic analysis of the local structure, dynamics, and interactions of multi-component systems. This overview describes the available techniques and summarizes their practical application to the study of biomolecular systems.",
                    "score": 0.902544379234314
                },
                {
                    "id": 11405220,
                    "contents": "Small-angle neutron scattering for molecular biology: basics and instrumentation.\nAs researchers strive to understand the interplay between the complex molecular systems that make up living cells, tools for characterizing the interactions between the various players involved have developed. Small-angle neutron scattering (SANS) plays an important role in building a molecular-level understanding of the structures of macromolecular systems that make up cells. SANS is widely applicable to the study of biological structures including, but by no means limited to, protein-protein or protein-nucleic acid complexes, lipid membranes, cellular scaffolding, and amyloid plaques. Here, we present a brief description of the technique as it is commonly applied to the study of biological systems and an overview instrumentation that is available at the various facilities around the world.",
                    "score": 0.9017825126647949
                },
                {
                    "id": 17874762,
                    "contents": "Dynamic Neutron Scattering by Biological Systems.\nDynamic neutron scattering directly probes motions in biological systems on femtosecond to microsecond timescales. When combined with molecular dynamics simulation and normal mode analysis, detailed descriptions of the forms and frequencies of motions can be derived. We examine vibrations in proteins, the temperature dependence of protein motions, and concepts describing the rich variety of motions detectable using neutrons in biological systems at physiological temperatures. New techniques for deriving information on collective motions using coherent scattering are also reviewed.",
                    "score": 0.9014912247657776
                },
                {
                    "id": 4919364,
                    "contents": "Neutron scattering: good news for biotechnology.\nIn its application to biological systems, neutron scattering is still an emerging technology with a great deal of potential. A consequence of the native interaction between neutrons and biological samples is that the hydrogen isotopes (1)H and (2)H are most significant in dynamical and structural studies, respectively.",
                    "score": 0.9006407260894775
                },
                {
                    "id": 18910294,
                    "contents": "Neutron Crystallography for the Study of Hydrogen Bonds in Macromolecules.\n<bAbstract</b<b:</b The hydrogen bond (H bond) is one of the most important interactions that form the foundation of secondary and tertiary protein structure. Beyond holding protein structures together, H bonds are also intimately involved in solvent coordination, ligand binding, and enzyme catalysis. The H bond by definition involves the light atom, H, and it is very difficult to study directly, especially with X-ray crystallographic techniques, due to the poor scattering power of H atoms. Neutron protein crystallography provides a powerful, complementary tool that can give unambiguous information to structural biologists on solvent organization and coordination, the electrostatics of ligand binding, the protonation states of amino acid side chains and catalytic water species. The method is complementary to X-ray crystallography and the dynamic data obtainable with NMR spectroscopy. Also, as it gives explicit H atom positions, it can be very valuable to computational chemistry where exact knowledge of protonation and solvent orientation can make a large difference in modeling. This article gives general information about neutron crystallography and shows specific examples of how the method has contributed to structural biology, structure-based drug design; and the understanding of fundamental questions of reaction mechanisms.",
                    "score": 0.9004493355751038
                },
                {
                    "id": 18346983,
                    "contents": "'Seeing' Atoms: The Crystallographic Revolution.\nLaue's experiment in 1912 of the diffraction of X-rays by crystals led to one of the most influential discoveries in the history of science: the first determinations of crystal structures, NaCl and diamond in particular, by W. L. Bragg in 1913. For the first time, the visualisation of the structure of matter at the atomic level became possible. X-ray diffraction provided a sort of microscope with atomic resolution, atoms became observable physical objects and their relative positions in space could be seen. All branches of science concerned with matter, solid-state physics, chemistry, materials science, mineralogy and biology, could now be firmly anchored on the spatial arrangement of atoms. During the ensuing 100 years, structure determination by diffraction methods has matured into an indispensable method of chemical analysis. We trace the history of the development of 'small-structure' crystallography (excepting macromolecular structures) in Switzerland. Among the pioneers figure Peter Debye and Paul Scherrer with powder diffraction, and Paul Niggli and his Zurich School with space group symmetry and geometrical crystallography. Diffraction methods were applied early on by chemists at the Universities of Bern and Geneva. By the 1970s, X-ray crystallography was firmly established at most Swiss Universities, directed by full professors. Today, chemical analysis by structure determination is the task of service laboratories. However, the demand of diffraction methods to solve problems in all disciplines of science is still increasing and powerful radiation sources and detectors are being developed in Switzerland and worldwide.",
                    "score": 0.8997741341590881
                },
                {
                    "id": 12530153,
                    "contents": "'Seeing' atoms: the crystallographic revolution.\nLaue's experiment in 1912 of the diffraction of X-rays by crystals led to one of the most influential discoveries in the history of science: the first determinations of crystal structures, NaCl and diamond in particular, by W. L. Bragg in 1913. For the first time, the visualisation of the structure of matter at the atomic level became possible. X-ray diffraction provided a sort of microscope with atomic resolution, atoms became observable physical objects and their relative positions in space could be seen. All branches of science concerned with matter, solid-state physics, chemistry, materials science, mineralogy and biology, could now be firmly anchored on the spatial arrangement of atoms. During the ensuing 100 years, structure determination by diffraction methods has matured into an indispensable method of chemical analysis. We trace the history of the development of 'small-structure' crystallography (excepting macromolecular structures) in Switzerland. Among the pioneers figure Peter Debye and Paul Scherrer with powder diffraction, and Paul Niggli and his Zurich School with space group symmetry and geometrical crystallography. Diffraction methods were applied early on by chemists at the Universities of Bern and Geneva. By the 1970s, X-ray crystallography was firmly established at most Swiss Universities, directed by full professors. Today, chemical analysis by structure determination is the task of service laboratories. However, the demand of diffraction methods to solve problems in all disciplines of science is still increasing and powerful radiation sources and detectors are being developed in Switzerland and worldwide. ",
                    "score": 0.8997741341590881
                },
                {
                    "id": 15226650,
                    "contents": "Magnetic Structure Determinations at NBS/NIST.\nMagnetic neutron scattering plays a central role in determining and understanding the microscopic properties of a vast variety of magnetic systems, from the fundamental nature, symmetry, and dynamics of magnetically ordered materials to elucidating the magnetic characteristics essential in technological applications. From the early days of neutron scattering measurements at NBS/NIST, magnetic diffraction studies have been a central theme involving many universities, industrial and government labs from around the United States and worldwide. Such measurements have been used to determine the spatial arrangement and directions of the atomic magnetic moments, the atomic magnetization density of the individual atoms in the material, and the value of the ordered moments as a function of thermodynamic parameters such as temperature, pressure, and applied magnetic field. These types of measurements have been carried out on single crystals, powders, thin films, and artificially grown multilayers, and often the information collected can be obtained by no other experimental technique. This article presents, in an historical perspective, a few examples of work carried out at the NIST Center for Neutron Research (NCNR), and discusses the key role that the Center can expect to play in future magnetism research.",
                    "score": 0.8984241485595703
                },
                {
                    "id": 16940237,
                    "contents": "The Fundamental Neutron Physics Facilities at NIST.\nThe program in fundamental neutron physics at the National Institute of Standards and Technology (NIST) began nearly two decades ago. The Neutron Interactions and Dosimetry Group currently maintains four neutron beam lines dedicated to studies of fundamental neutron interactions. The neutrons are provided by the NIST Center for Neutron Research, a national user facility for studies that include condensed matter physics, materials science, nuclear chemistry, and biological science. The beam lines for fundamental physics experiments include a high-intensity polychromatic beam, a 0.496 nm monochromatic beam, a 0.89 nm monochromatic beam, and a neutron interferometer and optics facility. This paper discusses some of the parameters of the beam lines along with brief presentations of some of the experiments performed at the facilities.",
                    "score": 0.8983199000358582
                },
                {
                    "id": 1517538,
                    "contents": "Inelastic scattering of neutrons and possible biological applications.\nThe field of neutron inelastic scattering has probably been developed to the stage where it can begin to help the biologist. Because essentially no experimental data have been obtained, it is difficult either to draw conclusions or to make forecasts except on the basis of general hypotheses. It seems likely, however, that the next stage is up to biologists. After reviewing those biological problems in which molecular dynamics might play an important role, they should suggest specimens of interest which can give inelastic peaks with existing spectrometers operating with 5 to 10-A neutrons at angles greater than 5degrees and with resolutions of approximately 50 mueV. These specimens may involve molecules slightly smaller and more mobile than some biologists would like, but a successful outcome might lead to the development of spectrometers capable of working in a more satisfactory range. In this event the return may well prove rewarding to the biologists.",
                    "score": 0.898267388343811
                },
                {
                    "id": 23408930,
                    "contents": "CENTAUR-The small- and wide-angle neutron scattering diffractometer/spectrometer for the Second Target Station of the Spallation Neutron Source.\nCENTAUR has been selected as one of the eight initial instruments to be built at the Second Target Station (STS) of the Spallation Neutron Source at Oak Ridge National Laboratory. It is a small-angle neutron scattering (SANS) and wide-angle neutron scattering (WANS) instrument with diffraction and spectroscopic capabilities. This instrument will maximally leverage the high brightness of the STS source, the state-of-the-art neutron optics, and a suite of detectors to deliver unprecedented capabilities that enable measurements over a wide range of length scales with excellent resolution, measurements on smaller samples, and time-resolved investigations of evolving structures. Notably, the simultaneous WANS and diffraction capability will be unique among neutron scattering instruments in the United States. This instrument will provide much needed capabilities for soft matter and polymer sciences, geology, biology, quantum condensed matter, and other materials sciences that need in situ and operando experiments for kinetic and/or out-of-equilibrium studies. Beam polarization and a high-resolution chopper will enable detailed structural and dynamical investigations of magnetic and quantum materials. CENTAUR's excellent resolution makes it ideal for low-angle diffraction studies of highly ordered large-scale structures, such as skyrmions, shear-induced ordering in colloids, and biomembranes. Additionally, the spectroscopic mode of this instrument extends to lower momentum transfers than are currently possible with existing spectrometers, thereby providing a unique capability for inelastic SANS studies.",
                    "score": 0.898134708404541
                },
                {
                    "id": 20070480,
                    "contents": "Probing extreme states of matter using ultra-intense x-ray radiation.\nExtreme states of matter, that is, matter at extremes of density (pressure) and temperature, can be created in the laboratory either statically or dynamically. In the former, the pressure-temperature state can be maintained for relatively long periods of time, but the sample volume is necessarily extremely small. When the extreme states are generated dynamically, the sample volumes can be larger, but the pressure-temperature conditions are maintained for only short periods of time (ps to<iμ</is). In either case, structural information can be obtained from the extreme states by the use of x-ray scattering techniques, but the x-ray beam must be extremely intense in order to obtain sufficient signal from the extremely-small or short-lived sample. In this article I describe the use of x-ray diffraction at synchrotrons and XFELs to investigate how crystal structures evolve as a function of density and temperature. After a brief historical introduction, I describe the developments made at the Synchrotron Radiation Source in the 1990s which enabled the almost routine determination of crystal structure at high pressures, while also revealing that the structural behaviour of materials was much more complex than previously believed. I will then describe how these techniques are used at the current generation of synchrotron and XFEL sources, and then discuss how they might develop further in the future at the next generation of x-ray lightsources.",
                    "score": 0.8959673643112183
                },
                {
                    "id": 18063079,
                    "contents": "A suite-level review of the neutron single-crystal diffraction instruments at Oak Ridge National Laboratory.\nThe nascent suite of single-crystal neutron diffractometers at the Oak Ridge National Laboratory has no equal at any other neutron scattering facility worldwide and offers the potential to re-assert single-crystal diffraction using neutrons as a significant tool to study nuclear and magnetic structures of small unit cell crystals, nuclear structures of macromolecules, and diffuse scattering. Signature applications and features of single-crystal neutron diffraction are high resolution nuclear structure analysis, magnetic structure and spin density determinations, contrast variation (particularly D<sub2</subO/H<sub2</subO) for nuclear structural studies, lack of radiation damage when using crystals of biological molecules such as proteins, and the fidelity to measure nuclear and magnetic diffuse scattering with elastic discrimination.",
                    "score": 0.8955085277557373
                },
                {
                    "id": 15409926,
                    "contents": "Crystallography is more than crystal structures.\nNew developments in neutron and synchrotron science and technology are discussed. ",
                    "score": 0.8953379988670349
                },
                {
                    "id": 1494721,
                    "contents": "Neutron scattering on nuclei.\nVery small angle neutron scattering studies have been made on intact nuclei under a variety of solution conditions. Scattering maxima are observed at 30 to 40 nm and at 18 nm in most environments. Although the spacing, intensity and presence of the maximum near 40 nm varies considerably with environment the 18 nm is rather constant. The 30 to 40 nm maximum appears to be best interpreted by the presence of 35 to 50 nm diameter fibers in nuclei. An important result is that no scattering maximum was observed near 11 nm, suggesting that a tightly super coiled nucleofilament with such a pitch is not present.",
                    "score": 0.8944154977798462
                },
                {
                    "id": 9979,
                    "contents": "Neutron scatter and diffraction techniques applied to nucleosome and chromatin structure.\nNeutron scatter and diffraction techniques have made substantial contributions to our understanding of the structure of the nucleosome, the structure of the 10-nm filament, the \"10-nm----30-nm\" filament transition, and the structure of the \"34-nm\" supercoil or solenoid of nucleosomes. Neutron techniques are unique in their properties, which allows for the separation of the spatial arrangements of histones and DNA in nucleosomes and chromatin. They have equally powerful applications in structural studies of any complex two-component biological system. A major success for the application of neutron techniques was the first clear proof that DNA was located on the outside of the histone octamer in the core particle. A full analysis of the neutron-scatter data gave the parameters of Table 3 and the low-resolution structure of the core particle in solution shown in Fig. 6. Initial low-resolution X-ray diffraction studies of core particle crystals gave a model with a lower DNA pitch of 2.7 nm. Higher-resolution X-ray diffraction studies now give a structure with a DNA pitch of 3.0 nm and a hole of 0.8 nm along the axis of the DNA supercoil. The neutron-scatter solution structure and the X-ray crystal structure of the core particle are thus in full agreement within the resolution of the neutron-scatter techniques. The model for the chromatosome is largely based on the structural parameters of the DNA supercoil in the core particle, nuclease digestion results showing protection of a 168-bp DNA length by histone H1 and H1 peptide, and the conformational properties of H1. The path of the DNA outside the chromatosome is not known, and this information is crucial for our understanding of higher chromatin structure. The interactions of the flexible basic and N- and C-terminal regions of H1 within chromatin and how these interactions are modulated by H1 phosphorylation are not known. The N- and C-terminal regions of H1 represent a new type of protein behavior, i.e., extensive protein domains that are designed not to fold up into secondary and tertiary protein structures. This behavior is increasingly observed in DNA and chromatin binding proteins, and in the case of the high-mobility group proteins HMG 14 and 17, the entire polypeptide chain is a flexible random coil over a wide range of solution, ionic, and pH conditions. It follows that the native conformations are probably imposed on these flexible domains and molecules by their binding sites in chromatin.(ABSTRACT TRUNCATED AT 400 WORDS)",
                    "score": 0.8936834335327148
                },
                {
                    "id": 7540914,
                    "contents": "Neutron protein crystallography: current status and a brighter future.\nHydrogen atoms are rarely seen in X-ray protein crystal structures, but are readily visualized by neutron crystallography, even at typical (1.5-2.5A) resolutions. Recent advances in neutron beamlines and deuterium labeling technologies have dramatically extended the scale and range of structures studied. High-quality neutron data can be collected to near atomic resolution ( approximately 1.5-2.5A) for proteins of 50-175kDa molecular weight, from perdeuterated samples, from crystals with volumes of 0.1mm(3) and at cryogenic temperatures (15K). These structures are providing unique and complementary insights into hydrogen-bonding interactions, protonation states, catalytic mechanisms and hydration states of biological structures that are not available from X-ray analysis alone. The new generation of spallation neutron sources promises further 10-50-fold gains in performance.",
                    "score": 0.8930507898330688
                },
                {
                    "id": 9699019,
                    "contents": "Structure of Nuclei and Nucleons: Extension of electron-scattering studies to higher energies gives a new model of the neutron and proton.\nIn concluding this discussion it may be appropriate to return to the theme introduced earlier and raise the question once again of the deeper, and possibly philosophical, meaning of the term \"elementary\" particle. As we have seen, the proton and neutron, which were once thought to be elementary particles, are now seen to be highly complex bodies. It is almost certain that physicists will subsequently investigate the constituent parts of the proton and neutron-the mesons of one sort or another. What will happen from that point on? One can only guess at future problems and future progress, but my personal conviction is that the search for ever-smaller and ever-more-fundamental particles will go on as long as man retains the curiosity he has always demonstrated (29).",
                    "score": 0.892855167388916
                },
                {
                    "id": 23812650,
                    "contents": "Exploring the Limits of Biological Complexity Amenable to Studies by Incoherent Neutron Spectroscopy.\nThe wavelengths of neutrons available at neutron scattering facilities are comparable with intra- and inter-molecular distances, while their energies are comparable with molecular vibrational energies, making such neutrons highly suitable for studies of molecular-level dynamics. The unmistakable trend in neutron spectroscopy has been towards measurements of systems of greater complexity. Several decades of studies of dynamics using neutron scattering have witnessed a progression from measurements of solids to liquids to protein complexes and biomembranes, which may exhibit properties characteristic of both solids and liquids. Over the last two decades, the frontier of complexity amenable to neutron spectroscopy studies has reached the level of cells. Considering this a baseline for neutron spectroscopy of systems of the utmost biological complexity, we briefly review what has been learned to date from neutron scattering studies at the cellular level and then discuss in more detail the recent strides into neutron spectroscopy of tissues and whole multicellular organisms.",
                    "score": 0.8927590847015381
                },
                {
                    "id": 14446424,
                    "contents": "The success story of crystallography.\nDiffractionists usually place the birth of crystallography in 1912 with the first X-ray diffraction experiment of Friedrich, Knipping and Laue. This discovery propelled the mathematical branch of mineralogy to global importance and enabled crystal structure determination. Knowledge of the geometrical structure of matter at atomic resolution had revolutionary consequences for all branches of the natural sciences: physics, chemistry, biology, earth sciences and material science. It is scarcely possible for a single person in a single article to trace and appropriately value all of these developments. This article presents the limited, subjective view of its author and a limited selection of references. The bulk of the article covers the history of X-ray structure determination from the NaCl structure to aperiodic structures and macromolecular structures. The theoretical foundations were available by 1920. The subsequent success of crystallography was then due to the development of diffraction equipment, the theory of the solution of the phase problem, symmetry theory and computers. The many structures becoming known called for the development of crystal chemistry and of data banks. Diffuse scattering from disordered structures without and with partial long-range order allows determination of short-range order. Neutron and electron scattering and diffraction are also mentioned.",
                    "score": 0.8927369713783264
                },
                {
                    "id": 20971481,
                    "contents": "Neutron sub-micrometre tomography from scattering data.\nNeutrons are valuable probes for various material samples across many areas of research. Neutron imaging typically has a spatial resolution of larger than 20 µm, whereas neutron scattering is sensitive to smaller features but does not provide a real-space image of the sample. A computed-tomography technique is demonstrated that uses neutron-scattering data to generate an image of a periodic sample with a spatial resolution of ∼300 nm. The achieved resolution is over an order of magnitude smaller than the resolution of other forms of neutron tomography. This method consists of measuring neutron diffraction using a double-crystal diffractometer as a function of sample rotation and then using a phase-retrieval algorithm followed by tomographic reconstruction to generate a map of the sample's scattering-length density. Topological features found in the reconstructions are confirmed with scanning electron micrographs. This technique should be applicable to any sample that generates clear neutron-diffraction patterns, including nanofabricated samples, biological membranes and magnetic materials, such as skyrmion lattices.",
                    "score": 0.8925308585166931
                },
                {
                    "id": 16008484,
                    "contents": "Nuclear Structure Studies With the Inelastic Neutron Scattering Reaction and Gamma-Ray Detection.\nThe (n,n'γ) reaction has been used at the University of Kentucky accelerator facility to examine the detailed structure of a number of nuclei. The advantages of this method are reviewed, and recent developments are described. Examples of unique nuclear structure studies that have been carried out with this method are presented.",
                    "score": 0.8922832012176514
                },
                {
                    "id": 17660744,
                    "contents": "IMAGINE: neutrons reveal enzyme chemistry.\nNeutron diffraction is exquisitely sensitive to the positions of H atoms in protein crystal structures. IMAGINE is a high-intensity, quasi-Laue neutron crystallography beamline developed at the High Flux Isotope Reactor (HFIR) at Oak Ridge National Laboratory. This state-of-the-art facility for neutron diffraction has enabled detailed structural analysis of macromolecules. IMAGINE is especially suited to resolve individual H atoms in protein structures, enabling neutron protein structures to be determined at or near atomic resolutions from crystals with volumes of less than 1 mm<sup3</sup and unit-cell edges of less than 150 Å. Beamline features include elliptical focusing mirrors that deliver neutrons into a 2.0 × 3.2 mm focal spot at the sample position, and variable short- and long-wavelength cutoff optics that provide automated exchange between multiple wavelength configurations. This review gives an overview of the IMAGINE beamline at the HFIR, presents examples of the scientific questions being addressed at this beamline, and highlights important findings in enzyme chemistry that have been made using the neutron diffraction capabilities offered by IMAGINE.",
                    "score": 0.8912209272384644
                },
                {
                    "id": 16593572,
                    "contents": "A novel approach to neutron scattering instrumentation for probing multiscale dynamics in soft and biological matter.\nWe present a concept and ray-tracing simulation of a mechanical device that will enable inelastic neutron scattering measurements where the data at energy transfers from a few μeV to several hundred meV can be collected in a single, gapless spectrum. Besides covering 5 orders of magnitude on the energy (time) scale, the device provides data over 2 orders of magnitude on the scattering momentum (length) scale in a single measurement. Such capabilities are geared primarily toward soft and biological matter, where the broad dynamical features of relaxation origin largely overlap with vibration features, thus necessitating gapless spectral coverage over several orders of magnitude in time and space. Furthermore, neutron scattering experiments with such a device are performed with a fixed neutron final energy, which enables measurements, with neutron energy loss in the sample, at arbitrarily low temperatures over the same broad spectral range. This capability is also invaluable in biological and soft matter research, as the variable temperature dependence of different relaxation components allows their separation in the scattering spectra as a function of temperature.",
                    "score": 0.891208827495575
                },
                {
                    "id": 14736580,
                    "contents": "Small Angle Neutron Scattering at the National Institute of Standards and Technology.\nThe small angle neutron scattering technique is a valuable method for the characterization of morphology of various materials. It can probe inhomogeneities in the sample (whether occurring naturally or introduced through isotopic substitution) at a length scale from the atomic size (nanometers) to the macroscopic (micrometers) size. This work provides an overview of the small angle neutron scattering facilities at the National Institute of Standards and Technology and a review of the technique as it has been applied to polymer systems, biological macromolecules, ceramic, and metallic materials. Specific examples have been included.",
                    "score": 0.8908789157867432
                },
                {
                    "id": 11405221,
                    "contents": "Small-angle scattering and neutron contrast variation for studying bio-molecular complexes.\nStructural molecular biology over the past several decades has progressed from studies of the individual proteins, subunits, and domains that accomplish specific biochemistry to seeking to understand the dynamic bio-molecular complexes and assemblies that are responsible for biological function. This progress has led to an expansion of the structural analysis \"tool box\" to include methods that complement the mainstay techniques of the field: X-ray crystallography, nuclear magnetic resonance (NMR), and cryo-electron microscopy. Small-angle scattering of X-rays or neutrons is one such complementary technique that provides information on the size and shape of scattering particles in solution. This low-resolution structural information can be a powerful complement to high-resolution structural data, especially for the study of bio-molecular interactions with ligands or each other. Further, exploitation of the different neutron-scattering properties of the stable isotopes of hydrogen ((1)H and (2)H) can be used to enrich the information available from the small-angle scattering data, especially for bio-molecular complexes.",
                    "score": 0.8907175660133362
                },
                {
                    "id": 1517535,
                    "contents": "Investigation of biological macromolecular systems with a pulsed neutron source--a review.\nThe conclusion that can be drawn on the basis of the above considerations is that investigation of biological macromolecules and crystalline structures by SAS and diffraction of neutrons with the TOF method is feasible. The main difficulties of the TOF method (the wavelength dependence of the incident beam, resolution power, and detector efficiency; the need for their determination and up-to-date values) are compensated for by its advantages. Both methods allow a high data accumulation rate and optimal employment of the incident neutron spectrum. The latter has been achieved by utilizing a dominant part of the Maxwellian spectrum and by a more uniform distribution of statistical accuracy over the most informative measuring range. Another advantage is the high degree of monochronatization of the incident neutron beam by the TOF method. The rigid requirements concerning the data accumulation rate and the capacity of the on-line system computer memory are technical problems but not basic ones.",
                    "score": 0.8905172944068909
                },
                {
                    "id": 23149145,
                    "contents": "EWALD: A macromolecular diffractometer for the second target station.\nRevealing the positions of all the atoms in large macromolecules is powerful but only possible with neutron macromolecular crystallography (NMC). Neutrons provide a sensitive and gentle probe for the direct detection of protonation states at near-physiological temperatures and clean of artifacts caused by x rays or electrons. Currently, NMC use is restricted by the requirement for large crystal volumes even at state-of-the-art instruments such as the macromolecular neutron diffractometer at the Spallation Neutron Source. EWALD's design will break the crystal volume barrier and, thus, open the door for new types of experiments, the study of grand challenge systems, and the more routine use of NMC in biology. EWALD is a single crystal diffractometer capable of collecting data from macromolecular crystals on orders of magnitude smaller than what is currently feasible. The construction of EWALD at the Second Target Station will cause a revolution in NMC by enabling key discoveries in the biological, biomedical, and bioenergy sciences.",
                    "score": 0.8901636600494385
                },
                {
                    "id": 14736584,
                    "contents": "Ultra-High Resolution Inelastic Neutron Scattering.\nTwo types of ultra high energy resolution neutron scattering instruments, the backscattering spectrometer and the spin echo spectrometer, are described. Examples of the types of research which can be done with these instruments are given and plans for a cold neutron backscattering spectrometer which will be built in the NIST Cold Neutron Research Facility (CNRF) are discussed. It is hoped that this information will be of use to researchers considering neutron scattering experiments at NIST.",
                    "score": 0.8898006677627563
                },
                {
                    "id": 16077203,
                    "contents": "Neutron Scattering from Polymers: Five Decades of Developing Possibilities.\nThe first three decades of my research career closely map the development of neutron scattering techniques for the study of molecular behavior. At the same time, the theoretical understanding of organization and motion of polymer molecules, especially in the bulk state, was developing rapidly and providing many predictions crying out for experimental verification. Neutron scattering is an ideal technique for providing the necessary evidence. This autobiographical essay describes the applications by my research group and other collaborators of increasingly sophisticated neutron scattering techniques to observe and understand molecular behavior in polymeric materials. It has been a stimulating and rewarding journey. ",
                    "score": 0.889467716217041
                },
                {
                    "id": 4702564,
                    "contents": "Musings about the development of XAFS.\nA personal recollection of the development of X-ray absorption fine structure (XAFS) into a structure-determination technique is presented. Because of confusion in the theoretical explanation of the 'Kronig structure', now called EXAFS, the extended XAFS, its explanation remained unresolved for about 40 years. As I was introduced to the EXAFS phenomenon by Farrel Lytle and saw his impressive data, the thought came to me that scattering of the photoelectron from surrounding atoms could be the mechanism of the effect. My graduate student, Dale Sayers, agreed to work on developing the theory under my supervision and to make EXAFS measurements under Lytle's supervision as his PhD thesis. The theory led to the idea of a Fourier transform of the EXAFS, which showed peaks from surrounding atoms, proving the validity of the theory and suggesting the method of structure determination by using standards from known structures. Within a few years, facilities at synchrotron sources were developed to measure XAFS, opening up the technique to the general scientific community. In spite of some initial growing pains, XAFS has matured into a powerful technique for local structure and has been applied to obtain magnetic structure, in addition to distribution of atoms. Other related techniques have been spawned from XAFS, expanding the impact of the original phenomenon.",
                    "score": 0.8884630799293518
                },
                {
                    "id": 10785637,
                    "contents": "X-ray diffraction as a local probe tool.\nFor the structural characterization of nanoscale objects, X-ray diffraction is widely used as a technique complementing local probe analysis methods such as scanning electron microscopy and transmission electron microscopy. Details on strain distributions, chemical composition, or size and shape of nanostructures are addressed. X-ray diffraction traditionally obtains very good statistically averaged properties over large ensembles-provided this averaging is meaningful for ensembles with sufficiently small dispersion of properties. In many cases, however, it is desirable to combine different analysis techniques on exactly the same nano-object, for example, to gain a more detailed insight into the interdependence of properties. X-ray beams focused to diameters in the sub-micron range, which are available at third-generation synchrotron sources, allow for such X-ray diffraction studies of individual nano-objects.",
                    "score": 0.8880302906036377
                },
                {
                    "id": 12316181,
                    "contents": "Powder diffraction: what's in a name?\nThe development of powder diffraction is briefly described; the extent of this development from studies of metals to protein crystal structures shows that powder diffraction is at the cutting edge of crystallography. A new name `polycrystallography' is proposed for these endeavours. ",
                    "score": 0.8877379894256592
                },
                {
                    "id": 13774401,
                    "contents": "Synchrotron radiation in life sciences.\nSynchrotron Radiation (SR) presents itself as a \"play-ground\" with a large range of methods and techniques suitable to unveil the mysteries of life. Here we attempt to present a few of these methods that complement those employed in the home laboratory. SR diffraction, spectroscopy and imaging methods relevant to the atomic structure determination and characterization of the properties and function of chemical compounds and macromolecules of biological relevance, are introduced.",
                    "score": 0.8875718712806702
                },
                {
                    "id": 21949179,
                    "contents": "Fundamentals of neutron crystallography in structural biology.\nThis chapter introduces this topic for the whole volume. It is not a review, rather it presents the basics, the key considerations and forward references to the other chapters. This starts by setting the scene of principles and overall strategy, moves onto planning an experiment including its feasibility and then outlines practicalities with options for the experiment. The crystal structure that results will lead to publication and associated with it, Protein Data Bank deposition.",
                    "score": 0.8866997957229614
                },
                {
                    "id": 11719073,
                    "contents": "Neutron scattering and protein dynamics.\nNeutrons play an important role in the study of proteins. The best known example is the determination of protein structures using neutron diffraction. Less well known, but possibly even more important in the future, is the determination of protein fluctuations using neutron scattering. Here, the background is sketched and some recent measurements are described that show how a relevant and revealing range of relaxation rates can be explored.",
                    "score": 0.8856608867645264
                },
                {
                    "id": 19559300,
                    "contents": "Direct Observation of Anapoles by Neutron Diffraction.\nThe scope of magnetic neutron scattering has been expanded by the observation of electronic Dirac dipoles (anapoles) that are polar (parity odd) and magnetic (time odd). A zero-magnetization ferromagnet Sm_{0.976}Gd_{0.024}Al_{2} with a diamond-type structure presents Dirac multipoles at basis-forbidden reflections that include the standard (2, 2, 2) reflection. Magnetic amplitudes measured at four such reflections are in full accord with a structure factor calculated from the appropriate magnetic space group.",
                    "score": 0.8851503133773804
                },
                {
                    "id": 15226648,
                    "contents": "Past and Present Crystallographic Work at the NBS/NIST Reactor.\nNeutron diffraction at NBS/NIST started soon after the NBS reactor became operational in the summer of 1969. Since that time, literally hundreds of crystal structures have been determined and refined using single crystal and powder neutron diffraction data, collected with a variety of instruments. This work has been usually done in collaboration with other NBS/NIST divisions and/or universities and industrial laboratories. In parallel with the technical developments and the experimental work, also theoretical aspects of crystal geometry have been clarified, and significant improvements in the techniques of profile refinements have been made. It is therefore understandable that a comprehensive description of all the crystallographic studies carried out up to the present is impossible under the constraints of space and time imposed by a review of this type, and, in the following sections, we will limit ourselves to give, only a brief account of the topics which, in our opinion, represent the highlights of the work carried out at the reactor.",
                    "score": 0.8848493695259094
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_17",
        "question": "The temperature of the fireball in a thermonuclear explosion can reach temperatures of approximately $10^7 \\mathrm{~K}$. What value of $\\lambda_{\\max }$ does this correspond to? ",
        "golden_answers": [
            " 3"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 9667103,
                    "contents": "PHYSICS: Will NIF Live Up to Its Name?\nThe National Ignition Facility (NIF)--if it works as advertised, which is by no means certain given all of NIF's problems (see main text)--will pump almost 2 million joules of laser energy into a BB-sized pellet of hydrogen. But the bigger question is whether the pellet will actually achieve ignition--that is, undergo a sustained nuclear reaction that gives off as much energy as was put in? Most scientists on the project are cautiously optimistic, but others have grave doubts.",
                    "score": 0.8719278573989868
                },
                {
                    "id": 13961044,
                    "contents": "Astrophysical explosions: from solar flares to cosmic gamma-ray bursts.\nAstrophysical explosions result from the release of magnetic, gravitational or thermonuclear energy on dynamical time scales, typically the sound-crossing time for the system. These explosions include solar and stellar flares, eruptive phenomena in accretion discs, thermonuclear combustion on the surfaces of white dwarfs and neutron stars, violent magnetic reconnection in neutron stars, thermonuclear and gravitational collapse supernovae and cosmic gamma-ray bursts, each representing a different type and amount of energy release. This paper summarizes the properties of these explosions and describes new research on thermonuclear explosions and explosions in extended circumstellar media. Parallels are drawn between studies of terrestrial and astrophysical explosions, especially the physics of the transition from deflagration-to-detonation.",
                    "score": 0.8710789084434509
                },
                {
                    "id": 9411098,
                    "contents": "Explosive nucleosynthesis in stars.\nRecent calculations provide convincing evidence that the naturally occurring nuclei were produced in explosions. The required temperature, density and expansion rate strongly suggest that before the explosion the objects were ordinary evolved massive stars. We review these new developments and present a new table indicating our hypothesis concerning the origin of the nuclei in the mass range 20 &lt; or = A &lt; or = 62.",
                    "score": 0.8690073490142822
                },
                {
                    "id": 16008477,
                    "contents": "Current Topics in Gamma-Ray Astrophysics.\nThis paper reports on recent progress toward unraveling the origin of gamma-ray bursts. It is concluded that neutron-star binaries are one of the few remaining candidates. A model is proposed based upon general relativistic hydrodynamic studies which indicate a new physical process by which to power a gamma-ray burst. Relativistically driven compression, heating, and collapse of the individual neutron stars can occur many seconds before inspiral and merger. This compression may produce a neutrino burst of ∼10(53) ergs lasting several seconds. The associated thermal neutrino emission produces an e (+)-e (-) pair plasma by [Formula: see text] annihilation. We show first results of a simulated burst which produces ∼10(51) erg in γ rays of the correct spectral and temporal properties.",
                    "score": 0.8571040630340576
                },
                {
                    "id": 5842435,
                    "contents": "Nonthermal optical transients from relativistic fireballs\nA general upper bound is derived on the total energy in incoherent nonthermal transients at frequency nu from relativistic fireballs with bulk Lorentz factors gamma and observed duration Deltat, and shown to be about 10(-2)[gammanuDeltat](3) ergs. It is suggested that detection in the optical can be achieved with the next generation of ground based gamma ray telescopes and/or small optical telescopes. Phenomena within the Galaxy such as accretion disk flares and neutron star magnetospheric discharges might be discovered in this way.",
                    "score": 0.8570387363433838
                },
                {
                    "id": 12029631,
                    "contents": "The observable signature of late heating of the Universe during cosmic reionization.\nModels and simulations of the epoch of reionization predict that spectra of the 21-centimetre transition of atomic hydrogen will show a clear fluctuation peak, at a redshift and scale, respectively, that mark the central stage of reionization and the characteristic size of ionized bubbles. This is based on the assumption that the cosmic gas was heated by stellar remnants-particularly X-ray binaries-to temperatures well above the cosmic microwave background at that time (about 30 kelvin). Here we show instead that the hard spectra (that is, spectra with more high-energy photons than low-energy photons) of X-ray binaries make such heating ineffective, resulting in a delayed and spatially uniform heating that modifies the 21-centimetre signature of reionization. Rather than looking for a simple rise and fall of the large-scale fluctuations (peaking at several millikelvin), we must expect a more complex signal also featuring a distinct minimum (at less than a millikelvin) that marks the rise of the cosmic mean gas temperature above the microwave background. Observing this signal, possibly with radio telescopes in operation today, will demonstrate the presence of a cosmic background of hard X-rays at that early time. ",
                    "score": 0.8566227555274963
                },
                {
                    "id": 18887466,
                    "contents": "Enhancement of the Triple Alpha Rate in a Hot Dense Medium.\nIn a sufficiently hot and dense astrophysical environment the rate of the triple-alpha (3α) reaction can increase greatly over the value appropriate for helium burning stars owing to hadronically induced deexcitation of the Hoyle state. In this Letter we use a statistical model to evaluate the enhancement as a function of temperature and density. For a density of 10^{6}  g cm^{-3} enhancements can exceed a factor of 100. In high temperature or density situations, the enhanced 3α rate is a better estimate of this rate and should be used in these circumstances. We then examine the effect of these enhancements on production of ^{12}C in the neutrino wind following a supernova explosion and in an x-ray burster.",
                    "score": 0.856394350528717
                },
                {
                    "id": 4930280,
                    "contents": "Supernova explosions in the Universe.\nDuring the lifetime of our Milky Way galaxy, there have been something like 100 million supernova explosions, which have enriched the Galaxy with the oxygen we breathe, the iron in our cars, the calcium in our bones and the silicon in the rocks beneath our feet. These exploding stars also influence the birth of new stars and are the source of the energetic cosmic rays that irradiate us on the Earth. The prodigious amount of energy (approximately 10(51), or approximately 2.5 x 10(28) megatonnes of TNT equivalent) and momentum associated with each supernova may even have helped to shape galaxies as they formed in the early Universe. Supernovae are now being used to measure the geometry of the Universe, and have recently been implicated in the decades-old mystery of the origin of the gamma-ray bursts. Together with major conceptual advances in our theoretical understanding of supernovae, these developments have made supernovae the centre of attention in astrophysics.",
                    "score": 0.8553211092948914
                },
                {
                    "id": 14094717,
                    "contents": "Measurement of the 18Ne(α,p0) 21Na reaction cross section in the burning energy region for x-ray bursts.\nThe 18Ne(α,p) 21Na reaction provides one of the main HCNO-breakout routes into the rp process in x-ray bursts. The 18Ne(α,p0) 21Na reaction cross section has been determined for the first time in the Gamow energy region for peak temperatures T∼2  GK by measuring its time-reversal reaction 21Na(p,α) 18Ne in inverse kinematics. The astrophysical rate for ground-state to ground-state transitions was found to be a factor of 2 lower than Hauser-Feshbach theoretical predictions. Our reduced rate will affect the physical conditions under which breakout from the HCNO cycles occurs via the 18Ne(α,p) 21Na reaction.",
                    "score": 0.8539602756500244
                },
                {
                    "id": 20657143,
                    "contents": "Energy Flow in Thin Shell Implosions and Explosions.\nEnergy flow and balance in convergent systems beyond petapascal energy densities controls the fate of late-stage stars and the potential for controlling thermonuclear inertial fusion ignition. Time-resolved x-ray self-emission imaging combined with a Bayesian inference analysis is used to describe the energy flow and the potential information stored in the rebounding spherical shock at 0.22 PPa (2.2 Gbar or billions of atmospheres pressure). This analysis, together with a simple mechanical model, describes the trajectory of the shell and the time history of the pressure at the fuel-shell interface, ablation pressure, and energy partitioning including kinetic energy of the shell and internal energy of the fuel. The techniques used here provide a fully self-consistent uncertainty analysis of integrated implosion data, a thermodynamic-path independent measurement of pressure in the petapascal range, and can be used to deduce the energy flow in a wide variety of implosion systems to petapascal energy densities.",
                    "score": 0.8537575602531433
                },
                {
                    "id": 10506780,
                    "contents": "Constraints on energetic particles in the Fleischmann-Pons experiment.\nIn recent Fleischmann-Pons experiments carried out by different groups, a thermal signal is seen indicative of excess energy production of a magnitude much greater than can be accounted for by chemistry. Correlated with the excess heat appears to be (4)He, with the associated energy near 24 MeV per helium atom. In nuclear reactions, the energy produced is expressed through the kinetic energy of the products; hence, it would be natural to assume that some of the reaction energy ends up as kinetic energy of the (4)He nucleus. Depending on the energy that the helium nucleus is born with, it will result in radiation (such as neutrons or x-rays) that can be seen outside of the cell. We have computed estimates of the expected neutron and x-ray emission as a function of helium energy and compared the results with upper limits taken from experiments. Experimental results with upper limits of neutron emission between 0.008 and 0.8 n/J are found to correspond to upper limits in alpha energy between 6.2 and 20.2 keV.",
                    "score": 0.8535796403884888
                },
                {
                    "id": 6285087,
                    "contents": "Superradiance in a torus magnetosphere around a black hole \nThe coalescence of a neutron star and a black hole in a binary system is believed to form a torus around a Kerr black hole. A similarly shaped magnetosphere then results from the remnant magnetic field of the neutron star. In the strong-field case, it contains a cavity for plasma waves located between the barrier of the gravitational potential and the surrounding torus. This cavity may be unstable to superradiance of electromagnetic waves. Superradiant amplification of such waves, initially excited by turbulence in the torus, should inflate into a bubble in a time as short as approximately 0.75 (1 percent/&amp;cjs3539;epsilon&amp;cjs3539;2)(M/7M middle dot in circle) seconds approximately 0.15 to 1.5 seconds, assuming an efficiency &amp;cjs3539;epsilon&amp;cjs3539;2 = 0.5 to 5 percent and a mass M = 7M middle dot in circle. These bubbles may burst and repeat, of possible relevance to intermittency in cosmological gamma-ray bursts. The model predicts gamma-ray bursts to be anticorrelated with their gravitational wave emissions.",
                    "score": 0.8534672260284424
                },
                {
                    "id": 7131120,
                    "contents": "Thermonuclear supernovae: simulations of the deflagration stage and their implications.\nLarge-scale, three-dimensional numerical simulations of the deflagration stage of a thermonuclear supernova explosion show the formation and evolution of a highly convoluted turbulent flame in the gravitational field of an expanding carbon-oxygen white dwarf. The flame dynamics are dominated by the gravity-induced Rayleigh-Taylor instability that controls the burning rate. The thermonuclear deflagration releases enough energy to produce a healthy explosion. The turbulent flame, however, leaves large amounts of unburned and partially burned material near the star center, whereas observations that imply these materials are present only in outer layers. This disagreement could be resolved if the deflagration triggers a detonation.",
                    "score": 0.8533481955528259
                },
                {
                    "id": 12547839,
                    "contents": "High-energy emission from transients.\nCosmic explosions dissipate energy into their surroundings on a very wide range of time scales: producing shock waves and associated particle acceleration. The historical culprits for the acceleration of the bulk of Galactic cosmic rays are supernova remnants: explosions on approximately 10(4) year time scales. Increasingly, however, time-variable emission points to rapid and efficient particle acceleration in a range of different astrophysical systems. Gamma-ray bursts have the shortest time scales, with inferred bulk Lorentz factors of approximately 1000 and photons emitted beyond 100 GeV, but active galaxies, pulsar wind nebulae and colliding stellar winds are all now associated with time-variable emission at approximately teraelectron volt energies. Cosmic photons and neutrinos at these energies offer a powerful probe of the underlying physical mechanisms of cosmic explosions, and a tool for exploring fundamental physics with these systems. Here, we discuss the motivations for high-energy observations of transients, the current experimental situation, and the prospects for the next decade, with particular reference to the major next-generation high-energy observatory, the Cherenkov Telescope Array.",
                    "score": 0.8518972992897034
                },
                {
                    "id": 9573786,
                    "contents": "HIGH-ENERGY ASTROPHYSICS: Gamma Ray Bursts May Pack a One-Two Punch.\nMost astrophysicists puzzling over what causes gamma ray bursts--short, intense explosions of high-energy photons that occur deep in space--now agree that the answer is a hypernova, the blast of energy released when a supermassive star collapses into a black hole. Two papers in this issue of Science (pp. 953 and 955), reporting on new x-ray observations of two gamma ray bursts, argue that the hypernova model tells only half of the story. On its way to becoming a black hole, the authors propose, the supermassive star actually collapses twice.",
                    "score": 0.8517322540283203
                },
                {
                    "id": 16638468,
                    "contents": "Hot explosions in the cool atmosphere of the Sun.\nThe solar atmosphere was traditionally represented with a simple one-dimensional model. Over the past few decades, this paradigm shifted for the chromosphere and corona that constitute the outer atmosphere, which is now considered a dynamic structured envelope. Recent observations by the Interface Region Imaging Spectrograph (IRIS) reveal that it is difficult to determine what is up and down, even in the cool 6000-kelvin photosphere just above the solar surface: This region hosts pockets of hot plasma transiently heated to almost 100,000 kelvin. The energy to heat and accelerate the plasma requires a considerable fraction of the energy from flares, the largest solar disruptions. These IRIS observations not only confirm that the photosphere is more complex than conventionally thought, but also provide insight into the energy conversion in the process of magnetic reconnection. ",
                    "score": 0.8516828417778015
                },
                {
                    "id": 11500930,
                    "contents": "On the origin of gamma-ray bursts.\nGamma-ray bursts are the most energetic explosions in the Universe, occurring at cosmological distances. The initial phase of the emission from these bursts is predominantly of gamma rays and stems from a highly relativistic outflow. The nature of this emission is still under debate. Here, I present the interpretation that the peak in the photon spectrum can be attributed to the black-body emission of the photosphere of the outflow, having a temperature of approximately 109K. An additional non-thermal spectral component can be attributed to additional dissipation of the kinetic energy in the outflow. This two-component model can be well fitted to most instantaneous spectra. Interestingly, the thermal component exhibits a recurring behaviour over emission pulse structures. Both the temperature and the energy flux vary as broken power laws. During the pre-break phase, the temperature is approximately constant while the energy flux rises. Furthermore, the ratio of the observed thermal flux to the emergent flux increases as a power law over the whole pulse. It is argued that these observations hold the key to our understanding of the prompt emission and the properties of the site from which it emanates.",
                    "score": 0.8514400720596313
                },
                {
                    "id": 9240530,
                    "contents": "Dynamic acceleration effects in explosions of laser-irradiated heteronuclear clusters.\nIntense, femtosecond irradiation of atomic and molecular clusters can initiate Coulomb explosions, generating particle energies sufficient to drive nuclear fusion. Last and Jortner have proposed, based on particle dynamics simulations, that heteronuclear clusters with a mixture of heavy and light ions will not explode by the simple, equilibrium Coulomb model but that dynamic effects can lead to a boosting of energy of the lighter ejected ions [Phys. Rev. Lett. 87, 033401 (2001)]. We present experimental confirmation of this theoretically predicted ion energy enhancement in methane clusters.",
                    "score": 0.8513628244400024
                },
                {
                    "id": 11566150,
                    "contents": "Terrestrial gamma-ray flashes as powerful particle accelerators.\nStrong electric discharges associated with thunderstorms can produce terrestrial gamma-ray flashes (TGFs), i.e., intense bursts of x rays and γ rays lasting a few milliseconds or less. We present in this Letter new TGF timing and spectral data based on the observations of the Italian Space Agency AGILE satellite. We determine that the TGF emission above 10 MeV has a significant power-law spectral component reaching energies up to 100 MeV. These results challenge TGF theoretical models based on runaway electron acceleration. The TGF discharge electric field accelerates particles over the large distances for which maximal voltages of hundreds of megavolts can be established. The combination of huge potentials and large electric fields in TGFs can efficiently accelerate particles in large numbers, and we reconsider here the photon spectrum and the neutron production by photonuclear reactions in the atmosphere.",
                    "score": 0.8509112596511841
                },
                {
                    "id": 5842480,
                    "contents": "Hydrodynamic collimation of gamma-ray-burst fireballs\nAnalytic solutions are presented for the hydrodynamic collimation of a relativistic fireball by a surrounding baryonic wind emanating from a torus. The opening angle is shown to be the ratio of the power output of the inner fireball to that of the exterior baryonic wind. The gamma ray burst 990123 might thus be interpreted as a baryon-poor jet (BPJ) with an energy output of order 10(50) erg or less, collimated by a baryonic wind from a torus with an energy output of order 10(52.5) erg, roughly the geometric mean of the BPJ and its isotropic equivalent.",
                    "score": 0.8506172895431519
                },
                {
                    "id": 21705041,
                    "contents": "The Great Pretenders Among the ULX Class.\nThe recent discoveries of pulsed X-ray emission from three ultraluminous X-ray (ULX) sources have finally enabled us to recognize a subclass within the ULX class: the great pretenders, neutron stars (NSs) that appear to emit X-ray radiation at isotropic luminosities <iL</i <sub<iX</i</sub = 7 × 10<sup39</sup erg s<sup-1</sup - 1 × 10<sup41</sup erg s<sup-1</sup only because their emissions are strongly beamed toward our direction and our sight lines are offset by only a few degrees from their magnetic-dipole axes. The three known pretenders appear to be stronger emitters than the presumed black holes of the ULX class, such as Holmberg II &amp; IX X-1, IC10 X-1, and NGC300 X-1. For these three NSs, we have adopted a single reasonable assumption, that their brightest observed outbursts unfold at the Eddington rate, and we have calculated both their propeller states and their surface magnetic-field magnitudes. We find that the results are not at all different from those recently obtained for the Magellanic Be/X-ray pulsars: the three NSs reveal modest magnetic fields of about 0.3-0.4 TG and beamed propeller-line X-ray luminosities of ~ 10<sup36-37</sup erg s<sup-1</sup, substantially below the Eddington limit.",
                    "score": 0.850436270236969
                },
                {
                    "id": 7079793,
                    "contents": "Time-resolved explosion of intense-laser-heated clusters.\nWe investigate the femtosecond explosive dynamics of intense laser-heated argon clusters by measuring the cluster complex transient polarizability. The time evolution of the polarizability is characteristic of competition in the optical response between supercritical and subcritical density regions of the expanding cluster. The results are consistent with time-resolved Rayleigh scattering measurements, and bear out the predictions of a recent laser-cluster interaction model [H. M. Milchberg, S. J. McNaught, and E. Parra, Phys. Rev. E 64, 056402 (2001)]].",
                    "score": 0.849990963935852
                },
                {
                    "id": 22479380,
                    "contents": "Experimental achievement and signatures of ignition at the National Ignition Facility.\nAn inertial fusion implosion on the National Ignition Facility, conducted on August 8, 2021 (N210808), recently produced more than a megajoule of fusion yield and passed Lawson's criterion for ignition [Phys. Rev. Lett. 129, 075001 (2022)10.1103/PhysRevLett.129.075001]. We describe the experimental improvements that enabled N210808 and present the first experimental measurements from an igniting plasma in the laboratory. Ignition metrics like the product of hot-spot energy and pressure squared, in the absence of self-heating, increased by ∼35%, leading to record values and an enhancement from previous experiments in the hot-spot energy (∼3×), pressure (∼2×), and mass (∼2×). These results are consistent with self-heating dominating other power balance terms. The burn rate increases by an order of magnitude after peak compression, and the hot-spot conditions show clear evidence for burn propagation into the dense fuel surrounding the hot spot. These novel dynamics and thermodynamic properties have never been observed on prior inertial fusion experiments.",
                    "score": 0.8497933149337769
                },
                {
                    "id": 8494696,
                    "contents": "Above threshold Coulomb explosion of molecules in intense laser pulses.\nWe have measured and explained a new mechanism of molecular ionization near the appearance intensity that produces a sequence of peaks in the nuclear kinetic energy spectrum separated by the photon energy. Our interpretation is based on an internally consistent model for the nuclear motion during an intense laser pulse. Within this model, the same concepts and language can be used for both dissociation and ionization, leading to a more unified understanding of the dynamics.",
                    "score": 0.8496115207672119
                },
                {
                    "id": 18902186,
                    "contents": "Explaining recurring maser flares in the ISM through large-scale entangled quantum mechanical states.\nWe apply Dicke's theory of superradiance (introduced in 1954) to the 6.7-GHz methanol and 22-GHz water spectral lines, often detected in molecular clouds as signposts for the early stages of the star formation process. We suggest that superradiance, characterized by burst-like features taking place over a wide range of time scales, may provide a natural explanation for the recent observations of periodic and seemingly alternating methanol and water maser flares in G107.298+5.639. Although these observations would be very difficult to explain within the context of maser theory, we show that these flares may result from simultaneously initiated 6.7-GHz methanol and 22-GHz water superradiant bursts operating on different time scales, thus providing a natural mechanism for their observed durations and time ordering. The evidence of superradiance in this source further suggests the existence of entangled quantum mechanical states, involving a very large number of molecules, over distances of up to a few kilometers in the interstellar medium.",
                    "score": 0.8492552042007446
                },
                {
                    "id": 18679422,
                    "contents": "Turbulent Kinetic Energy in the Energy Balance of a Solar Flare.\nThe energy released in solar flares derives from a reconfiguration of magnetic fields to a lower energy state, and is manifested in several forms, including bulk kinetic energy of the coronal mass ejection, acceleration of electrons and ions, and enhanced thermal energy that is ultimately radiated away across the electromagnetic spectrum from optical to x rays. Using an unprecedented set of coordinated observations, from a suite of instruments, we here report on a hitherto largely overlooked energy component-the kinetic energy associated with small-scale turbulent mass motions. We show that the spatial location of, and timing of the peak in, turbulent kinetic energy together provide persuasive evidence that turbulent energy may play a key role in the transfer of energy in solar flares. Although the kinetic energy of turbulent motions accounts, at any given time, for only ∼(0.5-1)% of the energy released, its relatively rapid (∼1-10  s) energization and dissipation causes the associated throughput of energy (i.e., power) to rival that of major components of the released energy in solar flares, and thus presumably in other astrophysical acceleration sites.",
                    "score": 0.8477745056152344
                },
                {
                    "id": 8785637,
                    "contents": "Fireball ejection from a molten hot spot to air by localized microwaves.\nA phenomenon of fireball ejection from hot spots in solid materials (silicon, germanium, glass, ceramics, basalt, etc.) to the atmosphere is presented. The hot spot is created in the substrate material by the microwave-drill mechanism [Jerby, Science 298, 587 (2002)10.1126/science.1077062]. The vaporized drop evolved from the hot spot is blown up, and forms a stable fireball buoyant in the air. The experimental observations of fireball ejection from silicate hot spots are referred to the Abrahamson-Dinniss theory [Nature (London) 403, 519 (2000)10.1038/35000525] suggesting a mechanism for ball-lightning initiation in nature. The fireballs observed in our experiments tend to absorb the available microwave power entirely, similarly to the plasmon resonance effect in submicron wavelengths [Nie and Emory, Science 275, 1102 (1997)10.1126/science.275.5303.1102].",
                    "score": 0.8473714590072632
                },
                {
                    "id": 4974365,
                    "contents": "The Synchrotron Spectrum of Fast Cooling Electrons Revisited.\nWe discuss the spectrum arising from synchrotron emission by fast cooling (FC) electrons, when fresh electrons are continually accelerated by a strong blast wave, into a power-law distribution of energies. The FC spectrum has so far been described by four power-law segments divided by three break frequencies nusa&lt;nuc&lt;num. This is valid for a homogeneous electron distribution. However, hot electrons are located right after the shock, while most electrons are farther downstream and have cooled. This spatial distribution changes the optically thick part of the spectrum, introducing a new break frequency, nuac&lt;nusa, and a new spectral slope, Fnu~nu11&amp;solm0;8 for nuac&lt;nu&lt;nusa. The familiar Fnu~nu2 holds only for nu&lt;nuac. This ordering of the break frequencies is relevant for typical gamma-ray burst (GRB) afterglows in an interstellar medium environment. Other possibilities arise for internal shocks or afterglows in dense circumstellar winds. We discuss the possible implications of this spectrum for GRBs and their afterglows in the context of the internal-external shock model. Observations of Fnu~nu11&amp;solm0;8 would enable us to probe scales much smaller than the typical size of the system and to constrain the amount of turbulent mixing behind the shock.",
                    "score": 0.8472222685813904
                },
                {
                    "id": 12354643,
                    "contents": "Resolving ultrafast heating of dense cryogenic hydrogen.\nWe report on the dynamics of ultrafast heating in cryogenic hydrogen initiated by a ≲300  fs, 92 eV free electron laser x-ray burst. The rise of the x-ray scattering amplitude from a second x-ray pulse probes the transition from dense cryogenic molecular hydrogen to a nearly uncorrelated plasmalike structure, indicating an electron-ion equilibration time of ∼0.9  ps. The rise time agrees with radiation hydrodynamics simulations based on a conductivity model for partially ionized plasma that is validated by two-temperature density-functional theory. ",
                    "score": 0.847091555595398
                },
                {
                    "id": 6729890,
                    "contents": "X-ray astronomy in the new millennium: a summary.\nRecent X-ray observations have had a major impact on topics ranging from proto-stars to cosmology. They have also drawn attention to important and general physical processes that currently limit our understanding of thermal and non-thermal X-ray sources. These include unmeasured atomic astrophysics data (wavelengths, oscillator strengths, etc.), basic hydromagnetic processes (e.g. shock structure, reconnection), plasma processes (such as electron-ion equipartition and heat conduction) and radiative transfer (in discs and accretion columns). Progress on these problems will probably come from integrative studies that draw upon observations, throughout the electromagnetic spectrum, of different classes of source. X-ray observations are also giving a new perspective on astronomical subjects, like the nature of galactic nuclei and the evolution of stellar populations. In addition, they are helping us to address central cosmological questions, including the measurement of the matter content of the Universe, understanding its overall luminosity density, describing its chemical evolution and locating the first luminous objects. X-ray astronomy has a healthy future with several international space missions under construction and in development.",
                    "score": 0.8468663692474365
                },
                {
                    "id": 9667031,
                    "contents": "ASTRONOMY: Neighborhood Gamma Ray Burst Boosts Theory.\nTitanic explosions that emit powerful flashes of energetic gamma rays are one of astronomy's hottest mysteries. Now an analysis of the nearest gamma ray burst yet detected has added weight to the popular theory that they are expelled during the death throes of supermassive stars.",
                    "score": 0.8466925024986267
                },
                {
                    "id": 11516735,
                    "contents": "Ultrafast x-ray Thomson scattering of shock-compressed matter.\nSpectrally resolved scattering of ultrafast K-alpha x-rays has provided experimental validation of the modeling of the compression and heating of shocked matter. The elastic scattering component has characterized the evolution and coalescence of two shocks launched by a nanosecond laser pulse into lithium hydride with an unprecedented temporal resolution of 10 picoseconds. At shock coalescence, we observed rapid heating to temperatures of 25,000 kelvin when the scattering spectra show the collective plasmon oscillations that indicate the transition to the dense metallic plasma state. The plasmon frequency determines the material compression, which is found to be a factor of 3, thereby reaching conditions in the laboratory relevant for studying the physics of planetary formation.",
                    "score": 0.846398115158081
                },
                {
                    "id": 14094594,
                    "contents": "Neutrino emission from gamma-ray burst fireballs, revised.\nWe review the neutrino flux from gamma-ray bursts, which is estimated from gamma-ray observations and used for the interpretation of recent IceCube data, from a particle physics perspective. We numerically calculate the neutrino flux for the same astrophysical assumptions as the analytical fireball neutrino model, including the dominant pion and kaon production modes, flavor mixing, and magnetic field effects on the secondary muons, pions, and kaons. We demonstrate that taking into account the full energy dependencies of all spectra, the normalization of the expected neutrino flux reduces by about one order of magnitude and the spectrum shifts to higher energies, where we can pin down the exact origin of the discrepancies by the recomputation of the analytical models. We also reproduce the IceCube-40 analysis for exactly the same bursts and same assumptions and illustrate the impact of uncertainties. We conclude that the baryonic loading of the fireballs, which is an important control parameter for the emission of cosmic rays, can be constrained significantly with the full-scale experiment after about ten years.",
                    "score": 0.8462972044944763
                },
                {
                    "id": 21532990,
                    "contents": "Coherent Electromagnetic Emission from Relativistic Magnetized Shocks.\nRelativistic magnetized shocks are a natural source of coherent emission, offering a plausible radiative mechanism for fast radio bursts (FRBs). We present first-principles 3D simulations that provide essential information for the FRB models based on shocks: the emission efficiency, spectrum, and polarization. The simulated shock propagates in an e^{±} plasma with magnetization σ&gt;1. The measured fraction of shock energy converted to coherent radiation is ≃10^{-3}σ^{-1}, and the energy-carrying wave number of the wave spectrum is ≃4ω_{c}/c, where ω_{c} is the upstream gyrofrequency. The ratio of the O-mode and X-mode energy fluxes emitted by the shock is ≃0.4σ^{-1}. The dominance of the X mode at σ≫1 is particularly strong, approaching 100% in the spectral band around 2ω_{c}. We also provide a detailed description of the emission mechanism for both X and O modes.",
                    "score": 0.8459464907646179
                },
                {
                    "id": 4554126,
                    "contents": "5-10 GeV neutrinos from gamma-Ray burst fireballs\nA gamma-ray burst fireball is likely to contain an admixture of neutrons. Inelastic collisions between differentially streaming protons and neutrons in the fireball produce nu(&amp;mgr;) (nu;(&amp;mgr;)) of approximately 10 GeV as well as nu(e) (nu;(e)) of approximately 5 GeV, which could produce approximately 7 events/year in km(3) detectors, if the neutron abundance is comparable to that of protons. Photons of approximately 10 GeV from pi(0) decay and approximately 100 MeV nu;(e) from neutron decay are also produced, but will be difficult to detect. Photons with energies less, similar1 MeV from shocks following neutron decay produce a characteristic signal which may be distinguishable from the proton-related MeV photons.",
                    "score": 0.845543622970581
                },
                {
                    "id": 17068797,
                    "contents": "An ultraluminous X-ray source powered by an accreting neutron star.\nThe majority of ultraluminous X-ray sources are point sources that are spatially offset from the nuclei of nearby galaxies and whose X-ray luminosities exceed the theoretical maximum for spherical infall (the Eddington limit) onto stellar-mass black holes. Their X-ray luminosities in the 0.5-10 kiloelectronvolt energy band range from 10(39) to 10(41) ergs per second. Because higher masses imply less extreme ratios of the luminosity to the isotropic Eddington limit, theoretical models have focused on black hole rather than neutron star systems. The most challenging sources to explain are those at the luminous end of the range (more than 10(40) ergs per second), which require black hole masses of 50-100 times the solar value or significant departures from the standard thin disk accretion that powers bright Galactic X-ray binaries, or both. Here we report broadband X-ray observations of the nuclear region of the galaxy M82 that reveal pulsations with an average period of 1.37 seconds and a 2.5-day sinusoidal modulation. The pulsations result from the rotation of a magnetized neutron star, and the modulation arises from its binary orbit. The pulsed flux alone corresponds to an X-ray luminosity in the 3-30 kiloelectronvolt range of 4.9 × 10(39) ergs per second. The pulsating source is spatially coincident with a variable source that can reach an X-ray luminosity in the 0.3-10 kiloelectronvolt range of 1.8 × 10(40) ergs per second. This association implies a luminosity of about 100 times the Eddington limit for a 1.4-solar-mass object, or more than ten times brighter than any known accreting pulsar. This implies that neutron stars may not be rare in the ultraluminous X-ray population, and it challenges physical models for the accretion of matter onto magnetized compact objects. ",
                    "score": 0.8452038764953613
                },
                {
                    "id": 4707509,
                    "contents": "Fast heating of ultrahigh-density plasma as a step towards laser fusion ignition.\nModern high-power lasers can generate extreme states of matter that are relevant to astrophysics, equation-of-state studies and fusion energy research. Laser-driven implosions of spherical polymer shells have, for example, achieved an increase in density of 1,000 times relative to the solid state. These densities are large enough to enable controlled fusion, but to achieve energy gain a small volume of compressed fuel (known as the 'spark') must be heated to temperatures of about 108 K (corresponding to thermal energies in excess of 10 keV). In the conventional approach to controlled fusion, the spark is both produced and heated by accurately timed shock waves, but this process requires both precise implosion symmetry and a very large drive energy. In principle, these requirements can be significantly relaxed by performing the compression and fast heating separately; however, this 'fast ignitor' approach also suffers drawbacks, such as propagation losses and deflection of the ultra-intense laser pulse by the plasma surrounding the compressed fuel. Here we employ a new compression geometry that eliminates these problems; we combine production of compressed matter in a laser-driven implosion with picosecond-fast heating by a laser pulse timed to coincide with the peak compression. Our approach therefore permits efficient compression and heating to be carried out simultaneously, providing a route to efficient fusion energy production.",
                    "score": 0.844623863697052
                },
                {
                    "id": 13912951,
                    "contents": "The Great Eruption of η Carinae.\nArising from A. Rest et al.  482, 375-378 (2012).During the years 1838-1858, the very massive star η Carinae became the prototype supernova impostor: it released nearly as much light as a supernova explosion and shed an impressive amount of mass, but survived as a star. In the standard interpretation, mass was driven outward by excess radiation pressure, persisting for several years. From a light-echo spectrum of that event, Rest et al. conclude that \"other physical mechanisms\" are required to explain it, because the gas outflow appears cooler than theoretical expectations. Here we note that (1) theory predicted a substantially lower temperature than they quoted, and (2) their inferred observational value is quite uncertain. Therefore, analyses so far do not reveal any significant contradiction between the observed spectrum and most previous discussions of the Great Eruption and its physics.",
                    "score": 0.8440567851066589
                },
                {
                    "id": 7377396,
                    "contents": "Dynamical overstability of radiative blast waves: the atomic physics of shock stability.\nAtomic-physics calculations of radiative cooling are used to develop criteria for the overstability of radiating shocks. Our calculations explain the measurement of shock overstability by Grun et al. [Phys. Rev. Lett. 66, 2738 (1991)]] and explain why the overstability was not observed in other experiments. The methodology described here can be especially useful in astrophysical situations where the relevant properties leading to an overstability can be measured spectroscopically, but the effective adiabatic index is harder to determine.",
                    "score": 0.8439068794250488
                },
                {
                    "id": 7297770,
                    "contents": "Multiple ionization of atom clusters by intense soft X-rays from a free-electron laser.\nIntense radiation from lasers has opened up many new areas of research in physics and chemistry, and has revolutionized optical technology. So far, most work in the field of nonlinear processes has been restricted to infrared, visible and ultraviolet light, although progress in the development of X-ray lasers has been made recently. With the advent of a free-electron laser in the soft-X-ray regime below 100 nm wavelength, a new light source is now available for experiments with intense, short-wavelength radiation that could be used to obtain deeper insights into the structure of matter. Other free-electron sources with even shorter wavelengths are planned for the future. Here we present initial results from a study of the interaction of soft X-ray radiation, generated by a free-electron laser, with Xe atoms and clusters. We find that, whereas Xe atoms become only singly ionized by the absorption of single photons, absorption in clusters is strongly enhanced. On average, each atom in large clusters absorbs up to 400 eV, corresponding to 30 photons. We suggest that the clusters are heated up and electrons are emitted after acquiring sufficient energy. The clusters finally disintegrate completely by Coulomb explosion.",
                    "score": 0.843644917011261
                },
                {
                    "id": 15547690,
                    "contents": "X-ray continuum emission spectroscopy from hot dense matter at Gbar pressures.\nWe have measured the time-resolved x-ray continuum emission spectrum of ∼30 times compressed polystyrene created at stagnation of spherically convergent shock waves within the Gbar fundamental science campaign at the National Ignition Facility. From an exponential emission slope between 7.7 keV and 8.1 keV photon energy and using an emission model which accounts for reabsorption, we infer an average electron temperature of 375 ± 21 eV, which is in good agreement with HYDRA-1D simulations. ",
                    "score": 0.8435119390487671
                },
                {
                    "id": 10699880,
                    "contents": "A new look at low-energy nuclear reaction research.\nThis paper presents a new look at low-energy nuclear reaction research, a field that has developed from one of the most controversial subjects in science, \"cold fusion.\" Early in the history of this controversy, beginning in 1989, a strong polarity existed; many scientists fiercely defended the claim of new physical effects as well as a new process in which like-charged atomic nuclei overcome the Coulomb barrier at normal temperatures and pressures. Many other scientists considered the entire collection of physical observations-along with the hypothesis of a \"cold fusion\"--entirely a mistake. Twenty years later, some people who had dismissed the field in its entirety are considering the validity of at least some of the reported experimental phenomena. As well, some researchers in the field are wondering whether the underlying phenomena may be not a fusion process but a neutron capture/absorption process. In 2002, a related tabletop form of thermonuclear fusion was discovered in the field of acoustic inertial confinement fusion. We briefly review some of this work, as well.",
                    "score": 0.8429598808288574
                },
                {
                    "id": 22237911,
                    "contents": "Localized thermonuclear bursts from accreting magnetic white dwarfs.\nNova explosions are caused by global thermonuclear runaways triggered in the surface layers of accreting white dwarfs<sup1-3</sup. It has been predicted<sup4-6</sup that localized thermonuclear bursts on white dwarfs can also take place, similar to type-I X-ray bursts observed in accreting neutron stars. Unexplained rapid bursts from the binary system TV Columbae, in which mass is accreted onto a moderately strong magnetized white dwarf from a low-mass companion, have been observed on several occasions in the past 40 years<sup7-11</sup. During these bursts, the optical/ultraviolet luminosity increases by a factor of more than  three in less than an hour and fades in around ten hours. Fast outflows have been observed in ultraviolet spectral lines<sup7</sup, with velocities of more than 3,500 kilometres per second, comparable to the escape velocity from the white dwarf surface. Here we report on optical bursts observed in TV Columbae and in two additional accreting systems, EI Ursae Majoris and ASASSN-19bh. The bursts have a total energy of approximately 10<sup-6</sup  times than those of classical nova explosions (micronovae) and bear a strong resemblance to type-I X-ray bursts<sup12-14</sup. We exclude accretion or stellar magnetic reconnection events as their origin and suggest thermonuclear runaway events in magnetically confined accretion columns as a viable explanation.",
                    "score": 0.8426361680030823
                },
                {
                    "id": 9667102,
                    "contents": "PHYSICS: Will Livermore Laser Ever Burn Brightly?\nThe National Ignition Facility (NIF), a superlaser being built here at Lawrence Livermore National Laboratory in an effort to use lasers rather than nuclear explosions to create a fusion reaction, is supposed to allow weapons makers to preserve the nuclear arsenal--and do nifty fusion science, too. But a new report that examines its troubled past also casts doubt on its future. Even some of NIF's scientific and political allies are beginning to talk openly of a scaled-down version of the original 192-laser design.",
                    "score": 0.8426014184951782
                },
                {
                    "id": 5746776,
                    "contents": "Compton-dragged Gamma-Ray Bursts Associated with Supernovae.\nIt is proposed that the gamma-ray photons that characterize the prompt emission of gamma-ray bursts are produced through the Compton-drag process, which is caused by the interaction of a relativistic fireball with a very dense soft photon bath. If gamma-ray bursts are indeed associated with supernovae, then the exploding star can provide enough soft photons for radiative drag to be effective. This model accounts for the basic properties of gamma-ray bursts, i.e., the overall energetics, the peak frequency of the spectrum, and the fast variability, with an efficiency that can exceed 50%. In this scenario, there is no need for particle acceleration in relativistic collisionless shocks. Furthermore, although the Poynting flux may be important in accelerating the outflow, no magnetic field is required in the gamma-ray production. The drag also naturally limits the relativistic expansion of the fireball to Gamma less, similar104.",
                    "score": 0.842261552810669
                },
                {
                    "id": 9263096,
                    "contents": "Energy of Tycho's supernova remnant is increasing with time.\nIt is shown, using the Zeldovich integral relations, that the energy of Tycho's Supernova Remnant is strongly growing with time, approximately as t(1/3). This growth can be attributed to the exothermic reactions going inside the remnant. The use of the assumption of the adiabaticity of the motion inside of the shock front, and no losses or gain of energy at the front, seems therefore unjustified.",
                    "score": 0.8418370485305786
                },
                {
                    "id": 13769377,
                    "contents": "Measurement of the survival probabilities for hot fusion reactions.\nWe have studied the fission-neutron emission competition in highly excited (274)Hs (Z=108) (where the fission barrier is due to shell effects) formed by a hot fusion reaction. Matching cross bombardments ((26)Mg+(248)Cm and (25)Mg+(248)Cm) were used to identify the properties of first chance fission of (274)Hs. A Harding-Farley analysis of the fission neutrons emitted in the (25)Mg,26+(248)Cm was performed to identify the prescission and postscission components of the neutron multiplicities in each system. (Γn/Γt) for the first chance fission of (274)Hs (E*=63  MeV) is 0.89±0.13; i.e., ∼90% of the highly excited nuclei survive. The high value of that survival probability is due to dissipative effects during deexcitation. A proper description of the survival probabilities of excited superheavy nuclei formed in hot fusion reactions requires consideration of both dynamic and static (shell-related) effects.",
                    "score": 0.8414373993873596
                },
                {
                    "id": 19634695,
                    "contents": "New frontiers in extreme conditions science at synchrotrons and free electron lasers.\nSynchrotrons and free electron lasers are unique facilities to probe the atomic structure and electronic properties of matter at extreme thermodynamical conditions. In this context, 'matter at extreme pressures and temperatures' was one of the science drivers for the construction of low emittance 4th generation synchrotron sources such as the Extremely Brilliant Source of the European Synchrotron Radiation Facility and hard x-ray free electron lasers, such as the European x-ray free electron laser. These new user facilities combine static high pressure and dynamic shock compression experiments to outstanding high brilliance and submicron beams. This combination not only increases the data-quality but also enlarges tremendously the accessible pressure, temperature and density space. At the same time, the large spectrum of available complementary x-ray diagnostics for static and shock compression studies opens unprecedented insights into the state of matter at extremes. The article aims at highlighting a new horizon of scientific opportunities based on the synergy between extremely brilliant synchrotrons and hard x-ray free electron lasers.",
                    "score": 0.84104984998703
                },
                {
                    "id": 7783894,
                    "contents": "Anisotropic explosions of hydrogen clusters under intense femtosecond laser irradiation.\nWe report on measurements of ion energy distributions from hydrogen clusters irradiated by intense laser pulses of duration 40 and 250 fs. Contrary to the predictions of a simple Coulomb explosion model, we observe a pronounced spatial anisotropy of the ion energies from these explosions with the highest energy ions ejected along the laser polarization direction. The origin of the anisotropy is distinct from that previously seen in clusters of high Z atoms such as Ar and Xe. Furthermore, a measured increase in H+ ion energy when longer, lower intensity pulses are employed suggests that multiple-pass, vacuum heating of the cluster electrons is important in the deposition of energy by the laser.",
                    "score": 0.8409920930862427
                },
                {
                    "id": 10532041,
                    "contents": "Measuring the cosmic-ray acceleration efficiency of a supernova remnant.\nCosmic rays are the most energetic particles arriving at Earth. Although most of them are thought to be accelerated by supernova remnants, the details of the acceleration process and its efficiency are not well determined. Here we show that the pressure induced by cosmic rays exceeds the thermal pressure behind the northeast shock of the supernova remnant RCW 86, where the x-ray emission is dominated by synchrotron radiation from ultrarelativistic electrons. We determined the cosmic-ray content from the thermal Doppler broadening measured with optical spectroscopy, combined with a proper-motion study in x-rays. The measured postshock proton temperature, in combination with the shock velocity, does not agree with standard shock heating, implying that &gt;50% of the postshock pressure is produced by cosmic rays.",
                    "score": 0.8406361937522888
                }
            ],
            "metric_score": {
                "retrieval_recall": 1,
                "retrieval_precision": 0.4
            }
        }
    },
    {
        "id": "test_18",
        "question": "Show that l'Hôpital's rule amounts to forming a Taylor expansion of both the numerator and the denominator. Evaluate the limit\r\n$$\r\n\\lim _{x \\rightarrow 0} \\frac{\\ln (1+x)-x}{x^2}\r\n$$\r\nboth ways.",
        "golden_answers": [
            " -1/2"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 8312356,
                    "contents": "An introduction to an updated bibliography of Andreas Vesalius (1514-1564).\nAfter more than forty years Dr. Harvey Cushing's list of Vesaliana needs to be updated. The present list combines the Vesaliana of Cushing with titles gathered by R. Calcoen and newly found earlier and more recent ones. They are arranged in alpha-numerical order while the list retains the already existing numberings.",
                    "score": 0.8811928033828735
                },
                {
                    "id": 5617465,
                    "contents": "A positivity result in the theory of Macdonald polynomials.\nWe outline here a proof that a certain rational function C(n)(q, t), which has come to be known as the \"q, t-Catalan,\" is in fact a polynomial with positive integer coefficients. This has been an open problem since 1994. Because C(n)(q, t) evaluates to the Catalan number at t = q = 1, it has also been an open problem to find a pair of statistics a, b on the collection (n) of Dyck paths Pi of length 2n yielding C(n)(q, t) = summation operator(pi) t(a(Pi))q(b(Pi)). Our proof is based on a recursion for C(n)(q, t) suggested by a pair of statistics recently proposed by J. Haglund. One of the byproducts of our results is a proof of the validity of Haglund's conjecture.",
                    "score": 0.878817081451416
                },
                {
                    "id": 8456014,
                    "contents": "On an analytic estimate in the theory of the Riemann zeta function and a theorem of Báez-Duarte.\nOn the Riemann hypothesis we establish a uniform upper estimate for zeta(s)/zeta (s + A), 0 &lt; or = A, on the critical line. We use this to give a purely complex-analytic variant of Báez-Duarte's proof of a strengthened Nyman-Beurling criterion for the validity of the Riemann Hypothesis. We investigate function-theoretically some of the functions defined by Báez-Duarte in his study and we show that their square-integrability is, in itself, an equivalent formulation of the Riemann Hypothesis. We conclude with a third equivalent formulation which resembles a \"causality\" statement.",
                    "score": 0.8788099884986877
                },
                {
                    "id": 19611924,
                    "contents": "Steven Weinberg (1933-2021).\nTitan of theoretical physics.",
                    "score": 0.8762193918228149
                },
                {
                    "id": 9660598,
                    "contents": "Correction and updating.\nIn the heading of David Cassidy's review of The Private Lives of Albert Einstein (18 February, p. 997) the price of the book as sold by its British publisher, Faber and Faber, was given incorrectly; the correct price is pound15.99. The book is also to be published in the United States by St. Martin's Press, New York, in April, at a price of $23.95.",
                    "score": 0.8759002089500427
                },
                {
                    "id": 23021285,
                    "contents": "A Universal Power Law Governing the Accuracy of Wave Function-Based Electronic Structure Calculations.\nA universal power law governing the accuracy of wave function-based electronic structure calculations is derived from first principles. The resulting expression <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:mfrac<mml:mrow<mml:miΔ</mml:mi<mml:miE</mml:mi<mml:mrow<mml:mo(</mml:mo<mml:miN</mml:mi<mml:mo,</mml:mo<mml:miN</mml:mi<mml:mo)</mml:mo</mml:mrow</mml:mrow<mml:mrow<mml:miN</mml:mi</mml:mrow</mml:mfrac</mml:mrow<mml:mo≳</mml:mo<mml:mrow<mml:mfrac<mml:mrow<mml:mn1</mml:mn</mml:mrow<mml:mrow<mml:mn9</mml:mn<mml:mrow<mml:msup<mml:mrow<mml:miπ</mml:mi</mml:mrow<mml:mrow<mml:mn2</mml:mn</mml:mrow</mml:msup</mml:mrow</mml:mrow</mml:mfrac</mml:mrow<mml:mspace/<mml:mig</mml:mi<mml:mspace/<mml:mrow<mml:mfrac<mml:mrow<mml:miN</mml:mi</mml:mrow<mml:mrow<mml:miN</mml:mi</mml:mrow</mml:mfrac</mml:mrow</mml:math, where <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mig</mml:mi</mml:math is a system-specific factor assuming values between zero and one and ≳ stands for asymptotic inequality at the limit of <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miN</mml:mi<mml:mo→</mml:mo<mml:mi∞</mml:mi</mml:math, allows facile estimation of the error <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miΔ</mml:mi<mml:miE</mml:mi<mml:mrow<mml:mo(</mml:mo<mml:miN</mml:mi<mml:mo,</mml:mo<mml:miN</mml:mi<mml:mo)</mml:mo</mml:mrow</mml:math in the electronic energy of a singlet state of an <iN</i-electron system computed with a basis set of <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miN</mml:mi</mml:math one-electron functions. Several approaches to the estimation of the factor <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mig</mml:mi</mml:math, which depends on the on-top two-electron density, are presented.",
                    "score": 0.8748330473899841
                },
                {
                    "id": 9617151,
                    "contents": "A Simple Proof of Siegel's Theorem.\nA brief and simple proof of Siegel's celebrated theorem that h(d) &gt;&gt; d(1/2-[unk]), as d --&gt; infinity, is given. Here h(d) denotes the class number of the quadratic field Q([unk]-d). Simple proofs that do not make use of algebraic number theory have been previously given by Estermann and Chowla.",
                    "score": 0.8739669322967529
                },
                {
                    "id": 9024525,
                    "contents": "The making of the standard model.\nA seemingly temporary solution to almost a century of questions has become one of physics' greatest successes.",
                    "score": 0.8720642924308777
                },
                {
                    "id": 1091161,
                    "contents": "Tutorial on large deviations for the binomial distribution.\nWe present, in an easy to use form, the large deviation theory of the binomial distribution: how to approximate the probability of k or more successes in n independent trials, each with success probability p, when the specified fraction of successes, a identical to k/n, satisfies 0 less than p less than a less than 1.",
                    "score": 0.8718603849411011
                },
                {
                    "id": 8313536,
                    "contents": "Self-consistent scaling theory for logarithmic-correction exponents.\nMultiplicative logarithmic corrections frequently characterize critical behavior in statistical physics. Here, a recently proposed theory relating the exponents of such terms is extended to account for circumstances which often occur when the leading specific-heat critical exponent vanishes. Also, the theory is widened to encompass the correlation function. The new relations are then confronted with results from the literature, and some new predictions for logarithmic corrections in certain models are made.",
                    "score": 0.8716335892677307
                },
                {
                    "id": 6308550,
                    "contents": "Exact 95% confidence intervals for differences in binomial proportions.\nA method is described that allows exact 95% confidence intervals to be computed for differences in binomial proportions. The method itself is not iterative, but it uses the iteratively computed 95% confidence intervals for the individual binomial proportions. The method converges with the usual normal approximation method, as denominators become large. It correlates very closely with the Yates-corrected chi-square test. The method works regardless of the definition of success or failure in the proportions and regardless of the order of the proportions.",
                    "score": 0.8712828755378723
                },
                {
                    "id": 12288917,
                    "contents": "A simple derivation of the Landau-Zener formula.\nUsing the contour integration approach proposed earlier, we find a simple derivation of the Landau-Zener formula which does not use explicitly the solution of the Schrödinger equation. ",
                    "score": 0.8708791732788086
                },
                {
                    "id": 20278940,
                    "contents": "[Sokolov Evgeniy Ivanovich (to the 90&lt;sup&gt;th&lt;/sup&gt; birthday)].\n.",
                    "score": 0.8702267408370972
                },
                {
                    "id": 19031252,
                    "contents": "A series of sequences convergent to Euler's constant.\nIn this paper, using continued fraction, we provide a new quicker sequence convergent to Euler's constant. We demonstrate the superiority of our new convergent sequences over DeTemple's sequence, Mortici's sequences, Vernescu's sequence, and Lu's sequence.",
                    "score": 0.8700963854789734
                },
                {
                    "id": 21421458,
                    "contents": "On powers that are sums of consecutive like powers.\nLet <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:mik</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn</mml:mrow </mml:math be even, and let <ir</i be a non-zero integer. We show that for almost all <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:mid</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn</mml:mrow </mml:math (in the sense of natural density), the equation <DispFormula <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow<mml:msup<mml:mix</mml:mi <mml:mik</mml:mi</mml:msup <mml:mo+</mml:mo <mml:msup<mml:mrow<mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo+</mml:mo <mml:mir</mml:mi <mml:mo)</mml:mo</mml:mrow <mml:mik</mml:mi</mml:msup <mml:mo+</mml:mo <mml:mo⋯</mml:mo <mml:mo+</mml:mo <mml:msup<mml:mrow<mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo+</mml:mo <mml:mrow<mml:mo(</mml:mo <mml:mid</mml:mi <mml:mo-</mml:mo <mml:mn1</mml:mn <mml:mo)</mml:mo</mml:mrow <mml:mir</mml:mi <mml:mo)</mml:mo</mml:mrow <mml:mik</mml:mi</mml:msup <mml:mo=</mml:mo <mml:msup<mml:miy</mml:mi <mml:min</mml:mi</mml:msup <mml:mo,</mml:mo <mml:mspace/ <mml:mix</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:miy</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:min</mml:mi <mml:mo∈</mml:mo <mml:miZ</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:min</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn <mml:mo,</mml:mo</mml:mrow </mml:math </DispFormula has no solutions.",
                    "score": 0.8695557713508606
                },
                {
                    "id": 19153725,
                    "contents": "Notice of Retraction.\n[This retracts the article on p. 661 in vol. 38.].",
                    "score": 0.8687609434127808
                },
                {
                    "id": 16617469,
                    "contents": "Gopalakrishnan, Martin, and Demler reply:.\nA Reply to the Comments by M. Sandbrink et al. and R. Lifshitz. ",
                    "score": 0.8685221076011658
                },
                {
                    "id": 8999784,
                    "contents": "A combinatorial model for the Macdonald polynomials.\nWe introduce a polynomial C(mu)[Z; q, t], depending on a set of variables Z = z(1), z(2),..., a partition mu, and two extra parameters q, t. The definition of C(mu) involves a pair of statistics (maj(sigma, mu), inv(sigma, mu)) on words sigma of positive integers, and the coefficients of the z(i) are manifestly in N[q,t]. We conjecture that C(mu)[Z; q, t] is none other than the modified Macdonald polynomial H(mu)[Z; q, t]. We further introduce a general family of polynomials F(T)[Z; q, S], where T is an arbitrary set of squares in the first quadrant of the xy plane, and S is an arbitrary subset of T. The coefficients of the F(T)[Z; q, S] are in N[q], and C(mu)[Z; q, t] is a sum of certain F(T)[Z; q, S] times nonnegative powers of t. We prove F(T)[Z; q, S] is symmetric in the z(i) and satisfies other properties consistent with the conjecture. We also show how the coefficient of a monomial in F(T)[Z; q, S] can be expressed recursively. maple calculations indicate the F(T)[Z; q, S] are Schur-positive, and we present a combinatorial conjecture for their Schur coefficients when the set T is a partition with at most three columns.",
                    "score": 0.868474006652832
                },
                {
                    "id": 19368151,
                    "contents": "[72 years of existence].\nNo Abstract available.",
                    "score": 0.8682969808578491
                },
                {
                    "id": 6534017,
                    "contents": "The first President of the Royal Society.\nFew people know the name of the Royal Society's first President, even though he features prominently in Thomas Sprat's famous allegorical frontispiece. In promotional images, his individual identity is irrelevant for proclaiming the Society's allegiance to Francis Bacon and commitment to experimental investigation. By contrast, William Brouncker's name does appear on Peter Lely's large portrait, which hung at the Royal Society. Brouncker was a gifted mathematician as well as a conscientious administrator, and Lely's portrait reproduces the diagram of one of his innovative algebraic proofs.",
                    "score": 0.868187427520752
                },
                {
                    "id": 18892474,
                    "contents": "On rational bounds for the gamma function.\nIn the article, we prove that the double inequality [Formula: see text] holds for all [Formula: see text], we present the best possible constants <iλ</i and <iμ</i such that [Formula: see text] for all [Formula: see text], and we find the value of [Formula: see text] in the interval [Formula: see text] such that [Formula: see text] for [Formula: see text] and [Formula: see text] for [Formula: see text], where [Formula: see text] is the classical gamma function, [Formula: see text] is Euler-Mascheroni constant and [Formula: see text] .",
                    "score": 0.8677424192428589
                },
                {
                    "id": 20648900,
                    "contents": "The Gibbs Paradox: Early History and Solutions.\nThis article is a detailed history of the Gibbs paradox, with philosophical morals. It purports to explain the origins of the paradox, to describe and criticize solutions of the paradox from the early times to the present, to use the history of statistical mechanics as a reservoir of ideas for clarifying foundations and removing prejudices, and to relate the paradox to broad misunderstandings of the nature of physical theory.",
                    "score": 0.8676226735115051
                },
                {
                    "id": 19153722,
                    "contents": "Notice of Retraction.\n[This retracts the article on p. 13 in vol. 38.].",
                    "score": 0.8674164414405823
                },
                {
                    "id": 12279682,
                    "contents": "Barrow, Leibniz and the geometrical proof of the fundamental theorem of the calculus.\nIn 1693, Gottfried Wilhelm Leibniz published in the Acta Eruditorum a geometrical proof of the fundamental theorem of the calculus. It is shown that this proof closely resembles Isaac Barrow's proof in Proposition 11, Lecture 10, of his Lectiones Geometricae, published in 1670. This comparison provides evidence that Leibniz gained substantial help from Barrow's book in formulating and presenting his geometrical formulation of this theorem. The analysis herein also supports the work of J. M. Child, who in 1920 studied the early manuscripts of Leibniz and concluded that he had frequently copied his diagrams from Barrow's book, but without acknowledgement. It is also shown that the diagram of Leibniz associated with his 1693 proof has often been reproduced with errors that make some aspects of his text difficult to comprehend.",
                    "score": 0.8673100471496582
                },
                {
                    "id": 9573887,
                    "contents": "Celestial mechanics on a microscopic scale.\nClassical and semiclassical methods are unrivaled in providing an intuitive and computationally tractable approach to the study of atomic, molecular, and nuclear dynamics. An important advantage of such methods is their ability to uncover in a single picture underlying structures that may be hard to extract from the profusion of data supplied by detailed quantum calculations. Modern trends in semiclassical mechanics are described, particularly the combination of group theoretical methods with techniques of nonlinear dynamics. Application is made to intramolecular energy transfer and to the electronic structure of atomic Rydberg states in external electric and magnetic fields.",
                    "score": 0.8670660853385925
                },
                {
                    "id": 19153724,
                    "contents": "Notice of Retraction.\n[This retracts the article on p. 101 in vol. 38.].",
                    "score": 0.8665505647659302
                },
                {
                    "id": 6034739,
                    "contents": "The original presentation of Boyle's law.\nThe original presentation of what we know as Boyle's law has several interesting features. First, the technical difficulties of the experiment were considerable, because Boyle used a glass tube full of mercury that was nearly 2.5 m long, and the large pressures sometimes shattered the glass. Next, Boyle's table of results contains extremely awkward fractions, such 10/13, 2/17, 13/19, and 18/23, which look very strange to us today. This was because he calculated the pressure for a certain volume of gas by using simple multiplication and division, keeping the vulgar fractions. Boyle was not able to express the numbers as decimals because this notation was not in common use at the time. Finally, his contention that pressure and volume were inversely related depended on the reader's comparing two sets of numbers in adjacent columns to see how well they agreed. Today we would plot the data, but again orthogonal graphs were not in general use in 1662. When Boyle's data are plotted by using modern conventional methods, they strongly support his hypothesis that the volume and pressure of a gas are inversely related.",
                    "score": 0.8660303950309753
                },
                {
                    "id": 5854019,
                    "contents": "In this issue \nCopyright 1998 Academic Press Limited",
                    "score": 0.8660122752189636
                },
                {
                    "id": 9378335,
                    "contents": "Bold diagrammatic Monte Carlo technique: when the sign problem is welcome.\nWe introduce a Monte Carlo scheme for sampling a bold-line diagrammatic series specifying an unknown function in terms of itself. The range of convergence of this bold(-line) diagrammatic Monte Carlo (BMC) technique is significantly broader than that of a simple iterative scheme for solving integral equations. With the BMC technique, a moderate \"sign problem\" turns out to be an advantage in terms of the convergence of the process. For an illustrative purpose, we solve the one-particle s-scattering problem. As an important application, we obtain the T matrix for a Fermi polaron (one spin-down particle interacting with the spin-up fermionic sea).",
                    "score": 0.8649984002113342
                },
                {
                    "id": 10013026,
                    "contents": "New applications of the renormalization group method in physics: a brief introduction.\nThe renormalization group (RG) method developed by Ken Wilson more than four decades ago has revolutionized the way we think about problems involving a broad range of energy scales such as phase transitions, turbulence, continuum limits and bifurcations in dynamical systems. The Theme Issue provides articles reviewing recent progress made using the RG method in atomic, condensed matter, nuclear and particle physics. In the following, we introduce these articles in a way that emphasizes common themes and the universal aspects of the method.",
                    "score": 0.8648523688316345
                },
                {
                    "id": 9616997,
                    "contents": "omega-Theorems for Riemann's Zeta-Function at Harmonic Combinations of Points.\nFor integer r &gt;/= 2 there are arbitrarily large T for which [Formula: see text] With s = sigma + it, corresponding results hold for sigma = c, 1/2 &lt;/= c &lt; 1, and for 1/zeta(1 + it). A similar result holds for [Formula: see text].",
                    "score": 0.8641509413719177
                },
                {
                    "id": 23492622,
                    "contents": "Retraction.\n[This retracts the article DOI: 10.1093/cz/zoy089.].",
                    "score": 0.8639200329780579
                },
                {
                    "id": 20648694,
                    "contents": "The Second Law of Thermodynamics as a Force Law.\nThe second law of thermodynamics states the increase of entropy, Δ S &gt; 0 , for real processes from state A to state B at constant energy from chemistry over biological life and engines to cosmic events. The connection of entropy to information, phase-space, and heat is helpful but does not immediately convince observers of the validity and basis of the second law. This gave grounds for finding a rigorous, but more easily acceptable reformulation. Here, we show using statistical mechanics that this principle is equivalent to a force law ⟨ ⟨ f ⟩ ⟩ &gt; 0 in systems where mass centers and forces can be identified. The sign of this net force--the average mean force along a path from A to B--determines the direction of the process. The force law applies to a wide range of processes from machines to chemical reactions. The explanation of irreversibility by a driving force appears more plausible than the traditional formulation as it emphasizes the cause instead of the effect of motions.",
                    "score": 0.8634927868843079
                },
                {
                    "id": 17559658,
                    "contents": "Retraction.\n[This retracts the article on p. 87 in vol. 53, PMID: 29662870.].",
                    "score": 0.8633469939231873
                },
                {
                    "id": 17631180,
                    "contents": "Reshaping the metaphor of proof.\nThe simplistic view of Mathematics as a logical system of formal truths deduced from a limited set of axioms by a limited set of inference rules immediately shatters when confronted with the history of Mathematics, or current mathematical practice. To become useful, mathematical Philosophy should contemplate what Mathematics actually was, over centuries, and what it is now, rather than speculate what it should be according to the philosophical orthodoxy. The first dogma that must be completely revised is the idea of proof as a text, rather than what it is for mathematicians themselves: a process, a plethora of interwoven arguments, a multi-dimensional structure. This article is part of the theme issue 'The notion of 'simple proof' - Hilbert's 24th problem'.",
                    "score": 0.8630877733230591
                },
                {
                    "id": 17094283,
                    "contents": "Visiting Newton's atelier before the Principia, 1679-1684.\nThe worksheets that presumably contained Newton's early development of the fundamental concepts in his Principia have been lost. A plausible reconstruction of this development is presented based on Newton's exchange of letters with Robert Hooke in 1679, with Edmund Halley in 1686, and on some clues in the diagram associated with Proposition 1 in Book 1 of the Principia that have been ignored in the past. A graphical construction associated with this proposition leads to a rapidly convergent method to obtain orbits for central forces, which elucidates how Newton may have have been led to formulate some of his most fundamental propositions in the Principia.",
                    "score": 0.8627042770385742
                },
                {
                    "id": 9691374,
                    "contents": "Fast algorithms for classical physics.\nSome of the recently developed fast summation methods that have arisen in scientific computing are described. These methods require an amount of work proportional to N or N log N to evaluate all pairwise interactions in an ensemble of N particles. Traditional methods, by contrast, require an amount of work proportional to N(2). As a result, largescale simulations can be carried out using only modest computer resources. In combination with supercomputers, it is possible to address questions that were previously out of reach. Problems from diffusion, gravitation, and wave propagation are considered.",
                    "score": 0.8626927733421326
                },
                {
                    "id": 18256813,
                    "contents": "Erratum to 10.1177/0003702817724164.\n<bDominic V. Poerio and Steven D. Brown</b In this article, we regret there were some revisions that were not made at the request of the authors. On page 379, on lines 7 and 10, within the Theory section, the epsilons should be in bold. On page 380, line 17, first column, first paragraph, the equation should have been displayed as follows: [Formula: see text] On page 380, line 20, first column, first paragraph, the equation should have been displayed as follows: [Formula: see text] On page 380, line 32, first column, first paragraph, the equation should have been displayed as follows: [Formula: see text] On page 380, line 17, second column, first paragraph, the equation should have been displayed as follows: [Formula: see text] On page 380, line 19, second column, first paragraph, the equation should have been displayed as follows: [Formula: see text] On page 380, line 25, second column, first paragraph, the equation should have appeared as [Formula: see text] On page 380, line 28, second column, first paragraph, the equation should have appeared as [Formula: see text] On page 380, line 29, second column, first paragraph, there was an extra character that did not belong in the line. It should instead have been <bX</b<i<subf  </sub</i. On page 380, line 33, second column, first paragraph, the equation should have appeared as [Formula: see text] On page 381, line 30, first column, second paragraph, the equation should have appeared as [Formula: see text] On page 381, line 33, first column, second paragraph, the equation should have appeared as [Formula: see text] On page 381, lines 42 to 43, first column, second paragraph, the equation should have appeared as [Formula: see text] On page 381, lines 14 to 15, second column, second paragraph, the equation should have appeared as [Formula: see text] On page 381, line 25, second column, second paragraph, the equation should have appeared as [Formula: see text] On page 388, there was a typographical error in Figure 3. It should have appeared as On page 390, line 4, first column, first paragraph, the line should have read, \"Figure 5 shows a comparison of the mean training spectrum for Foss1 and Foss2 …\" Reference 11 on page 391 was incomplete. It should have appeared as, \"G. Strang, T. Nguyen. 'Finite Length Signals'. In: G. Strang, T. Nguyen, editors. Wavelengths and Filter Banks. Wellesley, MA: Wellesley-Cambridge Press, 1976. Pp. 263-289\".",
                    "score": 0.862617015838623
                },
                {
                    "id": 18946823,
                    "contents": "Error bounds for the asymptotic expansion of the Hurwitz zeta function.\nIn this paper, we reconsider the large-<ia</i asymptotic expansion of the Hurwitz zeta function <iζ</i(<is</i,<ia</i). New representations for the remainder term of the asymptotic expansion are found and used to obtain sharp and realistic error bounds. Applications to the asymptotic expansions of the polygamma functions, the gamma function, the Barnes <iG</i-function and the <is</i-derivative of the Hurwitz zeta function <iζ</i(<is</i,<ia</i) are provided. A detailed discussion on the sharpness of our error bounds is also given.",
                    "score": 0.8623229265213013
                },
                {
                    "id": 20675964,
                    "contents": "On generating functions in additive number theory, II: lower-order terms and applications to PDEs.\nWe obtain asymptotics for sums of the form <DispFormula <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow <mml:mtable <mml:mtr <mml:mtd <mml:mrow<mml:munderover<mml:mo∑</mml:mo <mml:mrow<mml:min</mml:mi <mml:mo=</mml:mo <mml:mn1</mml:mn</mml:mrow <mml:miP</mml:mi</mml:munderover <mml:mie</mml:mi <mml:mfenced<mml:msub<mml:miα</mml:mi <mml:mik</mml:mi</mml:msub <mml:mspace/ <mml:msup<mml:min</mml:mi <mml:mik</mml:mi</mml:msup <mml:mspace/ <mml:mo+</mml:mo <mml:mspace/ <mml:msub<mml:miα</mml:mi <mml:mn1</mml:mn</mml:msub <mml:min</mml:mi</mml:mfenced <mml:mo,</mml:mo</mml:mrow </mml:mtd </mml:mtr </mml:mtable </mml:mrow </mml:math </DispFormula involving lower order main terms. As an application, we show that for almost all <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow<mml:msub<mml:miα</mml:mi <mml:mn2</mml:mn</mml:msub <mml:mo∈</mml:mo <mml:mrow<mml:mo[</mml:mo <mml:mn0</mml:mn <mml:mo,</mml:mo <mml:mn1</mml:mn <mml:mo)</mml:mo</mml:mrow </mml:mrow </mml:math one has <DispFormula <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow <mml:mtable <mml:mtr <mml:mtd <mml:mrow<mml:munder<mml:mosup</mml:mo <mml:mrow<mml:msub<mml:miα</mml:mi <mml:mn1</mml:mn</mml:msub <mml:mo∈</mml:mo <mml:mrow<mml:mo[</mml:mo <mml:mn0</mml:mn <mml:mo,</mml:mo <mml:mn1</mml:mn <mml:mo)</mml:mo</mml:mrow </mml:mrow </mml:munder <mml:mrow<mml:mo|</mml:mo</mml:mrow <mml:munder<mml:mo∑</mml:mo <mml:mrow<mml:mn1</mml:mn <mml:mo≤</mml:mo <mml:min</mml:mi <mml:mo≤</mml:mo <mml:miP</mml:mi</mml:mrow </mml:munder <mml:mie</mml:mi <mml:mfenced<mml:msub<mml:miα</mml:mi <mml:mn1</mml:mn</mml:msub <mml:mfenced<mml:msup<mml:min</mml:mi <mml:mn3</mml:mn</mml:msup <mml:mo+</mml:mo <mml:min</mml:mi</mml:mfenced <mml:mo+</mml:mo <mml:msub<mml:miα</mml:mi <mml:mn2</mml:mn</mml:msub <mml:msup<mml:min</mml:mi <mml:mn3</mml:mn</mml:msup </mml:mfenced <mml:mrow<mml:mo|</mml:mo</mml:mrow <mml:mo≪</mml:mo <mml:msup<mml:miP</mml:mi <mml:mrow<mml:mn3</mml:mn <mml:mo/</mml:mo <mml:mn4</mml:mn <mml:mo+</mml:mo <mml:miε</mml:mi</mml:mrow </mml:msup <mml:mo,</mml:mo</mml:mrow </mml:mtd </mml:mtr </mml:mtable </mml:mrow </mml:math </DispFormula and that in a suitable sense this is best possible. This allows us to improve bounds for the fractal dimension of solutions to the Schrödinger and Airy equations.",
                    "score": 0.8623076677322388
                },
                {
                    "id": 12819677,
                    "contents": "Powerlaw: a Python package for analysis of heavy-tailed distributions.\nPower laws are theoretically interesting probability distributions that are also frequently used to describe empirical data. In recent years, effective statistical methods for fitting power laws have been developed, but appropriate use of these techniques requires significant programming and statistical insight. In order to greatly decrease the barriers to using good statistical methods for fitting power law distributions, we developed the powerlaw Python package. This software package provides easy commands for basic fitting and statistical analysis of distributions. Notably, it also seeks to support a variety of user needs by being exhaustive in the options available to the user. The source code is publicly available and easily extensible. ",
                    "score": 0.8620290756225586
                },
                {
                    "id": 19541436,
                    "contents": "Corrections to Be Made in the Proemium to This Volume.\n[This corrects the article on p. i in vol. 43.].",
                    "score": 0.8618010878562927
                },
                {
                    "id": 19919760,
                    "contents": "Convergence of Nonperturbative Approximations to the Renormalization Group.\nWe provide analytical arguments showing that the \"nonperturbative\" approximation scheme to Wilson's renormalization group known as the derivative expansion has a finite radius of convergence. We also provide guidelines for choosing the regulator function at the heart of the procedure and propose empirical rules for selecting an optimal one, without prior knowledge of the problem at stake. Using the Ising model in three dimensions as a testing ground and the derivative expansion at order six, we find fast convergence of critical exponents to their exact values, irrespective of the well-behaved regulator used, in full agreement with our general arguments. We hope these findings will put an end to disputes regarding this type of nonperturbative methods.",
                    "score": 0.8615368008613586
                },
                {
                    "id": 16191462,
                    "contents": "Retraction.\n[This retracts the article on p. 170 in vol. 15, PMID: 26130980.]. ",
                    "score": 0.8614460229873657
                },
                {
                    "id": 16946529,
                    "contents": "Under cover.\nI came to this book as a fan of its author. I had enjoyed reading Covey's previous book, Seven Habits of Highly. ",
                    "score": 0.8611547350883484
                },
                {
                    "id": 17462513,
                    "contents": "Beyond the LSD method for the partial sums of multiplicative functions.\nThe Landau-Selberg-Delange method gives an asymptotic formula for the partial sums of a multiplicative function <if</i whose prime values are <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miα</mml:mi</mml:math on average. In the literature, the average is usually taken to be <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miα</mml:mi</mml:math with a very strong error term, leading to an asymptotic formula for the partial sums with a very strong error term. In practice, the average at the prime values may only be known with a fairly weak error term, and so we explore here how good an estimate this will imply for the partial sums of <if</i, developing new techniques to do so.",
                    "score": 0.8610796332359314
                },
                {
                    "id": 3745189,
                    "contents": "[Automatic design of a linear or logarithmic scale. Application to plotting of conversion scales].\nThis flexible program permits automatic linear or logarithmic scaling between two limiting values set by the user. The software is in BASIC adapted for the Hewlett-Packard calculators HP-9845B and HP-85A.",
                    "score": 0.8609980940818787
                },
                {
                    "id": 20650853,
                    "contents": "The Rényi Entropies Operate in Positive Semifields.\nWe set out to demonstrate that the Rényi entropies are better thought of as operating in a type of non-linear semiring called a positive semifield. We show how the Rényi's postulates lead to Pap's g-calculus where the functions carrying out the domain transformation are Rényi's information function and its inverse. In its turn, Pap's g-calculus under Rényi's information function transforms the set of positive reals into a family of semirings where \"standard\" product has been transformed into sum and \"standard\" sum into a power-emphasized sum. Consequently, the transformed product has an inverse whence the structure is actually that of a positive semifield. Instances of this construction lead to idempotent analysis and tropical algebra as well as to less exotic structures. We conjecture that this is one of the reasons why tropical algebra procedures, like the Viterbi algorithm of dynamic programming, morphological processing, or neural networks are so successful in computational intelligence applications. But also, why there seem to exist so many computational intelligence procedures to deal with \"information\" at large.",
                    "score": 0.8609341979026794
                },
                {
                    "id": 17427422,
                    "contents": "Some notes on Sonine-Gegenbauer integrals.\nWe provide an explicit formula for a Sonine-Gegenbauer integral, which seems to be unknown in the literature so far. For another type of these integrals, we show a dependence relation over the rational functions, including the explicit calculation of the coefficient functions.",
                    "score": 0.8608946204185486
                },
                {
                    "id": 19986742,
                    "contents": "The discovery of the depletion force.\nThis Editorial reports how the depletion force theory was originally developed by Sho Asakura and Fumio Oosawa and how their one-page paper was \"rediscovered\" about 20 years after the paper was published. The first part of this Editorial is mostly based on the lecture by Oosawa and his autobiographies, and the second part is written by one of two scientists who found the paper. The aim of this Editorial is to record the background of the discovery of the depletion force. We believe that this Editorial presents an interesting story showing how science develops. The story reminds us of the importance of basic education and continuous interests in unknown phenomena and interactions between people of different disciplines, although they are sometimes considered as separate elements of research.",
                    "score": 0.8608080148696899
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_19",
        "question": "Evaluate the series\r\n$$\r\nS=\\sum_{n=1}^{\\infty} \\frac{(-1)^{n+1}}{2^n}\r\n$$",
        "golden_answers": [
            " 1/3"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 21453649,
                    "contents": "Improving series convergence: the simple pendulum and beyond.\nA simple and easy to implement method for improving the convergence of a power series is presented. We observe that the most obvious or analytically convenient point about which to make a series expansion is not always the most computationally efficient. Series convergence can be dramatically improved by choosing the center of the series expansion to be at or near the average value at which the series is to be evaluated. For illustration, we apply this method to the well-known simple pendulum and to the Mexican hat type of potential. Large performance gains are demonstrated. While the method is not always the most computationally efficient on its own, it is effective, straightforward, quite general, and can be used in combination with other methods.",
                    "score": 0.8792939782142639
                },
                {
                    "id": 22558670,
                    "contents": "Division of Power Series: Recursive and Non-Recursive Formulas.\nIn this paper we propose a new formula to divide power series. We develop two versions of the formula: a recursive and a non-recursive one, the latter aiming to reduce the computational cost for high-order series truncation. To use the non-recursive formula we define certain fundamental sets of summation indexes. Additional non-trivial information about effects of repetition of the indexes are needed and contabilized within a coefficient 𝛾 in the formula, we explain how to calculate the coefficient 𝛾 for each summation index by constructing appropriate mappings between the fundamental sets of indexes previous defined.",
                    "score": 0.8731149435043335
                },
                {
                    "id": 20650615,
                    "contents": "Approximate Entropy and Sample Entropy: A Comprehensive Tutorial.\nApproximate Entropy and Sample Entropy are two algorithms for determining the regularity of series of data based on the existence of patterns. Despite their similarities, the theoretical ideas behind those techniques are different but usually ignored. This paper aims to be a complete guideline of the theory and application of the algorithms, intended to explain their characteristics in detail to researchers from different fields. While initially developed for physiological applications, both algorithms have been used in other fields such as medicine, telecommunications, economics or Earth sciences. In this paper, we explain the theoretical aspects involving Information Theory and Chaos Theory, provide simple source codes for their computation, and illustrate the techniques with a step by step example of how to use the algorithms properly. This paper is not intended to be an exhaustive review of all previous applications of the algorithms but rather a comprehensive tutorial where no previous knowledge is required to understand the methodology.",
                    "score": 0.8730841279029846
                },
                {
                    "id": 21421458,
                    "contents": "On powers that are sums of consecutive like powers.\nLet <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:mik</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn</mml:mrow </mml:math be even, and let <ir</i be a non-zero integer. We show that for almost all <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:mid</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn</mml:mrow </mml:math (in the sense of natural density), the equation <DispFormula <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow<mml:msup<mml:mix</mml:mi <mml:mik</mml:mi</mml:msup <mml:mo+</mml:mo <mml:msup<mml:mrow<mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo+</mml:mo <mml:mir</mml:mi <mml:mo)</mml:mo</mml:mrow <mml:mik</mml:mi</mml:msup <mml:mo+</mml:mo <mml:mo⋯</mml:mo <mml:mo+</mml:mo <mml:msup<mml:mrow<mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo+</mml:mo <mml:mrow<mml:mo(</mml:mo <mml:mid</mml:mi <mml:mo-</mml:mo <mml:mn1</mml:mn <mml:mo)</mml:mo</mml:mrow <mml:mir</mml:mi <mml:mo)</mml:mo</mml:mrow <mml:mik</mml:mi</mml:msup <mml:mo=</mml:mo <mml:msup<mml:miy</mml:mi <mml:min</mml:mi</mml:msup <mml:mo,</mml:mo <mml:mspace/ <mml:mix</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:miy</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:min</mml:mi <mml:mo∈</mml:mo <mml:miZ</mml:mi <mml:mo,</mml:mo <mml:mspace/ <mml:min</mml:mi <mml:mo≥</mml:mo <mml:mn2</mml:mn <mml:mo,</mml:mo</mml:mrow </mml:math </DispFormula has no solutions.",
                    "score": 0.8729037046432495
                },
                {
                    "id": 19031252,
                    "contents": "A series of sequences convergent to Euler's constant.\nIn this paper, using continued fraction, we provide a new quicker sequence convergent to Euler's constant. We demonstrate the superiority of our new convergent sequences over DeTemple's sequence, Mortici's sequences, Vernescu's sequence, and Lu's sequence.",
                    "score": 0.8706409335136414
                },
                {
                    "id": 14094978,
                    "contents": "Estimation of the entropy based on its polynomial representation.\nEstimating entropy from empirical samples of finite size is of central importance for information theory as well as the analysis of complex statistical systems. Yet, this delicate task is marred by intrinsic statistical bias. Here we decompose the entropy function into a polynomial approximation function and a remainder function. The approximation function is based on a Taylor expansion of the logarithm. Given n observations, we give an unbiased, linear estimate of the first n power series terms based on counting sets of k coincidences. For the remainder function we use nonlinear Bayesian estimation with a nearly flat prior distribution on the entropy that was developed by Nemenman, Shafee, and Bialek. Our simulations show that the combined entropy estimator has reduced bias in comparison to other available estimators.",
                    "score": 0.8657979965209961
                },
                {
                    "id": 17462513,
                    "contents": "Beyond the LSD method for the partial sums of multiplicative functions.\nThe Landau-Selberg-Delange method gives an asymptotic formula for the partial sums of a multiplicative function <if</i whose prime values are <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miα</mml:mi</mml:math on average. In the literature, the average is usually taken to be <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miα</mml:mi</mml:math with a very strong error term, leading to an asymptotic formula for the partial sums with a very strong error term. In practice, the average at the prime values may only be known with a fairly weak error term, and so we explore here how good an estimate this will imply for the partial sums of <if</i, developing new techniques to do so.",
                    "score": 0.8648249506950378
                },
                {
                    "id": 14718520,
                    "contents": "Universal series induced by approximate identities and some relevant applications.\nWe prove the existence of series [Formula: see text], whose coefficients [Formula: see text] are in [Formula: see text] and whose terms [Formula: see text] are translates by rational vectors in [Formula: see text] of a family of approximations to the identity, having the property that the partial sums are dense in various spaces of functions such as Wiener's algebra [Formula: see text], [Formula: see text], [Formula: see text], [Formula: see text], for every [Formula: see text], and the space of measurable functions. Applying this theory to particular situations, we establish approximations by such series to solutions of the heat and Laplace equations as well as to probability density functions.",
                    "score": 0.8604140281677246
                },
                {
                    "id": 10299610,
                    "contents": "Algorithm for computation of Zernike polynomials expansion coefficients.\nA numerically efficient algorithm for expanding a function in a series of Zernike polynomials is presented. The algorithm evaluates the expansion coefficients through the standard 2-D integration formula derived from the Zernike polynomials' orthogonal properties. Quadratic approximations are used along with the function to be expanded to eliminate the computational problems associated with integrating the oscillatory behavior of the Zernike polynomials. This yields a procedure that is both fast and numerically accurate. Comparisons are made between the proposed scheme and a procedure using a nested 2-D Simpson's integration rule. The results show that typically at least a fourfold improvement in computational speed can be expected in practical use.",
                    "score": 0.8602203130722046
                },
                {
                    "id": 12379440,
                    "contents": "On the higher power sums of reciprocal higher-order sequences.\nLet {u(n)} be a higher-order linear recursive sequence. In this paper, we use the properties of error estimation and the analytic method to study the reciprocal sums of higher power of higher-order sequences. Then we establish several new and interesting identities relating to the infinite and finite sums.",
                    "score": 0.8538684248924255
                },
                {
                    "id": 7634727,
                    "contents": "A unifying view of wiener and volterra theory and polynomial kernel regression.\nVolterra and Wiener series are perhaps the best-understood nonlinear system representations in signal processing. Although both approaches have enjoyed a certain popularity in the past, their application has been limited to rather low-dimensional and weakly nonlinear systems due to the exponential growth of the number of terms that have to be estimated. We show that Volterra and Wiener series can be represented implicitly as elements of a reproducing kernel Hilbert space by using polynomial kernels. The estimation complexity of the implicit representation is linear in the input dimensionality and independent of the degree of nonlinearity. Experiments show performance advantages in terms of convergence, interpretability, and system sizes that can be handled.",
                    "score": 0.853289783000946
                },
                {
                    "id": 9691374,
                    "contents": "Fast algorithms for classical physics.\nSome of the recently developed fast summation methods that have arisen in scientific computing are described. These methods require an amount of work proportional to N or N log N to evaluate all pairwise interactions in an ensemble of N particles. Traditional methods, by contrast, require an amount of work proportional to N(2). As a result, largescale simulations can be carried out using only modest computer resources. In combination with supercomputers, it is possible to address questions that were previously out of reach. Problems from diffusion, gravitation, and wave propagation are considered.",
                    "score": 0.8531262874603271
                },
                {
                    "id": 17269017,
                    "contents": "Correction to: Explicit upper bound for the average number of divisors of irreducible quadratic polynomials.\n[This corrects the article DOI: 10.1007/s00605-017-1061-y.].",
                    "score": 0.8524232506752014
                },
                {
                    "id": 7952328,
                    "contents": "Discrete sums for the rapid determination of exponential decay constants.\nSeveral computational methods are presented for the rapid extraction of decay time constants from discrete exponential data. Two methods are found to be comparably fast and highly accurate. They are corrected successive integration and a method involving the Fourier transform (FT) of the data and the application of an expression that does not assume continuous data. FT methods in the literature are found to introduce significant systematic error owing to the assumption that data are continuous. Corrected successive integration methods in the literature are correct, but we offer a more direct way of applying them which we call linear regression of the sum. We recommend the use of the latter over FT-based methods, as the FT methods are more affected by noise in the original data.",
                    "score": 0.8521959781646729
                },
                {
                    "id": 8058211,
                    "contents": "A computationally simple and robust method to detect determinism in a time series.\nWe present a new, simple, and fast computational technique, termed the incremental slope (IS), that can accurately distinguish between deterministic from stochastic systems even when the variance of noise is as large or greater than the signal, and remains robust for time-varying signals. The IS method is more accurate than the widely utilized Poincare plot analysis especially when the data are severely contaminated by noise. The efficacy of the IS is demonstrated with several simulated deterministic and stochastic signals.",
                    "score": 0.8518618941307068
                },
                {
                    "id": 9617151,
                    "contents": "A Simple Proof of Siegel's Theorem.\nA brief and simple proof of Siegel's celebrated theorem that h(d) &gt;&gt; d(1/2-[unk]), as d --&gt; infinity, is given. Here h(d) denotes the class number of the quadratic field Q([unk]-d). Simple proofs that do not make use of algebraic number theory have been previously given by Estermann and Chowla.",
                    "score": 0.8503917455673218
                },
                {
                    "id": 20573763,
                    "contents": "The exponentiated generalized power series: Family of distributions: theory, properties and applications.\nWe propose a new generalized family of distributions called the exponentiated generalized power series (EGPS) family of distributions and study its sub-model, the exponentiated generalized logarithmic (EGL) class of distributions, in detail. The structural properties of the new model (EGPS) and its sub-model (EGL) distribution including moments, order statistics, Rényi entropy, and maximum likelihood estimates are derived. We used the method of maximum likelihood to estimate the parameters of this new family of distributions. Simulation study was carried out to examine the bias and the mean square error of the maximum likelihood estimators for each of the model's parameters. Finally, we showed real life data examples to illustrate the models' applicability, flexibility and usefulness.",
                    "score": 0.850333571434021
                },
                {
                    "id": 8254968,
                    "contents": "Detrended cross-correlation analysis: a new method for analyzing two nonstationary time series.\nHere we propose a new method, detrended cross-correlation analysis, which is a generalization of detrended fluctuation analysis and is based on detrended covariance. This method is designed to investigate power-law cross correlations between different simultaneously recorded time series in the presence of nonstationarity. We illustrate the method by selected examples from physics, physiology, and finance.",
                    "score": 0.8501917719841003
                },
                {
                    "id": 23389571,
                    "contents": "A fast algorithm for computing the Boys function.\nWe present a new fast algorithm for computing the Boys function using a nonlinear approximation of the integrand via exponentials. The resulting algorithms evaluate the Boys function with real and complex valued arguments and are competitive with previously developed algorithms for the same purpose.",
                    "score": 0.8497642278671265
                },
                {
                    "id": 9616968,
                    "contents": "Airey's Converging Factor.\nAsmptotic series for the calculation of functions, for values of the argument numerically &gt;1, start off with terms whose numerical values decrease but, at a certain stage, the terms begin to increase in numerical value and must be ignored. At this stage, there may be two adjacent terms of equal numerical value; when the least term of the asymptotic series is spoken of, it is in reference to the first of these two terms. The sum of the initial terms of the asymptotic series up to, and including, the least term often furnishes a fair approximation to the desired value of the function being evaluated. It was early observed by computers that if the terms of the asymptotic series alternate in sign, this approximation was often improved by replacing the least term by its half. The factor by which the least term of the asymptotic series must be multiplied so that the true value of the function being evaluated is obtained by addition of this modified least term to the remaining initial terms of the asymptotic series is known as the converging factor for the asymptotic series. The converging factor for the asymptotic series involved in the calculation of the exponential integral, for large negative values of the argument, was given as a power series in the reciprocal of the argument by Airey; the first term of this series is (1/2). A method for the determination of the coefficients of this series is given.",
                    "score": 0.8493599891662598
                },
                {
                    "id": 15539424,
                    "contents": "On the additive properties of the fat-shattering dimension.\nThe properties of the VC-dimension under various compositions are well-understood, but this is much less the case for classes of continuous functions. In this brief, we show that a commonly used scale-sensitive dimension, Vγ, is much less well-behaved under Minkowski summation than its VC cousin, while the fat-shattering dimension retains some compositional similarity to the VC-dimension. As an application, we analyze the fat-shattering dimension of trigonometric functions and series.",
                    "score": 0.8488289713859558
                },
                {
                    "id": 9618297,
                    "contents": "Rational approximations to linear forms of exponentials and binomials.\nMahler proved the following quantitative result supplementing the Lindemann-Weierstrass theorem: Sigma(i=0) (n)C(i)e(ri) &gt; H(-n-epsilon) for any distinct rational numbers r(0),r(1),..., r(n) and rational integers C(0),C(1),...,C(n) with H = max(0&lt;/=i&lt;/=n) C(i). We improve Mahler's estimate by replacing exponentials e(ri) by linearly independent linear forms L(i) = Sigma L(ij)e(sij) with rational L(ij),s(ij)i = 0,1,...,n. Similar results are obtained for binomials (a/b)(ri) or Sigma L(ij)(a/b)(sij) with integers a,b and logb/loga &gt; 1 - epsilon. The simplest examples of new numbers with the irrationality exponent \"2 + epsilon\" are sinh 1 or sin 1.",
                    "score": 0.8483335971832275
                },
                {
                    "id": 9652484,
                    "contents": "Systematic series expansions for processes on networks.\nWe use series expansions to study dynamics of equilibrium and nonequilibrium systems on networks. This analytical method enables us to include detailed nonuniversal effects of the network structure. We show that even low order calculations produce results which compare accurately to numerical simulation, while the results can be systematically improved. We show that certain commonly accepted analytical results for the critical point on networks with a broad degree distribution need to be modified in certain cases due to disassortativity; the present method is able to take into account the assortativity at sufficiently high order, while previous results correspond to leading and second order approximations in this method. Finally, we apply this method to real-world data.",
                    "score": 0.8473930358886719
                },
                {
                    "id": 9617330,
                    "contents": "Maximal functions: Poisson integrals on symmetric spaces.\nLet u be a harmonic function on a symmetric space which is the Poisson integral of a function f in L(p), 1 &lt;/= p &lt;/= infinity. Then u converges restrictedly and admissibly to f almost everywhere. This result is proved by obtaining an appropriate maximal theorem which takes into account the structure of the Poisson kernel.",
                    "score": 0.8469884395599365
                },
                {
                    "id": 12258677,
                    "contents": "A new sum analogous to Gauss sums and its fourth power mean.\nThe main purpose of this paper is to use the analytic methods and the properties of Gauss sums to study the computational problem of one kind of new sum analogous to Gauss sums and give an interesting fourth power mean and a sharp upper bound estimate for it. ",
                    "score": 0.8468175530433655
                },
                {
                    "id": 6590341,
                    "contents": "Approximate entropy (ApEn) as a complexity measure.\nApproximate entropy (ApEn) is a recently developed statistic quantifying regularity and complexity, which appears to have potential application to a wide variety of relatively short (greater than 100 points) and noisy time-series data. The development of ApEn was motivated by data length constraints commonly encountered, e.g., in heart rate, EEG, and endocrine hormone secretion data sets. We describe ApEn implementation and interpretation, indicating its utility to distinguish correlated stochastic processes, and composite deterministic/ stochastic models. We discuss the key technical idea that motivates ApEn, that one need not fully reconstruct an attractor to discriminate in a statistically valid manner-marginal probability distributions often suffice for this purpose. Finally, we discuss why algorithms to compute, e.g., correlation dimension and the Kolmogorov-Sinai (KS) entropy, often work well for true dynamical systems, yet sometimes operationally confound for general models, with the aid of visual representations of reconstructed dynamics for two contrasting processes. (c) 1995 American Institute of Physics.",
                    "score": 0.8467404842376709
                },
                {
                    "id": 6146107,
                    "contents": "Predictability, complexity, and learning.\nWe define predictive information I(pred)(T) as the mutual information between the past and the future of a time series. Three qualitatively different behaviors are found in the limit of large observation times T:I(pred)(T) can remain finite, grow logarithmically, or grow as a fractional power law. If the time series allows us to learn a model with a finite number of parameters, then I(pred)(T) grows logarithmically with a coefficient that counts the dimensionality of the model space. In contrast, power-law growth is associated, for example, with the learning of infinite parameter (or nonparametric) models such as continuous functions with smoothness constraints. There are connections between the predictive information and measures of complexity that have been defined both in learning theory and the analysis of physical systems through statistical mechanics and dynamical systems theory. Furthermore, in the same way that entropy provides the unique measure of available information consistent with some simple and plausible conditions, we argue that the divergent part of I(pred)(T) provides the unique measure for the complexity of dynamics underlying a time series. Finally, we discuss how these ideas may be useful in problems in physics, statistics, and biology.",
                    "score": 0.8462357521057129
                },
                {
                    "id": 23167501,
                    "contents": "Simple renormalization schemes for multiple scattering series expansions.\nA number of renormalization schemes for improving the convergence of multiple scattering series expansions are investigated. Numerical tests on a small Cu(111) cluster demonstrate their effectiveness, for example increasing the rate of convergence by up to a factor 2 or by transforming a divergent series into a convergent one. These techniques can greatly facilitate multiple scattering calculations, especially for spectroscopies such as photoelectron diffraction, Auger electron diffraction, low energy electron diffraction <ietc.</i, where an electron propagates with a kinetic energy of hundreds of eV in a cluster of hundreds of atoms.",
                    "score": 0.8460327386856079
                },
                {
                    "id": 9962175,
                    "contents": "Computing the multifractal spectrum from time series: an algorithmic approach.\nWe show that the existing methods for computing the f(alpha) spectrum from a time series can be improved by using a new algorithmic scheme. The scheme relies on the basic idea that the smooth convex profile of a typical f(alpha) spectrum can be fitted with an analytic function involving a set of four independent parameters. While the standard existing schemes [P. Grassberger et al., J. Stat. Phys. 51, 135 (1988); A. Chhabra and R. V. Jensen, Phys. Rev. Lett. 62, 1327 (1989)] generally compute only an incomplete f(alpha) spectrum (usually the top portion), we show that this can be overcome by an algorithmic approach, which is automated to compute the D(q) and f(alpha) spectra from a time series for any embedding dimension. The scheme is first tested with the logistic attractor with known f(alpha) curve and subsequently applied to higher-dimensional cases. We also show that the scheme can be effectively adapted for analyzing practical time series involving noise, with examples from two widely different real world systems. Moreover, some preliminary results indicating that the set of four independent parameters may be used as diagnostic measures are also included.",
                    "score": 0.8459209203720093
                },
                {
                    "id": 15997402,
                    "contents": "The rapidly convergent solutions of strongly nonlinear oscillators.\nBased on the harmonic balance method (HBM), an approximate solution is determined from the integral expression (i.e., first order differential equation) of some strongly nonlinear oscillators. Usually such an approximate solution is obtained from second order differential equation. The advantage of the new approach is that the solution converges significantly faster than that obtained by the usual HBM as well as other analytical methods. By choosing some well known nonlinear oscillators, it has been verified that an n-th (n ≥ 2) approximate solution (concern of this article) is very close to (2n - 1)-th approximations obtained by usual HBM. ",
                    "score": 0.8455904722213745
                },
                {
                    "id": 15791453,
                    "contents": "Nonlinear time-series analysis revisited.\nIn 1980 and 1981, two pioneering papers laid the foundation for what became known as nonlinear time-series analysis: the analysis of observed data-typically univariate-via dynamical systems theory. Based on the concept of state-space reconstruction, this set of methods allows us to compute characteristic quantities such as Lyapunov exponents and fractal dimensions, to predict the future course of the time series, and even to reconstruct the equations of motion in some cases. In practice, however, there are a number of issues that restrict the power of this approach: whether the signal accurately and thoroughly samples the dynamics, for instance, and whether it contains noise. Moreover, the numerical algorithms that we use to instantiate these ideas are not perfect; they involve approximations, scale parameters, and finite-precision arithmetic, among other things. Even so, nonlinear time-series analysis has been used to great advantage on thousands of real and synthetic data sets from a wide variety of systems ranging from roulette wheels to lasers to the human heart. Even in cases where the data do not meet the mathematical or algorithmic requirements to assure full topological conjugacy, the results of nonlinear time-series analysis can be helpful in understanding, characterizing, and predicting dynamical systems. ",
                    "score": 0.8455566167831421
                },
                {
                    "id": 22388509,
                    "contents": "Extended Wang sum and associated products.\nThe Wang sum involving the exponential sums of Lerch's Zeta functions is extended to the finite sum of the Huwitz-Lerch Zeta function to derive sums and products involving cosine and tangent trigonometric functions. The general theorem used to derive these sums and products is in the form of the finite sum over positive integers of the Hurwitz-Lerch Zeta function where the associated parameters are general complex numbers. New Hurwitz-Lerch Zeta function recurrence identities with consecutive neighbours are derived. Some finite sum and product formulae examples involving cosine, tangent and the product of cosine and tangent functions are also derived and evaluated.",
                    "score": 0.8453848958015442
                },
                {
                    "id": 19088042,
                    "contents": "Some new results on convex sequences.\nIn the present paper, we obtained a main theorem related to factored infinite series. Some new results are also deduced.",
                    "score": 0.8452999591827393
                },
                {
                    "id": 2667573,
                    "contents": "Further remarks on convergence of decomposition method.\nThe decomposition method solves a wide class of nonlinear functional equations. This method uses a series solution with rapid convergence. This paper is intended as a useful review and clarification of related issues.",
                    "score": 0.8452672958374023
                },
                {
                    "id": 19477880,
                    "contents": "Correction: The complex dynamics of products and its asymptotic properties.\n[This corrects the article DOI: 10.1371/journal.pone.0177360.].",
                    "score": 0.8440278768539429
                },
                {
                    "id": 21716799,
                    "contents": "Computing sums in terms of beta, polygamma, and Gauss hypergeometric functions.\nIn the paper, by virtue of the binomial inversion formula, a general formula of higher order derivatives for a ratio of two differentiable function, and other techniques, the authors compute several sums in terms of the beta function and its partial derivatives, polygamma functions, the Gauss hypergeometric function, and a determinant. These results generalize known ones in combinatorics.",
                    "score": 0.8440091609954834
                },
                {
                    "id": 20867802,
                    "contents": "Practical rules for summing the series of the Tweedie probability density function with high-precision arithmetic.\nFor some ranges of its parameters and arguments, the series for Tweedie probability density functions are sometimes exceedingly difficult to sum numerically. Existing numerical implementations utilizing inversion techniques and properties of stable distributions can cope with these problems, but no single one is successful in all cases. In this work we investigate heuristically the nature of the problem, and show that it is not related to the order of summation of the terms. Using a variable involved in the analytical proof of convergence of the series, the critical parameter for numerical non-convergence (\"alpha\") is identified, and an heuristic criterion is developed to avoid numerical non-convergence for a reasonably large sub-interval of the latter. With these practical rules, simple summation algorithms provide sufficiently robust results for the calculation of the density function and its definite integrals. These implementations need to utilize high-precision arithmetic, and are programmed in the Python programming language. A thorough comparison with existing R functions allows the identification of cases when the latter fail, and provide further guidance to their use.",
                    "score": 0.8438857197761536
                },
                {
                    "id": 18974547,
                    "contents": "Correction: Fitting power-laws in empirical data with estimators that work for all exponents.\n[This corrects the article DOI: 10.1371/journal.pone.0170920.].",
                    "score": 0.8437659740447998
                },
                {
                    "id": 8378619,
                    "contents": "Fundamentals of superresolution.\nThe fundamental principles behind superresolution are discussed, and different schemes classified. Different definitions for localization of a wave are discussed.",
                    "score": 0.8433759212493896
                },
                {
                    "id": 3888305,
                    "contents": "Metrics from nonlinear dynamics adapted for characterizing the behavior of nonequilibrium enzymatic rate functions.\nSeveral metrics from nonlinear dynamics and statistical mechanics have been characterized on computer-generated number series with various signal-to-noise ratios, demonstrating their individual reliability as a function of sample size and their relationships to each other. The root mean square (RMS) evaluates amplitude, and the power spectral density (PSD) provides a visual display of the frequency spectrum; both measures have very high reliability even for an N as low as 50. The Fractal Dimension (D) is shown to converge rapidly and also to be reliable when N is as low as 50. These three measures (RMS, PSD, and D) have been applied to the complex kinetics of tyrosine hydroxylase time courses (50-point curves) at various BH4 concentrations (near physiological, but far from equilibrium levels). Recently developed measures of spectral entropy and the Liapunov Exponent, -lambda are also characterized.",
                    "score": 0.8431746959686279
                },
                {
                    "id": 6590342,
                    "contents": "Tests for nonlinearity in short stationary time series.\nTo compare direct tests for detecting determinism in chaotic time series, data from Henon, Lorenz, and Mackey-Glass equations were contaminated with various levels of additive colored noise. These data were analyzed with a variety of recently developed tests for determinism, and the results compared. (c) 1995 American Institute of Physics.",
                    "score": 0.84302818775177
                },
                {
                    "id": 14442606,
                    "contents": "Entropy rate estimates from mutual information.\nWe show how to estimate the Kolmogorov-Sinai entropy rate for chaotic systems using the mutual information function, easily obtainable from experimental time series. We state the conditions under which the relationship is exact, and explore the usefulness of the approach for both maps and flows. We also explore refinements of the method, and study its convergence properties as a function of time series length.",
                    "score": 0.8430044651031494
                },
                {
                    "id": 18347567,
                    "contents": "Monotone and fast computation of Euler's constant.\nWe construct sequences of finite sums [Formula: see text] and [Formula: see text] converging increasingly and decreasingly, respectively, to the Euler-Mascheroni constant <iγ</i at the geometric rate 1/2. Such sequences are easy to compute and satisfy complete monotonicity-type properties. As a consequence, we obtain an infinite product representation for [Formula: see text] converging in a monotone and fast way at the same time. We use a probabilistic approach based on a differentiation formula for the gamma process.",
                    "score": 0.8424316048622131
                },
                {
                    "id": 9097437,
                    "contents": "Systematic perturbation calculation of integrals with applications to physics.\nIn this paper we generalize and improve a method for calculating the period of a classical oscillator and other integrals of physical interest, which was recently developed by some of the authors. We derive analytical expressions that prove to be more accurate than those commonly found in the literature, and test the convergence of the series produced by the approach.",
                    "score": 0.8421297669410706
                },
                {
                    "id": 6590021,
                    "contents": "Practical implementation of nonlinear time series methods: The TISEAN package.\nWe describe the implementation of methods of nonlinear time series analysis which are based on the paradigm of deterministic chaos. A variety of algorithms for data representation, prediction, noise reduction, dimension and Lyapunov estimation, and nonlinearity testing are discussed with particular emphasis on issues of implementation and choice of parameters. Computer programs that implement the resulting strategies are publicly available as the TISEAN software package. The use of each algorithm will be illustrated with a typical application. As to the theoretical background, we will essentially give pointers to the literature. (c) 1999 American Institute of Physics.",
                    "score": 0.8417816162109375
                },
                {
                    "id": 23351778,
                    "contents": "A Class of Double Integrals Involving Gaussian and Trigonometric Factors.\nThe five parameter double integral <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow <mml:mrow<mml:msubsup<mml:mo∫</mml:mo <mml:mn0</mml:mn <mml:mi∞</mml:mi</mml:msubsup <mml:mid</mml:mi</mml:mrow <mml:miy</mml:mi <mml:mtextexp</mml:mtext <mml:mrow<mml:mo(</mml:mo <mml:mrow<mml:mo-</mml:mo <mml:msup<mml:mip</mml:mi <mml:mn2</mml:mn</mml:msup <mml:msup<mml:miy</mml:mi <mml:mn2</mml:mn</mml:msup </mml:mrow <mml:mo)</mml:mo</mml:mrow <mml:mtextsin</mml:mtext <mml:mo(</mml:mo <mml:miβ</mml:mi <mml:miy</mml:mi <mml:mo+</mml:mo <mml:miθ</mml:mi <mml:mo)</mml:mo</mml:mrow </mml:math times <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow <mml:mrow<mml:msubsup<mml:mo∫</mml:mo <mml:mn0</mml:mn <mml:miy</mml:mi</mml:msubsup <mml:mid</mml:mi</mml:mrow <mml:mix</mml:mi <mml:mtextexp</mml:mtext <mml:mrow<mml:mo(</mml:mo <mml:mrow<mml:mo-</mml:mo <mml:msup<mml:mix</mml:mi <mml:mn2</mml:mn</mml:msup </mml:mrow <mml:mo)</mml:mo</mml:mrow <mml:mtextcos</mml:mtext <mml:mo(</mml:mo <mml:miϵ</mml:mi <mml:miβ</mml:mi <mml:mix</mml:mi <mml:mo+</mml:mo <mml:miϕ</mml:mi <mml:mo)</mml:mo</mml:mrow </mml:math is evaluated in terms of Fourier transforms of exp(- <ix</i <sup2</sup)erfc(<iαx</i). Some new expressions for these transforms are obtained.",
                    "score": 0.8414695262908936
                },
                {
                    "id": 17926147,
                    "contents": "A new type of Taylor series expansion.\nWe present a variant of the classical integration by parts to introduce a new type of Taylor series expansion and to present some closed forms for integrals involving Jacobi and Laguerre polynomials, which cannot be directly obtained by usual symbolic computation programs, i.e., only some very specific values can be computed by the mentioned programs. An error analysis is given in the sequel for the introduced expansion.",
                    "score": 0.8414668440818787
                },
                {
                    "id": 8682396,
                    "contents": "Computing second derivatives in feed-forward networks: a review.\nThe calculation of second derivatives is required by recent training and analysis techniques of connectionist networks, such as the elimination of superfluous weights, and the estimation of confidence intervals both for weights and network outputs. We review and develop exact and approximate algorithms for calculating second derivatives. For networks with |w| weights, simply writing the full matrix of second derivatives requires O(|w|(2)) operations. For networks of radial basis units or sigmoid units, exact calculation of the necessary intermediate terms requires of the order of 2h+2 backward/forward-propagation passes where h is the number of hidden units in the network. We also review and compare three approximations (ignoring some components of the second derivative, numerical differentiation, and scoring). The algorithms apply to arbitrary activation functions, networks, and error functions.",
                    "score": 0.8412207365036011
                },
                {
                    "id": 4319805,
                    "contents": "TSAN: a package for time series analysis.\nMany biomedical data are in the form of time series. Analyses of these data include: (1) search for any biorhythm; (2) test of homogeneity of several time series; (3) assessment of stationarity; (4) test of normality of the time series histogram; (5) evaluation of dependence between data points. In this paper we present a subroutine package called TSAN. It is developed to accomplish these tasks. Computational methods, as well as flowcharts, for these subroutines are described. Two sample runs are demonstrated.",
                    "score": 0.8409010171890259
                },
                {
                    "id": 5937873,
                    "contents": "Fast algorithm for generating long self-affine profiles.\nWe introduce a fast algorithm for generating long self-affine profiles. The algorithm, which is based on the fast wavelet transform, is faster than the conventional Fourier filtering algorithm. In addition to increased performance for large systems, the algorithm, named the wavelet filtering algorithm, a priori gives rise to profiles for which the long-range correlation extends throughout the entire system independently of the length scale.",
                    "score": 0.8403646945953369
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_20",
        "question": "Calculate the percentage difference between $\\ln (1+x)$ and $x$ for $x=0.0050$",
        "golden_answers": [
            " 0.249"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 11107397,
                    "contents": "The crux of the method: assumptions in ordinary least squares and logistic regression.\nLogistic regression has increasingly become the tool of choice when analyzing data with a binary dependent variable. While resources relating to the technique are widely available, clear discussions of why logistic regression should be used in place of ordinary least squares regression are difficult to find. The current paper compares and contrasts the assumptions of ordinary least squares with those of logistic regression and explains why logistic regression's looser assumptions make it adept at handling violations of the more important assumptions in ordinary least squares.",
                    "score": 0.9065066576004028
                },
                {
                    "id": 7958854,
                    "contents": "Multiple linear regression.\nThis chapter describes multiple linear regression, a statistical approach used to describe the simultaneous associations of several variables with one continuous outcome. Important steps in using this approach include estimation and inference, variable selection in model building, and assessing model fit. The special cases of regression with interactions among the variables, polynomial regression, regressions with categorical (grouping) variables, and separate slopes models are also covered. Examples in microbiology are used throughout.",
                    "score": 0.9044228196144104
                },
                {
                    "id": 15302521,
                    "contents": "A Version of Quadratic Regression with Interpretable Parameters.\nThe quadratic regression model is popular and effective in describing a wide variety of data, but it is based on a function whose parameters are not easy to interpret. We suggest an alternative form of the quadratic model that has the same expectation function, but also has the useful feature that its parameters are interpretable. Examples are provided of a simple regression problem and also of a nonlinear mixed-effects model. The models can be estimated with available software. ",
                    "score": 0.899418830871582
                },
                {
                    "id": 18799840,
                    "contents": "WASP (Write a Scientific Paper): Multivariate analysis.\nLinear regression is the equation which provides of straight line that best describes the association between two continuous variables, x and y. However, it is often the case that the dependent variable y is influenced by more than one variable and not just a single x variable. Multivariate analysis is a statistical modeling technique wherein multiple x variables are analysed simultaneously for their effect on y, resulting in an additive model (via an equation) that explains the observation/s and corrects for confounding association/s using one dependent and several independent variables, assigning a gradient to each of these independent variables, and with all product terms of gradient and magnitude of the independent variables adding up to estimate 'y'. This paper outlines these various techniques and applications.",
                    "score": 0.8987371921539307
                },
                {
                    "id": 9617527,
                    "contents": "Strong consistency of least squares estimates in multiple regression.\nThe strong consistency of least squares estimates in multiple regression models with independent errors is obtained under minimal assumptions on the design and weak moment conditions on the errors.",
                    "score": 0.896635115146637
                },
                {
                    "id": 7404951,
                    "contents": "Method of fitting logistic curve.\n\"The paper presents a simple method of fitting the Logistic Curve by estimating the parameters in a different way than the methods known in the literature.\"",
                    "score": 0.8954812288284302
                },
                {
                    "id": 21962719,
                    "contents": "Transformation based on likelihood ratio.\nWe respond here on a recent letter in this journal, on the transformation based on likelihood ratio.",
                    "score": 0.8954635262489319
                },
                {
                    "id": 8448773,
                    "contents": "Beyond the P IV: gain confidence in confidence intervals.\nThis is the last in a 4-part series discussing the proper use, interpretation, and limitations of P values.",
                    "score": 0.8933464884757996
                },
                {
                    "id": 23290163,
                    "contents": "A Note on the Behavior of Least Squares Regression Estimates When Both Variables Are Subject to Error.\nFor the errors in variables model X = U + V, Y = βf(U) + W, sufficient conditions are given for the L.S. limiting estimate of β to satisfy <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:miP</mml:mi <mml:mo(</mml:mo <mml:mover<mml:miβ</mml:mi <mml:mo^</mml:mo</mml:mover <mml:mo/</mml:mo <mml:miβ</mml:mi <mml:mo&lt;</mml:mo <mml:mn1</mml:mn <mml:mo)</mml:mo <mml:mo=</mml:mo <mml:mn1</mml:mn</mml:mrow </mml:math or <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:miP</mml:mi <mml:mo(</mml:mo <mml:mover<mml:miβ</mml:mi <mml:mo^</mml:mo</mml:mover <mml:mo/</mml:mo <mml:miβ</mml:mi <mml:mo&gt;</mml:mo <mml:mn1</mml:mn <mml:mo)</mml:mo <mml:mo=</mml:mo <mml:mn1</mml:mn</mml:mrow </mml:math as the sample size tends to infinity.",
                    "score": 0.8927158117294312
                },
                {
                    "id": 19209629,
                    "contents": "The sum of standardized residuals: Goodness-of-fit test for binary response models.\nWe propose a new goodness-of-fit statistic for evaluating generalized linear models with binary responses on the basis of the sum of standardized residuals. We derive the asymptotic distribution of the sum of standardized residuals statistic and argue that, despite its relative simplicity, it typically outperforms many of the more sophisticated currently used goodness-of-fit statistics.",
                    "score": 0.8923444151878357
                },
                {
                    "id": 4360905,
                    "contents": "Article 5. An introduction to estimation--2: from z to t.\nProvided the sample size is large enough (that is, n greater than 100), the z statistic can be used to determine the confidence interval estimation of the population mean even when the sigma is not known. In these cases the estimation of the standard error of the mean is used. The z statistic is also valid when determining the population's proportion based upon a large sample. However, when dealing with smaller samples, the z statistic is replaced by the t statistic. This makes it possible to estimate, in a population with an unknown standard deviation: The probability of getting a sample mean greater than or equal to a particular value The value of a sample mean with a particular probability of occurring The probability of getting a sample mean between two particular values The confidence interval for the estimation of the population mean can also be determined using the t statistic.",
                    "score": 0.891566276550293
                },
                {
                    "id": 2036805,
                    "contents": "LILLY--a linear least squares curve fitting program for one independent variable.\nA program was written to perform a linear least squares curve fitting on data. It includes facilities to report the usual statistics and digital plotter output. Seven types of curves are available for fitting the data. Other features of LILLY include provision of facilities for the selection of subsets in different symbols and separate curve fitting for these subsets. The program also provides a confidence region about the fitted line and the prediction interval for data points. Examples of the use of the program are described.",
                    "score": 0.8912981152534485
                },
                {
                    "id": 4801402,
                    "contents": "Summarizing the predictive power of a generalized linear model.\nThis paper studies summary measures of the predictive power of a generalized linear model, paying special attention to a generalization of the multiple correlation coefficient from ordinary linear regression. The population value is the correlation between the response and its conditional expectation given the predictors, and the sample value is the correlation between the observed response and the model predicted value. We compare four estimators of the measure in terms of bias, mean squared error and behaviour in the presence of overparameterization. The sample estimator and a jack-knife estimator usually behave adequately, but a cross-validation estimator has a large negative bias with large mean squared error. One can use bootstrap methods to construct confidence intervals for the population value of the correlation measure and to estimate the degree to which a model selection procedure may provide an overly optimistic measure of the actual predictive power.",
                    "score": 0.8884363770484924
                },
                {
                    "id": 2123524,
                    "contents": "Fitting curves to data using nonlinear regression: a practical and nonmathematical review.\nMany types of data are best analyzed by fitting a curve using nonlinear regression, and computer programs that perform these calculations are readily available. Like every scientific technique, however, a nonlinear regression program can produce misleading results when used inappropriately. This article reviews the use of nonlinear regression in a practical and nonmathematical manner to answer the following questions: Why is nonlinear regression superior to linear regression of transformed data? How does nonlinear regression differ from polynomial regression and cubic spline? How do nonlinear regression programs work? What choices must an investigator make before performing nonlinear regression? What do the final results mean? How can two sets of data or two fits to one set of data be compared? What problems can cause the results to be wrong? This review is designed to demystify nonlinear regression so that both its power and its limitations will be appreciated.",
                    "score": 0.8884226679801941
                },
                {
                    "id": 20324467,
                    "contents": "Insert here, the title of your paper, Capitalize first letter.\nInsert here your abstract text.",
                    "score": 0.8882150650024414
                },
                {
                    "id": 4693911,
                    "contents": "Logistic regression when binary predictor variables are highly correlated.\nStandard logistic regression can produce estimates having large mean square error when predictor variables are multicollinear. Ridge regression and principal components regression can reduce the impact of multicollinearity in ordinary least squares regression. Generalizations of these, applicable in the logistic regression framework, are alternatives to standard logistic regression. It is shown that estimates obtained via ridge and principal components logistic regression can have smaller mean square error than estimates obtained through standard logistic regression. Recommendations for choosing among standard, ridge and principal components logistic regression are developed. Published in 2001 by John Wiley &amp; Sons, Ltd.",
                    "score": 0.8881507515907288
                },
                {
                    "id": 9411449,
                    "contents": "Properties of R(2) statistics for logistic regression.\nVarious R(2) statistics have been proposed for logistic regression to quantify the extent to which the binary response can be predicted by a given logistic regression model and covariates. We study the asymptotic properties of three popular variance-based R(2) statistics. We find that two variance-based R(2) statistics, the sum of squares and the squared Pearson correlation, have identical asymptotic distribution whereas the third one, Gini's concentration measure, has a different asymptotic behaviour and may overstate the predictivity of the model and covariates when the model is mis-specified. Our result not only provides a theoretical basis for the findings in previous empirical and numerical work, but also leads to asymptotic confidence intervals. Statistical variability can then be taken into account when assessing the predictive value of a logistic regression model.",
                    "score": 0.8878201842308044
                },
                {
                    "id": 18674903,
                    "contents": "Common pitfalls in statistical analysis: Linear regression analysis.\nIn a previous article in this series, we explained correlation analysis which describes the strength of relationship between two continuous variables. In this article, we deal with linear regression analysis which predicts the value of one continuous variable from another. We also discuss the assumptions and pitfalls associated with this analysis.",
                    "score": 0.8877286314964294
                },
                {
                    "id": 18179801,
                    "contents": "Corrigendum.\n[This corrects the article DOI: 10.1093/ofid/ofy063.].",
                    "score": 0.8870330452919006
                },
                {
                    "id": 9094368,
                    "contents": "Statistics review 14: Logistic regression.\nThis review introduces logistic regression, which is a method for modelling the dependence of a binary response variable on one or more explanatory variables. Continuous and categorical explanatory variables are considered.",
                    "score": 0.8868273496627808
                },
                {
                    "id": 6299466,
                    "contents": "Computing measures of explained variation for logistic regression models.\nThe proportion of explained variation (R2) is frequently used in the general linear model but in logistic regression no standard definition of R2 exists. We present a SAS macro which calculates two R2-measures based on Pearson and on deviance residuals for logistic regression. Also, adjusted versions for both measures are given, which should prevent the inflation of R2 in small samples.",
                    "score": 0.886536717414856
                },
                {
                    "id": 22607444,
                    "contents": "XXXXXXXXXXX.\nXXXXXXXXXXX.",
                    "score": 0.8865076899528503
                },
                {
                    "id": 21445281,
                    "contents": "p-Value: Villain or Scapegoat?\n.",
                    "score": 0.8864455819129944
                },
                {
                    "id": 794988,
                    "contents": "[Regression and correlation].\nSimple linear regression and correlation are frequently used in medical publications. The methods are overused and have become greatly confused, probably because of the close similarity between the mathematical calculations. Simple regression is a method for a mathematical description of the dependence of a random response variable of another variable, a regressor, which is not random. The model can be used to predict the response form given values of the regressor. Correlation is a measure of the degree of linear association between two random variables, and has nothing to do with regression. The method is mainly an investigative tool in a statistical analysis, or to suggest further research; for forming hypotheses rather than for testing them. To judge form publications, fitting of a regression line and calculation of the correlation coefficient is the method of choice in modelling the linear relationship between two random variables. This is a completely misguided approach. When both variables are random, least squares estimation, as used in regression, is not appropriate. The correct method is to estimate a linear structural model by maximum likelihood.",
                    "score": 0.8864109516143799
                },
                {
                    "id": 2373567,
                    "contents": "Multifit: a flexible non-linear least squares regression program in BASIC.\nMULTIFIT, a program in BASIC for implementation on microcomputers, has been developed for non-linear least squares regression fitting of enzyme kinetic, pharmacokinetic and other data to specific models. The program contains a simple procedure for insertion of model equations with up to five parameters (to be fitted) up to 3 independent variables and 1 dependent variable, and can be used to generate a family of programs with pre-set model functions.",
                    "score": 0.8862838745117188
                },
                {
                    "id": 19143746,
                    "contents": "Corrigendum.\n[This corrects the article DOI: 10.1002/ams2.198.].",
                    "score": 0.8860052227973938
                },
                {
                    "id": 7317563,
                    "contents": "Statistics review 6: Nonparametric methods.\nThe present review introduces nonparametric methods. Three of the more common nonparametric methods are described in detail, and the advantages and disadvantages of nonparametric versus parametric methods in general are discussed.",
                    "score": 0.8857364654541016
                },
                {
                    "id": 21420303,
                    "contents": "[Multiple linear regression models with natural logarithmic transformations of variables].\nIn general, the application conditions of linear regression models could be met after the natural logarithmic transformation of data. From the practical perspective, this paper introduced the linear regression models with natural logarithmic transformation of independent variable, dependent variable, and both independent and dependent variables in detail. The paper illustrated why the equation and coefficients could not be directly explained after the natural logarithmic transformation of data. The percentage changes of <iX</i and/or <iY</i were applied to elaborate the principle and method for the explanation of the equation and coefficients. Three examples were used to fit simple linear models with natural logarithmic transformation of independent, dependent, and both independent and dependent variables and the results of theses models were explained in detail.",
                    "score": 0.8854710459709167
                },
                {
                    "id": 5123590,
                    "contents": "The centercept: an estimable and meaningful regression parameter.\nLinear regression is a mathematical model that is employed broadly throughout all of social science research. The choice of parameterization for linear models has important substantive and statistical implications. This article examines the typical parameterization chosen, which includes a parameter for slope and a parameter for the y-intercept. The article demonstrates that the centercept has an interpretive advantage over the traditionally used y-intercept and that the centercept is typically estimated more accurately.",
                    "score": 0.885375440120697
                },
                {
                    "id": 21676638,
                    "contents": "Correction: Log-transformation and its implications for data analysis.\n[This corrects the article PMCPMC4120293.].",
                    "score": 0.8848986625671387
                },
                {
                    "id": 21198693,
                    "contents": "Corrigendum.\n[This corrects the article DOI: 10.1002/ams2.486.].",
                    "score": 0.8848245143890381
                },
                {
                    "id": 845745,
                    "contents": "Software for estimating LD50 and LD90 by logit analysis.\nWe describe a user-friendly software package using Turbo Pascal language under MS-DOS environment for estimating LD50 and LD90 by Logit Analysis with a X2 test of goodness of fit for the model.",
                    "score": 0.8848215937614441
                },
                {
                    "id": 2580565,
                    "contents": "Explained variation for logistic regression.\nDifferent measures of the proportion of variation in a dependent variable explained by covariates are reported by different standard programs for logistic regression. We review twelve measures that have been suggested or might be useful to measure explained variation in logistic regression models. The definitions and properties of these measures are discussed and their performance is compared in an empirical study. Two of the measures (squared Pearson correlation between the binary outcome and the predictor, and the proportional reduction of squared Pearson residuals by the use of covariates) give almost identical results, agree very well with the multiple R2 of the general linear model, have an intuitively clear interpretation and perform satisfactorily in our study. For all measures the explained variation for the given sample and also the one expected in future samples can be obtained easily. For small samples an adjustment analogous to Radj2 in the general linear model is suggested. We discuss some aspects of application and recommend the routine use of a suitable measure of explained variation for logistic models.",
                    "score": 0.8847275972366333
                },
                {
                    "id": 12275694,
                    "contents": "mmeta: An R Package for Multivariate Meta-Analysis.\nThis paper describes the core features of the R package <bmmeta</b, <bwhich</bimplements the exact posterior inference of odds ratio, relative risk, and risk difference given either a single 2 × 2 table or multiple 2 × 2 tables when the risks within the same study are independent or correlated.",
                    "score": 0.8847153186798096
                },
                {
                    "id": 20287565,
                    "contents": "Corrigendum.\n[This corrects the article DOI: 10.1002/ams2.635.].",
                    "score": 0.8845775127410889
                },
                {
                    "id": 16311689,
                    "contents": "Neither fixed nor random: weighted least squares meta-analysis.\nThis study challenges two core conventional meta-analysis methods: fixed effect and random effects. We show how and explain why an unrestricted weighted least squares estimator is superior to conventional random-effects meta-analysis when there is publication (or small-sample) bias and better than a fixed-effect weighted average if there is heterogeneity. Statistical theory and simulations of effect sizes, log odds ratios and regression coefficients demonstrate that this unrestricted weighted least squares estimator provides satisfactory estimates and confidence intervals that are comparable to random effects when there is no publication (or small-sample) bias and identical to fixed-effect meta-analysis when there is no heterogeneity. When there is publication selection bias, the unrestricted weighted least squares approach dominates random effects; when there is excess heterogeneity, it is clearly superior to fixed-effect meta-analysis. In practical applications, an unrestricted weighted least squares weighted average will often provide superior estimates to both conventional fixed and random effects.",
                    "score": 0.8844171762466431
                },
                {
                    "id": 20291613,
                    "contents": "The Calculus of M-Estimation in R with geex.\nM-estimation, or estimating equation, methods are widely applicable for point estimation and asymptotic inference. In this paper, we present an R package that can find roots and compute the empirical sandwich variance estimator for any set of user-specified, unbiased estimating equations. Examples from the M-estimation primer by Stefanski and Boos (2002) demonstrate use of the software. The package also includes a framework for finite sample, heteroscedastic, and autocorrelation variance corrections, and a website with an extensive collection of tutorials.",
                    "score": 0.8842930793762207
                },
                {
                    "id": 6078920,
                    "contents": "Interpretation of the odds ratio from logistic regression after a transformation of the covariate vector.\nLogistic regression assumes a linear relationship between the logit and the continuous covariate. When the relationship is not linear, one can employ transformations of the covariate to satisfy the linearity assumption. We present an approach that allows interpretation of the odds ratio as it relates to the continuous covariate in its original metric. A numerical example illustrates the results.",
                    "score": 0.8840612173080444
                },
                {
                    "id": 16385304,
                    "contents": "Statistics: general linear models (a flexible approach).\nThis article moves on to discuss a type of statistical testing different from those we have discussed previously, namely a General Linear Model. This system incorporates a number of other statistical models and is a powerful tool used widely in modern statistics. ",
                    "score": 0.883733332157135
                },
                {
                    "id": 313425,
                    "contents": "The second best in statistics.\nWhen estimating a parameter, it may not be possible to remove all sources of bias. Yet a priori we do not know whether eliminating some sources will improve or worsen the estimate.",
                    "score": 0.8836703300476074
                },
                {
                    "id": 6416181,
                    "contents": "The significance of non-significance.\nWe discuss the implications of empirical results that are statistically non-significant. Figures illustrate the interrelations among effect size, sample sizes and their dispersion, and the power of the experiment. All calculations (detailed in Appendix) are based on actual noncentral t-distributions, with no simplifying mathematical or statistical assumptions, and the contribution of each tail is determined separately. We emphasize the importance of reporting, wherever possible, the a priori power of a study so that the reader can see what the chances were of rejecting a null hypothesis that was false. As a practical alternative, we propose that non-significant inference be qualified by an estimate of the sample size that would be required in a subsequent experiment in order to attain an acceptable level of power under the assumption that the observed effect size in the sample is the same as the true effect size in the population; appropriate plots are provided for a power of 0.8. We also point out that successive outcomes of independent experiments each of which may not be statistically significant on its own, can be easily combined to give an overall p value that often turns out to be significant. And finally, in the event that the p value is high and the power sufficient, a non-significant result may stand and be published as such.",
                    "score": 0.8834181427955627
                },
                {
                    "id": 19282269,
                    "contents": "Log Odds and the Interpretation of Logit Models.\nWe discuss how to interpret coefficients from logit models, focusing on the importance of the standard deviation (σ) of the error term to that interpretation. We show how odds ratios are computed, how they depend on the standard deviation (σ) of the error term, and their sensitivity to different model specifications. We also discuss alternatives to odds ratios. There is no single odds ratio; instead, any estimated odds ratio is conditional on the data and the model specification. Odds ratios should not be compared across different studies using different samples from different populations. Nor should they be compared across models with different sets of explanatory variables. To communicate information regarding the effect of explanatory variables on binary {0,1} dependent variables, average marginal effects are generally preferable to odds ratios, unless the data are from a case-control study.",
                    "score": 0.8833420276641846
                },
                {
                    "id": 4991527,
                    "contents": "The Fisher-Pitman permutation test: an attractive alternative to the F test.\nThe Fisher-Pitman permutation test is shown to possess significant advantages over conventional alternatives when analyzing differences among independent samples with unequal variances.",
                    "score": 0.8833308219909668
                },
                {
                    "id": 21330496,
                    "contents": "Corrigendum.\n[This corrects the article DOI: 10.1002/ams2.522.].",
                    "score": 0.8831377625465393
                },
                {
                    "id": 10812627,
                    "contents": "FIRE: an SPSS program for variable selection in multiple linear regression analysis via the relative importance of predictors.\nWe provide an SPSS program that implements currently recommended techniques and recent developments for selecting variables in multiple linear regression analysis via the relative importance of predictors. The approach consists of: (1) optimally splitting the data for cross-validation, (2) selecting the final set of predictors to be retained in the equation regression, and (3) assessing the behavior of the chosen model using standard indices and procedures. The SPSS syntax, a short manual, and data files related to this article are available as supplemental materials from brm.psychonomic-journals.org/content/supplemental.",
                    "score": 0.8831230401992798
                },
                {
                    "id": 4553178,
                    "contents": "[Introduction to regression models].\nRegression models are widely used. They are viewed by clinicians as a passport for a publication in major journals. The expressions: multivariate, logistic regression and Cox model are synonymous with complexity and appear both magical and seductive. Altogether, most clinicians do not read the results of regression models with a critical eye. Our aim is to describe the most common regression models in a unifying framework, and to explain how to interpret each model. We hope that investigators will then be able to discuss the models with the statisticians.",
                    "score": 0.8831197023391724
                },
                {
                    "id": 14014977,
                    "contents": "SPSS macros to compare any two fitted values from a regression model.\nIn regression models with first-order terms only, the coefficient for a given variable is typically interpreted as the change in the fitted value of Y for a one-unit increase in that variable, with all other variables held constant. Therefore, each regression coefficient represents the difference between two fitted values of Y. But the coefficients represent only a fraction of the possible fitted value comparisons that might be of interest to researchers. For many fitted value comparisons that are not captured by any of the regression coefficients, common statistical software packages do not provide the standard errors needed to compute confidence intervals or carry out statistical tests-particularly in more complex models that include interactions, polynomial terms, or regression splines. We describe two SPSS macros that implement a matrix algebra method for comparing any two fitted values from a regression model. The !OLScomp and !MLEcomp macros are for use with models fitted via ordinary least squares and maximum likelihood estimation, respectively. The output from the macros includes the standard error of the difference between the two fitted values, a 95% confidence interval for the difference, and a corresponding statistical test with its p-value.",
                    "score": 0.8831178545951843
                },
                {
                    "id": 1275816,
                    "contents": "2 x 2 kappa coefficients: measures of agreement or association.\nTwo general but different contexts in which kappa might be used are defined: agreement and association. Two models, one for agreement and one for utility of association, are defined yielding different kappa coefficients and different sampling theory. Asymptotic results are derived for both models. Small-sample evaluations are presented for the model for agreement.",
                    "score": 0.8830218315124512
                },
                {
                    "id": 600676,
                    "contents": "Residual plots for log odds ratio regression models.\nThis article describes graphical diagnostic methods for log odds ratio regression models. To study the effects of an additional covariate on log odds ratio regression analysis, three types of residual plots based on weighted least squares (WLS) are discussed: (i) added variable plot (partial regression plot), (ii) partial residual plot, and (iii) augmented partial residual plot. These plots provide diagnostic procedures for identifying heterogeneity of error variances, outliers, or nonlinearity of the model. They are especially useful for clarifying whether including a covariate as a linear term is appropriate, or whether quadratic or other nonlinear transformations are preferable. A well-known data set for case-control studies is analyzed to illustrate the residual plots.",
                    "score": 0.8829551935195923
                },
                {
                    "id": 6076107,
                    "contents": "Regression towards the mean, historically considered.\nThe simple yet subtle concept of regression towards the mean is reviewed historically. Verbal, geometric, and mathematical expressions of the concept date to the discoverer of the concept, Francis Galton. That discovery and subsequent understanding (and misunderstanding) of the concept are surveyed.",
                    "score": 0.8828569650650024
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_21",
        "question": "Calculate the reduced mass of a nitrogen molecule in which both nitrogen atoms have an atomic mass of 14.00.",
        "golden_answers": [
            " 7.00"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 9699147,
                    "contents": "Free Carbon Atom Chemistry: The elusive carbon atom, simplest of organic species, can now be studied with new techniques.\nThe studies of the chemistry of free carbon atoms described here represent only a start toward understanding the properties of this intriguing species. Although many important aspects of its chemistry, such as the influence of its electronic-spin state, are still poorly understood, some generalizations may be made.",
                    "score": 0.8711704015731812
                },
                {
                    "id": 14171210,
                    "contents": "Nitrogenase structure and function relationships by density functional theory.\nModern density functional theory has tremendous potential with matching popularity in metalloenzymology to reveal the unseen atomic and molecular details of structural data, spectroscopic measurements, and biochemical experiments by providing insights into unobservable structures and states, while also offering theoretical justifications for observed trends and differences. An often untapped potential of this theoretical approach is to bring together diverse experimental structural and reactivity information and allow for these to be critically evaluated at the same level. This is particularly applicable for the tantalizingly complex problem of the structure and molecular mechanism of biological nitrogen fixation. In this chapter we provide a review with extensive practical details of the compilation and evaluation of experimental data for an unbiased and systematic density functional theory analysis that can lead to remarkable new insights about the structure-function relationships of the iron-sulfur clusters of nitrogenase.",
                    "score": 0.8701680302619934
                },
                {
                    "id": 11556450,
                    "contents": "The density matrix renormalization group in quantum chemistry.\nThe density matrix renormalization group is a method that is useful for describing molecules that have strongly correlated electrons. Here we provide a pedagogical overview of the basic challenges of strong correlation, how the density matrix renormalization group works, a survey of its existing applications to molecular problems, and some thoughts on the future of the method.",
                    "score": 0.8691790103912354
                },
                {
                    "id": 21891917,
                    "contents": "Charge Anisotropy of Nitrogen: Where Chemical Intuition Fails.\nFor more than half a century computer simulations were developed and employed to study ensemble properties of a wide variety of atomic and molecular systems with tremendous success. Nowadays, a selection of force-fields is available that describe the interactions in such systems. A key feature of force-fields is an adequate description of the electrostatic potential (ESP). Several force-fields model the ESP via point charges positioned at the atom centers. A major shortcoming of this approach, its inability to model anisotropies in the ESP, can be mitigated using additional charge sites. It has been shown that nitrogen is the most problematic element abundant in many polymers as well as large molecules of biological origin. To tackle this issue, small organic molecules containing a single nitrogen atom were studied. In performing rigorous scans of the surroundings of these nitrogen atoms, positions where a single extra charge can enhance the ESP description the most were identified. Significant improvements are found for ammonia, amines, and amides. Interestingly, the optimal location for the extra charge does not correlate with the chemically intuitive position of the nitrogen lone pair. In fact, the placement of an extra charge in the lone-pair location does not lead to significant improvements in most cases.",
                    "score": 0.8685727715492249
                },
                {
                    "id": 10410796,
                    "contents": "Understanding molecular structure from molecular mechanics.\nMolecular mechanics gives us a well known model of molecular structure. It is less widely recognized that valence bond theory gives us structures which offer a direct interpretation of molecular mechanics formulations and parameters. The electronic effects well-known in physical organic chemistry can be directly interpreted in terms of valence bond structures, and hence quantitatively calculated and understood. The basic theory is outlined in this paper, and examples of the effects, and their interpretation in illustrative examples is presented.",
                    "score": 0.8669974207878113
                },
                {
                    "id": 13140626,
                    "contents": "The Role of Naturally Occurring Stable Isotopes in Mass Spectrometry, Part III: Small Gas Molecule Calculations.\nIn the third instalment of this tutorial, the authors explain the determination of the isotopic composition of a sample from a mass spectrometric measurement, and the methods of calculation as well as the units used. This tutorial outlines the practices in common usage, so that researchers new to this field can obtain a good understanding of the fundamentals involved.",
                    "score": 0.8668842315673828
                },
                {
                    "id": 17762247,
                    "contents": "Look Better: Single Atoms in Chemistry and Single Atoms in Physics.\nFostering fruitful collaboration between chemistry and physics scholars, the analysis of the differences in the practical approach to single atoms in chemistry and in physics affords a number of conceptual outcomes pointing to a more balanced and useful relationship between chemistry and physics.",
                    "score": 0.8646535277366638
                },
                {
                    "id": 9667892,
                    "contents": "CHEMISTRY: Harnessing the Power of Diatomics.\nWhen a diatomic molecule is broken up into its constituent atoms, these very energetic atoms provide a large driving force for further reaction. Diatomic molecules often do not undergo productive chemistry, however, because the energy needed to break the diatomic bond is also high. In his Perspective, Thorp discusses the work by MacBeth et al., who have synthesized a nonheme iron complex that reacts with O2 to produce two equivalents of a metal-oxo complex. The complex elegantly mimic the ability of some enzymes to influence metal ion coordination spheres.",
                    "score": 0.863741397857666
                },
                {
                    "id": 9122837,
                    "contents": "Quantum mechanical determinations of reaction mechanisms, acid base, and redox properties of nitrogen oxides and their donors.\nThis chapter reviews computational methods based on quantum mechanics and commonly used commercial programs for the exploration of chemical phenomena, particularly in the field of nitrogen oxides. Examples from the literature are then used to demonstrate the application of these methods to the chemistry and biochemistry of various nitrogen oxides. These examples include determining reaction mechanisms using computed reaction energies, predicting rates of reactions using transition state theory, and determining chemical properties such as hydration equilibria, pKa's, and reduction potentials.",
                    "score": 0.8633435964584351
                },
                {
                    "id": 8755159,
                    "contents": "A fortunate life in physical chemistry.\nThis article contains a very personal account of my evolution as a physical chemist/chemical physicist, with commentary on some of the influences on that evolution and summary accounts of research accomplishments in four of the subject areas that have engaged my attention, ranging from isolated molecules to condensed matter.",
                    "score": 0.862197995185852
                },
                {
                    "id": 21079133,
                    "contents": "Correction: Towards accurate and precise positions of hydrogen atoms bonded to heavy metal atoms.\nCorrection for 'Towards accurate and precise positions of hydrogen atoms bonded to heavy metal atoms' by Magdalena Woińska et al., Chem. Commun., 2021, 57, 3652-3655, DOI: 10.1039/D0CC07661A.",
                    "score": 0.8615851998329163
                },
                {
                    "id": 10595100,
                    "contents": "Average local ionization energy: A review.\nThe average local ionization energy I(r) is the energy necessary to remove an electron from the point r in the space of a system. Its lowest values reveal the locations of the least tightly-held electrons, and thus the favored sites for reaction with electrophiles or radicals. In this paper, we review the definition of I(r) and some of its key properties. Apart from its relevance to reactive behavior, I(r) has an important role in several fundamental areas, including atomic shell structure, electronegativity and local polarizability and hardness. All of these aspects of I(r) are discussed.",
                    "score": 0.8599476218223572
                },
                {
                    "id": 8966082,
                    "contents": "[Ending diatomic molecular terms].\nA method is discussed to find diatomic molecular terms of equivalent and non-equivalent configuration.",
                    "score": 0.8593576550483704
                },
                {
                    "id": 10487660,
                    "contents": "Density functional theory.\nDensity functional theory (DFT) finds increasing use in applications related to biological systems. Advancements in methodology and implementations have reached a point where predicted properties of reasonable to high quality can be obtained. Thus, DFT studies can complement experimental investigations, or even venture with some confidence into experimentally unexplored territory. In the present contribution, we provide an overview of the properties that can be calculated with DFT, such as geometries, energies, reaction mechanisms, and spectroscopic properties. A wide range of spectroscopic parameters is nowadays accessible with DFT, including quantities related to infrared and optical spectra, X-ray absorption and Mössbauer, as well as all of the magnetic properties connected with electron paramagnetic resonance spectroscopy except relaxation times. We highlight each of these fields of application with selected examples from the recent literature and comment on the capabilities and limitations of current methods.",
                    "score": 0.8564695119857788
                },
                {
                    "id": 19729180,
                    "contents": "The Neglected Nuclei.\nSince the nuclei in a molecule are treated as stationary, it is perhaps natural that interpretations of molecular properties and reactivity have focused primarily upon the electronic density distribution. The role of the nuclei has generally received little explicit consideration. Our objective has been to at least partially redress this imbalance in emphasis. We discuss a number of examples in which the nuclei play the determining role with respect to molecular properties and reactive behavior. It follows that conventional interpretations based solely upon electronic densities and donating or withdrawing tendencies should be made with caution.",
                    "score": 0.8561434745788574
                },
                {
                    "id": 7316489,
                    "contents": "The hydrogen bond in the solid state.\nThe hydrogen bond is the most important of all directional intermolecular interactions. It is operative in determining molecular conformation, molecular aggregation, and the function of a vast number of chemical systems ranging from inorganic to biological. Research into hydrogen bonds experienced a stagnant period in the 1980s, but re-opened around 1990, and has been in rapid development since then. In terms of modern concepts, the hydrogen bond is understood as a very broad phenomenon, and it is accepted that there are open borders to other effects. There are dozens of different types of X-H.A hydrogen bonds that occur commonly in the condensed phases, and in addition there are innumerable less common ones. Dissociation energies span more than two orders of magnitude (about 0.2-40 kcal mol(-1)). Within this range, the nature of the interaction is not constant, but its electrostatic, covalent, and dispersion contributions vary in their relative weights. The hydrogen bond has broad transition regions that merge continuously with the covalent bond, the van der Waals interaction, the ionic interaction, and also the cation-pi interaction. All hydrogen bonds can be considered as incipient proton transfer reactions, and for strong hydrogen bonds, this reaction can be in a very advanced state. In this review, a coherent survey is given on all these matters.",
                    "score": 0.8557019233703613
                },
                {
                    "id": 6828963,
                    "contents": "[Nobel Prize 2002 for chemistry: mass spectrometry and nuclear magnetic resonance].\nThe Nobel Prize in Chemistry for 2002 has been awarded to two powerful spectroscopic methodologies through three valorous scientists, John Fenn and Koichi Tanaka, for mass spectrometry and Kurt Wüthrich for nuclear magnetic resonance. These techniques were previously known for their intensive use in chemical analysis. They are now developed at the chemistry/biology interface. Two new methods of soft ionization in mass spectrometry and a strategy of sequential assignment of nuclear magnetic resonance signals of biopolymers now allow the use of these powerful and complementary methodologies for the structural analysis of biological macromolecules, proteins, nucleic acids (DNA, RNA) and polysaccharides. Through the elucidation of their planar and three-dimensional structures and of the molecular mechanisms that govern their interactions, these techniques now may afford precious clues for understanding the molecular mechanisms of life.",
                    "score": 0.8552373647689819
                },
                {
                    "id": 18543292,
                    "contents": "Matter - a current picture.\nA century ago, a two-part review by W. C. McC. Lewis entitled \"The Structure of Matter\" appeared in this journal, surveying the achievements that had been made to date in that field. Topics included the value of Avogadro's constant, the dimensions of a molecule, equations of state for non-ideal gases, then-current theories relating electron configurations to the Periodic Law, the then-new nuclear atom model of Rutherford, and the first findings from X-ray crystallographic studies of matter, a field then in its nascent phase. This article is a sequel to that work. As a vast quantity of research has been addressed to the topic in the intervening period, the view presented here can at best be selective and idiosyncratic. Nonetheless, it attempts to capture some of the important strides in 'matter science', broadly defined, over the past century, highlight some recent areas of interest or novelty, and give a picture of some of the mysteries that remain.",
                    "score": 0.8543103933334351
                },
                {
                    "id": 21387698,
                    "contents": "Addendum: A guide to small-molecule structure assignment through computation of (¹H and ¹³C) NMR chemical shifts.\nAn amendment to this paper has been published and can be accessed via a link at the top of the paper.",
                    "score": 0.8533996939659119
                },
                {
                    "id": 19411411,
                    "contents": "NMReDATA, a standard to report the NMR assignment and parameters of organic compounds.\nEven though NMR has found countless applications in the field of small molecule characterization, there is no standard file format available for the NMR data relevant to structure characterization of small molecules. A new format is therefore introduced to associate the NMR parameters extracted from 1D and 2D spectra of organic compounds to the proposed chemical structure. These NMR parameters, which we shall call NMReDATA (for nuclear magnetic resonance extracted data), include chemical shift values, signal integrals, intensities, multiplicities, scalar coupling constants, lists of 2D correlations, relaxation times, and diffusion rates. The file format is an extension of the existing Structure Data Format, which is compatible with the commonly used MOL format. The association of an NMReDATA file with the raw and spectral data from which it originates constitutes an NMR record. This format is easily readable by humans and computers and provides a simple and efficient way for disseminating results of structural chemistry investigations, allowing automatic verification of published results, and for assisting the constitution of highly needed open-source structural databases.",
                    "score": 0.8528574109077454
                },
                {
                    "id": 20990282,
                    "contents": "The density matrix renormalization group in chemistry and molecular physics: Recent developments and new challenges.\nIn the past two decades, the density matrix renormalization group (DMRG) has emerged as an innovative new method in quantum chemistry relying on a theoretical framework very different from that of traditional electronic structure approaches. The development of the quantum chemical DMRG has been remarkably fast: it has already become one of the reference approaches for large-scale multiconfigurational calculations. This perspective discusses the major features of DMRG, highlighting its strengths and weaknesses also in comparison with other novel approaches. The method is presented following its historical development, starting from its original formulation up to its most recent applications. Possible routes to recover dynamical correlation are discussed in detail. Emerging new fields of applications of DMRG are explored, such as its time-dependent formulation and the application to vibrational spectroscopy.",
                    "score": 0.8524692058563232
                },
                {
                    "id": 12829603,
                    "contents": "The significance and impact of Wade's rules.\nThe emergence of a set of simple yet powerful electron counting rules following a classic paper by Wade published in 1971 in J. Chem. Soc. D has transformed the way chemists think about the structures of clusters with delocalised skeletal bonding.",
                    "score": 0.8524134755134583
                },
                {
                    "id": 6859901,
                    "contents": "Update of the AIM2000-program for atoms in molecules.\nThe second version of the program package AIM2000 is presented. AIM2000 makes use of the well established theory of atoms in molecules. AIM2000 analyzes the molecular structure and calculates properties of atoms in molecules as well as properties of interatomic surfaces. The program has an interactive, context-sensitive help component and extensive 2D and 3D visualization components.",
                    "score": 0.8523650169372559
                },
                {
                    "id": 22386442,
                    "contents": "Correction to Temperature and Pressure-Dependent Rate Constants for the Reaction of Propargyl Radical with Molecular Oxygen.\n[This corrects the article DOI: 10.1021/acsomega.2c04316.].",
                    "score": 0.8520546555519104
                },
                {
                    "id": 9721119,
                    "contents": "Lee Pedersen's work in theoretical and computational chemistry and biochemistry.\nNature at the lab level in biology and chemistry can be described by the application of quantum mechanics. In many cases, a reasonable approximation to quantum mechanics is classical mechanics realized through Newton's equations of motion. Dr. Pedersen began his career using quantum mechanics to describe the properties of small molecular complexes that could serve as models for biochemical systems. To describe large molecular systems required a drop-back to classical means and this led surprisingly to a major improvement in the classical treatment of electrostatics for all molecules, not just biological molecules. Recent work has involved the application of quantum mechanics for the putative active sites of enzymes to gain greater insight into the key steps in enzyme catalysis.",
                    "score": 0.8519717454910278
                },
                {
                    "id": 7699422,
                    "contents": "Spiers Memorial Lecture. Quantum chemistry: the first seventy years.\nPresent-day theoretical chemistry is rooted in Quantum Mechanics. The aim of the opening lecture is to trace the evolution of Quantum Chemistry from the Heitler-London paper of 1927 up to the end of the last century, emphasizing concepts rather than calculations. The importance of symmetry concepts became evident in the early years: one thinks of the necessary anti-symmetry of the wave function under electron permutations, the Pauli principle, the aufbau scheme, and the classification of spectroscopic states. But for chemists perhaps the key concept is embodied in the Hellmann-Feynman theorem, which provides a pictorial interpretation of chemical bonding in terms of classical electrostatic forces exerted on the nuclei by the electron distribution. Much of the lecture is concerned with various electron distribution functions--the electron density, the current density, the spin density, and other 'property densities'--and with their use in interpreting both molecular structure and molecular properties. Other topics touched upon include Response theory and propagators; Chemical groups in molecules and the group function approach; Atoms in molecules and Bader's theory; Electron correlation and the 'pair function'. Finally, some long-standing controversies, in particular the EPR paradox, are re-examined in the context of molecular dissociation. By admitting the concept of symmetry breaking, along with the use of the von Neumann-Dirac statistical ensemble, orthodox quantum mechanics can lead to a convincing picture of the dissociation mechanism.",
                    "score": 0.8517629504203796
                },
                {
                    "id": 6768550,
                    "contents": "The electronic structure of nitrilimines revisited.\nA combination of density-functional theory and natural resonance theory has been used to show that a complete description of the electronic structure of nitrilimines, R(1)CNNR(2), requires four resonance structures (propargylic, allenic, 1,3-dipolar and carbenic); appropriate substituents were shown to enhance the carbene character of nitrilimines to the point where they may be considered stable carbenes.",
                    "score": 0.8516798615455627
                },
                {
                    "id": 15481631,
                    "contents": "Comment on \"Density functional theory studies on molecular structure, vibrational spectra and electronic properties of cyanuric acid\".\nIn a recently published paper [Spectrochim. Acta A: Mol. Biomol. Spect. 138 (2015) 711-722], Prabhaharan, Prabakaran, Srinivasan, and Gunasekaran presented a combined experimental and theoretical study on molecular structure, vibrational spectra and NBO analysis of cyanuric acid, and explain their findings using the tri-hydroxy tautomeric form of the compound. In reality, the compound adopts the tri-oxo tautomeric form, which is by over 100kJmol(-1) more stable comparatively to the tri-hydroxy tautomer discussed and characterized by Prabhaharan et al.",
                    "score": 0.8512967824935913
                },
                {
                    "id": 21603920,
                    "contents": "Chemical Bonding: The Journey from Miniature Hooks to Density Functional Theory.\nOur modern understanding of chemistry is predicated upon bonding interactions between atoms and ions resulting in the assembly of all of the forms of matter that we encounter in our daily life. It was not always so. This review article traces the development of our understanding of bonding from prehistory, through the debates in the 19th century C.E. bearing on valence, to modern quantum chemical models and beyond.",
                    "score": 0.8512258529663086
                },
                {
                    "id": 17214861,
                    "contents": "Molecular Thermodynamics Using Nuclear Magnetic Resonance (NMR) Spectroscopy.\nNuclear magnetic resonance (NMR) spectroscopy is perhaps the most widely used technology from the undergraduate teaching labs in organic chemistry to advanced research for the determination of three-dimensional structure as well as dynamics of biomolecular systems... The NMR spectrum of a molecule under a given experimental condition is unique, providing both quantitative and structural information. In particular, the quantitative nature of NMR spectroscopy offers the ability to follow a reaction pathway of the given molecule in a dynamic process under well-defined experimental conditions. To highlight the use of NMR when determining the molecular thermodynamic parameters, a review of three distinct applications developed from our laboratory is presented. These applications include the thermodynamic parameters of (a) molecular oxidation from time-dependent kinetics, (b) intramolecular rotation, and (c) intermolecular exchange. An experimental overview and the method of data analysis are provided so that these applications can be adopted in a range of molecular systems.",
                    "score": 0.8505592942237854
                },
                {
                    "id": 11263285,
                    "contents": "7Li,15N heteronuclear multiple quantum shift correlation-a fast and reliable 2D NMR method on natural abundant nuclei.\nA straightforward natural abundance 2D HMQC NMR experiment between lithium-7 and nitrogen-15 is reported; this fast, reliable and routinely implementable method represents a powerful spectroscopic tool to study complex structures or intermediate species in solution, in particular those containing nitrogen-lithium bonds.",
                    "score": 0.8501686453819275
                },
                {
                    "id": 20687931,
                    "contents": "Nuclear Magnetic Resonance: A Spectroscopic Probe to Understand the Electronic Structure and Reactivity of Molecules and Materials.\nThis Perspective focuses on the ability of chemical shift to identify and characterize the electronic structure and associated reactivity of molecules and materials. After a general introduction on NMR parameters, we will show selected examples where the chemical shift of various NMR active nuclei has been used to investigate and understand electronic properties, with a particular focus on organometallic compounds and inorganic materials with relevance to catalysis. We will demonstrate how the NMR parameter of probe molecules and ligands can be used to elucidate the nature of active sites and how they can help to understand and predict their reactivity. Lastly, we will give an overview over recent advances in deciphering metal NMR parameters. Overall, we show how chemical shift is a reactivity descriptor that can be analyzed and understood on a molecular level.",
                    "score": 0.8500784039497375
                },
                {
                    "id": 21382058,
                    "contents": "Correction: Cyclo[18]carbon: the smallest all-carbon electron acceptor.\nCorrection for 'Cyclo[18]carbon: the smallest all-carbon electron acceptor' by Anton J. Stasyuk et al., Chem. Commun., 2020, 56, 352-355.",
                    "score": 0.8498625159263611
                },
                {
                    "id": 22509757,
                    "contents": "Molecular Dynamics-From Macromolecule to Small Molecules.\nAll natural molecules have their own physical, chemical, or biological properties and functions [...].",
                    "score": 0.8495866060256958
                },
                {
                    "id": 12168364,
                    "contents": "100th anniversary of Bohr's model of the atom.\nIn the fall of 1913 Niels Bohr formulated his atomic models at the age of 27. This Essay traces Bohr's fundamental reasoning regarding atomic structure and spectra, the periodic table of the elements, and chemical bonding. His enduring insights and superseded suppositions are also discussed. ",
                    "score": 0.8495050668716431
                },
                {
                    "id": 14729483,
                    "contents": "First-Principles Study of Molecular Clusters Formed by Nitric Acid and Ammonia.\nMolecular clusters formed by m nitric acid molecules and n ammonia molecules are studied with density functional theory. For smaller clusters with m, n ≤ 4, all possible combinations of m and n are considered, while for larger clusters in the 5 ≤ m, n ≤ 8 range we only consider the possibilities with |m - n| ≤ 1. Hydrogen bond network formation is an important stabilization mechanism in these clusters. At the same time, proton transfer is generally preferred except in the smallest clusters. Nitric acid and ammonia evaporation rates of these clusters are calculated with both collision activation barriers and reaction thermodynamics explicitly considered. However, unlike in the case of cluster growth from sulfuric acid and ammonia, activation barriers do not play an important role here. If m and n are unequal, evaporation of the abundant species is always preferred. For clusters with m = n &gt; 2, ammonia evaporation is faster than nitric acid. Stabilities of all clusters can be quantitatively evaluated by the evaporation rate of the preferred species. Larger clusters are generally more stable. However, exceptions can occur at structure motif transition point. Deviation from the stoichiometry of m = n significantly lowers the cluster stability. For a cluster pair formed by the same number of molecules, the nitric acid abundant one is more stable, which determines the growth pathway of these clusters.",
                    "score": 0.8494749069213867
                },
                {
                    "id": 7890663,
                    "contents": "What is an atom in a molecule?\nThe derivation of the Hirshfeld atoms in molecules from information theory is clarified. The importance for chemistry of the concept of atoms in molecules (AIM) is stressed, and it is argued that this concept, while highly useful, constitutes a noumenon in the sense of Kant.",
                    "score": 0.8491177558898926
                },
                {
                    "id": 19095686,
                    "contents": "Structure Determination Techniques Flex Their Muscles.\nA historical challenge: Gas-phase electron diffraction and single-crystal X-ray diffraction are both established techniques, but they were both pushed to their limits by the challenge posed by the highly flexible tetranitromethane molecule. New approaches had to be developed for the structure of the molecule to be elucidated.",
                    "score": 0.8489218354225159
                },
                {
                    "id": 16785252,
                    "contents": "Molecular Electron Density Theory: A Modern View of Reactivity in Organic Chemistry.\nA new theory for the study of the reactivity in Organic Chemistry, named Molecular Electron Density Theory (MEDT), is proposed herein. MEDT is based on the idea that while the electron density distribution at the ground state is responsible for physical and chemical molecular properties, as proposed by the Density Functional Theory (DFT), the capability for changes in electron density is responsible for molecular reactivity. Within MEDT, the reactivity in Organic Chemistry is studied through a rigorous quantum chemical analysis of the changes of the electron density as well as the energies associated with these changes along the reaction path in order to understand experimental outcomes. Studies performed using MEDT allow establishing a modern rationalisation and to gain insight into molecular mechanisms and reactivity in Organic Chemistry.",
                    "score": 0.8484381437301636
                },
                {
                    "id": 11660371,
                    "contents": "Kinetic energy density and covalent bonding - a complementary analysis at the border of bond and no bond.\nAn analysis of the kinetic energy density within a molecule identifies patterns within its electronic structure that are intuitively linked to familiar concepts of chemical bonding.",
                    "score": 0.8480920195579529
                },
                {
                    "id": 12167646,
                    "contents": "The RTAM electronic bibliography, version 17.0, on relativistic theory of atoms and molecules.\nThe RTAM bibliography is freely available at rtam.csc.fi and the Version 17.0 of August 22, 2013 now contains 16,566 items from the year 1916-2013. \"Production works\" were systematically covered until 1999. Since the year 2000, mainly methodological papers were included. The methods and principles behind RTAM are described.",
                    "score": 0.847858190536499
                },
                {
                    "id": 18921928,
                    "contents": "Nominal Mass?\nThe current IUPAC-recommended definition of the term \"nominal mass,\" based on the most abundant naturally occurring stable isotope of an element, is flawed. We propose that Nominal mass should be defined as the sum of integer masses of protons and neutrons in any chemical species. In this way, all isotopes and isotopologues can be assigned a definitive identifier. Graphical Abstract ᅟ.",
                    "score": 0.8477383852005005
                },
                {
                    "id": 18431298,
                    "contents": "Electronegativity Seen as the Ground-State Average Valence Electron Binding Energy.\nWe introduce a new electronegativity scale for atoms, based consistently on ground-state energies of valence electrons. The scale is closely related to (yet different from) L. C. Allen's, which is based on configuration energies. Using a combination of literature experimental values for ground-state energies and ab initio-calculated energies where experimental data are missing, we are able to provide electronegativities for elements 1-96. The values are slightly smaller than Allen's original scale, but correlate well with Allen's and others. Outliers in agreement with other scales are oxygen and fluorine, now somewhat less electronegative, but in better agreement with their chemistry with the noble gas elements. Group 11 and 12 electronegativities emerge as high, although Au less so than in other scales. Our scale also gives relatively high electronegativities for Mn, Co, Ni, Zn, Tc, Cd, Hg (affected by choice of valence state), and Gd. The new electronegativities provide hints for new alloy/compound design, and a framework is in place to analyze those energy changes in reactions in which electronegativity changes may not be controlling.",
                    "score": 0.847495973110199
                },
                {
                    "id": 8789253,
                    "contents": "The electronic structure of nitrilimine: absence of the carbenic form.\nThe electronic structure of nitrilimine HCNNH is shown to essentially be propargylic by CASSCF and Spin-Coupled (modern VB) calculations; in contrast to a recent claim, the carbenic resonance form is absent.",
                    "score": 0.8474899530410767
                },
                {
                    "id": 11076106,
                    "contents": "Introduction to nuclear magnetic resonance.\nThis brief guide is not intended as a full explanation of the theory and practice of nuclear magnetic resonance (NMR), on which there are a large number of excellent texts (1-3), but as an introduction to the terms used in the subsequent chapters. The section as a whole does not provide a comprehensive outline of the NMR of organic compounds, which would be out of place in this volume, but is a selection of particular applications likely to be of use to molecular biologists and biochemists. Over the last few years, the number of publications dealing with NMR determinations of protein and peptide conformation in solution has increased dramatically, and this is reflected in the amount of space given here to the subject in Chapters 2 and Chapters 3 . The use of NMR in the study of internal mobility in proteins and in interactions between molecules is covered in Chapter 7 . Chapters 5 and Chapters 6 deal with structural studies on complex carbohydrates, which have thrived on recent advances in NMR. Nucleic acids and their interactions are covered in Chapter 4 .",
                    "score": 0.8474643230438232
                },
                {
                    "id": 10864954,
                    "contents": "First calculations of 15N-15N J values and new calculations of chemical shifts for high nitrogen systems: a comment on the long search for HN5 and its pentazole anion.\nIn the potential solution observation of the long-sought-after pentazole anion (N(5)(-)), the principal experimental tool used for detection is NMR. However, in two experiments, very different conclusions were reached. To assist in the interpretation, we report predictive level coupled-cluster results for the spin-spin coupling constants and chemical shifts for all of the key species, which include NO(3)(-), N(5)(-), HN(5), N(3)(-), and MeOC(6)H(5)N(3). In the case of the shifts, an empirical estimate based on the molecule polarity enables comparison of gas-phase and observed values with expected error bars of approximately +/-10 ppm. For the scalar couplings, the evidence is that the solution effects are modest, enabling the gas-phase values (with error bars are approximately +/-5 Hz) to be accurate. The latter supports the observation of centrally (15)N labeled N(3)(-) in the cerium(IV) ammonium nitrate (CAN) solution which could only occur if the pentazole anion had been created in the experiment, yet with too short a lifetime to be observed in NMR.",
                    "score": 0.8474538922309875
                },
                {
                    "id": 8501042,
                    "contents": "An optimized molecular potential for carbon dioxide.\nAn optimized molecular potential model for carbon dioxide is presented in this paper. Utilizing the established techniques of molecular-dynamics and histogram reweighting grand canonical Monte Carlo simulations, this model is demonstrated to show excellent predictability for thermodynamic, transport, and liquid structural properties in a wide temperature-pressure range with remarkable accuracies. The average deviations of this new model from experimental data for the saturated liquid densities, vapor densities, vapor pressures, and heats of vaporization are around 0.1%, 2.3%, 0.7%, and 1.9%, respectively. The calculated critical point is almost pinpointed by the new model. The experimental radial distribution functions ranging from 240.0 to 473.0 K are well reproduced as compared to neutron-diffraction measurements. The predicted self-diffusion coefficients are in good agreement with the nuclear-magnetic-resonance measurements. The previously published potential models for CO2 are also systematically evaluated, and our proposed new model is found to be superior to the previous models in general.",
                    "score": 0.8473812341690063
                },
                {
                    "id": 16575358,
                    "contents": "Implementation and Validation of Fully Relativistic GW Calculations: Spin-Orbit Coupling in Molecules, Nanocrystals, and Solids.\nWe present an implementation of G0W0 calculations including spin-orbit coupling (SOC) enabling investigations of large systems, with thousands of electrons, and we discuss results for molecules, solids, and nanocrystals. Using a newly developed set of molecules with heavy elements (called GW-SOC81), we find that, when based upon hybrid density functional calculations, fully relativistic (FR) and scalar-relativistic (SR) G0W0 calculations of vertical ionization potentials both yield excellent performance compared to experiment, with errors below 1.9%. We demonstrate that while SR calculations have higher random errors, FR calculations systematically underestimate the VIP by 0.1 to 0.2 eV. We further verify that SOC effects may be well approximated at the FR density functional level and then added to SR G0W0 results for a broad class of systems. We also address the use of different root-finding algorithms for the G0W0 quasiparticle equation and the significant influence of including d electrons in the valence partition of the pseudopotential for G0W0 calculations. Finally, we present statistical analyses of our data, highlighting the importance of separating definitive improvements from those that may occur by chance due to a limited number of samples. We suggest the statistical analyses used here will be useful in the assessment of the accuracy of a large variety of electronic structure methods. ",
                    "score": 0.8471382856369019
                },
                {
                    "id": 18915257,
                    "contents": "Density Functional Theory: Not Quite the Right Answer for the Right Reason Yet.\nMore insight or only more parameters? A recent claim that the development of new density functional theory (DFT) functionals is straying from the right path has sparked a lively discussion among theoretical chemists about the future of DFT.",
                    "score": 0.8471048474311829
                },
                {
                    "id": 18284823,
                    "contents": "The generalized maximum hardness principle revisited and applied to atoms and molecules.\nIn this perspective contribution, we revisit the Maximum Hardness Principle (MHP), formulated by Pearson in 1987, and an equivalent Minimum Polarizability Principle (MPP) from Chattaraj and Parr, with particular emphasis on the cases where nuclear potential acting on electrons does not remain constant, and where substantial modifications of the nuclear geometry take place (Generalized MHP, GMHP). We first bring basic concepts related to electronic hardness, and then we present an overview of important manifestations of the GMHP for molecular systems such as (i) the tendency of two free radicals to couple, (ii) reduced reactivity of noble gases, (iii) symmetry-breaking distortions related to the Jahn-Teller effect, and/or these connected with (anti)aromatic character of certain organic molecules, (iv) enhanced reactivity of excited states, (v) high-low spin transitions, etc. GMHP is an important qualitative indicator in studies of molecular isomerism and reactivity. Quantitative aspects, traditionally measured by changes of electronic plus nuclear energy, are readily explained by changes of hardness (or polarizability) of a molecular system. Several important exceptions from (G)MHP are discussed.",
                    "score": 0.8470311164855957
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_22",
        "question": "Two narrow slits are illuminated with red light of wavelength $694.3 \\mathrm{~nm}$ from a laser, producing a set of evenly placed bright bands on a screen located $3.00 \\mathrm{~m}$ beyond the slits. If the distance between the bands is $1.50 \\mathrm{~cm}$, then what is the distance between the slits?\r\n",
        "golden_answers": [
            " 0.139"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 15524017,
                    "contents": "On the instrument profile of slit spectrographs.\nWe derive an analytic expression for the instrument profile of a slit spectrograph, also known as the line spread function. While this problem is not new, our treatment relies on the operatorial approach to the description of diffractive optical systems, which provides a general framework for the analysis of the performance of slit spectrographs under different illumination conditions. Based on our results, we propose an approximation to the spectral resolution of slit spectrographs, taking into account diffraction effects and sampling by the detector, which improves upon the often adopted approximation based on the root-sum-square of the individual contributions from the slit, the grating, and the detector pixel. ",
                    "score": 0.8946331143379211
                },
                {
                    "id": 10186065,
                    "contents": "Double-slit camera.\nThis Technical Note is a comment on the imaging properties of the double-slit camera. We show its application to the correction of geometrical distortions and propose some other possibilities.",
                    "score": 0.889726996421814
                },
                {
                    "id": 11479961,
                    "contents": "Diffraction Filters in XUV Spectroscopy.\nThe transmission of diffraction filters depends mainly on the geometrical parameters, the slit width 2d, the distance x(n,n-1) of the slits from each other, and the number n of the slits. Therefore the filter curve may be \"shifted\" continuously throughout the XUV spectral region simply by changing the corresponding parameters. This is discussed in detail. Diffraction filters can be utilized in a wide range of experiments in solar, stellar, and laboratory spectroscopy. As is shown for three well known optical arrangements, diffraction filters improve the signal-to-noise ratio considerably, to some extent simplifying the experiment at the same time. Consequently this new technique is an efficient optical tool.",
                    "score": 0.8853071331977844
                },
                {
                    "id": 13001107,
                    "contents": "Measuring coherence functions using non-parallel double slits.\nWe present an experimental method for the fast measurement of both the spectral (spatial) and complex degrees of coherence of an optical field using only a binary amplitude mask and a detector array. We test the method by measuring a two-dimensional spectral degree of coherence function created by a broadband thermal source. The results are compared to those expected by the van Cittert-Zernike theorem and found to agree well in both amplitude and phase. ",
                    "score": 0.8834415078163147
                },
                {
                    "id": 16919688,
                    "contents": "Young's double-slit experiment: noise-resolution duality.\nStatistical aspects of Young's double-slit diffraction experiment are analysed quantitatively. It is shown that the signal-to-noise ratio and the spatial resolution in the detected diffraction pattern satisfy a duality relationship which implies that both of them cannot be improved simultaneously beyond a certain limit if the total number of particles forming the image is fixed. As a consequence of this duality, it is possible to estimate the minimal number of particles that have to be detected in order for two slits separated by a given distance to be resolved with a confidence level corresponding to a pre-defined signal-to-noise ratio, e.g. according to the Rose criterion. These results are related to the recently introduced imaging system quality characteristic which combines the spatial resolution and the noise sensitivity, and allows one to estimate the efficiency with which imaging quanta are utilised in a system to deliver maximal amount of information about the imaged object. The presented results can be useful for applications where the imaging quanta are at a premium or where minimization of the radiation dose is important. ",
                    "score": 0.8816538453102112
                },
                {
                    "id": 10092469,
                    "contents": "Double slit with continuously variable width and center-to-center separation.\nLinear polarizers and a half-wave plate are used to make a double slit whose width and center-to-center separation are continuously variable.",
                    "score": 0.88054358959198
                },
                {
                    "id": 17303770,
                    "contents": "The Young-Feynman controlled double-slit electron interference experiment.\nThe key features of quantum mechanics are vividly illustrated by the Young-Feynman two-slit thought experiment, whose second part discusses the recording of an electron distribution with one of the two slits partially or totally closed by an aperture. Here, we realize the original Feynman proposal in a modern electron microscope equipped with a high brightness gun and two biprisms, with one of the biprisms used as a mask. By exciting the microscope lenses to conjugate the biprism plane with the slit plane, observations are carried out in the Fraunhofer plane with nearly ideal control of the covering of one of the slits. A second, new experiment is also presented, in which interference phenomena due to partial overlap of the slits are observed in the image plane. This condition is obtained by inserting the second biprism between the two slits and the first biprism and by biasing it in order to overlap their images.",
                    "score": 0.8772523403167725
                },
                {
                    "id": 10516255,
                    "contents": "Resolution and stray light in near infrared spectroscopy.\nThe slit function at 1064 nm for a double monochromator spectrophotometer has been obtained with sufficient dynamic range to quantitatively account for the resolution and stray light over a wide range of resolutionv and absorbance levels. Conventional stray light tests are found to underestimate seriously that portion of the nearby stray light that most influences errors in ir absorbance determinations, and improved tests are suggested. A revision of the definition of stray light is suggested in order to minimize the variation of stray light with resolution. Convolutions of the observed slit functions with the transmittance function for the 1691-nm band of chloroform agree with observed absorbance measurements over a wide range of resolution and absorbance levels. The ratio of true to observed absorbance levels for chloroform is significantly less influenced by resolution than the literature, using triangular or Gaussian slit functions and Lorentzian absorbance functions, predicts.",
                    "score": 0.87721848487854
                },
                {
                    "id": 13864057,
                    "contents": "Young's experiment with a double slit of sub-wavelength dimensions.\nWe report that the interference pattern of Young's double-slit experiment changes as a function of polarization in the sub-wavelength diffraction regime. Experiments carried out with terahertz time-domain spectroscopy reveal that diffracted waves from sub-wavelength-scale slits exhibit either positive or negative phase shift with respect to Gouy phase depending on the polarization. Theoretical explanation based on the induction of electric current and magnetic dipole in the vicinity of the slits shows an excellent agreement with the experimental results. ",
                    "score": 0.8765426874160767
                },
                {
                    "id": 17055605,
                    "contents": "Nonclassical paths in quantum interference experiments.\nIn a double slit interference experiment, the wave function at the screen with both slits open is not exactly equal to the sum of the wave functions with the slits individually open one at a time. The three scenarios represent three different boundary conditions and as such, the superposition principle should not be applicable. However, most well-known text books in quantum mechanics implicitly and/or explicitly use this assumption that is only approximately true. In our present study, we have used the Feynman path integral formalism to quantify contributions from nonclassical paths in quantum interference experiments that provide a measurable deviation from a naive application of the superposition principle. A direct experimental demonstration for the existence of these nonclassical paths is difficult to present. We find that contributions from such paths can be significant and we propose simple three-slit interference experiments to directly confirm their existence. ",
                    "score": 0.8734903931617737
                },
                {
                    "id": 9590652,
                    "contents": "Detection of subwavelength slit-width variation with irradiance measurements in the far field.\nWe demonstrate that, under suitable conditions, subwavelength feature variations of an object can affect the corresponding far-field diffraction pattern in a measurable way. We present an experiment in which width variations of less than 1/100 of the wavelength are measured with a slit whose width is 100 times the wavelength. Integral and differential intensity measurements in the far field are fully consistent with standard diffraction theory even in the subwavelength variation regime. In particular, slit modulations of 6 nm with a wavelength of 670 nm are shown to follow theoretical calculations within the experimental sensitivity of ~10(-5) .",
                    "score": 0.8721999526023865
                },
                {
                    "id": 17087686,
                    "contents": "Dynamic Double-Slit Experiment in a Single Atom.\nA single-atom \"double-slit\" experiment is realized by photoionizing rubidium atoms using two independent low power lasers. The photoelectron wave of well-defined energy recedes to the continuum either from the 5P or 6P states in the same atom, resulting in two-path interference imaged in the far field using a photoelectron detector. Even though the lasers are independent and not phase locked, the transitions within the atom impart the phase relationship necessary for interference. The experiment is designed so that either 5P or 6P states are excited by one laser, before ionization by the second beam. The measurement cannot determine which excitation path is taken, resulting in interference in wave-vector space analogous to Young's double-slit studies. As the lasers are tunable in both frequency and intensity, the individual excitation-ionization pathways can be varied, allowing dynamic control of the interference term. Since the electron wave recedes in the Coulomb potential of the residual ion, a quantum model is used to capture the dynamics. Excellent agreement is found between theory and experiment.",
                    "score": 0.8712301850318909
                },
                {
                    "id": 11474510,
                    "contents": "Unfolding spectrometer slit broadening effects from broad spectra.\nA method is described in which approximate correction for spectral slit broadening is performed at the same time that reflectance or transmittance data are being fitted with analytic dispersion curves. The method is valid for spectra whose structure is not too sharp on a scale comparable with the spectrometer resolution. It is not to be used for sharp line spectra. The key problem that is solved is to find the fastest way to compute the slit broadening effect on the spectra obtained from the trial dispersion curves. The method is applied, as an example, to analyze some reststrahlen data taken with a grating spectrometer in the far ir from a sample of PrCl(3). The same approximate method could also be used with data from other types of spectrometers having different slit broadening functions, such as from two-crystal x-ray spectrometers, in regions where very sharp spikes do not appear in the spectra.",
                    "score": 0.8697890639305115
                },
                {
                    "id": 9578258,
                    "contents": "Absolute determination of the wavelength and spectrum of an extreme-ultraviolet beam by a Young's double-slit measurement.\nThe interference pattern produced by irradiation of a pair of pinholes with a beam contains information on both the spatial and the temporal coherence properties of the beam, as well as its power spectrum. We demonstrate experimentally for what is believed to be the first time that the spectrum of an extreme-ultraviolet (EUV) beam can be obtained from a measurement of the interference pattern produced by a pinhole pair. This approach offers a convenient method of making absolute wavelength and relative spectral intensity calibrations in the EUV.",
                    "score": 0.868678629398346
                },
                {
                    "id": 11404805,
                    "contents": "Transmission of light through slit apertures in metallic films.\nTransmission of polarized light through sub-wavelength slit apertures is studied based on the electromagnetic field distributions obtained in computer simulations. The results show the existence of a cutoff for E|| and a strong transmission (with no cutoff) for E?; here || and ? refer to the direction of the incident E-field relative to the long axis of the slit. These observations are explained by the standard waveguide theory involving inhomogeneous plane waves that bounce back and forth between the interior walls of the slit aperture. We examine the roles played by the slit-width, by the film thickness, and by the real and imaginary parts of the host material's dielectric constant in determining the transmission efficiency. We also show that the slit's sharp edges can be rounded to eliminate highly-localized electric dipoles without significantly affecting the slit's throughput. Finally, interference among the surface charges and currents induced in the vicinity of two adjacent slits is shown to result in enhanced transmission through both slits when the slits are separated by about one half of one wavelength.",
                    "score": 0.8683098554611206
                },
                {
                    "id": 5223615,
                    "contents": "X-ray diffraction from rectangular slits.\nIt is shown that for micrometre-sized beams the X-ray diffraction from slits is a source of strong parasitic background, even for slits of high quality. In order to illustrate this effect, the coherent diffraction from rectangular slits has been studied in detail. A large number of interference fringes with strong visibility have been observed using a single set of slits made of polished cylinders. For very small apertures, asymmetrical slits generate asymmetrical patterns. This pattern is calculated from the theory of electromagnetic field propagation and compared with experiment in the far-field regime. The use of guard slits to remove Fraunhofer diffraction from the beam-defining slits is treated theoretically. Numerical simulations yield the optimum aperture of the guard slits with respect to the distance to the primary slits. Diffraction theory is shown to be essential to understand how to reduce the background-to-signal ratio in high-resolution experiments.",
                    "score": 0.8675028085708618
                },
                {
                    "id": 22832295,
                    "contents": "Which-way identification by an asymmetrical double-slit experiment with monochromatic photons.\nRecently, a laser beam asymmetrical double-slit experiment was proposed and performed, concerning ontological physical reality in quantum mechanics, under an assumption of single-photon interference. In the present study, by controlling better for saturation effects and upgrading the slit's shape, we succeed in producing new interference samples with acceptable quality. Applying almost the same geometrical set-up, the present experiment makes the \"which-way\" identification with higher experimental confidence. In the results, the ontological which-way effect observed in our recent experiment is well reconfirmed without any additional measurement of relative integral intensity.",
                    "score": 0.8670219779014587
                },
                {
                    "id": 13505273,
                    "contents": "Influence of film thickness on the optical transmission through subwavelength single slits in metallic thin films.\nSilver and gold films with thicknesses in the range of 120-450 nm were evaporated onto glass substrates. A sequence of slits with widths varying between 70 and 270 nm was milled in the films using a focused gallium ion beam. We have undertaken high-resolution measurements of the optical transmission through the single slits with 488.0 nm (for Ag) and 632.8 nm (for Au) laser sources aligned to the optical axis of a microscope. Based on the present experimental results, it was possible to observe that (1) the slit transmission is notably affected by the film thickness, which presents a damped oscillatory behavior as the thickness is augmented, and (2) the transmission increases linearly with increasing slit width for a fixed film thickness.",
                    "score": 0.8643432855606079
                },
                {
                    "id": 16354139,
                    "contents": "Resolution criteria in double-slit microscopic imaging experiments.\nDouble-slit imaging is widely used for verifying the resolution of high-resolution and super-resolution microscopies. However, due to the fabrication limits, the slit width is generally non-negligible, which can affect the claimed resolution. In this paper we theoretically calculate the electromagnetic field distribution inside and near the metallic double slit using waveguide mode expansion method, and acquire the far-field image by vectorial Fourier optics. We find that the slit width has minimal influence when the illuminating light is polarized parallel to the slits. In this case, the claimed resolution should be based on the center-to-center distance of the double-slit.",
                    "score": 0.8643051981925964
                },
                {
                    "id": 14812629,
                    "contents": "Measurement-induced decoherence and information in double-slit interference.\nThe double slit experiment provides a classic example of both interference and the effect of observation in quantum physics. When particles are sent individually through a pair of slits, a wave-like interference pattern develops, but no such interference is found when one observes which \"path\" the particles take. We present a model of interference, dephasing, and measurement-induced decoherence in a one-dimensional version of the double-slit experiment. Using this model, we demonstrate how the loss of interference in the system is correlated with the information gain by the measuring apparatus/observer. In doing so, we give a modern account of measurement in this paradigmatic example of quantum physics that is accessible to students taking quantum mechanics at the graduate or senior undergraduate levels.",
                    "score": 0.8638745546340942
                },
                {
                    "id": 14200504,
                    "contents": "The electromagnetics of light transmission through subwavelength slits in metallic films.\nBy numerically calculating the relevant electromagnetic fields and charge current densities, we show how local charges and currents near subwavelength structures govern light transmission through subwavelength apertures in a real metal film. The illumination of a single aperture generates surface waves; and in the case of slits, generates them with high efficiency and with a phase close to -π with respect to a reference standing wave established at the metal film front facet. This phase shift is due to the direction of induced charge currents running within the slit walls. The surface waves on the entrance facet interfere with the standing wave. This interference controls the profile of the transmission through slit pairs as a function of their separation. We compare the calculated transmission profile for a two-slit array to simple interference models and measurements [Phys. Rev. B 77(11), 115411 (2008)].",
                    "score": 0.8636865615844727
                },
                {
                    "id": 11477319,
                    "contents": "Spectrometer slit programmer with no moving parts.\nAn optical system with no moving mechanical parts has been installed in a rapid scanning spectrometer to program the spectral slit width as a function of wavelength. A set of contoured slits and baffles maintains a good balance between signal and resolution and keeps the dynamic range of the background signal within reasonable limits.",
                    "score": 0.8635929822921753
                },
                {
                    "id": 9956527,
                    "contents": "Interference from a nonlocal double-slit through one-photon process.\nIn this paper, we report an interference experiment in which a spatially incoherent light source illuminates two spatially separated apertures, whose superposition at the same place forms a double-slit. The experimental result exhibits a well-defined interference fringe solely through intensity measurements, in agreement with the theoretical analysis by means of the first-order spatial interference of the incoherent light. Consequently, the nonlocal double-slit interference with thermal light should be attributed to the first-order spatial correlation of incoherent field.",
                    "score": 0.8629772663116455
                },
                {
                    "id": 4680662,
                    "contents": "\"Either-or\" two-slit interference: stable coherent propagation of individual photons through separate slits.\nIn quantum theory, nothing that is observable, be it physical, chemical, or biological, is separable from the observer. Furthermore, \". all possible knowledge concerning that object is given by its wave function\" (Wigner, E. 1967. Symmetries and Reflections. Indiana University Press, Bloomington, IN), which can only describe probabilities of future events. In physical systems, quantum mechanical probabilistic events that are microscopic must, in turn, account for macroscopic events that are associated with a greater degree of certainty. In biological systems, probabilistic statistical mechanical events, such as secretion of microscopic synaptic vesicles, must account for macroscopic postsynaptic potentials; probabilistic single-channel events sum to produce a macroscopic ionic current across a cell membrane; and bleaching of rhodopsin molecules (responsible for quantal potential \"bumps\") produces a photoreceptor generator potential. Among physical systems, a paradigmatic example of how quantum theory applies to the observation of events concerns the interactions of particles (e.g., photons, electrons) with the two-slit apparatus to generate an interference pattern from a single common light source. For two-slit systems that use two independent laser sources with brief (&lt;1 ms) intervals of mutual coherence (Paul, H. 1986. Rev. Modern Phys. 58:209-231), each photon has been considered to arise from both beams and has a probability amplitude to pass through each of the two slits. Here, a single laser source two-slit interference system was constructed so that each photon has a probability amplitude to pass through only one or the other, but not both slits. Furthermore, all photons passing through one slit could be distinguished from all photons passing through the other slit before their passage. This \"either-or\" system produced a stable interference pattern indistinguishable from the interference produced when both slits were accessible to each photon. Because this system excludes the interaction of one photon with both slits, phase correlation of photon movements derives from the \"entanglement\" of all photon wave functions due to their dependence on a common laser source. Because a laser source (as well as Young's original point source) will have stable time-averaged spatial coherence even at low intensities, the \"either-or\" two-slit interference can result from distinct individual photons passing one at a time through one or the other slit-rather than wave-like behavior of individual photons. In this manner, single, successive photons passing through separate slits will assemble over time in phase-correlated wave distributions that converge in regions of low and high probability.",
                    "score": 0.862574577331543
                },
                {
                    "id": 11940183,
                    "contents": "Far-ultraviolet astronomical narrowband imaging.\nWe describe an all-reflective system for narrowband imaging suitable for imaging emission lines in the far ultraviolet. The system, which we call a monochromatic imager, combines a pupil plane grating monochromator with a telescope and camera to image a scene in one or more very narrow bands. The monochromator uses physical stops at its input and output apertures, and, as a result, the system has excellent rejection of out-of-band and off-axis light.",
                    "score": 0.8617235422134399
                },
                {
                    "id": 1761002,
                    "contents": "Multiple-slit illumination of the optic disc.\nA modification to a photo slit-lamp illuminator adds detail to the human optic disc surface by projecting onto it a pattern of fine parallel lines. These stripes curve as they traverse the disc, and its surface contour is revealed. Application of this technique may improve the reliability of methods used to quantitate disc topography.",
                    "score": 0.8609088659286499
                },
                {
                    "id": 16757900,
                    "contents": "Experimental demonstration of a quantum shutter closing two slits simultaneously.\nThe interference between two paths of a single photon at a double slit is widely considered to be the most paradoxical result of quantum theory. Here is a new interesting question to the phenomenon: can a single shutter simultaneously close two slits by effectively being in a superposition of different locations? Aharonov and Vaidman have shown that it is indeed possible to construct a quantum shutter that can close two slits and reflect a probe photon perfectly when its initial and final states are appropriately selected. Here we report the experimental demonstration of their proposal overcoming the difficulty to realize a 'quantum shutter' by employing photonic quantum routers. The reflectance ratio of 0.61 ± 0.027 surpasses the classical limit with 4.1 standard deviation, shedding new light on the unusual physical properties of quantum operations. This experimental demonstration, where the strong measurement and non-local superposition seem co-existing, provides an alternative to weak measurements as a way to explore the nature of quantum physics.",
                    "score": 0.8608187437057495
                },
                {
                    "id": 11401438,
                    "contents": "Spectral anomalies in Young's double-slit interference experiment.\nWe report a phenomenon of spectral anomalies in the interference field of Young's double-slit interference experiment. The potential applications of the spectral anomalies in the information encoding and information transmission in free space are also considered.",
                    "score": 0.8607175350189209
                },
                {
                    "id": 11519154,
                    "contents": "Arbitrary-intensity-profiles measurement of laser beams by a scanning and rotating slit.\nBy taking advantage of the mathematical analogy of optical power passing through a narrow slit and the attenuation of an x-ray beam passing through a biological tissue, and by applying to the optical case the projection and reconstruction algorithms of computed tomography, one can determine in detail the intensity profile of an arbitrary laser beam by properly combining the position and orientation of the slit. Until now, to the best of my knowledge, the scanning slit has been limited to the measurement of Gaussian or nearly Gaussian beams.",
                    "score": 0.8606362342834473
                },
                {
                    "id": 11965419,
                    "contents": "High-harmonic-generation spectrum reconstruction from Young's double-slits interference pattern using the maximum entropy method.\nA method is proposed that uses maximum entropy analysis of a Young's two-slit interference pattern for the measurement of the spectrum of a high-harmonic-generation light source. The approach is tested using experimental data, and the results are found to be consistent with those obtained directly using a grazing incidence spectrometer.",
                    "score": 0.8600980639457703
                },
                {
                    "id": 6454572,
                    "contents": "Characterization of the signature of subwavelength variation from far-field irradiance.\nThe dynamic signature of the subwavelength variation of a slit is shown to be determinable from far-field irradiance with a precision of better than 1 nm. One can increase the efficiency of measurement of the subwavelength's signature by adjusting the detection width over which the subwavelength variation is detected. The subwavelength variation of a rectangular aperture was also examined to show the general feasibility.",
                    "score": 0.8594732284545898
                },
                {
                    "id": 11432449,
                    "contents": "Modified Young's Interferometer.\nA modified Young's two-slit interferometer measures the separation between the centers of two slits or two lines when they are nearly coincident. A prototype instrument, which functions as an automatic, interferometric micrometer, is described. This instrument measures the position of a slit with a resolution of 5 nm.",
                    "score": 0.8585938811302185
                },
                {
                    "id": 9642615,
                    "contents": "Slits as adjustable pinholes for coherent X-ray scattering experiments.\nThe combination of accurate translation stages with carefully polished slit blades leads to slits that have many advantages as pinholes for coherent X-ray scattering experiments. The size is adjustable and can be made as small as 0.5 mum. Setting up is easy, while the blade thickness (1 mm tungsten) also makes the slits useful for hard X-rays. A relation between the slit-sample distance and the minimum beam size, together with the corresponding slit size, is derived. This shows that a micrometer-sized beam can be achieved with this type of slits.",
                    "score": 0.8583157062530518
                },
                {
                    "id": 10997288,
                    "contents": "Imaging channeled spectrograph: a high resolution spectrometer providing multiple simultaneous 2-D monochromatic images over a large spectral range.\nAn imaging channeled spectrograph (ICS) consists of a Fabry-Perot bandpass filter followed by a wide slit imaging grating spectrograph. This unique configuration combines the 2-D monochromatic imaging of a Fabry-Perot system with the high resolution and comprehensive wavelength coverage of a grating spectrograph. The ICS produces a series of simultaneous, high resolution, nonoverlapping, 2-D monochromatic images uniformly distributed over a large spectral range. This paper describes the ICS optical properties in general and calculates the optical performance of an ICS designed for the proposed NRL spectrocoronagraph.",
                    "score": 0.857867956161499
                },
                {
                    "id": 11940298,
                    "contents": "On the transmission of diffuse light through thick slits.\nWe study the transmission of diffuse light through thick slits. For perfectly conducting slits and in-plane s-polarized illumination, the transmittance curves present a staircaselike behavior as a function of the aperture width, where the steps mark the appearance of new propagation modes. In contrast, with p-polarized illumination the transmittance increases linearly with the aperture width, with only some perturbations in the positions that correspond to the appearance of new modes. Out-of-plane incidence and more realistic assumptions about the slit, such as finite conductivity and roughness, are also discussed.",
                    "score": 0.857702374458313
                },
                {
                    "id": 8679226,
                    "contents": "Experimental demonstration of tomographic slit technique for measurement of arbitrary intensity profiles of light beams.\nWe demonstrate experimentally an optical imaging method that makes use of a slit to collect tomographic projection data of arbitrarily shaped light beams; a tomographic backprojection algorithm is then used to reconstruct the intensity profiles of these beams. Two different implementations of the method are presented. In one, a single slit is scanned and rotated in front of the laser beam. In the other, the sides of a polygonal slit, which is linearly displaced in a x-y plane perpendicular to the beam, are used to collect the data. This latter version is more suitable than the other for adaptation at micrometer-size scale. A mathematical justification is given here for the superior performance against laser-power fluctuations of the tomographic slit technique compared with the better-known tomographic knife-edge technique.",
                    "score": 0.8569756746292114
                },
                {
                    "id": 18934171,
                    "contents": "What is the maximum attainable visibility by a partially coherent electromagnetic field in Young's double-slit interference?\nWhat is the maximum visibility attainable in double-slit interference by an electromagnetic field if arbitrary - but reversible - polarization and spatial transformations are applied? Previous attempts at answering this question for electromagnetic fields have emphasized maximizing the visibility under local polarization transformations. I provide a definitive answer in the general setting of partially coherent electromagnetic fields. An analytical formula is derived proving that the maximum visibility is determined by only the two smallest eigenvalues of the 4×4 two-point coherency matrix associated with the electromagnetic field. This answer reveals, for example, that any two points in a spatially incoherent scalar field can always achieve full interference visibility by applying an appropriate reversible transformation spanning both the polarization and spatial degrees of freedom - without loss of energy. Surprisingly, almost all current measures predict zero-visibility for such fields. This counter-intuitive result exploits the higher dimensionality of the Hilbert space associated with vector - rather than scalar - fields to enable coherency conversion between the field's degrees of freedom.",
                    "score": 0.8564950227737427
                },
                {
                    "id": 15836220,
                    "contents": "Squeezing millimeter waves through a single, nanometer-wide, centimeter-long slit.\nWe demonstrate broadband non-resonant squeezing of terahertz (THz) waves through an isolated 2-nm-wide, 2-cm-long slit (aspect ratio of 10(7)), representing a maximum intensity enhancement factor of one million. Unlike resonant nanogap structures, a single, effectively infinitely-long slit passes incident electromagnetic waves with no cutoff, enhances the electric field within the gap with a broad 1/f spectral response, and eliminates interference effects due to finite sample boundaries and adjacent elements. To construct such a uniform, isolated slit that is much longer than the millimeter-scale spot of a THz beam, we use atomic layer lithography to pattern vertical nanogaps in a metal film over an entire 4-inch wafer. We observe an increasing field enhancement as the slit width decreases from 20 nm to 2 nm, in agreement with numerical calculations. ",
                    "score": 0.8564908504486084
                },
                {
                    "id": 15717637,
                    "contents": "The Merli-Missiroli-Pozzi Two-Slit Electron-Interference Experiment.\nIn 2002 readers of <iPhysics World</i voted Young's double-slit experiment with single electrons as \"the most beautiful experiment in physics\" of all time. Pier Giorgio Merli, Gian Franco Missiroli, and Giulio Pozzi carried out this experiment in a collaboration between the Italian Research Council and the University of Bologna almost three decades earlier. I examine their experiment, place it in historical context, and discuss its philosophical implications.",
                    "score": 0.8558779954910278
                },
                {
                    "id": 18779719,
                    "contents": "On the equivalence between Young's double-slit and crystal double-refraction interference experiments.\nWe show, both analytically and experimentally, that under common experimental conditions the interference pattern produced in a classic Young's double-slit experiment is indistinguishable from that generated by means of a doubly refracting uniaxial crystal whose optic axis makes a skew angle with the light propagation direction. The equivalence between diffraction and crystal optics interference experiments, taken for granted by Arago and Fresnel in their pioneering research on the interference of polarized light beams, is thus rigorously proven.",
                    "score": 0.8557052612304688
                },
                {
                    "id": 15915374,
                    "contents": "Slit lamp photography: The basics.\nThis introductory paper is designed to explain the basics of slit lamp photography with the use of illustrations and sample images. The two primary methods of illumination are described with reference to positioning and magnification, as well as the use of background illumination. Filters and dye usage are described along with a brief explanation of associated imaging techniques. Further explanation of techniques will be looked at in subsequent articles, this paper aims to give an over view rather than an in-depth discussion of techniques. ",
                    "score": 0.8556186556816101
                },
                {
                    "id": 10471696,
                    "contents": "Two-slit diffraction with highly charged particles: Niels Bohr's consistency argument that the electromagnetic field must be quantized.\nWe analyze Niels Bohr's proposed two-slit interference experiment with highly charged particles which argues that the consistency of elementary quantum mechanics requires that the electromagnetic field must be quantized. In the experiment a particle's path through the slits is determined by measuring the Coulomb field that it produces at large distances; under these conditions the interference pattern must be suppressed. The key is that, as the particle's trajectory is bent in diffraction by the slits, it must radiate and the radiation must carry away phase information. Thus, the radiation field must be a quantized dynamical degree of freedom. However, if one similarly tries to determine the path of a massive particle through an inferometer by measuring the Newtonian gravitational potential the particle produces, the interference pattern would have to be finer than the Planck length and thus indiscernible. Unlike for the electromagnetic field, Bohr's argument does not imply that the gravitational field must be quantized.",
                    "score": 0.8554419279098511
                },
                {
                    "id": 10527357,
                    "contents": "Dependence of resonant light transmission properties of a subwavelength slit on structural parameters.\nWe perform a systematic study of the resonant transmission of visible and near-infrared (NIR) light through a single subwavelength slit in a gold film when the parameters defining the structure are varied. We further examine the optical properties of a related nanostructure, a cross with subwavelength sized features. Focused ion beam (FIB) milling was used to fabricate nanoslits and crosses with linewidths ranging from 26 nm to 85 nm. The dimensions of the structure are found to affect strongly the transmittance spectrum. For example, as the slit becomes narrower the resonance is observed to both sharpen and shift significantly. Our observations are in good agreement with our earlier numerical calculations on the optical properties of nanoslits.",
                    "score": 0.8551782965660095
                },
                {
                    "id": 11632597,
                    "contents": "Tunable optical transmission through gold slit arrays with Z-shaped channels.\nThe transmission of a normally incident wave through an array of subwavelength gold film with Z-shaped slits has been explored by using the finite-difference time-domain method. The results show that the transmission of a thinner metal film perforated with a Z-shaped slit array behaves nearly the same as that of a thicker metal film perforated with straight slit array with the same central slit length, which is useful for the miniaturization of the optical device. It is also presented that the transmission of a Z-shaped slit array sensitively depends on the slit geometrical parameters. By adjusting the width and length of each section of the Z-shaped slit, noticeable magnitude modification of the transmission, redshift, and blueshift of the resonance modes is found, which is useful for the design of frequency-selective and sensor optical devices.",
                    "score": 0.8551063537597656
                },
                {
                    "id": 10876101,
                    "contents": "Thin slits: transmission and polarization.\nThe paper discusses measurement of the transmission ratio T ||/T? of thin slits for light polarized linearly parallel and perpendicular to the slit direction at optical wavelengths and as a function of the angle of incidence. To obtain perfectly identical geometrical beams, the plane of polarization of the linearly polarized light is rotated in the measuring setup by means of plates of optically active quartz. The results indicate that the transmissivity is higher for light polarized parallel to the slit direction. This effect is more pronounced with narrow slits than with wide slits and, moreover, increases with the wavelength. For tangential orientation of the slit, the ratio T ||/T? increases with the angle of incidence. The paper studies the effect of surface reflections.",
                    "score": 0.8550779819488525
                },
                {
                    "id": 8728642,
                    "contents": "Attosecond double-slit experiment.\nA new scheme for a double-slit experiment in the time domain is presented. Phase-stabilized few-cycle laser pulses open one to two windows (slits) of attosecond duration for photoionization. Fringes in the angle-resolved energy spectrum of varying visibility depending on the degree of which-way information are measured. A situation in which one and the same electron encounters a single and a double slit at the same time is observed. The investigation of the fringes makes possible interferometry on the attosecond time scale. From the number of visible fringes, for example, one derives that the slits are extended over about 500 as.",
                    "score": 0.8549953699111938
                },
                {
                    "id": 21243626,
                    "contents": "First order design of compact, broadband, high spectral resolution ultraviolet-visible imaging spectrometer.\nAn imaging spectrometer combining an entrance slit, a Fabry-Perot interferometer (FPI) and a plane transmission grating is presented. Each unit of the entrance slit is imaged on a separate column of the detector and different wavelengths are dispersed across different rows of that column. To cover the full spectral range, the FPI needs to scan N steps. For each unit of the entrance slit, one spectrum is obtained at each FPI spacing position and a total of N spectra are sequentially obtained to constitute a high resolution spectrum. The combination of imaging, interferometry and dispersive spectrometry enables the instrument to obtain spatial information and high-resolution spectral information of a broadband source in the ultraviolet-visible spectral region. First-order approximations of system performance are given. The unique design of the optics will make the instrument compact and suitable for high-spectral-resolution broadband ultraviolet-visible spectral imaging.",
                    "score": 0.8549907207489014
                },
                {
                    "id": 11249997,
                    "contents": "Non-linear Young's double-slit experiment.\nThe Young's double slit experiment is recreated using intense and short laser pulses. Our experiment evidences the role of the non-linear Kerr effect in the formation of interference patterns. In particular, our results evidence a mixed mechanism in which the zeroth diffraction order of each slit are mainly affected by self-focusing and self-phase modulation, while the higher orders propagate linearly. Despite of the complexity of the general problem of non-linear propagation, we demonstrate that this experiment retains its simplicity and allows for a geometrical interpretation in terms of simple optical paths. In consequence, our results may provide key ideas on experiments on the formation of interference patterns with intense laser fields in Kerr media.",
                    "score": 0.8549067974090576
                },
                {
                    "id": 17682689,
                    "contents": "Optical design of a multi-channel narrow-band imager for Lyman ultraviolet observation of diffuse sources.\nThis paper describes a novel optical design for a multi-channel narrow-band imager observing at the Lyman ultraviolet wavelengths. As one of the key instruments onboard the Census of Warm-Hot Intergalactic Medium, Accretion, and Feedback Explorer space mission, the imager is designed to map the neutral hydrogen Lyman-α line emissions from the intergalactic medium and nearby galaxies. The optical design features an instantaneous field of view (FOV) of 20 arc min in diameter and a moderate and adjustable spectral resolution of 500-2000. A highly dispersive monochromator system is used to split the incident light into several wavelength channels, each with a full-field imaging capability and adjustable bandwidth, and the ensuing imaging optics form the individual channel images on different areas of the same microchannel plate detector. Channel wavelengths are tunable and a continuous wavelength scanning across the entire band of interest is proposed, which yields spectrally resolved 3D images with moderate spectral resolutions.",
                    "score": 0.8545680046081543
                },
                {
                    "id": 9999916,
                    "contents": "Schwarzschild spectrometer.\nThis is a proposal and description of a new spectrometer based on the Schwarzschild optical system. The proposed design contains two Schwarzschild optical systems. Light diverging from the spectrometer entrance slit is collimated by the first one; the collimated light beam hits a planar diffraction grating and the light dispersed from the grating is focused by the second system, which is concentric with the first. A very simple procedure obtains designs that are anastigmatic for the center of the slit and for a particular wavelength. A specific example shows the performance of this type of spectrometer.",
                    "score": 0.8541564345359802
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_23",
        "question": "Calculate the energy and wavelength associated with an $\\alpha$ particle that has fallen through a potential difference of $4.0 \\mathrm{~V}$. Take the mass of an $\\alpha$ particle to be $6.64 \\times 10^{-27} \\mathrm{~kg}$.",
        "golden_answers": [
            " 1.3"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 11603208,
                    "contents": "Particle optics in the Rayleigh regime.\nLight scattering and absorption by particles suspended in the atmosphere modifies the transfer of solar energy in the atmosphere, thereby influencing global and regional climate change and atmospheric visibility. Of particular interest are the optical properties of particles in the Rayleigh regime, where particles are small compared with the wavelength of the scattered or absorbed light, because these particles experience little gravitational settlement and may have long atmospheric lifetimes. Optical properties of particles in the Rayleigh regime are commonly derived from electromagnetic theory using Maxwell's equations and appropriate boundary conditions. The size dependence of particle scattering and absorption are derived here from the most basic principles for coherent processes such as Rayleigh scattering (i.e., add amplitudes if in phase) and incoherent processes such as absorption (i.e., add cross sections), at the same time yielding understanding of the upper particle size limit for the Rayleigh regime. The wavelength dependence of Rayleigh scattering and absorption are also obtained by adding a basic scale invariance for particle optics. Simple consequences for particle single-scattering albedo (\"whiteness\") and the optical measurement of particle mass densities are explained. These alternative derivations complement the conventional understanding obtained from electromagnetic theory.",
                    "score": 0.8622470498085022
                },
                {
                    "id": 10456161,
                    "contents": "Approximate methods for modeling the scattering properties of nonspherical particles: evaluation of the Wentzel-Kramers-Brillouin method.\nSeveral approximate methods for modeling the electromagnetic (em) scattering properties of nonspherical particles are examined and evaluated. Although some of the approaches are applicable to arbitrary shapes we confine our attention here mainly to spheres and cylinders, for which exact solutions are available for comparisons. Evaluations include comparisons of the computed angular phase function, total extinction efficiency, and backscatter efficiency. Approximate methods investigated include the Rayleigh-Gans (RG) approximation, the Wentzel-Kramers-Brillouin or WKB approximation [and the closely related eikonal approximation (EA)], diffraction theory, and the second-order Shifrin iterative technique. Examples using spheres indicate that for weakly absorbing particles of moderate- to large-size parameters with a real refractive index near unity (i.e., the optically soft case), all models work well in representing the phase function over all scattering angles, with the Shifrin approximation showing the best agreement with the exact solutions. For larger refractive indices, however, the Shifrin approximation breaks down, whereas the WKB method continues to perform relatively well for all scattering angles over a wide range of particle sizes, including those appropriate in both the RG (small particle) and the diffraction (large particle) limits. The relationship between the WKB, eikonal, and anomalous diffraction descriptions of particle extinction is discussed briefly. Backscatter is also discussed in the context of the WKB model, and two modifications to improve the description are included: one to add an internal-reflected internal wave and the other to add a multiplicative scaling factor to preserve the correct backscatter result for strong absorption in the geometric optics limit. A major conclusion of the paper is that the WKB method offers a viable alternative to the more widely used RG and diffraction approximations and is a method that offers significant improvement in accuracy with only a slight increase in mathematical complexity.",
                    "score": 0.861180305480957
                },
                {
                    "id": 6538745,
                    "contents": "Yet another look at light scattering from particles in absorbing media.\nWe examine the scattering properties of particles contained in absorbing media. Rather than consider energy fluxes through arbitrary integrating spheres, we examine the extinction from its fundamental definition: the energy removed from the plane wave, or incident beam. The resulting energy received by a detector contains two terms: one the result of the incident beam traversing through the medium that would have occurred if the particle were not present, and a correction term due to the presence of the particle. Both terms have the same dependence on the pathlength that the beam travels between two arbitrarily located parallel planes and are independent of where the particle is located within the medium. The result is that the definition of the extinction cross section is not dependent on a reference plane or the particle location within the medium.",
                    "score": 0.8603617548942566
                },
                {
                    "id": 9271173,
                    "contents": "The spectroscopy and dynamics of microparticles.\nThe 137th Faraday Discussion covered a wide range of subjects divided into the four categories of Spectroscopic Techniques, Dusty Plasmas and X-Ray Characterization, Atmospheric Aerosols, and Particle Manipulation. These divisions organized the thinking into specific areas of research and allowed one to see interconnections between the two central foci of physical chemistry; techniques and applications. Physical chemists excel at developing and mastering a wide range of new techniques and applying them to a variety of tasks as the need arises. At times specific tasks present themselves and in response new techniques are developed. The presentations provided examples of both such interplays. In these remarks the presentations are summarized, common features are highlighted, and possible directions for future research are suggested.",
                    "score": 0.8599469661712646
                },
                {
                    "id": 9072243,
                    "contents": "Disentangling the volume effect through intensity-difference spectra: application to laser-induced dissociation of H2+.\nAn intensity-difference spectrum method is developed to disentangle the intensity volume effect inherent in focused laser beam interaction with gas-phase matter. This method is applicable to a Gaussian beam of constant axial intensity, which keeps the exact contribution from a predetermined intensity range and eliminates the contributions from lower intensities. We apply this method to the angularly resolved kinetic energy release spectrum of laser-induced dissociation of H2+. The difference spectrum at higher intensities is found to be dominated by the bond-softening process, and the distribution shifts to lower energy and becomes narrower with increasing intensity.",
                    "score": 0.8597233295440674
                },
                {
                    "id": 23109414,
                    "contents": "Photoelectron energy peaks shift against the radiation pressure in strong-field ionization.\nThe photoelectric effect describes the ejection of an electron upon absorption of one or several photons. The kinetic energy of this electron is determined by the photon energy reduced by the binding energy of the electron and, if strong laser fields are involved, by the ponderomotive potential in addition. It has therefore been widely taken for granted that for atoms and molecules, the photoelectron energy does not depend on the electron's emission direction, but theoretical studies have questioned this since 1990. Here, we provide experimental evidence that the energies of photoelectrons emitted against the light propagation direction are shifted toward higher values, while those electrons that are emitted along the light propagation direction are shifted to lower values. We attribute the energy shift to a nondipole contribution to the ponderomotive potential that is due to the interaction of the moving electrons with the incident photons.",
                    "score": 0.8566936254501343
                },
                {
                    "id": 11649691,
                    "contents": "Light propagation in moderately dense particle systems: a reexamination of the Kubelka-Munk theory.\nA numerical method (NM) is developed to characterize radiative transfer in a moderately dense particle population, i.e., a suspension of concentration of &lt;1-10% by volume. It assumes that the particles scatter in accord with the Mie equations, that the propagation of light over short distances is in accord with the exponential transmission law, and that the light flows in many (thirty-six) directions. For representative systems, predictions of the Kubelka-Munk theory (KMT) are compared with those of the NM; partial agreement is found. While this theory can be a useful tool, radiative transport in representative samples is found not to obey strictly either the assumptions for writing the basic differential equations of the KMT or those for solving them. The movement of diffuse light through an attenuating system is found to often collimate it, not to make it more diffuse as expected. This effect causes errors in absolute KMT predictions. New transport equations, like Schuster's, with four parameters instead of two are written and solved to obtain some new KMT equations. Their predictions are compared with those of the NM.",
                    "score": 0.855856716632843
                },
                {
                    "id": 11961059,
                    "contents": "Ab initio calculations of optical absorption spectra: solution of the Bethe-Salpeter equation within density matrix perturbation theory.\nWe describe an ab initio approach to compute the optical absorption spectra of molecules and solids, which is suitable for the study of large systems and gives access to spectra within a wide energy range. In this approach, the quantum Liouville equation is solved iteratively within first order perturbation theory, with a Hamiltonian containing a static self-energy operator. This procedure is equivalent to solving the statically screened Bethe-Salpeter equation. Explicit calculations of single particle excited states and inversion of dielectric matrices are avoided using techniques based on density functional perturbation theory. In this way, full absorption spectra may be obtained with a computational workload comparable to ground state Hartree-Fock calculations. We present results for small molecules, for the spectra of a 1 nm Si cluster in a wide energy range (20 eV), and for a dipeptide exhibiting charge transfer excitations.",
                    "score": 0.8545161485671997
                },
                {
                    "id": 18098862,
                    "contents": "Deviations from Beer's law on the microscale - nonadditivity of absorption cross sections.\nBeer's law assumes a linear dependence of absorbance on concentration, accordingly the index of absorption and the molar attenuation coefficient are material properties and the absorption cross section, including absorbance itself, must be additive if chemical interactions are excluded. Under the \"no interaction\" condition, a linear dependence should also exist between macroscopic polarization and the number of induced dipole moments per unit volume. The latter linear dependence is the basis for dispersion theory. Invoking Maxwell's wave equation, Beer's law has been derived recently from dispersion theory. As a result, Beer's law is a limiting law. Accordingly, indices of absorption and molar attenuation coefficients including absorption cross sections are no material properties and the latter can per se not be additive. Indeed, as we show in this contribution, not even for particles very small compared to wavelength, where the scattering cross sections can be neglected, is this additivity a given, except for comparably large distances between the particles. We investigate the magnitude of these critical distances with the help of finite difference time domain calculations for amorphous SiO2 spheres in the infrared spectral range. Based on electric field maps, we conclude that the deviations scale with oscillator strengths and, correspondingly, with local electric fields and nearfield effects.",
                    "score": 0.8537536859512329
                },
                {
                    "id": 14139034,
                    "contents": "Optical forces on small particles from partially coherent light.\nWe put forward a theory on the optical force exerted upon a dipolar particle by a stationary and ergodic partially coherent light field. We show through a rigorous analysis that the ensemble averaged electromagnetic force is given in terms of a partial gradient of the space-variable diagonal elements of the coherence tensor. Further, by following this result we characterize the conservative and nonconservative components of this force. In addition, we establish the propagation law for the optical force in terms of the coherence function of light at a diffraction plane. This permits us to evaluate the effect of the degree of coherence on the force components by using the archetypical configuration of Young's two-aperture diffraction pattern, so often employed to characterize coherence of waves.",
                    "score": 0.8531318306922913
                },
                {
                    "id": 12777053,
                    "contents": "Absolute absorption cross sections from photon recoil in a matter-wave interferometer.\nWe measure the absolute absorption cross section of molecules using a matter-wave interferometer. A nanostructured density distribution is imprinted onto a dilute molecular beam through quantum interference. As the beam crosses the light field of a probe laser some molecules will absorb a single photon. These absorption events impart a momentum recoil which shifts the position of the molecule relative to the unperturbed beam. Averaging over the shifted and unshifted components within the beam leads to a reduction of the fringe visibility, enabling the absolute absorption cross section to be extracted with high accuracy. This technique is independent of the molecular density, it is minimally invasive and successfully eliminates many problems related to photon cycling, state mixing, photobleaching, photoinduced heating, fragmentation, and ionization. It can therefore be extended to a wide variety of neutral molecules, clusters, and nanoparticles. ",
                    "score": 0.8529481887817383
                },
                {
                    "id": 6502806,
                    "contents": "Theory of the Kapitza-Dirac diffraction effect.\nWe treat the Kapitza-Dirac diffraction effect observed recently by Batelaan et al. using a newly developed nonperturbative quantum-field scattering theory. Our theory shows that an electron beam passing perpendicularly through a focused standing light wave can produce diffraction patterns. Our theory predicts (1) the minimum value of the ponderomotive energy is (Planck's over 2 pi omega)(2)/m(e)c(2), (2) the critical laser intensity above which the first pair of electron diffraction peaks will occur, and (3) the existence of sidebands in the electron spectra separated far from the central band by a momentum of several hundred photons. Our theory provides a unified explanation of the experimental results of Bucksbaum et al. and Batelaan et al.",
                    "score": 0.8525882363319397
                },
                {
                    "id": 11036881,
                    "contents": "Extinction and the optical theorem. Part I. Single particles.\nWe study the extinction caused by a single particle and present a conceptual phase-based explanation for the related optical theorem. Simulations of the energy flow caused by a particle's presence in a collimated beam of light demonstrate how the extinction process occurs. It is shown that extinction does not necessarily cause a reduction of the energy flow along the exact forward direction. Implications regarding the measurement of the single-particle extinction cross section are discussed. This work is extended to noninteracting and interacting multiparticle groups in Part II [J. Opt. Soc. Am. A25, pp. 1514 (2008)].",
                    "score": 0.8524712324142456
                },
                {
                    "id": 9968370,
                    "contents": "Absorption and scattering of light by small particles: the interference structure.\nWe point out errors in the derivation of the periodicity of the interference structure of the Mie extinction curve, recently published in ABSORPTION AND SCATTERING OFLIGHTBY SMALL PARTICLES, by C. F. Bohren and D. R. Huffman (Wiley, New York, 1983).",
                    "score": 0.8523534536361694
                },
                {
                    "id": 10525006,
                    "contents": "Using ultra-short pulses to determine particle size and density distributions.\nWe analyze the time dependent response of strongly scattering media (SSM) to ultra-short pulses of light. A random walk technique is used to model the optical scattering of ultra-short pulses of light propagating through media with random shapes and various packing densities. The pulse spreading was found to be strongly dependent on the average particle size, particle size distribution, and the packing fraction. We also show that the intensity as a function of time-delay can be used to analyze the particle size distribution and packing fraction of an optically thick sample independently of the presence of absorption features. Finally, we propose an all new way to measure the shape of ultra-short pulses that have propagated through a SSM.",
                    "score": 0.8523420095443726
                },
                {
                    "id": 8707230,
                    "contents": "Fundamental limits of the dispersion of the two-photon absorption cross section.\nWe rigorously apply the sum rules to the sum-over-states expression to calculate the fundamental limits of the dispersion of the two-photon absorption cross section. A comparison of the theory with the data suggests that the truncated sum rules in the three-level model give a reasonable fundamental limit. Furthermore, we posit that the two-photon absorption cross section near the limit must have only three dominant states, so by default, the three-level model is appropriate. This ansatz is supported by a rigorous analytical calculation that the resonant term gets smaller as more states are added. We also find that the contributions of the nonexplicitly resonant terms cannot be neglected when analyzing real molecules with many excited states, even near resonance. However, puzzling as it may be, extrapolating an off-resonant result to resonance using only the resonant term of the three-level model is shown to be consistent with the exact result. In addition, the off-resonant approximation is shown to scale logarithmically when compared with the full three-level model. This scaling can be used to simplify the analysis of measurements. We find that existing molecules are still far from the fundamental limit; so, there is room for improvement. But, reaching the fundamental limit would require precise control of the energy-level spacing, independently of the transition dipole moments-a task that does not appear possible using today's synthetic approaches. So, we present alternative methods that can still lead to substantial improvements which only require the control of the transition moment to the first excited state. While it is best to normalize measured two-photon absorption cross sections to the fundamental limits when comparing molecules, we show that simply dividing by the square of the number of electrons per molecule yields a good metric for comparison.",
                    "score": 0.8520398139953613
                },
                {
                    "id": 9097896,
                    "contents": "Gyroresonant surfing acceleration.\nWe discuss a new acceleration or energization mechanism of charged particles in space and astrophysical plasmas. In the presence of an electrostatic potential gradient and a circularly polarized electromagnetic monochromatic wave, particles are accelerated efficiently by keeping cyclotron resonance with the wave due to the electrostatic dragging force. In addition, particles can propagate against the electrostatic potential even if they have smaller parallel energy. This mechanism is potentially widely applicable, in terms of particle acceleration and transport, to various space and astrophysical phenomena, such as shock environment and short-large amplitude magnetic structures. We introduce the basic physical process of the acceleration or energization mechanism theoretically and numerically.",
                    "score": 0.850759744644165
                },
                {
                    "id": 19350727,
                    "contents": "A general approach for the calculation and characterization of x-ray absorption spectra.\nWe present a general approach for the calculation and assignment of X-ray absorption spectra based on electronic wavepacket propagations performed using explicitly time-dependent electronic structure calculations. Such calculations have the appeal of yielding the entire absorption spectrum for the cost of a single set of electronic wavepacket propagations, obviating the need to explicitly calculate large numbers of core-excited states. The spectrum can either be calculated from the Fourier transform of the time-dependent dipole moment or from the Fourier transform of the wavepacket autocorrelation function. We propose that calculating the absorption spectrum using the latter approach will generally be the preferred option. This method has two important advantages. First, the autocorrelation functions can be obtained for twice the propagation time, resulting in a halving of the computational effort required to calculate the spectrum relative to the time-dependent dipole moment approach. Second, using the tools of filter diagonalisation, the autocorrelation functions may be used to determine the time-independent final core-excited states underlying the peaks of interest in the spectrum. The proposed scheme is validated by calculating and characterizing the X-ray absorption spectra of benzene and trifluoroacetonitrile at the time-dependent second-order algebraic diagrammatic construction level of theory.",
                    "score": 0.850581705570221
                },
                {
                    "id": 13606498,
                    "contents": "Observing the onset of effective mass.\nThe response of a particle in a periodic potential to an applied force is commonly described by an effective mass, which accounts for the detailed interaction between the particle and the surrounding potential. Using a Bose-Einstein condensate of (87)Rb atoms initially in the ground band of an optical lattice, we experimentally show that the initial response of a particle to an applied force is in fact characterized by the bare mass. Subsequently, the particle response undergoes rapid oscillations and only over time scales that are long compared to those of the interband dynamics is the effective mass observed to be an appropriate description. Our results elucidate the role of the effective mass on short time scales, which is relevant for example in the interaction of few-cycle laser pulses with dielectric and semiconductor materials.",
                    "score": 0.8501681089401245
                },
                {
                    "id": 14442891,
                    "contents": "General description of electromagnetic radiation processes based on instantaneous charge acceleration in \"endpoints\".\nWe present a methodology for calculating the electromagnetic radiation from accelerated charged particles. Our formulation-the \"endpoint formulation\"-combines numerous results developed in the literature in relation to radiation arising from particle acceleration using a complete, and completely general, treatment. We do this by describing particle motion via a series of discrete, instantaneous acceleration events, or \"endpoints,\" with each such event being treated as a source of emission. This method implicitly allows for particle creation and destruction, and is suited to direct numerical implementation in either the time or frequency domains. In this paper we demonstrate the complete generality of our method for calculating the radiated field from charged particle acceleration, and show how it reduces to the classical named radiation processes such as synchrotron, Tamm's description of Vavilov-Cherenkov, and transition radiation under appropriate limits. Using this formulation, we are immediately able to answer outstanding questions regarding the phenomenology of radio emission from ultra-high-energy particle interactions in both the earth's atmosphere and the moon. In particular, our formulation makes it apparent that the dominant emission component of the Askaryan effect (coherent radio-wave radiation from high-energy particle cascades in dense media) comes from coherent \"bremsstrahlung\" from particle acceleration, rather than coherent Vavilov-Cherenkov radiation.",
                    "score": 0.849962055683136
                },
                {
                    "id": 6490065,
                    "contents": "Electromagnetic fields on a quantum scale. I.\nThis is the first in a series of two articles, the second of which provides an exact electro-magnetic field description of photon emission, absorption, and radiation pattern. Photon energy exchanges are analyzed and shown to be the triggered, regenerative response of a non-local eigenstate electron. This first article presents a model-based, hidden variable analysis of quantum theory that provides the statistical nature of wave functions. The analysis uses the equations of classical electro-magnetism and conservation of energy while modeling an eigenstate electron as a nonlocal entity. Essential to the analysis are physical properties that were discovered and analyzed only after the historical interpretation of quantum mechanics was established: electron non-locality and the standing electro-magnetic energy that accompanies and encompasses an active, electrically small volume. The standing energy produces a driving radiation reaction force that, under certain circumstances, is many orders of magnitude larger than currently accepted values. These properties provide a sufficient basis for the Schrödinger equation as a descriptor of non-relativistic eigenstate electrons in or near equilibrium. The uncertainty principle follows, as does the exclusion principle. The analysis leads to atomic stability and causality in the sense that the status of physical phenomena at any instant specifies the status an instant later.",
                    "score": 0.8498661518096924
                },
                {
                    "id": 16509072,
                    "contents": "Detecting radiation reaction at moderate laser intensities.\nWe propose a new method of detecting radiation reaction effects in the motion of particles subjected to laser pulses of moderate intensity and long duration. The effect becomes sizable for particles that gain almost no energy through the interaction with the laser pulse. Hence, there are regions of parameter space in which radiation reaction is actually the dominant influence on charged particle motion. ",
                    "score": 0.8496158123016357
                },
                {
                    "id": 9271172,
                    "contents": "Elastic light scattering from free sub-micron particles in the soft X-ray regime.\nWe report the first experimental results on angle-resolved elastic light scattering in the soft X-ray regime, where free sub-micron particles in the size regime between 150 and 250 nm are studied in the gas phase by using a continuous particle beam. Two different types of studies are reported: (i) Angle-resolved elastic light scattering experiments provide specific information on the scattering patterns in the regime of element-selective inner-shell excitation near the Si 2p-edge (80-150 eV). In addition to intense forward scattering, we observe distinct features in the angle-resolved scattering patterns. These are modelled by using Mie theory as well as a model that includes contributions from diffuse and specular reflection. The results are primarily attributed to scattering from soft X-rays in the surface layer. (ii) Spectroscopic experiments are reported, where the photon detector is placed at a given scattering angle while scanning the photon energy near the Si 2p-absorption edge. These results are also analyzed by a Mie model, yielding accurate information of the size distribution.",
                    "score": 0.8494284749031067
                },
                {
                    "id": 14279005,
                    "contents": "Large molecules reveal a linear length scaling for double photoionization.\nWe have measured the ratio of doubly to singly charged parent ions of benzene, naphthalene, anthracene, and pentacene using monochromatized synchrotron radiation up to 30 eV above the corresponding threshold. Our measurements show a striking similarity between the ratio of doubly charged to all parent ions and the ratio for helium. Moreover, the magnitudes of the ratios for these molecules scale linearly with their lengths with an amazing accuracy. A high ratio, i.e., a high relative double-photoionization probability, makes a molecule an important source of low-energy electrons that can promote radiation damage of biomolecules [B. Boudaïffa et al., Science 287, 1658 (2000)].",
                    "score": 0.8493950963020325
                },
                {
                    "id": 3239887,
                    "contents": "A solution to the Yang equation with electron energy loss following Harder's formula.\nThe Yang diffusion transport equation for charged particles was modified to allow the linear angular scattering power to vary with penetration depth in the scattering medium. Assuming charged particle energy loss to be a linear function of depth, conditional solutions to this transport equation have been found for the two cases of interest specified by Yang. The normalized excess path length distributions predicted for a 10-MeV electron beam show a shift toward larger excess path lengths compared to Yang's solutions.",
                    "score": 0.8493901491165161
                },
                {
                    "id": 9611020,
                    "contents": "Photon propagation function: spectral analysis of its asymptotic form.\nThe physical attitudes of source theory, displacing those of renormalized, perturbative, operator field theory, are used in a simple discussion of the asymptotic behavior of the photon propagation function. A guiding principle is the elementary consistency requirement that, under circumstances where a physical parameter cannot be accurately measured, no sensitivity to its precise value can enter the description of those circumstances. The mathematical tool is the spectral representation of the propagation function, supplemented by an equivalent phase representation. The Gell-Mann-Low equation is recovered, but with their function now interpreted physically as the spectral weight function. A crude inequality is established for the latter, which helps in interpolating between the initial rising behavior and the ultimate zero at infinite mass. There is a brief discussion of the aggressive source theory viewpoint that denies the existence of a \"bare charge\".",
                    "score": 0.8492498397827148
                },
                {
                    "id": 21232937,
                    "contents": "Light of Two Atoms in Free Space: Bunching or Antibunching?\nPhoton statistics divides light sources into three different categories, characterized by bunched, antibunched, or uncorrelated photon arrival times. Single atoms, ions, molecules, or solid state emitters display antibunching of photons, while classical thermal sources exhibit photon bunching. Here we demonstrate a light source in free space, where the photon statistics depends on the direction of observation, undergoing a continuous crossover between photon bunching and antibunching. We employ two trapped ions, observe their fluorescence under continuous laser light excitation, and record spatially resolved the autocorrelation function g^{(2)}(τ) with a movable Hanbury Brown and Twiss detector. Varying the detector position we find a minimum value for antibunching, g^{(2)}(0)=0.60(5) and a maximum of g^{(2)}(0)=1.46(8) for bunching, demonstrating that this source radiates fundamentally different types of light alike. The observed variation of the autocorrelation function is understood in the Dicke model from which the observed maximum and minimum values can be modeled, taking independently measured experimental parameters into account.",
                    "score": 0.8483849167823792
                },
                {
                    "id": 10823336,
                    "contents": "Distribution of r·p in atomic systems.\nWe present formulas for computing the probability distribution of the posmom s = r · p in atoms, when the electronic wave function is expanded in a single particle Gaussian basis. We study the posmom density, S(s), for the electrons in the ground states of 36 lightest atoms (H-Kr) and construct an empirical model for the contribution of each atomic orbital to the total S(s). The posmom density provides unique insight into types of trajectories electrons may follow, complementing existing spectroscopic techniques that provide information about where electrons are (X-ray crystallography) or where they go (Compton spectroscopy). These, a priori, predictions of the quantum mechanically observable posmom density provide an challenging target for future experimental work.",
                    "score": 0.8483470678329468
                },
                {
                    "id": 7830278,
                    "contents": "Theory of time-dependent reactive scattering: cumulative time-evolving differential cross sections and nearside-farside analyses of time-dependent scattering amplitudes for the H + D2 --&gt; HD + D reaction.\nNearside-farside (NF) theory, originally developed in the energy domain for the time-independent description of molecular collisions and chemical reactions, is applied to the plane wave packet (PWP) formulation of time-dependent scattering. The NF theory decomposes the partial wave series representation for the time-dependent PWP scattering amplitude into two time-dependent subamplitudes: one N, the other F. In addition, NF local angular momentum (LAM) theory is applied to the PWP scattering amplitude. The novel concept of a cumulative time-evolving differential cross section is introduced, in which the upper infinite time limit of a half-Fourier transform is replaced by a finite time. In a similar way, a cumulative energy-evolving angular distribution is defined. Application is made to the state-to-state reaction, H + D2(v(i) = 0, j(i) = 0) --&gt; HD(v(f) = 3, j(f) = 0) + D, where v(i), j(i) and v(f), j(f) are vibrational and rotational quantum numbers for the initial and final states, respectively. This reaction exhibits time-direct and time-delayed (by about 25 fs) collision mechanisms. It is shown that the direct-time mechanism is N dominant scattering, whereas the time-delayed mechanism exhibits characteristics of NF interference. The NF and LAM theories provide valuable insights into the time-dependent properties of a reaction, as do snapshots from a movie of the cumulative time-evolving differential cross section.",
                    "score": 0.8483167290687561
                },
                {
                    "id": 11466581,
                    "contents": "Improvements to the spectral transparency method for determining particle-size distribution.\nThe previously developed spectral transparency method is improved in two ways: (a) A calculation scheme is developed that enables the consideration of light dispersion within a substance. We abandon the assumption that m(nu) = const and develop a method of calculating N(r) from gamma*(nu) provided that the function m(nu) is specified. (b) A new scheme of processing data on gamma*(nu)is proposed that significantly reduces the oscillation in the answer and requires less initial experimental data.",
                    "score": 0.8478423953056335
                },
                {
                    "id": 23614009,
                    "contents": "Effect of the finite speed of light in ionization of extended molecular systems.\nWe study propagation effects due to the finite speed of light in ionization of extended molecular systems. We present a general quantitative theory of these effects and show under which conditions such effects should appear. The finite speed of light propagation effects are encoded in the non-dipole terms of the time-dependent Shrödinger equation and display themselves in the photoelectron momentum distribution projected on the molecular axis. Our numerical modeling for the [Formula: see text] molecular ion and the [Formula: see text] dimer shows that the finite light propagation time from one atomic center to another can be accurately determined in a table top laser experiment which is much more readily accessible than the ground breaking synchrotron measurement by Grundmann et al. (Science 370:339, 2020).",
                    "score": 0.8474946618080139
                },
                {
                    "id": 21149683,
                    "contents": "Mie scattering revisited: Study of bichromatic Mie scattering of electromagnetic waves by a distribution of spherical particles.\nTwo experiments to measure the size of microscopic dielectric spherical particles immersed in purified water with spheres of a nominal diameter 5.2 ± 0.15 μm have been carried out in order to revisit Mie scattering techniques. The first experiment uses a 1 mW helium-neon (He-Ne) laser with a wavelength of 632.8 nm, while the second one is carried out using a diode laser of 780.0 nm wavelength and a nominal power of 80 mW. The distribution of the scattered light intensity is recorded experimentally, and since the theoretical background has been known for several decades (see references), only a modest amount of theory is included. We considered the Mie scattering by a set of spheres of different diameters in our case with a distribution of sphere diameters with mean diameter 5.2 μm and standard deviation 0.15 μm. Our measured Mie scattering angular distribution accounts for the effect of the diameter distribution, which we assume to be a Gaussian distribution. Our results indicate that there is very good agreement between experiment and theoretical predictions. The technique we offer here is found to be useful to familiarize technicians who work in the areas of applied optics, such as chemistry, electronics, water contamination, and optical instruments with Mie scattering techniques, and who may not have a formal introduction to the electromagnetic theory. One specific area in which these techniques might be useful is the study of aerosols that may arise when naturally produced droplets from humans, such as those produced by coughing, sneezing, talking, and breathing, are present, as it happens in response to the Severe Acute Respiratory Syndrome Coronavirus 2, also known as SARS-CoV-2.",
                    "score": 0.847184956073761
                },
                {
                    "id": 13180479,
                    "contents": "Time-, frequency-, and wavevector-resolved x-ray diffraction from single molecules.\nUsing a quantum electrodynamic framework, we calculate the off-resonant scattering of a broadband X-ray pulse from a sample initially prepared in an arbitrary superposition of electronic states. The signal consists of single-particle (incoherent) and two-particle (coherent) contributions that carry different particle form factors that involve different material transitions. Single-molecule experiments involving incoherent scattering are more influenced by inelastic processes compared to bulk measurements. The conditions under which the technique directly measures charge densities (and can be considered as diffraction) as opposed to correlation functions of the charge-density are specified. The results are illustrated with time- and wavevector-resolved signals from a single amino acid molecule (cysteine) following an impulsive excitation by a stimulated X-ray Raman process resonant with the sulfur K-edge. Our theory and simulations can guide future experimental studies on the structures of nano-particles and proteins. ",
                    "score": 0.8468774557113647
                },
                {
                    "id": 23805837,
                    "contents": "Particle trajectories, gamma-ray emission, and anomalous radiative trapping effects in magnetic dipole wave.\nIn studies of interaction of matter with laser fields of extreme intensity there are two limiting cases of a multibeam setup maximizing either the electric field or the magnetic field. In this work attention is paid to the optimal configuration of laser beams in the form of an m-dipole wave, which maximizes the magnetic field. We consider in such highly inhomogeneous fields the advantages and specific features of laser-matter interaction, which stem from individual particle trajectories that are strongly affected by gamma photon emission. It is shown that in this field mode qualitatively different scenarios of particle dynamics take place in comparison with the mode that maximizes the electric field. A detailed map of possible regimes of particle motion (ponderomotive trapping, normal radiative trapping, radial, and axial anomalous radiative trapping), as well as angular and energy distributions of particles and gamma photons, is obtained in a wide range of laser powers up to 300 PW, and it reveals signatures of radiation losses experimentally detectable even with subpetawatt lasers.",
                    "score": 0.8467170000076294
                },
                {
                    "id": 20319978,
                    "contents": "Speed of sound from fundamental physical constants.\nTwo dimensionless fundamental physical constants, the fine structure constant α and the proton-to-electron mass ratio [Formula: see text], are attributed a particular importance from the point of view of nuclear synthesis, formation of heavy elements, planets, and life-supporting structures. Here, we show that a combination of these two constants results in a new dimensionless constant that provides the upper bound for the speed of sound in condensed phases, <iv<subu</sub</i We find that [Formula: see text], where <ic</i is the speed of light in vacuum. We support this result by a large set of experimental data and first-principles computations for atomic hydrogen. Our result expands the current understanding of how fundamental constants can impose new bounds on important physical properties.",
                    "score": 0.8466351628303528
                },
                {
                    "id": 18688602,
                    "contents": "The partial light scattering cross section of spherical particles.\nWe define the partial scattering cross section and partial efficiencies to demonstrate that the total scattering is the sum of two roughly equal parts: approximately half from the forward scattering lobe due to 2D diffraction by the projected sphere and half from the 2D to 3D diffraction crossover. The first part is at angles such that θ≲λ/D, a result previously known, which can be quite small for large particles. The second part is in a new regime we call the \"hump,\" visible in q-space, which to a good approximation contains the other half of the scattered light. The hump disappears when the imaginary part of the refractive index is significant.",
                    "score": 0.846429705619812
                },
                {
                    "id": 11294200,
                    "contents": "Light scattering by an arbitrary particle: a physical reformulation of the coupled dipole method.\nThe coupled dipole model of scattering by an arbitrary particle has been reformulated in terms of internal scattering processes of all orders. This formalism readily permits physical interpretation of observables and provides a rational basis for making computations more efficient. The calculation of scattering parameters can be simplified by appropriately terminating the infinite series at any order as well as by restricting the summations over the dipolar interaction terms within each order. Large particles can be partitioned into segments so that the scattered field is a superposition of the fields from the segments together with fields due to interactions among dipoles in different segments.",
                    "score": 0.84622722864151
                },
                {
                    "id": 10273804,
                    "contents": "The size of the proton.\nThe proton is the primary building block of the visible Universe, but many of its properties-such as its charge radius and its anomalous magnetic moment-are not well understood. The root-mean-square charge radius, r(p), has been determined with an accuracy of 2 per cent (at best) by electron-proton scattering experiments. The present most accurate value of r(p) (with an uncertainty of 1 per cent) is given by the CODATA compilation of physical constants. This value is based mainly on precision spectroscopy of atomic hydrogen and calculations of bound-state quantum electrodynamics (QED; refs 8, 9). The accuracy of r(p) as deduced from electron-proton scattering limits the testing of bound-state QED in atomic hydrogen as well as the determination of the Rydberg constant (currently the most accurately measured fundamental physical constant). An attractive means to improve the accuracy in the measurement of r(p) is provided by muonic hydrogen (a proton orbited by a negative muon); its much smaller Bohr radius compared to ordinary atomic hydrogen causes enhancement of effects related to the finite size of the proton. In particular, the Lamb shift (the energy difference between the 2S(1/2) and 2P(1/2) states) is affected by as much as 2 per cent. Here we use pulsed laser spectroscopy to measure a muonic Lamb shift of 49,881.88(76) GHz. On the basis of present calculations of fine and hyperfine splittings and QED terms, we find r(p) = 0.84184(67) fm, which differs by 5.0 standard deviations from the CODATA value of 0.8768(69) fm. Our result implies that either the Rydberg constant has to be shifted by -110 kHz/c (4.9 standard deviations), or the calculations of the QED effects in atomic hydrogen or muonic hydrogen atoms are insufficient.",
                    "score": 0.8459142446517944
                },
                {
                    "id": 7157205,
                    "contents": "Optical forces on small particles: attractive and repulsive nature and plasmon-resonance conditions.\nA detailed study of time-averaged electromagnetic forces on subwavelength-sized particles is presented. An analytical decomposition of the force into gradient and scattering-plus-absorption components is carried out, on the basis of which the attractive or repulsive behavior of the force is explained. Small metallic particles are shown to experience both kinds of forces; which kind also depends on the excitation of surface plasmons. Resonances give rise to enhancements of both the scattering and the absorption forces, but the gradient force can become negligible. Also, close to resonant wavelengths, the gradient force can be maximum, while both the scattering and the absorption forces remain large. Comparisons of analytic results with rigorous calculations allow the establishment of ranges of validity of the dipolar approximation for these forces.",
                    "score": 0.8458530306816101
                },
                {
                    "id": 8199962,
                    "contents": "Multiple scattering by particles embedded in an absorbing medium. 1. Foldy-Lax equations, order-of-scattering expansion, and coherent field.\nThis paper presents a systematic analysis of the problem of multiple scattering by a finite group of arbitrarily sized, shaped, and oriented particles embedded in an absorbing, homogeneous, isotropic, and unbounded medium. The volume integral equation is used to derive generalized Foldy-Lax equations and their order-of-scattering form. The far-field version of the Foldy-Lax equations is used to derive the transport equation for the so-called coherent field generated by a large group of sparsely, randomly, and uniformly distributed particles. The differences between the generalized equations and their counterparts describing multiple scattering by particles embedded in a non-absorbing medium are highlighted and discussed.",
                    "score": 0.8457440137863159
                },
                {
                    "id": 8793767,
                    "contents": "A line-shape function in terms of changes in both molecular structure and force constants: a Gaussian approximation.\nWe propose a new expression of a line-shape function (LSF) including the effects of changes in both force constants and the molecular structure within the harmonic-oscillator approximation. This expression enables us to calculate the LSF using only the data on molecular structures, force constants, and electronic energies in the initial and final electronic states without solving the eigenvalue equation for the normal vibration of a molecule. To derive the LSF expression, we consider one-photon emission from a polyatomic molecule thermalized in an electronic excited state, and derive the intensity distribution function for one-photon emission using not Lax and Kubo and Toyozawa's [J. Chem. Phys. 20, 1752 (1952); Prog. Theor. Phys. 13, 160 (1955)] generating function method but rather the density-matrix method. As a simple application, a Gaussian approximate LSF is applied to SO(2). As a result, it is found that the effect of change in force constants between the initial and final electronic states cannot be ignored, nor can the effect of change in the molecular structure between these two states. The LSF expression obtained is applicable to studies of not only radiative transition but also of electron-transfer and energy-transfer processes where both changes in molecular structure and force constants between the initial and final electronic states cannot be disregarded.",
                    "score": 0.8455022573471069
                },
                {
                    "id": 14295602,
                    "contents": "Near-field: a finite-difference time-dependent method for simulation of electrodynamics on small scales.\nWe develop near-field (NF), a very efficient finite-difference time-dependent (FDTD) approach for simulating electromagnetic systems in the near-field regime. NF is essentially a time-dependent version of the quasistatic frequency-dependent Poisson algorithm. We assume that the electric field is longitudinal, and hence propagates only a set of time-dependent polarizations and currents. For near-field scales, the time step (dt) is much larger than in the usual Maxwell FDTD approach, as it is not related to the velocity of light; rather, it is determined by the rate of damping and plasma oscillations in the material, so dt = 2.5 a.u. was well converged in our simulations. The propagation in time is done via a leapfrog algorithm much like Yee's method, and only a single spatial convolution is needed per time step. In conjunction, we also develop a new and very accurate 8 and 9 Drude-oscillators fit to the permittivity of gold and silver, desired here because we use a large time step. We show that NF agrees with Mie-theory in the limit of small spheres and that it also accurately describes the evolution of the spectral shape as a function of the separation between two gold or silver spheres. The NF algorithm is especially efficient for systems with small scale dynamics and makes it very simple to introduce additional effects such as embedding.",
                    "score": 0.8454769849777222
                },
                {
                    "id": 12729844,
                    "contents": "Communication: Spectral representation of the Lamb shift for atomic and molecular calculations.\nA spectral representation of the self-energy based on hydrogenic atomic data is examined for its usefulness to evaluate the self-energy of many-electron atoms, and thus its potential for molecular calculations. Use of the limited hydrogenic data with a diagonal projection overestimates the valence self-energy by an order of magnitude. The same diagonal projection for the vacuum polarization produces a similar overestimate, but a full projection produces values that are within a factor of 2 of the exact value, as does a density-fitting procedure. ",
                    "score": 0.845434308052063
                },
                {
                    "id": 9181635,
                    "contents": "Exact solution of Maxwell's equations for optical interactions with a macroscopic random medium: addendum.\nThis Addendum provides a revised set of figures containing converged numerical data for total scattering cross section (TSCS), replacing the figures in our recent publication [Opt. Lett. 29, 1393 (2004)]. Due to the use of an overly large time step, our original TSCS data exhibited a systematic, nonphysical diminution above 150 THz for all cases studied. We have determined that numerical convergence in the temporal sense for the pseudospectral time-domain (PSTD) algorithm employed previously requires limiting the time step to no more than 1/60th of the sinusoidal period at the maximum frequency of interest, which in the previous case was 300 THz. This is an important point that we hereby report to future users of PSTD simulations in electrodynamics and optics. Note that all our original conclusions remain valid.",
                    "score": 0.844961404800415
                },
                {
                    "id": 23092694,
                    "contents": "Mutually guided light and particle beam propagation.\nThe polarizability of atoms and molecules gives rise to optical forces that trap particles and a refractive index that guides light beams, potentially leading to a self-guided laser and particle beam propagation. In this paper, the mutual interactions between an expanding particle beam and a diffracting light beam are investigated using an axisymmetric particle-light coupled simulation. The nonlinear coupling between particles and photons is dependent on the particle beam radius, particle density, particle velocity and temperature, polarizability, light beam waist, light frequency (with respect to the resonance frequency), and light intensity. The computational results show that the maximum propagation distance is achieved when the waveguiding effect is optimized to single-mode operation. The application of the coupled beam propagation as a space propulsion system is discussed.",
                    "score": 0.8449015021324158
                },
                {
                    "id": 6545697,
                    "contents": "Energy distributions in multiple photon absorption experiments.\nPhotofragmentation experiments on molecules and clusters often involve multiple photon absorption. The distributions of the absorbed number of photons are frequently approximated by Poisson distributions. For realistic laser beam profiles, this approximation fails seriously due to the spatial variation of the mean number of absorbed photons across the laser beam. We calculate the distribution of absorbed energy for various laser and molecular-beam parameters. For a Gaussian laser beam, the spatially averaged distributions have a power-law behavior for low energy with a cutoff at an energy which is proportional to fluence. The power varies between -1 for an almost parallel laser beam and -5/2 for a divergent beam (on the scale of the molecular beam). We show that the experimental abundance spectra of fullerenes and small carbon clusters can be used to reconstruct the distribution of internal energy in the excited C60 molecule prior to fragmentation and find good agreement with the calculated curves.",
                    "score": 0.8448110818862915
                },
                {
                    "id": 22288720,
                    "contents": "Bethe-Salpeter equation spectra for very large systems.\nWe present a highly efficient method for the extraction of optical properties of very large molecules via the Bethe-Salpeter equation. The crutch of this approach is the calculation of the action of the effective Coulombic interaction, W, through a stochastic time-dependent Hartree propagation, which uses only ten stochastic orbitals rather than propagating the full sea of occupied states. This leads to a scaling that is at most cubic in system size with trivial parallelization of the calculation. We apply this new method to calculate the spectra and electronic density of the dominant excitons of a carbon-nanohoop bound fullerene system with 520 electrons using less than 4000 core hours.",
                    "score": 0.8445134162902832
                },
                {
                    "id": 18412525,
                    "contents": "Light Emission from Gold Nanoparticles under Ultrafast Near-Infrared Excitation: Thermal Radiation, Inelastic Light Scattering, or Multiphoton Luminescence?\nGold nanoparticles emit broad-band upconverted luminescence upon irradiation with pulsed infrared laser radiation. Although the phenomenon is widely observed, considerable disagreement still exists concerning the underlying physics, most notably over the applicability of concepts such as multiphoton absorption, inelastic scattering, and interband vs intraband electronic transitions. Here, we study single particles and small clusters of particles by employing a spectrally resolved power-law analysis of the irradiation-dependent emission as a sensitive probe of these physical models. Two regimes of emission are identified. At low irradiance levels of kW/cm<sup2</sup, the emission follows a well-defined integer-exponent power law suggestive of a multiphoton process. However, at higher irradiance levels of several kW/cm<sup2</sup, the nonlinearity exponent itself depends on the photon energy detected, a tell-tale signature of a radiating heated electron gas. We show that in this regime, the experiments are incompatible with both interband transitions and inelastic light scattering as the cause of the luminescence, whereas they are compatible with the notion of luminescence linked to intraband transitions.",
                    "score": 0.843995213508606
                },
                {
                    "id": 10462372,
                    "contents": "Physically reasonable analytic expression for the single-scattering phase function.\nAn analytic phase function that reduces to the Rayleigh phase function for the scattering of unpolarized light is presented and compared with the traditional Henyey-Greenstein phase function. Comparisons between the proposed phase function and the phase function for three of Deirmendjian's polydispersions are shown and applications to radiative transfer are demonstrated.",
                    "score": 0.8439661264419556
                },
                {
                    "id": 8616089,
                    "contents": "Scaling of wave-packet dynamics in an intense midinfrared field.\nA theoretical investigation is presented that examines the wavelength scaling from near-visible (0.8 micro m) to midinfrared (2 micro m) of the photoelectron distribution and high harmonics generated by a \"single\" atom in an intense electromagnetic field. The calculations use a numerical solution of the time-dependent Schrödinger equation (TDSE) in argon and the strong-field approximation in helium. The scaling of electron energies (lambda2), harmonic cutoff (lambda2), and attochirp (lambda -1) agree with classical mechanics, but it is found that, surprisingly, the harmonic yield follows a lambda -(5-6) scaling at constant intensity. In addition, the TDSE results reveal an unexpected contribution from higher-order returns of the rescattering electron wave packet.",
                    "score": 0.8439447283744812
                }
            ],
            "metric_score": {
                "retrieval_recall": 1,
                "retrieval_precision": 0.2
            }
        }
    },
    {
        "id": "test_24",
        "question": "Calculate the number of photons in a $2.00 \\mathrm{~mJ}$ light pulse at (a) $1.06 \\mu \\mathrm{m}$\r\n",
        "golden_answers": [
            " 1.07"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 19751266,
                    "contents": "Photons to the left, photons to the right, photons down under: editorial.\nEditor-in-Chief P. Scott Carney introduces the Journal's newest Topical Editor, Arti Agrawal.",
                    "score": 0.8741708993911743
                },
                {
                    "id": 9553079,
                    "contents": "The efficiency curve: a new function.\nWorking from first principles, an efficiency curve function has been developed by considering the physics of photon transport through matter. The function has been compared to other function in popular usage and been found to fit the data better especially about the knee of the curve. The main disadvantage of the new function is that it is data hungry, but this can be overcome by use of Monte Carlo simulations.",
                    "score": 0.8714779019355774
                },
                {
                    "id": 18985783,
                    "contents": "Generator of arbitrary classical photon statistics.\nWe propose and experimentally demonstrate a device for generating light with arbitrary classical photon-number distribution. We use programmable acousto-optical modulation to control the intensity of light within the dynamic range of more than 30 dB and inter-level transitions faster than 500 ns. We propose a universal method that allows the high-fidelity generation of user-defined photon statistics. Extremely high precision &lt;0.001 can be reached for lower photon numbers, and faithful tail behavior can be reached for very high photon numbers. We demonstrate arbitrary statistics generation for up to 500 photons. The proposed device can produce any classical light statistics with given parameters including Poissonian, super-Poissonian, thermal, and heavy-tailed distributions like log-normal. The presented method can be used to simulate communication channels, calibrate the response of photon-number-resolving detectors, or probe physical phenomena sensitive to photon statistics.",
                    "score": 0.8709184527397156
                },
                {
                    "id": 8657344,
                    "contents": "Photon correlation and scattering: introduction to the feature issue.\nThis special issue of Applied Optics contains research papers on photon correlation and scattering, many of which were presented at the OSA Topical Meeting that was held 16-18 August 2004.",
                    "score": 0.8633339405059814
                },
                {
                    "id": 9857524,
                    "contents": "Invited review article: Single-photon sources and detectors.\nWe review the current status of single-photon-source and single-photon-detector technologies operating at wavelengths from the ultraviolet to the infrared. We discuss applications of these technologies to quantum communication, a field currently driving much of the development of single-photon sources and detectors.",
                    "score": 0.8621370792388916
                },
                {
                    "id": 7327423,
                    "contents": "Comment on \"Excitation with a focused, pulsed optical beam in scattering media: diffraction effects\".\nTo incorporate the wave properties of light, it was recently proposed to modify the Monte Carlo-based photon transport model to a semi-quantum-mechanical representation by considering each ray as a photon wave packet [Appl. Opt. 39, 5244 (2000)]. It is not clear from the paper whether each photon wave packet is considered representative of an entire plane wave or if each is spatially localized. However, for each interpretation we identify problems with the approach suggested for combining the wave-packet contributions. These include violation of the principle of conservation of energy and the use of a scattering phase function that is incompatible with the suggested way of calculating the intensity values. These issues render the approach impractical.",
                    "score": 0.8617797493934631
                },
                {
                    "id": 12771000,
                    "contents": "Fast and accurate propagation of coherent light.\nWe describe a fast algorithm to propagate, for any user-specified accuracy, a time-harmonic electromagnetic field between two parallel planes separated by a linear, isotropic and homogeneous medium. The analytical formulation of this problem (ca 1897) requires the evaluation of the so-called Rayleigh-Sommerfeld integral. If the distance between the planes is small, this integral can be accurately evaluated in the Fourier domain; if the distance is very large, it can be accurately approximated by asymptotic methods. In the large intermediate region of practical interest, where the oscillatory Rayleigh-Sommerfeld kernel must be applied directly, current numerical methods can be highly inaccurate without indicating this fact to the user. In our approach, for any user-specified accuracy <iϵ</i&gt;0, we approximate the kernel by a short sum of Gaussians with complex-valued exponents, and then efficiently apply the result to the input data using the unequally spaced fast Fourier transform. The resulting algorithm has computational complexity [Formula: see text], where we evaluate the solution on an <iN</i×<iN</i grid of output points given an <iM</i×<iM</i grid of input samples. Our algorithm maintains its accuracy throughout the computational domain.",
                    "score": 0.8582248687744141
                },
                {
                    "id": 10541281,
                    "contents": "Elementary functions: propagation of partially coherent light.\nThe theory of propagation of partially coherent light is well known, but performing numerical calculations still presents a difficulty because of the dimensionality of the problem. We propose using a recently introduced method based on the use of elementary functions [Wald et al. Proc. SPIE6040, 59621G (2005)] to reduce the integrals to two dimensions. We formalize the method, describe its inherent assumptions and approximations, and introduce a sampling criterion for adequate interpolation. We present an analysis of some special cases, such as the Gaussian Schell-model beam, and briefly discuss generalized numerical propagation of two-dimensional field distributions.",
                    "score": 0.8577403426170349
                },
                {
                    "id": 10305778,
                    "contents": "Probability distributions for the integrated intensity and photocount associated with a K-distribution for laser intensity.\nA numerical approach is used for evaluating the probability density functions of the integrated intensity and photocount when the received laser intensity obeys a K-distribution. Different scattering strengths are considered for comparisons. Also, those probability distribution functions based on a generalized K-distribution and a lognormally modulated exponential distribution for the laser intensity are computed and compared with those based on the K-distribution. Some general trends are drawn. The accuracy of our numerical computations is also discussed.",
                    "score": 0.8572206497192383
                },
                {
                    "id": 9617205,
                    "contents": "Photon propagation function: a comparison of asymptotic functions.\nAn earlier paper asserts the logarithmic asymptotic identity of various asymptotic functions associated with the photon propagation function, including the spectral weight function and the Gell-Mann-Low function. This note exhibits explicit expressions for the deviations between pairs of functions. It is emphasized that the differences are quantitatively small, and that the various functions have common qualitative characteristics. The discussion refers to a particular method for comparing the functions, which has no special physical status. When that restriction is removed, it becomes possible to prove the general existence of a transformation of variable that will produce the Gell-Mann-Low function from the spectral weight function. This supplies a physical interpretation that has otherwise been missing in the Gell-Mann-Low approach.",
                    "score": 0.8569852113723755
                },
                {
                    "id": 5197362,
                    "contents": "Observation of nonclassical photon statistics due to quantum interference.\nPhase-dependent photon statistics is observed in the mixed field of a narrow band two-photon source and a coherent field. At a certain phase, the nonclassical effect of photon antibunching occurs while at another the photon bunching effect appears. Furthermore, we observed a novel nonclassical phenomenon that exhibits more complex structure. The different features in photon statistics are attributed to a two-photon interference effect.",
                    "score": 0.856869101524353
                },
                {
                    "id": 11274761,
                    "contents": "Photon-counting statistics of pulsed light sources.\nWe report measurement of the photon-counting distributions of nanosecond-duration light pulses. Photon counting is performed on light sources with widely different photon statistics, such as (1) a Q-switched Nd:YAG-laserpumped dye laser operating well above threshold and producing single-mode nanosecond pulses, (2) the same laser operating close to threshold, and (3) a rotating ground-glass aberrator illuminated by the laser pulses of case (1). The method is particularly suitable for the investigation of the statistics of light generated by the nonlinear interaction of radiation with matter.",
                    "score": 0.856766939163208
                },
                {
                    "id": 19633432,
                    "contents": "Measurement of the transverse spatial quantum state of light at the single-photon level: publisher's note.\nThis publisher's note amends the author listing of Opt. Lett.30, 3365 (2005)OPLEDP0146-959210.1364/OL.30.003365.",
                    "score": 0.8532971739768982
                },
                {
                    "id": 10516366,
                    "contents": "Rayleigh centennial.\nThis brief sketch of the contributions of the fourth Baron Rayleigh is intended to supplement the biographical material contained in the October 1964 issue of Applied Optics.",
                    "score": 0.8531484603881836
                },
                {
                    "id": 7949094,
                    "contents": "Two quantum-mechanical photocount formulas.\nWe derive two quantum-mechanical photocount formulas when a light field's density operator rho is known; one involves rho's coherent state mean value and the other involves rho's Wigner function; when this information is known, then using these two formulas to calculate the photocount would be convenient. We employ the technique of integration within an antinormally ordered (or Weyl-ordered) product of operators in our derivation.",
                    "score": 0.8527684807777405
                },
                {
                    "id": 20388031,
                    "contents": "Coherent light brightens the quantum science frontier.\nControlling coherent light across a vast spectral range enables ultraprecise measurements and the quantum control of atomic, molecular, and condensed-matter systems.",
                    "score": 0.8520307540893555
                },
                {
                    "id": 9936904,
                    "contents": "Simple method of measuring the duration of short laser pulses.\nWe present a simple method to determine the duration of short laser pulses by measuring the efficiency of a second harmonic generation experiment.",
                    "score": 0.8504610061645508
                },
                {
                    "id": 9961053,
                    "contents": "[Dirichlet's Theorem].\nIn the introduction to Chapter II of his work L'Intégrale de Fourier et ses Applications à l'Optique, Duffieux reduces Dirichlet's Theorem to a \"specific summary.\" Developed by a convolution where the functions of influence apply [Rev. Opt. 34, 351 (1960)], Dirichlet's Theorem immediately gives data on the form of two functions that the Fourier transform introduces in Fraunhoffer diffraction at infinity. The distribution plane, where one normally cuts off Huygens' pupils, F(x,y), is composed not of points, but of diffraction figures or correlation functions. The function f(u,v) of a spread of frequencies is also a directive function, but it shows no correlation and has discontinuities. F(x,y) is linked with the undulatory theory of light, and f(u,v) represents a corpuscular flux. Two conclusions can be drawn therefrom: (1) the limited pupils must, correctly, be defined by the directive function f(u,v); (2) Fourier's equation establishes a relation between two aspects of the propagation of the lig t crossing a plane, one of which conforms to the undulatory theory of light, the other to his corpuscular theory. We are visibly lacking a corpusculatory theory of light and its coherent images.",
                    "score": 0.8503284454345703
                },
                {
                    "id": 8728808,
                    "contents": "Experimental reconstruction of photon statistics without photon counting.\nExperimental reconstructions of photon number distributions of both continuous-wave and pulsed light beams are reported. Our scheme is based on on/off avalanche photo-detection assisted by maximum-likelihood estimation and does not involve photon counting. Reconstructions of the distribution for both semiclassical and quantum states of light are reported for single-mode as well as for multi-mode beams.",
                    "score": 0.8502312302589417
                },
                {
                    "id": 6502806,
                    "contents": "Theory of the Kapitza-Dirac diffraction effect.\nWe treat the Kapitza-Dirac diffraction effect observed recently by Batelaan et al. using a newly developed nonperturbative quantum-field scattering theory. Our theory shows that an electron beam passing perpendicularly through a focused standing light wave can produce diffraction patterns. Our theory predicts (1) the minimum value of the ponderomotive energy is (Planck's over 2 pi omega)(2)/m(e)c(2), (2) the critical laser intensity above which the first pair of electron diffraction peaks will occur, and (3) the existence of sidebands in the electron spectra separated far from the central band by a momentum of several hundred photons. Our theory provides a unified explanation of the experimental results of Bucksbaum et al. and Batelaan et al.",
                    "score": 0.8493516445159912
                },
                {
                    "id": 12970914,
                    "contents": "Photon number distributions from a diode laser.\nWe use balanced homodyne detection to characterize light from a diode laser as it crosses the threshold. We measure the single-time second-order correlation function g(2), and also extract the photon number distribution. Just above the laser threshold, we find that the measured g(2) exceeds the prediction of the semiclassical single-mode laser model. From the reconstructed photon number distributions, we conclude that this excess is due to emission from nonlasing modes. For higher pumping current, the light noise increases due to a different mechanism, possibly mode competition or mode partition noise.",
                    "score": 0.8489087820053101
                },
                {
                    "id": 21011106,
                    "contents": "Entangling Macroscopic Light States by Delocalized Photon Addition.\nWe present a scheme, based on the delocalized heralded addition of a single photon, to entangle two or more distinct field modes, each containing arbitrary light states. A high degree of entanglement can in principle endure light states of macroscopic intensities and is expected to be particularly robust against losses. We experimentally establish and measure significant entanglement between two identical weak laser pulses containing up to 60 photons each.",
                    "score": 0.8488982319831848
                },
                {
                    "id": 11109051,
                    "contents": "Nonlinear optics: the next decade.\nThis paper concludes the Focus Serial assembled of invited papers in key areas of nonlinear optics (Editors: J.M. Dudley and R.W. Boyd), and it discusses new directions for future research in this field.",
                    "score": 0.8482831716537476
                },
                {
                    "id": 21256557,
                    "contents": "Radiance and photon noise: imaging in geometrical optics, physical optics, quantum optics and radiology.\nThe statistics of detector outputs produced by an imaging system are derived from basic radiometric concepts and definitions. We show that a fundamental way of describing a photon-limited imaging system is in terms of a Poisson random process in spatial, angular, and wavelength variables. We begin the paper by recalling the concept of radiance in geometrical optics, radiology, physical optics, and quantum optics. The propagation and conservation laws for radiance in each of these domains are reviewed. Building upon these concepts, we distinguish four categories of imaging detectors that all respond in some way to the incident radiance, including the new category of photon-processing detectors (capable of measuring radiance on a photon-by-photon basis). This allows us to rigorously show how the concept of radiance is related to the statistical properties of detector outputs and to the information content of a single detected photon. A Monte-Carlo technique, which is derived from the Boltzmann transport equation, is presented as a way to estimate probability density functions to be used in reconstruction from photon-processing data.",
                    "score": 0.8481483459472656
                },
                {
                    "id": 4203003,
                    "contents": "The tracks of the Compton effect.\nThe observation of scattered radiations of larger wavelength than the primary had been repeatedly rejected or explained away by many researchers, including Compton. After years of vacillations, he recognized the effect named after him and was the first to develop a quantal equation predicting the wavelength of scattered radiation. It became one of the most significant contributions to modern radiation physics, opening the doors of quantum mechanics.",
                    "score": 0.8477352857589722
                },
                {
                    "id": 9611020,
                    "contents": "Photon propagation function: spectral analysis of its asymptotic form.\nThe physical attitudes of source theory, displacing those of renormalized, perturbative, operator field theory, are used in a simple discussion of the asymptotic behavior of the photon propagation function. A guiding principle is the elementary consistency requirement that, under circumstances where a physical parameter cannot be accurately measured, no sensitivity to its precise value can enter the description of those circumstances. The mathematical tool is the spectral representation of the propagation function, supplemented by an equivalent phase representation. The Gell-Mann-Low equation is recovered, but with their function now interpreted physically as the spectral weight function. A crude inequality is established for the latter, which helps in interpolating between the initial rising behavior and the ultimate zero at infinite mass. There is a brief discussion of the aggressive source theory viewpoint that denies the existence of a \"bare charge\".",
                    "score": 0.8469877243041992
                },
                {
                    "id": 21057275,
                    "contents": "Author Correction: Analysis of laser radiation using the Nonlinear Fourier transform.\nAn amendment to this paper has been published and can be accessed via a link at the top of the paper.",
                    "score": 0.8468602895736694
                },
                {
                    "id": 8679229,
                    "contents": "Photon correlation and scattering: introduction to the feature issue.\nThis feature issue of Applied Optics contains 25 research papers on photon correlation and scattering. Many of the papers in this volume were presented at an OSA Topical Meeting that was held 21-24 August 1996 in Capri, Italy. The focus of these papers is research in dynamic light scattering, surface light scattering, photon correlation, laser velocimetry, and their applications to biological, chemical, and physical processes.",
                    "score": 0.8465864658355713
                },
                {
                    "id": 8342719,
                    "contents": "Two-photon absorption strength: a new tool for the quantification of two-photon absorption.\nIn this paper, we define the two-photon absorption strength, a new characterization tool, similar to the oscillator strength, but for two-photon absorption. It allows the quantification of the two-photon absorption properties of molecular systems which are one-photon transparent. Its definition is such that the corresponding numerical values are around 100 for small molecules. We also show that this new theoretical tool allows the direct comparison of experimental and theoretical data without requiring the introduction of any arbitrary band width. As an example, the experimental and theoretical (AM1+CNDOS and HF+CIS3-21G) two-photon absorption properties of the 2,2'-bi(9,9-dihexylfluorene) molecule are compared.",
                    "score": 0.8464183211326599
                },
                {
                    "id": 8261280,
                    "contents": "Photon correlation and scattering: introduction to the feature issue.\nThis feature issue of Applied Optics contains 31 research papers on photon correlation and scattering, many of which were presented at an OSA Topical Meeting that was held 21-23 August 2000 in Whistler, British Columbia, Canada. These papers focus on research in dynamic light scattering, surface light scattering, photon correlation, and laser velocimetry and their applications to physical, chemical, and biological processes.",
                    "score": 0.8457043766975403
                },
                {
                    "id": 9578266,
                    "contents": "Diffusion coefficient depends on time, not on absorption.\nThe recent controversy over whether the photon diffusion coefficient depends on absorption is addressed by use of the analytical solution of the photon transport equation in an infinite homogeneous scattering medium. The diffusion coefficient is found to be independent of absorption but temporally dependent. After a long period of time, the photon diffusion coefficient approaches D=1/3mu(s)(?) , which supports a claim made by Furutsu and Yamada [Phys. Rev. E 50, 3634 (1994)]. At early times, the diffusion coefficient is smaller than D=1/3mu(s)(?) , but this reduction cannot be expressed as D=1/3(mu(s)(?)+mu(a)) , since the time-dependent diffusion coefficient is found to be unrelated to absorption.",
                    "score": 0.8446977138519287
                },
                {
                    "id": 18093657,
                    "contents": "Photon statistics as an interference phenomenon.\nInterference of light fields, first postulated by Young, is one of the fundamental pillars of physics. Dirac extended this observation to the quantum world by stating that each photon interferes only with itself. A precondition for interference to occur is that no welcher-weg information labels the paths the photon takes; otherwise, the interference vanishes. This remains true, even if two-photon interference is considered, e.g., in the Hong-Ou-Mandel-experiment. Here, the two photons interfere only if they are indistinguishable, e.g., in frequency, momentum, polarization, and time. Less known is the fact that two-photon interference and photon indistinguishability also determine the photon statistics in the overlapping light fields of two independent sources. As a consequence, measuring the photon statistics in the far field of two independent sources reveals the degree of indistinguishability of the emitted photons. In this Letter, we prove this statement in theory using a quantum mechanical treatment. We also demonstrate the outcome experimentally with a simple setup consisting of two statistically independent thermal light sources with adjustable polarizations. We find that the photon statistics vary indeed as a function of the polarization settings, the latter determining the degree of welcher-weg information of the photons emanating from the two sources.",
                    "score": 0.8446611166000366
                },
                {
                    "id": 10059428,
                    "contents": "Single-photon generation by electron beams.\nWe propose a drastically new method for generating single photons in a deterministic way by interaction of electron beams with optical waveguides. We find a single swift electron to produce a guided photon with large probability. The change in energy and propagation direction of the electron reveals the creation of a photon, with the photon energy directly read from the energy-loss spectrum or the beam displacement. Our study demonstrates the viability of deterministically creating single guided photons using electron beams with better than picosecond time uncertainty, thus opening a new avenue for making room temperature, heralded frequency-tunable sources affordable for scientific and commercial developments.",
                    "score": 0.8446409702301025
                },
                {
                    "id": 10854014,
                    "contents": "Confining stationary light: dirac dynamics and klein tunneling.\nWe discuss the properties of 1D stationary pulses of light in an atomic ensemble with electromagnetically induced transparency in the limit of tight spatial confinement. When the size of the wave packet becomes comparable or smaller than the absorption length of the medium, it must be described by a two-component vector which obeys the one-dimensional two-component Dirac equation with an effective mass m;{*} and effective speed of light c;{*}. Then a fundamental lower limit to the spatial width in an external potential arises from Klein tunneling and is given by the effective Compton length lambda_{C}=variant Planck's over 2pi/(m;{*}c;{*}). Since c;{*} and m;{*} can be externally controlled and can be made small, it is possible to observe effects of the relativistic dispersion for rather low energies or correspondingly on macroscopic length scales.",
                    "score": 0.8445650339126587
                },
                {
                    "id": 6392221,
                    "contents": "[Not Available].\nThe object of this study is Leonhard Euler's physical optics as it is formulated in Nova theoria lucis et colorum (1746). The focus is on this particular work by Euler for two reasons: 1) Nova theoria represents undoubtedly the most comprehensive and systematic medium theory of the 18th century; 2) it contains the basic principles of Euler's conception of the nature of light, which he later maintained. The works of the most important advocates of this tradition (Huygens, Malebranche and Johann II Bernoulli) are here analyzed to give a historical frame to Euler's role in the medium tradition. Though these authors try to elaborate a theory of light alternative to the emission theory, they never realize the contrast between the medium and the emission traditions. From this perspective, Nova theoria is a real transition point: Euler is fully aware of the antithesis between the two traditions; he compares them, he refutes the arguments in favor of emission theory and formulates an alternative one, that will substantially be the first and the most significant antagonist of emission model. The essay examines also the central questions of Euler's theory of light, i.e. how pulses are generated and propagated, the nature of the rays of light and the relations among pulse distance, frequency, and velocity.",
                    "score": 0.8442766070365906
                },
                {
                    "id": 7570090,
                    "contents": "What diffraction limit?\nSeveral approaches are capable of beating the classical 'diffraction limit'. In the optical domain, not only are superlenses a promising choice: concepts such as super-oscillations could provide feasible alternatives.",
                    "score": 0.8438152074813843
                },
                {
                    "id": 10242000,
                    "contents": "Introduction.\nThis issue, the largest issue of Optics Express to date, focuses on some recent developments in the generation and application of novel quantum states of light, particularly those quantum states of light that manifest one or more of the following characteristics upon detection: quadrature squeezing, sub-Poissonian photon statistics, or nonclassical photon correlation. The interest in such quantum states of light stems not only from their fundamental importance, but also from their potential utility in practical applications. The sensitivity of many optical measurements that can be made with laser light can be enhanced by use of such light states.",
                    "score": 0.8437380790710449
                },
                {
                    "id": 23686030,
                    "contents": "A narrow bandwidth extreme ultra-violet light source for time- and angle-resolved photoemission spectroscopy.\nHere, we present a high repetition rate, narrow bandwidth, extreme ultraviolet photon source for time- and angle-resolved photoemission spectroscopy. The narrow bandwidth pulses <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:moΔ</mml:mo <mml:miE</mml:mi <mml:mo=</mml:mo <mml:mn9</mml:mn <mml:mo,</mml:mo <mml:mo </mml:mo <mml:mn14</mml:mn <mml:mo,</mml:mo <mml:mo </mml:mo <mml:mtextand</mml:mtext <mml:mo </mml:mo <mml:mn18</mml:mn</mml:mrow </mml:math  meV for photon energies <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mih</mml:mi <mml:miν</mml:mi <mml:mo=</mml:mo <mml:mn10.8</mml:mn <mml:mo,</mml:mo <mml:mo </mml:mo <mml:mn18.1</mml:mn <mml:mo,</mml:mo <mml:mo </mml:mo <mml:mtextand</mml:mtext <mml:mo </mml:mo <mml:mn25.3</mml:mn</mml:math  eV are generated through high harmonic generation using ultra-violet drive pulses with relatively long pulse lengths (461 fs). The high harmonic generation setup employs an annular drive beam in tight focusing geometry at a repetition rate of 250 kHz. Photon energy selection is provided by a series of selectable multilayer bandpass mirrors and thin film filters, thus avoiding any time broadening introduced by single grating monochromators. A two stage optical-parametric amplifier provides &lt; 100 fs tunable pump pulses from 0.65 μm to 9 <iμ</im. The narrow bandwidth performance of the light source is demonstrated through angle-resolved photoemission measurements on a series of quantum materials, including high-temperature superconductor Bi-2212, WSe<sub2</sub, and graphene.",
                    "score": 0.8432695269584656
                },
                {
                    "id": 15619163,
                    "contents": "Quantum optics: science and technology in a new light.\nLight facilitates exploration of quantum phenomena that illuminate the basic properties of nature and also enables radical new technologies based on these phenomena. The critical features of quantum light that underpin the opportunities for discovery and application are exceptionally low noise and strong correlations. Rapid progress in both science and technology has been stimulated by adopting components developed for optical telecommunications and networking, such as highly efficient detectors, integrated photonic circuits, and waveguide- or nanostructure-based nonlinear optical devices. These provide the means to generate new quantum states of light and matter of unprecedented scale, containing many photons with quantum correlations across space and time. Notably, networks with only several tens of photons are already beyond what can be efficiently analyzed by current computers. ",
                    "score": 0.8431202173233032
                },
                {
                    "id": 7947444,
                    "contents": "Looking to the future of quantum optics.\nLight has provided both fundamental phenomenology and enabling technology for scientific discovery for many years, and today it continues to play a central role in fundamental explorations and innovative applications. The ability to manipulate light beams and pulses with the quantum degrees of freedom of optical radiation will add to those advances. The future of quantum optics, which encompasses both the generation and manipulation of nonclassical radiation, as well as its interaction with matter, lies in the rich variety of quantum states that is now becoming feasible to prepare, together with the numerous applications in sensing, imaging, metrology, communications, and information processing that such states enable.",
                    "score": 0.842739462852478
                },
                {
                    "id": 15589593,
                    "contents": "Quantum optics with one or two photons.\nWe discuss the concept of a single-photon state together with how they are generated, measured and interact with linear and nonlinear systems. In particular, we consider how a single-photon state interacts with an opto-mechanical system: an optical cavity with a moving mirror and how such states can be used as a measurement probe for the mechanical degrees of freedom. We conclude with a discussion of how single-photon states are modified in a gravitational field due to the red-shift.",
                    "score": 0.8426387310028076
                },
                {
                    "id": 10367730,
                    "contents": "Controlling the velocity of light pulses.\nIt is now possible to exercise a high degree of control over the velocity at which light pulses pass through material media. This velocity, known as the group velocity, can be made to be very different from the speed of light in a vacuum c. Specifically, the group velocity of light can be made much smaller than c, greater than c, or even negative. We present a survey of methods for establishing extreme values of the group velocity, concentrating especially on methods that work in room-temperature solids. We also describe some applications of slow light.",
                    "score": 0.8421726226806641
                },
                {
                    "id": 8532142,
                    "contents": "Happy centenary, photon.\nOne hundred years ago Albert Einstein introduced the concept of the photon. Although in the early years after 1905 the evidence for the quantum nature of light was not compelling, modern experiments--especially those using photon pairs--have beautifully confirmed its corpuscular character. Research on the quantum properties of light (quantum optics) triggered the evolution of the whole field of quantum information processing, which now promises new technology, such as quantum cryptography and even quantum computers.",
                    "score": 0.8421270847320557
                },
                {
                    "id": 9977851,
                    "contents": "Basic diffraction phenomena in time domain.\nUsing a recently developed technique (SEA TADPOLE) for easily measuring the complete spatiotemporal electric field of light pulses with micrometer spatial and femtosecond temporal resolution, we directly demonstrate the formation of theo-called boundary diffraction wave and Arago's spot after an aperture, as well as the superluminal propagation of the spot. Our spatiotemporally resolved measurements beautifully confirm the time-domain treatment of diffraction. Also they prove very useful for modern physical optics, especially in micro- and meso-optics, and also significantly aid in the understanding of diffraction phenomena in general.",
                    "score": 0.8418305516242981
                },
                {
                    "id": 11738714,
                    "contents": "Two-photon-induced excited-state nonlinearities.\nWe report a theoretical investigation of laser-pulse-duration dependence of excited-state nonlinearities induced by two-photon absorption (2PA). We investigate the spatiotemporal characteristics of the transmitted pulses caused by 2PA-induced excited-state absorption, which strongly depends on laser pulse duration. By taking into account 2PA cross-section, excited-state photophysical properties, as well as laser pulse duration, we quantitatively determine the effective fifth-order nonlinearities caused by excited-state absorption and refraction. The results are capable of predicting the magnitude of 2PA-induced excited-state nonlinearities on the time scales where laser pulse duration is less than or comparable to the lifetime of 2PA-induced excited states. We also develop Z-scan theories for quickly yet unambiguously estimation of 2PA coefficient, third-order nonlinear refraction index, and excited-state absorption and refraction cross-sections.",
                    "score": 0.8417977690696716
                },
                {
                    "id": 16614179,
                    "contents": "Excitation of a single atom with exponentially rising light pulses.\nWe investigate the interaction between a single atom and optical pulses in a coherent state with a controlled temporal envelope. In a comparison between a rising exponential and a square envelope, we show that the rising exponential envelope leads to a higher excitation probability for fixed low average photon numbers, in accordance with a time-reversed Weisskopf-Wigner model. We characterize the atomic transition dynamics for a wide range of the average photon numbers and are able to saturate the optical transition of a single atom with ≈50 photons in a pulse by a strong focusing technique. ",
                    "score": 0.8417763710021973
                },
                {
                    "id": 16740215,
                    "contents": "Optics. Spatially structured photons that travel in free space slower than the speed of light.\nThat the speed of light in free space is constant is a cornerstone of modern physics. However, light beams have finite transverse size, which leads to a modification of their wave vectors resulting in a change to their phase and group velocities. We study the group velocity of single photons by measuring a change in their arrival time that results from changing the beam's transverse spatial structure. Using time-correlated photon pairs, we show a reduction in the group velocity of photons in both a Bessel beam and photons in a focused Gaussian beam. In both cases, the delay is several micrometers over a propagation distance of ~1 meter. Our work highlights that, even in free space, the invariance of the speed of light only applies to plane waves. ",
                    "score": 0.8416828513145447
                },
                {
                    "id": 22186397,
                    "contents": "Rapid response.\nExtremely short X-ray pulses from a free-electron laser are helping to clarify how phytochromes respond to light, but puzzles remain.",
                    "score": 0.8416592478752136
                },
                {
                    "id": 14863772,
                    "contents": "Measuring the second order correlation function and the coherence time using random phase modulation.\nA new approach to measure the second order correlation function g(2) and the coherence time was investigated. The g(2) was calculated from the photon pair time interval distribution by direct numerical self-convolution with the high order correction. The accuracy of this method was examined using an optical fiber based Hanbury-Brown-Twiss interferometer with a pseudo-thermal light source. We found that the significance of the high order correction is related to the factor Īτc, which is the overlapping of the photon wave packets. A novel technique was also demonstrated to measure the coherence time τc of a light source using the random phase modulation. This method is more suitable for a weak light source with a long coherence time using a simple experimental setup.",
                    "score": 0.8413712382316589
                },
                {
                    "id": 6490065,
                    "contents": "Electromagnetic fields on a quantum scale. I.\nThis is the first in a series of two articles, the second of which provides an exact electro-magnetic field description of photon emission, absorption, and radiation pattern. Photon energy exchanges are analyzed and shown to be the triggered, regenerative response of a non-local eigenstate electron. This first article presents a model-based, hidden variable analysis of quantum theory that provides the statistical nature of wave functions. The analysis uses the equations of classical electro-magnetism and conservation of energy while modeling an eigenstate electron as a nonlocal entity. Essential to the analysis are physical properties that were discovered and analyzed only after the historical interpretation of quantum mechanics was established: electron non-locality and the standing electro-magnetic energy that accompanies and encompasses an active, electrically small volume. The standing energy produces a driving radiation reaction force that, under certain circumstances, is many orders of magnitude larger than currently accepted values. These properties provide a sufficient basis for the Schrödinger equation as a descriptor of non-relativistic eigenstate electrons in or near equilibrium. The uncertainty principle follows, as does the exclusion principle. The analysis leads to atomic stability and causality in the sense that the status of physical phenomena at any instant specifies the status an instant later.",
                    "score": 0.8413510918617249
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_25",
        "question": "The force constant of ${ }^{35} \\mathrm{Cl}^{35} \\mathrm{Cl}$ is $319 \\mathrm{~N} \\cdot \\mathrm{m}^{-1}$. Calculate the fundamental vibrational frequency",
        "golden_answers": [
            " 556"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 22555224,
                    "contents": "The Local Vibrational Mode Theory and Its Place in the Vibrational Spectroscopy Arena.\nThis Feature Article starts highlighting some recent experimental and theoretical advances in the field of IR and Raman spectroscopy, giving a taste of the breadth and dynamics of this striving field. The local mode theory is then reviewed, showing how local vibrational modes are derived from fundamental normal modes. New features are introduced that add to current theoretical efforts: (i) a unique measure of bond strength based on local mode force constants ranging from bonding in single molecules in different environments to bonding in periodic systems and crystals and (ii) a new way to interpret vibrational spectra by pinpointing and probing interactions between particular bond stretching contributions to the normal modes. All of this represents a means to work around the very nature of normal modes, namely that the vibrational motions in polyatomic molecules are delocalized. Three current focus points of the local mode analysis are reported, demonstrating how the local mode analysis extracts important information hidden in vibrational spectroscopy data supporting current experiments: (i) metal-ligand bonding in heme proteins, such as myoglobin and neuroglobin; (ii) disentanglement of DNA normal modes; and (iii) hydrogen bonding in water clusters and ice. Finally, the use of the local mode analysis by other research groups is summarized. Our vision is that in the future local mode analysis will be routinely applied by the community and that this Feature Article serves as an incubator for future collaborations between experiment and theory.",
                    "score": 0.8890930414199829
                },
                {
                    "id": 9626800,
                    "contents": "Systematic study of vibrational frequencies calculated with the self-consistent charge density functional tight-binding method.\nWe present a detailed study of harmonic vibrational frequencies obtained with the self-consistent charge density functional tight-binding (SCC-DFTB) method. Our testing set comprises 66 molecules and 1304 distinct vibrational modes. Harmonic vibrational frequencies are computed using an efficient analytical algorithm developed and coded by the authors. The obtained results are compared to experiment and to other theoretical findings. Scaling factor for the SCC-DFTB method, determined by minimization of mean absolute deviation of scaled frequencies, is found to be 0.9933. The accuracy of the scaled SCC-DFTB frequencies is noticeably better than for other semiempirical methods (including standard DFTB method) and approximately twice worse than for other well established scaled ab initio quantum chemistry methods (e.g., HF, BLYP, B3LYP). Mean absolute deviation for the scaled SCC-DFTB frequencies is 56 cm(-1), while standard deviation is 82 cm(-1), and maximal absolute deviation is as large as 529 cm(-1). Using SCC-DFTB allows for substantial time savings; computational time is reduced from hours to seconds when compared to standard ab initio techniques.",
                    "score": 0.8863434791564941
                },
                {
                    "id": 14524188,
                    "contents": "Advances in Quantum Mechanochemistry: Electronic Structure Methods and Force Analysis.\nIn quantum mechanochemistry, quantum chemical methods are used to describe molecules under the influence of an external force. The calculation of geometries, energies, transition states, reaction rates, and spectroscopic properties of molecules on the force-modified potential energy surfaces is the key to gain an in-depth understanding of mechanochemical processes at the molecular level. In this review, we present recent advances in the field of quantum mechanochemistry and introduce the quantum chemical methods used to calculate the properties of molecules under an external force. We place special emphasis on quantum chemical force analysis tools, which can be used to identify the mechanochemically relevant degrees of freedom in a deformed molecule, and spotlight selected applications of quantum mechanochemical methods to point out their synergistic relationship with experiments.",
                    "score": 0.8861784338951111
                },
                {
                    "id": 7670298,
                    "contents": "Vibrational structure theory: new vibrational wave function methods for calculation of anharmonic vibrational energies and vibrational contributions to molecular properties.\nA number of recently developed theoretical methods for the calculation of vibrational energies and wave functions are reviewed. Methods for constructing the appropriate quantum mechanical Hamilton operator are briefly described before reviewing a particular branch of theoretical methods for solving the nuclear Schrödinger equation. The main focus is on wave function methods using the vibrational self-consistent field (VSCF) as starting point, and includes vibrational configuration interaction (VCI), vibrational Møller-Plesset (VMP) theory, and vibrational coupled cluster (VCC) theory. The convergence of the different methods towards the full vibrational configuration interaction (FVCI) result is discussed. Finally, newly developed vibrational response methods for calculation of vibrational contributions to properties, energies, and transition probabilities are discussed.",
                    "score": 0.8860921263694763
                },
                {
                    "id": 20680018,
                    "contents": "Vibrational heat-bath configuration interaction.\nWe introduce vibrational heat-bath configuration interaction (VHCI) as an accurate and efficient method for calculating vibrational eigenstates of anharmonic systems. Inspired by its origin in electronic structure theory, VHCI is a selected CI approach that uses a simple criterion to identify important basis states with a pre-sorted list of anharmonic force constants. Screened second-order perturbation theory and simple extrapolation techniques provide significant improvements to variational energy estimates. We benchmark VHCI on four molecules with 12-48 degrees of freedom and use anharmonic potential energy surfaces truncated at fourth and sixth orders. When compared to other methods using the same truncated potentials, VHCI produces vibrational spectra of tens or hundreds of states with sub-wavenumber accuracy at low computational cost.",
                    "score": 0.8857540488243103
                },
                {
                    "id": 17933501,
                    "contents": "Dynamic <i>ab initio</i> Methods for Vibrational Spectroscopy.\nOur group focuses on the development of computational methods derived from quantum mechanics and their application to a variety of challenging systems ranging from (bio-)molecules over coordination compounds to solar light-driven processes. In this review, we describe our recent activities for accurate calculation of spectroscopic properties. Emphasis is put on forefront methods for vibrational spectroscopy, in particular with respect to condensed phase systems, based on ab initio molecular dynamics. This approach has several advantages compared to standard static approaches and proven to be a highly valuable tool for in-depth analysis of complex systems.",
                    "score": 0.8803036212921143
                },
                {
                    "id": 19358685,
                    "contents": "The Hellmann-Feynman theorem: a perspective.\nThe Hellmann-Feynman theorem has, with a few exceptions, not been exploited to the degree that it merits. This is due, at least in part, to a widespread failure to recognize that its greatest value may be conceptual rather than numerical, i.e., in achieving insight into molecular properties and behavior. In this brief overview, we shall discuss three examples of significant concepts that have come out of the Hellmann-Feynman theorem: (1) The forces exerted upon the nuclei in molecules are entirely Coulombic in nature. (2) The total energies of atoms and molecules can be expressed rigorously in terms of just the electrostatic potentials at their nuclei that are produced by the electrons and other nuclei. (3) Dispersion forces are due to the attractions of nuclei to their own polarized electronic densities. To summarize, energy and force analyses should not be viewed as competitive but rather as complementary.",
                    "score": 0.8797602653503418
                },
                {
                    "id": 12635461,
                    "contents": "Vibrational self-consistent field calculations for spectroscopy of biological molecules: new algorithmic developments and applications.\nThis review describes the vibrational self-consistent field (VSCF) method and its other variants for computing anharmonic vibrational spectroscopy of biological molecules. The superiority and limitations of this algorithm are discussed with examples. The spectroscopic accuracy of the VSCF method is compared with experimental results and other available state-of-the-art algorithms for various biologically important systems. For large biological molecules with many vibrational modes, the scaling of computational effort is investigated. The accuracy of the vibrational spectra of biological molecules using the VSCF approach for different electronic structure methods is also assessed. Finally, a few open problems and challenges in this field are discussed.",
                    "score": 0.8742883205413818
                },
                {
                    "id": 11955975,
                    "contents": "TAMkin: a versatile package for vibrational analysis and chemical kinetics.\nTAMkin is a program for the calculation and analysis of normal modes, thermochemical properties and chemical reaction rates. At present, the output from the frequently applied software programs ADF, CHARMM, CPMD, CP2K, Gaussian, Q-Chem, and VASP can be analyzed. The normal-mode analysis can be performed using a broad variety of advanced models, including the standard full Hessian, the Mobile Block Hessian, the Partial Hessian Vibrational approach, the Vibrational Subsystem Analysis with or without mass matrix correction, the Elastic Network Model, and other combinations. TAMkin is readily extensible because of its modular structure. Chemical kinetics of unimolecular and bimolecular reactions can be analyzed in a straightforward way using conventional transition state theory, including tunneling corrections and internal rotor refinements. A sensitivity analysis can also be performed, providing important insight into the theoretical error margins on the kinetic parameters. Two extensive examples demonstrate the capabilities of TAMkin: the conformational change of the biological system adenylate kinase is studied, as well as the reaction kinetics of the addition of ethene to the ethyl radical. The important feature of batch processing large amounts of data is highlighted by performing an extended level of theory study, which TAMkin can automate significantly.",
                    "score": 0.8734797835350037
                },
                {
                    "id": 21502466,
                    "contents": "Non-conventional force fields for applications in spectroscopy and chemical reaction dynamics.\nExtensions and improvements of empirical force fields are discussed in view of applications to computational vibrational spectroscopy and reactive molecular dynamics simulations. Particular focus is on quantitative studies, which make contact with experiments and provide complementary information for a molecular-level understanding of processes in the gas phase and in solution. Methods range from including multipolar charge distributions to reproducing kernel Hilbert space approaches and machine learned energy functions based on neural networks.",
                    "score": 0.8733578324317932
                },
                {
                    "id": 7008278,
                    "contents": "Vibrational spectroscopy and the development of new force fields for biological molecules.\nThe role of vibrational spectroscopy in the testing of force fields of biological molecules and in the determination of improved force fields is discussed. Analysis shows that quantitative testing of potential energy surfaces by comparison with spectroscopic data generally requires calculations that include anharmonic couplings between different vibrational modes. Applications of the vibrational self-consistent field (VSCF) method to calculations of spectroscopy of biological molecules are presented, and comparison with experiment is used to determine the merits and flaws of various types of force fields. The main conclusions include the following: (1) Potential surfaces from ab initio methods at the level of MP2 yield very satisfactory agreement with spectroscopic experimental data. (2) By the test of spectroscopy, ab initio force fields are considerably superior to the standard versions of force fields such as AMBER or OPLS. (3) Much of the spectroscopic weakness of AMBER and OPLS is due to incorrect description of anharmonic coupling between different vibrational modes. (4) Potential surfaces of the QM/MM (Quantum Mechanics/Molecular Mechanics) type, and potentials based on improved versions of semi-empirical electronic structure theory, which are feasible for large biological molecules, yield encouraging results by the test of vibrational spectroscopy.",
                    "score": 0.8726645708084106
                },
                {
                    "id": 15105328,
                    "contents": "Fundamental frequency from classical molecular dynamics.\nWe give a theoretical validation for calculating fundamental frequencies of a molecule from classical molecular dynamics (MD) when its anharmonicity is small enough to be treated by perturbation theory. We specifically give concrete answers to the following questions: (1) What is the appropriate initial condition of classical MD to calculate the fundamental frequency? (2) From that condition, how accurately can we extract fundamental frequencies of a molecule? (3) What is the benefit of using ab initio MD for frequency calculations? Our analytical approaches to those questions are classical and quantum normal form theories. As numerical examples we perform two types of MD to calculate fundamental frequencies of H2O with MP2/aug-cc-pVTZ: one is based on the quartic force field and the other one is direct ab initio MD, where the potential energies and the gradients are calculated on the fly. From those calculations, we show comparisons of the frequencies from MD with the post vibrational self-consistent field calculations, second- and fourth-order perturbation theories, and experiments. We also apply direct ab initio MD to frequency calculations of C-H vibrational modes of tetracene and naphthalene. We conclude that MD can give the same accuracy in fundamental frequency calculation as second-order perturbation theory but the computational cost is lower for large molecules. ",
                    "score": 0.8706909418106079
                },
                {
                    "id": 18165625,
                    "contents": "A systematic benchmarking of computational vibrational spectroscopy with DFTB3: Normal mode analysis and fast Fourier transform dipole autocorrelation function.\nComputational vibrational spectroscopy serves as an important tool in the interpretation of experimental infrared (IR) spectra. In this article, we present a systematic benchmarking study of DFTB3 with two different computational vibrational spectroscopic methods, based on either normal mode analysis (NMA) or fast Fourier transform dipole autocorrelation function (FT-DAC). The results were compared with experimental data and theoretical calculations with B3LYP/cc-pVTZ. The empirical scaling factors for DFTB3/NMA, DFTB3-freq/NMA, and DFTB3/FT-DAC methods are 0.9993, 1.0059, and 0.9982, respectively. We also demonstrate the significance of anharmonicity and conformational sampling in vibrational spectroscopic calculations on flexible molecules. As expected, DFTB3/FT-DAC predicted the anharmonic vibrational peaks more accurately than DFTB3/NMA and NMA spectra are highly dependent on the initial structures. The potential limitations of DFTB3 for vibrational spectroscopic calculations and the challenges in assigning the FT-DAC spectral peaks were noted. DFTB3/FT-DAC is expected to serve as a promising technique in computational spectroscopy in complex biomolecular systems. © 2018 Wiley Periodicals, Inc.",
                    "score": 0.8699739575386047
                },
                {
                    "id": 21648239,
                    "contents": "Vibrational Spectroscopic Map, Vibrational Spectroscopy, and Intermolecular Interaction.\nVibrational spectroscopy is an essential tool in chemical analyses, biological assays, and studies of functional materials. Over the past decade, various coherent nonlinear vibrational spectroscopic techniques have been developed and enabled researchers to study time-correlations of the fluctuating frequencies that are directly related to solute-solvent dynamics, dynamical changes in molecular conformations and local electrostatic environments, chemical and biochemical reactions, protein structural dynamics and functions, characteristic processes of functional materials, and so on. In order to gain incisive and quantitative information on the local electrostatic environment, molecular conformation, protein structure and interprotein contacts, ligand binding kinetics, and electric and optical properties of functional materials, a variety of vibrational probes have been developed and site-specifically incorporated into molecular, biological, and material systems for time-resolved vibrational spectroscopic investigation. However, still, an all-encompassing theory that describes the vibrational solvatochromism, electrochromism, and dynamic fluctuation of vibrational frequencies has not been completely established mainly due to the intrinsic complexity of intermolecular interactions in condensed phases. In particular, the amount of data obtained from the linear and nonlinear vibrational spectroscopic experiments has been rapidly increasing, but the lack of a quantitative method to interpret these measurements has been one major obstacle in broadening the applications of these methods. Among various theoretical models, one of the most successful approaches is a semiempirical model generally referred to as the vibrational spectroscopic map that is based on a rigorous theory of intermolecular interactions. Recently, genetic algorithm, neural network, and machine learning approaches have been applied to the development of vibrational solvatochromism theory. In this review, we provide comprehensive descriptions of the theoretical foundation and various examples showing its extraordinary successes in the interpretations of experimental observations. In addition, a brief introduction to a newly created repository Web site (http://frequencymap.org) for vibrational spectroscopic maps is presented. We anticipate that a combination of the vibrational frequency map approach and state-of-the-art multidimensional vibrational spectroscopy will be one of the most fruitful ways to study the structure and dynamics of chemical, biological, and functional molecular systems in the future.",
                    "score": 0.8686066269874573
                },
                {
                    "id": 17946607,
                    "contents": "Anharmonic vibrational eigenfunctions and infrared spectra from semiclassical molecular dynamics.\nWe describe a new approach based on semiclassical molecular dynamics that allows simulating infrared absorption or emission spectra of molecular systems with inclusion of anharmonic intensities. This is achieved from semiclassical power spectra by computing first the vibrational eigenfunctions as a linear combination of harmonic states, and then the oscillator strengths associated with the vibrational transitions. We test the approach against a 1D Morse potential and apply it to the water molecule with results in excellent agreement with discrete variable representation quantum benchmarks. The method does not require any grid calculations, and it is directly extendable to high dimensional systems. The usual exponential scaling of the basis set size with the dimensionality of the system can be avoided by means of an appropriate truncation scheme. Furthermore, the approach has the advantage to provide IR spectra beyond the harmonic approximation without losing the possibility of an intuitive assignment of absorption peaks in terms of normal modes of vibration.",
                    "score": 0.8685035109519958
                },
                {
                    "id": 20461504,
                    "contents": "How to VPT2: Accurate and Intuitive Simulations of CH Stretching Infrared Spectra Using VPT2+K with Large Effective Hamiltonian Resonance Treatments.\nThis article primarily discusses the utility of vibrational perturbation theory for the prediction of X-H stretching vibrations with particular focus on the specific variant, second-order vibrational perturbation theory with resonances (VPT2+K). It is written as a tutorial, reprinting most important formulas and providing numerous simple examples. It discusses the philosophy and practical considerations behind vibrational simulations with VPT2+K, including but not limited to computational method selection, cost-saving approximations, approaches to evaluating intensity, resonance identification, and effective Hamiltonian structure. Particular attention is given to resonance treatments, beginning with simple Fermi dyads and gradually progressing to arbitrarily large polyads that describe both Fermi and Darling-Dennison resonances. VPT2+K combined with large effective Hamiltonians is shown to be a reliable framework for modeling the complicated CH stretching spectra of alkenes. An error is also corrected in the published analytic formula for the VPT2 transition moment between the vibrational ground state and triply excited states.",
                    "score": 0.867830753326416
                },
                {
                    "id": 19115043,
                    "contents": "Preface: Special Topic: From Quantum Mechanics to Force Fields.\nThis Special Topic issue entitled \"From Quantum Mechanics to Force Fields\" is dedicated to the ongoing efforts of the theoretical chemistry community to develop a new generation of accurate force fields based on data from high-level electronic structure calculations and to develop faster electronic structure methods for testing and designing force fields as well as for carrying out simulations. This issue includes a collection of 35 original research articles that illustrate recent theoretical advances in the field. It provides a timely snapshot of recent developments in the generation of approaches to enable more accurate molecular simulations of processes important in chemistry, physics, biophysics, and materials science.",
                    "score": 0.8677353262901306
                },
                {
                    "id": 10108918,
                    "contents": "Vibrational spectroscopy: can density functional theory cope with highly electronegative atoms?\nVibrational properties of molecules composed solely of highly electronegative atoms are studied by means of density functional methods. Performance of different combinations of exchange and correlation functionals is tested. It is demonstrated that certain functionals can successfully simulate infrared spectra of systems containing only fluorine, oxygen and nitrogen.",
                    "score": 0.8675020933151245
                },
                {
                    "id": 17209726,
                    "contents": "Calculating free energies from the vibrational density of states function: Validation and critical assessment.\nWe explore and show the usefulness of the density of states function for computing vibrational free energies and free energy differences between small systems. Therefore, we compare this density of states integration method (DSI) to more established schemes such as Bennett's Acceptance Ratio method (BAR), the Normal Mode Analysis (NMA), and the Quasiharmonic Analysis (QHA). The strengths and shortcomings of all methods are highlighted with three numerical examples. Furthermore, the free energy of the ionization of ammonia and the mutation from serine to cysteine are computed using extensive ab initio molecular dynamics simulations. We conclude that DSI improves upon the other frequency-based methods (NMA and QHA) regarding the treatment of anharmonicity and yielding results comparable to BAR in all cases without the need for alchemical transformations. Low-frequency modes lead to larger errors indicating that long simulation times might be required for larger systems. In addition, we introduce the use of DSI for the localization of the vibrational free energy to specific atoms or residues, leading to insights into the underlying process, a unique feature that is only offered by this method.",
                    "score": 0.8670947551727295
                },
                {
                    "id": 15481631,
                    "contents": "Comment on \"Density functional theory studies on molecular structure, vibrational spectra and electronic properties of cyanuric acid\".\nIn a recently published paper [Spectrochim. Acta A: Mol. Biomol. Spect. 138 (2015) 711-722], Prabhaharan, Prabakaran, Srinivasan, and Gunasekaran presented a combined experimental and theoretical study on molecular structure, vibrational spectra and NBO analysis of cyanuric acid, and explain their findings using the tri-hydroxy tautomeric form of the compound. In reality, the compound adopts the tri-oxo tautomeric form, which is by over 100kJmol(-1) more stable comparatively to the tri-hydroxy tautomer discussed and characterized by Prabhaharan et al.",
                    "score": 0.8668109178543091
                },
                {
                    "id": 14721148,
                    "contents": "Computational Analysis of Vibrational Sum Frequency Generation Spectroscopy.\nVibrational sum frequency generation (VSFG) spectroscopy is a widely used probe of interfaces and, having ideal surface sensitivity and selectivity, is particularly powerful when applied to wet and soft interfaces. Although VSFG spectroscopy can sensitively detect molecular details of interfaces, interpretation of observed spectra has, until recently, been challenging and often ambiguous. The situation has been greatly improved by remarkable advances in computational VSFG analysis on the basis of molecular modeling and molecular dynamics simulation. This article reviews the basic idea of computational VSFG analysis and recent applications to both aqueous and organic interfaces.",
                    "score": 0.8667747974395752
                },
                {
                    "id": 13565638,
                    "contents": "Calculations of the electric fields in liquid solutions.\nThe electric field created by a condensed-phase environment is a powerful and convenient descriptor for intermolecular interactions. Not only does it provide a unifying language to compare many different types of interactions, but it also possesses clear connections to experimental observables, such as vibrational Stark effects. We calculate here the electric fields experienced by a vibrational chromophore (the carbonyl group of acetophenone) in an array of solvents of diverse polarities using molecular dynamics simulations with the AMOEBA polarizable force field. The mean and variance of the calculated electric fields correlate well with solvent-induced frequency shifts and band broadening, suggesting Stark effects as the underlying mechanism of these key solution-phase spectral effects. Compared to fixed-charge and continuum models, AMOEBA was the only model examined that could describe nonpolar, polar, and hydrogen bonding environments in a consistent fashion. Nevertheless, we found that fixed-charge force fields and continuum models were able to replicate some results of the polarizable simulations accurately, allowing us to clearly identify which properties and situations require explicit polarization and/or atomistic representations to be modeled properly, and to identify for which properties and situations simpler models are sufficient. We also discuss the ramifications of these results for modeling electrostatics in complex environments, such as proteins. ",
                    "score": 0.8664903044700623
                },
                {
                    "id": 11505930,
                    "contents": "Recent progress in theoretical analysis of vibrational sum frequency generation spectroscopy.\nThis article summarizes the computational analysis of the vibrational sum frequency generation (SFG) spectroscopy with molecular dynamics simulation. The analysis allows direct comparison of experimental SFG spectra and microscopic interface structure obtained by molecular simulation, and thereby obviates empirical fitting procedures of the observed spectra. In the theoretical formulation, the frequency-dependent nonlinear susceptibility of an interface is calculated in two ways, based on the energy representation and time-dependent representation. The application to aqueous interfaces revealed a number of new insights into the local structure of electrolyte interfaces and the interpretation of SFG spectroscopy.",
                    "score": 0.8662503957748413
                },
                {
                    "id": 15713207,
                    "contents": "Vibrational solvatochromism. III. Rigorous treatment of the dispersion interaction contribution.\nA rigorous first principles theory of vibrational solvatochromism including the intermolecular dispersion interaction, which is based on the effective fragment potential method, is developed. The present theory is an extended version of our previous vibrational solvatochromism model that took into account the Coulomb, exchange-repulsion, and induction interactions. We show that the frequency shifts of the amide I mode of N-methylacetamide in H2O and CDCl3, when combined with molecular dynamics simulations, can be quantitatively reproduced by the theory, which indicates that the dispersion interaction contribution to the vibrational frequency shift is not always negligibly small. Nonetheless, the reason that the purely Coulombic interaction model for vibrational solvatochromism works well for describing amide I mode frequency shifts in polar solvents is because the electrostatic contribution is strong and highly sensitive to the relative orientation of surrounding solvent molecules, which is in stark contrast with polarization, dispersion, and exchange-repulsion contributions. It is believed that the theory presented and discussed here will be of great use in quantitatively describing vibrational solvatochromism and electrochromism of infrared probes in not just polar solvent environments but also in biopolymers such as proteins. ",
                    "score": 0.866186261177063
                },
                {
                    "id": 22263706,
                    "contents": "Energetic Origins of Force Constants: Adding a New Dimension to the Hessian Matrix via Interacting Quantum Atoms.\nThe Interacting Quantum Atoms (IQA) energy decomposition scheme divides the total energy of a molecule into intra- and interatomic contributions. While the former relates to the kinetic and potential energies of electrons inside a unique individual atomic basin, the latter contains the Coulomb and exchange-correlation potentials between electrons from two atomic basins. Considering that the molecular energy is a sum of IQA contributions, the Hessian matrix can also be written as a sum of \"IQA Hessian\" matrices, whose elements are second derivatives of IQA terms. Herein, we present a mathematical formalism for the IQA decomposition of force constants revealing their energetic origins. The method consists of adding a new dimension to the Hessian matrix, which becomes 3<iN</i × 3<iN</i × <iN</i<sup2</sup, with <iN</i being the number of atoms in the molecule and <iN</i<sup2</sup the number of IQA terms. Since there is no analytical method that produces the IQA second derivatives, the three-dimensional IQA Hessian is numerically calculated. When studying molecular vibrations, force constants, providing information about the nature of chemical bond and related to infrared frequencies, can be obtained by Wilson's <bFG</b method, which involves detailed manipulations of the Hessian matrix. In this paper, the methodology is reported and validated for a set of 30 molecules and more than 200 force constants and their interactions. Energetic origins of force constants are presented for diatomics and small molecules containing carbon-carbon, oxygen-oxygen, and carbon-oxygen bonds with different bond orders. It is found that bond stability and stiffness can have strikingly different energetic origins.",
                    "score": 0.8653221130371094
                },
                {
                    "id": 15074157,
                    "contents": "Next-Generation Force Fields from Symmetry-Adapted Perturbation Theory.\nSymmetry-adapted perturbation theory (SAPT) provides a unique set of advantages for parameterizing next-generation force fields from first principles. SAPT provides a direct, basis-set superposition error free estimate of molecular interaction energies, a physically intuitive energy decomposition, and a seamless transition to an asymptotic picture of intermolecular interactions. These properties have been exploited throughout the literature to develop next-generation force fields for a variety of applications, including classical molecular dynamics simulations, crystal structure prediction, and quantum dynamics/spectroscopy. This review provides a brief overview of the formalism and theory of SAPT, along with a practical discussion of the various methodologies utilized to parameterize force fields from SAPT calculations. It also highlights a number of applications of SAPT-based force fields for chemical systems of particular interest. Finally, the review ends with a brief outlook on the future opportunities and challenges that remain for next-generation force fields based on SAPT.",
                    "score": 0.8652535080909729
                },
                {
                    "id": 19076345,
                    "contents": "Far infrared spectroscopy of hydrogen bonding collective motions in complex molecular systems.\nFar infrared spectroscopy is a technique that allows the probing of the low frequency region of vibrational spectra and reveals, among others, vibrational modes of inter- and intramolecular hydrogen bonding. Due to their collective nature, these modes are highly sensitive to the conformational state of the molecules as well as to their interactions. Far infrared spectroscopy is thus an emerging technique for the characterization of the low frequency motions of complex molecules, including polymers, peptides, proteins or ionic liquids. This technique is not limited by the molecule's size and can be applied to solids and liquids. An overview of far infrared studies on complex structures and their interactions is given revealing the potential of the approach.",
                    "score": 0.8644505739212036
                },
                {
                    "id": 6545460,
                    "contents": "Vibrational coupled cluster theory.\nThe theory and first implementation of a vibrational coupled cluster (VCC) method for calculations of the vibrational structure of molecules is presented. Different methods for introducing approximate VCC methods are discussed including truncation according to a maximum number of simultaneous mode excitations as well as an interaction space order concept is introduced. The theory is tested on calculation of anharmonic frequencies for a three-mode model system and a formaldehyde quartic force field. The VCC method is compared to vibrational self-consistent-field, vibrational Møller-Plesset perturbation theory, and vibrational configuration interaction (VCI). A VCC calculation typically gives higher accuracy than a corresponding VCI calculation with the same number of parameters and the same formal operation count.",
                    "score": 0.8643732070922852
                },
                {
                    "id": 20136024,
                    "contents": "Molecular Polarizabilities in Aqueous Systems from First-Principles.\nWe discuss the results of first-principles calculations of molecular polarizabilities in condensed systems composed of well-defined building blocks, with a focus on water and simple aqueous solutions. We show that molecular polarizabilities are subtle fingerprints of structural changes induced in liquid water by the environment, e.g., the presence of ions and confined media, as well as by temperature and pressure. We also point out the importance of molecular polarizabilities in the calculation and interpretation of specific vibrational signatures of aqueous systems, notably Raman and sum-frequency generation spectra.",
                    "score": 0.8641201257705688
                },
                {
                    "id": 12996923,
                    "contents": "A quantitative quantum-chemical analysis tool for the distribution of mechanical force in molecules.\nThe promising field of mechanochemistry suffers from a general lack of understanding of the distribution and propagation of force in a stretched molecule, which limits its applicability up to the present day. In this article, we introduce the JEDI (Judgement of Energy DIstribution) analysis, which is the first quantum chemical method that provides a quantitative understanding of the distribution of mechanical stress energy among all degrees of freedom in a molecule. The method is carried out on the basis of static or dynamic calculations under the influence of an external force and makes use of a Hessian matrix in redundant internal coordinates (bond lengths, bond angles, and dihedral angles), so that all relevant degrees of freedom of a molecule are included and mechanochemical processes can be interpreted in a chemically intuitive way. The JEDI method is characterized by its modest computational effort, with the calculation of the Hessian being the rate-determining step, and delivers, except for the harmonic approximation, exact ab initio results. We apply the JEDI analysis to several example molecules in both static quantum chemical calculations and Born-Oppenheimer Molecular Dynamics simulations in which molecules are subject to an external force, thus studying not only the distribution and the propagation of strain in mechanically deformed systems, but also gaining valuable insights into the mechanochemically induced isomerization of trans-3,4-dimethylcyclobutene to trans,trans-2,4-hexadiene. The JEDI analysis can potentially be used in the discussion of sonochemical reactions, molecular motors, mechanophores, and photoswitches as well as in the development of molecular force probes. ",
                    "score": 0.8631880283355713
                },
                {
                    "id": 23543079,
                    "contents": "Efficient Quantum Vibrational Spectroscopy of Water with High-Order Path Integrals: From Bulk to Interfaces.\nVibrational spectroscopy is key in probing the interplay between the structure and dynamics of aqueous systems. To map different regions of experimental spectra to the microscopic structure of a system, it is important to combine them with first-principles atomistic simulations that incorporate the quantum nature of nuclei. Here we show that the large cost of calculating the quantum vibrational spectra of aqueous systems can be dramatically reduced compared with standard path integral methods by using approximate quantum dynamics based on high-order path integrals. Together with state-of-the-art machine-learned electronic properties, our approach gives an excellent description not only of the infrared and Raman spectra of bulk water but also of the 2D correlation and the more challenging sum-frequency generation spectra of the water-air interface. This paves the way for understanding complex interfaces such as water encapsulated between or in contact with hydrophobic and hydrophilic materials through robust and inexpensive surface-sensitive and multidimensional spectra with first-principles accuracy.",
                    "score": 0.8630426526069641
                },
                {
                    "id": 8715281,
                    "contents": "Spectroscopic properties in the liquid phase: combining high-level ab initio calculations and classical molecular dynamics.\nWe present an integrated computational tool, rooted in density functional theory, the polarizable continuum model, and classical molecular dynamics employing spherical boundary conditions, to study the spectroscopic observables of molecules in solution. As a test case, a modified OPLS-AA force field has been developed and used to compute the UV and NMR spectra of acetone in aqueous solution. The results show that provided the classical force fields are carefully reparameterized and validated, the proposed approach is robust and effective, and can also be used by nonspecialists to provide a general and powerful complement to experimental techniques.",
                    "score": 0.8630046844482422
                },
                {
                    "id": 14812926,
                    "contents": "Fast and accurate hybrid QM//MM approach for computing anharmonic corrections to vibrational frequencies.\nWe have developed and tested a new time-effective and accurate hybrid QM//MM generalized second-order vibrational perturbation theory (GVPT2) approach. In this approach, two different levels of theory were used, a high level one (DFT) for computing the harmonic spectrum and a lower fast one (Molecular Mechanic) for the anharmonic corrections. To validate our approach, we used B2PLYP/def2-TZVPP as the high-level method, and the MMFF94 method for the anharmonic corrections as the low-level method. The calculations were carried out on 28 molecules (containing from 2 to 47 atoms) covering a broad range of vibrational modes present in organic molecules. We find that this fast hybrid method reproduces the experimental frequencies with a very good accuracy for organic and bio-molecules. The root-mean-square deviation (RMSD) is about 27 cm <sup-1</sup while the full B3LYP/SNSD simulation reproduces the experimental values with a RMSD of about 41 cm <sup-1</sup. Concerning the computational time, the hybrid B2PLYP//MMFF94 approach considerably outperforms the full B3LYP/SNSD: for the larger molecule of our set (a dipeptide containing 47 atoms), the anharmonic corrections are 2300 times faster using hybrid MMFF94 rather than full B3LYP, which represents an additional computation time to the harmonic calculation of merely 9 %, instead of 32100 % with the full B3LYP approach. This time-effective and accurate alternative to the traditional GVPT2 approach will allow the spectroscopy community to explore anharmonic effects in larger biomolecules, which are generally unaffordable.",
                    "score": 0.8629976511001587
                },
                {
                    "id": 848577,
                    "contents": "Low-frequency parameterization of hydrogen bonding.\nWe review the model of the hydrogen bond developed by Lippincott and Schroeder and discuss the frequency range in which it is valid, specifically in the optical and near infrared range. We then show why and how to modify the Lippincott and Schroeder formulate to apply to the far infrared and lower ranges. The contrasts between the old and modified systems, particularly with respect to the effective force constants are worked out and plotted for an example.",
                    "score": 0.8629038333892822
                },
                {
                    "id": 7008279,
                    "contents": "Potential energy functions: from consistent force fields to spectroscopically determined polarizable force fields.\nWe review our methodology for producing physically accurate potential energy functions, particularly relevant in the context of Lifson's goal of including frequency agreement as one of the criteria of a self-consistent force field. Our spectroscopically determined force field (SDFF) procedure guarantees such agreement by imposing it as an initial constraint on parameter optimization, and accomplishes this by an analytical transformation of ab initio \"data\" into the energy function format. After describing the elements of the SDFF protocol, we indicate its implementation to date and then discuss recent advances in our representation of the force field, in particular those required to produce an SDFF for the peptide group.",
                    "score": 0.8628669381141663
                },
                {
                    "id": 13711482,
                    "contents": "Force fields for classical molecular dynamics.\nIn this chapter we review the basic features and the principles underlying molecular mechanics force fields commonly used in molecular modeling of biological macromolecules. We start by summarizing the historical background and then describe classical pairwise additive potential energy functions. We introduce the problem of the calculation of nonbonded interactions, of particular importance for charged macromolecules. Different parameterization philosophies are then presented, followed by a section on force field validation. We conclude with a brief overview on future perspectives for the development of classical force fields.",
                    "score": 0.8625624775886536
                },
                {
                    "id": 7982335,
                    "contents": "Exploring the effect of anharmonicity of molecular vibrations on thermodynamic properties.\nThermodynamic properties of selected small and medium size molecules were calculated using harmonic and anharmonic vibrational frequencies. Harmonic vibrational frequencies were obtained by normal mode analysis, whereas anharmonic ones were calculated using the vibrational self-consistent field (VSCF) method. The calculated and available experimental thermodynamic data for zero point energy, enthalpy, entropy, and heat capacity are compared. It is found that the anharmonicity and coupling of molecular vibrations can play a significant role in predicting accurate thermodynamic quantities. Limitations of the current VSCF method for low frequency modes have been partially removed by following normal mode displacements in internal, rather than Cartesian, coordinates.",
                    "score": 0.8624292016029358
                },
                {
                    "id": 13463323,
                    "contents": "PICVib: an accurate, fast, and simple procedure to investigate selected vibrational modes at high theoretical levels.\nA new approach Procedure for Investigating Categories of Vibrations (PICVib) for estimating vibrational frequencies of selected modes using only the structure and energy calculations at a more demanding computational level is presented and explored. The PICVib has an excellent performance at only a small fraction of the computational demand required for a complete analytical calculation. The errors are smaller than ca. 0.5% when DFT functionals are combined with high level ab initio methods. The approach is general because it can use any quantum chemical program and electronic structure method. It is very robust because it was validated for a wide range of frequency values (ca. 20-4800 cm(-1)) and systems: XH(3) (D(3h) ) with X = B, Al, Ga, N, P, As, O, S, and Se, YH(4) (D(4h) ) with Y = C, Si, and Ge, conformers of RDX, S(N) 2 and E2 reactions, [W(dppe)(2)(NNC(5)H(10))] complex, carbon nanotubes, and hydrogen-bonded complexes including guanine-cytosine pair.",
                    "score": 0.8622503876686096
                },
                {
                    "id": 15561105,
                    "contents": "Supramolecular Chemistry and Mechanochemistry of Macromolecules: Recent Advances by Single-Molecule Force Spectroscopy.\nAtomic force spectroscopy (AFM)-based single-molecule force spectroscopy (SMFS) was invented in the 1990s. Since then, SMFS has been developed into a powerful tool to study the inter- and intra-molecular interactions of macromolecules. Using SMFS, a number of problems in the field of supramolecular chemistry and mechanochemistry have been studied at the single-molecule level, which are not accessible by traditional ensemble characterization methods. In this review, the principles of SMFS are introduced, followed by the discussion of several problems of contemporary interest at the interface of supramolecular chemistry and mechanochemistry of macromolecules, including single-chain elasticity of macromolecules, interactions between water and macromolecules, interactions between macromolecules and solid surface, and the interactions in supramolecular polymers. ",
                    "score": 0.8621712923049927
                },
                {
                    "id": 16247872,
                    "contents": "Efficient anharmonic vibrational spectroscopy for large molecules using local-mode coordinates.\nThis article presents a general computational approach for efficient simulations of anharmonic vibrational spectra in chemical systems. An automated local-mode vibrational approach is presented, which borrows techniques from localized molecular orbitals in electronic structure theory. This approach generates spatially localized vibrational modes, in contrast to the delocalization exhibited by canonical normal modes. The method is rigorously tested across a series of chemical systems, ranging from small molecules to large water clusters and a protonated dipeptide. It is interfaced with exact, grid-based approaches, as well as vibrational self-consistent field methods. Most significantly, this new set of reference coordinates exhibits a well-behaved spatial decay of mode couplings, which allows for a systematic, a priori truncation of mode couplings and increased computational efficiency. Convergence can typically be reached by including modes within only about 4 Å. The local nature of this truncation suggests particular promise for the ab initio simulation of anharmonic vibrational motion in large systems, where connection to experimental spectra is currently most challenging. ",
                    "score": 0.8617058992385864
                },
                {
                    "id": 17684706,
                    "contents": "Theory of coherent two-dimensional vibrational spectroscopy.\nTwo-dimensional (2D) vibrational spectroscopy has emerged as one of the most important experimental techniques useful to study the molecular structure and dynamics in condensed phases. Theory and computation have also played essential and integral roles in its development through the nonlinear optical response theory and computational methods such as molecular dynamics (MD) simulations and electronic structure calculations. In this article, we present the fundamental theory of coherent 2D vibrational spectroscopy and describe computational approaches to simulate the 2D vibrational spectra. The classical approximation to the quantum mechanical nonlinear response function is invoked from the outset. It is shown that the third-order response function can be evaluated in that classical limit by using equilibrium or non-equilibrium MD simulation trajectories. Another simulation method is based on the assumptions that the molecular vibrations can still be described quantum mechanically and that the relevant molecular response functions are evaluated by the numerical integration of the Schrödinger equation. A few application examples are presented to help the researchers in this and related areas to understand the fundamental principles and to use these methods for their studies with 2D vibrational spectroscopic techniques. In summary, this exposition provides an overview of current theoretical efforts to understand the 2D vibrational spectra and an outlook for future developments.",
                    "score": 0.8616575598716736
                },
                {
                    "id": 16303392,
                    "contents": "Measuring electric fields and noncovalent interactions using the vibrational stark effect.\nOver the past decade, we have developed a spectroscopic approach to measure electric fields inside matter with high spatial (&lt;1 Å) and field (&lt;1 MV/cm) resolution. The approach hinges on exploiting a physical phenomenon known as the vibrational Stark effect (VSE), which ultimately provides a direct mapping between observed vibrational frequencies and electric fields. Therefore, the frequency of a vibrational probe encodes information about the local electric field in the vicinity around the probe. The VSE method has enabled us to understand in great detail the underlying physical nature of several important biomolecular phenomena, such as drug-receptor selectivity in tyrosine kinases, catalysis by the enzyme ketosteroid isomerase, and unidirectional electron transfer in the photosynthetic reaction center. Beyond these specific examples, the VSE has provided a conceptual foundation for how to model intermolecular (noncovalent) interactions in a quantitative, consistent, and general manner. The starting point for research in this area is to choose (or design) a vibrational probe to interrogate the particular system of interest. Vibrational probes are sometimes intrinsic to the system in question, but we have also devised ways to build them into the system (extrinsic probes), often with minimal perturbation. With modern instruments, vibrational frequencies can increasingly be recorded with very high spatial, temporal, and frequency resolution, affording electric field maps correspondingly resolved in space, time, and field magnitude. In this Account, we set out to explain the VSE in broad strokes to make its relevance accessible to chemists of all specialties. Our intention is not to provide an encyclopedic review of published work but rather to motivate the underlying framework of the methodology and to describe how we make and interpret the measurements. Using certain vibrational probes, benchmarked against computer models, it is possible to use the VSE to measure absolute electric fields in arbitrary environments. The VSE approach provides an organizing framework for thinking generally about intermolecular interactions in a quantitative way and may serve as a useful conceptual tool for molecular design. ",
                    "score": 0.8614503145217896
                },
                {
                    "id": 20964778,
                    "contents": "The Bending Mode of Water: A Powerful Probe for Hydrogen Bond Structure of Aqueous Systems.\nInsights into the microscopic structure and dynamics of the water's hydrogen-bonded network are crucial to understand the role of water in biology, atmospheric and geochemical processes, and chemical reactions in aqueous systems. Vibrational spectroscopy of water has provided many such insights, in particular using the O-H stretch mode. In this Perspective, we summarize our recent studies that have revealed that the H-O-H bending mode can be an equally powerful reporter for the microscopic structure of water and provides more direct access to the hydrogen-bonded network than the conventionally studied O-H stretch mode. We discuss the fundamental vibrational properties of the water bending mode, such as the intermolecular vibrational coupling, and its effects on the spectral lineshapes and vibrational dynamics. Several examples of static and ultrafast bending mode spectroscopy illustrate how the water bending mode provides an excellent window on the microscopic structure of both bulk and interfacial water.",
                    "score": 0.8613491654396057
                },
                {
                    "id": 8948891,
                    "contents": "Quantum studies of the vibrations in H3O2- and D3O2-.\nThe vibrations of H3O2- and D3O2- are investigated using diffusion Monte Carlo (DMC) and vibrational configuration-interaction approaches, as implemented in the program MULTIMODE. These studies use the potential surface recently developed by Huang et al. [ J. Am. Chem. Soc. 126, 5042 (2004)]. The focus of this work is on the vibrational ground state and fundamentals which occur between 100 and 3700 cm(-1). In most cases, excellent agreement is obtained between the fundamental frequencies calculated by the two approaches. This serves to demonstrate the power of both methods for treating this very anharmonic system. Based on the results of the MULTIMODE and DMC treatments, the extent and nature of the couplings in H3O2- and D3O2- are investigated.",
                    "score": 0.8612710237503052
                },
                {
                    "id": 13735590,
                    "contents": "Size-extensive vibrational self-consistent field method.\nThe vibrational self-consistent field (VSCF) method is a mean-field approach to solve the vibrational Schrödinger equation and serves as a basis of vibrational perturbation and coupled-cluster methods. Together they account for anharmonic effects on vibrational transition frequencies and vibrationally averaged properties. This article reports the definition, programmable equations, and corresponding initial implementation of a diagrammatically size-extensive modification of VSCF, from which numerous terms with nonphysical size dependence in the original VSCF equations have been eliminated. When combined with a quartic force field (QFF), this compact and strictly size-extensive VSCF (XVSCF) method requires only quartic force constants of the ∂(4)V/∂Q(i)(2)∂Q(j)(2) type, where V is the electronic energy and Q(i) is the ith normal coordinate. Consequently, the cost of a XVSCF calculation with a QFF increases only quadratically with the number of modes, while that of a VSCF calculation grows quartically. The effective (mean-field) potential of XVSCF felt by each mode is shown to be harmonic, making the XVSCF equations subject to a self-consistent analytical solution without matrix diagonalization or a basis-set expansion, which are necessary in VSCF. Even when the same set of force constants is used, XVSCF is nearly three orders of magnitude faster than VSCF implemented similarly. Yet, the results of XVSCF and VSCF are shown to approach each other as the molecular size is increased, implicating the inclusion of unnecessary, nonphysical terms in VSCF. The diagrams of the XVSCF energy expression and their evaluation rules are also proposed, underscoring their connected structures.",
                    "score": 0.8612043261528015
                },
                {
                    "id": 4960013,
                    "contents": "Heteronuclear diatomic force constants clarified through perturbation theory II.\nA simple relationship between the heteronuclear diatomic force constant (K(AB)) and the homonuclear diatomic force constants (K(AA), K(BB)), which was proposed in a previous report, has been improved through the second-order perturbation theory as K(AB) = zeta3(K(AA) x K(BB))(1/2); zeta = (R(AA) x R(BB))(1/2)/R(AB) where zeta denotes the correction factor in which R(AB), R(AA), and R(BB) are the equilibrium internuclear distances of diatomic molecules AB, AA, and BB, respectively. To test the above expression, a large number of heteronuclear diatomic force constants have been calculated and compared with those obtained from normal coordinate analyses as well as ab initio quantum mechanical methods (Gaussian 98W). We have found that the above modified expression better reproduces the force constants of most heteronuclear diatomic molecules than the previous expression. It is therefore expected that the expression may also be applied to the prediction of stretching force constants between heteronuclear diatomics in various polyatomic molecules.",
                    "score": 0.8611201047897339
                },
                {
                    "id": 5801180,
                    "contents": "Force Spectroscopy of Molecular Systems-Single Molecule Spectroscopy of Polymers and Biomolecules.\nHow do molecules interact with each other? What happens if a neurotransmitter binds to a ligand-operated ion channel? How do antibodies recognize their antigens? Molecular recognition events play a pivotal role in nature: in enzymatic catalysis and during the replication and transcription of the genome; it is also important for the cohesion of cellular structures and in numerous metabolic reactions that molecules interact with each other in a specific manner. Conventional methods such as calorimetry provide very precise values of binding enthalpies; these are, however, average values obtained from a large ensemble of molecules without knowledge of the dynamics of the molecular recognition event. Which forces occur when a single molecular couple meets and forms a bond? Since the development of the scanning force microscope and force spectroscopy a couple of years ago, tools have now become available for measuring the forces between interfaces with high precision-starting from colloidal forces to the interaction of single molecules. The manipulation of individual molecules using force spectroscopy is also possible. In this way, the mechanical properties on a molecular scale are measurable. The study of single molecules is not an exclusive domain of force spectroscopy; it can also be performed with a surface force apparatus, laser tweezers, or the micropipette technique. Regardless of these techniques, force spectroscopy has been proven as an extraordinary versatile tool. The intention of this review article is to present a critical evaluation of the actual development of static force spectroscopy. The article mainly focuses on experiments dealing with inter- and intramolecular forces-starting with \"simple\" electrostatic forces, then ligand-receptor systems, and finally the stretching of individual molecules.",
                    "score": 0.8609158396720886
                },
                {
                    "id": 13775780,
                    "contents": "Selected new developments in vibrational structure theory: potential construction and vibrational wave function calculations.\nThis perspective addresses selected recent developments in the theoretical calculation of vibrational spectra, energies, wave functions and properties. The theoretical foundation and recently developed computational protocols for constructing hierarchies of vibrational Hamiltonian operators are reviewed. A many-mode second quantization (SQ) formulation is discussed prior to the discussion of anharmonic wave functions. Emphasis is put on vibrational self-consistent field (VSCF) based methods and in particular vibrational coupled cluster (VCC) theory. Other issues are also reviewed briefly, such as inclusion of thermal effects, response theoretical calculation of spectra, and the difficulty in treating dense spectra. ",
                    "score": 0.8606513738632202
                },
                {
                    "id": 9173772,
                    "contents": "Anharmonic vibrational properties by a fully automated second-order perturbative approach.\nThis paper describes the implementation of a fully automated code for the building of anharmonic force constants and their use in a second-order perturbative evaluation of vibrorotational parameters. Next, a number of test applications are discussed, which show the strengths and limits of various computational levels.",
                    "score": 0.8601901531219482
                },
                {
                    "id": 19500410,
                    "contents": "Vibrational tug-of-war: The pK<sub>A</sub> dependence of the broad vibrational features of strongly hydrogen-bonded carboxylic acids.\nMedium and strong hydrogen bonds give rise to broad vibrational features frequently spanning several hundred wavenumbers and oftentimes exhibiting unusual substructures. These broad vibrational features can be modeled from first principles, in a reduced dimensional calculation, that adiabatically separates low-frequency modes, which modulate the hydrogen bond length, from high-frequency OH stretch and bend modes that contribute to the vibrational structure. Previously this method was used to investigate the origin of an unusual vibrational feature frequently found in the spectra of dimers between carboxylic acids and nitrogen-containing aromatic bases that spans over 900 cm<sup-1</sup and contains two broad peaks. It was found that the width of this feature largely originates from low-frequency modes modulating the hydrogen bond length and that the structure results from Fermi resonance interactions. In this report, we examine how these features change with the relative acid and base strength of the components as reflected by their aqueous pK<subA</sub values. Dimers with large pK<subA</sub differences are found to have features that can extend to frequencies below 1000 cm<sup-1</sup. The relationships between mean OH/NH frequency, aqueous pK<subA</sub, and O-N distance are examined in order to obtain a more rigorous understanding of the origin and shape of the vibrational features. The mean OH/NH frequencies are found to correlate well with O-N distances. The lowest OH stretch frequencies are found in dimer geometries with O-N distances between 2.5 and 2.6 Å. At larger O-N distances, the hydrogen bonding interaction is not as strong, resulting in higher OH stretch frequencies. When the O-N distance is smaller than 2.5 Å, the limited space between the O and N determines the OH stretch frequency, which gives rise to frequencies that decrease with O-N distances. These two effects place a lower limit on the OH stretch frequency which is calculated to be near 700 cm<sup-1</sup. Understanding how the vibrational features of strongly hydrogen-bonded structures depend on the relative pK<subA</sub and other structural parameters will guide studies of biological structures and analysis of proton transfer studies using photoacids.",
                    "score": 0.8597277998924255
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_26",
        "question": "$$\r\n\\text {Calculate the energy of a photon for a wavelength of } 100 \\mathrm{pm} \\text { (about one atomic diameter). }\r\n$$\r\n",
        "golden_answers": [
            " 2"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 9553079,
                    "contents": "The efficiency curve: a new function.\nWorking from first principles, an efficiency curve function has been developed by considering the physics of photon transport through matter. The function has been compared to other function in popular usage and been found to fit the data better especially about the knee of the curve. The main disadvantage of the new function is that it is data hungry, but this can be overcome by use of Monte Carlo simulations.",
                    "score": 0.8996001482009888
                },
                {
                    "id": 9857524,
                    "contents": "Invited review article: Single-photon sources and detectors.\nWe review the current status of single-photon-source and single-photon-detector technologies operating at wavelengths from the ultraviolet to the infrared. We discuss applications of these technologies to quantum communication, a field currently driving much of the development of single-photon sources and detectors.",
                    "score": 0.8921725749969482
                },
                {
                    "id": 19751266,
                    "contents": "Photons to the left, photons to the right, photons down under: editorial.\nEditor-in-Chief P. Scott Carney introduces the Journal's newest Topical Editor, Arti Agrawal.",
                    "score": 0.8895781636238098
                },
                {
                    "id": 15592425,
                    "contents": "Note: Derivation of two-photon circular dichroism--Addendum to \"Two-photon circular dichroism\" [J. Chem. Phys. 62, 1006 (1975)].\nThis addendum shows the detailed derivation of the fundamental equations for two-photon circular dichroism which are given in a very condensed form in the original publication [I. Tinoco, J. Chem. Phys. 62, 1006 (1975)]. In addition, some minor errors are corrected and some of the derivations in the original publication are commented. ",
                    "score": 0.8887038230895996
                },
                {
                    "id": 11469371,
                    "contents": "The development of soviet optics and spectroscopy during the past fifty years.\nA history of Soviet spectroscopy is given, with special emphasis on various areas indicating the earliest workers in each specialty and their principal successors; for example, the work of Rozhdestvenskii (anomalous dispersion); Fok (self-consistant field calculations), Terenin (photochemistry, atomic beams), Mandelstam (combination scattering), Vavilov (luminescence, quantum properties of light), Cerenkov (radiation), Chaika (atomic lifetimes), Gross (excitons), and Volkenstein (molecular vibrations).",
                    "score": 0.8850240707397461
                },
                {
                    "id": 8342719,
                    "contents": "Two-photon absorption strength: a new tool for the quantification of two-photon absorption.\nIn this paper, we define the two-photon absorption strength, a new characterization tool, similar to the oscillator strength, but for two-photon absorption. It allows the quantification of the two-photon absorption properties of molecular systems which are one-photon transparent. Its definition is such that the corresponding numerical values are around 100 for small molecules. We also show that this new theoretical tool allows the direct comparison of experimental and theoretical data without requiring the introduction of any arbitrary band width. As an example, the experimental and theoretical (AM1+CNDOS and HF+CIS3-21G) two-photon absorption properties of the 2,2'-bi(9,9-dihexylfluorene) molecule are compared.",
                    "score": 0.8843616247177124
                },
                {
                    "id": 4203003,
                    "contents": "The tracks of the Compton effect.\nThe observation of scattered radiations of larger wavelength than the primary had been repeatedly rejected or explained away by many researchers, including Compton. After years of vacillations, he recognized the effect named after him and was the first to develop a quantal equation predicting the wavelength of scattered radiation. It became one of the most significant contributions to modern radiation physics, opening the doors of quantum mechanics.",
                    "score": 0.8834136724472046
                },
                {
                    "id": 20388031,
                    "contents": "Coherent light brightens the quantum science frontier.\nControlling coherent light across a vast spectral range enables ultraprecise measurements and the quantum control of atomic, molecular, and condensed-matter systems.",
                    "score": 0.8832966089248657
                },
                {
                    "id": 15619163,
                    "contents": "Quantum optics: science and technology in a new light.\nLight facilitates exploration of quantum phenomena that illuminate the basic properties of nature and also enables radical new technologies based on these phenomena. The critical features of quantum light that underpin the opportunities for discovery and application are exceptionally low noise and strong correlations. Rapid progress in both science and technology has been stimulated by adopting components developed for optical telecommunications and networking, such as highly efficient detectors, integrated photonic circuits, and waveguide- or nanostructure-based nonlinear optical devices. These provide the means to generate new quantum states of light and matter of unprecedented scale, containing many photons with quantum correlations across space and time. Notably, networks with only several tens of photons are already beyond what can be efficiently analyzed by current computers. ",
                    "score": 0.8818521499633789
                },
                {
                    "id": 8532142,
                    "contents": "Happy centenary, photon.\nOne hundred years ago Albert Einstein introduced the concept of the photon. Although in the early years after 1905 the evidence for the quantum nature of light was not compelling, modern experiments--especially those using photon pairs--have beautifully confirmed its corpuscular character. Research on the quantum properties of light (quantum optics) triggered the evolution of the whole field of quantum information processing, which now promises new technology, such as quantum cryptography and even quantum computers.",
                    "score": 0.8814623355865479
                },
                {
                    "id": 5718365,
                    "contents": "Does the photon-diffusion coefficient depend on absorption?\nWe investigate the controversy over the precise form of the photon diffusion coefficient and suggest that it is largely independent of absorption, i.e., Do = v/3mu(s)'. After presentation of the general theoretical arguments underlying this assertion, Monte Carlo simulations are performed and explicitly reveal that the absorption independent diffusion coefficient gives better agreement with theory than the traditionally accepted photon diffusion coefficient, D(mu)a = v/3(mu(s) + mu(a)). The importance of resolving this controversy for the proper characterization of the material optical properties is discussed.",
                    "score": 0.8804655075073242
                },
                {
                    "id": 7947444,
                    "contents": "Looking to the future of quantum optics.\nLight has provided both fundamental phenomenology and enabling technology for scientific discovery for many years, and today it continues to play a central role in fundamental explorations and innovative applications. The ability to manipulate light beams and pulses with the quantum degrees of freedom of optical radiation will add to those advances. The future of quantum optics, which encompasses both the generation and manipulation of nonclassical radiation, as well as its interaction with matter, lies in the rich variety of quantum states that is now becoming feasible to prepare, together with the numerous applications in sensing, imaging, metrology, communications, and information processing that such states enable.",
                    "score": 0.8789314031600952
                },
                {
                    "id": 10876206,
                    "contents": "The rayleigh: interpretation of the unit in terms of column emission rate or apparent radiance expressed in SI units.\nThe rayleigh, originally defined as a unit to express the total column light emission rate [10(10) photons sec(-1) (m(2)column) (-1)] can equivalently be defined as a unit for apparent photon radiance ((1/4)pi 10(10) photons sec(-1) m(-2) sr(-1)). The selection of the appropriate definition will depend upon the physical situation and the interests of the user. The applicability of the unit for expressing the quantitative measurement of all extended light sources, including optically thick media, is both handy and valid.",
                    "score": 0.8783485293388367
                },
                {
                    "id": 23547850,
                    "contents": "An electron walks into a quantum bar….\nQuantum electron-light interaction may find use in microscopy applications.",
                    "score": 0.8779211640357971
                },
                {
                    "id": 15589593,
                    "contents": "Quantum optics with one or two photons.\nWe discuss the concept of a single-photon state together with how they are generated, measured and interact with linear and nonlinear systems. In particular, we consider how a single-photon state interacts with an opto-mechanical system: an optical cavity with a moving mirror and how such states can be used as a measurement probe for the mechanical degrees of freedom. We conclude with a discussion of how single-photon states are modified in a gravitational field due to the red-shift.",
                    "score": 0.8774172067642212
                },
                {
                    "id": 15144670,
                    "contents": "Ruling Engines, Diffraction Gratings and Wavelength Measurements before the Rowland Era.\nDiffraction gratings have contributed enormously to modern science. Although some historians have written about them, there is much more to be brought to light. This paper discusses their development and use in the period up to about 1880 before Rowland began to produce them. Rittenhouse described the action of a diffraction grating in 1786, but no explanation was possible until the wave theory of light was developed. Fraunhofer discovered the dark lines in the solar spectrum in 1814, and then investigated diffraction, producing the first ruled gratings, making detailed measurements and calculating the wavelengths of prominent spectral lines. After Bunsen and Kirchhoff showed the association between spectral lines and chemical elements there was an upsurge of interest in measuring wavelengths. The gratings used in this work almost all came from one source, a relatively unknown instrument maker called Nobert, who made them by an extremely laborious process using a machine he had built himself. The most significant wavelength measurements were made by Ångström, but Mascart, Van der Willigen, Stefan, Ditscheiner and Cornu also did important work. Nobert gratings were investigated by Quincke, copied photographically by Rayleigh, and were known and discussed in the USA. Nobert's work helped to advance spectroscopy much more than has been acknowledged. ",
                    "score": 0.8773820400238037
                },
                {
                    "id": 15286836,
                    "contents": "Three photons are better than two.\nThree-photon microscopy was suggested in the 1990s, but laser technology at the time was just not up to the challenge. Lauren Ware explores how recent technology advances are bringing three-photon microscopy back into focus. ",
                    "score": 0.8766661882400513
                },
                {
                    "id": 10516366,
                    "contents": "Rayleigh centennial.\nThis brief sketch of the contributions of the fourth Baron Rayleigh is intended to supplement the biographical material contained in the October 1964 issue of Applied Optics.",
                    "score": 0.875484049320221
                },
                {
                    "id": 10014731,
                    "contents": "Books and Software: Getting the basics of NMR.\nA review of Acomplete Introduction to Modern NMR Spectroscopy.",
                    "score": 0.8751314282417297
                },
                {
                    "id": 10059428,
                    "contents": "Single-photon generation by electron beams.\nWe propose a drastically new method for generating single photons in a deterministic way by interaction of electron beams with optical waveguides. We find a single swift electron to produce a guided photon with large probability. The change in energy and propagation direction of the electron reveals the creation of a photon, with the photon energy directly read from the energy-loss spectrum or the beam displacement. Our study demonstrates the viability of deterministically creating single guided photons using electron beams with better than picosecond time uncertainty, thus opening a new avenue for making room temperature, heralded frequency-tunable sources affordable for scientific and commercial developments.",
                    "score": 0.8750486373901367
                },
                {
                    "id": 10656539,
                    "contents": "Comment on: Quantum optics with particles of light.\nErrors in the recent article, \"Quantum optics with particles of light,\" are discussed. \"Dispersed states\" resulting from linear optics are simply coherent states, and have no interesting quantum statistics.",
                    "score": 0.8747096657752991
                },
                {
                    "id": 8261280,
                    "contents": "Photon correlation and scattering: introduction to the feature issue.\nThis feature issue of Applied Optics contains 31 research papers on photon correlation and scattering, many of which were presented at an OSA Topical Meeting that was held 21-23 August 2000 in Whistler, British Columbia, Canada. These papers focus on research in dynamic light scattering, surface light scattering, photon correlation, and laser velocimetry and their applications to physical, chemical, and biological processes.",
                    "score": 0.8738674521446228
                },
                {
                    "id": 15643832,
                    "contents": "Single Molecules, Cells, and Super-Resolution Optics (Nobel Lecture).\nThe resolution of a microscope is determined by the diffraction limit in classical microscopy, whereby objects that are separated by half a wavelength can no longer be visually separated. To go below the diffraction limit required several tricks and discoveries. In his Nobel Lecture, E. Betzig describes the developments that have led to modern super high-resolution microscopy. ",
                    "score": 0.8734166026115417
                },
                {
                    "id": 19633432,
                    "contents": "Measurement of the transverse spatial quantum state of light at the single-photon level: publisher's note.\nThis publisher's note amends the author listing of Opt. Lett.30, 3365 (2005)OPLEDP0146-959210.1364/OL.30.003365.",
                    "score": 0.8729994297027588
                },
                {
                    "id": 12626226,
                    "contents": "Optical properties of biological tissues: a review.\nA review of reported tissue optical properties summarizes the wavelength-dependent behavior of scattering and absorption. Formulae are presented for generating the optical properties of a generic tissue with variable amounts of absorbing chromophores (blood, water, melanin, fat, yellow pigments) and a variable balance between small-scale scatterers and large-scale scatterers in the ultrastructures of cells and tissues.",
                    "score": 0.8729310035705566
                },
                {
                    "id": 11109051,
                    "contents": "Nonlinear optics: the next decade.\nThis paper concludes the Focus Serial assembled of invited papers in key areas of nonlinear optics (Editors: J.M. Dudley and R.W. Boyd), and it discusses new directions for future research in this field.",
                    "score": 0.8725532293319702
                },
                {
                    "id": 22145386,
                    "contents": "Mid-infrared, long-wave infrared, and terahertz photonics: introduction.\nThis feature issue presents recent progress in long-wavelength photonics, focusing on wavelengths that span the mid-infrared (3-50 µm), the long-wavelength infrared (30-60 µm), and the terahertz (60-300 µm) portions of the electromagnetic spectrum. The papers in this feature issue report recent progress in the generation, manipulation, detection, and use of light across this long-wave region of the \"photonics spectrum,\" including novel sources and cutting edge advances in detectors, long-wavelength non-linear processes, optical metamaterials and metasurfaces, and molecular spectroscopy. The range of topics covered in this feature issue provide an excellent insight into the expanding interest in long-wavelength photonics, which could open new possibilities for basic research and applications in industries that span health, environmental, and security.",
                    "score": 0.872397243976593
                },
                {
                    "id": 8679229,
                    "contents": "Photon correlation and scattering: introduction to the feature issue.\nThis feature issue of Applied Optics contains 25 research papers on photon correlation and scattering. Many of the papers in this volume were presented at an OSA Topical Meeting that was held 21-24 August 1996 in Capri, Italy. The focus of these papers is research in dynamic light scattering, surface light scattering, photon correlation, laser velocimetry, and their applications to biological, chemical, and physical processes.",
                    "score": 0.8722429275512695
                },
                {
                    "id": 15981740,
                    "contents": "Employing Theories Far beyond Their Limits-The Case of the (Boguer-) Beer-Lambert Law.\nFor spectroscopists, the (Bouguer-)Beer-Lambert law is unquestionably an essential principle, since it is inseparably linked with one of the most important quantities in spectroscopy, the absorbance. In spite of its importance, a quantitative discussion of the legitimacy of relating the transmittance, the quantity that is usually measured, to the absorbance by assuming a logarithmic relation between both quantities cannot be found in literature. In this contribution, we quantitatively discuss, based on examples, the errors that can be introduced by disregarding the exact solution based on Maxwell's equations and show that these errors can easily exceed one order of magnitude. We also re-derive the Beer-Lambert law, thereby providing guidance as how to convert transmittance into absorbance properly. ",
                    "score": 0.8722129464149475
                },
                {
                    "id": 7520093,
                    "contents": "Transforming nonlocality into a frequency dependence: a shortcut to spectroscopy.\nMeasurable spectra are often derived from contractions of many-body Green's functions. One calculates hence more information than needed. Here we present and illustrate an in principle exact approach to construct effective potentials and kernels for the direct calculation of electronic spectra. In particular, a dynamical but local and real potential yields the spectral function needed to describe photoemission. We discuss for model solids the frequency dependence of this \"photoemission potential\" stemming from the nonlocality of the corresponding self-energy.",
                    "score": 0.8715386986732483
                },
                {
                    "id": 6490065,
                    "contents": "Electromagnetic fields on a quantum scale. I.\nThis is the first in a series of two articles, the second of which provides an exact electro-magnetic field description of photon emission, absorption, and radiation pattern. Photon energy exchanges are analyzed and shown to be the triggered, regenerative response of a non-local eigenstate electron. This first article presents a model-based, hidden variable analysis of quantum theory that provides the statistical nature of wave functions. The analysis uses the equations of classical electro-magnetism and conservation of energy while modeling an eigenstate electron as a nonlocal entity. Essential to the analysis are physical properties that were discovered and analyzed only after the historical interpretation of quantum mechanics was established: electron non-locality and the standing electro-magnetic energy that accompanies and encompasses an active, electrically small volume. The standing energy produces a driving radiation reaction force that, under certain circumstances, is many orders of magnitude larger than currently accepted values. These properties provide a sufficient basis for the Schrödinger equation as a descriptor of non-relativistic eigenstate electrons in or near equilibrium. The uncertainty principle follows, as does the exclusion principle. The analysis leads to atomic stability and causality in the sense that the status of physical phenomena at any instant specifies the status an instant later.",
                    "score": 0.8711700439453125
                },
                {
                    "id": 11864319,
                    "contents": "Correction to the Beer-Lambert-Bouguer law for optical absorption.\nThe Beer-Lambert-Bouguer absorption law, known as Beer's law for absorption in an optical medium, is precise only at power densities lower than a few kW. At higher power densities this law fails because it neglects the processes of stimulated emission and spontaneous emission. In previous models that considered those processes, an analytical expression for the absorption law could not be obtained. We show here that by utilizing the Lambert W-function, the two-level energy rate equation model is solved analytically, and this leads into a general absorption law that is exact because it accounts for absorption as well as stimulated and spontaneous emission. The general absorption law reduces to Beer's law at low power densities. A criterion for its application is given along with experimental examples.",
                    "score": 0.8711206912994385
                },
                {
                    "id": 10944766,
                    "contents": "A simple introduction to multiphoton microscopy.\nMultiphoton microscopy is a powerful technique based on complex quantum mechanical effects. Thanks to the development of turnkey mode-locked laser systems, multiphoton microscopy is now available for everyone to use without extreme complexity. In this short introduction, we describe qualitatively the important concepts underlying the most commonly used type of multiphoton microscopy (two-photon excitation). We elucidate how those properties lead to the powerful results that have been achieved using this technique. As with any technique, two-photon excitation microscopy has limitations that we describe, and we provide examples of particular classes of experiments where two-photon excitation microscopy is advantageous over other approaches. Finally, we briefly describe other useful multiphoton microscopy approaches, such as three-photon excitation and second harmonic generation imaging.",
                    "score": 0.8709803819656372
                },
                {
                    "id": 6668055,
                    "contents": "Molecules in optical, electric, and magnetic fields: a personal perspective.\nPhysical chemistry and theoretical chemistry have advanced over the past 50 years from being largely qualitative to having a mature status based firmly on the principles of quantum and statistical mechanics. My interest in the chemical elements and their compounds has prompted me to learn more about the nature of matter through the measurement and interpretation of optical, electric, and magnetic properties of molecules. In addition to holding intrinsic interest, such properties tell us about charge and current distributions and form the basis of electro-optics, magneto-optics, and nonlinear optics. They also help us understand the nature and strength of long-range intermolecular forces, the hydrogen bond, and molecular biology-topics that are apparently forever young.",
                    "score": 0.8706868290901184
                },
                {
                    "id": 10876305,
                    "contents": "Submillimeter laser wavelength tables.\nTables are presented that list submillimeter laser lines observed in the optical pumping of molecular gases with CO(2) laser radiation. The lines have been obtained from previous publications by various authors and are in the wavelength range from 34micron to 1.965 mm. One table lists, for each gas, the submillimeter wavelengths observed, the line of the CO(2) pump laser, references to the literature, and, where available, the polarization and power of the submillimeter laser and the power of the CO(2) pump laser. A second table lists all the observed laser wavelengths in numerical order together with the gas in which each line was observed. These tables should be useful to researchers working with submillimeter lasers.",
                    "score": 0.8699918985366821
                },
                {
                    "id": 11296293,
                    "contents": "Absorption spectroscopy at the limit: detection of a single atom.\nWe investigate the sensitivity limit of absorption spectroscopy. An experiment is described in which the decrease in transmitted light intensity that is due to absorption by a single, electromagnetically confined atomic ion is observed.",
                    "score": 0.8699818849563599
                },
                {
                    "id": 8657344,
                    "contents": "Photon correlation and scattering: introduction to the feature issue.\nThis special issue of Applied Optics contains research papers on photon correlation and scattering, many of which were presented at the OSA Topical Meeting that was held 16-18 August 2004.",
                    "score": 0.8697599172592163
                },
                {
                    "id": 21406084,
                    "contents": "Multiphoton microscopy: a personal historical review, with some future predictions.\nThe historical development of multiphoton microscopy is described, starting with a review of two-photon absorption, and including two- and three-photon fluorescence microscopies, and second- and third-harmonic generation microscopies. The effects of pulse length on signal strength and breakdown are considered. Different contrast mechanisms, including use of nanoparticles, are discussed. Two new promising techniques that can be applied to multiphoton microscopy are described.",
                    "score": 0.86878901720047
                },
                {
                    "id": 22038408,
                    "contents": "Observation of the molecular response to light upon photoexcitation.\nWhen a molecule interacts with light, its electrons can absorb energy from the electromagnetic field by rapidly rearranging their positions. This constitutes the first step of photochemical and photophysical processes that include primary events in human vision and photosynthesis. Here, we report the direct measurement of the initial redistribution of electron density when the molecule 1,3-cyclohexadiene (CHD) is optically excited. Our experiments exploit the intense, ultrashort hard x-ray pulses of the Linac Coherent Light Source (LCLS) to map the change in electron density using ultrafast x-ray scattering. The nature of the excited electronic state is identified with excellent spatial resolution and in good agreement with theoretical predictions. The excited state electron density distributions are thus amenable to direct experimental observation.",
                    "score": 0.8683285713195801
                },
                {
                    "id": 8342078,
                    "contents": "Quantum yield calculations for strongly absorbing chromophores.\nThis article demonstrates that a commonly-made assumption in quantum yield calculations may produce errors of up to 25% in extreme cases and can be corrected by a simple modification to the analysis.",
                    "score": 0.8677443861961365
                },
                {
                    "id": 10876170,
                    "contents": "Men and milestones in optics. VI: The rise of infrared spectroscopy in the U.S.A. to World War II.\nThis survey reviews the rise of ir spectroscopy in the United States from about 1845 to about 1941 in terms of the discoveries and activities of the individuals who contributed importantly to this field. Generally speaking, the emphasis is on molecular, rather than atomic, spectra and on experimentation, rather than theory. The presentation is chronological with respect to the birth dates of the contributors, and a limited amount of biographical material is included for some of them. Some quantitative information about the institutions where ir spectroscopy was carried on, and for the journals in which the results appeared, is appended.",
                    "score": 0.8673588633537292
                },
                {
                    "id": 11419774,
                    "contents": "Coherence-a Sticky Subject.\nThe concept of coherence has been applied in the quantum theory of radiation and matter as well as in classical optics. We review here the meaning of the term in each case and show how these apparently different uses of the word coherence can be understood in terms of a single concept involving interference (nonzero cross terms), minimum uncertainty, and cohering (uniform variance) of the wave packet that describes the system. Self-induced transparency, superradiance, and superconductivity are discussed as dramatic examples of coherence.",
                    "score": 0.8672425150871277
                },
                {
                    "id": 4736833,
                    "contents": "Observation of the Kapitza-Dirac effect.\nIn their famous 1927 experiment, Davisson and Germer observed the diffraction of electrons by a periodic material structure, so showing that electrons can behave like waves. Shortly afterwards, Kapitza and Dirac predicted that electrons should also be diffracted by a standing light wave. This Kapitza-Dirac effect is analogous to the diffraction of light by a grating, but with the roles of the wave and matter reversed. The electron and the light grating interact extremely weakly, via the 'ponderomotive potential', so attempts to measure the Kapitza-Dirac effect had to wait for the development of the laser. The idea that the underlying interaction with light is resonantly enhanced for electrons in an atom led to the observation that atoms could be diffracted by a standing wave of light. Deflection of electrons by high-intensity laser light, which is also a consequence of the Kapitza-Dirac effect, has also been demonstrated. But the coherent interference that characterizes wave diffraction has not hitherto been observed. Here we report the diffraction of free electrons from a standing light wave-a realization of the Kapitza-Dirac effect as originally proposed.",
                    "score": 0.8671983480453491
                },
                {
                    "id": 6392221,
                    "contents": "[Not Available].\nThe object of this study is Leonhard Euler's physical optics as it is formulated in Nova theoria lucis et colorum (1746). The focus is on this particular work by Euler for two reasons: 1) Nova theoria represents undoubtedly the most comprehensive and systematic medium theory of the 18th century; 2) it contains the basic principles of Euler's conception of the nature of light, which he later maintained. The works of the most important advocates of this tradition (Huygens, Malebranche and Johann II Bernoulli) are here analyzed to give a historical frame to Euler's role in the medium tradition. Though these authors try to elaborate a theory of light alternative to the emission theory, they never realize the contrast between the medium and the emission traditions. From this perspective, Nova theoria is a real transition point: Euler is fully aware of the antithesis between the two traditions; he compares them, he refutes the arguments in favor of emission theory and formulates an alternative one, that will substantially be the first and the most significant antagonist of emission model. The essay examines also the central questions of Euler's theory of light, i.e. how pulses are generated and propagated, the nature of the rays of light and the relations among pulse distance, frequency, and velocity.",
                    "score": 0.8671938180923462
                },
                {
                    "id": 8808999,
                    "contents": "PhotochemCAD 2: a refined program with accompanying spectral databases for photochemical calculations.\nThe PhotochemCAD program has been revised extensively. Calculations can be performed using eight modules (oscillator strength, transition dipole moment and natural radiative lifetime, Förster energy transfer, multicomponent analysis, blackbody radiator, artificial spectrum creation, transmission calculation, and analysis of energy transfer among linear multichromophore arrays). The user interface has been streamlined to facilitate visual display, operation of the various modules, input of user data via a wizard and output of spectra and calculations. The database of absorption and fluorescence spectra has been expanded to 150 photochemically relevant compounds. A database of solar spectra has been added. The program runs under Windows and is equipped with extensive literature references and help features, including a tutorial section with video files.",
                    "score": 0.8670470118522644
                },
                {
                    "id": 13131488,
                    "contents": "Measurement of a wavelength of light for which the energy shift for an atom vanishes.\nLight at a magic-zero wavelength causes a zero energy shift for an atom. We measured the longest magic-zero wavelength for ground state potassium atoms to be λ(zero)=768.9712(15) nm, and we show how this measurement provides an improved experimental benchmark for atomic structure calculations. This λ(zero) measurement determines the ratio of the potassium atom D1 and D2 line strengths with record precision. It also demonstrates a new application for atom interferometry, and we discuss how decoherence will fundamentally limit future measurements of magic-zero wavelengths.",
                    "score": 0.8670188784599304
                },
                {
                    "id": 21468596,
                    "contents": "The Bouguer-Beer-Lambert Law: Shining Light on the Obscure.\nThe Beer-Lambert law is unquestionably the most important law in optical spectroscopy and indispensable for the qualitative and quantitative interpretation of spectroscopic data. As such, every spectroscopist should know its limits and potential pitfalls, arising from its application, by heart. It is the goal of this work to review these limits and pitfalls, as well as to provide solutions and explanations to guide the reader. This guidance will allow a deeper understanding of spectral features, which cannot be explained by the Beer-Lambert law, because they arise from electromagnetic effects/the wave nature of light. Those features include band shifts and intensity changes based exclusively upon optical conditions, i. e. the method chosen to record the spectra, the substrate and the form of the sample. As such, the review will be an essential tool towards a full understanding of optical spectra and their quantitative interpretation based not only on oscillator positions, but also on their strengths and damping constants.",
                    "score": 0.8668810725212097
                },
                {
                    "id": 21353628,
                    "contents": "Publisher Correction: Selective manipulation of electronically excited states through strong light-matter interactions.\nAn amendment to this paper has been published and can be accessed via a link at the top of the paper.",
                    "score": 0.866851806640625
                },
                {
                    "id": 22458302,
                    "contents": "Ray Freeman 1932-2022.\nRay Freeman changed the way that chemists use NMR spectroscopy, playing a central role in the great blossoming of NMR techniques and their chemical and biological applications that followed the introduction of pulse Fourier transform methods in 1966. Techniques that he pioneered are still in daily use in every serious chemical laboratory in the world. He is remembered by the NMR community as both a great innovator and a great communicator, and by his former students and postdocs as the kindest and most supportive of supervisors.",
                    "score": 0.8665242791175842
                },
                {
                    "id": 12070654,
                    "contents": "Spectroscopic method for measuring refractive index.\nA method for routine, but precise measurements of refractive index is described. The method is fast and accurate. It is based on the analysis of interference fringes, and uses positions of the fringe maxima and/or minima and a precise measurement of sample thickness to extract refractive index. An extremely dense dataset of refractive index values over the entire spectral range of interest can be routinely obtained. ",
                    "score": 0.8662381768226624
                }
            ],
            "metric_score": {
                "retrieval_recall": 1,
                "retrieval_precision": 0.2
            }
        }
    },
    {
        "id": "test_27",
        "question": "A proton and a negatively charged $\\mu$ meson (called a muon) can form a short-lived species called a mesonic atom. The charge of a muon is the same as that on an electron and the mass of a muon is $207 m_{\\mathrm{e}}$. Assume that the Bohr theory can be applied to such a mesonic atom and calculate the ground-state energy, the radius of the first Bohr orbit, and the energy and frequency associated with the $n=1$ to $n=2$ transition in a mesonic atom.",
        "golden_answers": [
            " 1.69"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 20460003,
                    "contents": "Measuring the α-particle charge radius with muonic helium-4 ions.\nThe energy levels of hydrogen-like atomic systems can be calculated with great precision. Starting from their quantum mechanical solution, they have been refined over the years to include the electron spin, the relativistic and quantum field effects, and tiny energy shifts related to the complex structure of the nucleus. These energy shifts caused by the nuclear structure are vastly magnified in hydrogen-like systems formed by a negative muon and a nucleus, so spectroscopy of these muonic ions can be used to investigate the nuclear structure with high precision. Here we present the measurement of two 2S-2P transitions in the muonic helium-4 ion that yields a precise determination of the root-mean-square charge radius of the α particle of 1.67824(83) femtometres. This determination from atomic spectroscopy is in excellent agreement with the value from electron scattering<sup1</sup, but a factor of 4.8 more precise, providing a benchmark for few-nucleon theories, lattice quantum chromodynamics and electron scattering. This agreement also constrains several beyond-standard-model theories proposed to explain the proton-radius puzzle<sup2-5</sup, in line with recent determinations of the proton charge radius<sup6-9</sup, and establishes spectroscopy of light muonic atoms and ions as a precise tool for studies of nuclear properties.",
                    "score": 0.8572406768798828
                },
                {
                    "id": 16722714,
                    "contents": "Where to place the positive muon in the Periodic Table?\nIn a recent study it was suggested that the positively charged muon is capable of forming its own \"atoms in molecules\" (AIM) in the muonic hydrogen-like molecules, composed of two electrons, a muon and one of the hydrogen's isotopes, thus deserves to be placed in the Periodic Table [Phys. Chem. Chem. Phys., 2014, 16, 6602]. In the present report, the capacity of the positively charged muon in forming its own AIM is considered in a large set of molecules replacing muons with all protons in the hydrides of the second and third rows of the Periodic Table. Accordingly, in a comparative study the wavefunctions of both sets of hydrides and their muonic congeners are first derived beyond the Born-Oppenheimer (BO) paradigm, assuming protons and muons as quantum waves instead of clamped particles. Then, the non-BO wavefunctions are used to derive the AIM structures of both hydrides and muonic congeners within the context of the multi-component quantum theory of atoms in molecules. The results of the analysis demonstrate that muons are generally capable of forming their own atomic basins and the properties of these basins are not fundamentally different from those AIM containing protons. Particularly, the bonding modes in the muonic species seem to be qualitatively similar to their congener hydrides and no new bonding model is required to describe the bonding of muons to a diverse set of neighboring atoms. All in all, the positively charged muon is similar to a proton from the structural and bonding viewpoint and deserves to be placed in the same box of hydrogen in the Periodic Table. This conclusion is in line with a large body of studies on the chemical kinetics of the muonic molecules portraying the positively charged muon as a lighter isotope of hydrogen. ",
                    "score": 0.8428563475608826
                },
                {
                    "id": 8655942,
                    "contents": "Ortho-para transition rate in mu-molecular hydrogen and the proton's induced pseudoscalar coupling gp.\nWe report a measurement of the ortho-para transition rate in the p mu p molecule. The experiment was conducted at TRIUMF via the measurement of the time dependence of the 5.2 MeV neutrons from muon capture in liquid hydrogen. The measurement yielded an ortho-para rate Lambda op = (11.1 +/- 1.7 +/-(0.9)(0.6)) x 10(4) s(-1), which is substantially larger than the earlier result of Bardin et al. The result has striking implications for the proton's induced pseudoscalar coupling g(p), changing the value of g(p) obtained from the most precise ordinary muon capture measurement from 10.6 +/- 2.7 to 0.8 +/- 2.8, and from the sole radiative muon capture measurement from 12.2 +/- 1.1 to 10.6 +/- 1.2, bringing the latter result closer to theoretical predictions.",
                    "score": 0.8418610095977783
                },
                {
                    "id": 17275464,
                    "contents": "Decay of muons generated by laser-induced processes in ultra-dense hydrogen H(0).\nThis work reports identification of muons by their characteristic life-time of 2.20 μs after laser-induction of their precursor mesons, both kaons K<sup±</sup and <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" <mml:mrow <mml:msubsup<mml:mrow<mml:mtextK</mml:mtext</mml:mrow <mml:mrow<mml:miL</mml:mi</mml:mrow <mml:mrow<mml:mn0</mml:mn</mml:mrow </mml:msubsup </mml:mrow </mml:math and pions π<sup±</sup in ultra-dense hydrogen H(0). The pair-production signal from scattered muons at a metal converter in front of a photo-multiplier detector is observed with its decay. The observed signal intensity is decreased by a metal beam-flag which intercepts the meson and muon flux to the detector. Using D(0), the observed decay time is (2.23 ± 0.05) μs in agreement with the free muon lifetime of 2.20 μs. This signal is apparently due to the preferential generation of positive muons. Using p(0), the observed decay time is in the range 1-2 μs, thus shorter than the free muon lifetime, as expected when the signal is mainly caused by negative muons which interact with matter by muon capture.",
                    "score": 0.8414645791053772
                },
                {
                    "id": 16274969,
                    "contents": "Negative muon chemistry: the quantum muon effect and the finite nuclear mass effect.\nThe any-particle molecular orbital method at the full configuration interaction level has been employed to study atoms in which one electron has been replaced by a negative muon. In this approach electrons and muons are described as quantum waves. A scheme has been proposed to discriminate nuclear mass and quantum muon effects on chemical properties of muonic and regular atoms. This study reveals that the differences in the ionization potentials of isoelectronic muonic atoms and regular atoms are of the order of millielectronvolts. For the valence ionizations of muonic helium and muonic lithium the nuclear mass effects are more important. On the other hand, for 1s ionizations of muonic atoms heavier than beryllium, the quantum muon effects are more important. In addition, this study presents an assessment of the nuclear mass and quantum muon effects on the barrier of Heμ + H2 reaction. ",
                    "score": 0.8380283117294312
                },
                {
                    "id": 18519595,
                    "contents": "Toward a muon-specific electronic structure theory: effective electronic Hartree-Fock equations for muonic molecules.\nAn effective set of Hartree-Fock (HF) equations are derived for electrons of muonic systems, i.e., molecules containing a positively charged muon, conceiving the muon as a quantum oscillator, which are completely equivalent to the usual two-component HF equations used to derive stationary states of the muonic molecules. In these effective equations, a non-Coulombic potential is added to the orthodox coulomb and exchange potential energy terms, which describes the interaction of the muon and the electrons effectively and is optimized during the self-consistent field cycles. While in the two-component HF equations a muon is treated as a quantum particle, in the effective HF equations it is absorbed into the effective potential and practically transformed into an effective potential field experienced by electrons. The explicit form of the effective potential depends on the nature of muon's vibrations and is derivable from the basis set used to expand the muonic spatial orbital. The resulting effective Hartree-Fock equations are implemented computationally and used successfully, as a proof of concept, in a series of muonic molecules containing all atoms from the second and third rows of the Periodic Table. To solve the algebraic version of the equations muon-specific Gaussian basis sets are designed for both muon and surrounding electrons and it is demonstrated that the optimized exponents are quite distinct from those derived for the hydrogen isotopes. The developed effective HF theory is quite general and in principle can be used for any muonic system while it is the starting point for a general effective electronic structure theory that incorporates various types of quantum correlations into the muonic systems beyond the HF equations.",
                    "score": 0.8345492482185364
                },
                {
                    "id": 22378412,
                    "contents": "Nuclear Excitation by Free Muon Capture.\nEfficient excitation of nuclei via exchange of a real or virtual photon has a fundamental importance for nuclear science and technology development. Here, we present a mechanism of nuclear excitation based on the capture of a free muon into the atomic orbits (NEμC). The cross section of such a proposed process is evaluated using the Feshbach projection operator formalism and compared to other known excitation phenomena, i.e., photoexcitation and nuclear excitation by electron capture (NEEC), showing up to 10 orders of magnitude increase in cross section. NEμC is particularly interesting for MeV excitations that become accessible thanks to the stronger binding of muons to the nucleus. The binding energies of muonic atoms have been calculated introducing a state of the art modification to the Flexible Atomic Code. An analysis of experimental scenarios in the context of modern muon production facilities shows that the effect can be detectable for selected isotopes. The total probability of NEμC is predicted to be P≈1×10^{-6} per incident muon in a beam-based scenario. Given the high transition energy provided by muons, NEμC can have important consequences for isomer feeding and particle-induced fission.",
                    "score": 0.8320471048355103
                },
                {
                    "id": 4418526,
                    "contents": "Muonic helium atom as a classical three-body problem\nWe study the classical problem of the muonic helium atom, a helium atom with one of its electrons replaced by a muon. First, we establish the connection of the model with the one-dimensional frozen planetary approximation of the helium atom and find that there is classically stable motion for the configuration alpha-particle-electron-muon, and no stable motion for the alpha-particle-muon-electron configuration. After that, we introduce the restricted muonic helium problem, a model for the movement of an electron in the potential of the alpha particle/muon pair moving in a circular orbit. In this model, the equilibrium points, their associated Lyapunov families of periodic orbits, and their stability parameters were studied. The most interesting feature is the stability of the halo orbits, for a range of energy values. The vicinity of the alpha particle is also studied, examining Poincare sections for increasing energy values showing an increase of the chaotic motion.",
                    "score": 0.831601083278656
                },
                {
                    "id": 16217204,
                    "contents": "Mesons from Laser-Induced Processes in Ultra-Dense Hydrogen H(0).\nLarge signals of charged light mesons are observed in the laser-induced particle flux from ultra-dense hydrogen H(0) layers. The mesons are formed in such layers on metal surfaces using &lt; 200 mJ laser pulse-energy. The time variation of the signal to metal foil collectors and the magnetic deflection to a movable pin collector are now studied. Relativistic charged particles with velocity up to 500 MeV u-1 thus 0.75 c are observed. Characteristic decay time constants for meson decay are observed, for charged and neutral kaons and also for charged pions. Magnetic deflections agree with charged pions and kaons. Theoretical predictions of the decay chains from kaons to muons in the particle beam agree with the results. Muons are detected separately by standard scintillation detectors in laser-induced processes in ultra-dense hydrogen H(0) as published previously. The muons formed do not decay appreciably within the flight distances used here. Most of the laser-ejected particle flux with MeV energy is not deflected by the magnetic fields and is thus neutral, either being neutral kaons or the ultra-dense HN(0) precursor clusters. Photons give only a minor part of the detected signals. PACS: 67.63.Gh, 14.40.-n, 79.20.Ds, 52.57.-z.",
                    "score": 0.8315233588218689
                },
                {
                    "id": 9667780,
                    "contents": "The Fundamental Nuclear Interaction: Important developments of the past decade on mesons and the theory of nuclear forces are described.\nGOPEB based upon known mesons have been found which realistically describe a massive accumulation of the experimental nuclear data up to 400 Mev. The N-N potential according to these models consists primarily of weak residual central terms surviving the cancellation of large repulsive and attractive vector and scalar static components; relativistic interactions arising from the exchange of pseudoscalar, vector, and scalar mesons and dipole type terms arising from the rho meson. The major dynamic terms are direct analogs of magnetic interactions illustrated in Fig. 1. Allowance must be made for the effective dependence of the coupling constants upon spin and isospin states. The nucleons are distributed sources which give rise to nonsingular generalized Yukawa functions in N-N potentials.",
                    "score": 0.8314893841743469
                },
                {
                    "id": 13116107,
                    "contents": "Proton structure from the measurement of 2S-2P transition frequencies of muonic hydrogen.\nAccurate knowledge of the charge and Zemach radii of the proton is essential, not only for understanding its structure but also as input for tests of bound-state quantum electrodynamics and its predictions for the energy levels of hydrogen. These radii may be extracted from the laser spectroscopy of muonic hydrogen (μp, that is, a proton orbited by a muon). We measured the 2S(1/2)(F=0)-2P(3/2)(F=1) transition frequency in μp to be 54611.16(1.05) gigahertz (numbers in parentheses indicate one standard deviation of uncertainty) and reevaluated the 2S(1/2)(F=1)-2P(3/2)(F=2) transition frequency, yielding 49881.35(65) gigahertz. From the measurements, we determined the Zemach radius, r(Z) = 1.082(37) femtometers, and the magnetic radius, r(M) = 0.87(6) femtometer, of the proton. We also extracted the charge radius, r(E) = 0.84087(39) femtometer, with an order of magnitude more precision than the 2010-CODATA value and at 7σ variance with respect to it, thus reinforcing the proton radius puzzle.",
                    "score": 0.8309406042098999
                },
                {
                    "id": 9708482,
                    "contents": "Correction.\nIn our article \"Mesons Produced by the Cyclotron\" (Gardner, E. et al. Science, 1950, 111, 191) there is a typographical error on page 196 in the table near the top of the page. The first entry in the right-hand column reads 28.8 and should read 26.8.",
                    "score": 0.8281406760215759
                },
                {
                    "id": 10273804,
                    "contents": "The size of the proton.\nThe proton is the primary building block of the visible Universe, but many of its properties-such as its charge radius and its anomalous magnetic moment-are not well understood. The root-mean-square charge radius, r(p), has been determined with an accuracy of 2 per cent (at best) by electron-proton scattering experiments. The present most accurate value of r(p) (with an uncertainty of 1 per cent) is given by the CODATA compilation of physical constants. This value is based mainly on precision spectroscopy of atomic hydrogen and calculations of bound-state quantum electrodynamics (QED; refs 8, 9). The accuracy of r(p) as deduced from electron-proton scattering limits the testing of bound-state QED in atomic hydrogen as well as the determination of the Rydberg constant (currently the most accurately measured fundamental physical constant). An attractive means to improve the accuracy in the measurement of r(p) is provided by muonic hydrogen (a proton orbited by a negative muon); its much smaller Bohr radius compared to ordinary atomic hydrogen causes enhancement of effects related to the finite size of the proton. In particular, the Lamb shift (the energy difference between the 2S(1/2) and 2P(1/2) states) is affected by as much as 2 per cent. Here we use pulsed laser spectroscopy to measure a muonic Lamb shift of 49,881.88(76) GHz. On the basis of present calculations of fine and hyperfine splittings and QED terms, we find r(p) = 0.84184(67) fm, which differs by 5.0 standard deviations from the CODATA value of 0.8768(69) fm. Our result implies that either the Rydberg constant has to be shifted by -110 kHz/c (4.9 standard deviations), or the calculations of the QED effects in atomic hydrogen or muonic hydrogen atoms are insufficient.",
                    "score": 0.8278523087501526
                },
                {
                    "id": 22093474,
                    "contents": "Long-range interactions of the ground state muonium with atoms.\nThe scaling relations for the dispersion coefficients of long-range interactions between the Mu(1s)-Mu(1s, 2s, or 2p) systems and the H(1s)-H(1s, 2s, or 2p) systems are obtained using analytical properties of hydrogenic wavefunctions, which allows us to obtain the dispersion coefficients for Mu(1s)-Mu(1s, 2s, or 2p) systems from the corresponding H(1s)-H(1s, 2s, or 2p) systems. Additionally, the dispersion coefficients of long-range interactions of Mu(1s) with the ground-state H, noble gas atoms He, Ne, Ar, Kr, and Xe, alkali-metal atoms Li, Na, K, and Rb, alkaline-earth atoms Be, Mg, Ca, and Sr, and Cu, Ag, F, and Cl atoms are calculated.",
                    "score": 0.8272433280944824
                },
                {
                    "id": 14708628,
                    "contents": "A precise measurement of the [Formula: see text] meson oscillation frequency.\nThe oscillation frequency, [Formula: see text], of [Formula: see text] mesons is measured using semileptonic decays with a [Formula: see text] or [Formula: see text] meson in the final state. The data sample corresponds to 3.0[Formula: see text] of <ipp</i collisions, collected by the LHCb experiment at centre-of-mass energies [Formula: see text] = 7 and 8[Formula: see text]. A combination of the two decay modes gives [Formula: see text], where the first uncertainty is statistical and the second is systematic. This is the most precise single measurement of this parameter. It is consistent with the current world average and has similar precision.",
                    "score": 0.8266274929046631
                },
                {
                    "id": 9550441,
                    "contents": "Correction.\nIn my report on the Echo Lakes Symposium on Cosmic Rays (Science, September 2, 1949) the pi- and micro-symbols were interchanged, in the line before last of the second column, p. 242, and in the first line of the third column in the same page. The portion of the text containing these two lines should read: \". . . the latest values for the masses of the micro- and the pi-meson (215 and 285 electron masses respectively) and for the mean life of the pi-meson (0.63x10(-8) see).\" In a recent letter to the writer, Dr. Barkas states that this value for the mean life of the pi-meson has been superseded by more accurate measurements. These measurements, made on positive pi-mesons, give a mean life of 1.97x10(-8) sec. Dr. Barkas also indicates that new mass measurements give 276 electron masses for positive or negative pi-mesons and 210 electron masses for positive micro-mesons.",
                    "score": 0.8263616561889648
                },
                {
                    "id": 15793414,
                    "contents": "New Exotic Meson and Baryon Resonances from Doubly Heavy Hadronic Molecules.\nWe predict several new exotic doubly heavy hadronic resonances, inferring from the observed exotic bottomoniumlike and charmoniumlike narrow states X(3872), Z_{b}(10610), Z_{b}(10650), Z_{c}(3900), and Z_{c}(4020/4025). We interpret the binding mechanism as mostly molecularlike isospin-exchange attraction between two heavy-light mesons in a relative S-wave state. We then generalize it to other systems containing two heavy hadrons which can couple through isospin exchange. The new predicted states include resonances in meson-meson, meson-baryon, baryon-baryon, and baryon-antibaryon channels. These include those giving rise to final states involving a heavy quark Q=c,b and antiquark Q[over ¯]^{'}=c[over ¯],b[over ¯], namely, DD[over ¯]^{*}, D^{*}D[over ¯]^{*}, D^{*}B^{*}, B[over ¯]B^{*}, B[over ¯]^{*}B^{*}, Σ_{c}D[over ¯]^{*}, Σ_{c}B^{*}, Σ_{b}D[over ¯]^{*}, Σ_{b}B^{*}, Σ_{c}Σ[over ¯]_{c}, Σ_{c}Λ[over ¯]_{c}, Σ_{c}Λ[over ¯]_{b}, Σ_{b}Σ[over ¯]_{b}, Σ_{b}Λ[over ¯]_{b}, and Σ_{b}Λ[over ¯]_{c}, as well as corresponding S-wave states giving rise to QQ^{'} or Q[over ¯]Q[over ¯]^{'}. ",
                    "score": 0.8259658813476562
                },
                {
                    "id": 11115819,
                    "contents": "Is the spectrum of highly excited mesons purely coulombian?\nWe show that a static central potential may provide a precise description of highly excited light unflavored mesons. Because of string breaking, this potential becomes of chromoelectric type at sufficiently large quark-antiquark distances giving rise to a Coulombian spectrum. The same conclusion can be inferred for any other meson sector through a straightforward extension of our analysis.",
                    "score": 0.8224411606788635
                },
                {
                    "id": 19343188,
                    "contents": "Hyperons: the strange ingredients of the nuclear equation of state.\nWe review the role and properties of hyperons in finite and infinite nuclear systems. In particular, we present different production mechanisms of hypernuclei, as well as several aspects of hypernuclear <iγ</i-ray spectroscopy, and the weak decay modes of hypernuclei. Then we discuss the construction of hyperon-nucleon and hyperon-hyperon interactions on the basis of the meson-exchange and chiral effective field theories. Recent developments based on the so-called <iV</i <sublow <ik</i</sub approach and lattice quantum chromodynamics will also be addressed. Finally, we go over some of the effects of hyperons on the properties of neutron and proto-neutron stars with an emphasis on the so-called 'hyperon puzzle', i.e. the problem of the strong softening of the equation of state, and the consequent reduction of the maximum mass, induced by the presence of hyperons, a problem which has become more intriguing and difficult to solve due the recent measurements of approximately 2<iM</i <sub⊙</sub millisecond pulsars. We discuss some of the solutions proposed to tackle this problem. We also re-examine the role of hyperons on the cooling properties of newly born neutron stars and on the development of the so-called r-mode instability.",
                    "score": 0.8211085200309753
                },
                {
                    "id": 10558628,
                    "contents": "Multiphoton excitation and subsequent ionization detection of metastable atoms: measurement of n3S-n3D splittings in He.\nA simple technique is described for the efficient detection of multiphoton transitions from metastable states of atomic or molecular species to their excited states of either even or odd parity. This technique is demonstrated in metastable He, and first measurements of n3S-n3D splittings for n = 18-22 are reported.",
                    "score": 0.8208341002464294
                },
                {
                    "id": 8762684,
                    "contents": "Nuclear signatures in high-order harmonic generation from laser-driven muonic atoms.\nHigh-order harmonic generation from muonic atoms exposed to intense laser fields is considered. Our particular interest lies in effects arising from the finite nuclear mass and size. We numerically perform a fully quantum mechanical treatment of the muon-nucleus dynamics by employing modified soft-core and hard-core potentials. It is shown that the position of the high-energy cutoff of the harmonic spectrum depends on the nuclear mass, while the height of the spectral plateau is sensitive to the nuclear radius. We also demonstrate that gamma-ray harmonics can be generated from muonic atoms in ultrastrong VUV fields, which have potential to induce photonuclear reactions.",
                    "score": 0.8205757141113281
                },
                {
                    "id": 16902133,
                    "contents": "Ab initio calculation of the neutron-proton mass difference.\nThe existence and stability of atoms rely on the fact that neutrons are more massive than protons. The measured mass difference is only 0.14% of the average of the two masses. A slightly smaller or larger value would have led to a dramatically different universe. Here, we show that this difference results from the competition between electromagnetic and mass isospin breaking effects. We performed lattice quantum-chromodynamics and quantum-electrodynamics computations with four nondegenerate Wilson fermion flavors and computed the neutron-proton mass-splitting with an accuracy of 300 kilo-electron volts, which is greater than 0 by 5 standard deviations. We also determine the splittings in the Σ, Ξ, D, and Ξcc isospin multiplets, exceeding in some cases the precision of experimental measurements. ",
                    "score": 0.8205400109291077
                },
                {
                    "id": 5793443,
                    "contents": "Meson structure in a relativistic many-body approach\nResults from an extensive relativistic many-body analysis utilizing a realistic effective QCD Hamiltonian are presented for the meson spectrum. A comparative numerical study of the BCS, Tamm-Dancoff (TDA), and RPA treatments provides new, significant insight into the condensate structure of the vacuum, the chiral symmetry governance of the pion, and the meson spin, orbital, and flavor mass splitting contributions. In contrast to a previous glueball application, substantial quantitative differences are computed between TDA and RPA for the light quark sector with the pion emerging as a Goldstone boson only in the RPA.",
                    "score": 0.8185245990753174
                },
                {
                    "id": 10802276,
                    "contents": "Kinetic isotope effects for the reactions of muonic helium and muonium with H2.\nThe neutral muonic helium atom may be regarded as the heaviest isotope of the hydrogen atom, with a mass of ~4.1 atomic mass units ((4.1)H), because the negative muon almost perfectly screens one proton charge. We report the reaction rate of (4.1)H with (1)H(2) to produce (4.1)H(1)H + (1)H at 295 to 500 kelvin. The experimental rate constants are compared with the predictions of accurate quantum-mechanical dynamics calculations carried out on an accurate Born-Huang potential energy surface and with previously measured rate constants of (0.11)H (where (0.11)H is shorthand for muonium). Kinetic isotope effects can be compared for the unprecedentedly large mass ratio of 36. The agreement with accurate quantum dynamics is quantitative at 500 kelvin, and variational transition-state theory is used to interpret the extremely low (large inverse) kinetic isotope effects in the 10(-4) to 10(-2) range.",
                    "score": 0.8174130916595459
                },
                {
                    "id": 18887755,
                    "contents": "Unraveling the Structure of Ultracold Mesoscopic Collinear Molecular Ions.\nWe present an in-depth many-body investigation of the so-called mesoscopic molecular ions that can buildup when an ion is immersed into an atomic Bose-Einstein condensate in one dimension. To this end, we employ the multilayer multiconfiguration time-dependent Hartree method for mixtures of ultracold bosonic species for solving the underlying many-body Schrödinger equation. This enables us to unravel the actual structure of such massive charged molecules from a microscopic perspective. Laying out their phase diagram with respect to atom number and interatomic interaction strength, we determine the maximal number of atoms bound to the ion and reveal spatial densities and molecular properties. Interestingly, we observe a strong interaction-induced localization, especially for the ion, that we explain by the generation of a large effective mass, similarly to ions in liquid Helium. Finally, we predict the dynamical response of the ion to small perturbations. Our results provide clear evidence for the importance of quantum correlations, as we demonstrate by benchmarking them with wave function ansatz classes employed in the literature.",
                    "score": 0.8170047402381897
                },
                {
                    "id": 14656215,
                    "contents": "Lattice QCD evidence that the Λ(1405) resonance is an antikaon-nucleon molecule.\nFor almost 50 years the structure of the Λ(1405) resonance has been a mystery. Even though it contains a heavy strange quark and has odd parity, its mass is lower than any other excited spin-1/2 baryon. Dalitz and co-workers speculated that it might be a molecular state of an antikaon bound to a nucleon. However, a standard quark-model structure is also admissible. Although the intervening years have seen considerable effort, there has been no convincing resolution. Here we present a new lattice QCD simulation showing that the strange magnetic form factor of the Λ(1405) vanishes, signaling the formation of an antikaon-nucleon molecule. Together with a Hamiltonian effective-field-theory model analysis of the lattice QCD energy levels, this strongly suggests that the structure is dominated by a bound antikaon-nucleon component. This result clarifies that not all states occurring in nature can be described within a simple quark model framework and points to the existence of exotic molecular meson-nucleon bound states. ",
                    "score": 0.816218912601471
                },
                {
                    "id": 22966876,
                    "contents": "The muon Smasher's guide.\nWe lay out a comprehensive physics case for a future high-energy muon collider, exploring a range of collision energies (from 1 to 100 TeV) and luminosities. We highlight the advantages of such a collider over proposed alternatives. We show how one can leverage both the point-like nature of the muons themselves as well as the cloud of electroweak radiation that surrounds the beam to blur the dichotomy between energy and precision in the search for new physics. The physics case is buttressed by a range of studies with applications to electroweak symmetry breaking, dark matter, and the naturalness of the weak scale. Furthermore, we make sharp connections with complementary experiments that are probing new physics effects using electric dipole moments, flavor violation, and gravitational waves. An extensive appendix provides cross section predictions as a function of the center-of-mass energy for many canonical simplified models.",
                    "score": 0.8159859776496887
                },
                {
                    "id": 8762864,
                    "contents": "Electroweak radiative corrections to muon capture.\nElectroweak radiative corrections to muon capture on nuclei are computed and found to be sizable. They enhance the capture rates for hydrogen and helium by 2.8% and 3.0%, respectively. As a result, the value of the induced pseudoscalar coupling, g(P)(exp), extracted from a recent hydrogen 1S singlet capture experiment is increased by about 21% to g(P)(exp)=7.3+/-1.2 and brought into good agreement with the prediction of chiral perturbation theory, g(P)(theory)=8.2+/-0.2. Implications for helium capture rate predictions are also discussed.",
                    "score": 0.8151349425315857
                },
                {
                    "id": 9572212,
                    "contents": "Evolution of meson science in Japan.\nForty years after Yukawa predicted the existence of mesons, experimental research activities with the use of mesons were started in Japan. Particles of the \"second generation,\" which have nothing to do with the structure of ordinary materials, such as muons, K mesons, and other exotic particles have been exploited as unique probes to study new constituents of matter.",
                    "score": 0.8142665028572083
                },
                {
                    "id": 7350934,
                    "contents": "Mesoscopic molecular ions in Bose-Einstein condensates.\nWe study the possible formation of large (mesoscopic) molecular ions in an ultracold degenerate bosonic gas doped with charged particles (ions). We show that the polarization potentials produced by the ionic impurities are capable of capturing hundreds of atoms into loosely bound states. We describe the spontaneous formation of these hollow molecular ions via phonon emission and suggest an optical technique for coherent stimulated transitions of condensate atoms into a specific bound state. These results open up new possibilities for manipulating tightly confined ensembles.",
                    "score": 0.8140661120414734
                },
                {
                    "id": 10633849,
                    "contents": "Possibility of deeply bound hadronic molecules from single pion exchange.\nPion exchange in an S wave between hadrons that are themselves in a relative S wave can shift energies by hundreds of MeV. In the case of charmed mesons D, D;{*}, D0, D1, a spectroscopy of quasimolecular states may arise consistent with enigmatic charmonium states observed above 4 GeV in e;{+}e;{-} annihilation. A possible explanation of Y(4260) --&gt; psipipi and Y(4360) --&gt; psi;{'}pipi is found. Searches in DD[over]3pi channels as well as B decays are recommended to test this hypothesis.",
                    "score": 0.813822865486145
                },
                {
                    "id": 12856178,
                    "contents": "Super strong nuclear force caused by migrating K̄ mesons - Revival of the Heitler-London-Heisenberg scheme in kaonic nuclear clusters.\nWe have studied the structure of K (-) pp comprehensively by solving this threebody system in a variational method, starting from the Ansatz that the Λ(1405) resonance (≡Λ (*)) is a K (-) p bound state. The structure of K (-) pp reveals a molecular feature, namely, the K (-) in Λ (*) as an \"atomic center\" plays a key role in producing strong covalent bonding with the other proton. We point out that strongly bound K̄ nuclear systems are formed by \"super strong\" nuclear force due to migrating real bosonic particles K̄ a la Heitler-London-Heisenberg, whereas the normal nuclear force is caused by mediating virtual mesons. We have shown that the elementary process, p + p → K (+) + Λ (*) + p, which occurs in a short impact parameter and with a large momentum transfer, leads to unusually large self-trapping of Λ (*) by the involved proton, since the Λ (*)-p system exists as a compact doorway state propagating to K (-) pp. ",
                    "score": 0.8130977153778076
                },
                {
                    "id": 16574495,
                    "contents": "Properties of mesons in a strong magnetic field.\nBy extending the [Formula: see text]-derivable approach in the Nambu-Jona-Lasinio model to a finite magnetic field we calculate the properties of pion, [Formula: see text], and [Formula: see text] mesons in a magnetic field at finite temperature not only in the quark-antiquark bound state scheme but also in the pion-pion scattering resonant state scenario. Our calculation as a result makes manifest that the masses of [Formula: see text] and [Formula: see text] meson can be nearly degenerate at the pseudo-critical temperature which increases with increasing magnetic field strength, and the [Formula: see text] mass ascends suddenly at almost the same critical temperature. Meanwhile the [Formula: see text] mesons' masses decrease with the temperature but increase with the magnetic field strength. We also check the Gell-Mann-Oakes-Renner relation and find that the relation can be violated clearly with increasing temperature, and the effect of the magnetic field becomes pronounced around the critical temperature. With different criteria, we analyze the effect of the magnetic field on the chiral phase transition and find that the pseudo-critical temperature of the chiral phase cross, [Formula: see text], is always enhanced by the magnetic field. Moreover, our calculations indicate that the [Formula: see text] mesons will get melted as the chiral symmetry has not yet been restored, but the [Formula: see text] meson does not disassociate even at very high temperature. Particularly, it is the first to show that there does not exist a vector meson condensate in the QCD vacuum in the pion-pion scattering scheme.",
                    "score": 0.8130748271942139
                },
                {
                    "id": 18319564,
                    "contents": "Quark Matter May Not Be Strange.\nIf quark matter is energetically favored over nuclear matter at zero temperature and pressure, then it has long been expected to take the form of strange quark matter (SQM), with comparable amounts of u, d, and s quarks. The possibility of quark matter with only u and d quarks (udQM) is usually dismissed because of the observed stability of ordinary nuclei. However, we find that udQM generally has lower bulk energy per baryon than normal nuclei and SQM. This emerges in a phenomenological model that describes the spectra of the lightest pseudoscalar and scalar meson nonets. Taking into account the finite size effects, udQM can be the ground state of baryonic matter only for baryon number A&gt;A_{min} with A_{min}≳300. This ensures the stability of ordinary nuclei and points to a new form of stable matter just beyond the periodic table.",
                    "score": 0.8130689263343811
                },
                {
                    "id": 18984805,
                    "contents": "Nucleon axial radius and muonic hydrogen-a new analysis and review.\nWeak capture in muonic hydrogen (μH) as a probe of the chiral properties and nucleon structure predictions of quantum chromodynamics (QCD) is reviewed. A recent determination of the axial-vector charge radius squared, [Formula: see text], from a model independent z expansion analysis of neutrino-nucleon scattering data is employed in conjunction with the MuCap measurement of the singlet muonic hydrogen capture rate, [Formula: see text], to update the induced pseudoscalar nucleon coupling [Formula: see text] derived from experiment, and [Formula: see text] predicted by chiral perturbation theory. Accounting for correlated errors this implies [Formula: see text], confirming theory at the 8% level. If instead, the predicted expression for [Formula: see text] is employed as input, then the capture rate alone determines [Formula: see text], or together with the independent z expansion neutrino scattering result, a weighted average [Formula: see text]. Sources of theoretical uncertainty are critically examined and potential experimental improvements are described that can reduce the capture rate error by about a factor of 3. Muonic hydrogen can thus provide a precise and independent [Formula: see text] value which may be compared with other determinations, such as ongoing lattice gauge theory calculations. The importance of an improved [Formula: see text] determination for phenomenology is illustrated by considering the impact on critical neutrino-nucleus cross sections at neutrino oscillation experiments.",
                    "score": 0.8125537037849426
                },
                {
                    "id": 10907973,
                    "contents": "Search for the photoexcitation of exotic mesons in the pi+pi+pi- system.\nA search for exotic mesons in the pi;{+}pi;{+}pi;{-} system photoproduced by the charge exchange reaction gammap--&gt;pi;{+}pi;{+}pi;{-}(n) was carried out by the CLAS Collaboration at Jefferson Lab. A tagged-photon beam with energies in the 4.8 to 5.4 GeV range, produced through bremsstrahlung from a 5.744 GeV electron beam, was incident on a liquid-hydrogen target. A partial wave analysis was performed on a sample of 83 000 events, the highest such statistics to date in this reaction at these energies. The main objective of this study was to look for the photoproduction of an exotic J;{PC}=1;{-+} resonant state in the 1 to 2 GeV mass range. Our partial wave analysis shows production of the a_{2}(1320) and the pi_{2}(1670) mesons, but no evidence for the a_{1}(1260), nor the pi_{1}(1600) exotic state at the expected levels. An upper limit of 13.5 nb is determined for the exotic pi_{1}(1600) cross section, less than 2% of the a_{2}(1320) production.",
                    "score": 0.8121532201766968
                },
                {
                    "id": 22342668,
                    "contents": "Microscopic Structure of the Low-Energy Electric Dipole Response of ^{120}Sn.\nThe microscopic structure of the low-energy electric dipole response, commonly denoted as pygmy dipole resonance (PDR), was studied for ^{120}Sn in a ^{119}Sn(d,pγ)^{120}Sn experiment. Unprecedented access to the single-particle structure of excited 1^{-} states below and around the neutron-separation threshold was obtained by comparing experimental data to predictions from a novel theoretical approach. The novel approach combines detailed structure input from energy-density functional plus quasiparticle-phonon model theory with reaction theory to obtain a consistent description of both the structure and reaction aspects of the process. The presented results show that the understanding of one-particle-one-hole structures of the 1^{-} states in the PDR region is crucial to reliably predict properties of the PDR and its contribution to nucleosynthesis processes.",
                    "score": 0.8119851350784302
                },
                {
                    "id": 8185982,
                    "contents": "Modification of the omega-meson lifetime in nuclear matter.\nInformation on hadron properties in the nuclear medium has been derived from the photoproduction of omega mesons on the nuclei C, Ca, Nb, and Pb using the Crystal Barrel/TAPS detector at the ELSA tagged photon facility in Bonn. The dependence of the omega-meson cross section on the nuclear mass number has been compared with three different types of models: a Glauber analysis, a Boltzmann-Uehling-Uhlenbeck analysis of the Giessen theory group, and a calculation by the Valencia theory group. In all three cases, the inelastic omega width is found to be 130-150 MeV/c(2) at normal nuclear matter density for an average 3-momentum of 1.1 GeV/c. In the rest frame of the omega meson, this inelastic omega width corresponds to a reduction of the omega lifetime by a factor approximately 30. For the first time, the momentum dependent omegaN cross section has been extracted from the experiment and is in the range of 70 mb.",
                    "score": 0.8112801909446716
                },
                {
                    "id": 11899865,
                    "contents": "Muon-pair creation by two x-ray laser photons in the field of an atomic nucleus.\nThe generation of muon-antimuon pairs is calculated in the collision of an ultrarelativistic bare ion with an intense x-ray laser beam. The reaction proceeds nonlinearly via absorption of two laser photons. By systematic study throughout the nuclear chart, we show that the interplay between the nuclear charge and size, along with the possibility of nuclear excitation leads to saturation of the total production rates for high-Z ions, in contrast to the usual Z2 scaling for pointlike projectiles. The process is experimentally accessible by combining present-day ion accelerators with near-future laser sources and in principle allows for the measurement of nuclear form factors.",
                    "score": 0.8112725615501404
                },
                {
                    "id": 5794950,
                    "contents": "Proton-neutron mixed-symmetry 3(+)(ms) state in 94Mo\nWe identify a Jpi = 3(+)(ms) state in 94Mo. This identification is based on six M1 and E2 strengths and is the first identification of a 3(+)(ms) state from B(M1) and B(E2) values. The transition strengths were determined from the measurement of Doppler shifts, branching ratios, and E2/M1 mixing ratios, obtained from gammagamma directional correlations following the 91Zr(alpha,n) reaction and the beta(+) decay of (94)Tc(m). The interacting boson model agrees with the observations, which prove the 2(+) mixed-symmetry states to be a building block in nuclear structure.",
                    "score": 0.8108432292938232
                },
                {
                    "id": 17640391,
                    "contents": "First Observation of Unbound ^{11}O, the Mirror of the Halo Nucleus ^{11}Li.\nThe structure of the extremely proton-rich nucleus _{8}^{11}O_{3}, the mirror of the two-neutron halo nucleus _{3}^{11}Li_{8}, has been studied experimentally for the first time. Following two-neutron knockout reactions with a ^{13}O beam, the ^{11}O decay products were detected after two-proton emission and used to construct an invariant-mass spectrum. A broad peak of width ∼3.4  MeV was observed. Within the Gamow coupled-channel approach, it was concluded that this peak is a multiplet with contributions from the four lowest ^{11}O resonant states: J^{π}=3/2_{1}^{-}, 3/2_{2}^{-}, 5/2_{1}^{+}, and 5/2_{2}^{+}. The widths and configurations of these states show strong, nonmonotonic dependencies on the depth of the p-^{9}C potential. This unusual behavior is due to the presence of a broad threshold resonant state in ^{10}N, which is an analog of the virtual state in ^{10}Li in the presence of the Coulomb potential. After optimizing the model to the data, only a moderate isospin asymmetry between ground states of ^{11}O and ^{11}Li was found.",
                    "score": 0.8100070953369141
                },
                {
                    "id": 14095518,
                    "contents": "Why three-body physics does not solve the proton-radius puzzle.\nThe possible involvement of weakly bound three-body systems in the muonic hydrogen spectroscopy experiment, which could resolve the current discrepancy between determinations of the proton radius, is investigated. Using variational calculations with complex coordinate rotation, we show that in the pμe ion, which was recently proposed as a possible candidate, the pμ core fails to bind the outer electron tightly enough to explain the discrepancy. It is also shown that the ppμ molecular ion cannot play any role in the observed line.",
                    "score": 0.8099777698516846
                },
                {
                    "id": 10633850,
                    "contents": "Implications of heavy-quark spin symmetry on heavy-meson hadronic molecules.\nIn recent years, many heavy mesons and charmonia were observed which do not fit in the conventional quark model expectations. Some of them are proposed to be hadronic molecules. Here we investigate the consequences of heavy-quark spin symmetry on these heavy-meson hadronic molecules. Heavy-quark spin symmetry enables us to predict new heavy-meson molecules and provides us with a method to test heavy-meson molecule assumptions of some newly observed states. In particular, we predict an eta_{c};{'}f_{0}(980) bound state as the spin-doublet partner of the Y(4660) proposed as a psi;{'}f_{0}(980) bound state with a mass of 4616_{-6};{+5} MeV and the prominent decay mode eta_{c};{'}pipi. The width is predicted to be Gamma(eta_{c};{'}pipi) = 60 +/- 30 MeV. The pi;{+}pi;{-} invariant mass spectrum and the line shape are calculated. We suggest searching for this state in B;{+/-} --&gt; eta_{c};{'}K;{+/-}pi;{+}pi;{-}, whose branching fraction is expected to be large.",
                    "score": 0.8093114495277405
                },
                {
                    "id": 13258630,
                    "contents": "Proton: the particle.\nThe purpose of this article is to review briefly the nature of protons: creation at the Big Bang, abundance, physical characteristics, internal components, and life span. Several particle discoveries by proton as the experimental tool are considered. Protons play important roles in science, medicine, and industry. This article was prompted by my experience in the curative treatment of cancer patients by protons and my interest in the nature of protons as particles. The latter has been stimulated by many discussions with particle physicists and reading related books and journals. Protons in our universe number ≈10(80). Protons were created at 10(-6) -1 second after the Big Bang at ≈1.37 × 10(10) years beforethe present. Proton life span has been experimentally determined to be ≥10(34) years; that is, the age of the universe is 10(-24)th of the minimum life span of a proton. The abundance of the elements is hydrogen, ≈74%; helium, ≈24%; and heavier atoms, ≈2%. Accordingly, protons are the dominant baryonic subatomic particle in the universe because ≈87% are protons. They are in each atom in our universe and thus involved in virtually every activity of matter in the visible universe, including life on our planet. Protons were discovered in 1919. In 1968, they were determined to be composed of even smaller particles, principally quarks and gluons. Protons have been the experimental tool in the discoveries of quarks (charm, bottom, and top), bosons (W(+), W(-), Z(0), and Higgs), antiprotons, and antineutrons. Industrial applications of protons are numerous and important. Additionally, protons are well appreciated in medicine for their role in radiation oncology and in magnetic resonance imaging. Protons are the dominant baryonic subatomic particle in the visible universe, comprising ≈87% of the particle mass. They are present in each atom of our universe and thus a participant in every activity involving matter.",
                    "score": 0.8093037605285645
                },
                {
                    "id": 13506910,
                    "contents": "Kinetics of the reaction of the heaviest hydrogen atom with H2, the 4Heμ + H2 → 4HeμH + H reaction: experiments, accurate quantal calculations, and variational transition state theory, including kinetic isotope effects for a factor of 36.1 in isotopic mass.\nThe neutral muonic helium atom (4)Heμ, in which one of the electrons of He is replaced by a negative muon, may be effectively regarded as the heaviest isotope of the hydrogen atom, with a mass of 4.115 amu. We report details of the first muon spin rotation (μSR) measurements of the chemical reaction rate constant of (4)Heμ with molecular hydrogen, (4)Heμ + H(2) → (4)HeμH + H, at temperatures of 295.5, 405, and 500 K, as well as a μSR measurement of the hyperfine coupling constant of muonic He at high pressures. The experimental rate constants, k(Heμ), are compared with the predictions of accurate quantum mechanical (QM) dynamics calculations carried out on a well converged Born-Huang (BH) potential energy surface, based on complete configuration interaction calculations and including a Born-Oppenheimer diagonal correction. At the two highest measured temperatures the agreement between the quantum theory and experiment is good to excellent, well within experimental uncertainties that include an estimate of possible systematic error, but at 295.5 K the quantum calculations for k(Heμ) are below the experimental value by 2.1 times the experimental uncertainty estimates. Possible reasons for this discrepancy are discussed. Variational transition state theory calculations with multidimensional tunneling have also been carried out for k(Heμ) on the BH surface, and they agree with the accurate QM rate constants to within 30% over a wider temperature range of 200-1000 K. Comparisons between theory and experiment are also presented for the rate constants for both the D + H(2) and Mu + H(2) reactions in a novel study of kinetic isotope effects for the H + H(2) reactions over a factor of 36.1 in isotopic mass of the atomic reactant.",
                    "score": 0.8092629313468933
                },
                {
                    "id": 22684093,
                    "contents": "First Observation of the Four-Proton Unbound Nucleus ^{18}Mg.\n^{18}Mg was observed, for the first time, by the invariant-mass reconstruction of ^{14}O+4p events. The ground-state decay energy and width are E_{T}=4.865(34)  MeV and Γ=115(100)  keV, respectively. The observed momentum correlations between the five particles are consistent with two sequential steps of prompt 2p decay passing through the ground state of ^{16}Ne. The invariant-mass spectrum also provides evidence for an excited state at an excitation energy of 1.84(14) MeV, which is likely the first excited 2^{+} state. As this energy exceeds that for the 2^{+} state in ^{20}Mg, this observation provides an argument for the demise of the N=8 shell closure in nuclei far from stability. However, in open systems this classical argument for shell strength is compromised by Thomas-Ehrman shifts.",
                    "score": 0.8090248107910156
                },
                {
                    "id": 17514809,
                    "contents": "Parton Distribution Functions from a Light Front Hamiltonian and QCD Evolution for Light Mesons.\nWe obtain the pion and the kaon parton distribution functions from the eigenstates of a light front effective Hamiltonian in the constituent quark-antiquark representation suitable for low-momentum scale applications. By taking these scales as the only free parameters, the valence quark distribution functions of the pion, after QCD evolution, are consistent with the data from the FNAL-E615 experiment. The ratio of the up quark distribution of the kaon to that of the pion also agrees with the CERN-NA3 experiment. Supplemented by known parton distribution functions for the nucleons, we further obtain the cross section consistent with experimental data for the π^{-}nucleus→μ^{+}μ^{-}X Drell-Yan process.",
                    "score": 0.8083622455596924
                },
                {
                    "id": 23465820,
                    "contents": "Measured proton electromagnetic structure deviates from theoretical predictions.\nThe visible world is founded on the proton, the only composite building block of matter that is stable in nature. Consequently, understanding the formation of matter relies on explaining the dynamics and the properties of the proton's bound state. A fundamental property of the proton involves the response of the system to an external electromagnetic field. It is characterized by the electromagnetic polarizabilities&lt;sup&gt;1&lt;/sup&gt; that describe how easily the charge and magnetization distributions inside the system are distorted by the electromagnetic field. Moreover, the generalized polarizabilities&lt;sup&gt;2&lt;/sup&gt; map out the resulting deformation of the densities in a proton subject to an electromagnetic field. They disclose essential information about the underlying system dynamics and provide a key for decoding the proton structure in terms of the theory of the strong interaction that binds its elementary quark and gluon constituents. Of particular interest is a puzzle in the electric generalized polarizability of the proton that remains unresolved for two decades&lt;sup&gt;2&lt;/sup&gt;. Here we report measurements of the proton's electromagnetic generalized polarizabilities at low four-momentum transfer squared. We show evidence of an anomaly to the behaviour of the proton's electric generalized polarizability that contradicts the predictions of nuclear theory and derive its signature in the spatial distribution of the induced polarization in the proton. The reported measurements suggest the presence of a new, not-yet-understood dynamical mechanism in the proton and present notable challenges to the nuclear theory.",
                    "score": 0.8082129955291748
                },
                {
                    "id": 8313595,
                    "contents": "Search for neutral, long-lived particles decaying into two muons in pp[over] collisions at sqrt[s]=1.96 TeV.\nWe present a search for a neutral particle, pair produced in pp[over] collisions at sqrt[s]=1.96 TeV, which decays into two muons and lives long enough to travel at least 5 cm before decaying. The analysis uses approximately 380 pb(-1) of data recorded with the D0 detector. The background is estimated to be about one event. No candidates are observed, and limits are set on the pair-production cross section times branching fraction into dimuons + X for such particles. For a mass of 10 GeV and lifetime of 4x10(-11) s, we exclude values greater than 0.14 pb (95% C.L.). These results are used to limit the interpretation of NuTeV's excess of dimuon events.",
                    "score": 0.807888388633728
                },
                {
                    "id": 20670446,
                    "contents": "Proton transfer at subkelvin temperatures.\nWe demonstrate a novel method to ionize molecules or molecular clusters by proton transfer at temperatures below 1 K. The method yields nascent ions and largely eliminates secondary reactions, even for notoriously 'delicate' molecules. Protonation is achieved inside liquid helium nanodroplets (HNDs) and begins with the formation of (H2)mH+ ions as the proton donors. In a separate and subsequent step the HNDs are doped with a proton acceptor molecule, X. Proton transfer occurs between X and the cold proton donor ions inside a helium droplet, an approach that avoids the large excess energy that is released if HNDs are first doped and then ionized. Mass spectra, recorded after stripping excess helium and hydrogen in a collision cell, show that this method offers a new way to determine proton affinities of molecules and clusters by proton-transfer bracketing, to investigate astrochemically relevant ion-molecule reactions at sub-kelvin temperatures, and to prepare XH+ ions that are suitable for messenger-tagging action spectroscopy.",
                    "score": 0.8072730302810669
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_28",
        "question": "$$\r\n\\beta=2 \\pi c \\tilde{\\omega}_{\\mathrm{obs}}\\left(\\frac{\\mu}{2 D}\\right)^{1 / 2}\r\n$$\r\nGiven that $\\tilde{\\omega}_{\\mathrm{obs}}=2886 \\mathrm{~cm}^{-1}$ and $D=440.2 \\mathrm{~kJ} \\cdot \\mathrm{mol}^{-1}$ for $\\mathrm{H}^{35} \\mathrm{Cl}$, calculate $\\beta$.",
        "golden_answers": [
            " 1.81"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 13205153,
                    "contents": "PI<sup>2</sup>PE: A Suite of Web Servers for Predictions Ranging From Protein Structure to Binding Kinetics.\nPI<sup2</supPE (http://pipe.sc.fsu.edu) is a suite of four web servers for predicting a variety of folding- and binding-related properties of proteins. These include the solvent accessibility of amino acids upon protein folding, the amino acids forming the interfaces of protein-protein and protein-nucleic acid complexes, and the binding rate constants of these complexes. Three of the servers debuted in 2007, and have garnered ~2,500 unique users and finished over 30,000 jobs. The functionalities of these servers are now enhanced, and a new sever, for predicting the binding rate constants, is added. Together, these web servers form a pipeline from protein sequence to tertiary structure, then to quaternary structure, and finally to binding kinetics.",
                    "score": 0.8281315565109253
                },
                {
                    "id": 10656277,
                    "contents": "On the electron affinity of B2.\nWe present the results of high-level ab initio calculations on the electron affinity of B(2). Our new best estimate of 1.93 -/+ 0.03 eV is in agreement with previous calculations as well as the sole existing experimental estimate of 1.8 eV, as derived from quantities with an uncertainty of 0.4 eV. The electron affinity of atomic boron, which is much smaller, is also calculated for comparison and again found to be in good agreement with experiment.",
                    "score": 0.8242666721343994
                },
                {
                    "id": 19495470,
                    "contents": "pytc: Open-Source Python Software for Global Analyses of Isothermal Titration Calorimetry Data.\nHere we describe pytc, an open-source Python package for global fits of thermodynamic models to multiple isothermal titration calorimetry experiments. Key features include simplicity, the ability to implement new thermodynamic models, a robust maximum likelihood fitter, a fast Bayesian Markov-Chain Monte Carlo sampler, rigorous implementation, extensive documentation, and full cross-platform compatibility. pytc fitting can be done using an application program interface or via a graphical user interface. It is available for download at https://github.com/harmslab/pytc .",
                    "score": 0.8231545686721802
                },
                {
                    "id": 13353236,
                    "contents": "MP2.X: a generalized MP2.5 method that produces improved binding energies with smaller basis sets.\nIn this article we present binding energy results for a scaled MP2.5 method along with several basis sets. The accuracy of the methods tested here is determined by comparison to reference data in the newly developed S66 data set of interaction energies. It is found that scaling of the MP2.5 correction term results in strongly improved binding energies for small basis sets, such as 6-31G* and 6-311++G**. The scaling parameter for larger basis sets, such as aug-cc-pVDZ and aug-cc-pVTZ, approaches a value of 0.50, which corresponds to the original (unparametrized) MP2.5 method. It is found that the MP2.X method yields S66 RMS errors of approximately 0.15 kcal mol(-1) for all basis sets. In addition to generally providing more accurate binding energies than MP2.5, MP2.X generally produces a more well-balanced description of noncovalent interactions, yielding better binding energies for dispersion-bound and mixed dispersion-electrostatic complexes.",
                    "score": 0.8208035826683044
                },
                {
                    "id": 6744071,
                    "contents": "Quantitative structure-property relationships for predicting Henry's law constant from molecular structure.\nVarious models are available for the prediction of Henry's law constant (H) or the air-water partition coefficient (Kaw), its dimensionless counterpart. Incremental methods are based on structural features such as atom types, bond types, and local structural environments; other regression models employ physicochemical properties, structural descriptors such as connectivity indices, and descriptors reflecting the electronic structure. There are also methods to calculate H from the ratio of vapor pressure (p(v)) and water solubility (S(w)) that in turn can be estimated from molecular structure, and quantum chemical continuum-solvation models to predict H via the solvation-free energy (deltaG(s)). This review is confined to methods that calculate H from molecular structure without experimental information and covers more than 40 methods published in the last 26 years. For a subset of eight incremental methods and four continuum-solvation models, a comparative analysis of their prediction performance is made using a test set of 700 compounds that includes a significant number of more complex and drug-like chemical structures. The results reveal substantial differences in the application range as well as in the prediction capability, a general decrease in prediction performance with decreasing H, and surprisingly large individual prediction errors, which are particularly striking for some quantum chemical schemes. The overall best-performing method appears to be the bond contribution method as implemented in the HENRYWIN software package, yielding a predictive squared correlation coefficient (q2) of 0.87 and a standard error of 1.03 log units for the test set.",
                    "score": 0.8182623982429504
                },
                {
                    "id": 9736878,
                    "contents": "Efficient method for predicting crystal structures at finite temperature: variable box shape simulations.\nWe present an efficient and robust method based on Monte Carlo simulations for predicting crystal structures at finite temperature. We apply this method, which is surprisingly easy to implement, to a variety of systems, demonstrating its effectiveness for hard, attractive, and anisotropic interactions, binary mixtures, semi-long-range soft interactions, and truly long-range interactions where the truly long-range interactions are treated using Ewald sums. In the case of binary hard-sphere mixtures, star polymers, and binary Lennard-Jones mixtures, the crystal structures predicted by this algorithm are consistent with literature, providing confidence in the method. Finally, we predict new crystal structures for hard asymmetric dumbbell particles, bowl-like particles and hard oblate cylinders and present the phase diagram for the oblate cylinders based on full free energy calculations.",
                    "score": 0.8141292929649353
                },
                {
                    "id": 11743904,
                    "contents": "[Not Available].\nThe basic computer program MICMAC has been developed to fit equilibrium constants to various types of experimental data with a microcomputer. The program uses the very efficient Gauss-Newton-Marquardt algorithm for non-linear least-squares multiparametric refinement. Highly interactive, convenient to use and of modular design, it allows for a rigorous weighting scheme, and it takes account of possible systematic errors. This program is useful for solving problems with several sets of experimental data. Some examples dealing with polarography, pH-metric titration and (13)C-NMR are given, illustrating the versatility of MICMAC. Comparison is made with some recently published programs.",
                    "score": 0.8130455613136292
                },
                {
                    "id": 17243754,
                    "contents": "A high-bias, low-variance introduction to Machine Learning for physicists.\nMachine Learning (ML) is one of the most exciting and dynamic areas of modern research and application. The purpose of this review is to provide an introduction to the core concepts and tools of machine learning in a manner easily understood and intuitive to physicists. The review begins by covering fundamental concepts in ML and modern statistics such as the bias-variance tradeoff, overfitting, regularization, generalization, and gradient descent before moving on to more advanced topics in both supervised and unsupervised learning. Topics covered in the review include ensemble models, deep learning and neural networks, clustering and data visualization, energy-based models (including MaxEnt models and Restricted Boltzmann Machines), and variational methods. Throughout, we emphasize the many natural connections between ML and statistical physics. A notable aspect of the review is the use of Python Jupyter notebooks to introduce modern ML/statistical packages to readers using physics-inspired datasets (the Ising Model and Monte-Carlo simulations of supersymmetric decays of proton-proton collisions). We conclude with an extended outlook discussing possible uses of machine learning for furthering our understanding of the physical world as well as open problems in ML where physicists may be able to contribute.",
                    "score": 0.8095194101333618
                },
                {
                    "id": 9654729,
                    "contents": "XFIT - an Interactive EXAFSAnalysis Program.\nXFIT is an interactive and user-friendly program for the analysis of X-ray absorption fine structure (XAFS, EXAFS) curves. XFIT incorporates in a single package a number of features available in other existing programs: ab initio EXAFS calculation (using FEFF4.06/6.01), empirical EXAFS calculation (as in XFPAKG), allowance for polarization, use of Fourier filtering, and the application of constraints and restraints. Additional features not previously available are: simultaneous refinement with respect to several data sets, simultaneous refinement of several absorber sites, and Monte-Carlo error analysis. Applications including the analysis of EXAFS data from mixtures and the analysis of DAFS (diffraction anomalous fine structure) data are indicated.",
                    "score": 0.8089961409568787
                },
                {
                    "id": 23021285,
                    "contents": "A Universal Power Law Governing the Accuracy of Wave Function-Based Electronic Structure Calculations.\nA universal power law governing the accuracy of wave function-based electronic structure calculations is derived from first principles. The resulting expression <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:mfrac<mml:mrow<mml:miΔ</mml:mi<mml:miE</mml:mi<mml:mrow<mml:mo(</mml:mo<mml:miN</mml:mi<mml:mo,</mml:mo<mml:miN</mml:mi<mml:mo)</mml:mo</mml:mrow</mml:mrow<mml:mrow<mml:miN</mml:mi</mml:mrow</mml:mfrac</mml:mrow<mml:mo≳</mml:mo<mml:mrow<mml:mfrac<mml:mrow<mml:mn1</mml:mn</mml:mrow<mml:mrow<mml:mn9</mml:mn<mml:mrow<mml:msup<mml:mrow<mml:miπ</mml:mi</mml:mrow<mml:mrow<mml:mn2</mml:mn</mml:mrow</mml:msup</mml:mrow</mml:mrow</mml:mfrac</mml:mrow<mml:mspace/<mml:mig</mml:mi<mml:mspace/<mml:mrow<mml:mfrac<mml:mrow<mml:miN</mml:mi</mml:mrow<mml:mrow<mml:miN</mml:mi</mml:mrow</mml:mfrac</mml:mrow</mml:math, where <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mig</mml:mi</mml:math is a system-specific factor assuming values between zero and one and ≳ stands for asymptotic inequality at the limit of <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miN</mml:mi<mml:mo→</mml:mo<mml:mi∞</mml:mi</mml:math, allows facile estimation of the error <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miΔ</mml:mi<mml:miE</mml:mi<mml:mrow<mml:mo(</mml:mo<mml:miN</mml:mi<mml:mo,</mml:mo<mml:miN</mml:mi<mml:mo)</mml:mo</mml:mrow</mml:math in the electronic energy of a singlet state of an <iN</i-electron system computed with a basis set of <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miN</mml:mi</mml:math one-electron functions. Several approaches to the estimation of the factor <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mig</mml:mi</mml:math, which depends on the on-top two-electron density, are presented.",
                    "score": 0.808327317237854
                },
                {
                    "id": 7579018,
                    "contents": "The fundamental constants and theory.\nThe Committee on Data for Science and Technology has recently recommended a new self-consistent set of values of basic constants and conversion factors of physics and chemistry. These values are based on a least-squares analysis that takes into account all of the latest relevant experimental and theoretical information in a consistent framework. Theory plays a role, because the experimental data are compared to the corresponding theoretical predictions which are functions of the fundamental constants. The best values of the constants are taken to be those that give the best agreement between the data and these predictions, in the least-squares sense. An overview of the calculations that influence the recommended values of the constants will be given.",
                    "score": 0.8077132105827332
                },
                {
                    "id": 14928646,
                    "contents": "The young person's guide to the PDB.\nThe Protein Data Bank (PDB), created in 1971 when merely seven protein crystal structures were known, today holds over 120, 000 experimentally-determined three-dimensional models of macromolecules, including gigantic structures comprised of hundreds of thousands of atoms, such as ribosomes and viruses. Most of the deposits come from X-ray crystallography experiments, with important contributions also made by NMR spectroscopy and, recently, by the fast growing Cryo-Electron Microscopy. Although the determination of a macromolecular crystal structure is now facilitated by advanced experimental tools and by sophisticated software, it is still a highly complicated research process requiring specialized training, skill, experience and a bit of luck. Understanding the plethora of structural information provided by the PDB requires that its users (consumers) have at least a rudimentary initiation. This is the purpose of this educational overview.",
                    "score": 0.807453989982605
                },
                {
                    "id": 5854019,
                    "contents": "In this issue \nCopyright 1998 Academic Press Limited",
                    "score": 0.8073537349700928
                },
                {
                    "id": 2371380,
                    "contents": "SIMP: a computer program in BASIC for nonlinear curve fitting.\nA computer program for nonlinear regression analysis is described. The program, SIMP, is written in BASIC for use with a wide range of microcomputers. The simplex algorithm is used to minimize the sum of the squared residuals around the fitted line, and the data can be weighted if required. The program is applicable to a wide range of pharmacological procedures requiring curve fitting, and the analysis of protein-binding data is given as an example.",
                    "score": 0.8071417212486267
                },
                {
                    "id": 5206899,
                    "contents": "Gaussian process: an efficient technique to solve quantitative structure-property relationship problems.\nWe introduce the Gaussian process (GP) model for the empirical modelling of the log P values of 44 1,2-dithiole-3-one molecules. A brief theoretical description of the method is given. Descriptive and predictive abilities of GP are evaluated and compared to multilinear regression results. Special attention is devoted to the automatic relevance determination (ARD) to reduce input variable numbers, which avoid the use of principal component analysis. The present approach was found to be an efficient method and a good alternative to more complicated using artificial neural network systems.",
                    "score": 0.8068758845329285
                },
                {
                    "id": 6620772,
                    "contents": "Gaussian processes for machine learning.\nGaussian processes (GPs) are natural generalisations of multivariate Gaussian random variables to infinite (countably or continuous) index sets. GPs have been applied in a large number of fields to a diverse range of ends, and very many deep theoretical analyses of various properties are available. This paper gives an introduction to Gaussian processes on a fairly elementary level with special emphasis on characteristics relevant in machine learning. It draws explicit connections to branches such as spline smoothing models and support vector machines in which similar ideas have been investigated. Gaussian process models are routinely used to solve hard machine learning problems. They are attractive because of their flexible non-parametric nature and computational simplicity. Treated within a Bayesian framework, very powerful statistical methods can be implemented which offer valid estimates of uncertainties in our predictions and generic model selection procedures cast as nonlinear optimization problems. Their main drawback of heavy computational scaling has recently been alleviated by the introduction of generic sparse approximations.13,78,31 The mathematical literature on GPs is large and often uses deep concepts which are not required to fully understand most machine learning applications. In this tutorial paper, we aim to present characteristics of GPs relevant to machine learning and to show up precise connections to other \"kernel machines\" popular in the community. Our focus is on a simple presentation, but references to more detailed sources are provided.",
                    "score": 0.8065711855888367
                },
                {
                    "id": 20737905,
                    "contents": "Bing Xu.\n\"My favorite saying is 'everybody is made of molecules'. My favorite molecule is water …\" Find out more about Bing Xu in his Author Profile.",
                    "score": 0.8064540028572083
                },
                {
                    "id": 5803560,
                    "contents": "Monte Carlo methods in electronic structures for large systems.\nQuantum Monte Carlo methods have recently made it possible to calculate the electronic structure of relatively large molecular systems with very high accuracy. These large systems range from positron complexes [NH(2),Ps] with approximately 10 electrons to C(20) isomers with 120 electrons, to silicon crystal structures of 250 atoms and 1000 valence electrons. The techniques for such calculations and a sampling of applications are reviewed.",
                    "score": 0.80593341588974
                },
                {
                    "id": 8072705,
                    "contents": "Stupid statistics!\nThe method of least squares is probably the most powerful data analysis tool available to scientists. Toward a fuller appreciation of that power, this work begins with an elementary review of statistics fundamentals, and then progressively increases in sophistication as the coverage is extended to the theory and practice of linear and nonlinear least squares. The results are illustrated in application to data analysis problems important in the life sciences. The review of fundamentals includes the role of sampling and its connection to probability distributions, the Central Limit Theorem, and the importance of finite variance. Linear least squares are presented using matrix notation, and the significance of the key probability distributions-Gaussian, chi-square, and t-is illustrated with Monte Carlo calculations. The meaning of correlation is discussed, including its role in the propagation of error. When the data themselves are correlated, special methods are needed for the fitting, as they are also when fitting with constraints. Nonlinear fitting gives rise to nonnormal parameter distributions, but the 10% Rule of Thumb suggests that such problems will be insignificant when the parameter is sufficiently well determined. Illustrations include calibration with linear and nonlinear response functions, the dangers inherent in fitting inverted data (e.g., Lineweaver-Burk equation), an analysis of the reliability of the van't Hoff analysis, the problem of correlated data in the Guggenheim method, and the optimization of isothermal titration calorimetry procedures using the variance-covariance matrix for experiment design. The work concludes with illustrations on assessing and presenting results.",
                    "score": 0.8058301210403442
                },
                {
                    "id": 14882832,
                    "contents": "Recommended Values of the Fundamental Physical Constants: A Status Report.\nWe summarize the principal advances made in the fundamental physical constants field since the completion of the 1986 CODATA least-squares adjustment of the constants and discuss their implications for both the 1986 set of recommended values and the next least-squares adjustment. In general, the new results lead to values of the constants with uncertainties 5 to 7 times smaller than the uncertainties assigned the 1986 values. However, the changes in the values themselves are less than twice the 1986 assigned one-standard-deviation uncertainties and thus are not highly significant. Although much new data has become available since 1986, three new results dominate the analysis: a value of the Planck constant obtained from a realization of the watt; a value of the fine-structure constant obtained from the magnetic moment anomaly of the electron; and a value of the molar gas constant obtained from the speed of sound in argon. Because of their dominant role in determining the values and uncertainties of many of the constants, it is highly desirable that additional results of comparable uncertainty that corroborate these three data items be obtained before the next adjustment is carried out. Until then, the 1986 CODATA set of recommended values will remain the set of choice.",
                    "score": 0.8055164813995361
                },
                {
                    "id": 2327542,
                    "contents": "EZ-FIT: a practical curve-fitting microcomputer program for the analysis of enzyme kinetic data on IBM-PC compatible computers.\nEZ-FIT, an interactive microcomputer software package, has been developed for the analysis of enzyme kinetic and equilibrium binding data. EZ-FIT was designed as a user-friendly menu-driven package that has the facility for data entry, editing, and filing. Data input permits the conversion of cpm, dpm, or optical density to molar per minute per milligram protein. Data can be fit to any of 14 model equations including Michaelis-Menten, Hill, isoenzyme, inhibition, dual substrate, agonist, antagonist, and modified integrated Michaelis-Menten. The program uses the Nelder-Mead simplex and Marquardt nonlinear regression algorithms sequentially. A report of the results includes the parameter estimates with standard errors, a Student t test to determine the accuracy of the parameter values, a Runs statistic test of the residuals, identification of outlying data, an Akaike information criterion test for goodness-of-fit, and, when the experimental variance is included, a chi 2 statistic test for goodness-of-fit. Several different graphs can be displayed: an X-Y, a Scatchard, an Eadie-Hofstee, a Lineweaver-Burk, a semilogarithmic, and a residual plot. A data analysis report and graphs are designed to evaluate the goodness-of-fit of the data to a particular model.",
                    "score": 0.8053898811340332
                },
                {
                    "id": 10860933,
                    "contents": "Reducing the bias and uncertainty of free energy estimates by using regression to fit thermodynamic integration data.\nThis report presents the application of polynomial regression for estimating free energy differences using thermodynamic integration data, i.e., slope of free energy with respect to the switching variable lambda. We employ linear regression to construct a polynomial that optimally fits the thermodynamic integration data, and thus reduces the bias and uncertainty of the resulting free energy estimate. Two test systems with analytical solutions were used to verify the accuracy and precision of the approach. Our results suggest that use of regression with high degree of polynomials provides the most accurate free energy difference estimates, but often with slightly larger uncertainty, compared to commonly used quadrature techniques. High degree polynomials possess the flexibility to closely fit the thermodynamic integration data but are often sensitive to small changes in the data points. Thus, we also used Chebyshev nodes to guide in the selection of nonequidistant lambda values for use in thermodynamic integration. We conclude that polynomial regression with nonequidistant lambda values delivers the most accurate and precise free energy estimates for thermodynamic integration data for the systems considered here. Software and documentation is available at http://www.phys.uidaho.edu/ytreberg/software.",
                    "score": 0.8050920963287354
                },
                {
                    "id": 15279169,
                    "contents": "Linear free-energy relationships between a single gas-phase ab initio equilibrium bond length and experimental pKa values in aqueous solution.\nRemarkably simple yet effective linear free energy relationships were discovered between a single ab initio computed bond length in the gas phase and experimental pKa values in aqueous solution. The formation of these relationships is driven by chemical features such as functional groups, meta/para substitution and tautomerism. The high structural content of the ab initio bond length makes a given data set essentially divide itself into high correlation subsets (HCSs). Surprisingly, all molecules in a given high correlation subset share the same conformation in the gas phase. Here we show that accurate pKa values can be predicted from such HCSs. This is achieved within an accuracy of 0.2 pKa units for 5 drug molecules. ",
                    "score": 0.8050355315208435
                },
                {
                    "id": 3632152,
                    "contents": "The binding capacity is a probability density function.\nThe binding capacity of a system, or equivalently, the fluctuations of the number of ligands bound around the average value defined by the binding isotherm, can be regarded as a probability density function for the chemical potential of the ligand. The first moment of this density function is the mean ligand activity as defined by Wyman and gives the average free energy (in kT units) of binding per site. The second moment is directly related to the cooperativity of the system. These and higher moments can be obtained from numerical integration of experimental data in a direct way. An analytical expression for the moment generating function shows that the N independent coefficients of the partition function of a system containing N sites are uniquely defined by the first N moments of the binding capacity.",
                    "score": 0.8049821853637695
                },
                {
                    "id": 18902383,
                    "contents": "Introduction to Bayesian Inference for Psychology.\nWe introduce the fundamental tenets of Bayesian inference, which derive from two basic laws of probability theory. We cover the interpretation of probabilities, discrete and continuous versions of Bayes' rule, parameter estimation, and model comparison. Using seven worked examples, we illustrate these principles and set up some of the technical background for the rest of this special issue of Psychonomic Bulletin &amp; Review. Supplemental material is available via https://osf.io/wskex/ .",
                    "score": 0.8048584461212158
                },
                {
                    "id": 17826083,
                    "contents": "The Envelope, Please.\nNobel Prize announcements dominated science news this week. The Nature news section led with three Prize-winner stories: medicine, physics, and chemistry. Science saved the Nobel details for next week and instead led with an announced $58 million non-profit effort to sequence the mouse genome and distribute the results free of charge.",
                    "score": 0.804858386516571
                },
                {
                    "id": 11502486,
                    "contents": "Protonate3D: assignment of ionization states and hydrogen coordinates to macromolecular structures.\nA new method, called Protonate3D, is presented for the automated prediction of hydrogen coordinates given the 3D coordinates of the heavy atoms of a macromolecular structure. Protonate3D considers side-chain \"flip,\" rotamer, tautomer, and ionization states of all chemical groups, ligands, and solvent, provided suitable templates are available in a parameter file. The energy model includes van der Waals, Coulomb, solvation, rotamer, tautomer, and titration effects. The results of computational validation experiments suggest that Protonate3D can accurately predict the location of hydrogen atoms in macromolecular structures.",
                    "score": 0.804761528968811
                },
                {
                    "id": 14399162,
                    "contents": "A tale of two textbooks: Experiments in genre.\nThough the notion of a scientific textbook has been around for almost three centuries, the category has hardly been stable. The plasticity of the textbook genre may be illustrated by recent variations as well as long-term trends. In this brief essay I examine two idiosyncratic but highly successful physics books, each published in the mid 1970s, whose production, marketing, and adoption reveal some of the slippage between such categories as textbook, scholarly monograph, and popular best seller.",
                    "score": 0.8045597672462463
                },
                {
                    "id": 5283513,
                    "contents": "Energetics by NMR: site-specific binding in a positively cooperative system.\nProteins with multiple binding sites exhibit a complex behavior that depends on the intrinsic affinities for each site and the energetic communication between the sites. The contributions from intrinsic affinity and cooperativity are difficult to deconvolute using conventional binding experiments that lack information about the occupancies of individual sites. Here, we report the concerted use of NMR and isothermal titration calorimetry to determine the intrinsic and cooperative binding free energies for a ligand-protein complex. The NMR measurements provided the site-specific information necessary to resolve the binding parameters. Using this approach, we observed that human ileal bile acid binding protein binds two molecules of glycocholic acid with low intrinsic affinity but an extraordinarily high degree of positive cooperativity. The highly cooperative nature of the binding provides insights into the protein's biological mechanism. With ongoing improvements in sensitivity and resolution, NMR methods are becoming more amenable to dissecting the complex binding energetics of multisite systems.",
                    "score": 0.8044569492340088
                },
                {
                    "id": 12819677,
                    "contents": "Powerlaw: a Python package for analysis of heavy-tailed distributions.\nPower laws are theoretically interesting probability distributions that are also frequently used to describe empirical data. In recent years, effective statistical methods for fitting power laws have been developed, but appropriate use of these techniques requires significant programming and statistical insight. In order to greatly decrease the barriers to using good statistical methods for fitting power law distributions, we developed the powerlaw Python package. This software package provides easy commands for basic fitting and statistical analysis of distributions. Notably, it also seeks to support a variety of user needs by being exhaustive in the options available to the user. The source code is publicly available and easily extensible. ",
                    "score": 0.804263710975647
                },
                {
                    "id": 20922753,
                    "contents": "β.\n。， 。 。1997 ， ，、b- 。， 。1997 ，b- 。， ( 1997 49 )， ，b- 。.",
                    "score": 0.8036361932754517
                },
                {
                    "id": 8072687,
                    "contents": "Isothermal titration calorimetry: experimental design, data analysis, and probing macromolecule/ligand binding and kinetic interactions.\nIsothermal titration calorimetry (ITC) is now routinely used to directly characterize the thermodynamics of biopolymer binding interactions and the kinetics of enzyme-catalyzed reactions. This is the result of improvements in ITC instrumentation and data analysis software. Modern ITC instruments make it possible to measure heat effects as small as 0.1 microcal (0.4 microJ), allowing the determination of binding constants, K's, as large as 10(8) - 10(9)M(-1). Modern ITC instruments make it possible to measure heat rates as small as 0.1 microcal/sec, allowing for the precise determination of reaction rates in the range of 10(-12) mol/sec. Values for K(m) and k(cat), in the ranges of 10(-2) - 10(3) microM and 0.05 - 500 sec(-1), respectively, can be determined by ITC. This chapter reviews the planning of an optimal ITC experiment for either a binding or kinetic study, guides the reader through simulated sample experiments, and reviews analysis of the data and the interpretation of the results.",
                    "score": 0.8034149408340454
                },
                {
                    "id": 15304076,
                    "contents": "The AIBLHiCoS Method: Predicting Aqueous pKa Values from Gas-Phase Equilibrium Bond Lengths.\nThe proposed AIBLHiCoS method predicts a given compound's pKa in aqueous solution from a single ab initio bond length only, after geometry optimization in the gas phase. Here we provide simple and predictive equations for naphthols and chemically similar biomolecules. Each linear equation corresponds to a High-Correlation Subset (HiCoS) that expresses the novel type of linear free energy relationship discovered here. The naphthol family exhibits a clear and strong relationship with the phenol family, with the \"active\" C-O bond always producing the highest correlations. The proposed method can isolate erroneous experiments and operate in non-aqueous solution and at different temperatures. Moreover, the existence of \"active fragments\" is demonstrated in a variety of sizable biomolecules for which the pKa is successfully predicted. ",
                    "score": 0.8031138777732849
                },
                {
                    "id": 9582816,
                    "contents": "Why the Schild method is better than Schild realised.\nIt is almost 60 years since Heinz Schild devised a method that allowed measurement of a genuine physical quantity, the equilibrium constant for binding of a competitive antagonist. The clever bit was that the measurements could be made using responses from tissues despite the fact that little or nothing was known about how the agonist worked. Since then, attempts have been made to generalise the Schild equation, but they are all based on false premises. It turns out that generalisation is usually not needed. His original simple result is still valid in cases where several agonist molecules must be bound to produce a response, even if the agonist binding sites interact or are not identical.",
                    "score": 0.803052544593811
                },
                {
                    "id": 17824404,
                    "contents": "Bayesian analysis of isothermal titration calorimetry for binding thermodynamics.\nIsothermal titration calorimetry (ITC) is the only technique able to determine both the enthalpy and entropy of noncovalent association in a single experiment. The standard data analysis method based on nonlinear regression, however, provides unrealistically small uncertainty estimates due to its neglect of dominant sources of error. Here, we present a Bayesian framework for sampling from the posterior distribution of all thermodynamic parameters and other quantities of interest from one or more ITC experiments, allowing uncertainties and correlations to be quantitatively assessed. For a series of ITC measurements on metal:chelator and protein:ligand systems, the Bayesian approach yields uncertainties which represent the variability from experiment to experiment more accurately than the standard data analysis. In some datasets, the median enthalpy of binding is shifted by as much as 1.5 kcal/mol. A Python implementation suitable for analysis of data generated by MicroCal instruments (and adaptable to other calorimeters) is freely available online.",
                    "score": 0.8029260635375977
                },
                {
                    "id": 15099756,
                    "contents": "High accuracy of Karplus equations for relating three-bond J couplings to protein backbone torsion angles.\n(3) JC'C' and (3) JHNHα couplings are related to the intervening backbone torsion angle ${\\varphi }$ by standard Karplus equations. Although these couplings are known to be affected by parameters other than ${\\varphi }$, including H-bonding, valence angles and residue type, experimental results and quantum calculations indicate that the impact of these latter parameters is typically very small. The solution NMR structure of protein GB3, newly refined by using extensive sets of residual dipolar couplings, yields 50-60 % better Karplus equation agreement between ${\\varphi }$ angles and experimental (3) JC'C' and (3) JHNHα values than does the high-resolution X-ray structure. In intrinsically disordered proteins, (3) JC'C' and (3) JHNHα couplings can be measured at even higher accuracy, and the impact of factors other than the intervening torsion angle on (3) J will be smaller than in folded proteins, making these couplings exceptionally valuable reporters on the ensemble of ${\\varphi }$ angles sampled by each residue. ",
                    "score": 0.8028269410133362
                },
                {
                    "id": 15028451,
                    "contents": "What is information?†.\nInformation is a precise concept that can be defined mathematically, but its relationship to what we call 'knowledge' is not always made clear. Furthermore, the concepts 'entropy' and 'information', while deeply related, are distinct and must be used with care, something that is not always achieved in the literature. In this elementary introduction, the concepts of entropy and information are laid out one by one, explained intuitively, but defined rigorously. I argue that a proper understanding of information in terms of prediction is key to a number of disciplines beyond engineering, such as physics and biology.",
                    "score": 0.8026242852210999
                },
                {
                    "id": 10686401,
                    "contents": "My 50 years of research in particle physics.\nSome of my work of the last 50 years in the field of theoretical particle physics is described with particular emphasis on the motivation, the process of investigation, relationship to the work of others, and its impact. My judgment is unavoidably subjective, although I do present the comments of other researchers as much as possible.",
                    "score": 0.802571177482605
                },
                {
                    "id": 9431899,
                    "contents": "Fast empirical pKa prediction by Ewald summation.\npK(a) calculations for macromolecules are normally performed by solving the Poisson-Boltzmann equation, accounting for the different dielectric constants of solvent and solute, as well as the ionic strength. Despite the large number of successful applications, there are some situations where the current algorithms are not suitable: (1) large scale, high-throughput analysis which requires calculations to be completed within a fraction of a second, e.g. when permanently monitoring pK(a) shifts during a molecular dynamics simulation; (2) prediction of pK(a)s in periodic boundaries, e.g. when reconstructing entire protein crystal unit cells from PDB files, including the correct protonation patterns at experimental pH. Such in silico crystals are needed by 'self-parameterizing' molecular dynamics force fields like YASARA YAMBER, that optimize their parameters while energy-minimizing high-resolution protein crystals. To address both problems, we define an empirical equation that expresses the pK(a) as a function of electrostatic potential, hydrogen bonds and accessible surface area. The electrostatic potential is evaluated by Ewald summation, which captures periodic crystal environments and the uncertainty in atom positions using Gaussian charge densities. The empirical proportionality constants are derived from 217 experimentally determined pK(a)s, and despite its simplicity, this pK(a) calculation method reaches a high overall jack-knifed accuracy, and is fast enough to be used during a molecular dynamics simulation. A reliable null-model to judge pK(a) prediction accuracies is also presented.",
                    "score": 0.8022102117538452
                },
                {
                    "id": 5014773,
                    "contents": "PK-PD curve-fitting problems with the Hill equation? Try one of the 1-exp functions derived from Hodgkin, Douglas or Gompertz.\nNon-linear phenomena are observed with enzyme kinetics, protein binding, pharmacokinetics or pharmacodynamics. The Hill equation, the Michaelis-Menten equation extended by a power coefficient, is traditionally used for sigmoid curve fitting. Sigmoid saturation phenomena can also be described by exponential functions (1-exp), extended by a power coefficient such as those derived by Hodgkin, Douglas or Gompertz. Comparing the 4 equations, the sigmoid 1-exp function in the form of Hodgkin and Huxley comes closest to the principle of simplicity and succinctness with regard to definition, slope and flexibility of the inflection point. To compare the applicability, a standardized sample of 250 curves was generated by each I of the 4 equations and mutually fitted with the remaining 3. The Hill equation gives the closest fit with the data generated by the other functions. The Douglas variant exhibits the highest rate of convergence. The Gompertz function provides the basic feature of a baseline effect. The sigmoid functions investigated (Hill, Hodgkin, Douglas, Gompertz) have differing characteristics and can be used interchangeably for solving specific problems in non-linear modeling.",
                    "score": 0.8021548390388489
                },
                {
                    "id": 17953994,
                    "contents": "Pr:RbPb<sub>2</sub>Cl<sub>5</sub>: temperature dependent spectra, dynamics and three-for-one excitation: erratum.\nWe present an erratum regarding the contents of Table 1.",
                    "score": 0.8021461963653564
                },
                {
                    "id": 9131511,
                    "contents": "Van't Hoff analysis of K degrees (T): how good...or bad?\nBinding constant data K degrees (T) are commonly subjected to van't Hoff analysis to extract estimates of DeltaH degrees, DeltaS degrees, and DeltaCP degrees for the process in question. When such analyses employ unweighted least-squares fitting of lnK degrees to an appropriate function of the temperature T, they are tacitly assuming constant relative error in K degrees. When this assumption is correct, the statistical errors in DeltaG degrees, DeltaH degrees, DeltaS degrees, DeltaCP degrees, and the T-derivative of DeltaCP degrees (if determined) are all independent of the actual values of K degrees and can be computed from knowledge of just the T values at which K degrees is known and the percent error in K degrees. All of these statistical errors except that for the highest-order constant are functions of T, so they must normally be calculated using a form of the error propagation equation that is not widely known. However, this computation can be bypassed by defining DeltaH degrees as a polynomial in (T-T0), the coefficients of which thus become DeltaH degrees, DeltaCP degrees, and 1/2 dDeltaCP degrees/dT at T=T0. The errors in the key quantities can then be computed by just repeating the fit for different T0. Procedures for doing this are described for a representative data analysis program. Results of such calculations show that expanding the T range from 10-40 to 5-45 degrees C gives significant improvement in the precision of all quantities. DeltaG degrees is typically determined with standard error a factor of approximately 30 smaller than that for DeltaH degrees. Accordingly, the error in TDeltaS degrees is nearly identical to that in DeltaH degrees. For 4% error in K degrees, the T-derivative in DeltaCP degrees cannot be determined unless it is approximately 10 cal mol-1 K-2 or greater; and DeltaCP degrees must be approximately 50 cal mol-1 K-1. Since all errors scale with the data error and inversely with the square root of the number of data points, the present results for 4% error cover any other relative error and number of points, for the same approximate T structure of the data.",
                    "score": 0.8014499545097351
                },
                {
                    "id": 8312356,
                    "contents": "An introduction to an updated bibliography of Andreas Vesalius (1514-1564).\nAfter more than forty years Dr. Harvey Cushing's list of Vesaliana needs to be updated. The present list combines the Vesaliana of Cushing with titles gathered by R. Calcoen and newly found earlier and more recent ones. They are arranged in alpha-numerical order while the list retains the already existing numberings.",
                    "score": 0.8013444542884827
                },
                {
                    "id": 22076669,
                    "contents": "Tom N. Grossmann.\n\"My favorite quote is 'All models are wrong, but some are useful' … I advise my students to read first and then go to the lab (can save months of work) …\" Find out more about Tom Grossmann in his Author Profile.",
                    "score": 0.8010507225990295
                },
                {
                    "id": 1133021,
                    "contents": "A method for conforming the pH dependence of the michaelis parameters of nonallosteric enzymes to four kinetic schemes.\nA nonlinear regression program for the analysis of the effect of pH on enzyme activity has been developed for the IBM micro range and compatible machines. The program conforms the V and Km pH profiles to one of four commonly occurring kinetic schemes. By using multiple linear regression the program computes initial estimates for the nonlinear search which are thus not required from the user. Two nonlinear optimization methods are included in order to effectively handle the nonnegativity constraints on the parameters. The program is user-friendly and provides plots of the fit and residual plots to help the user decide on the goodness of fit obtained. The program was coded in Turbo Pascal version 4.0 and runs on IBM micros or close compatibles with four types of graphics cards.",
                    "score": 0.8009743094444275
                },
                {
                    "id": 4147965,
                    "contents": "Insulin action: 1948-80.\nInsulin is an old hormone from the standpoint of evolution. It is found in primitive vertebrates, insects, and crustacea and has effects on growth and glucose uptake in animals low on the evolutionary ladder, yes even unicellular organisms. The fascinating problem to consider is the relative emergence of the hormone and of its receptor. Csaba has reviewed recently the work with more primitive species. He argues convincingly that receptor molecules precede the hormones and adapt themselves to become the specific recognition sites they now are in the mammalian organism. This is a fascinating basis area for further research. The history of insulin research is rich and vivid, and has served to open up very important aspects of biochemistry and physiology. It was the first of the protein or peptide group of hormones; the protein whose amino acid sequence studies served to initiate this fruitful area of polymer biochemistry; and it began the important era of specific immunoassays, a technique that has revolutionized the study of the behavior and action of potent natural materials that are highly active in minute concentrations. Last but certainly not the least of its virtues is its medical use to maintain the life and health of countless victims of severe diabetes. The continuing study of the details of insulin action will undoubtedly have further profound influences on the basic and applied aspects of medicine and biology.",
                    "score": 0.8008331656455994
                },
                {
                    "id": 15448571,
                    "contents": "The Standard Model: how far can it go and how can we tell?\nThe Standard Model of particle physics encapsulates our current best understanding of physics at the smallest distances and highest energies. It incorporates quantum electrodynamics (the quantized version of Maxwell's electromagnetism) and the weak and strong interactions, and has survived unmodified for decades, save for the inclusion of non-zero neutrino masses after the observation of neutrino oscillations in the late 1990s. It describes a vast array of data over a wide range of energy scales. I review a selection of these successes, including the remarkably successful prediction of a new scalar boson, a qualitatively new kind of object observed in 2012 at the Large Hadron Collider. New calculational techniques and experimental advances challenge the Standard Model across an ever-wider range of phenomena, now extending significantly above the electroweak symmetry breaking scale. I will outline some of the consequences of these new challenges, and briefly discuss what is still to be found.This article is part of the themed issue 'Unifying physics and technology in light of Maxwell's equations'.",
                    "score": 0.8007882833480835
                },
                {
                    "id": 15467385,
                    "contents": "Predicting pKa Values in Aqueous Solution for the Guanidine Functional Group from Gas Phase Ab Initio Bond Lengths.\nHere we applied a novel method1a to predict pKa values of the guanidine functional group, which is a notoriously difficult. This method, which was developed in our lab, uses only one ab initio bond length obtained at a low level of theory. The method is shown to work for drug molecules, delivers prediction errors of less than 0.5 log units, successfully treats tautomerisation in close relation with experiment, and demonstrates strong correlations with only a few data points. The high structural content of the ab initio bond length makes a given data set essentially divide itself into high correlation subsets. One then observes that molecules within a subset possess a common substructure. Each high correlation subset exists in its own region of chemical space. The high correlation subset method is explored with respect to this position in chemical space, in particular tautomerisation. The proposed method is able to distinguish between different tautomeric forms and the preferred tautomeric form emerges naturally, in agreement with experiment. ",
                    "score": 0.8006675243377686
                },
                {
                    "id": 9670433,
                    "contents": "A short history of SHELX.\nAn account is given of the development of the SHELX system of computer programs from SHELX-76 to the present day. In addition to identifying useful innovations that have come into general use through their implementation in SHELX, a critical analysis is presented of the less-successful features, missed opportunities and desirable improvements for future releases of the software. An attempt is made to understand how a program originally designed for photographic intensity data, punched cards and computers over 10000 times slower than an average modern personal computer has managed to survive for so long. SHELXL is the most widely used program for small-molecule refinement and SHELXS and SHELXD are often employed for structure solution despite the availability of objectively superior programs. SHELXL also finds a niche for the refinement of macromolecules against high-resolution or twinned data; SHELXPRO acts as an interface for macromolecular applications. SHELXC, SHELXD and SHELXE are proving useful for the experimental phasing of macromolecules, especially because they are fast and robust and so are often employed in pipelines for high-throughput phasing. This paper could serve as a general literature citation when one or more of the open-source SHELX programs (and the Bruker AXS version SHELXTL) are employed in the course of a crystal-structure determination.",
                    "score": 0.8006359934806824
                },
                {
                    "id": 19147079,
                    "contents": "Bayesian inference for psychology, part III: Parameter estimation in nonstandard models.\nWe demonstrate the use of three popular Bayesian software packages that enable researchers to estimate parameters in a broad class of models that are commonly used in psychological research. We focus on WinBUGS, JAGS, and Stan, and show how they can be interfaced from R and MATLAB. We illustrate the use of the packages through two fully worked examples; the examples involve a simple univariate linear regression and fitting a multinomial processing tree model to data from a classic false-memory experiment. We conclude with a comparison of the strengths and weaknesses of the packages. Our example code, data, and this text are available via https://osf.io/ucmaz/ .",
                    "score": 0.8004758954048157
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_29",
        "question": "Two narrow slits separated by $0.10 \\mathrm{~mm}$ are illuminated by light of wavelength $600 \\mathrm{~nm}$. What is the angular position of the first maximum in the interference pattern? If a detector is located $2.00 \\mathrm{~m}$ beyond the slits, what is the distance between the central maximum and the first maximum?",
        "golden_answers": [
            " 12"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 13001107,
                    "contents": "Measuring coherence functions using non-parallel double slits.\nWe present an experimental method for the fast measurement of both the spectral (spatial) and complex degrees of coherence of an optical field using only a binary amplitude mask and a detector array. We test the method by measuring a two-dimensional spectral degree of coherence function created by a broadband thermal source. The results are compared to those expected by the van Cittert-Zernike theorem and found to agree well in both amplitude and phase. ",
                    "score": 0.9035511016845703
                },
                {
                    "id": 15524017,
                    "contents": "On the instrument profile of slit spectrographs.\nWe derive an analytic expression for the instrument profile of a slit spectrograph, also known as the line spread function. While this problem is not new, our treatment relies on the operatorial approach to the description of diffractive optical systems, which provides a general framework for the analysis of the performance of slit spectrographs under different illumination conditions. Based on our results, we propose an approximation to the spectral resolution of slit spectrographs, taking into account diffraction effects and sampling by the detector, which improves upon the often adopted approximation based on the root-sum-square of the individual contributions from the slit, the grating, and the detector pixel. ",
                    "score": 0.9014570713043213
                },
                {
                    "id": 16919688,
                    "contents": "Young's double-slit experiment: noise-resolution duality.\nStatistical aspects of Young's double-slit diffraction experiment are analysed quantitatively. It is shown that the signal-to-noise ratio and the spatial resolution in the detected diffraction pattern satisfy a duality relationship which implies that both of them cannot be improved simultaneously beyond a certain limit if the total number of particles forming the image is fixed. As a consequence of this duality, it is possible to estimate the minimal number of particles that have to be detected in order for two slits separated by a given distance to be resolved with a confidence level corresponding to a pre-defined signal-to-noise ratio, e.g. according to the Rose criterion. These results are related to the recently introduced imaging system quality characteristic which combines the spatial resolution and the noise sensitivity, and allows one to estimate the efficiency with which imaging quanta are utilised in a system to deliver maximal amount of information about the imaged object. The presented results can be useful for applications where the imaging quanta are at a premium or where minimization of the radiation dose is important. ",
                    "score": 0.8983302116394043
                },
                {
                    "id": 13864057,
                    "contents": "Young's experiment with a double slit of sub-wavelength dimensions.\nWe report that the interference pattern of Young's double-slit experiment changes as a function of polarization in the sub-wavelength diffraction regime. Experiments carried out with terahertz time-domain spectroscopy reveal that diffracted waves from sub-wavelength-scale slits exhibit either positive or negative phase shift with respect to Gouy phase depending on the polarization. Theoretical explanation based on the induction of electric current and magnetic dipole in the vicinity of the slits shows an excellent agreement with the experimental results. ",
                    "score": 0.8950110673904419
                },
                {
                    "id": 5223615,
                    "contents": "X-ray diffraction from rectangular slits.\nIt is shown that for micrometre-sized beams the X-ray diffraction from slits is a source of strong parasitic background, even for slits of high quality. In order to illustrate this effect, the coherent diffraction from rectangular slits has been studied in detail. A large number of interference fringes with strong visibility have been observed using a single set of slits made of polished cylinders. For very small apertures, asymmetrical slits generate asymmetrical patterns. This pattern is calculated from the theory of electromagnetic field propagation and compared with experiment in the far-field regime. The use of guard slits to remove Fraunhofer diffraction from the beam-defining slits is treated theoretically. Numerical simulations yield the optimum aperture of the guard slits with respect to the distance to the primary slits. Diffraction theory is shown to be essential to understand how to reduce the background-to-signal ratio in high-resolution experiments.",
                    "score": 0.8943898677825928
                },
                {
                    "id": 11404805,
                    "contents": "Transmission of light through slit apertures in metallic films.\nTransmission of polarized light through sub-wavelength slit apertures is studied based on the electromagnetic field distributions obtained in computer simulations. The results show the existence of a cutoff for E|| and a strong transmission (with no cutoff) for E?; here || and ? refer to the direction of the incident E-field relative to the long axis of the slit. These observations are explained by the standard waveguide theory involving inhomogeneous plane waves that bounce back and forth between the interior walls of the slit aperture. We examine the roles played by the slit-width, by the film thickness, and by the real and imaginary parts of the host material's dielectric constant in determining the transmission efficiency. We also show that the slit's sharp edges can be rounded to eliminate highly-localized electric dipoles without significantly affecting the slit's throughput. Finally, interference among the surface charges and currents induced in the vicinity of two adjacent slits is shown to result in enhanced transmission through both slits when the slits are separated by about one half of one wavelength.",
                    "score": 0.8942543268203735
                },
                {
                    "id": 14200504,
                    "contents": "The electromagnetics of light transmission through subwavelength slits in metallic films.\nBy numerically calculating the relevant electromagnetic fields and charge current densities, we show how local charges and currents near subwavelength structures govern light transmission through subwavelength apertures in a real metal film. The illumination of a single aperture generates surface waves; and in the case of slits, generates them with high efficiency and with a phase close to -π with respect to a reference standing wave established at the metal film front facet. This phase shift is due to the direction of induced charge currents running within the slit walls. The surface waves on the entrance facet interfere with the standing wave. This interference controls the profile of the transmission through slit pairs as a function of their separation. We compare the calculated transmission profile for a two-slit array to simple interference models and measurements [Phys. Rev. B 77(11), 115411 (2008)].",
                    "score": 0.8918172717094421
                },
                {
                    "id": 9642615,
                    "contents": "Slits as adjustable pinholes for coherent X-ray scattering experiments.\nThe combination of accurate translation stages with carefully polished slit blades leads to slits that have many advantages as pinholes for coherent X-ray scattering experiments. The size is adjustable and can be made as small as 0.5 mum. Setting up is easy, while the blade thickness (1 mm tungsten) also makes the slits useful for hard X-rays. A relation between the slit-sample distance and the minimum beam size, together with the corresponding slit size, is derived. This shows that a micrometer-sized beam can be achieved with this type of slits.",
                    "score": 0.8882033228874207
                },
                {
                    "id": 9590652,
                    "contents": "Detection of subwavelength slit-width variation with irradiance measurements in the far field.\nWe demonstrate that, under suitable conditions, subwavelength feature variations of an object can affect the corresponding far-field diffraction pattern in a measurable way. We present an experiment in which width variations of less than 1/100 of the wavelength are measured with a slit whose width is 100 times the wavelength. Integral and differential intensity measurements in the far field are fully consistent with standard diffraction theory even in the subwavelength variation regime. In particular, slit modulations of 6 nm with a wavelength of 670 nm are shown to follow theoretical calculations within the experimental sensitivity of ~10(-5) .",
                    "score": 0.8880252838134766
                },
                {
                    "id": 17055605,
                    "contents": "Nonclassical paths in quantum interference experiments.\nIn a double slit interference experiment, the wave function at the screen with both slits open is not exactly equal to the sum of the wave functions with the slits individually open one at a time. The three scenarios represent three different boundary conditions and as such, the superposition principle should not be applicable. However, most well-known text books in quantum mechanics implicitly and/or explicitly use this assumption that is only approximately true. In our present study, we have used the Feynman path integral formalism to quantify contributions from nonclassical paths in quantum interference experiments that provide a measurable deviation from a naive application of the superposition principle. A direct experimental demonstration for the existence of these nonclassical paths is difficult to present. We find that contributions from such paths can be significant and we propose simple three-slit interference experiments to directly confirm their existence. ",
                    "score": 0.8860848546028137
                },
                {
                    "id": 9956527,
                    "contents": "Interference from a nonlocal double-slit through one-photon process.\nIn this paper, we report an interference experiment in which a spatially incoherent light source illuminates two spatially separated apertures, whose superposition at the same place forms a double-slit. The experimental result exhibits a well-defined interference fringe solely through intensity measurements, in agreement with the theoretical analysis by means of the first-order spatial interference of the incoherent light. Consequently, the nonlocal double-slit interference with thermal light should be attributed to the first-order spatial correlation of incoherent field.",
                    "score": 0.8846002221107483
                },
                {
                    "id": 10949717,
                    "contents": "Analytic Derivation and Monte Carlo Validation of a Sensitivity Formula for Slit-Slit Collimation With Penetration.\nA slit-slit collimator consists of two orthogonal slits and can be conceptualized as a generalized pinhole. Since the two slits are independent of each other, there can be independent axial and transaxial acceptance angles. A small axial acceptance angle may help mitigate axial blurring with circular orbits, allowing multiple copies axially. In addition, since the two slit planes can be placed at different distances with respect to the source, a better detector usage can be achieved, especially in the case of detectors and imaged objects with different aspect ratios. In this paper an analytical expression is derived for the sensitivity of slit-slit collimation including effective slit widths for photon penetration. An analytical expression for sensitivity is necessary in order to accurately model the system response. This expression could also be useful for comparing the slit-slit's sensitivity performance with others. When the effective slit width is used instead of the geometric slit width, the derived analytical expression accurately accounts for photon penetration of the aperture. The derived expression for the sensitivity was validated by Monte Carlo simulation for both geometric and penetrative cases.",
                    "score": 0.8798279762268066
                },
                {
                    "id": 17303770,
                    "contents": "The Young-Feynman controlled double-slit electron interference experiment.\nThe key features of quantum mechanics are vividly illustrated by the Young-Feynman two-slit thought experiment, whose second part discusses the recording of an electron distribution with one of the two slits partially or totally closed by an aperture. Here, we realize the original Feynman proposal in a modern electron microscope equipped with a high brightness gun and two biprisms, with one of the biprisms used as a mask. By exciting the microscope lenses to conjugate the biprism plane with the slit plane, observations are carried out in the Fraunhofer plane with nearly ideal control of the covering of one of the slits. A second, new experiment is also presented, in which interference phenomena due to partial overlap of the slits are observed in the image plane. This condition is obtained by inserting the second biprism between the two slits and the first biprism and by biasing it in order to overlap their images.",
                    "score": 0.8787634372711182
                },
                {
                    "id": 22142744,
                    "contents": "Testing scalar diffraction theory: Gaussian beam on a slit.\nWe recorded diffraction patterns using a commercially available slit and sensor over a wide range of experimental circumstances, including near- and far-field regimes and oblique incidence at large angles. We then compared the measured patterns with theoretical intensity curves calculated via the numerical integration of formulas derived within the framework of scalar diffraction theory. Experiment and theory show particularly good agreement when the first Rayleigh-Sommerfeld (R-S) formula is used. The Kirchhoff formula, though problematic in the context of mathematical consistency, agrees with the first R-S formula, even for large incidence angles, whereas the second R-S formula differs visibly. To obtain such a good agreement, we replaced the assumption of an incident plane wave with that of a Gaussian beam and implemented geometric corrections to account for slit imperfections. These results reveal how the scope of scalar diffraction theory can be extended with a small set of auxiliary assumptions.",
                    "score": 0.8787344098091125
                },
                {
                    "id": 11965419,
                    "contents": "High-harmonic-generation spectrum reconstruction from Young's double-slits interference pattern using the maximum entropy method.\nA method is proposed that uses maximum entropy analysis of a Young's two-slit interference pattern for the measurement of the spectrum of a high-harmonic-generation light source. The approach is tested using experimental data, and the results are found to be consistent with those obtained directly using a grazing incidence spectrometer.",
                    "score": 0.8778364658355713
                },
                {
                    "id": 15876422,
                    "contents": "Modifying the optical path in a nonlinear double-slit experiment.\nIn this Letter, we study a nonlinear interferometric setup based on diffraction, rather than beam combining. It consists of a nonlinear analog of Young's double-slit experiment where a nonlinear material is placed exactly after one of the slits. The presence of nonlinearity breaks the transverse spatial symmetry of the system and, thus, modifies the optical path. For moderate nonlinearities, this leads to a self-induced shift of the intensity pattern in the transverse plane. A simple theoretical model is developed which is surprisingly accurate in predicting the intensity profile of the main lobes for a wide range of parameters. We discuss possible applications of our model in nonlinear interferometry, for example in measuring the nonlinearities of optical materials. ",
                    "score": 0.8772574663162231
                },
                {
                    "id": 11479961,
                    "contents": "Diffraction Filters in XUV Spectroscopy.\nThe transmission of diffraction filters depends mainly on the geometrical parameters, the slit width 2d, the distance x(n,n-1) of the slits from each other, and the number n of the slits. Therefore the filter curve may be \"shifted\" continuously throughout the XUV spectral region simply by changing the corresponding parameters. This is discussed in detail. Diffraction filters can be utilized in a wide range of experiments in solar, stellar, and laboratory spectroscopy. As is shown for three well known optical arrangements, diffraction filters improve the signal-to-noise ratio considerably, to some extent simplifying the experiment at the same time. Consequently this new technique is an efficient optical tool.",
                    "score": 0.8768969178199768
                },
                {
                    "id": 8679226,
                    "contents": "Experimental demonstration of tomographic slit technique for measurement of arbitrary intensity profiles of light beams.\nWe demonstrate experimentally an optical imaging method that makes use of a slit to collect tomographic projection data of arbitrarily shaped light beams; a tomographic backprojection algorithm is then used to reconstruct the intensity profiles of these beams. Two different implementations of the method are presented. In one, a single slit is scanned and rotated in front of the laser beam. In the other, the sides of a polygonal slit, which is linearly displaced in a x-y plane perpendicular to the beam, are used to collect the data. This latter version is more suitable than the other for adaptation at micrometer-size scale. A mathematical justification is given here for the superior performance against laser-power fluctuations of the tomographic slit technique compared with the better-known tomographic knife-edge technique.",
                    "score": 0.8750054836273193
                },
                {
                    "id": 11940298,
                    "contents": "On the transmission of diffuse light through thick slits.\nWe study the transmission of diffuse light through thick slits. For perfectly conducting slits and in-plane s-polarized illumination, the transmittance curves present a staircaselike behavior as a function of the aperture width, where the steps mark the appearance of new propagation modes. In contrast, with p-polarized illumination the transmittance increases linearly with the aperture width, with only some perturbations in the positions that correspond to the appearance of new modes. Out-of-plane incidence and more realistic assumptions about the slit, such as finite conductivity and roughness, are also discussed.",
                    "score": 0.8748953342437744
                },
                {
                    "id": 10092469,
                    "contents": "Double slit with continuously variable width and center-to-center separation.\nLinear polarizers and a half-wave plate are used to make a double slit whose width and center-to-center separation are continuously variable.",
                    "score": 0.8746895790100098
                },
                {
                    "id": 13505273,
                    "contents": "Influence of film thickness on the optical transmission through subwavelength single slits in metallic thin films.\nSilver and gold films with thicknesses in the range of 120-450 nm were evaporated onto glass substrates. A sequence of slits with widths varying between 70 and 270 nm was milled in the films using a focused gallium ion beam. We have undertaken high-resolution measurements of the optical transmission through the single slits with 488.0 nm (for Ag) and 632.8 nm (for Au) laser sources aligned to the optical axis of a microscope. Based on the present experimental results, it was possible to observe that (1) the slit transmission is notably affected by the film thickness, which presents a damped oscillatory behavior as the thickness is augmented, and (2) the transmission increases linearly with increasing slit width for a fixed film thickness.",
                    "score": 0.8746436834335327
                },
                {
                    "id": 11262803,
                    "contents": "Geometrical optics modeling of the grating-slit test.\nA novel optical testing method termed the grating-slit test is discussed. This test uses a grating and a slit, as in the Ronchi test, but the grating-slit test is different in that the grating is used as the incoherent illuminating object instead of the spatial filter. The slit is located at the plane of the image of a sinusoidal intensity grating. An insightful geometrical-optics model for the grating-slit test is presented and the fringe contrast ratio with respect to the slit width and object-grating period is obtained. The concept of spatial bucket integration is used to obtain the fringe contrast ratio.",
                    "score": 0.8740675449371338
                },
                {
                    "id": 11249997,
                    "contents": "Non-linear Young's double-slit experiment.\nThe Young's double slit experiment is recreated using intense and short laser pulses. Our experiment evidences the role of the non-linear Kerr effect in the formation of interference patterns. In particular, our results evidence a mixed mechanism in which the zeroth diffraction order of each slit are mainly affected by self-focusing and self-phase modulation, while the higher orders propagate linearly. Despite of the complexity of the general problem of non-linear propagation, we demonstrate that this experiment retains its simplicity and allows for a geometrical interpretation in terms of simple optical paths. In consequence, our results may provide key ideas on experiments on the formation of interference patterns with intense laser fields in Kerr media.",
                    "score": 0.8736622333526611
                },
                {
                    "id": 11519154,
                    "contents": "Arbitrary-intensity-profiles measurement of laser beams by a scanning and rotating slit.\nBy taking advantage of the mathematical analogy of optical power passing through a narrow slit and the attenuation of an x-ray beam passing through a biological tissue, and by applying to the optical case the projection and reconstruction algorithms of computed tomography, one can determine in detail the intensity profile of an arbitrary laser beam by properly combining the position and orientation of the slit. Until now, to the best of my knowledge, the scanning slit has been limited to the measurement of Gaussian or nearly Gaussian beams.",
                    "score": 0.873494029045105
                },
                {
                    "id": 14812629,
                    "contents": "Measurement-induced decoherence and information in double-slit interference.\nThe double slit experiment provides a classic example of both interference and the effect of observation in quantum physics. When particles are sent individually through a pair of slits, a wave-like interference pattern develops, but no such interference is found when one observes which \"path\" the particles take. We present a model of interference, dephasing, and measurement-induced decoherence in a one-dimensional version of the double-slit experiment. Using this model, we demonstrate how the loss of interference in the system is correlated with the information gain by the measuring apparatus/observer. In doing so, we give a modern account of measurement in this paradigmatic example of quantum physics that is accessible to students taking quantum mechanics at the graduate or senior undergraduate levels.",
                    "score": 0.8712999820709229
                },
                {
                    "id": 7079576,
                    "contents": "Spatial width and power-content ratio of hard-edge diffracted beams.\nOn the basis of the intensity-moment formalism, certain analytical relationships are obtained for both the angular domain and the size of a transverse region of the beam that ensure a power content of at least 75% of the total power. As an illustrative application, the analytical results are compared with the exact values (numerically computed) of the amplitude of a lowest-order Gaussian beam diffracted by slits.",
                    "score": 0.8707953691482544
                },
                {
                    "id": 6454572,
                    "contents": "Characterization of the signature of subwavelength variation from far-field irradiance.\nThe dynamic signature of the subwavelength variation of a slit is shown to be determinable from far-field irradiance with a precision of better than 1 nm. One can increase the efficiency of measurement of the subwavelength's signature by adjusting the detection width over which the subwavelength variation is detected. The subwavelength variation of a rectangular aperture was also examined to show the general feasibility.",
                    "score": 0.8705875873565674
                },
                {
                    "id": 8652824,
                    "contents": "Double-slit interference with Laguerre-Gaussian beams.\nThe interference of Laguerre-Gaussian beams carrying orbital angular momentum was demonstrated in Young's double-slit geometry. Double-slit interference is shown to be affected by the azimuthal phase dependence of a Laguerre-Gaussian beam. This interference provides new insight into the helical phase structure of the Laguerre-Gaussian beam and has potential applications for measuring the orbital angular momentum of an arbitrary wavefront.",
                    "score": 0.8705729246139526
                },
                {
                    "id": 18779719,
                    "contents": "On the equivalence between Young's double-slit and crystal double-refraction interference experiments.\nWe show, both analytically and experimentally, that under common experimental conditions the interference pattern produced in a classic Young's double-slit experiment is indistinguishable from that generated by means of a doubly refracting uniaxial crystal whose optic axis makes a skew angle with the light propagation direction. The equivalence between diffraction and crystal optics interference experiments, taken for granted by Arago and Fresnel in their pioneering research on the interference of polarized light beams, is thus rigorously proven.",
                    "score": 0.870343804359436
                },
                {
                    "id": 11388208,
                    "contents": "Concerning the instrumental profile of a double monochromator.\nThe response of a monochromator to an intense line, the so-called instrumental profile or slit function, is studied over a range of signals comprising seven orders of magnitude, which corresponds to a maximum frequency shift of about five times the slit width. For a 1-m double monochromator with concave, holographic gratings, the observed profile is approximately described by diffraction theory except for the extreme wings.",
                    "score": 0.870302677154541
                },
                {
                    "id": 22177160,
                    "contents": "The Interference Pattern of Plasmonic and Photonic Modes Manipulated by Slit Width.\nWe demonstrate that the interference pattern of the plasmonic and photonic modes can be controlled by changing the slit width of a square slit structure. Based on the analyses of the plasmonic and photonic modes of slits with different widths, we theoretically derived the expressions of wavefield generated by a square slit. A far-field scattered imaging system is utilized to collect the intensity distribution experimentally. Various interference patterns, including stripes, square-like lattice array, and diamond-like lattice array, have been observed by adjusting the slit widths. In addition, the results were validated by performing finite-difference time-domain simulations, which are consistent with the theoretical and experimental results.",
                    "score": 0.8701490759849548
                },
                {
                    "id": 17087686,
                    "contents": "Dynamic Double-Slit Experiment in a Single Atom.\nA single-atom \"double-slit\" experiment is realized by photoionizing rubidium atoms using two independent low power lasers. The photoelectron wave of well-defined energy recedes to the continuum either from the 5P or 6P states in the same atom, resulting in two-path interference imaged in the far field using a photoelectron detector. Even though the lasers are independent and not phase locked, the transitions within the atom impart the phase relationship necessary for interference. The experiment is designed so that either 5P or 6P states are excited by one laser, before ionization by the second beam. The measurement cannot determine which excitation path is taken, resulting in interference in wave-vector space analogous to Young's double-slit studies. As the lasers are tunable in both frequency and intensity, the individual excitation-ionization pathways can be varied, allowing dynamic control of the interference term. Since the electron wave recedes in the Coulomb potential of the residual ion, a quantum model is used to capture the dynamics. Excellent agreement is found between theory and experiment.",
                    "score": 0.8676550388336182
                },
                {
                    "id": 20851261,
                    "contents": "Diffraction by ruled gratings with variable spacing: fundamental method of intensity calculation.\nA regular diffraction grating produces intensity patterns that combine waves coming through equispaced slits, so that the waves emerging from any two neighboring slits have identical phase differences. In this paper, we calculate the degradation in the intensity pattern when the grating has irregular spacing. The model of randomness considers the grating spacing and openings as being created by a \"random walk.\" The resolving power of the grating is evaluated in relation to the D lines of sodium. It is shown that as the number of rulings increases, the uniformity of their spacing becomes more important in precision spectroscopic measurements, such as in astrophysical spectroscopy.",
                    "score": 0.86714106798172
                },
                {
                    "id": 15836220,
                    "contents": "Squeezing millimeter waves through a single, nanometer-wide, centimeter-long slit.\nWe demonstrate broadband non-resonant squeezing of terahertz (THz) waves through an isolated 2-nm-wide, 2-cm-long slit (aspect ratio of 10(7)), representing a maximum intensity enhancement factor of one million. Unlike resonant nanogap structures, a single, effectively infinitely-long slit passes incident electromagnetic waves with no cutoff, enhances the electric field within the gap with a broad 1/f spectral response, and eliminates interference effects due to finite sample boundaries and adjacent elements. To construct such a uniform, isolated slit that is much longer than the millimeter-scale spot of a THz beam, we use atomic layer lithography to pattern vertical nanogaps in a metal film over an entire 4-inch wafer. We observe an increasing field enhancement as the slit width decreases from 20 nm to 2 nm, in agreement with numerical calculations. ",
                    "score": 0.8671014308929443
                },
                {
                    "id": 11632597,
                    "contents": "Tunable optical transmission through gold slit arrays with Z-shaped channels.\nThe transmission of a normally incident wave through an array of subwavelength gold film with Z-shaped slits has been explored by using the finite-difference time-domain method. The results show that the transmission of a thinner metal film perforated with a Z-shaped slit array behaves nearly the same as that of a thicker metal film perforated with straight slit array with the same central slit length, which is useful for the miniaturization of the optical device. It is also presented that the transmission of a Z-shaped slit array sensitively depends on the slit geometrical parameters. By adjusting the width and length of each section of the Z-shaped slit, noticeable magnitude modification of the transmission, redshift, and blueshift of the resonance modes is found, which is useful for the design of frequency-selective and sensor optical devices.",
                    "score": 0.8661916255950928
                },
                {
                    "id": 11432449,
                    "contents": "Modified Young's Interferometer.\nA modified Young's two-slit interferometer measures the separation between the centers of two slits or two lines when they are nearly coincident. A prototype instrument, which functions as an automatic, interferometric micrometer, is described. This instrument measures the position of a slit with a resolution of 5 nm.",
                    "score": 0.8660122156143188
                },
                {
                    "id": 10911109,
                    "contents": "Development of new apertures for coherent X-ray experiments.\nWhen one performs a coherent small-angle X-ray scattering experiment, the incident beam must be spatially filtered by slits on a length scale smaller than the transverse coherence length of the source which is typically around 10 microm. The Fraunhofer diffraction pattern of the slit is one of the important sources of background in these experiments. New slits which minimize this parasitic background have been designed and tested. The slit configuration apodizes the beam by the use of partially transmitting inclined slit jaws. A model is presented which predicts that the high wavevector tails of the diffraction pattern fall as the inverse fourth power of the wavevector instead of the inverse second power that is observed for standard slits. Using cleaved GaAs single-crystal edges, Fraunhofer diffraction patterns from 3 and 5.5 keV X-rays were measured, in agreement with the theoretical model proposed. A novel phase-peak diffraction pattern associated with phase variations of the transmitted electric field was also observed. The model proposed adequately accounts for this phenomenon.",
                    "score": 0.8657639026641846
                },
                {
                    "id": 14328932,
                    "contents": "Asymmetrically filled slits in a metal film that split a light beam into two depending on its wavelength.\nBy applying a scattering-wave theory, the electromagnetic response of an arbitrary array of multiple slits perforated on a metallic film and filled with different slit dielectric materials can be studied in an analytical way. Here, the wavelength-dependent splitting of a light beam into two by asymmetrically filled slits in a metal film using intraslit and interslit dual-wave interferences is fully explored. We consider a triple-slit structure perforated on a gold film, where the middle slit is used for the surface-plasmon (SP) excitation by a narrow Gaussian beam while the two side slits are used for the detection of a transmitted SP wave propagated from the middle opaque slit either at a particular wavelength or at double that wavelength, respectively. For this proposed simple structure, we show that only one of the two side observation slits can be in a passing state for a particular wavelength, but the other blocked slit will change to a passing state at double that wavelength with a specific design for the slit depth, slit dielectric, and interslit distance in the deep subwavelength regime. In this sense, SP mediated light transmission becomes wavelength sensitive in our model, and a single light beam can be separated into two according to its wavelength in the transverse direction parallel to the array. This provides us with a unique way for direct optical reading in the near-field region using a nonspectroscopic approach.",
                    "score": 0.865001916885376
                },
                {
                    "id": 22832295,
                    "contents": "Which-way identification by an asymmetrical double-slit experiment with monochromatic photons.\nRecently, a laser beam asymmetrical double-slit experiment was proposed and performed, concerning ontological physical reality in quantum mechanics, under an assumption of single-photon interference. In the present study, by controlling better for saturation effects and upgrading the slit's shape, we succeed in producing new interference samples with acceptable quality. Applying almost the same geometrical set-up, the present experiment makes the \"which-way\" identification with higher experimental confidence. In the results, the ontological which-way effect observed in our recent experiment is well reconfirmed without any additional measurement of relative integral intensity.",
                    "score": 0.8649391531944275
                },
                {
                    "id": 10849884,
                    "contents": "Extraordinary optical absorption through subwavelength slits.\nWe report on the ability of resonant plasmonic slits to efficiently concentrate electromagnetic energy into a nanoscale volume of absorbing material placed inside or directly behind the slit. This gives rise to extraordinary optical absorption characterized by an absorption enhancement factor that well exceeds the enhancements seen for extraordinary optical transmission through slits. A semianalytic Fabry-Perot model for the resonant absorption is developed and shown to quantitatively agree with full-field simulations. We show that absorption enhancements of nearly 1000% can be realized at 633 nm for slits in aluminum films filled with silicon. This effect can be utilized in a wide range of applications, including high-speed photodetectors, optical lithography and recording, and biosensors.",
                    "score": 0.8648346066474915
                },
                {
                    "id": 1347323,
                    "contents": "Scanning multiple slit assembly: a practical and efficient device to reduce scatter.\nA scanning multiple slit assembly consisting of an array of long narrow beam-defining slits coupled with scatter-eliminating slots beneath the patient is a feasible, practical, and efficient method of reducing scatter and increasing contrast and image quality in diagnostic radiology. Measurements of the ratio of scattered-to-primary radiation transmitted by a scanning multiple slit assembly and a conventional high ratio grid under similar conditions showed the relative intensity of scatter transmitted by the slit assembly to be only one-third that of the grid. A noticeable improvement in contrast was obtained using the slit assembly, without increase in patient exposure. The design, construction, and clinical implications of such a scatter-eliminating technique are discussed.",
                    "score": 0.8645647764205933
                },
                {
                    "id": 10186065,
                    "contents": "Double-slit camera.\nThis Technical Note is a comment on the imaging properties of the double-slit camera. We show its application to the correction of geometrical distortions and propose some other possibilities.",
                    "score": 0.8645198345184326
                },
                {
                    "id": 9578258,
                    "contents": "Absolute determination of the wavelength and spectrum of an extreme-ultraviolet beam by a Young's double-slit measurement.\nThe interference pattern produced by irradiation of a pair of pinholes with a beam contains information on both the spatial and the temporal coherence properties of the beam, as well as its power spectrum. We demonstrate experimentally for what is believed to be the first time that the spectrum of an extreme-ultraviolet (EUV) beam can be obtained from a measurement of the interference pattern produced by a pinhole pair. This approach offers a convenient method of making absolute wavelength and relative spectral intensity calibrations in the EUV.",
                    "score": 0.8643221855163574
                },
                {
                    "id": 10876101,
                    "contents": "Thin slits: transmission and polarization.\nThe paper discusses measurement of the transmission ratio T ||/T? of thin slits for light polarized linearly parallel and perpendicular to the slit direction at optical wavelengths and as a function of the angle of incidence. To obtain perfectly identical geometrical beams, the plane of polarization of the linearly polarized light is rotated in the measuring setup by means of plates of optically active quartz. The results indicate that the transmissivity is higher for light polarized parallel to the slit direction. This effect is more pronounced with narrow slits than with wide slits and, moreover, increases with the wavelength. For tangential orientation of the slit, the ratio T ||/T? increases with the angle of incidence. The paper studies the effect of surface reflections.",
                    "score": 0.8643015623092651
                },
                {
                    "id": 504614,
                    "contents": "Signal and noise in modulation transfer function determinations using the slit, wire, and edge techniques.\nThe modulation transfer function (MTF) of an idealized imaging system can be determined from the Fourier transform of the system's line-spread function (LSF). Three techniques of experimentally determining the LSF require imaging either a slit, wire, or edge. In this paper, these three techniques are modeled theoretically to determine the noise in the calculated MTFs as a function of spatial frequency resulting from both quantum fluctuations and stochastic detector noise. The techniques are compared using the signal-to-noise ratio (SNR) in the MTF, defined as the ratio of the MTF value to the standard deviation in an ensemble of MTF determinations from independent measurements. It is shown that for a specified photon fluence, the edge method MTF has the highest SNR at low spatial frequencies, while that of the slit method is superior at high frequencies. The wire method SNR is always inferior to that of the slit technique. This suggests that the edge method is preferable for measuring parameters such as the low-frequency drop, and the slit method is preferable for determining high-frequency response. The cross-over frequency at which the slit and edge methods are equal (f(e)) for quantum-noise limited systems is a function of the slit width and the length over which the LSF is measured. For detector-noise limited systems, f(e) is dependent on the slit width only. The SNR in all but the quantum-noise limited slit method can therefore be increased by decreasing the length over which the LSF is measured, smoothing the tails of the LSF, or by fitting the tails to an analytic expression.",
                    "score": 0.8642916679382324
                },
                {
                    "id": 16664575,
                    "contents": "Optical Diffraction in Close Proximity to Plane Apertures. I. Boundary-Value Solutions for Circular Apertures and Slits.\nIn this paper the classical Rayleigh-Sommerfeld and Kirchhoff boundary-value diffraction integrals are solved in closed form for circular apertures and slits illuminated by normally incident plane waves. The mathematical expressions obtained involve no simplifying approximations and are free of singularities, except in the aperture plane itself. Their use for numerical computations was straightforward and provided new insight into the nature of diffraction in the near zone where the Fresnel approximation does not apply. The Rayleigh-Sommerfeld integrals were found to be very similar to each other, so that polarization effects appear to be negligibly small. On the other hand, they differ substantially at sub-wavelength differences from the aperture plane and do not correctly describe the diffracted field as an analytical continuation of the incident geometrical field.",
                    "score": 0.8642838001251221
                },
                {
                    "id": 10516255,
                    "contents": "Resolution and stray light in near infrared spectroscopy.\nThe slit function at 1064 nm for a double monochromator spectrophotometer has been obtained with sufficient dynamic range to quantitatively account for the resolution and stray light over a wide range of resolutionv and absorbance levels. Conventional stray light tests are found to underestimate seriously that portion of the nearby stray light that most influences errors in ir absorbance determinations, and improved tests are suggested. A revision of the definition of stray light is suggested in order to minimize the variation of stray light with resolution. Convolutions of the observed slit functions with the transmittance function for the 1691-nm band of chloroform agree with observed absorbance measurements over a wide range of resolution and absorbance levels. The ratio of true to observed absorbance levels for chloroform is significantly less influenced by resolution than the literature, using triangular or Gaussian slit functions and Lorentzian absorbance functions, predicts.",
                    "score": 0.8640193343162537
                },
                {
                    "id": 13043907,
                    "contents": "Double slit interferometry to measure the EUV refractive indices of solids using high harmonics.\nAccurate values of the extreme ultraviolet (EUV) optical properties of materials are required to make EUV optics such as filters and multilayer mirrors. The optical properties of aluminum studied in this report are required, in particular, as aluminum is used as an EUV filter material. The complex refractive index of solid aluminum and the imaginary part of the refractive index of solid iron between 17 eV and 39 eV have been measured using EUV harmonics produced from an 800 nm laser focused to 10(14) Wcm(2) in an argon gas jet impinging on a double slit interferometer.",
                    "score": 0.8639121651649475
                },
                {
                    "id": 8574332,
                    "contents": "Detection of subwavelength slit-width variation with measurements in the far field by use of an embedded-aperture interferometer configuration.\nThe dynamic signature of the subwavelength variation of a rectangular aperture has recently been shown to be determinable from far-field irradiance with a precision better than 1 nm [Opt. Lett. 29, 1045 (2004)]. We have proposed, and have theoretically shown, that detection sensitivity can be greatly enhanced with an embedded-aperture Mach-Zehnder interferometer configuration, after parameter optimization. The sensitivity, in terms of derivative intensity of observed subwavelength variations, could be enhanced approximately 2.7 times, compared with the directly detected method. Another method of detection of subwavelength variation from pattern measurement of far-field diffraction has also been proposed. The associated shifting of the dark line of the diffraction pattern had a good linear correlation to subwavelength variation, which was magnified approximately 150 times, and gave good contrast for measurement.",
                    "score": 0.8630807399749756
                },
                {
                    "id": 16672939,
                    "contents": "Diffraction by three-dimensional slit-shape curves: decomposition in terms of Airy and Pearcey functions.\nWe analyze the diffraction field generated by coherent illumination of a three-dimensional transmittance characterized by a slit-shape curve. Generic features are obtained using the Frenet-Serret equations, which allow a decomposition of the optical field. The analysis is performed by describing the influence of the curvature and torsion on osculating, normal, and rectifying planes. We show that the diffracted field has a decomposition in three optical fields propagating along three optical axes that are mutually perpendicular. The decomposition is in terms of the Pearcey and Airy functions, and the generalized Airy function. Experimental results are shown. ",
                    "score": 0.8630136251449585
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_30",
        "question": "$$\r\n\\text { If we locate an electron to within } 20 \\mathrm{pm} \\text {, then what is the uncertainty in its speed? }\r\n$$",
        "golden_answers": [
            " 3.7"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 23547850,
                    "contents": "An electron walks into a quantum bar….\nQuantum electron-light interaction may find use in microscopy applications.",
                    "score": 0.8889039158821106
                },
                {
                    "id": 9667144,
                    "contents": "Erratum.\nIn Arthur L. Robinson's Research News article \"Electron microscope inventors share Nobel physics prize\" (14 Nov., p. 821), the quantum mechanical wavelength of an electron with an energy of 100 kiloelectron volts is incorrectly stated to be about 0.1 angstrom (p. 821, column 2). The correct value is 0.037 angstrom. Also, the electron column of the first electron microscope was vertical, not horizontal.",
                    "score": 0.8786958456039429
                },
                {
                    "id": 17597372,
                    "contents": "Electronegativity-a perspective.\nElectronegativity is a very useful concept but it is not a physical observable; it cannot be determined experimentally. Most practicing chemists view it as the electron-attracting power of an atom in a molecule. Various formulations of electronegativity have been proposed on this basis, and predictions made using different formulations generally agree reasonably well with each other and with chemical experience. A quite different approach, loosely linked to density functional theory, is based on a ground-state free atom or molecule, and equates electronegativity to the negative of an electronic chemical potential. A problem that is encountered with this approach is the differentiation of a noncontinuous function. We show that this approach leads to some results that are not chemically valid. A formulation of atomic electronegativity that does prove to be effective is to express it as the average local ionization energy on an outer contour of the atom's electronic density.",
                    "score": 0.873792290687561
                },
                {
                    "id": 10636251,
                    "contents": "Force microscopy: on the charge.\nThe atomic force microscope has recently been the subject of a series of exciting developments. The latest advance shows that this instrument can measure the charge state of an individual atom.",
                    "score": 0.8729882836341858
                },
                {
                    "id": 9667893,
                    "contents": "One hundred years of quantum physics.\nThis year marks the 100th anniversary of Max Planck's creation of the quantum concept, an idea so revolutionary that it took nearly 30 years for scientists to develop it into the theory that has transformed the way scientists view reality. In this month's essay, Daniel Kleppner and Roman Jackiw recount how quantum theory, which they rate as \"the most precisely tested and most successful theory in the history of science,\" came to be, how it changed the world, and how it might continue to evolve to make the dream of ultimate understanding of the universe come true.",
                    "score": 0.8701432943344116
                },
                {
                    "id": 9174366,
                    "contents": "EDM 1.0: electron direct methods.\nA computer program designed to provide a number of quantitative analysis tools for high-resolution imaging and electron diffraction data is described. The program includes basic image manipulation, both real space and reciprocal space image processing, Wiener-filtering, symmetry averaging, methods for quantification of electron diffraction patterns and two-dimensional direct methods. The program consists of a number of sub-programs written in a combination of C++, C and Fortran. It can be downloaded either as GNU source code or as binaries and has been compiled and verified on a wide range of platforms, both Unix based and PC's. Elements of the design philosophy as well as future possible extensions are described.",
                    "score": 0.8696945905685425
                },
                {
                    "id": 4740333,
                    "contents": "Quantum computing.\nQuantum computing is a quickly growing research field. This article introduces the basic concepts of quantum computing, recent developments in quantum searching, and decoherence in a possible quantum dot realization.",
                    "score": 0.8676629662513733
                },
                {
                    "id": 6805266,
                    "contents": "Man the nanoscopes.\nNew light microscopy techniques are pushing the limits of resolution to 50 nm and below. Fluorescence microscopy that rivals electron microscopy in resolution but operates on intact cells may be within reach.",
                    "score": 0.8673004508018494
                },
                {
                    "id": 8726099,
                    "contents": "Nearsightedness of electronic matter.\nIn an earlier paper, W. Kohn had qualitatively introduced the concept of \"nearsightedness\" of electrons in many-atom systems. It can be viewed as underlying such important ideas as Pauling's \"chemical bond,\" \"transferability,\" and Yang's computational principle of \"divide and conquer.\" It describes the fact that, for fixed chemical potential, local electronic properties, such as the density n(r), depend significantly on the effective external potential only at nearby points. Changes of that potential, no matter how large, beyond a distance R have limited effects on local electronic properties, which rapidly tend to zero as a function of R. In the present paper, the concept is first sharpened for representative models of uncharged fermions moving in external potentials, and then the effects of electron-electron interactions and of perturbing external charges are discussed.",
                    "score": 0.8662911653518677
                },
                {
                    "id": 4457894,
                    "contents": "Electron crystallography and non-linear optics.\nElectron crystallography can be used to obtain specific information about molecular parameters such as the polarisability, dipole moment, and hyperpolarisability. In this, work we show how a combination of quantum mechanics and simulation methods can be used to solve several unknown organic structures and how the calculated molecular parameters can be used to predict the corresponding physical properties of the crystals.",
                    "score": 0.8661393523216248
                },
                {
                    "id": 22601406,
                    "contents": "Spatial and phase resolution in electron microscopy.\nWith the invention of the aberration corrector in electron optics, the spatial resolution in electron microscopy has progressively improved and has now reached the sub-50 picometre regime, and atomic-resolution electron microscopy has become a versatile tool for investigating the atomic structures in materials and devices. Furthermore, the phase resolution in electron microscopy also exhibits outstanding progress, and it has become possible to visualise electromagnetic fields at atomic dimensions, which strongly contributes to understanding the physical and chemical properties of materials. The electron microscopy society has grown with the improvements in spatial and phase resolutions, and hence we must continuously develop new hardware, software and methodologies to boost these resolutions. Here, we review the historical progress of spatial and phase resolutions in electron microscopy, where we clarify the definition of these resolutions. We also discuss the future targets in electron microscopy.",
                    "score": 0.866072952747345
                },
                {
                    "id": 16738741,
                    "contents": "Solving difficult structures with electron diffraction.\nPrecession electron diffraction has solved a long-standing challenge in electron diffraction. Further progress promises a general technique for structure determination of difficult crystals. ",
                    "score": 0.8652589917182922
                },
                {
                    "id": 15643832,
                    "contents": "Single Molecules, Cells, and Super-Resolution Optics (Nobel Lecture).\nThe resolution of a microscope is determined by the diffraction limit in classical microscopy, whereby objects that are separated by half a wavelength can no longer be visually separated. To go below the diffraction limit required several tricks and discoveries. In his Nobel Lecture, E. Betzig describes the developments that have led to modern super high-resolution microscopy. ",
                    "score": 0.8647574186325073
                },
                {
                    "id": 10656539,
                    "contents": "Comment on: Quantum optics with particles of light.\nErrors in the recent article, \"Quantum optics with particles of light,\" are discussed. \"Dispersed states\" resulting from linear optics are simply coherent states, and have no interesting quantum statistics.",
                    "score": 0.8647563457489014
                },
                {
                    "id": 6232742,
                    "contents": "Atomic force microscopy: a forceful way with single molecules.\nThe atomic force microscope (AFM) now routinely provides images that reveal subnanometer surface structures of biomolecules. The sensitivity and precision of AFM provide new opportunities for studying the mechanical properties of biomolecules and their interactions in their native environment.",
                    "score": 0.8645390272140503
                },
                {
                    "id": 9553079,
                    "contents": "The efficiency curve: a new function.\nWorking from first principles, an efficiency curve function has been developed by considering the physics of photon transport through matter. The function has been compared to other function in popular usage and been found to fit the data better especially about the knee of the curve. The main disadvantage of the new function is that it is data hungry, but this can be overcome by use of Monte Carlo simulations.",
                    "score": 0.8643157482147217
                },
                {
                    "id": 7256310,
                    "contents": "Quantum technology: the second quantum revolution.\nWe are currently in the midst of a second quantum revolution. The first quantum revolution gave us new rules that govern physical reality. The second quantum revolution will take these rules and use them to develop new technologies. In this review we discuss the principles upon which quantum technology is based and the tools required to develop it. We discuss a number of examples of research programs that could deliver quantum technologies in coming decades including: quantum information technology, quantum electromechanical systems, coherent quantum electronics, quantum optics and coherent matter technology.",
                    "score": 0.863204300403595
                },
                {
                    "id": 10595100,
                    "contents": "Average local ionization energy: A review.\nThe average local ionization energy I(r) is the energy necessary to remove an electron from the point r in the space of a system. Its lowest values reveal the locations of the least tightly-held electrons, and thus the favored sites for reaction with electrophiles or radicals. In this paper, we review the definition of I(r) and some of its key properties. Apart from its relevance to reactive behavior, I(r) has an important role in several fundamental areas, including atomic shell structure, electronegativity and local polarizability and hardness. All of these aspects of I(r) are discussed.",
                    "score": 0.8625190854072571
                },
                {
                    "id": 21609262,
                    "contents": "Beyond the One-Electron Approximation: Density of States for Interacting Electrons.\nThe concept \"density of states\" can be given many different meanings when we go beyond the one-electron approximation. In this survey we concentrate on the definition tied to excitation processes, where one electron is added or removed from the solid. We discuss the one-particle spectral function for conduction and core electrons in metals, how it can be approximately calculated, and how it can be related to different types of experiments like x-ray photoemission, x-ray emission and absorption, photoemission and optical absorption in the ultraviolet, and the Compton effect. We also discuss the form of the exchange-correlation potential for use in band structure calculations.",
                    "score": 0.8618322014808655
                },
                {
                    "id": 9868378,
                    "contents": "Electrons, photons, and force: quantitative single-molecule measurements from physics to biology.\nSingle-molecule measurement techniques have illuminated unprecedented details of chemical behavior, including observations of the motion of a single molecule on a surface, and even the vibration of a single bond within a molecule. Such measurements are critical to our understanding of entities ranging from single atoms to the most complex protein assemblies. We provide an overview of the strikingly diverse classes of measurements that can be used to quantify single-molecule properties, including those of single macromolecules and single molecular assemblies, and discuss the quantitative insights they provide. Examples are drawn from across the single-molecule literature, ranging from ultrahigh vacuum scanning tunneling microscopy studies of adsorbate diffusion on surfaces to fluorescence studies of protein conformational changes in solution.",
                    "score": 0.8614814877510071
                },
                {
                    "id": 19358685,
                    "contents": "The Hellmann-Feynman theorem: a perspective.\nThe Hellmann-Feynman theorem has, with a few exceptions, not been exploited to the degree that it merits. This is due, at least in part, to a widespread failure to recognize that its greatest value may be conceptual rather than numerical, i.e., in achieving insight into molecular properties and behavior. In this brief overview, we shall discuss three examples of significant concepts that have come out of the Hellmann-Feynman theorem: (1) The forces exerted upon the nuclei in molecules are entirely Coulombic in nature. (2) The total energies of atoms and molecules can be expressed rigorously in terms of just the electrostatic potentials at their nuclei that are produced by the electrons and other nuclei. (3) Dispersion forces are due to the attractions of nuclei to their own polarized electronic densities. To summarize, energy and force analyses should not be viewed as competitive but rather as complementary.",
                    "score": 0.860442578792572
                },
                {
                    "id": 7928752,
                    "contents": "Why phase errors affect the electron function more than amplitude errors.\nIf Fexp(ialpha) are the set of structure factors for a structure f, the amplitudes can be converted to those of an uncorrelated structure g (amplitude swapping) by multiplying each F by the positive number G/F. Correspondingly, the image f is convoluted with k, the Fourier transform of G/F; k has a large peak at the origin, so that f * k approximately f. For swapped phases, the image f is convoluted with l, the Fourier transform of exp(iDeltaalpha), where Deltaalpha, the phase difference between F and G, is a random variable; l does not have a large peak at the origin, so that f * l does not resemble f. The paper provides quantitative descriptions of these arguments.",
                    "score": 0.8599827885627747
                },
                {
                    "id": 23469050,
                    "contents": "NanoMi: An open source electron microscope hardware and software platform.\nWe outline a public license (open source) electron microscopy platform, referred to as NanoMi. NanoMi offers a modular, flexible electron microscope platform that can be utilized for a variety of applications, such as microscopy education and development of proof-of-principle experiments, and can be used to complement an existing experimental apparatus. All components are ultra-high vacuum compatible and the electron optics elements are independent from the vacuum envelope. The individual optical components are mounted on a 127 mm (5-inch) diameter half-pipe, allowing customizing of electron optics for a variety of purposes. The target capabilities include SEM, TEM, scanning TEM (STEM), and electron diffraction (ED) at up to 50 keV incident electron energy. The intended image resolution in SEM, TEM and STEM modes is ≈ 10 nm. We describe the existing components and the interfaces among components that ensure their compatibility and interchangeability. The paper provides a resource for those who consider building or utilizing their own NanoMi.",
                    "score": 0.8587915897369385
                },
                {
                    "id": 16008519,
                    "contents": "Erratum: The NIST Length Scale Interferometer.\n[This corrects the article on p. 225 in vol. 104.].",
                    "score": 0.8587276935577393
                },
                {
                    "id": 10284577,
                    "contents": "Super-accuracy and super-resolution getting around the diffraction limit.\nIn many research areas such as biology, biochemistry, and biophysics, measuring distances or identifying and counting objects can be of great importance. To do this, researchers often need complicated and expensive tools in order to have accurate measurements. In addition, these measurements are often done under nonphysiological settings. X-ray diffraction, for example, gets Angstrom-level structures, but it requires crystallizing a biological specimen. Electron microscopy (EM) has about 10A resolution, but often requires frozen (liquid nitrogen) samples. Optical microscopy, while coming closest to physiologically relevant conditions, has been limited by the minimum distances to be measured, typically about the diffraction limit, or approximately 200 nm. However, most biological molecules are &lt;5-10nm in diameter, and getting molecular details requires imaging at this scale. In this chapter, we will describe some of the experimental approaches, from our lab and others, that push the limits of localization accuracy and optical resolution in fluorescence microscopy.",
                    "score": 0.8585717678070068
                },
                {
                    "id": 9617647,
                    "contents": "Integrated spatial electron populations in molecules: The electron projection function.\nA \"projection function,\" P(x,z), is defined as the partial integral of the molecular electron density, rho(x,y,z), over the region -infinity &lt; y &lt; +infinity. The projection provides a three-dimensional representation of molecular electron distributions. Chemically useful information can be discerned from graphical displays in either perspective plot or contour format. Numerical integration of the function gives the integrated spatial electron population for any region of interest. The use of the projection function and difference functions is exemplified by application to acetaldehyde.",
                    "score": 0.8571792244911194
                },
                {
                    "id": 12717646,
                    "contents": "Direct detection pays off for electron cryo-microscopy.\nImproved electron detectors and image-processing techniques will allow the structures of macromolecules to be determined from tens of thousands of single-particle cryo-EM images, rather than the hundreds of thousands needed previously.",
                    "score": 0.8566306829452515
                },
                {
                    "id": 10139022,
                    "contents": "The uncertainty principle determines the nonlocality of quantum mechanics.\nTwo central concepts of quantum mechanics are Heisenberg's uncertainty principle and a subtle form of nonlocality that Einstein famously called \"spooky action at a distance.\" These two fundamental features have thus far been distinct concepts. We show that they are inextricably and quantitatively linked: Quantum mechanics cannot be more nonlocal with measurements that respect the uncertainty principle. In fact, the link between uncertainty and nonlocality holds for all physical theories. More specifically, the degree of nonlocality of any theory is determined by two factors: the strength of the uncertainty principle and the strength of a property called \"steering,\" which determines which states can be prepared at one location given a measurement at another.",
                    "score": 0.8566228151321411
                },
                {
                    "id": 8248562,
                    "contents": "MMM1D: a method for calculating electrostatic interactions in one-dimensional periodic geometries.\nWe present a new method to accurately calculate the electrostatic energy and forces on charges in a system with periodic boundary conditions in one of three spatial dimensions. We transform the Coulomb sum via a convergence factor into a series of fast decaying functions similar to the Lekner method. Rigorous error bounds for the energies and the forces are derived and numerically verified. The method has a computational complexity of O(N(2)), but is faster and easier to use than previously reported methods.",
                    "score": 0.8565829992294312
                },
                {
                    "id": 9952611,
                    "contents": "HOW ACCURATELY CAN A SINGLE MOLECULE BE LOCALIZED WHEN IMAGED THROUGH AN OPTICAL MICROSCOPE?\nWe present a simple analytical expression for the fundamental limit to the accuracy with which the location of a single molecule can be determined that is imaged through an optical microscope. This expression depends on the optical properties of the microscope and the photophysical properties of the single molecule. We also show how the fundamental limit is deteriorated by factors like pixelation of the detector and noise sources in the detection system. The present results gives an experimenter insight into what is achievable in an optical microscope and provide guidelines for experimental design.",
                    "score": 0.8564895987510681
                },
                {
                    "id": 4769139,
                    "contents": "Maximum entropy methods in electron crystallography.\nThe maximum entropy (ME) method of solving crystal structures in two or three dimensions from electron diffraction data is described. Applications to organic and inorganic molecules, membrane proteins and surface structures are outlined, and the power of the ME formalism to deal with incomplete and error prone data is demonstrated.",
                    "score": 0.8564466238021851
                },
                {
                    "id": 17403455,
                    "contents": "JEOL, NMR and ESR: A 65 year evolution.\nFelix Bloch and Edward Purcell successfully detected NMR signals in 1946, and VARIAN was the first company in the world to complete a commercial product in 1950. JEOL released their first commercial NMR instrument 6 years later. At that time, the magnetic field intensity was 30-40 MHz, so the ability to separate signals was extremely low. The users of NMR wanted higher magnetic fields, and the key issue for NMR manufacturers became how to increase the magnetic field strength. With a permanent magnet, the maximum magnetic field is 90 MHz (2.11 Tesla), and the limit with an electromagnet is 100 MHz (2.4 Tesla). This limitation was removed with the advent of superconducting magnets (SCM). Furthermore, in addition to the Continuous Wave method, which only allowed observation of 1H nuclei, Pulse Fourier Transform (FT) methods were developed, enabling observation and measurement of 13C and other nuclei. The development of SCM and FT was epoch-making for NMR, and the field has flourished since then. Of course, there has been technical innovation that could not be accomplished by the NMR manufacturers alone, such as the development of superconducting materials and winding techniques for SCM, and new algorithm development and the acceleration of computing speeds for FT. This report will relate the story of NMR, including these developments that have provided the background.",
                    "score": 0.8564398884773254
                },
                {
                    "id": 9091754,
                    "contents": "Maximal probability domains in linear molecules.\nRegions of space are defined to maximize the probability to find a given number of electrons within. Their chemical significance and their relationship to the electron localization function (ELF) are explored by analyzing the results for a few linear molecules: LiH, BH, N2, CO, CS, C2H2, and C4H2.",
                    "score": 0.8564256429672241
                },
                {
                    "id": 20530838,
                    "contents": "Decoherence-Induced Universality in Simple Metal Cluster Photoelectron Angular Distributions.\nMeasured angular distributions of photoelectrons from size-selected copper and sodium cluster anions are demonstrated to exhibit a universal behavior independent of the initial electron state, cluster size, or material, which can be traced back to momentum conservation upon photoemission. Quantum simulations reproduce the universality under the assumption that multielectron dynamics localizes the emission on the cluster surface and renders the cluster opaque to photoelectrons, thereby quenching interference effects that would otherwise obscure this almost classical behavior.",
                    "score": 0.8563874959945679
                },
                {
                    "id": 9698579,
                    "contents": "Condensed matter physicists shrink their horizons.\nIn the world of the condensed matter physicist, a micron is a chasm and a millimeter an ocean. At the March American Physical Society meeting in Seattle, some of the 4500 physicists probed the hazards of the micro world, where weird quantum effects can scramble information. Others outlined its opportunities: Molecular engineering that is leading to new information storage materials, and minute structures that could form tethers and containers in some future nanotechnology.",
                    "score": 0.8563132882118225
                },
                {
                    "id": 11786302,
                    "contents": "Is science prepared for atomic-resolution electron microscopy?\nThe efforts of microscopists have given aberration-corrected transmission electron microscopy the power to reveal atomic structures with unprecedented precision. It is now up to materials scientists to use this power for extracting physical properties from microscopic atomic arrangements.",
                    "score": 0.8555668592453003
                },
                {
                    "id": 21084269,
                    "contents": "Quantum optics with swift electrons.\nStimulated and spontaneous interactions of electron wavepackets with optical near fields were explored with complementary techniques. In striking agreement with theory, scientists have demonstrated the dependence of spontaneous and stimulated quantum mechanical processes on the spatial distribution of optical modes.",
                    "score": 0.8554707169532776
                },
                {
                    "id": 4595978,
                    "contents": "Erratum.\nNo abstract",
                    "score": 0.8546929359436035
                },
                {
                    "id": 6028984,
                    "contents": "Breakthrough of the year. The runners-up.\nScience recognizes nine other major discoveries on scales ranging from the cosmic to the quantum: Ribosome Revelations Fossil Find One Word--Organics New Cells for Old Water, Water, Everywhere Cosmic BOOMERANG Good Reception So NEAR ... Quantum Curiosities",
                    "score": 0.8545171022415161
                },
                {
                    "id": 9707664,
                    "contents": "The tunneling microscope: a new look at the atomic world.\nA new instrument called the tunneling microscope has recently been developed that is capable of generating real-space images of surfaces showing atomic structure. These images offer a new view of matter on an atomic scale. The current capabilities and limitations and the physics involved in the technique are discussed along with specific results from a study of silicon crystal surfaces.",
                    "score": 0.8543392419815063
                },
                {
                    "id": 23170915,
                    "contents": "QForte: An Efficient State-Vector Emulator and Quantum Algorithms Library for Molecular Electronic Structure.\nWe introduce a novel open-source software package QForte, a comprehensive development tool for new quantum simulation algorithms. QForte incorporates functionality for handling molecular Hamiltonians, Fermionic encoding, ansatz construction, time evolution, and state-vector emulation, requiring only a classical electronic structure package as a dependency. QForte also contains black-box implementations of a wide variety of quantum algorithms, including variational and projective quantum eigensolvers, adaptive eigensolvers, quantum imaginary time evolution, and quantum Krylov methods. We highlight two features of QForte: (i) how the Python class structure of QForte enables the facile implementation of new algorithms, and (ii) how existing algorithms can be executed in just a few lines of code.",
                    "score": 0.8542807698249817
                },
                {
                    "id": 6668053,
                    "contents": "High resolution spectroscopy in the gas phase: even large molecules have well-defined shapes.\nA review of recent high-resolution microwave, infrared, and optical spectroscopy experiments demonstrates that remarkable progress has been made in the past 20 years in determining the equilibrium geometries of large polyatomic molecules and their clusters in the gas phase, and how these geometries change when the photon is absorbed. A special focus is on the dynamical information that can be obtained from such studies, particularly of electronically excited states.",
                    "score": 0.8542692065238953
                },
                {
                    "id": 11231225,
                    "contents": "Studying atomic structures by aberration-corrected transmission electron microscopy.\nSeventy-five years after its invention, transmission electron microscopy has taken a great step forward with the introduction of aberration-corrected electron optics. An entirely new generation of instruments enables studies in condensed-matter physics and materials science to be performed at atomic-scale resolution. These new possibilities are meeting the growing demand of nanosciences and nanotechnology for the atomic-scale characterization of materials, nanosynthesized products and devices, and the validation of expected functions. Equipped with electron-energy filters and electron-energy-loss spectrometers, the new instruments allow studies not only of structure but also of elemental composition and chemical bonding. The energy resolution is about 100 milli-electron volts, and the accuracy of spatial measurements has reached a few picometers. However, understanding the results is generally not straightforward and only possible with extensive quantum-mechanical computer calculations.",
                    "score": 0.8542640805244446
                },
                {
                    "id": 6768208,
                    "contents": "The scanning tunnelling microscope as an operative tool: doing physics and chemistry with single atoms and molecules.\nThe scanning tunnelling microscope, initially invented to image surfaces down to the atomic scale, has been further developed in the last few years to an operative tool, with which atoms and molecules can be manipulated at will at low substrate temperatures in different manners to create and investigate artificial structures, whose properties can be investigated employing spectroscopic dI/dV measurements. The tunnelling current can be used to selectively break chemical bonds, but also to induce chemical association. These possibilities give rise to startling new opportunities for physical and chemical experiments on the single atom and single molecule level. Here we provide a short overview on recent results obtained with these techniques.",
                    "score": 0.8539894223213196
                },
                {
                    "id": 6729924,
                    "contents": "Electron interference: mystery and reality.\nInterference of electron waves has developed from a fascinating phenomenon in basic physics to a key method for the highly sophisticated investigation of both electric and magnetic structures in solid-state materials. After more than 20 years of development, electron holography in the transmission electron microscope is now a very powerful technique for the analysis of micro-fields down to atomic dimensions. The applications extend from highly sensitive measurements in semiconductor technology to the quantitative characterization of atomic structures.",
                    "score": 0.8538935780525208
                },
                {
                    "id": 19085586,
                    "contents": "Retraction: Transferring electrons to water.\nThis corrects the article DOI: 10.1038/nchem.768.",
                    "score": 0.8536552786827087
                },
                {
                    "id": 6766206,
                    "contents": "Average electron radii in many-electron atoms.\nIn many-electron atoms, the average electron radius r represents the mean distance of a single electron from the nucleus when all the interelectronic interactions are averaged. If the electron-electron interaction is explicitly considered, the average radius r splits into two different radii, inner radius r(&lt;) and outer radius r(&gt;). For the 102 atoms He through Lr in their ground states, the radii r(&lt;) and r(&gt;) are systematically examined at the Hartree-Fock limit level. The effect of electron correlations on r(&lt;) and r(&gt;) is also discussed for the He atom and its isoelectronic ions.",
                    "score": 0.8535099029541016
                },
                {
                    "id": 9691374,
                    "contents": "Fast algorithms for classical physics.\nSome of the recently developed fast summation methods that have arisen in scientific computing are described. These methods require an amount of work proportional to N or N log N to evaluate all pairwise interactions in an ensemble of N particles. Traditional methods, by contrast, require an amount of work proportional to N(2). As a result, largescale simulations can be carried out using only modest computer resources. In combination with supercomputers, it is possible to address questions that were previously out of reach. Problems from diffusion, gravitation, and wave propagation are considered.",
                    "score": 0.8534685969352722
                },
                {
                    "id": 10003712,
                    "contents": "Books: One molecule at a time.\nA review of Single-Molecule Optical Detection, Imaging, and Spectroscopy.",
                    "score": 0.8534037470817566
                },
                {
                    "id": 13150298,
                    "contents": "Digital electron diffraction--seeing the whole picture.\nThe advantages of convergent-beam electron diffraction for symmetry determination at the scale of a few nm are well known. In practice, the approach is often limited due to the restriction on the angular range of the electron beam imposed by the small Bragg angle for high-energy electron diffraction, i.e. a large convergence angle of the incident beam results in overlapping information in the diffraction pattern. Techniques have been generally available since the 1980s which overcome this restriction for individual diffracted beams, by making a compromise between illuminated area and beam convergence. Here a simple technique is described which overcomes all of these problems using computer control, giving electron diffraction data over a large angular range for many diffracted beams from the volume given by a focused electron beam (typically a few nm or less). The increase in the amount of information significantly improves the ease of interpretation and widens the applicability of the technique, particularly for thin materials or those with larger lattice parameters.",
                    "score": 0.8533881902694702
                }
            ],
            "metric_score": {
                "retrieval_recall": 1,
                "retrieval_precision": 0.2
            }
        }
    },
    {
        "id": "test_31",
        "question": "The mean temperature of the earth's surface is $288 \\mathrm{~K}$. What is the maximum wavelength of the earth's blackbody radiation?",
        "golden_answers": [
            " 1.01"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 8450806,
                    "contents": "[From sun to earth].\nSun emits a vast array of electromagnetic radiations. After a long but fast journey, the spectrum of visible and ultraviolet light, and infrared radiations reaches the furthermost boundaries of the Earth. Only a fraction of them reaches the biosphere. Photogeoclimatology primarily depends on this energy and is modulated by the latitude, soil relief, seasons and nycthemeral cycle.",
                    "score": 0.8741509318351746
                },
                {
                    "id": 9110663,
                    "contents": "We reside in the sun's atmosphere.\nThe Sun is the origin of all activities of the Earth, including its solid, liquid and gas states, as well as life on the Earth surface. Life was created on this planet and was further evolved after long physical/chemical processes, so that life here matches with what this planet requires. This paper contends that the Earth is located within the solar atmosphere, but we do not feel it in a daily life because of the blocking effects of the Earth's magnetic field and atmosphere, preventing the entry of the solar atmosphere directly into the Earth's domain. This paper emphasizes that we should not attempt to change the quality of the natural environment that delicate interactions between the Sun and the Earth have established for us by taking a long time.",
                    "score": 0.8630726933479309
                },
                {
                    "id": 9699869,
                    "contents": "Why is the temperature of the universe 2.726 Kelvin?\nThe Cosmic Background Explorer satellite has recently made the most accurate measurement of the temperature of the universe, determining it to be 2.726 +/- 0.01 kelvin. In trying to understand why the temperature has this value, one is led to discover the most fundamental features of the universe-an early, radiation-dominated epoch, enormous entropy per nucleon, synthesis of the light elements around 3 minutes after the bang, and a small excess of matter over antimatter-as well as some of the most pressing issues in cosmology today-the development of structure in the universe and the identification of the nature of the ubiquitous dark matter.",
                    "score": 0.856812596321106
                },
                {
                    "id": 14587342,
                    "contents": "Erratum to: On the average temperature of airless spherical bodies and the magnitude of Earth's atmospheric thermal effect.\n[This corrects the article DOI: 10.1186/2193-1801-3-723.].",
                    "score": 0.8545669913291931
                },
                {
                    "id": 6731017,
                    "contents": "Water water everywhere.\nDuring the last decade of the 20th century the world was exposed to increasing episodes of extreme weather. Figures reveal a 0.6 degrees C rise in average temperatures since records began in 1860, with the 1990s being the warmest decade and 1998 the warmest year. Experts believe that these rising temperatures, or global warming, are in part due to human influences.",
                    "score": 0.8522320985794067
                },
                {
                    "id": 7855350,
                    "contents": "Do satellites detect trends in surface solar radiation?\nLong-term variations in solar radiation at Earth's surface (S) can affect our climate, the hydrological cycle, plant photosynthesis, and solar power. Sustained decreases in S have been widely reported from about the year 1960 to 1990. Here we present an estimate of global temporal variations in S by using the longest available satellite record. We observed an overall increase in S from 1983 to 2001 at a rate of 0.16 watts per square meter (0.10%) per year; this change is a combination of a decrease until about 1990, followed by a sustained increase. The global-scale findings are consistent with recent independent satellite observations but differ in sign and magnitude from previously reported ground observations. Unlike ground stations, satellites can uniformly sample the entire globe.",
                    "score": 0.8514341711997986
                },
                {
                    "id": 11869790,
                    "contents": "The myth of the boiling point.\nAround 1800, many reputable scientists reported significant variations in the temperature of pure water boiling under normal atmospheric pressure. The reported variations included a difference of over 1 degree C between boiling in metallic and glass vessels (Gay-Lussac), and \"superheating\" up to 112 degrees C on extracting dissolved air out of water (De Luc). I have confirmed most of these observations in my own experiments, many of which are described in this paper. Water boils at the \"boiling point\" only under very particular circumstances. Our common-sense intuition about the fixedness of the boiling point is only sustained by our limited experience.",
                    "score": 0.8483693599700928
                },
                {
                    "id": 14860508,
                    "contents": "Progress towards the determination of thermodynamic temperature with ultra-low uncertainty.\nPrevious research effort towards the determination of the Boltzmann constant has significantly improved the supporting theory and the experimental practice of several primary thermometry methods based on the measurement of a thermodynamic property of a macroscopic system at the temperature of the triple point of water. Presently, experiments are under way to demonstrate their accuracy in the determination of the thermodynamic temperature T over an extended range spanning the interval between a few kelvin and the copper freezing point (1358 K). We discuss how these activities will improve the link between thermodynamic temperature and the temperature as measured using the International Temperature Scale of 1990 (ITS-90) and report some preliminary results obtained by dielectric constant gas thermometry and acoustic gas thermometry. We also provide information on the status of other primary methods, such as Doppler broadening thermometry, Johnson noise thermometry and refractive index gas thermometry. Finally, we briefly consider the implications of these advancements for the dissemination of calibrated temperature standards. ",
                    "score": 0.8481754064559937
                },
                {
                    "id": 9667530,
                    "contents": "The Earth and planetary sciences.\nDuring the last two decades the earth sciences community has become persuaded that the earth is a dynamic body; an engine driven by its internal heat. The major surface manifestation of this dynamism has been fragmentation of the earth's outer shell and subsequent relative horizontal movement of the pieces on a large scale. The driving force is convection within the earth, but much remains to be learned about the nature of the convection and the composition of the earth's interior. The other terrestrial planets show evidence of once having been hot, but their surfaces suggest long-term stability and lack evidence of continuing convection.",
                    "score": 0.8470308780670166
                },
                {
                    "id": 9667893,
                    "contents": "One hundred years of quantum physics.\nThis year marks the 100th anniversary of Max Planck's creation of the quantum concept, an idea so revolutionary that it took nearly 30 years for scientists to develop it into the theory that has transformed the way scientists view reality. In this month's essay, Daniel Kleppner and Roman Jackiw recount how quantum theory, which they rate as \"the most precisely tested and most successful theory in the history of science,\" came to be, how it changed the world, and how it might continue to evolve to make the dream of ultimate understanding of the universe come true.",
                    "score": 0.8464853167533875
                },
                {
                    "id": 20661307,
                    "contents": "What Is Temperature? Modern Outlook on the Concept of Temperature.\nThe meaning and evolution of the notion of \"temperature\" (which is a key concept for the condensed and gaseous matter theories) are addressed from different points of view. The concept of temperature has turned out to be much more fundamental than conventionally thought. In particular, the temperature may be introduced for systems built of a \"small\" number of particles and particles at rest. The Kelvin temperature scale may be introduced into quantum and relativistic physics due to the fact that the efficiency of the quantum and relativistic Carnot cycles coincides with that of the classical one. The relation of temperature with the metrics of the configurational space describing the behavior of systems built from non-interacting particles is demonstrated. The role of temperature in constituting inertia and gravity forces treated as entropy forces is addressed. The Landauer principle asserts that the temperature of a system is the only physical value defining the energy cost of the isothermal erasure of a single bit of information. The fundamental role of the temperature of the cosmic microwave background in modern cosmology is discussed. The range of problems and controversies related to the negative absolute temperature is treated.",
                    "score": 0.8463473320007324
                },
                {
                    "id": 21799091,
                    "contents": "The \"1958 He<sup>4</sup> Scale of Temperatures\": Part 1. Introduction.\nThe generally used practical scale of temperatures between 1° and 5.2° K is the He<sup4</sup vapor pressure scale based on an accepted vapor pressure equation or table. In Sèvres (near Paris), October 1958, the International Committee on Weights and Measures recommended for international use the \"1958 He<sup4</sup Scale\" based on a vapor pressure table arrived at through international cooperation and agreement. This table resulted from a consideration of all reliable He<sup4</sup vapor pressure data obtained using gas thermometers, and paramagnetic susceptibility and carbon resistor thermometers. The theoretical vapor pressure equation from statistical thermodynamics was used with thermodynamic data on liquid He<sup4</sup and the vapor equation of state to insure satisfactory agreement of the vapor pressure table with reliable thermodynamic data.",
                    "score": 0.8454848527908325
                },
                {
                    "id": 20941272,
                    "contents": "Fahrenheit 101.\nIs there any convincing explanation for why mammals and birds maintain their body temperature close to 40°C?",
                    "score": 0.8453266620635986
                },
                {
                    "id": 9572478,
                    "contents": "The \"little ice age\": northern hemisphere average observations and model calculations.\nNumerical energy balance climate model calculations of the average surface temperature of the Northern Hemisphere for the past 400 years are compared with a new reconstruction of the past climate. Forcing with volcanic dust produces the best simulation, whereas expressing the solar constant as a function of the envelope of the sunspot number gives very poor results.",
                    "score": 0.8451981544494629
                },
                {
                    "id": 15199584,
                    "contents": "The Most Important Discovery of Science.\nOxygen has often been called the most important discovery of science. I disagree. Over five centuries, reports by six scientists told of something in air we animals all need. Three reported how to generate it. It acquired many names, finally oxygen. After 8 years of studying it, Lavoisier still couldn't understand its nature. No special date and no scientist should get credit for discovering oxygen. Henry Cavendish discovered how to make inflammable air (H2). When burned, it made water. This was called impossible because water was assumed to be an element. When Lavoisier repeated the Cavendish test on June 24, 1783, he realized it demolished two theories, phlogiston and water as an element, a Kuhnian paradigm shift that finally unlocked his great revolution of chemistry. ",
                    "score": 0.8447557091712952
                },
                {
                    "id": 23165145,
                    "contents": "Tomáš Slanina.\nMy favorite example of science in everyday life is photochemistry, nature's most efficient way to store solar energy … My favorite way to spend a holiday is hiking in polar regions far from everyone …\" Find out more about Tomáš Slanina in his Introducing … Profile.",
                    "score": 0.8446359038352966
                },
                {
                    "id": 9430314,
                    "contents": "Thermal energy and the origin of life.\nLife has evolved on Earth with electromagnetic radiation (light), fermentable organic molecules, and oxidizable chemicals as sources of energy. Biological use of thermal energy has not been observed although heat, and the thermal gradients required to convert it into free energy, are ubiquitous and were even more abundant at the time of the origin of life on Earth. Nevertheless, Earth-organisms sense thermal energy, and in suitable environments may have gained the capability to use it as energy source. It has been proposed that the first organisms obtained their energy by a first protein named pF(1) that worked on a thermal variation of the binding change mechanism of today's ATP sythase enzyme. Organisms using thermosynthesis may still live where light or chemical energy sources are not available. Possible suitable examples are subsurface environments on Earth and in the outer Solar System, in particular the subsurface oceans of the icy satellites of Jupiter and Saturn.",
                    "score": 0.844501793384552
                },
                {
                    "id": 9572922,
                    "contents": "Satellite Observations of the Earth's Radiation Budget.\nMeteorological satellites have provided the first complete data on energy exchange between earth and space. The planetary albedo is 29 percent for the mean annual case, and the entire earth-atmosphere system is in near radiative equilibrium. More energy is absorbed in tropical regions than previously believed, and major energy source and sink regions exist within latitude belts.",
                    "score": 0.8433066606521606
                },
                {
                    "id": 14853760,
                    "contents": "Standing on the shoulders of giants.\nIn this editorial, the author explains that the journal Temperature stands on the shoulders of giants-prominent scientists of the past and current members of the Temperature community. Temperature also uses the best tools, such as Google Scholar profiles. The editorial includes a new puzzle: why does warm water freeze faster than cold water? ",
                    "score": 0.8425251245498657
                },
                {
                    "id": 15907188,
                    "contents": "The invention of atmosphere.\nThe word \"atmosphere\" was a neologism Willebrord Snellius created for his Latin translation of Simon Stevin's cosmographical writings. Astronomers and mathematical practitioners, such as Snellius and Christoph Scheiner, applying the techniques of Ibn Mu'ādh and Witelo, were the first to use the term in their calculations of the height of vapors that cause twilight. Their understandings of the atmosphere diverged from Aristotelian divisions of the aerial region. From the early years of the seventeenth century, the term was often associated with atomism or corpuscular matter theory. The concept of the atmosphere changed dramatically with the advent of pneumatic experiments in the middle of the seventeenth century. Pierre Gassendi, Walter Charleton, and Robert Boyle transformed the atmosphere of the mathematicians giving it the characteristics of weight, specific gravity, and fluidity, while disputes about its extent and border remained unresolved. ",
                    "score": 0.8424848318099976
                },
                {
                    "id": 9550582,
                    "contents": "Microwave emission spectrum of the moon: mean global heat flow and average depth of the regolith.\nEarth-based observations of the lunar microwave brightness temperature spectrum at wavelengths between 5 and 500 centimeters, when reexamined in the light of physical property data derived from the Apollo program, tentatively support the high heat flows measured in situ and indicate that a regolith thickness between 10 and 30 meters may characterize a large portion of the lunar near side.",
                    "score": 0.8421374559402466
                },
                {
                    "id": 17011136,
                    "contents": "Infrared Solar Physics.\nThe infrared solar spectrum contains a wealth of physical data about our Sun, and is explored using modern detectors and technology with new ground-based solar telescopes. The scientific motivation behind exploring these wavelengths is presented, along with a brief look at the rich history of observations here. Several avenues of solar physics research exploiting and benefiting from observations at infrared wavelengths from roughly 1000 nm to 12 400 nm are discussed, and the instrument and detector technology driving this research is briefly summarized. Finally, goals for future work at infrared wavelengths are presented in conjunction with ground and space-based observations.",
                    "score": 0.842071533203125
                },
                {
                    "id": 12810006,
                    "contents": "Astronomical reach of fundamental physics.\nUsing basic physical arguments, we derive by dimensional and physical analysis the characteristic masses and sizes of important objects in the universe in terms of just a few fundamental constants. This exercise illustrates the unifying power of physics and the profound connections between the small and the large in the cosmos we inhabit. We focus on the minimum and maximum masses of normal stars, the corresponding quantities for neutron stars, the maximum mass of a rocky planet, the maximum mass of a white dwarf, and the mass of a typical galaxy. To zeroth order, we show that all these masses can be expressed in terms of either the Planck mass or the Chandrasekar mass, in combination with various dimensionless quantities. With these examples, we expose the deep interrelationships imposed by nature between disparate realms of the universe and the amazing consequences of the unifying character of physical law. ",
                    "score": 0.8419351577758789
                },
                {
                    "id": 17385799,
                    "contents": "The surface temperature of Europa.\nPrevious estimates of the annual mean surface temperature of Jupiter's moon, Europa, neglected the effect of the eccentricity of Jupiter's orbit around the Sun, the effect of the emissivity and heat capacity of Europa's ice, the effect of the eclipse of Europa (i.e., the relative time that Europa is within the shadow of Jupiter), the effect of Jupiter's radiation, and the effect of Europa's internal heating. Other studies concentrated on the diurnal cycle but neglected some of the above factors. In addition, to our knowledge, the seasonal cycle of the surface temperature of Europa was not estimated. Here we systematically estimate the diurnal, seasonal and annual mean surface temperature of Europa, when Europa's obliquity, emissivity, heat capacity, and eclipse, as well as Jupiter's radiation, internal heating, and eccentricity, are all taken into account. For a typical internal heating rate of <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mn0.05</mml:mn <mml:mspace/ <mml:mtextW</mml:mtext <mml:mspace/ <mml:msup<mml:mrow<mml:mtextm</mml:mtext</mml:mrow <mml:mrow<mml:mo-</mml:mo <mml:mn2</mml:mn</mml:mrow </mml:msup </mml:math , the equator, pole, and the global and mean annual mean surface temperatures are 96 K, 46 K, and 90 K, respectively. We found that the temperature at the high latitudes is significantly affected by the internal heating, especially during the winter solstice, suggesting that measurements of high latitude surface temperatures can be used to constrain the internal heating. We also estimate the incoming solar radiation to Enceladus, the moon of Saturn.",
                    "score": 0.841842770576477
                },
                {
                    "id": 9405646,
                    "contents": "Climate: how unusual is today's solar activity?\nTo put global warming into context requires knowledge about past changes in solar activity and the role of the Sun in climate change. Solanki et al. propose that solar activity during recent decades was exceptionally high compared with that over the preceding 8,000 years. However, our extended analysis of the radiocarbon record reveals several periods during past centuries in which the strength of the magnetic field in the solar wind was similar to, or even higher than, that of today.",
                    "score": 0.8412614464759827
                },
                {
                    "id": 19521754,
                    "contents": "'Space is blue and birds fly through it'.\nQuantum mechanics is not about 'quantum states': it is about values of physical variables. I give a short fresh presentation and update on the <irelational</i perspective on the theory, and a comment on its philosophical implications.This article is part of a discussion meeting issue 'Foundations of quantum mechanics and their impact on contemporary society'.",
                    "score": 0.8408812880516052
                },
                {
                    "id": 7445571,
                    "contents": "Celsius versus centigrade: the nomenclature of the temperature scale of science.\nThe temperature scale used by scientists in America has been called centigrade, while in many countries it was called Celsius for its inventor. In 1948 the 9th General Conference on Weights and Measures, representing 33 nations that subscribed to the Treaty of the Meter, adopted the name Celsius. This name, however, did not come into general use by scientists in America, partly because they were unaware of the official action of the conference and partly because some preferred the old name. At the 11th General Conference in 1960 the scale was defined in a way that makes the adjective centigrade inexact. The name Celsius is correct and its use by American scientists would help make the nomenclature of temperature uniform in all countries.",
                    "score": 0.8402199745178223
                },
                {
                    "id": 22934854,
                    "contents": "Calibrating a thermometer for Earth's interior over time.\nNew high-pressure, high-temperature experiments refine our ability to trace the thermal evolution of the Earth's interior using the geological record of intermittent, large-volume volcanic episodes.",
                    "score": 0.8402161598205566
                },
                {
                    "id": 6484601,
                    "contents": "A half-century with solar neutrinos (Nobel Lecture).\nThe Sun derives its energy from fusion reactions in which hydrogen is transformed into helium. Every time four protons are turned into a helium nucleus, two neutrinos are produced. These neutrinos take only two seconds to reach the surface of the Sun and another eight minutes or so to reach the Earth. Thus, neutrinos tell us what happened in the center of the Sun eight minutes ago. The Sun produces one-third as many neutrinos as predicted by the standard solar model of particle physics. The author's pioneering work proved that nothing was wrong with the experiments or the theory; something was \"wrong\" with the neutrinos, in the sense that they behave in ways beyond the standard model.",
                    "score": 0.8401505351066589
                },
                {
                    "id": 20266326,
                    "contents": "The 1962 He<sup>3</sup> Scale of Temperatures III. Evaluation and Status.\nIn this third paper the 1962 He<sup3</sup Scale of Temperatures is evaluated both as to its precision and its deviations from the thermodynamic Kelvin Scale. Various thermodynamic quantities of He<sup3</sup consistent with the 1962 He<sup3</sup Scale are derived and listed. The correction to an observed vapor pressure for small amounts of He<sup4</sup is discussed and tabulated. A description is given of the method of multiple variable least squares analysis used for deriving the final scale equation and for re-analysis of isotherm data. Finally the present status of the 1962 He<sup3</sup Scale is discussed along with some considerations for the future.",
                    "score": 0.8390382528305054
                },
                {
                    "id": 18984802,
                    "contents": "Thermodynamics of finite systems: a key issues review.\nA little over ten years ago, Campisi, and Dunkel and Hilbert, published papers claiming that the Gibbs (volume) entropy of a classical system was correct, and that the Boltzmann (surface) entropy was not. They claimed further that the quantum version of the Gibbs entropy was also correct, and that the phenomenon of negative temperatures was thermodynamically inconsistent. Their work began a vigorous debate of exactly how the entropy, both classical and quantum, should be defined. The debate has called into question the basis of thermodynamics, along with fundamental ideas such as whether heat always flows from hot to cold. The purpose of this paper is to sum up the present status-admittedly from my point of view. I will show that standard thermodynamics, with some minor generalizations, is correct, and the alternative thermodynamics suggested by Hilbert, Hänggi, and Dunkel is not. Heat does not flow from cold to hot. Negative temperatures are thermodynamically consistent. The small 'errors' in the Boltzmann entropy that started the whole debate are shown to be a consequence of the micro-canonical assumption of an energy distribution of zero width. Improved expressions for the entropy are found when this assumption is abandoned.",
                    "score": 0.8385774493217468
                },
                {
                    "id": 22477738,
                    "contents": "Whom is real science for?<b>The Biggest Ideas in the Universe</b> <i>Sean Carroll</i> Dutton, 2022. 304 pp.\nSkip the metaphors-physics needn't be diluted for nonexperts to achieve real understanding.",
                    "score": 0.8377647399902344
                },
                {
                    "id": 4720599,
                    "contents": "The evolution of the universe.\nSome 15 billion years ago the universe emerged from a hot, dense sea of matter and energy. As the cosmos expanded and cooled, it spawned galaxies, stars, planets and life.",
                    "score": 0.8376258015632629
                },
                {
                    "id": 9667726,
                    "contents": "Astronomy and solar physics: measurement of the solar spectral irradiance from 200 to 3000 nanometers.\nThe solar spectrum experiment on Spacelab 1 measured 98 percent of the sun's total energy output. It improved the absolute accuracy of solar irradiance data, especially in the ultraviolet and infrared regions. In order to detect any variation in the spectrum on future shuttle flights, the data were obtained in a radiation scale that can be preserved with high precision over many years. The instrument performance and preliminary data reduction are described.",
                    "score": 0.837076723575592
                },
                {
                    "id": 643575,
                    "contents": "[Solar radiation--physicochemical aspects].\nThe solar radiation spectrum and the properties of its components are studied in the present paper. The history of the sun rays before reaching earth surface is analysed. A simplified analysis of the interaction mechanisms of these components with molecules, the energy absorption capabilities of the latter and the expected biological consequences are considered. Special emphasis are given to the properties of ultra-violet and infra-red radiations and their production considered.",
                    "score": 0.8368514776229858
                },
                {
                    "id": 13305675,
                    "contents": "Sensing temperature.\nTemperature is an omnipresent physical variable reflecting the rotational, vibrational and translational motion of matter, what Richard Feynman called the \"jiggling\" of atoms. Temperature varies across space and time, and this variation has dramatic effects on the physiology of living cells. It changes the rate and nature of chemical reactions, and it alters the configuration of the atoms that make up nucleic acids, proteins, lipids and other biomolecules, significantly affecting their activity. While life may have started in a \"warm little pond\", as Charles Darwin mused, the organisms that surround us today have only made it this far by devising sophisticated systems for sensing and responding to variations in temperature, and by using these systems in ways that allow them to persist and thrive in the face of thermal fluctuation.",
                    "score": 0.8361244201660156
                },
                {
                    "id": 9659816,
                    "contents": "Solar constant: first direct measurements.\nThe solar constant was directly measured from an altitude of about 82 kilometers-apparently the first such determination. The total solar intensity was 136.1 milliwatts per square centimeter, or 1.952 calories per square centimeter, per minute-about 2.5 percent less than Johnson's derived value. Energy in the ultraviolet and visible regions (for lambda less than 607 nanometers) was 7.0 percent less than that obtained by integration over Johnson'Scurve; for integral flux of lambda greater than 607 nanometers there was almost perfect agreement. Seven supporting series of measurements from lower altitudes agreed extremely well with these results after correction for atmospheric extinction.",
                    "score": 0.8360193967819214
                },
                {
                    "id": 2441633,
                    "contents": "Thermodynamics and the primary processes of photosynthesis.\nNumerous discussions of the relationship of the thermodynamics of radiation to photosynthesis have been published, but the results are often in disagreement or at best difficult to compare with one another. The recent treatment of maximal photosynthetic efficiencies by Ross and Calvin is here shown to be directly related to the thermodynamic method of Duysens. A smooth connection between the light and dark conditions is derived, the case of polarized light is considered briefly, and a critique of some other thermodynamic treatments is presented.",
                    "score": 0.8358566761016846
                },
                {
                    "id": 5045836,
                    "contents": "The Water Vapor Spectrum in the Region 8600-15 000 cm(-1): Experimental and Theoretical Studies for a New Spectral Line Database.\nNew laboratory measurements are presented for the near-infrared and visible spectrum (8600-15 000 cm(-1)) of water vapor. Spectral line parameters, principally intensities and air-broadening coefficients, are derived from Fourier transform spectroscopic measurements at high resolution (0.03 cm(-1)), a range of optical path lengths (5-513 m), and temperatures of both 252 and 296 K. Experimental line parameters are derived for 5034 assigned transitions and thorough error analysis shows parameter errors of less than 2.5% for one-third and less than 5% for over half of the lines. Calculated spectra, derived using these line parameters, reproduce the original spectra to within 2%. A comparison of the line intensities with those in the HITRAN-96 database identifies large errors in the latter with random differences that exceed a factor of two for many lines, and systematic differences between 6 and 26% depending on the water band under consideration. The recent corrections to the HITRAN database by Giver et al. (J. Quant. Spectrosc. Radiat. Transfer 66, 101-105 (2000)) do not remove these discrepancies and the differences change to 6-38%. The new data are expected to substantially increase the calculated absorption of solar energy due to water vapor in climate models. Copyright 2001 Academic Press. ",
                    "score": 0.8351944088935852
                },
                {
                    "id": 5194738,
                    "contents": "The Big Bang as scientific fact.\nIn the year 1900, humanity had barely a notion of our place on the cosmic stage, and no inkling at all of how we got here. The one hundred short years of the twentieth century sufficed to unravel 14 billion years of cosmic history and how those grand events, after 9 billions of years or so, set the stage for the birth of our own home, the Solar System. The key events in this history are not hard to comprehend; they can be sketched in a few brief pages. This precious knowledge is part of our shared heritage as human beings and is fundamental to the future prospects of our species. Without it, we are ignorant of the powerful forces that have shaped our past and that will shape our destiny in the future. Read here the cosmic history of humanity, beginning with the Big Bang.",
                    "score": 0.8350765705108643
                },
                {
                    "id": 10963109,
                    "contents": "A basic introduction to the thermodynamics of the Earth system far from equilibrium and maximum entropy production.\nThe Earth system is remarkably different from its planetary neighbours in that it shows pronounced, strong global cycling of matter. These global cycles result in the maintenance of a unique thermodynamic state of the Earth's atmosphere which is far from thermodynamic equilibrium (TE). Here, I provide a simple introduction of the thermodynamic basis to understand why Earth system processes operate so far away from TE. I use a simple toy model to illustrate the application of non-equilibrium thermodynamics and to classify applications of the proposed principle of maximum entropy production (MEP) to such processes into three different cases of contrasting flexibility in the boundary conditions. I then provide a brief overview of the different processes within the Earth system that produce entropy, review actual examples of MEP in environmental and ecological systems, and discuss the role of interactions among dissipative processes in making boundary conditions more flexible. I close with a brief summary and conclusion.",
                    "score": 0.8347715735435486
                },
                {
                    "id": 7185442,
                    "contents": "European seasonal and annual temperature variability, trends, and extremes since 1500.\nMultiproxy reconstructions of monthly and seasonal surface temperature fields for Europe back to 1500 show that the late 20th- and early 21st-century European climate is very likely (&gt;95% confidence level) warmer than that of any time during the past 500 years. This agrees with findings for the entire Northern Hemisphere. European winter average temperatures during the period 1500 to 1900 were reduced by approximately 0.5 degrees C (0.25 degrees C for annual mean temperatures) compared to the 20th century. Summer temperatures did not experience systematic century-scale cooling relative to present conditions. The coldest European winter was 1708/1709; 2003 was by far the hottest summer.",
                    "score": 0.8346682190895081
                },
                {
                    "id": 1811003,
                    "contents": "Water vapor pressure calculation.\nAccurate calculation of water vapor pressure for systems saturated with water vapor can be performed using the Goff-Gratch equation. A form of the equation that can be adapted for computer programming and for use in electronic databases is provided.",
                    "score": 0.8346675634384155
                },
                {
                    "id": 14492787,
                    "contents": "Comment on \"Strong signature of the active Sun in 100 years of terrestrial insolation data\" by W. Weber.\nAn analysis of ground-based observations of solar irradiance was recently published in this journal, reporting an apparent increase of solar irradiance on the ground of the order of 1% between solar minima and maxima [1]. Since the corresponding variations in total solar irradiance on top of the atmosphere are accurately determined from satellite observations to be of the order of 0.1% only [2], the one order of magnitude stronger effect in the terrestrial insolation data was interpreted as evidence for cosmic-ray induced aerosol formation in the atmosphere. In my opinion, however, this result does not reflect reality. Using the energy budget of Earth's surface, I show that changes of ground-based insolation with the solar cycle of the order of 1% between solar minima and maxima would result in large surface air temperature variations which are inconsistent with the instrumental record. It would appear that the strong variations of terrestrial irradiance found by [1] are due to the uncorrected effects of volcanic or local aerosols and seasonal variations. Taking these effects into account, I find a variation of terrestrial insolation with solar activity which is of the same order as the one measured from space, bringing the surface energy budget into agreement with the solar signal detected in temperature data.",
                    "score": 0.8345115780830383
                },
                {
                    "id": 10353999,
                    "contents": "Non-equilibrium thermodynamics, maximum entropy production and Earth-system evolution.\nThe present-day atmosphere is in a unique state far from thermodynamic equilibrium. This uniqueness is for instance reflected in the high concentration of molecular oxygen and the low relative humidity in the atmosphere. Given that the concentration of atmospheric oxygen has likely increased throughout Earth-system history, we can ask whether this trend can be generalized to a trend of Earth-system evolution that is directed away from thermodynamic equilibrium, why we would expect such a trend to take place and what it would imply for Earth-system evolution as a whole. The justification for such a trend could be found in the proposed general principle of maximum entropy production (MEP), which states that non-equilibrium thermodynamic systems maintain steady states at which entropy production is maximized. Here, I justify and demonstrate this application of MEP to the Earth at the planetary scale. I first describe the non-equilibrium thermodynamic nature of Earth-system processes and distinguish processes that drive the system's state away from equilibrium from those that are directed towards equilibrium. I formulate the interactions among these processes from a thermodynamic perspective and then connect them to a holistic view of the planetary thermodynamic state of the Earth system. In conclusion, non-equilibrium thermodynamics and MEP have the potential to provide a simple and holistic theory of Earth-system functioning. This theory can be used to derive overall evolutionary trends of the Earth's past, identify the role that life plays in driving thermodynamic states far from equilibrium, identify habitability in other planetary environments and evaluate human impacts on Earth-system functioning.",
                    "score": 0.8340175747871399
                },
                {
                    "id": 9571616,
                    "contents": "CLIMATE CHANGE: The Causes of 20th Century Warming.\nGlobal air surface temperatures increased by about 0.6 degrees C during the 20th century, but as Zwiers and Weaver discuss in their Perspective, the warming was not continuous. Two distinct periods of warming, from 1910 to 1945 and since 1976, were separated by a period of very gradual cooling. The authors highlight the work by Stott et al., who have performed the most comprehensive simulation of 20th century climate to date. The agreement between observed and simulated temperature variations strongly suggests that forcing from anthropogenic activities, moderated by variations in solar and volcanic forcing, has been the main driver of climate change during the past century.",
                    "score": 0.8339188098907471
                },
                {
                    "id": 11439072,
                    "contents": "Understanding recent climate change.\nThe Earth's atmosphere has a natural greenhouse effect, without which the global mean surface temperature would be about 33 degrees C lower and life would not be possible. Human activities have increased atmospheric concentrations of carbon dioxide, methane, and other gases in trace amounts. This has enhanced the greenhouse effect, resulting in surface warming. Were it not for the partly offsetting effects of increased aerosol concentrations, the increase in global mean surface temperature over the past 100 years would be larger than observed. Continued surface warming through the 21st century is inevitable and will likely have widespread ecological impacts. The magnitude and rate of warming for the global average will be largely dictated by the strength and direction of climate feedbacks, thermal inertia of the oceans, the rate of greenhouse gas emissions, and aerosol concentrations. Because of regional expressions of climate feedbacks, changes in atmospheric circulation, and a suite of other factors, the magnitude and rate of warming and changes in other key climate elements, such as precipitation, will not be uniform across the planet. For example, due to loss of its floating sea-ice cover, the Arctic will warm the most.",
                    "score": 0.8338721990585327
                },
                {
                    "id": 4726234,
                    "contents": "The biosphere below.\nMore than a mile below Earth's surface, tiny creatures thrive in searing heat and crushing pressure. Scientists think these microorganisms might teach us about the origins and evolution of early life.",
                    "score": 0.8335949778556824
                },
                {
                    "id": 11830550,
                    "contents": "Let the Sun shine.\nThere is more than enough power available from the Sun to satisfy the world's needs, so why are we not rushing to exploit it?",
                    "score": 0.8333327770233154
                },
                {
                    "id": 21799236,
                    "contents": "Vapor Pressure Formulation for Water in Range 0 to 100 °C. A Revision.\nIn 1971 Wexler and Greenspan published a formulation for the vapor pressure of water encompassing the temperature range 0 to 100 °C. In this paper a revision is made of that earlier formulation to make it consistent with the definitive experimental value of the vapor pressure of water at its triple point recently obtained by Guildner, Johnson, and Jones. The two formulations are essentially identical at temperatures from 25 to 100 °C. For temperatures below 25 °C the new formulation predicts values that are higher than the 1971 formulation. At the triple point, the vapor pressure given by the new formulation is 611.657 Pa whereas the value given by the 1971 formulation is 611.196 Pa. A table is given of the vapor pressure as a function of temperature at 0.1-deg intervals over the range 0 to 100 °C on the International Practical Temperature Scale of 1968, together with values of the temperature derivative at 1-deg intervals.",
                    "score": 0.8330668807029724
                }
            ],
            "metric_score": {
                "retrieval_recall": 1,
                "retrieval_precision": 0.2
            }
        }
    },
    {
        "id": "test_32",
        "question": "The power output of a laser is measured in units of watts (W), where one watt is equal to one joule per second. $\\left(1 \\mathrm{~W}=1 \\mathrm{~J} \\cdot \\mathrm{s}^{-1}\\right.$.) What is the number of photons emitted per second by a $1.00 \\mathrm{~mW}$ nitrogen laser? The wavelength emitted by a nitrogen laser is $337 \\mathrm{~nm}$.",
        "golden_answers": [
            " 1.70"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 10185905,
                    "contents": "Lasers: the first fifty years.\nThis year marks the 50th anniversary of the invention of the laser. The Optical Society of America is publishing this feature issue to celebrate this auspicious birthday.",
                    "score": 0.9161804914474487
                },
                {
                    "id": 10672785,
                    "contents": "The rise of the laser. Interview by Joerg Heber.\nIt was the realization of semiconductor lasers that led to the commercial success of lasers. Herbert Kroemer explains to Nature Materials his contributions to the design principle of these lasers, for which he shared the 2000 Nobel Prize in Physics.",
                    "score": 0.9127414226531982
                },
                {
                    "id": 6356493,
                    "contents": "Principles of lasers.\nThe physics of lasers is described: a laser is light amplication by stimulation of emitted radiation. The laser beam is monochromatic, highly collimated, and delivers very high energy.",
                    "score": 0.9052717685699463
                },
                {
                    "id": 10672783,
                    "contents": "Fifty brilliant years.\nThe first demonstration of the laser has not only led to a myriad of commercial applications, but fifty years on basic research continues to rejuvenate the fundamental physics of the laser.",
                    "score": 0.9040233492851257
                },
                {
                    "id": 22814608,
                    "contents": "The Invention of the Laser.\nIn this chapter, I describe a scientific rivalry at Columbia University's physics department in the days of the 1950s before and when the laser invented, and the race to build a laser eventually won by a scientist in California in 1960. It tracks the arc from Charles Townes' success in amplifying microwaves with a device he called the maser, to graduate student Gordon Gould's realization of how shorter and more powerful light waves could also be amplified. The chapter describes Gould's notebook, written in 1957, diagramming an optically pumped laser. In the same notebook, he coined the word laser, an acronym for light amplification by stimulated emission of radiation, and suggested possible uses for the coherent light beams he imagined. The chapter also covers Gould's wish to patent and profit from his invention, his mistaken belief that he had to build a laser to receive a patent, and the flirtation with radical politics that barred him from the laboratory where he worked once the government classified the laser project that it was funding. Townes and his colleague and brother-in-law Arthur Schawlow, both eventual Physics Nobelists, meanwhile filed an application and received a patent for what they called an optical maser. Theodore Maiman at Hughes Laboratories built the first working laser in 1960, as the chapter describes. It concludes with the results of Gould's long battle to win basic laser patents and his eventual success.",
                    "score": 0.8992135524749756
                },
                {
                    "id": 6195826,
                    "contents": "[Characteristics of laser light].\nLaser is one of the greatest technical discoveries of the 20th century. It is important in basic sciences, but particularly in diagnosis and therapy of various pathologic conditions of human organism. It is electromagnetic radiation, not X-irradiation and, as such, it is not expected to produce new generation of iatrogenic malignancies. Laser falls between infrared and ultraviolet on the spectrum mainly in the visible light spectrum. Properties of laser light are: monochromacity (the same color), coherence (all of the light waves are in phase both spatially and temporally), collimation (all rays are parallel to each other and do not diverge significantly even over long distances). Lasers were first conceived by Einstein in 1917 when he wrote his \"Zur Quantum Theorie der Strahlung\" (the quantum theory of radiation) which enumerated concepts of stimulated and spontaneous emission and absorption. Drs. Arthur Schawlow and Charles Townes, in 1956, extended lasers into the optical frequency range and Maiman, in 1960, operated the first laser using ruby as the active medium (ruby laser). Laser is an acronym for Light Amplification by Stimulated Emission of Radiation. To understand the acronym, it is necessary to understand the basic physics of the atom. However, if the atom that is in the excited state is struck by another photon of energy before it returns to the ground state, two photons of equal frequency and energy, travelling in the same direction and in perfect spatial and temporal harmony, are produced. This phenomenon is termed stimulated emission of radiation. An external power source hyperexcites the atoms in the laser medium so that the number of atoms possessing upper energy levels exceeds the number of atoms in a power energy level, a condition termed a population inversion. This \"pumping system\" which imparts additional energy to the atoms may be optical, mechanical, or chemical. These atoms in a hyperexcited state spontaneously emit photons of light. The laser chamber or optical cavity contains an active lasing medium which usually determines the name of each laser. There are four types of lasing material commonly employed. Solid state lasers use a solid matrix material such as a ruby crystal. Gas lasers use a gas or mixture of gases such as helium, argon, and CO2. Dye lasers employ a complex organic dye in liquid solution or suspension such as rhodamine. Semiconductor lasers use two layers of semiconductor substances such as gallium arsenide.",
                    "score": 0.8865708112716675
                },
                {
                    "id": 11441586,
                    "contents": "Chemical lasers: a comprehensive literature survey.\nA bibliography of chemical laser publications covering the period 1964 through 1971 has been compiled. The chronologically listed references are followed by tables showing the chemical systems exhibiting laser action and by an alphabetical author index.",
                    "score": 0.88655024766922
                },
                {
                    "id": 9936904,
                    "contents": "Simple method of measuring the duration of short laser pulses.\nWe present a simple method to determine the duration of short laser pulses by measuring the efficiency of a second harmonic generation experiment.",
                    "score": 0.883760929107666
                },
                {
                    "id": 10185904,
                    "contents": "A short history of laser development.\nHalf a century has passed since Theodore Maiman's small ruby rod crossed the threshold of laser emission. The breakthrough demonstration earned headlines, but in the early years the laser was called \"a solution looking for a problem,\" and there was a germ of truth in the joke. Years of development since then have vastly improved laser performance,and tremendously increased their variety, earning lasers important roles in scientific research, consumer products, telecommunications,engineering, medicine, materials working, and a host of other applications. This article reviews the highlights of those developments and puts them into context, showing how laser technology has evolved to meet application requirements.",
                    "score": 0.882512629032135
                },
                {
                    "id": 11845624,
                    "contents": "Photochemistry: role of lasers.\nThis Technology editorial originally appeared in the Business Section of The New York Times, 21 May edition. It is reprinted here by permission.",
                    "score": 0.8811579942703247
                },
                {
                    "id": 5718426,
                    "contents": "Laser physics and physiology.\nLaser light begins when an excited and unstable electron moves from its unstable state back to a more stable state producing energy in the form of a photon. Laser light is coherent which means that the light waves move in phase together in space and time. Laser light is monochromatic which means it is comprised of only one color or wavelength. Laser light is also collimated which means it is perfectly parallel and travels in a single direction with very little divergence. Medical lasers fall in the infrared and visible as well as ultraviolet portion of the electromagnetic spectrum and are available at different wavelengths. The wavelength of each laser partially determines the effect it will have on tissue. A specific wavelength or color can be used to selectively target a specific tissue such as hemoglobin, water, or melanin. Heat is produced by the laser, destroying the targeted tissues.",
                    "score": 0.8806511759757996
                },
                {
                    "id": 11645393,
                    "contents": "The laser at fifty.\nDevices of all shapes and sizes are capable of lasing.",
                    "score": 0.8789451122283936
                },
                {
                    "id": 3970001,
                    "contents": "The power density of a surgical laser beam: its meaning and measurement.\nThis paper discusses the fundamental concepts of matter, energy, power, and power density, with specific emphasis on the power density of a laser. It points out that a laser beam does not have a single, unique value of diameter within which all of its radiation is confined. Therefore, a computation of power density requires both a value of diameter, and the value of the fraction of total power which is transmitted within that diameter. Some possible means of measuring diameter, power, and power density are presented.",
                    "score": 0.8744401931762695
                },
                {
                    "id": 11262794,
                    "contents": "Generating green to red light with semiconductor lasers.\nDiode lasers enable one to continuously cover the 730 to 1100 nm range as well as the 370 to 550 nm range by frequency doubling, but a large part of the electro-magnetic spectrum spanning from green to red remains accessible only through expensive and unpractical optically pumped dye lasers. Here we devise a method to multiply the frequency of optical waves by a factor 3/2 with a conversion that is phase-coherent and highly efficient. Together with harmonic generation, it will enable one to cover the visible spectrum with semiconductor lasers, opening new avenues in important fields such as laser spectroscopy and optical metrology.",
                    "score": 0.8743466138839722
                },
                {
                    "id": 11463433,
                    "contents": "Laser power calculations: sources of error.\nThe physical phenomena that dominate the power characteristics of a laser depend on the detailed nature of the amplifying medium and the resonator structure. In predicting the power characteristics, numerous approximations are always required. The most important approximations are considered here in detail, and error estimates are presented so that a designer can select the appropriate model for a particular application. Emphasis is placed on analytic solutions and specific phenomena considered include longitudinal and transverse spatial hole burning, large single-pass gain, and mixed line broadening.",
                    "score": 0.8731008768081665
                },
                {
                    "id": 11441976,
                    "contents": "Comparison of the laser power and total irradiance scales maintained by the national bureau of standards.\nThe paper describes an intercomparison of the instrument used to realize and maintain the NBS laser power and energy scale with the instrument used to realize and maintain the upper end of the NBS total irradiance scale. The intercomparison was conducted by performing simultaneous measurements of the average power from a cw kyrpton laser with both instruments. The procedure and apparatus of the comparison are described. The measured difference between the two instruments was well within the ~1.5% limit of error associated with the intercomparison.",
                    "score": 0.8730790019035339
                },
                {
                    "id": 9694337,
                    "contents": "Free-electron lasers.\nFree-electron lasers are tunable, potentially powerful sources of coherent radiation over a broad range of wavelengths from the far-infrared to the far-ultraviolet regions of the spectrum. These unique capabilities make them suitable for a broad variety of applications from medicine to strategic defense.",
                    "score": 0.8715102672576904
                },
                {
                    "id": 11442011,
                    "contents": "Dye Lasers--a Classified Bibliography 1966-1972.\nA bibliography of dye lasers has been compiled starting with the year 1966, when the first definitive report of a dye laser was published by Sorokin et al., and continuing through 1972.",
                    "score": 0.8710860013961792
                },
                {
                    "id": 18435926,
                    "contents": "Publisher Correction: Measurement of the emission spectrum of a semiconductor laser using laser-feedback interferometry.\nA correction to this article has been published and is linked from the HTML and PDF versions of this paper. The error has been fixed in the paper.",
                    "score": 0.8708950877189636
                },
                {
                    "id": 14567076,
                    "contents": "Portable, high-accuracy, non-absorbing laser power measurement at kilowatt levels by means of radiation pressure.\nWe describe a non-traditional optical power meter which measures radiation pressure to accurately determine a laser's optical power output. This approach traces its calibration of the optical watt to the kilogram. Our power meter is designed for high-accuracy and portability with the capability of multi-kilowatt measurements whose upper power limit is constrained only by the mirror quality. We provide detailed uncertainty evaluation and validate experimentally an average expanded relative uncertainty of 0.016 from 1 kW to 10 kW. Radiation pressure as a power measurement tool is unique to the extent that it does not rely on absorption of the light to produce a high-accuracy result. This permits fast measurements, simplifies power scalability, and allows high-accuracy measurements to be made during use of the laser for other applications.",
                    "score": 0.8683953285217285
                },
                {
                    "id": 10185921,
                    "contents": "Simple approach to the relation between laser frequency noise and laser line shape.\nFrequency fluctuations of lasers cause a broadening of their line shapes. Although the relation between the frequency noise spectrum and the laser line shape has been studied extensively, no simple expression exists to evaluate the laser linewidth for frequency noise spectra that does not follow a power law. We present a simple approach to this relation with an approximate formula for evaluation of the laser linewidth that can be applied to arbitrary noise spectral densities.",
                    "score": 0.8676791191101074
                },
                {
                    "id": 16920031,
                    "contents": "Quantum cascade lasers: 20 years of challenges.\nWe review the most recent technological and application advances of quantum cascade lasers, underlining the present milestones and future directions from the Mid-infrared to the Terahertz spectral range. Challenges and developments, which are the subject of the contributions to this focus issue, are also introduced. ",
                    "score": 0.8666422367095947
                },
                {
                    "id": 20388031,
                    "contents": "Coherent light brightens the quantum science frontier.\nControlling coherent light across a vast spectral range enables ultraprecise measurements and the quantum control of atomic, molecular, and condensed-matter systems.",
                    "score": 0.8665146827697754
                },
                {
                    "id": 11109051,
                    "contents": "Nonlinear optics: the next decade.\nThis paper concludes the Focus Serial assembled of invited papers in key areas of nonlinear optics (Editors: J.M. Dudley and R.W. Boyd), and it discusses new directions for future research in this field.",
                    "score": 0.8665136098861694
                },
                {
                    "id": 6999618,
                    "contents": "Laser applications to chemical and environmental analysis: introduction to the feature issue.\nThis issue of Applied Optics features 14 papers that describe recent advances of laser techniques, including instrumentation, application in combustion research, and detection of pollutants. Most of these contributions were presented at the Eighth Optical Society of America Topical Meeting on Laser Applications to Chemical and Environmental Analysis (8th LACEA), held in Boulder, Colorado, 7-10 February, 2002.",
                    "score": 0.8663235902786255
                },
                {
                    "id": 15589593,
                    "contents": "Quantum optics with one or two photons.\nWe discuss the concept of a single-photon state together with how they are generated, measured and interact with linear and nonlinear systems. In particular, we consider how a single-photon state interacts with an opto-mechanical system: an optical cavity with a moving mirror and how such states can be used as a measurement probe for the mechanical degrees of freedom. We conclude with a discussion of how single-photon states are modified in a gravitational field due to the red-shift.",
                    "score": 0.8663051128387451
                },
                {
                    "id": 10876305,
                    "contents": "Submillimeter laser wavelength tables.\nTables are presented that list submillimeter laser lines observed in the optical pumping of molecular gases with CO(2) laser radiation. The lines have been obtained from previous publications by various authors and are in the wavelength range from 34micron to 1.965 mm. One table lists, for each gas, the submillimeter wavelengths observed, the line of the CO(2) pump laser, references to the literature, and, where available, the polarization and power of the submillimeter laser and the power of the CO(2) pump laser. A second table lists all the observed laser wavelengths in numerical order together with the gas in which each line was observed. These tables should be useful to researchers working with submillimeter lasers.",
                    "score": 0.8661164045333862
                },
                {
                    "id": 10171982,
                    "contents": "Dye lasers: introduction by the feature editors.\nThis special issue of Applied Optics provides a perspective on recent trends in dye laser research.",
                    "score": 0.8656038045883179
                },
                {
                    "id": 9698700,
                    "contents": "Free-electron lasers: present status and future prospects.\nFree-electron lasers as scientific instruments are reviewed. The present status and future prospects are delineated with attention drawn to the size, complexity, availability, and performance capability of this new tool.",
                    "score": 0.8651366233825684
                },
                {
                    "id": 19715079,
                    "contents": "Editorial: Trends in Optical/Laser Spectroscopy and Applications.\nOptics and optical spectroscopy are dynamic fields that are developing very fast nowadays, triggered by (i) the need to go deeper in the scientific approach to nature's processes and phenomena, (ii) the evolution of applications in technological and industrial processes, art conservation, environment protection and cosmic space, and (iii) the sometimes hard to predict evolutions of knowledge in science, life sciences, artistic culture, technology and industrial processes [...].",
                    "score": 0.8650801181793213
                },
                {
                    "id": 21057275,
                    "contents": "Author Correction: Analysis of laser radiation using the Nonlinear Fourier transform.\nAn amendment to this paper has been published and can be accessed via a link at the top of the paper.",
                    "score": 0.8647156357765198
                },
                {
                    "id": 9013519,
                    "contents": "The excimer lasers.\nThe excimer lasers are a group of lasers that have found wide application in a variety of medical fields including dermatology, cardiology, ophthalmology, and orthopedics. The word excimer refers to excited dimer. These lasers operate in the ultraviolet range, and examples include the 193 nm argon-fluroide, 248 nm krypton-fluoride, 351 nm xenon-fluoride, and of particular interest to dermatology, the 308 nm xenon-chloride. These lasers utilize a mixture of a noble gas and a halogen as a lasing material. They were first used in medicine for their ability to produce cold tissue ablation, but more recently have been used in dermatology as a method of non-ablative phototherapy.",
                    "score": 0.8640702962875366
                },
                {
                    "id": 9667320,
                    "contents": "Scenes from a marriage--of optics and electronics.\nBALTIMORE-Exploring the common ground between optics and electronics, more than 6800 physicists, spectroscopists, and engineers gathered here from 21 to 26 May at the joint meetings of the Conference on Lasers and Electro-Optics and the Quantum Electronics and Laser Science conference. Participants unveiled new technologies that have sprung up on this common ground, such as an imaging technique that can gauge the chemical composition of materials. They also described ways to broaden that ground, such as a novel approach for integrating lasers and silicon chips-a challenge that has slowed progress toward a new generation of high-speed computers and communications.",
                    "score": 0.8638079762458801
                },
                {
                    "id": 10305273,
                    "contents": "Interferometric laser power meter.\nA simple interferometric laser power meter can be constructed from a glass plate coated on one side with an absorbing film. When the plate is heated by the incident laser beam, its thickness and refractive index increase. The changes are monitored interferometrically.",
                    "score": 0.8634655475616455
                },
                {
                    "id": 15525212,
                    "contents": "Accurate frequency noise measurement of free-running lasers.\nWe present a simple method to accurately measure the frequency noise power spectrum of lasers. It relies on creating the beat note between two lasers, capturing the corresponding signal in the time domain, and appropriately postprocessing the data to derive the frequency noise power spectrum. In contrast to methods already established, it does not require stabilization of the laser to an optical reference, i.e., a second laser, to an optical cavity or to an atomic transition. It further omits a frequency discriminator and hence avoids bandwidth limitation and nonlinearity effects common to high-resolution frequency discriminators. ",
                    "score": 0.8630454540252686
                },
                {
                    "id": 6132851,
                    "contents": "Semiconductor laser with optical feedback: from excitable to deterministic low-frequency fluctuations.\nSemiconductor lasers with optical feedback present a regime in which power dropouts are observed. Although this regime has been extensively studied, there is no agreement about whether the dropouts are deterministically or stochastically generated. In this paper we will study the statistics of time intervals between dropouts assuming noise-driven simple excitable models. We explain the appearance of characteristic times in the first return maps.",
                    "score": 0.8626965284347534
                },
                {
                    "id": 9699417,
                    "contents": "Some emerging applications of lasers.\nNew laser applications are emerging in almost every field of science. Many of them show both a high degree of technical sophistication and broad practical utility. The progress being made is illustrated by specific applications in three areas: laser microchemistry, optical disk data storage, and remote sensing.",
                    "score": 0.8624426126480103
                },
                {
                    "id": 17642076,
                    "contents": "An intense, few-cycle source in the long-wave infrared.\nFor the last several decades, the wavelength range accessible for strong-field, few-cycle studies has remained limited to the visible, near infrared and mid-wave infrared regimes. In particular, sources in the long-wave infrared have been lacking. We report the development of a 1 kHz, few-cycle laser source with up to a 9 μm central wavelength and gigawatt peak powers. When focused, this source can ionize gas targets, which we demonstrate here through the ionization of atomic xenon at wavelengths ranging from 5 μm to 9 μm. This opens up new opportunities for fundamental atomic and molecular physics, enabling experimental tests of strong-field ionization theories in the extreme long-wavelength, few-cycle limit and the direct excitation of vibrational transitions in organic molecules.",
                    "score": 0.8620458245277405
                },
                {
                    "id": 929380,
                    "contents": "[The use of lasers in medicine].\nThe paper provides information concerning basic types of lasers used in medicine. Their most frequent indications are summarized and advantages of single types of apparatus are described.",
                    "score": 0.8619592189788818
                },
                {
                    "id": 9413223,
                    "contents": "Recent developments in tunable lasers for spectroscopy.\nAdvances in tunable lasers over the past few years are reviewed. Particular emphasis is placed on their application to spectroscopy.",
                    "score": 0.8617468476295471
                },
                {
                    "id": 13572548,
                    "contents": "Experimental validation of a simple approximation to determine the linewidth of a laser from its frequency noise spectrum.\nLaser frequency fluctuations can be characterized either comprehensively by the frequency noise spectrum or in a simple but incomplete manner by the laser linewidth. A formal relation exists to calculate the linewidth from the frequency noise spectrum, but it is laborious to apply in practice. We recently proposed a much simpler geometrical approximation applicable to any arbitrary frequency noise spectrum. Here we present an experimental validation of this approximation using laser sources of different spectral characteristics. For each of them, we measured both the frequency noise spectrum to calculate the approximate linewidth and the actual linewidth directly. We observe a very good agreement between the approximate and directly measured linewidths over a broad range of values (from kilohertz to megahertz) and for significantly different laser line shapes.",
                    "score": 0.8616116046905518
                },
                {
                    "id": 7617903,
                    "contents": "Absolute measurement of F2-laser power at 157 nm.\nWe report a comparison of laser power measurements at the F2-laser wavelength of 157 nm made at two facilities of the Physikalisch-Technische Bundesanstalt (PTB), the German national metrology institute. At the PTB laboratory at the electron storage ring BESSY II in Berlin, the scale for laser power was directly traced to a cryogenic radiometer operating at 157 nm, whereas at the PTB laser radiometry facility in Braunschweig the calibration of transfer detectors was performed with a newly developed standard for laser power at 157 nm, which is traceable in several steps to a cryogenic radiometer operating at 633 nm. The comparison was performed under vacuum conditions with laser pulse energies of approximately 10 microJ, however with different average powers because different primary standard radiometers were used. The relative deviation for the responsivity of the transfer detector was 4.8% and thus within the combined standard uncertainty.",
                    "score": 0.8615214824676514
                },
                {
                    "id": 4040514,
                    "contents": "The medical laser: an indispensable tool of the physician and surgeon.\nThe enormous proliferation of developments in the field of lasers has brought many changes and improvements to medicine. Lasers generate electromagnetic radiation unique in nature: Their light is coherent, collimated, and monochromatic. Because of these qualities, laser rays can be focused to very small spots of enormous power density. The wavelengths produced by a particular type of laser are determined by the characteristic energy levels of the emitting elements in the laser medium. The wavelengths of lasers currently used in therapy and surgery range from about 400 nm to 10,600 nm; at surgical power densities and at these wavelengths, because photonic ionization of atoms does not take place, laser rays are not oncogenic. Lasers can be used for converting radiant energy into heat in living tissues, for stimulating or moderating chemical reactions, or for mechanically disrupting histologic structure. Argon-ion, carbon dioxide, helium-neon, neodymium-doped yttrium-aluminum-garnet, ruby, organic-dye, and krypton-ion lasers are frequently used in medicine for therapeutic, analytical, or surgical applications. Laser use in medicine will increase as new developments bring forth new applications.",
                    "score": 0.8611409068107605
                },
                {
                    "id": 9102189,
                    "contents": "Laser technology: source of coherent kiloelectronvolt X-rays.\nGenerating X-rays that have the properties of laser light has been a long-standing goal for experimental science. Here we describe the emission of highly collimated, spatially coherent X-rays, at a wavelength of about 1 nanometre and at photon energies extending to 1.3 kiloelectronvolts, from atoms that have been ionized by a 5-femtosecond laser pulse. This means that a laboratory source of laser-like, kiloelectronvolt X-rays, which will operate on timescales relevant to many chemical, biological and materials problems, is now within reach.",
                    "score": 0.8605949282646179
                },
                {
                    "id": 15619163,
                    "contents": "Quantum optics: science and technology in a new light.\nLight facilitates exploration of quantum phenomena that illuminate the basic properties of nature and also enables radical new technologies based on these phenomena. The critical features of quantum light that underpin the opportunities for discovery and application are exceptionally low noise and strong correlations. Rapid progress in both science and technology has been stimulated by adopting components developed for optical telecommunications and networking, such as highly efficient detectors, integrated photonic circuits, and waveguide- or nanostructure-based nonlinear optical devices. These provide the means to generate new quantum states of light and matter of unprecedented scale, containing many photons with quantum correlations across space and time. Notably, networks with only several tens of photons are already beyond what can be efficiently analyzed by current computers. ",
                    "score": 0.8605058193206787
                },
                {
                    "id": 10238629,
                    "contents": "Introduction.\nWhen a coherent superposition of Rydberg states is excited by a laser pulse, a Rydberg wave packet is created. These wave packets are supremely quantum mechanical objects. However, they can be constructed to display classical, nearly classical, or semiclassical behavior, and thus serve as a natural bridge between the microscopic and mesoscopic worlds. In addition, their comparative simplicity allows detailed studies of the fundamental interactions of light with matter. The authors of this focus issue were invited to submit papers that reflect both the range of dynamical behavior exhibited by Rydberg wave packets, and the depth of understanding of them that is possible with current experiments and theory. In particular, the papers in this issue illustrate the possibility that emerging laser technology can be used not only to observe quantum behavior, but also to control it.",
                    "score": 0.8603104948997498
                },
                {
                    "id": 9960958,
                    "contents": "Laser beams and resonators.\nThis paper is a review of the theory-of laser beams and resonators. It is meant to be tutorial in nature and useful in scope. No attempt is made to be exhaustive in the treatment. Rather, emphasis is placed on formulations and derivations which lead to basic understanding and on results which bear practical significance.",
                    "score": 0.8602682948112488
                },
                {
                    "id": 21370742,
                    "contents": "Towards an in situ, full-power gauge of the focal-volume intensity of petawatt-class lasers.\nAbout 50 years ago, Sarachick and Schappert [Phys. Rev. D. 1, 2738-2752 (1970)] showed that relativistic Thomson scattering leads to wavelength shifts that are proportional to the laser intensity. About 28 years later, Chen et al. [Nature 396, 653-655 (1998)] used these shifts to estimate their laser intensity near 10<sup18</sup W/cm <sup2</sup. More recently, there have been several theoretical studies aimed at exploiting nonlinear Thomson scattering as a tool for direct measurement of intensities well into the relativistic regime. We present the first quantitative study of this approach for intensities between 10<sup18</sup and 10<sup19</sup W/cm <sup2</sup. We show that the spectral shifts are in reasonable agreement with estimates of the peak intensity extracted from images of the focal area obtained at reduced power. Finally, we discuss the viability of the approach, its range of usefulness and how it might be extended to gauge intensities well in excess of 10<sup19</sup W/cm <sup2</sup.",
                    "score": 0.8602555990219116
                },
                {
                    "id": 3630053,
                    "contents": "Lasers in medicine--a review.\nLaser systems permit very high energy radiation of a single wavelength to be focused on a tiny spot, and have found application in many areas of engineering. They are also currently used in many branches of medicine. The fields reviewed here are ophthalmology, gynaecology, dermatology, otolaryngology, gastroenterology and physiotherapy. Lasers which are in wide use for medical applications include argon, YAG and carbon dioxide types. In many areas, lasers have been found to be more effective than conventional treatment methods with advantages including less blood loss, more accurate removal of unwanted tissue, shorter operating time and less postoperative pain. It is expected that the next decade will see the laser as an everyday tool in many more medical applications.",
                    "score": 0.8600165247917175
                },
                {
                    "id": 15144670,
                    "contents": "Ruling Engines, Diffraction Gratings and Wavelength Measurements before the Rowland Era.\nDiffraction gratings have contributed enormously to modern science. Although some historians have written about them, there is much more to be brought to light. This paper discusses their development and use in the period up to about 1880 before Rowland began to produce them. Rittenhouse described the action of a diffraction grating in 1786, but no explanation was possible until the wave theory of light was developed. Fraunhofer discovered the dark lines in the solar spectrum in 1814, and then investigated diffraction, producing the first ruled gratings, making detailed measurements and calculating the wavelengths of prominent spectral lines. After Bunsen and Kirchhoff showed the association between spectral lines and chemical elements there was an upsurge of interest in measuring wavelengths. The gratings used in this work almost all came from one source, a relatively unknown instrument maker called Nobert, who made them by an extremely laborious process using a machine he had built himself. The most significant wavelength measurements were made by Ångström, but Mascart, Van der Willigen, Stefan, Ditscheiner and Cornu also did important work. Nobert gratings were investigated by Quincke, copied photographically by Rayleigh, and were known and discussed in the USA. Nobert's work helped to advance spectroscopy much more than has been acknowledged. ",
                    "score": 0.8595693707466125
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_33",
        "question": " Sirius, one of the hottest known stars, has approximately a blackbody spectrum with $\\lambda_{\\max }=260 \\mathrm{~nm}$. Estimate the surface temperature of Sirius.\r\n",
        "golden_answers": [
            "11000"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 9662229,
                    "contents": "Saturn's gravitational field, internal rotation, and interior structure.\nSaturn's internal rotation period is unknown, though it must be less than 10 hours, 39 minutes, and 22 seconds, as derived from magnetic field plus kilometric radiation data. By using the Cassini spacecraft's gravitational data, along with Pioneer and Voyager radio occultation and wind data, we obtain a rotation period of 10 hours, 32 minutes, and 35 +/- 13 seconds. This more rapid spin implies slower equatorial wind speeds on Saturn than previously assumed, and the winds at higher latitudes flow both east and west, as on Jupiter. Our related Saturn interior model has a molecular-to-metallic hydrogen transition about halfway to the planet's center.",
                    "score": 0.8843194842338562
                },
                {
                    "id": 5522089,
                    "contents": "Gravitational evidence for an undifferentiated Callisto.\nBefore the arrival of the Galileo spacecraft at Jupiter, models for the interior structure of the four galilean satellites--Io, Europa, Ganymede and Callisto-ranged from uniform mixtures of rock and ice (that is, undifferentiated objects) or rocky cores surrounded by a mantle of water ice. Now it appears that Io has a large metallic core and that Ganymede is strongly differentiated, most probably into a three-layer structure consisting of a metallic core, a silicate mantle and a deep outer layer of ice. Direct information on the interior structure of Callisto determined from previous spacecraft fly-bys was essentially limited to an estimate of the mean density being intermediate between pure ice and pure rock. Here we report measurements of Callisto's gravitational field which reveal that, in contrast to Io and Ganymede, this galilean satellite is most probably a homogeneous object consisting of a solar mixture of 40% compressed ice and 60% rock (including iron and iron sulphide). Callisto's undifferentiated state is consistent with the apparent lack of an intrinsic magnetic field, and indicates that the outermost galilean satellite has not experienced a heating phase sufficiently high to separate its rock and metal components from the lighter ices.",
                    "score": 0.8723827004432678
                },
                {
                    "id": 16597694,
                    "contents": "Massive stars. A chemical signature of first-generation very massive stars.\nNumerical simulations of structure formation in the early universe predict the formation of some fraction of stars with several hundred solar masses. No clear evidence of supernovae from such very massive stars has, however, yet been found in the chemical compositions of Milky Way stars. We report on an analysis of a very metal-poor star SDSS J001820.5-093939.2, which possesses elemental-abundance ratios that differ significantly from any previously known star. This star exhibits low [α-element Fe] ratios and large contrasts between the abundances of odd and even element pairs, such as scandium/titanium and cobalt/nickel. Such features have been predicted by nucleosynthesis models for supernovae of stars more than 140 times as massive as the Sun, suggesting that the mass distribution of first-generation stars might extend to 100 solar masses or larger. ",
                    "score": 0.8706218004226685
                },
                {
                    "id": 7198466,
                    "contents": "A stellar relic from the early Milky Way.\nThe chemical composition of the most metal-deficient stars largely reflects the composition of the gas from which they formed. These old stars provide crucial clues to the star formation history and the synthesis of chemical elements in the early Universe. They are the local relics of epochs otherwise observable only at very high redshifts; if totally metal-free ('population III') stars could be found, this would allow the direct study of the pristine gas from the Big Bang. Earlier searches for such stars found none with an iron abundance less than 1/10,000 that of the Sun, leading to the suggestion that low-mass stars could form from clouds above a critical iron abundance. Here we report the discovery of a low-mass star with an iron abundance as low as 1/200,000 of the solar value. This discovery suggests that population III stars could still exist--that is, that the first generation of stars also contained long-lived low-mass objects. The previous failure to find them may be an observational selection effect.",
                    "score": 0.8670257329940796
                },
                {
                    "id": 6267007,
                    "contents": "Helioseismology: probing the interior of a star.\nHelioseismology offers, for the first time, an opportunity to probe in detail the deep interior of a star (our Sun). The results will have a profound impact on our understanding not only of the solar interior, but also neutrino physics, stellar evolution theory, and stellar population studies in astrophysics.",
                    "score": 0.8663196563720703
                },
                {
                    "id": 12347804,
                    "contents": "A Sedna-like body with a perihelion of 80 astronomical units.\nThe observable Solar System can be divided into three distinct regions: the rocky terrestrial planets including the asteroids at 0.39 to 4.2 astronomical units (AU) from the Sun (where 1 AU is the mean distance between Earth and the Sun), the gas giant planets at 5 to 30 AU from the Sun, and the icy Kuiper belt objects at 30 to 50 AU from the Sun. The 1,000-kilometre-diameter dwarf planet Sedna was discovered ten years ago and was unique in that its closest approach to the Sun (perihelion) is 76 AU, far greater than that of any other Solar System body. Formation models indicate that Sedna could be a link between the Kuiper belt objects and the hypothesized outer Oort cloud at around 10,000 AU from the Sun. Here we report the presence of a second Sedna-like object, 2012 VP113, whose perihelion is 80 AU. The detection of 2012 VP113 confirms that Sedna is not an isolated object; instead, both bodies may be members of the inner Oort cloud, whose objects could outnumber all other dynamically stable populations in the Solar System.",
                    "score": 0.8656774759292603
                },
                {
                    "id": 4723714,
                    "contents": "10 micron spectra of protostars and the solid methanol abundance.\nWe have searched for the strong C-O stretching absorption of solid methanol near 9.8 micrometers toward the heavily obscured protostars AFGL 961, AFGL 2591, the BN object and Mon R2 IRS 3.  There is no clear evidence for this feature in the spectra, resulting in very conservative upper limits to the methanol abundance of 6% to 17% relative to solid H2O toward these objects.  This is well below previous estimates of 50%-80% obtained toward W33 A, NGC 7538 IRS 9, AFGL 2136, and W3 IRS 5, which were based on the assignment of the interstellar 6.85 micrometers absorption feature to the methanol C-H bending mode.  This study shows that such high methanol abundances are not a characteristic of all interstellar ices.",
                    "score": 0.8622468709945679
                },
                {
                    "id": 9667563,
                    "contents": "Astronomers watch the stars come out in berkeley.\nNew and strange sightings caught the attention of astronomers at this June's American Astronomical Society (AAS) meeting in Berkeley: a supernova that has changed its identity, a clutch of mysterious blue stars, and objects at the edge of the universe, shining brilliantly at the far end of the ultraviolet spectrum. Meanwhile, a more familiar object-one species of supernova-is raising hopes of predicting the ultimate fate of this cosmic zoo.",
                    "score": 0.8616423606872559
                },
                {
                    "id": 8902767,
                    "contents": "An upper limit to the masses of stars.\nThere is no accepted upper mass limit for stars. Such a basic quantity eludes both theory and observation, because of an imperfect understanding of the star-formation process and because of incompleteness in surveying the Galaxy. The Arches cluster is ideal for investigating such limits, being large enough to expect stars at least as massive as approximately 500 solar masses (approximately 500 Mo; based on a typical mass function), and young enough for its most massive members to still be visible. It is also old enough to be free of its natal molecular cloud, it is at a well-established distance, and it is close enough for us to discern its individual stars. Here I report an absence of stars with initial masses greater than 130 Mo in the Arches cluster, whereas the typical mass function predicts 18. I conclude that this indicates a firm limit of 150 Mo for stars; the probability that the observations are consistent with there being no upper limit is 10(-8).",
                    "score": 0.8596601486206055
                },
                {
                    "id": 9694461,
                    "contents": "Infrared Stars: The interaction between stars and interstellar clouds produces \"infrared stars\" of two different kinds.\nOur searches for very cool stars have revealed three kinds of objects: very cool Mira stars, perhaps cooler than any of this type previously known; extremely dense interstellar clouds, more dense than any known heretofore; and, probably, cool circumstellar clouds that may be planetary systems in an early stage of formation.",
                    "score": 0.8584988117218018
                },
                {
                    "id": 6996614,
                    "contents": "Low-mass relics of early star formation.\nThe earliest stars to form in the Universe were the first sources of light, heat and metals after the Big Bang. The products of their evolution will have had a profound impact on subsequent generations of stars. Recent studies of primordial star formation have shown that, in the absence of metals (elements heavier than helium), the formation of stars with masses 100 times that of the Sun would have been strongly favoured, and that low-mass stars could not have formed before a minimum level of metal enrichment had been reached. The value of this minimum level is very uncertain, but is likely to be between 10(-6) and 10(-4) that of the Sun. Here we show that the recent discovery of the most iron-poor star known indicates the presence of dust in extremely low-metallicity gas, and that this dust is crucial for the formation of lower-mass second-generation stars that could survive until today. The dust provides a pathway for cooling the gas that leads to fragmentation of the precursor molecular cloud into smaller clumps, which become the lower-mass stars.",
                    "score": 0.8580713868141174
                },
                {
                    "id": 19583683,
                    "contents": "IRC +10216 as a spectroscopic laboratory: improved rotational constants for SiC<sub>2</sub>, its isotopologues, and Si<sub>2</sub>C.\nThis work presents a detailed analysis of the laboratory and astrophysical spectral data available for <sup28</supSiC<sub2</sub, <sup29</supSiC<sub2</sub,<sup30</supSiC<sub2</sub, Si<sup13</supCC, and Si<sub2</subC. New data on the rotational lines of these species between 70 and 350 GHz have been obtained with high spectral resolution (195 kHz) with the IRAM 30m telescope in the direction of the circumstellar envelope IRC +10216. Frequency measurements can reach an accuracy of 50 kHz for features observed with a good signal to noise ratio. From the observed astrophysical lines and the available laboratory data new rotational and centrifugal distortion constants have been derived for all the isotopologues of SiC<sub2</sub, allowing to predict their spectrum with high accuracy in the millimeter and submillimeter domains. Improved rotational and centrifugal distortion constants have also been obtained for disilicon carbide, Si<sub2</subC. This work shows that observations of IRC +10216 taken with the IRAM 30m telescope, with a spectral resolution of 195 kHz, can be used for any molecular species detected in this source to derive, or improve, its rotational constants. Hence, IRC +10216 in addition to be one the richest sources in molecular species in the sky, can also be used as a state-of-the-art spectroscopy laboratory in the millimeter and submillimeter domains.",
                    "score": 0.8576682209968567
                },
                {
                    "id": 20287054,
                    "contents": "SiO, <sup>29</sup>SiO, and <sup>30</sup>SiO emission from 67 oxygen-rich stars. A survey of 61 maser lines from 7 to 1 mm.\nCircumstellar environments of oxygen-rich stars are among the strongest SiO maser emitters. Physical processes such as collisions, infrared pumping and overlaps favors the inversion of level population and produce maser emission at different vibrational states. Despite numerous observational and theoretical efforts, we still do not have an unified picture including all the physical processes involved in the SiO maser emission. The aim of this work is to provide homogeneous data in a large sample of oxygen-rich stars. We present a survey of 67 oxygen-rich stars from 7 to 1 mm, in their rotational transitions from <iJ</i = 1 → 0 to <iJ</i = 5 → 4, for vibrational numbers <iv</i from 0 to 6 in the three main SiO isotopologues. We have used one of the 34 m NASA antennas at Robledo and the IRAM 30 m radio telescope. The first tentative detection of a <iv</i = 6 line is reported, as well as the detection of new maser lines. The highest vibrational levels seem confined to small volumes, presumably close to the stars. The <iJ</i = 1 → 0, <iv</i = 2 line flux is greater than the corresponding <iv</i = 1 in almost half of the sample, which may confirm a predicted dependence on the pulsation cycle. This database is potentially useful in models which should consider most of the physical agents, time dependency, and mass-loss rates. As by-product, we report detections of 27 thermal rotational lines from other molecules, including isotopologues of SiS, H<sub2</subS, SO, SO<sub2</sub, and NaCl.",
                    "score": 0.8574747443199158
                },
                {
                    "id": 8290359,
                    "contents": "The trans-neptunian object UB313 is larger than Pluto.\nThe most distant known object in the Solar System, 2003 UB313 (97 au from the Sun), was recently discovered near its aphelion. Its high eccentricity and inclination to the ecliptic plane, along with its perihelion near the orbit of Neptune, identify it as a member of the 'scattered disk'. This disk of bodies probably originates in the Kuiper belt objects, which orbit near the ecliptic plane in circular orbits between 30 and 50 au, and may include Pluto as a member. The optical brightness of 2003 UB313, if adjusted to Pluto's distance, is greater than that of Pluto, which suggested that it might be larger than Pluto. The actual size, however, could not be determined from the optical measurements because the surface reflectivity (albedo) was unknown. Here we report observations of the thermal emission of 2003 UB313 at a wavelength of 1.2 mm, which in combination with the measured optical brightness leads to a diameter of 3,000 +/- 300 +/- 100 km. Here the first error reflects measurement uncertainties, while the second derives from the unknown object orientation. This makes 2003 UB313 the largest known trans-neptunian object, even larger than Pluto (2,300 km). The albedo is 0.60 +/- 0.10 +/- 0.05, which is strikingly similar to that of Pluto, suggesting that the methane seen in the optical spectrum causes a highly reflective icy surface.",
                    "score": 0.8573742508888245
                },
                {
                    "id": 9694269,
                    "contents": "The formation of sunlike stars.\nUnderstanding how stars like the sun formed constitutes one of the principal challenges confronting modern astrophysics. In recent years, advances in observational technology, particularly at infrared and millimeter wavelengths, have produced an avalanche of critical data and unexpected discoveries about the process of star formation, which is blocked from external view at optical and shorter wavelengths by an obscuring blanket of interstellar dust. Fueled by this new knowledge, a comprehensive empirical picture of stellar genesis is beginning to emerge, laying the foundations for a coherent theory of the birth of sunlike stars.",
                    "score": 0.8566988706588745
                },
                {
                    "id": 11120309,
                    "contents": "Astronomy. How old is that star?\nDespite being fundamental in determining its physical state, a star's age cannot be measured directly, and estimation methods are imprecise.",
                    "score": 0.8566553592681885
                },
                {
                    "id": 20283752,
                    "contents": "TMC-1, the starless core sulfur factory: Discovery of NCS, HCCS, H<sub>2</sub>CCS, H<sub>2</sub>CCCS, and C<sub>4</sub>S and detection of C<sub>5</sub>S.\nWe report the detection of the sulfur-bearing species NCS, HCCS, H<sub2</subCCS, H<sub2</subCCCS, and C<sub4</subS for the first time in space. These molecules were found towards TMC-1 through the observation of several lines for each species. We also report the detection of C<sub5</subS for the first time in a cold cloud through the observation of five lines in the 31-50 GHz range. The derived column densities are <iN</i(NCS) = (7.8±0.6)×10<sup11</sup cm<sup-2</sup, <iN</i(HCCS) = (6.8±0.6)×10<sup11</sup cm<sup-2</sup, N(H<sub2</subCCS) = (7.8±0.8)×10<sup11</sup cm<sup-2</sup, N(H<sub2</subCCCS) = (3.7±0.4)×10<sup11</sup cm<sup-2</sup, N(C<sub4</subS) = (3.8±0.4)×10<sup10</sup cm<sup-2</sup, and N(C<sub5</subS) = (5.0±1.0)×10<sup10</sup cm<sup-2</sup. The observed abundance ratio between C<sub3</subS and C<sub4</subS is 340, that is to say a factor of approximately one hundred larger than the corresponding value for CCS and C<sub3</subS. The observational results are compared with a state-of-the-art chemical model, which is only partially successful in reproducing the observed abundances. These detections underline the need to improve chemical networks dealing with S-bearing species.",
                    "score": 0.8552188277244568
                },
                {
                    "id": 9694136,
                    "contents": "Central object of the 30 doradus nebula, a supermassive star.\nR136 (HD 38268) is the central object of the 30 Doradus Nebula, a giant region of ionized hydrogen in the Large Magellanic Cloud. Observations of R136 at low and high spectral resolution with the International Ultraviolet Explorer reveal a peculiar hot object with a massive stellar wind. An outflow speed of 3500 kilometers per second and a temperature of approximately 60,000 K are indicated by the spectra. The bulk of the observed ultraviolet radiation must come from R136a, the brightest and bluest component of R136. Its absolute visual magnitude and observed temperature imply a luminosity about 10(8) times that of the sun. Most of the ionizations produced in 30 Doradus are provided by this peculiar object. If RI36a is a dense cluster of very hot stars, about 30 stars of classes O3 and WN3 exist in a region estimated to have a diameter of less than 0.1 parsec. This is inconsistent with the ultraviolet line spectrum and the evidence for optical variability. An alternative interpretation of the observations is that the radiation from R136a is dominated by a single superluminous object with the following approximate properties: luminosity and temperature as given above, a radius 100 times that of the sun, a mass 2500 times that of the sun, and a loss rate of 10(-3.5) solar masses per year. Model interior calculations for hydrogen-burning stars are consistent with these parameters. Such stars, however, are expected to be unstable, and this may account for the massive stellar wind.",
                    "score": 0.8545020222663879
                },
                {
                    "id": 8345528,
                    "contents": "A thick cloud of Neptune Trojans and their colors.\nThe dynamical and physical properties of asteroids offer one of the few constraints on the formation, evolution, and migration of the giant planets. Trojan asteroids share a planet's semimajor axis but lead or follow it by about 60 degrees near the two triangular Lagrangian points of gravitational equilibrium. Here we report the discovery of a high-inclination Neptune Trojan, 2005 TN(53). This discovery demonstrates that the Neptune Trojan population occupies a thick disk, which is indicative of \"freeze-in\" capture instead of in situ or collisional formation. The Neptune Trojans appear to have a population that is several times larger than the Jupiter Trojans. Our color measurements show that Neptune Trojans have statistically indistinguishable slightly red colors, which suggests that they had a common formation and evolutionary history and are distinct from the classical Kuiper Belt objects.",
                    "score": 0.8544935584068298
                },
                {
                    "id": 4722148,
                    "contents": "Interstellar SiO as a tracer of high-temperature chemistry.\nThe J = 2-1 transition of SiO has been searched for toward both hot and cold molecular gas.  SiO was not detected toward the dark clouds TMC-1, L134 N, and B335, down to column density upper limits of N &lt; 2-4 x 10(10) cm-2.  The species, however, has been observed toward all sources with a kinetic temperature greater than or equal to 30 K, with the largest column densities (N approximately 10(13)-10(17) cm-2) measured in the warmest (TK &gt; or  = 100 K) material.  The abundance of SiO, relative to HCN, is found to be approximately 0.1-1 in the massive star-forming regions toward Orion and NGC 7538; toward the dark clouds, the upper limits to this ratio is less than 0.0002-0.004.  A similar enhancement in the warmer regions is reflected in the SiO/H2 ratio as well.  A linear relation was found between the natural log of the SiO concentration and 1/TK, suggesting that the species' formation involves a chemically specific process that contains an activation barrier of approximately 90 K.  SiO was also found to be underabundant with respect to SO in cold clouds, with SiO/SO &lt; 1/1000, versus SiO/SO &gt; or =, measured in Orion-KL.  The formation of SiO is therefore linked closely to the local gas kinetic temperature, rather than the oxygen abundance, and its synthesis is likely to involve high-temperature gas-phase reactions.  The species thus may serve as an unambiguous indicator of high-temperature or \"shock\" chemistry.",
                    "score": 0.8544421195983887
                },
                {
                    "id": 8438392,
                    "contents": "Ultraviolet imaging spectroscopy shows an active saturnian system.\nNeutral oxygen in the saturnian system shows variability, and the total number of oxygen atoms peaks at 4 x 10(34). Saturn's aurora brightens in response to solar-wind forcing, and the auroral spectrum resembles Jupiter's. Phoebe's surface shows variable water-ice content, and the data indicate it originated in the outer solar system. Saturn's rings also show variable water abundance, with the purest ice in the outermost A ring. This radial variation is consistent with initially pure water ice bombarded by meteors, but smaller radial structures may indicate collisional transport and recent renewal events in the past 10(7) to 10(8) years.",
                    "score": 0.8536890149116516
                },
                {
                    "id": 5519697,
                    "contents": "Interstellar ices studied with the Infrared Space Observatory.\nThe Infrared Space Observatory (ISO) was launched by the European Space Agency on 17 November 1995. The availability of spectra from the Short Wavelength Spectrometer (SWS) on ISO is a landmark in the study of interstellar ices and organics; they provide a wealth of data in the 2-20 microns region of the spectrum covering the principal solid state resonances of condensed matter in interstellar clouds. We thus have the opportunity to study many species likely to be relevant to the inventory of CNO-bearing interstellar material present at the formation of our own and other planetary systems. This paper presents a brief overview of what has been learned from the data available so far. A comparison is made between the compositions of ices in molecular clouds, protostellar condensations and comets. Key areas of uncertainty are highlighted as a basis for future research.",
                    "score": 0.8530091047286987
                },
                {
                    "id": 15434212,
                    "contents": "The formation of submillimetre-bright galaxies from gas infall over a billion years.\nSubmillimetre-bright galaxies at high redshift are the most luminous, heavily star-forming galaxies in the Universe and are characterized by prodigious emission in the far-infrared, with a flux of at least five millijanskys at a wavelength of 850 micrometres. They reside in haloes with masses about 10(13) times that of the Sun, have low gas fractions compared to main-sequence disks at a comparable redshift, trace complex environments and are not easily observable at optical wavelengths. Their physical origin remains unclear. Simulations have been able to form galaxies with the requisite luminosities, but have otherwise been unable to simultaneously match the stellar masses, star formation rates, gas fractions and environments. Here we report a cosmological hydrodynamic galaxy formation simulation that is able to form a submillimetre galaxy that simultaneously satisfies the broad range of observed physical constraints. We find that groups of galaxies residing in massive dark matter haloes have increasing rates of star formation that peak at collective rates of about 500-1,000 solar masses per year at redshifts of two to three, by which time the interstellar medium is sufficiently enriched with metals that the region may be observed as a submillimetre-selected system. The intense star formation rates are fuelled in part by the infall of a reservoir gas supply enabled by stellar feedback at earlier times, not through major mergers. With a lifetime of nearly a billion years, our simulations show that the submillimetre-bright phase of high-redshift galaxies is prolonged and associated with significant mass buildup in early-Universe proto-clusters, and that many submillimetre-bright galaxies are composed of numerous unresolved components (for which there is some observational evidence). ",
                    "score": 0.8528977036476135
                },
                {
                    "id": 22682582,
                    "contents": "Cassini Exploration of the Planet Saturn: A Comprehensive Review.\nBefore Cassini, scientists viewed Saturn's unique features only from Earth and from three spacecraft flying by. During more than a decade orbiting the gas giant, Cassini studied the planet from its interior to the top of the atmosphere. It observed the changing seasons, provided up-close observations of Saturn's exotic storms and jet streams, and heard Saturn's lightning, which cannot be detected from Earth. During the Grand Finale orbits, it dove through the gap between the planet and its rings and gathered valuable data on Saturn's interior structure and rotation. Key discoveries and events include: watching the eruption of a planet-encircling storm, which is a 20- or 30-year event, detection of gravity perturbations from winds 9000 km below the tops of the clouds, demonstration that eddies are supplying energy to the zonal jets, which are remarkably steady over the 25-year interval since the Voyager encounters, re-discovery of the north polar hexagon after 25 years, determination of elemental abundance ratios He/H, C/H, N/H, P/H, and As/H, which are clues to planet formation and evolution, characterization of the semiannual oscillation of the equatorial stratosphere, documentation of the mysteriously high temperatures of the thermosphere outside the auroral zone, and seeing the strange intermittency of lightning, which typically ceases to exist on the planet between outbursts every 1-2 years. These results and results from the Jupiter flyby are all discussed in this review.",
                    "score": 0.8526806235313416
                },
                {
                    "id": 4726130,
                    "contents": "Detection of water ice on Nereid.\nWe report the detection of the 1.5 and 2.0 micrometers absorption bands of water ice in the near-infrared reflection spectrum of Neptune's distant irregular satellite Nereid. The spectrum and albedo of Nereid appear intermediate between those of the Uranian satellites Umbriel and Oberon, suggesting a surface composed of a combination of water ice frost and a dark and spectrally neutral material. In contrast, the surface of Nereid appears dissimilar to those of the outer solar system minor planets Chiron, Pholus, and 1997 CU26. The spectrum thus provides support for the hypothesis that Nereid is a regular satellite formed in a circumplanetary environment rather than a captured object.",
                    "score": 0.852020800113678
                },
                {
                    "id": 9666977,
                    "contents": "Saturn's Ring and the Satellites of Jupiter: Interpretations of Infrared Spectra.\nInfrared spectra of Saturn's ring correspond closely with the reflection spectrum of water ice. This result supports Kuiper's suggestion for the composition of the ring. The absence of the strong absorption at 8873 A in spectra of Io, Ganymede, and Callisto leads to a new upper limit for the abundance of methane in possible atmospheres of these satellites.",
                    "score": 0.851904034614563
                },
                {
                    "id": 17432790,
                    "contents": "Formation of the first generation of stars and blackholes in the Universe.\nModern sky surveys using large ground-based telescopes have discovered a variety of celestial objects. Prominent structures such as galaxies and galaxy clusters are found virtually everywhere, and their collective distribution forms the large-scale structure of the Universe. It is thought that all of the rich content in the present-day Universe developed through gravitational amplification of primeval density fluctuations generated in the very early phase of cosmic evolution. The standard theoretical model based on an array of recent observations accurately predicts the physical conditions in the early Universe, and powerful super-computers allow us to simulate in detail the formation and evolution of cosmic structure to the present epoch. We review recent progress in the study on the first generation of stars and blackholes. We focus on the physics of early structure formation, while identifying several key issues and open questions. Finally, we discuss prospects for future observations of the first stars, galaxies and blackholes.",
                    "score": 0.8518279790878296
                },
                {
                    "id": 9695505,
                    "contents": "The most luminous stars.\nStars with individual luminosities more than a million times that of the sun are now being studied in a variety of contexts. Observational and theoretical ideas about the most luminous stars have changed greatly in the past few years. They can be observed spectroscopically even in nearby galaxies. They are not very stable; some have had violent outbursts in which large amounts of mass were lost. Because of their instabilities, these stars do not evolve to become red superglants as less luminous stars do. Theoretical scenarios for the evolution of these most massive stars depend on the effects of turbulence and mixing combined with high radition densities.",
                    "score": 0.8517559766769409
                },
                {
                    "id": 18144261,
                    "contents": "X makes nine: a distant ice giant in the solar system.\nEver since Pluto lost its status as one of the main planets of our solar system and was demoted to just another frozen denizen of the Kuiper belt, we have had to make do with eight, albeit in a pleasing symmetry, with four rocky ones this side of the asteroid belt and four giants on the far side. Now it looks like number nine is back on the slate: the existence of a large planet, about ten times as massive as Earth and hundreds of times more distant from the Sun than Earth itself, has been postulated to explain the curiously bunched-up orbits of several small celestial bodies, far beyond the orbit of Neptune. To date, we have only \"proof by simulation\" and we are yet to observe this massive planet in the backyard of our solar system by more direct means. However, powerful new telescopes should provide visual evidence within the next few decades.",
                    "score": 0.8516606092453003
                },
                {
                    "id": 7628126,
                    "contents": "Astrobiologically interesting stars within 10 parsecs of the sun.\nThe existence of life based on carbon chemistry and water oceans relies upon planetary properties, chiefly climate stability, and stellar properties, such as mass, age, metallicity, and galactic orbits. The latter can be well constrained with present knowledge. We present a detailed, up-to-date compilation of the atmospheric parameters, chemical composition, multiplicity, and degree of chromospheric activity for the astrobiologically interesting solar-type stars within 10 parsecs of the Sun. We determined their state of evolution, masses, ages, and space velocities, and produced an optimized list of candidates that merit serious scientific consideration by the future space-based interferometry probes aimed at directly detecting Earthsized extrasolar planets and seeking spectroscopic infrared biomarkers as evidence of photosynthetic life. The initially selected stars number 33 solar-type within the total population (excluding some incompleteness for late M-dwarfs) of 182 stars closer than 10 parsecs. A comprehensive and detailed data compilation for these objects is still lacking; a considerable amount of recent data has so far gone unexplored in this context. We present 13 objects as the nearest \"biostars,\" after eliminating multiple stars, young, chromospherically active, hard x-ray- emitting stars, and low metallicity objects. Three of these \"biostars\"-- Zeta Tucanae, Beta Canum Venaticorum, and 61 Virginis -- closely reproduce most of the solar properties and are considered as premier targets. We show that approximately 7% of the nearby stars are optimally interesting targets for exobiology.",
                    "score": 0.8515918850898743
                },
                {
                    "id": 4956538,
                    "contents": "The Morphologies of the Small Magellanic Cloud.\nWe compare the distribution of stars of different spectral types, and hence mean age, within the central SMC and find that the asymmetric structures are almost exclusively composed of young main-sequence stars. Because of the relative lack of older stars in these features and the extremely regular distribution of red giant and clump stars in the SMC central body, we conclude that tides alone are not responsible for the irregular appearance of the central SMC. The dominant physical mechanism in determining the current-day appearance of the SMC must be star formation triggered by a hydrodynamic interaction between gaseous components. These results extend the results of population studies (see Gardiner &amp; Hatzidimitriou) inward in radius and also confirm the suggestion of the spheroidal nature of the central SMC based on kinematic arguments (Dopita et al.; Hardy, Suntzeff, &amp; Azzopardi). Finally, we find no evidence in the underlying older stellar population for a \"bar\" or \"outer arm,\" again supporting our classification of the central SMC as a spheroidal body with highly irregular recent star formation.",
                    "score": 0.8514195680618286
                },
                {
                    "id": 6908448,
                    "contents": "Spectroscopy among the stars.\nThe space between the stars is not void, but filled with interstellar matter, mainly composed of dust and gas, which gather in large interstellar clouds. In our Galaxy these interstellar clouds are distributed along a thin, but extended layer which basically traces out the spiral distribution of matter: the stars, the gas, and the dust component. Up to the present time more than 100 different molecules have been identified in interstellar molecular clouds. The majority of the interstellar molecules constitute carbon containing organic substances. During the past years, overwhelming evidence has been gathered, mainly through spectroscopic observations, that interstellar molecular clouds provide the birthplaces for stars. In fact detailed high spectral and spatial resolution spectroscopic measurements reveal physical and chemical processes of the intricate star formation process.",
                    "score": 0.8513086438179016
                },
                {
                    "id": 9611038,
                    "contents": "Solar abundance of iridium.\nBy a method of spectrum synthesis, which yields log gfA, where g is the statistical weight of the lower level, f is the oscillator strength, and A is the abundance, an attempt is made to deduce the solar iridium abundance from one relatively unblended, but fairly weak IrI line, lambda 3220.78 A. If the Corliss-Bozman f-value for this line is adopted, we find log A(Ir) = 0.82 on the scale log A(H) = 12.00. The discordance with the value found from carbonaceous chondrites may arise from faulty f-values or from difficulties arising from line blending in this far ultraviolet domain of the solar spectrum.",
                    "score": 0.8513073325157166
                },
                {
                    "id": 8660667,
                    "contents": "Vega is a rapidly rotating star.\nVega, the second brightest star in the northern hemisphere, serves as a primary spectral type standard. Although its spectrum is dominated by broad hydrogen lines, the narrower lines of the heavy elements suggested slow to moderate rotation, giving confidence that the ground-based calibration of its visible spectrum could be safely extrapolated into the ultraviolet and near-infrared (through atmosphere models), where it also serves as the primary photometric calibrator. But there have been problems: the star is too bright compared to its peers and it has unusually shaped absorption line profiles, leading some to suggest that it is a distorted, rapidly rotating star seen pole-on. Here we report optical interferometric observations that show that Vega has the asymmetric brightness distribution of the bright, slightly offset polar axis of a star rotating at 93 per cent of its breakup speed. In addition to explaining the unusual brightness and line shape peculiarities, this result leads to the prediction of an excess of near-infrared emission compared to the visible, in agreement with observations. The large temperature differences predicted across its surface call into question composition determinations, adding uncertainty to Vega's age and opening the possibility that its debris disk could be substantially older than previously thought.",
                    "score": 0.8508339524269104
                },
                {
                    "id": 21767060,
                    "contents": "A Census of Star Formation in the Outer Galaxy. II. The GLIMPSE360 Field.\nWe have conducted a study of star formation in the outer Galaxy from 65°&lt; <il</i &lt; 265°in the region observed by the GLIMPSE360 program. This Spitzer warm mission program mapped the plane of the outer Milky Way with IRAC at 3.6 and 4.5 <iμ</im. We combine the IRAC, Wide-field Infrared Survey Explorer (WISE), and Two Micron All Sky Survey catalogs and our previous results from another outer Galaxy survey and identify a total of 47,338 young stellar objects (YSOs) across the field spanning &gt;180° in Galactic longitude. Using the DBSCAN method on the combined catalog, we identify 618 clusters or aggregations of YSOs having five or more members. We identify 10,476 class I, 29,604 class II, and 7325 anemic class II/class III YSOs. The ratio of YSOs identified as members of clusters was 25,528/47,338, or 54%. We found that 100 of the clusters identified have previously measured distances in the WISE H II survey. We used these distances in our spectral energy distribution (SED) fitting of the YSOs in these clusters, of which 96 had YSOs with &lt;3<iσ</i fits. We used the derived masses from the SED model fits to estimate the initial mass function (IMF) in the inner and outer Galaxy clusters; dividing the clusters by galactocentric distances, the slopes were Γ = 1.87 ± 0.31 above 3 <iM</i <subⵙ</sub for <iR</i <subGal</sub &lt; 11.5 kpc and Γ = 1.15 ± 0.24 above 3 <iM</i <subⵙ</sub for <iR</i <subGal</sub &gt; 11.5 kpc. The slope of the combined IMF was found to be Γ = 1.92 ± 0.42 above 3 <iM</i <subⵙ</sub. These values are consistent with each other within the uncertainties and with literature values in the inner Galaxy high-mass star formation regions. The slopes are likely also consistent with a universal Salpeter IMF.",
                    "score": 0.8501584529876709
                },
                {
                    "id": 14107411,
                    "contents": "Stardust in meteorites.\nPrimitive meteorites, interplanetary dust particles, and comets contain dust grains that formed around stars that lived their lives before the solar system formed. These remarkable objects have been intensively studied since their discovery a little over twenty years ago and they provide samples of other stars that can be studied in the laboratory in exquisite detail with modern analytical tools. The properties of stardust grains are used to constrain models of nucleosynthesis in red giant stars and supernovae, the dominant sources of dust grains that are recycled into the interstellar medium by stars.",
                    "score": 0.8496082425117493
                },
                {
                    "id": 9036483,
                    "contents": "Chemical evolution of star-forming regions.\nRecent advances in the understanding of the chemical processes that occur during all stages of the formation of stars, from the collapse of molecular clouds to the assemblage of icy planetesimals in protoplanetary accretion disks, are reviewed. Observational studies of the circumstellar material within 100-10,000 AU of the young star with (sub)millimeter single-dish telescopes, millimeter interferometers, and ground-based as well as space-borne infrared observatories have only become possible within the past few years. Results are compared with detailed chemical models that emphasize the coupling of gas-phase and grain-surface chemistry. Molecules that are particularly sensitive to different routes of formation and that may be useful in distinguishing between a variety of environments and histories are outlined. In the cold, low-density prestellar cores, radicals and long unsaturated carbon chains are enhanced. During the cold collapse phase, most species freeze out onto the grains in the high-density inner region. Once young stars ignite, their surroundings are heated through radiation and/or shocks, whereupon new chemical characteristics appear. Evaporation of ices drives a ''hot core'' chemistry rich in organic molecules, whereas shocks propagating through the dense envelope release both refractory and volatile grain material, resulting in prominent SiO, OH, and H2O emission. The role of future instrumentation in further developing these chemical and temporal diagnostics is discussed.",
                    "score": 0.8485789895057678
                },
                {
                    "id": 6444689,
                    "contents": "The physics of neutron stars.\nNeutron stars are some of the densest manifestations of massive objects in the universe. They are ideal astrophysical laboratories for testing theories of dense matter physics and provide connections among nuclear physics, particle physics, and astrophysics. Neutron stars may exhibit conditions and phenomena not observed elsewhere, such as hyperon-dominated matter, deconfined quark matter, superfluidity and superconductivity with critical temperatures near 10(10) kelvin, opaqueness to neutrinos, and magnetic fields in excess of 10(13) Gauss. Here, we describe the formation, structure, internal composition, and evolution of neutron stars. Observations that include studies of pulsars in binary systems, thermal emission from isolated neutron stars, glitches from pulsars, and quasi-periodic oscillations from accreting neutron stars provide information about neutron star masses, radii, temperatures, ages, and internal compositions.",
                    "score": 0.8484340906143188
                },
                {
                    "id": 5144932,
                    "contents": "1998 SM165: a large Kuiper belt object with an irregular shape.\nThe recent discovery of an ancient reservoir of icy bodies at and beyond the orbit of Neptune-the Kuiper belt-has opened a new frontier in astronomy. Measurements of the physical and chemical nature of Kuiper belt objects (KBOs) can constrain our ideas of the processes of planet formation and evolution. Our 1.8-m Vatican Advanced Technology Telescope and charge-coupled device camera observations of the KBO 1998 SM(165) indicate its brightness periodically varies by 0.56 magnitudes over a 4-h interval. If we assume a uniform albedo of 0.04, which is typical of values found in the literature for a handful of KBOs, and an \"equator-on\" aspect, we find 1998 SM(165) has axes of length 600 x 360 km. If our assumptions are correct, such dimensions put 1998 SM(165) among the largest elongated objects known in our solar system. Perhaps long ago, two nearly spherical KBOs of comparable size coalesced to form a compound object, or perhaps 1998 SM(165) is the residual core of a catastrophic fragmentation of a larger precursor.",
                    "score": 0.8478682041168213
                },
                {
                    "id": 17891157,
                    "contents": "The formation of solar-neighbourhood stars in two generations separated by 5 billion years.\nThe chemical compositions of stars encode those of the gas from which they formed, providing important clues regarding the formation histories of galaxies. A powerful diagnostic is the abundance of α elements (O, Mg, Si, S, Ca and Ti) relative to iron, [α/Fe]. The α elements are synthesized and injected into the interstellar medium by type II supernovae, which occur about ten million years after their originating stars form; by contrast, iron is returned to the interstellar medium by type Ia supernovae, which occur after a much longer timescale of roughly one billion years<sup1</sup. Periods of rapid star formation therefore tend to produce high-[α/Fe] stellar populations (because only type II supernovae have time to contribute to interstellar-medium enrichment as the stellar population forms), whereas low-[α/Fe] stars require periods of star formation that last more than a few billion years (over which timescales type Ia supernovae begin to affect the elemental composition of the interstellar medium more strongly than type II supernovae). The existence of two distinct groups of stars in the solar neighbourhood<sup2-7</sup, one with high [α/Fe] and the other with low [α/Fe], therefore suggests two different origins, but the mechanism by which this bimodal distribution arose remains unknown. Here we use a model of disk-galaxy evolution to show that the two episodes of star formation<sup8</sup predicted by the 'cold flow' theory of galactic gas accretion<sup9,10</sup also explain the observed chemical bimodality. In this scenario, the high-[α/Fe] stars form early, during an initial phase of accretion that involves infalling streams of cold primordial gas. There is then a hiatus of around two billion years until the shock-heated gas in the galactic dark-matter halo has cooled as a result of radiation and can itself commence accretion. The low-[α/Fe] stars form during this second phase. The peaks in these two star-formation episodes are separated by around five billion years. In addition, the large-scale variation in the abundance patterns of these two stellar populations that has been observed for the Milky Way<sup5,7</sup is partially explained by the spatial variation in this gas-accretion history.",
                    "score": 0.8472745418548584
                },
                {
                    "id": 18461342,
                    "contents": "An excess of massive stars in the local 30 Doradus starburst.\nThe 30 Doradus star-forming region in the Large Magellanic Cloud is a nearby analog of large star-formation events in the distant universe. We determined the recent formation history and the initial mass function (IMF) of massive stars in 30 Doradus on the basis of spectroscopic observations of 247 stars more massive than 15 solar masses ([Formula: see text]). The main episode of massive star formation began about 8 million years (My) ago, and the star-formation rate seems to have declined in the last 1 My. The IMF is densely sampled up to 200 [Formula: see text] and contains 32 ± 12% more stars above 30 [Formula: see text] than predicted by a standard Salpeter IMF. In the mass range of 15 to 200 [Formula: see text], the IMF power-law exponent is [Formula: see text], shallower than the Salpeter value of 2.35.",
                    "score": 0.8471479415893555
                },
                {
                    "id": 4726561,
                    "contents": "The faint young Sun paradox: an observational test of an alternative solar model.\nWe report the results of deep observations at radio (3.6 cm) wavelengths of the nearby solar-type star pi 01 Ursa Majoris with the Very Large Array (VLA) intended to test an alternative theory of solar luminosity evolution. The standard model predicts a solar luminosity only 75% of the present value and surface temperatures below freezing on Earth and Mars at 4 Ga, seemingly in conflict with geologic evidence for liquid water on these planets. An alternative model invokes a compensatory mass loss through a declining solar wind that results in a more consistent early luminosity. The free-free emission from an enhanced wind around nearby young Sun-like stars should be detectable at microwave frequencies. Our observations of pi 01 UMa, a 300 million year-old solar-mass star, place an upper limit on the mass loss rate of 4-5 x 10(-11) M(solar) yr-1. Total mass loss from such a star over 4 Gyr would be less than 6%. If this star is indeed an analog of the early Sun, it casts doubt on the alternative model as a solution to the faint young Sun paradox, particularly for Mars.",
                    "score": 0.8470484018325806
                },
                {
                    "id": 4722905,
                    "contents": "The organic surface of 5145 Pholus:  constraints set by scattering theory.\nNo known body in the Solar System has a spectrum redder than that of object 5145 Pholus. We use Hapke scattering theory and optical constants measured in this laboratory to examine the ability of mixtures of a number of organic solids and ices to reproduce the observed spectrum and phase variation. The primary materials considered are poly-HCN, kerogen, Murchison organic extract, Titan tholin, ice tholin, and water ice. In a computer grid search of over 10 million models, we find an intraparticle mixture of 15% Titan tholin, 10% poly-HCN, and 75% water ice with 10-micrometers particles to provide an excellent fit. Replacing water ice with ammonia ice improves the fits significantly while using a pure hydrocarbon tholin, Tholin alpha, instead of Titan tholin makes only modest improvements. All acceptable fits require Titan tholin or some comparable material to provide the steep slope in the visible, and poly-HCN or some comparable material to provide strong absorption in the near-infrared. A pure Titan tholin surface with 16-micrometers particles, as well as all acceptable Pholus models, fit the present spectrophotometric data for the transplutonian object 1992 QB1. The feasibility of gas-phase chemistry to generate material like Titan tholin on such small objects is examined. An irradiated transient atmosphere arising from sublimating ices may generate at most a few centimeters of tholin over the lifetime of the Solar System, but this is insignificant compared to the expected lag deposit of primordial contaminants left behind by the sublimating ice. Irradiation of subsurface N2/CH4 or NH3/CH4 ice by cosmic rays may generate approximately 20 cm of tholin in the upper 10 m of regolith in the same time scale but the identity of this tholin to its gas-phase equivalent has not been demonstrated.",
                    "score": 0.8469029068946838
                },
                {
                    "id": 21859312,
                    "contents": "A Kinematically Cold Structure of Candidate Young OB Stars toward the Anticenter.\nWe combine <iGalaxy Evolution Explorer</i and <iGaia</i DR2 catalogs to track star formation in the outskirts of our Galaxy. Using photometry, proper motions, and parallaxes we identify a structure of ~300 OB-type candidates located between 12 and 15 kpc from the Galactic center that are kinematically cold. The structure is located between <il</i = 120° and 200°, above the plane up to ~700 pc and below the plane to ~1 kpc. The bulk motion is disklike; however, we measure a mean upward vertical motion of 5.7 ± 0.4 km s<sup-1</sup, and a mean outward radial motion of between 8 and 16 km s<sup-1</sup. The velocity dispersion along the least dispersed of its proper-motion axes (perpendicular to the Galactic disk) is 6.0 ± 0.3 km s<sup-1</sup, confirming the young age of this structure. While spatially encompassing the outer spiral arm of the Galaxy, this structure is not a spiral arm. Its explanation as the Milky Way warp is equally unsatisfactory. The structure's vertical extent, mean kinematics, and asymmetry with respect to the plane indicate that its origin is more akin to a wobble generated by a massive satellite perturbing the Galaxy's disk. The mean stellar ages in this outer structure indicate the event took place some 200 Myr ago.",
                    "score": 0.8467996120452881
                },
                {
                    "id": 15256450,
                    "contents": "SI-BEARING MOLECULES TOWARD IRC+10216: ALMA UNVEILS THE MOLECULAR ENVELOPE OF CWLEO.\nWe report the detection of SiS rotational lines in high-vibrational states as well as SiO and SiC<sub2</sub lines in their ground vibrational state toward IRC+10216 during the Atacama Large Millimeter Array Cycle 0. The spatial distribution of these molecules shows compact emission for SiS and a more extended emission for SiO and SiC<sub2</sub, and also proves the existence of an increase in the SiC<sub2</sub emission at the outer shells of the circumstellar envelope. We analyze the excitation conditions of the vibrationally excited SiS using the population diagram technique, and we use a large velocity gradient model to compare with the observations. We found moderate discrepancies between the observations and the models that could be explained if SiS lines detected are optically thick. Additionally, the line profiles of the detected rotational lines in the high energy vibrational states show a decreasing linewidth with increasing energy levels. This may be evidence that these lines could be excited only in the inner shells, i.e., the densest and hottest, of the circumstellar envelope of IRC+10216.",
                    "score": 0.846410870552063
                },
                {
                    "id": 20557861,
                    "contents": "Color, composition, and thermal environment of Kuiper Belt object (486958) Arrokoth.\nThe outer Solar System object (486958) Arrokoth (provisional designation 2014 MU<sub69</sub) has been largely undisturbed since its formation. We studied its surface composition using data collected by the New Horizons spacecraft. Methanol ice is present along with organic material, which may have formed through irradiation of simple molecules. Water ice was not detected. This composition indicates hydrogenation of carbon monoxide-rich ice and/or energetic processing of methane condensed on water ice grains in the cold, outer edge of the early Solar System. There are only small regional variations in color and spectra across the surface, which suggests that Arrokoth formed from a homogeneous or well-mixed reservoir of solids. Microwave thermal emission from the winter night side is consistent with a mean brightness temperature of 29 ± 5 kelvin.",
                    "score": 0.8461027145385742
                },
                {
                    "id": 11129617,
                    "contents": "A connection between star formation activity and cosmic rays in the starburst galaxy M82.\nAlthough Galactic cosmic rays (protons and nuclei) are widely believed to be mainly accelerated by the winds and supernovae of massive stars, definitive evidence of this origin remains elusive nearly a century after their discovery. The active regions of starburst galaxies have exceptionally high rates of star formation, and their large size-more than 50 times the diameter of similar Galactic regions-uniquely enables reliable calorimetric measurements of their potentially high cosmic-ray density. The cosmic rays produced in the formation, life and death of massive stars in these regions are expected to produce diffuse gamma-ray emission through interactions with interstellar gas and radiation. M82, the prototype small starburst galaxy, is predicted to be the brightest starburst galaxy in terms of gamma-ray emission. Here we report the detection of &gt;700-GeV gamma-rays from M82. From these data we determine a cosmic-ray density of 250 eV cm(-3) in the starburst core, which is about 500 times the average Galactic density. This links cosmic-ray acceleration to star formation activity, and suggests that supernovae and massive-star winds are the dominant accelerators.",
                    "score": 0.8458175659179688
                },
                {
                    "id": 5525212,
                    "contents": "Europa's differentiated internal structure: inferences from two Galileo encounters.\nDoppler data generated with the Galileo spacecraft's radio carrier wave during two Europa encounters on 19 December 1996 (E4) and 20 February 1997 (E6) were used to measure Europa's external gravitational field. The measurements indicate that Europa has a predominantly water ice-liquid outer shell about 100 to 200 kilometers thick and a deep interior with a density in excess of about 4000 kilograms per cubic meter. The deep interior could be a mixture of metal and rock or it could consist of a metal core with a radius about 40 percent of Europa's radius surrounded by a rock mantle with a density of 3000 to 3500 kilograms per cubic meter. The metallic core is favored if Europa has a magnetic field.",
                    "score": 0.8454945683479309
                },
                {
                    "id": 11598549,
                    "contents": "Seismic evidence for the loss of stellar angular momentum before the white-dwarf stage.\nWhite-dwarf stars represent the final products of the evolution of some 95% of all stars. If stars were to keep their angular momentum throughout their evolution, their white-dwarf descendants, owing to their compact nature, should all rotate relatively rapidly, with typical periods of the order of a few seconds. Observations of their photospheres show, in contrast, that they rotate much more slowly, with periods ranging from hours to tens of years. It is not known, however, whether a white dwarf could 'hide' some of its original angular momentum below the superficial layers, perhaps spinning much more rapidly inside than at its surface. Here we report a determination of the internal rotation profile of a white dwarf using a method based on asteroseismology. We show that the pulsating white dwarf PG 1159-035 rotates as a solid body (encompassing more than 97.5% of its mass) with the relatively long period of 33.61 +/- 0.59 h. This implies that it has lost essentially all of its angular momentum, thus favouring theories which suggest important angular momentum transfer and loss in evolutionary phases before the white-dwarf stage.",
                    "score": 0.8454173803329468
                },
                {
                    "id": 12024811,
                    "contents": "An Earth-sized planet with an Earth-like density.\nRecent analyses of data from the NASA Kepler spacecraft have established that planets with radii within 25 per cent of the Earth's (R Earth symbol) are commonplace throughout the Galaxy, orbiting at least 16.5 per cent of Sun-like stars. Because these studies were sensitive to the sizes of the planets but not their masses, the question remains whether these Earth-sized planets are indeed similar to the Earth in bulk composition. The smallest planets for which masses have been accurately determined are Kepler-10b (1.42 R Earth symbol) and Kepler-36b (1.49 R Earth symbol), which are both significantly larger than the Earth. Recently, the planet Kepler-78b was discovered and found to have a radius of only 1.16 R Earth symbol. Here we report that the mass of this planet is 1.86 Earth masses. The resulting mean density of the planet is 5.57 g cm(-3), which is similar to that of the Earth and implies a composition of iron and rock.",
                    "score": 0.8448234796524048
                }
            ],
            "metric_score": {
                "retrieval_recall": 1,
                "retrieval_precision": 0.2
            }
        }
    },
    {
        "id": "test_34",
        "question": "A ground-state hydrogen atom absorbs a photon of light that has a wavelength of $97.2 \\mathrm{~nm}$. It then gives off a photon that has a wavelength of $486 \\mathrm{~nm}$. What is the final state of the hydrogen atom?",
        "golden_answers": [
            " 2"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 22067069,
                    "contents": "Spectroscopy of Highly Excited States of the Hydrogen Atom.\nIn this contribution, we describe the status of the development of a precision-spectroscopic experiment aimed at measuring transitions to states of high principal quantum number <in</i of the hydrogen atom (H). These states form series (called Rydberg series) which converge for <in</i → ∞ to the ionization threshold of H. The ionization energy of H can thus be determined directly by measuring the frequencies of transitions to high-<in</i states and extrapolating the Rydberg series to <in</i → ∞.",
                    "score": 0.8932930827140808
                },
                {
                    "id": 13553588,
                    "contents": "Ultracold hydrogen atoms: a versatile coolant to produce ultracold molecules.\nWe show theoretically that ultracold hydrogen atoms have very favorable properties for sympathetic cooling of molecules to microkelvin temperatures. We calculate the potential energy surfaces for spin-polarized interactions of H atoms with the prototype molecules NH(3Σ-) and OH(2Π) and show that they are shallow (50 to 80  cm(-1)) and only weakly anisotropic. We carry out quantum collision calculations on H+NH and H+OH and show that the ratio of elastic to inelastic cross sections is high enough to allow sympathetic cooling from temperatures well over 1 K for NH and around 250 mK for OH.",
                    "score": 0.8747645616531372
                },
                {
                    "id": 16423135,
                    "contents": "Electron-hole pair excitation determines the mechanism of hydrogen atom adsorption.\nHow much translational energy atoms and molecules lose in collisions at surfaces determines whether they adsorb or scatter. The fact that hydrogen (H) atoms stick to metal surfaces poses a basic question. Momentum and energy conservation demands that the light H atom cannot efficiently transfer its energy to the heavier atoms of the solid in a binary collision. How then do H atoms efficiently stick to metal surfaces? We show through experiments that H-atom collisions at an insulating surface (an adsorbed xenon layer on a gold single-crystal surface) are indeed nearly elastic, following the predictions of energy and momentum conservation. In contrast, H-atom collisions with the bare gold surface exhibit a large loss of translational energy that can be reproduced by an atomic-level simulation describing electron-hole pair excitation. ",
                    "score": 0.872450590133667
                },
                {
                    "id": 15581306,
                    "contents": "Communication: Test of quantum chemistry in vibrationally hot hydrogen molecules.\nPrecision measurements are performed on highly excited vibrational quantum states of molecular hydrogen. The v = 12, J = 0 - 3 rovibrational levels of H2 (X(1)Σg (+)), lying only 2000 cm(-1) below the first dissociation limit, were populated by photodissociation of H2S and their level energies were accurately determined by two-photon Doppler-free spectroscopy. A comparison between the experimental results on v = 12 level energies with the best ab initio calculations shows a good agreement, where the present experimental accuracy of 3.5 × 10(-3) cm(-1) is more precise than theory, hence providing a gateway to further test theoretical advances in this benchmark quantum system. ",
                    "score": 0.8708588480949402
                },
                {
                    "id": 19846902,
                    "contents": "Laser-Driven Anharmonic Oscillator: Ground-State Dissociation of the Helium Hydride Molecular Ion by Midinfrared Pulses.\nThe vibrational motion of molecules represents a fundamental example of an anharmonic oscillator. Using a prototype molecular system, HeH^{+}, we demonstrate that appropriate laser pulses make it possible to drive the nuclear motion in the anharmonic potential of the electronic ground state, increasing its energy above the potential barrier and facilitating dissociation by purely vibrational excitation. We find excellent agreement between the frequency-dependent response of the helium hydride molecular cation to both classical and quantum mechanical simulations, thus removing any ambiguities through electronic excitation. Our results provide access to the rich dynamics of anharmonic quantum oscillator systems and pave the way to state-selective control schemes in ground-state chemistry by the adequate choice of the laser parameters.",
                    "score": 0.869959831237793
                },
                {
                    "id": 11274806,
                    "contents": "Three-photon excitation of hydrogen Rydberg states.\nA three-photon process using radiation at 2430 and 3660 A and with a 1s-2s two-photon resonance is used to excite atomic hydrogen from the ground state to Rydberg states of high principal quantum number. Collision-induced ionization is used to monitor the excitation.",
                    "score": 0.8696324229240417
                },
                {
                    "id": 9666505,
                    "contents": "The hydrogen atom and its reactions in solution.\nHydrogen atoms have been generated in solution by photolysis of thiols in solutions of organic compounds, and the relative rate constants, k(H), have been measured for the reaction H* + QH --&gt; H(2) + Q*, where QH is any organic compound which contains hydrogen. This represents the first kinetic study of the hydrogen atom in which it is generated in solution by a technique not involving ionizing radiation. The relative values of k(H) are in agreement with the values from radiolysis for most of the substances studied; however, for some compounds significantly different results have been obtained.",
                    "score": 0.8685686588287354
                },
                {
                    "id": 15783485,
                    "contents": "Electron-Proton Decoupling in Excited-State Hydrogen Atom Transfer in the Gas Phase.\nHydrogen-release by photoexcitation, excited-state-hydrogen-transfer (ESHT), is one of the important photochemical processes that occur in aromatic acids and is responsible for photoprotection of biomolecules. The mechanism is described by conversion of the initial state to a charge-separated state along the O(N)-H bond elongation, leading to dissociation. Thus ESHT is not a simple H-atom transfer in which a proton and a 1s electron move together. Here we show that the electron-transfer and the proton-motion are decoupled in gas-phase ESHT. We monitor electron and proton transfer independently by picosecond time-resolved near-infrared and infrared spectroscopy for isolated phenol-(ammonia)5 , a benchmark molecular cluster. Electron transfer from phenol to ammonia occurred in less than 3 picoseconds, while the overall H-atom transfer took 15 picoseconds. The observed electron-proton decoupling will allow for a deeper understanding and control of of photochemistry in biomolecules. ",
                    "score": 0.8678680658340454
                },
                {
                    "id": 17587862,
                    "contents": "Dissociation Energy of the Hydrogen Molecule at 10^{-9} Accuracy.\nThe ionization energy of ortho-H_{2} has been determined to be E_{I}^{o}(H_{2})/(hc)=124 357.238 062(25)  cm^{-1} from measurements of the GK(1,1)-X(0,1) interval by Doppler-free, two-photon spectroscopy using a narrow band 179-nm laser source and the ionization energy of the GK(1,1) state by continuous-wave, near-infrared laser spectroscopy. E_{I}^{o}(H_{2}) was used to derive the dissociation energy of H_{2}, D_{0}^{N=1}(H_{2}), at 35 999.582 894(25)  cm^{-1} with a precision that is more than one order of magnitude better than all previous results. The new result challenges calculations of this quantity and represents a benchmark value for future relativistic and QED calculations of molecular energies.",
                    "score": 0.8675122261047363
                },
                {
                    "id": 14197692,
                    "contents": "Experimental ionization of atomic hydrogen with few-cycle pulses.\nWe present experimental data on strong-field ionization of atomic hydrogen by few-cycle laser pulses. We obtain quantitative agreement at the 10% level between the data and an ab initio simulation over a wide range of laser intensities and electron energies.",
                    "score": 0.8665836453437805
                },
                {
                    "id": 10363876,
                    "contents": "Hydrogen forms in water by proton transfer to a distorted electron.\nSolvated electrons are ubiquitous intermediates in radiation-induced processes, with their lifetime being determined by quenching processes, such as the direct reaction with protons under acidic conditions. Ab initio molecular dynamics simulations allow us to unravel with molecular resolution the ultrafast reaction mechanism by which the electron and proton react in water. The path to a successful reaction involves a distortion and contraction of the hydrated electron and a rapid proton motion along a chain of hydrogen bonds, terminating on the water molecule most protruding into the electron cloud. This fundamental reaction is thus decidedly shown to be of a proton-transfer rather than electron-transfer character. Due to the desolvation penalty connected with breaking of the hydration shells of these charged particles, the reaction is, however, not diffusion-limited, in agreement with the interpretation of kinetics measurements.",
                    "score": 0.8658280968666077
                },
                {
                    "id": 9707366,
                    "contents": "Hot hydrogen atoms: initiators of reactions of interest in interstellar chemistry and evolution.\nPhotochemically generated hot hydrogen atoms initiate reactions with simple molecular substrates including methane to produce organic alcohols, amines, acids, amino acids, and other compounds. The typical quantum yields for the formation of amino acids are 2 x 10(-5) to 4 x 10(-5). Hot hydrogen atoms may be important initiators of reactions in interstellar space and in planetary atmospheres.",
                    "score": 0.8638896942138672
                },
                {
                    "id": 15379292,
                    "contents": "Schrödinger equation solved for the hydrogen molecule with unprecedented accuracy.\nThe hydrogen molecule can be used for determination of physical constants, including the proton charge radius, and for improved tests of the hypothetical long range force between hadrons, which require a sufficiently accurate knowledge of the molecular levels. In this work, we perform the first step toward a significant improvement in theoretical predictions of H2 and solve the nonrelativistic Schrödinger equation to the unprecedented accuracy of 10(-12). We hope that it will inspire a parallel progress in the spectroscopy of the molecular hydrogen. ",
                    "score": 0.8629891872406006
                },
                {
                    "id": 11522557,
                    "contents": "Communication: The ionization and dissociation energies of HD.\nThe adiabatic ionization energy [in units of hc, E(i)=124 568.485 81(36) cm(-1)] and the dissociation energy [D(0)=36 405.783 66(36) cm(-1)] of HD have been determined using a hybrid experimental-theoretical method. Experimentally, the wave numbers of the EF(v=0,N=0)→np[X(+)(v(+)=0 and 1, N(+)=0)] and EF(v=0,N=1)→np[X(+)(v(+)=0,N(+)=1)] transitions to singlet Rydberg states were measured by laser spectroscopy and used to validate predictions of the electron binding energies by multichannel quantum defect theory. Adding the transition energies, the electron binding energies and previously reported term energies of the EF state led to a determination of the adiabatic ionization energy of HD and of rovibrational energy spacings in HD(+). Combining these measurements with highly accurate theoretical values of the ionization energies of the one-electron systems H, D, and HD(+) further enabled a new determination of the dissociation energy of HD.",
                    "score": 0.8626742362976074
                },
                {
                    "id": 9667103,
                    "contents": "PHYSICS: Will NIF Live Up to Its Name?\nThe National Ignition Facility (NIF)--if it works as advertised, which is by no means certain given all of NIF's problems (see main text)--will pump almost 2 million joules of laser energy into a BB-sized pellet of hydrogen. But the bigger question is whether the pellet will actually achieve ignition--that is, undergo a sustained nuclear reaction that gives off as much energy as was put in? Most scientists on the project are cautiously optimistic, but others have grave doubts.",
                    "score": 0.8626132011413574
                },
                {
                    "id": 6545027,
                    "contents": "Spectroscopy of highly excited vibrational states of HCN in its ground electronic state.\nAn experimental technique based on a scheme of vibrationally mediated photodissociation has been developed and applied to the spectroscopic study of highly excited vibrational states in HCN, with energies between 29,000 and 30,000 cm(-1). The technique consists of four sequential steps: in the first one, a high power laser is used to vibrationally excite the sample to an intermediate state, typically (0,0,4), the nu3 mode being approximately equivalent to the C-H stretching vibration. Then a second laser is used to search for transitions between this intermediate state and highly vibrationally excited states. When one of these transitions is found, HCN molecules are transferred to a highly excited vibrational state. Third, a ultraviolet laser photodissociates the highly excited molecules to produce H and CN radicals in its A 2Pi electronic state. Finally, a fourth laser (probe) detects the presence of the CN(A) photofragments by means of an A--&gt;B--&gt;X laser induced fluorescence scheme. The spectra obtained with this technique, consisting of several rotationally resolved vibrational bands, have been analyzed. The positions and rotational parameters of the states observed are presented and compared with the results of a state-of-the-art variational calculation.",
                    "score": 0.862592875957489
                },
                {
                    "id": 9611026,
                    "contents": "Atomic regime in which the magnetic interaction dominates the coulomb interaction for highly excited States of hydrogen.\nThe atomic regime in which the interaction of the electron with an external magnetic field dominates the Coulomb interaction with the nucleus, relevant to pulsars, can be realized at laboratory magnetic fields for discrete autoionized states of hydrogen, at energies above the ionization limit. Approximate wave functions, energy levels, and electric dipole transition probabilities are presented for hydrogen, and an atomic beam absorption spectroscopy experiment at 50 kG is proposed to study this new regime.",
                    "score": 0.8624312281608582
                },
                {
                    "id": 4411819,
                    "contents": "The H1Sigma+&lt;INF POS=\"STACK\"&gt;g (v = 0 and 1) and EF1Sigma+&lt;INF POS=\"STACK\"&gt;g (v = 28 and 32) States of D2: Term Values and Fluorescence Lifetimes.\nThe extreme ultraviolet-visible double resonant excitation method was applied to the gerade Rydberg states of D2 molecules. Tunable coherent extreme ultraviolet radiation near 103 nm prepared D2 in the B1Sigma+&lt;INF POS=\"STACK\"&gt;u (v = 7, J) state. Visible laser light subsequently brought them to the H1Sigma+&lt;INF POS=\"STACK\"&gt;g (v = 0 and 1), EF1Sigma+&lt;INF POS=\"STACK\"&gt;g (v = 28 and 32), and GK1Sigma+&lt;INF POS=\"STACK\"&gt;g (v = 2 and 5) states. Our term values for the GK1Sigma+&lt;INF POS=\"STACK\"&gt;g state were in complete agreement with previous values, while deviations beyond the experimental error were found for the H1Sigma+&lt;INF POS=\"STACK\"&gt;g (v = 1) and EF1Sigma+&lt;INF POS=\"STACK\"&gt;g (v = 28 and 32) states. The fluorescence lifetimes, measured under a collision-free environment for the first time, were in reasonable agreement with ab initio calculations. Copyright 1998 Academic Press.",
                    "score": 0.8606371879577637
                },
                {
                    "id": 11420863,
                    "contents": "Optical phase and the ionization-dissociation dynamics of excited H(2).\nWe investigate the influence of optical phase on the dynamics of hydrogen molecules excited to a spectral region with competition between predominantly rotational ionization, and dissociation. We show that an appropriate choice of optical phase changes the relative timing of the ionization and dissociation. Furthermore, the temporal width of the ionization and dissociation fluxes can also be controlled, in a matter-wave analogy of transform-limited optical pulses. The close link between the optical phase and the photoinduced electronic and molecular dynamics has important implications for femtochemistry.",
                    "score": 0.8601962327957153
                },
                {
                    "id": 11252316,
                    "contents": "Measurement of the 2S hyperfine interval in atomic hydrogen.\nAn optical measurement of the 2S hyperfine interval in atomic hydrogen using two-photon spectroscopy of the 1S-2S transition gives a value of 177 556 834.3(6.7) Hz. The uncertainty is 2.4 times smaller than achieved by our group in 2003 and more than 4 times smaller than for any independent radio-frequency measurement. The specific combination of the 2S and 1S hyperfine intervals predicted by QED theory 8fHFS(2S)-fHFS(1S)=48 953(3) Hz is in good agreement with the value of 48 923(54) Hz obtained from this experiment.",
                    "score": 0.8584832549095154
                },
                {
                    "id": 15302155,
                    "contents": "Probing QED and fundamental constants through laser spectroscopy of vibrational transitions in HD(.).\nThe simplest molecules in nature, molecular hydrogen ions in the form of H2(+) and HD(+), provide an important benchmark system for tests of quantum electrodynamics in complex forms of matter. Here, we report on such a test based on a frequency measurement of a vibrational overtone transition in HD(+) by laser spectroscopy. We find that the theoretical and experimental frequencies are equal to within 0.6(1.1) parts per billion, which represents the most stringent test of molecular theory so far. Our measurement not only confirms the validity of high-order quantum electrodynamics in molecules, but also enables the long predicted determination of the proton-to-electron mass ratio from a molecular system, as well as improved constraints on hypothetical fifth forces and compactified higher dimensions at the molecular scale. With the perspective of comparisons between theory and experiment at the 0.01 part-per-billion level, our work demonstrates the potential of molecular hydrogen ions as a probe of fundamental physical constants and laws. ",
                    "score": 0.8582861423492432
                },
                {
                    "id": 8255044,
                    "contents": "Single-photon atomic cooling.\nWe report the cooling of an atomic ensemble with light, where each atom scatters only a single photon on average. This is a general method that does not require a cycling transition and can be applied to atoms or molecules that are magnetically trapped. We discuss the application of this new approach to the cooling of hydrogenic atoms for the purpose of precision spectroscopy and fundamental tests.",
                    "score": 0.8574918508529663
                },
                {
                    "id": 15087529,
                    "contents": "Accurate adiabatic correction in the hydrogen molecule.\nA new formalism for the accurate treatment of adiabatic effects in the hydrogen molecule is presented, in which the electronic wave function is expanded in the James-Coolidge basis functions. Systematic increase in the size of the basis set permits estimation of the accuracy. Numerical results for the adiabatic correction to the Born-Oppenheimer interaction energy reveal a relative precision of 10(-12) at an arbitrary internuclear distance. Such calculations have been performed for 88 internuclear distances in the range of 0 &lt; R ⩽ 12 bohrs to construct the adiabatic correction potential and to solve the nuclear Schrödinger equation. Finally, the adiabatic correction to the dissociation energies of all rovibrational levels in H2, HD, HT, D2, DT, and T2 has been determined. For the ground state of H2 the estimated precision is 3 × 10(-7) cm(-1), which is almost three orders of magnitude higher than that of the best previous result. The achieved accuracy removes the adiabatic contribution from the overall error budget of the present day theoretical predictions for the rovibrational levels. ",
                    "score": 0.8570324778556824
                },
                {
                    "id": 23829609,
                    "contents": "Atomic excited states and the related energy levels.\nThis article is about generalization and extension of the Bohr atomic model as well as the Rydberg formula to make them applicable to all atomic/ionic excited states and their energy levels. Bohr and Rydberg's original works were deemed only for hydrogen and the hydrogen-like ions but in time many mistakenly have come to the conclusion that those original forms of the theory are applicable to all species. This article clarifies the subject and helps with the misunderstandings. The article reviews first the original theory of atoms, the related excited states, and the related energy levels. It then shows the shortcoming of the original formulations and makes changes to generalize the theory and extend their applications to all atoms and their related ions. The theory of atomic excited states is re-formulated using a newly defined parameter called \"characteristic exponent k\" and the corresponding ionization energy. Numerical calculations and detailed works for several elements are presented to establish a better understanding of excited states. The article seeks also for a connection between the atomic energy levels and the internal structures and inner electrons of atoms. Furthermore, a small data bank is generated using the calculated \"characteristic exponents k\" for elements to be utilized for future simulations, studies, and research activities.",
                    "score": 0.8566964268684387
                },
                {
                    "id": 5189113,
                    "contents": "Excited-state proton transfer: from constrained systems to \"super\" photoacids to superfast proton transfer.\nWe have used knowledge of the electronic structure of excited states of acids to design molecules that exhibit enhanced excited-state acidity. Such \"super\" photoacids are the strongest reversible photoacids known and allow the time evolution of proton transfer to be examined in a wide array of organic solvents. This includes breaking/formation of the hydrogen bonds in hundreds of femtoseconds, solvent reorientation and relaxation in picoseconds, proton dissociation, and, finally, diffusion and geminate recombination of the dissociated proton, observed in nanoseconds.",
                    "score": 0.8565822839736938
                },
                {
                    "id": 17922043,
                    "contents": "New Measurement of the 1S-3S Transition Frequency of Hydrogen: Contribution to the Proton Charge Radius Puzzle.\nWe present a new measurement of the 1S-3S two-photon transition frequency of hydrogen, realized with a continuous-wave excitation laser at 205 nm on a room-temperature atomic beam, with a relative uncertainty of 9×10^{-13}. The proton charge radius deduced from this measurement, r_{p}=0.877(13)  fm, is in very good agreement with the current CODATA-recommended value. This result contributes to the ongoing search to solve the proton charge radius puzzle, which arose from a discrepancy between the CODATA value and a more precise determination of r_{p} from muonic hydrogen spectroscopy.",
                    "score": 0.8565639853477478
                },
                {
                    "id": 16676860,
                    "contents": "Hydrogen Atom Transfer from Water or Alcohols Activated by Presolvated Electrons.\nHigh-energy irradiation of protic solvents can transiently introduce excess electrons that are implicated in a diverse range of reductive processes. Here we report the evolution of electron solvation in water and in alcohols following photodetachment from aqueous hydroxide or the corresponding alkoxides studied by two- and three-pulse femtosecond spectroscopy and ab initio molecular dynamic simulations. The experiments reveal an ultrafast recombination channel of the excess electrons. Through the calculations this channel emerges as an H-atom transfer process to the hydroxyl or alkoxy radical species from neighboring solvent molecules, which are activated as the presolvated electron occupies their antibonding orbitals. The initially low activation barrier in the early stages of electron solvation was found to increase (from 12 to 44 kJ/mol in water) as full solvation proceeded. ",
                    "score": 0.8561542630195618
                },
                {
                    "id": 7128350,
                    "contents": "Observation of a motional Stark effect to determine the second-order Doppler effect.\nThe high resolution two-photon spectroscopy of hydrogen is often limited by the second-order Doppler effect. To determine this effect, we apply a magnetic field perpendicular to the atomic beam. This field induces a quadratic motional Stark shift proportional, as the second-order Doppler effect, to v(2) (v atomic velocity). For some magnetic field, these two effects are opposite and the total shift due to the atomic velocity is reduced. We present the first observation of this effect for the 1S-3S transition in hydrogen.",
                    "score": 0.855350136756897
                },
                {
                    "id": 15589593,
                    "contents": "Quantum optics with one or two photons.\nWe discuss the concept of a single-photon state together with how they are generated, measured and interact with linear and nonlinear systems. In particular, we consider how a single-photon state interacts with an opto-mechanical system: an optical cavity with a moving mirror and how such states can be used as a measurement probe for the mechanical degrees of freedom. We conclude with a discussion of how single-photon states are modified in a gravitational field due to the red-shift.",
                    "score": 0.855280339717865
                },
                {
                    "id": 9037032,
                    "contents": "Resolved: electronic states underneath broad absorptions.\nThe far UV absorption spectra of many polyatomic molecules show featureless, broad bands, even though the lifetimes of the underlying electronic states can be long enough to render the states observable. Using photoionization from Rydberg states we measure electron binding energies, thereby referencing the electronic spectra to the adiabatic ionization energy. In trimethylamine, we find that the 3s, the 3p(x,y), and the 3p(z) Rydberg states have binding energies of 3.087, 2.251, and 2.204 eV, respectively. Vibrational motions excited while preparing the Rydberg states do not interfere with the spectra.",
                    "score": 0.8551688194274902
                },
                {
                    "id": 18393988,
                    "contents": "Deep-Ultraviolet Frequency Metrology of H_{2} for Tests of Molecular Quantum Theory.\nMolecular hydrogen and its isotopic and ionic species are benchmark systems for testing quantum chemical theory. Advances in molecular energy structure calculations enable the experimental verification of quantum electrodynamics and potentially a determination of the proton charge radius from H_{2} spectroscopy. We measure the ground state energy in ortho-H_{2} relative to the first electronically excited state by Ramsey-comb laser spectroscopy on the EF^{1}Σ_{g}^{+}-X^{1}Σ_{g}^{+}(0,0) Q1 transition. The resulting transition frequency of 2 971 234 992 965(73) kHz is 2 orders of magnitude more accurate than previous measurements. This paves the way for a considerably improved determination of the dissociation energy (D_{0}) for fundamental tests with molecular hydrogen.",
                    "score": 0.8551421165466309
                },
                {
                    "id": 15084746,
                    "contents": "The ionization energy of C2.\nResonant two-photon threshold ionization spectroscopy is employed to determine the ionization energy of C2 to 5 meV precision, about two orders of magnitude more precise than the previously accepted value. Through exploration of the ionization threshold after pumping the 0-3 band of the newly discovered 4(3)Πg ← a(3)Πu band system of C2, the ionization energy of the lowest rovibronic level of the a(3)Πu state was determined to be 11.791(5) eV. Accounting for spin-orbit and rotational effects, we calculate that the ionization energy of the forbidden origin of the a(3)Πu state is 11.790(5) eV, in excellent agreement with quantum thermochemical calculations which give 11.788(10) eV. The experimentally derived ionization energy of X(1)Σg(+) state C2 is 11.866(5) eV.",
                    "score": 0.8548293709754944
                },
                {
                    "id": 14226600,
                    "contents": "Broad photoelectron spectrum and lowered electron affinity due to hydrogen in ZnOH: a joint experimental and theoretical study.\nWe report a combined experimental and theoretical photoelectron spectroscopy study of ZnOH(-). We find that the electron binding energy spectrum of ZnOH(-) reveals a broad and featureless peak between 1.4 and 2.4 eV in energy. The vertical detachment energy (VDE) of ZnOH(-) is determined to be 1.78 eV, which is lower than the 2.08 eV VDE of ZnO(-). Our theoretical calculations match the VDE of ZnOH(-) accurately, but we find that the broadness of the peak cannot be explained by rotational or vibrational state excitation. The broadness of this peak is in strong contrast to the narrow and easily understood first peak of the ZnO spectrum, which features a well-resolved vibrational progression that can be readily explained by calculating the Franck-Condon transition factors. This study provides spectroscopic evidence of the effect of hydrogen on diatomic ZnO.",
                    "score": 0.8547431230545044
                },
                {
                    "id": 17475916,
                    "contents": "The Right Answer for the Right Reason: My Personal Goal for Quantum Chemistry.\nA brief history of quantum theory is given to illustrate the barriers to progress caused by preconceived ideas. The biases in my own thinking which I had to overcome to approach the right answer for the right reason are discussed. This is followed by a personal autobiography illustrating how I have led a life of serendipity with no real sense of purpose. Chance events have shaped my life. The algorithms for which I am best known are briefly discussed. Then highlights from the many applications of theory to excited states, bonding in ice, spin properties and magnetism, (e,2e) shake-up spectra, and organic reactions are mentioned. This wide range of applications is mostly due to accidental collaboration with colleagues who sought my help. My real interest was in developing methods which could address these problems.",
                    "score": 0.8546844124794006
                },
                {
                    "id": 17614168,
                    "contents": "Hydrogen molecular ions: H<sub>3</sub><sup>+</sup>, H<sub>5</sub><sup>+</sup> and beyond.\nThree decades after the spectroscopic detection of H<sub3</sub<sup+</sup in space, the inspiring developments in physics, chemistry and astronomy of H<subn</sub<sup+</sup (n = 3, 5, 7) systems, which led to this Royal Society Discussion Meeting, are reviewed, the present state of the art as represented by the meeting surveyed and future lines of research considered. This article is part of a discussion meeting issue 'Advances in hydrogen molecular ions: H<sub3</sub<sup+</sup, H<sub5</sub<sup+</sup and beyond'.",
                    "score": 0.8544560670852661
                },
                {
                    "id": 11274710,
                    "contents": "Excitation and ionization of hydrogen Rydberg states in a plasma.\nHydrogen Rydberg states in a hydrogen plasma are optically excited from the plasma-excited n = 2 state. Photoionization and optogalvanic ionization, which is due to electron-impact ionization and other collisional processes, are used to monitor the Rydberg states. This process may be used to study collisional ionization of the Rydberg states.",
                    "score": 0.8544142246246338
                },
                {
                    "id": 9695221,
                    "contents": "Hydrogen Energy Levels: Perturbation Caused by Proton Structure.\nThe shifts in the lowest electronic energy levels of the hydrogen atom caused by the extended charge distribution of the proton have been calculated and found to be of the order of the unexplained portion of the Lamb shift for these levels.",
                    "score": 0.8530875444412231
                },
                {
                    "id": 7894984,
                    "contents": "Elementary steps in excited-state proton transfer.\nThe absorption of a photon by a hydroxy-aromatic photoacid triggers a cascade of events contributing to the overall phenomenon of intermolecular excited-state proton transfer. The fundamental steps involved were studied over the last 20 years using a combination of theoretical and experimental techniques. They are surveyed in this sequel in sequential order, from fast to slow. The excitation triggers an intramolecular charge transfer to the ring system, which is more prominent for the anionic base than the acid. The charge redistribution, in turn, triggers changes in hydrogen-bond strengths that set the stage for the proton-transfer step itself. This step is strongly influenced by the solvent, resulting in unusual dependence of the dissociation rate coefficient on water content, temperature, and isotopic substitution. The photolyzed proton can diffuse in the aqueous solution in a mechanism that involves collective changes in hydrogen-bonding. On longer times, it may recombine adiabatically with the excited base or quench it. The theory for these diffusion-influenced geminate reactions has been developed, showing nice agreement with experiment. Finally, the effect of inert salts, bases, and acids on these reactions is analyzed.",
                    "score": 0.8528861999511719
                },
                {
                    "id": 9611049,
                    "contents": "Radiationless relaxation in \"large\" molecules: Experimental evidence for preparation of true molecular eigenstates and Born-Oppenheimer states by a coherent light source.\nPhoton absorption and emission by molecules that undergo radiationless transitions are examined using the single modes of lasers having well-defined coherence properties. Contrary to the usual beliefs, where it is assumed that the molecule is prepared in a Born-Oppenheimer singlet state and then \"crosses-over\" to other states (vibrationally \"hot\" singlets and/or triplets), it is shown experimentally that the true eigenstates of the molecule can be prepared, even in \"large\" molecules, if the laser correlation time is relatively long and the molecular relaxation is made slow. On the other hand, lasers with short (psec) correlation time have yielded effectively the singlet Born-Oppenheimer state, which has a much shorter lifetime than the true eigenstates. Effects of magnetic fields and temperature are also reported. The former changes the amount of mixing amongst the Born-Oppenheimer states. The latter, on the other hand, swings the molecule from being \"small\" (i.e., sparse vibronic structure with long lifetimes) to being \"large\" (i.e., dense statistical distribution of levels) since the relaxation between levels is very effective at high temperatures. Finally, the results of this work show that the words fluorescence and phosphorescence in their strict meaning are misleading if the true eigenstates, which may contain both singlet and triplet character, are prepared.",
                    "score": 0.8528058528900146
                },
                {
                    "id": 11728507,
                    "contents": "(2+1) laser-induced fluorescence of spin-polarized hydrogen atoms.\nWe report the measurement of the spin polarization of hydrogen (SPH) atoms by (2+1) laser-induced fluorescence, produced via the photodissociation of thermal HBr molecules with circularly polarized 193 nm light. This scheme, which involves two-photon laser excitation at 205 nm and fluorescence at 656 nm, offers an experimentally simpler polarization-detection method than the previously reported vacuum ultraviolet detection scheme, allowing the detection of SPH atoms to be performed more straightforwardly, from the photodissociation of a wide range of molecules and from a variety of collision experiments.",
                    "score": 0.8523015975952148
                },
                {
                    "id": 13706088,
                    "contents": "To be or not to be: the early history of H3 and H3+.\nTriatomic hydrogen became a major research area only after 1980, but its history goes back to J. J. Thomson's discovery in 1911. In fact, the possible existence of H(3) was suggested as early as 1895. This paper outlines the history of H(3) and H(3)(+) up to the mid-1930s, when chemists and physicists ceased to believe in the existence of the H(3) molecule. In the intervening years, there was a great deal of interest in 'active hydrogen' and also in the configuration of H(3), which was examined by Bohr in 1919. While H(3) was abandoned, H(3)(+) was not. Although the properties of H(3)(+) were largely unknown, the existence of the ion was firmly established, and its structure studied by means of the new methods of quantum chemistry.",
                    "score": 0.852117657661438
                },
                {
                    "id": 16178577,
                    "contents": "Where Is the Electronic Oscillator Strength? Mapping Oscillator Strength across Molecular Absorption Spectra.\nThe effectiveness of solar energy capture and conversion materials derives from their ability to absorb light and to transform the excitation energy into energy stored in free carriers or chemical bonds. The Thomas-Reiche-Kuhn (TRK) sum rule mandates that the integrated (electronic) oscillator strength of an absorber equals the total number of electrons in the structure. Typical molecular chromophores place only about 1% of their oscillator strength in the UV-vis window, so individual chromophores operate at about 1% of their theoretical limit. We explore the distribution of oscillator strength as a function of excitation energy to understand this circumstance. To this aim, we use familiar independent-electron model Hamiltonians as well as first-principles electronic structure methods. While model Hamiltonians capture the qualitative electronic spectra associated with π electron chromophores, these Hamiltonians mistakenly focus the oscillator strength in the fewest low-energy transitions. Advanced electronic structure methods, in contrast, spread the oscillator strength over a very wide excitation energy range, including transitions to Rydberg and continuum states, consistent with experiment. Our analysis rationalizes the low oscillator strength in the UV-vis spectral region in molecules, a step toward the goal of oscillator strength manipulation and focusing. ",
                    "score": 0.8513365983963013
                },
                {
                    "id": 13666745,
                    "contents": "Autoionization of molecular hydrogen: where do the Fano lineshapes go?\nAtomic autoionization following photoabsorption is a typical example of quantum interferences governed by electron-electron correlation. Coherence between direct photoionization and autoionization paths results in \"Fano profiles\", widely explored in atoms in the last 60 years. The advent of femto- and attosecond laser technology made time-resolved images of the delayed electron ejection in autoionization accessible, leading to the reemergence of such studies in atomic systems. The counterpart molecular phenomena show the richness, as well as the complexity, added by nuclear motion, which may proceed on similar time scales. However, Fano profiles are usually absent in measured molecular photoionization cross sections and an unequivocal parametrization of molecular autoionization signatures, similar to that introduced by Fano in atoms [U. Fano, Phys. Rev. 1961, 124, 1866] has not yet been achieved. In this work we introduce a simple semiclassical model that accounts for all the features observed in H2 photoionization and demonstrate that the interference structures observed in dissociative ionization spectra are almost exclusively due to the phase accumulated in the nuclear motion. Furthermore, we show that the temporal build-up of these structures in the energy-differential cross sections is also determined by nuclear motion. We validate our models by comparing with full-dimensional ab initio calculations solving the time-dependent Schrödinger equation.",
                    "score": 0.8513161540031433
                },
                {
                    "id": 8738388,
                    "contents": "Bohr's 1913 molecular model revisited.\nIt is generally believed that the old quantum theory, as presented by Niels Bohr in 1913, fails when applied to few electron systems, such as the H(2) molecule. Here, we find previously undescribed solutions within the Bohr theory that describe the potential energy curve for the lowest singlet and triplet states of H(2) about as well as the early wave mechanical treatment of Heitler and London. We also develop an interpolation scheme that substantially improves the agreement with the exact ground-state potential curve of H(2) and provides a good description of more complicated molecules such as LiH, Li(2), BeH, and He(2).",
                    "score": 0.8512638807296753
                },
                {
                    "id": 11051952,
                    "contents": "H2 superexcited states: experimental and theoretical characterization of their competing decay-channel fluorescence, dissociation, and ionization.\nThe absolute cross sections for the competing decay channels fluorescence, dissociation, and ionization of photoexcited long-lived superexcited H(2) molecular levels have been measured from the ionization threshold of H(2) up to the H(1s)+H(n=3) dissociation limit. The total and partial natural widths of these levels have been determined. Good agreement is found with first principles calculations carried out by multichannel quantum defect theory. The calculations reproduce the balance between the competing decay processes as well as its substantial level-to-level evolution.",
                    "score": 0.851211428642273
                },
                {
                    "id": 7150464,
                    "contents": "Molecule without electrons: binding bare nuclei with strong laser fields.\nWe show how a carefully chosen combination of strong linearly and circularly polarized laser fields can bind two same-sign charges, not only suppressing their Coulomb repulsion in all three spatial dimensions, but also creating an effective attraction. As an example, we show how a molecule HD2+ stripped of both electrons can be kept bound by the laser fields.",
                    "score": 0.8509600758552551
                },
                {
                    "id": 13270175,
                    "contents": "Fundamental vibration of molecular hydrogen.\nThe fundamental ground tone vibration of H(2), HD, and D(2) is determined to an accuracy of 2×10(-4) cm(-1) from Doppler-free laser spectroscopy in the collisionless environment of a molecular beam. This rotationless vibrational splitting is derived from the combination difference between electronic excitation from the X(1)Σ(g)(+), v=0, and v=1 levels to a common EF(1)Σ(g)(+), v=0 level. Agreement within 1σ between the experimental result and a full ab initio calculation provides a stringent test of quantum electrodynamics in a chemically bound system.",
                    "score": 0.8507283926010132
                },
                {
                    "id": 5806313,
                    "contents": "The Absorption Spectrum of HDO in the 16 300-16 670 and 18 000-18 350 cm(-1) Spectral Regions.\nThe absorption spectrum of HDO has been recorded by Intracavity Laser Absorption Spectroscopy in the 16 300-16 670 and 18 000-18 350 cm(-1) spectral regions corresponding to the weak 2nu(2) + 4nu(3) and nu(2) + 5nu(3) bands, respectively. The nu(2) + 5nu(3) band centered at 18 208.434 cm(-1) was found almost isolated and has been satisfactorily reproduced in the frame of the effective Hamiltonian model. On the other hand, the 2nu(2) + 4nu(3) band at 16 456.201 cm(-1) is strongly perturbed as the (0 2 4) bright state is involved in a complex interaction scheme including the (1 0 4), (5 0 1), (1 5 2), and (1 11 0) states. The rovibrational assignment of these interacting states was greatly helped by the high-accuracy ab initio predictions performed by D. Schwenke and H. Partridge [J. Chem. Phys. 000-000 (2000)]. They could be partly modeled by an effective Hamiltonian which has allowed the assignment and reproduction of most of the observed transitions. Copyright 2000 Academic Press.",
                    "score": 0.850660502910614
                },
                {
                    "id": 18243825,
                    "contents": "Fundamental Transitions and Ionization Energies of the Hydrogen Molecular Ions with Few ppt Uncertainty.\nWe calculate ionization energies and fundamental vibrational transitions for H_{2}^{+}, D_{2}^{+}, and HD^{+} molecular ions. The nonrelativistic quantum electrodynamics expansion for the energy in terms of the fine structure constant α is used. Previous calculations of orders mα^{6} and mα^{7} are improved by including second-order contributions due to the vibrational motion of nuclei. Furthermore, we evaluate the largest corrections at the order mα^{8}. That allows us to reduce the fractional uncertainty to the level of 7.6×10^{-12} for fundamental transitions and to 4.5×10^{-12} for the ionization energies.",
                    "score": 0.8506020307540894
                },
                {
                    "id": 9749430,
                    "contents": "Spectroscopic observation and characterization of H(+)H(-) heavy Rydberg states.\nA series of discrete resonances was observed in the spectrum of H2, which can be unambiguously assigned to bound quantum states in the 1/R Coulombic potential of the H+H- ion-pair system. Two-step laser excitation was performed, using tunable extreme ultraviolet radiation at lambda = 94-96 nm in the first step, and tunable ultraviolet radiation in the range lambda = 310-350 nm in the second step. The resonances, detected via H+ and H2+ ions produced in the decay process, follow a sequence of principal quantum numbers (n = 140-230) associated with a Rydberg formula in which the Rydberg constant is mass scaled. The series converges upon the ionic H+H- dissociation threshold. This limit can be calculated without further assumptions from known ionization and dissociation energies in the hydrogen system and the electronegativity of the hydrogen atom. A possible excitation mechanism is discussed in terms of a complex resonance. Detailed measurements are performed to unravel and quantify the decay of the heavy Rydberg states into molecular H2+ ions, as well as into atomic fragments, both H(n = 2) and H(n = 3). Lifetimes are found to scale as n3.",
                    "score": 0.850200891494751
                }
            ],
            "metric_score": {
                "retrieval_recall": 1,
                "retrieval_precision": 0.4
            }
        }
    },
    {
        "id": "test_35",
        "question": "It turns out that the solution of the Schrödinger equation for the Morse potential can be expressed as\r\n$$\r\nG(v)=\\tilde{\\omega}_{\\mathrm{e}}\\left(v+\\frac{1}{2}\\right)-\\tilde{\\omega}_{\\mathrm{e}} \\tilde{x}_{\\mathrm{e}}\\left(v+\\frac{1}{2}\\right)^2\r\n$$\r\nChapter 5 / The Harmonic Oscillator and Vibrational Spectroscopy\r\nwhere\r\n$$\r\n\\tilde{x}_{\\mathrm{e}}=\\frac{h c \\tilde{\\omega}_{\\mathrm{e}}}{4 D}\r\n$$\r\nGiven that $\\tilde{\\omega}_{\\mathrm{e}}=2886 \\mathrm{~cm}^{-1}$ and $D=440.2 \\mathrm{~kJ} \\cdot \\mathrm{mol}^{-1}$ for $\\mathrm{H}^{35} \\mathrm{Cl}$, calculate $\\tilde{x}_{\\mathrm{e}}$ and $\\tilde{\\omega}_{\\mathrm{e}} \\tilde{x}_{\\mathrm{e}}$.",
        "golden_answers": [
            " 0.01961"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 22381144,
                    "contents": "Vibrational levels of a generalized Morse potential.\nA Generalized Morse Potential (GMP) is an extension of the Morse Potential (MP) with an additional exponential term and an additional parameter that compensate for MP's erroneous behavior in the long range part of the interaction potential. Because of the additional term and parameter, the vibrational levels of the GMP cannot be solved analytically, unlike the case for the MP. We present several numerical approaches for solving the vibrational problem of the GMP based on Galerkin methods, namely, the Laguerre Polynomial Method (LPM), the Symmetrized LPM, and the Polynomial Expansion Method (PEM), and apply them to the vibrational levels of the homonuclear diatomic molecules B<sub2</sub, O<sub2</sub, and F<sub2</sub, for which high level theoretical near full configuration interaction (CI) electronic ground state potential energy surfaces and experimentally measured vibrational levels have been reported. Overall, the LPM produces vibrational states for the GMP that are converged to within spectroscopic accuracy of 0.01 cm<sup-1</sup in between 1 and 2 orders of magnitude faster and with much fewer basis functions/grid points than the Colbert-Miller Discrete Variable Representation (CN-DVR) method for the three homonuclear diatomic molecules examined in this study. A Python library that fits and solves the GMP and similar potentials can be downloaded from https://gitlab.com/gds001uw/generalized-morse-solver.",
                    "score": 0.888512372970581
                },
                {
                    "id": 9050245,
                    "contents": "The Morse oscillator under time-dependent external fields.\nA method to solve the equations for the Morse oscillator under intense time-dependent external fields is presented. Exact analytical formulas for the dipole matrix elements are calculated by the use of the hypergeometric algebra. The continuum is described by an expansion using Laguerre functions. The full algorithm for the calculation of wave functions can be controlled by the convergence of series and by the errors of a first order integration method. We apply our technique to the selective preparation of high overtones by femtosecond laser pulses. The population of the target state is optimized as a function of the intensity and frequency. Introducing a second simultaneous laser, we study the effects of relative frequency and phase over the target state population and dissociation channels. The calculations exhibit a rich interference pattern showing the enhancement and the suppression of the target population by varying the laser parameters.",
                    "score": 0.8833029866218567
                },
                {
                    "id": 4411818,
                    "contents": "Modified Morse Potential for Diatomic Molecules.\nWe present a diatomic potential which closely resembles the standard Morse function but incorporates additional flexibility for fitting experimental vibrational energy-gap data. This flexibility is accommodated by introducing a continuously variable radially dependent change in the exponent of the Morse function, which in practice is adequately realized via a relatively small number of constant parameters. As an illustration, the method is applied to calculate the quantum vibrational levels of the X1Sigma+&lt;INF POS=\"STACK\"&gt;g ground electronic state of the N2 molecule. Copyright 1998 Academic Press.",
                    "score": 0.8819793462753296
                },
                {
                    "id": 16990884,
                    "contents": "Morse, Lennard-Jones, and Kratzer Potentials: A Canonical Perspective with Applications.\nCanonical approaches are applied to classic Morse, Lennard-Jones, and Kratzer potentials. Using the canonical transformation generated for the Morse potential as a reference, inverse transformations allow the accurate generation of the Born-Oppenheimer potential for the H<sub2</sub<sup+</sup ion, neutral covalently bound H<sub2</sub, van der Waals bound Ar<sub2</sub, and the hydrogen bonded one-dimensional dissociative coordinate in a water dimer. Similar transformations are also generated using the Lennard-Jones and Kratzer potentials as references. Following application of inverse transformations, vibrational eigenvalues generated from the Born-Oppenheimer potentials give significantly improved quantitative comparison with values determined from the original accurately known potentials. In addition, an algorithmic strategy based upon a canonical transformation to the dimensionless form applied to the force distribution associated with a potential is presented. The resulting canonical force distribution is employed to construct an algorithm for deriving accurate estimates for the dissociation energy, the maximum attractive force, and the internuclear separations corresponding to the maximum attractive force and the potential well.",
                    "score": 0.8772425055503845
                },
                {
                    "id": 12136738,
                    "contents": "Three-dimensional effective mass Schrödinger equation: harmonic and Morse-type potential solutions.\nIn this work, a scheme to generate exact wave functions and eigenvalues for the spherically symmetric three-dimensional position-dependent effective mass Schrödinger equation is presented. The methodology is implemented by means of separation of variables and point canonical transformations that allow to recognize a radial dependent equation with important differences as compared with the one-dimensional position dependent mass problem, which has been widely studied. This situation deserves to consider the boundary conditions of the emergent problem. To obtain specific exact solutions, the methodology requires known solutions of ordinary one-dimensional Schrödinger equations. We have preferred those applications that use the harmonic oscillator and the Morse oscillator solutions.",
                    "score": 0.8765218257904053
                },
                {
                    "id": 10539692,
                    "contents": "Analytic dynamics of the Morse oscillator derived by semiclassical closures.\nThe quantized Hamilton dynamics methodology [O. V. Prezhdo and Y. V. Pereverzev, J. Chem. Phys. 113, 6557 (2000)] is applied to the dynamics of the Morse potential using the SU(2) ladder operators. A number of closed analytic approximations are derived in the Heisenberg representation by performing semiclassical closures and using both exact and approximate correspondence between the ladder and position-momentum variables. In particular, analytic solutions are given for the exact classical dynamics of the Morse potential as well as a second-order semiclassical approximation to the quantum dynamics. The analytic approximations are illustrated with the O-H stretch of water and a Xe-Xe dimer. The results are extended further to coupled Morse oscillators representing a linear triatomic molecule. The reported analytic expressions can be used to accelerate classical molecular dynamics simulations of systems containing Morse interactions and to capture quantum-mechanical effects.",
                    "score": 0.8748706579208374
                },
                {
                    "id": 9056912,
                    "contents": "Computational method for the quantum Hamilton-Jacobi equation: bound states in one dimension.\nAn accurate computational method for the one-dimensional quantum Hamilton-Jacobi equation is presented. The Mobius propagation scheme, which can accurately pass through singularities, is used to numerically integrate the quantum Hamilton-Jacobi equation for the quantum momentum function. Bound state wave functions are then synthesized from the phase integral using the antithetic cancellation technique. Through this procedure, not only the quantum momentum functions but also the wave functions are accurately obtained. This computational approach is demonstrated through two solvable examples: the harmonic oscillator and the Morse potential. The excellent agreement between the computational and the exact analytical results shows that the method proposed here may be useful for solving similar quantum mechanical problems.",
                    "score": 0.8734502792358398
                },
                {
                    "id": 22887239,
                    "contents": "Nonrelativistic treatment of inversely quadratic Hellmann-Kratzer potential and thermodynamic properties.\nThe study presents approximate analytical solutions of the Schrödinger equation with a newly proposed potential model called Inversely Quadratic Hellmann-Kratzer potential (IQHKP). This potential is a superposition of Inversely Quadratic Hellman potential and Kratzer potential. The energy eigenvalues and corresponding wavefunction are calculated via the formula method. We applied our results to evaluate thermodynamic functions such as vibrational free energy, <iF</i, vibrational internal energy, <iU</i, vibrational entropy, <iS</i, and vibrational specific heat, <iC</i. We also reported special cases of importance.",
                    "score": 0.8693056106567383
                },
                {
                    "id": 19014961,
                    "contents": "Matrix elements for anharmonic potentials: Application to I<sub>2</sub> morse oscillator.\nMany authors have contributed expressions for obtaining analytical matrix elements for Morse oscillators. In this work, we discuss the advantages of using these expressions. At the same time, we propose a full numerical method to calculate these matrix elements and we compare, for the I<sub2</sub system, the different results given by Gallas, Vasan, and Cross, and the variational method.",
                    "score": 0.8674427270889282
                },
                {
                    "id": 9290082,
                    "contents": "A semiclassical study of wave packet dynamics in anharmonic potentials.\nClassical and semiclassical methods are developed to calculate and invert the wave packet motion measured in pump-probe experiments. With classical propagation of the Wigner distribution of the initial wave packet created by the pump pulse, we predict the approximate probe signal with slightly displaced recurrence peaks, and derive a set of first-order canonical perturbation expressions to relate the temporal features of the signal to the characteristics of the potential surface. A reduced dynamics scheme based on the Gaussian assumption leads to the correct center of mass motion but does not describe the evolution of the shape of the wave packet accurately. To incorporate the quantum interference into classical trajectories, we propose a final-value representation semiclassical method, specifically designed for the purpose of computing pump-probe signals, and demonstrate its efficiency and accuracy with a Morse oscillator and two kinetically coupled Morse oscillators. For the case of one-color pump probe, a simple phase-space quantization scheme is devised to reproduce the temporal profile at the left-turning point without actual wave packet propagation, revealing a quantum mechanical perspective of the nearly classical pump-probe signal.",
                    "score": 0.8670637607574463
                },
                {
                    "id": 23780143,
                    "contents": "Nonrelativistic solutions of Schrödinger equation and thermodynamic properties with the proposed modified Mobius square plus Eckart potential.\nWe obtain solutions of Schrödinger equation for the modified Mobius square plus Eckart (MMPSE) potential via the formula method. Numerical results are reported. In addition, the partition function <iZ</i and other thermodynamic properties such as vibrational free energy, <iF</i, vibrational internal energy, <iU</i, vibrational entropy, <iS</i, and vibrational specific heat, <iC</i are presented. We also discuss special cases of this potential. Our result is consistent with previous studies in the literature.",
                    "score": 0.8669614791870117
                },
                {
                    "id": 18868407,
                    "contents": "Dynamics of interacting electrons under effect of a Morse potential.\nWe consider interacting electrons moving in a nonlinear Morse lattice. We set the initial conditions as follows: electrons were initially localized at the center of the chain and a solitonic deformation was produced by an impulse excitation on the center of the chain. By solving quantum and classical equations for this system numerically, we found that a fraction of electronic wave function was trapped by the solitonic excitation, and trapping specificities depend on the degree of interaction among electrons. Also, there is evidence that the effective electron velocity depends on Coulomb interaction and electron-phonon coupling in a nontrivial way. This association is explained in detail along this work. In addition, we briefly discuss the dependence of our results with the type of initial condition we choose for the electrons and lattice.",
                    "score": 0.8662599325180054
                },
                {
                    "id": 6589673,
                    "contents": "Comparison between phase space structures in coupled Morse systems and in various su(2) approximations.\nWhile Hamiltonians written in terms of position and momentum provide a transparent picture of the motion of a system, Hamiltonians written in terms of Lie algebras are easier to handle quantum mechanically. Therefore we are interested to know how to transform one into the other. Since the exact transformation often leads to complicated expressions, we look for approximations which preserve the essential features. As basic criterion we look for the degree of equality of the classical phase space structures. We illustrate our ideas for the case of two coupled Morse systems and its approximation in terms of the Lie algebra su(2), which is relevant to anharmonic models of molecular spectroscopy. (c) 2001 American Institute of Physics.",
                    "score": 0.8662500977516174
                },
                {
                    "id": 17946607,
                    "contents": "Anharmonic vibrational eigenfunctions and infrared spectra from semiclassical molecular dynamics.\nWe describe a new approach based on semiclassical molecular dynamics that allows simulating infrared absorption or emission spectra of molecular systems with inclusion of anharmonic intensities. This is achieved from semiclassical power spectra by computing first the vibrational eigenfunctions as a linear combination of harmonic states, and then the oscillator strengths associated with the vibrational transitions. We test the approach against a 1D Morse potential and apply it to the water molecule with results in excellent agreement with discrete variable representation quantum benchmarks. The method does not require any grid calculations, and it is directly extendable to high dimensional systems. The usual exponential scaling of the basis set size with the dimensionality of the system can be avoided by means of an appropriate truncation scheme. Furthermore, the approach has the advantage to provide IR spectra beyond the harmonic approximation without losing the possibility of an intuitive assignment of absorption peaks in terms of normal modes of vibration.",
                    "score": 0.8646169304847717
                },
                {
                    "id": 5290388,
                    "contents": "The unexplained accuracy of the Lagrange-mesh method.\nThe Lagrange-mesh method is an approximate variational calculation which resembles a mesh calculation because of the use of a Gauss quadrature. In order to analyze its accuracy, four different Lagrange-mesh calculations based on the zeros of Laguerre polynomials are compared with exact variational calculations based on the corresponding Laguerre basis. The comparison is performed for three solvable radial potentials: the Morse, harmonic-oscillator, and Coulomb potentials. The results show that the accuracies of the energies obtained for different partial waves with the different mesh approximations are very close to the variational accuracy, even in the presence of the centrifugal singularity. The same property holds for the approximate wave functions. This striking accuracy remains unexplained.",
                    "score": 0.860461950302124
                },
                {
                    "id": 6070491,
                    "contents": "Divergence-free WKB method.\nA new semiclassical approach to the linear and nonlinear one-dimensional Schrödinger equation is presented. For both equations our zeroth-order solutions include nonperturbative quantum corrections to the WKB solution and the Thomas-Fermi solution, thereby allowing us to make uniformly converging perturbative expansions of the wave functions. Our method leads to a new quantization condition that yields exact eigenenergies for the harmonic-oscillator and Morse potentials.",
                    "score": 0.8599207997322083
                },
                {
                    "id": 5249715,
                    "contents": "Exact equilibrium statistical mechanics of two particles interacting via Lennard-Jones and Morse potentials.\nThe exact classical statistical phase-space volume is obtained for a finite system consisting of two particles interacting via both Lennard-Jones and Morse potentials and confined in a spherical volume. The case when the center of mass of the system is fixed at the center of the sphere is also considered. It is shown that the microcanonical caloric curve of the system can have properties similar to those of large clusters, and the equation of state of the system can have behavior similar to that of bulk systems. It is also shown that the fixing of the center of mass of the system can appreciably change the properties of the microcanonical caloric curve and the equation of state of the system.",
                    "score": 0.8579634428024292
                },
                {
                    "id": 8398301,
                    "contents": "Multidimensional reactive scattering with quantum trajectories: dynamics with Morse vibrational modes.\nThe reactive scattering of a wave packet is studied by the quantum trajectory method for a model system with up to 25 Morse vibrational modes. The equations of motion are formulated in curvilinear reaction path coordinates with the restriction to a planar reaction path. Spatial derivatives are evaluated by the least squares method using contracted basis sets. Dynamical results, including trajectory evolution and time-dependent reaction probabilities, are presented and analyzed. For the case of one Morse vibrational mode, the results are in good agreement with those derived through direct numerical integration of the time-dependent Schrodinger equation.",
                    "score": 0.8567857146263123
                },
                {
                    "id": 14830297,
                    "contents": "Pushing the limit for the grid-based treatment of Schrödinger's equation: a sparse Numerov approach for one, two and three dimensional quantum problems.\nThe general Numerov method employed to numerically solve ordinary differential equations of second order was adapted with a special focus on solving Schrödinger's equation. By formulating a hierarchy of novel stencil expressions for the numerical treatment of the Laplace operator in one, two and three dimensions the method could not only be simplified over the standard Numerov scheme. The improved framework enables the natural use of matrix sparsity to reduce the memory demand and the associated computing time, thus enabling the application of the method to larger problems. The performance of the adapted method is demonstrated using exemplary harmonic and Morse problems in one and two dimensions. Furthermore, the vibrational frequencies of molecular hydrogen and water are calculated, inherently considering the influence of anharmonicity, mode-mode coupling and nuclear quantum effects. The estimation of the tunneling splitting in malonaldehyde serves as an example for a two-dimensional problem.",
                    "score": 0.8556703925132751
                },
                {
                    "id": 4491552,
                    "contents": "Solution of the relativistic Dirac-Morse problem.\nThe Dirac equation for a charged particle in a static electromagnetic field is written for the special case of a spherically symmetric potential. Besides the well-known Dirac-Coulomb and Dirac-oscillator potentials, we obtain a relativistic version of the S-wave Morse potential. This is accomplished by adding a simple exponential potential term to the Dirac operator, which in the nonrelativistic limit reproduces the usual Morse potential. The relativistic bound-states spectrum and spinor wave functions are obtained.",
                    "score": 0.8552778363227844
                },
                {
                    "id": 23307875,
                    "contents": "Morse potential specific heat with applications: an integral equations theory based.\nThe specific heat in its molar form or mass form is a significant thermal property in the study of the thermal capacity of the described system. There are two basic methods for the determination of the molar specific heat capacity, one of them is the experimental procedure and the other is the theoretical procedure. The present study deals with finding a formula of the molar specific heat capacity using the theory of the integral equations for Morse interaction which is a very important potential for the study of the general oscillations in the quantum mechanics. We use the approximation (Mean-Spherical) for finding the total energy of the compositions described by Morse interaction. We find two formulas of the heat capacity, one at a constant pressure and the other at a constant volume. We conclude that the Morse molar specific heat is temperature dependent via the inverse square low with respect to temperature. Besides, we find that the Morse molar specific heat is proportional to the square of the Morse interaction well depth. Also, we find that the Morse molar specific heat depends on the particles' diameter, the bond distance of Morse interaction, the width parameter of Morse interaction, and the volumetric density of the system. We apply the formula of the specific heat for finding the specific heat of the vibrational part for two dimer which are the lithium and caesium dimers and for the hydrogen fluoride, hydrogen chloride, nitrogen, and hydrogen molecules.",
                    "score": 0.8535232543945312
                },
                {
                    "id": 7748825,
                    "contents": "An optimized algebraic basis for molecular potentials.\nThe computation of vibrational spectra of diatomic molecules through the exact diagonalization of algebraically determined matrices based on powers of Morse coordinates is made substantially more efficient by choosing a properly adapted quantum mechanical basis, specifically tuned to the molecular potential. A substantial improvement is achieved while still retaining the full advantage of the simplicity and numerical light-weightedness of an algebraic approach. In the scheme we propose, the basis is parametrized by two quantities which can be adjusted to best suit the molecular potential through a simple minimization procedure.",
                    "score": 0.8524851202964783
                },
                {
                    "id": 4491364,
                    "contents": "Numerically complemented analytic method for solving the time-independent one-dimensional Schrödinger equation.\nA general method of solving the one-dimensional Schrödinger equation is developed. The first step is to construct an exactly solvable reference potential of several smoothly joined Morse-type components, which should be a good approximation to a given potential. The exact solutions for that reference Hamiltonian are then combined with a nonperturbative approach [R. G. Gordon, J. Chem. Phys. 51, 14 (1969)], which enables us to numerically solve the energy eigenvalue problem for the original potential to any desired accuracy. A full description of the analytical procedures is given and examples of both exact and numerical solutions, are presented.",
                    "score": 0.8521429300308228
                },
                {
                    "id": 16183399,
                    "contents": "Mixed semiclassical initial value representation time-averaging propagator for spectroscopic calculations.\nA mixed semiclassical initial value representation expression for spectroscopic calculations is derived. The formulation takes advantage of the time-averaging filtering and the hierarchical properties of different trajectory based propagation methods. A separable approximation is then introduced that greatly reduces (about an order of magnitude) the computational cost compared with a full Herman-Kluk time-averaging semiclassical calculation for the same systems. The expression is exact for the harmonic case and it is tested numerically for a Morse potential coupled to one or two additional harmonic degrees of freedom. Results are compared to full Herman-Kluk time-averaging calculations and exact quantum wavepacket propagations. We found the peak positions of the mixed semiclassical approximations to be always in very good agreement with full quantum calculations, while overtone peak intensities are lower with respect to the exact ones. Given the reduced computational effort required by this new mixed semiclassical approximation, we believe the present method to make spectroscopic calculations available for higher dimensional systems than accessible before. ",
                    "score": 0.8519670367240906
                },
                {
                    "id": 10518778,
                    "contents": "Mori-Zwanzig formalism as a practical computational tool.\nAn operational procedure is presented to compute explicitly the different terms in the generalized Langevin equation (GLE) for a few relevant variables obtained within Mori-Zwanzig formalism. The procedure amounts to introducing an artificial controlled parameter which can be tuned in such a way that the so-called projected dynamics becomes explicit and the GLE reduces to a Markovian equation. The projected dynamics can be realised in practice by introducing constraints, and it is shown that the Green-Kubo formulae computed with these dynamics do not suffer from the plateau problem. The methodology is illustrated in the example of star polymer molecules in a melt using their center of mass as relevant variables. Through this example, we show that not only the effective potentials, but also the friction forces and the noise play a very important role in the dynamics.",
                    "score": 0.8507336378097534
                },
                {
                    "id": 9617257,
                    "contents": "Infinitesimal generators and quasi-units in potential theory.\nThe underlying structure is taken as a strongly superharmonic cone [unk], defined as a partially ordered abelian semigroup with identity 0 which admits a multiplication by nonnegative scalars and satisfies two fundamental axioms of a potentialtheoretic character. In terms of a fixed nonzero element e there is introduced on [unk] a one-parameter family of nonlinear operators S(lambda) (lambda &gt;/= 0) closely connected with the abstract theory of quasibounded and singular elements. The semigroup {S(lambda)} admits an infinitesimal generator A, and the elements invariant under A, called quasi-units, generalize the Yosida quasi-units in the theory of Riesz spaces. Quasi-units in [unk] are studied, both from a potentialtheoretic and a function-alanalytic viewpoint, culminating in a spectral representation theorem for quasi-bounded elements which extends the classical Freudenthal spectral theorem of Riesz space theory.",
                    "score": 0.8499554395675659
                },
                {
                    "id": 10666309,
                    "contents": "Formation of Schrödinger-cat states in the Morse potential: Wigner function picture.\nWe investigate the time evolution of Morse coherent states in the potential of the NO molecule. We present animated wave functions and Wigner functions of the system exhibiting spontaneous formation of Schrödinger-cat states at certain stages of the time evolution. These nonclassical states are coherent superpositions of two localized states corresponding to two di.erent positions of the center of mass. We analyze the degree of nonclassicality as the function of the expectation value of the position in the initial state. Our numerical calculations are based on a novel, essentially algebraic treatment of the Morse potential.",
                    "score": 0.848701536655426
                },
                {
                    "id": 8295872,
                    "contents": "Effects of anharmonicity on nonadiabatic electron transfer: a model.\nThe effect of anharmonicity in the intramolecular modes of a model system for exothermic intramolecular nonadiabatic electron transfer is probed by examining the dependence of the transition probability on the exoergicity. The Franck-Condon factor for the Morse potential is written in terms of the Gauss hypergeometric function both for a ground initial state and for the general case, and comparisons are made between the first-order perturbation theory results for transition probability for harmonic and Morse oscillators. These results are verified with quantum dynamical simulations using wave-packet propagations on a numerical grid. The transition-probability expression incorporating a high-frequency quantum mode and low-frequency medium mode is compared for Morse and harmonic oscillators in different temperature ranges and with various coarse-graining treatments of the delta function from the Fermi golden rule expression. We find that significant deviations from the harmonic approximation are expected for even moderately anharmonic quantum modes at large values of exoergicity. The addition of a second quantum mode of opposite displacement negates the anharmonic effect at small energy change, but in the inverted regime a significantly flatter dependence on exoergicity is predicted for anharmonic modes.",
                    "score": 0.8481131792068481
                },
                {
                    "id": 19986932,
                    "contents": "Analytic and numerical vibronic spectra from quasi-classical trajectory ensembles.\nThe truncated Wigner approximation to quantum dynamics in phase space is explored in the context of computing vibronic line shapes for monomer linear optical spectra. We consider multiple model potential forms including a shifted harmonic oscillator with both equal and unequal frequencies on the ground and excited state potentials as well as a shifted Morse potential model. For the equal-frequency shifted harmonic oscillator model, we derive an analytic expression for the exact vibronic line shape that emphasizes the importance of using a quantum mechanical distribution of phase space initial conditions. For the unequal-frequency shifted harmonic oscillator model, we are no longer able to obtain an exact expression for the vibronic line shape in terms of independent deterministic classical trajectories. We show how one can rigorously account for corrections to the truncated Wigner approximation through nonlinear responses of the line shape function to momentum fluctuations along a classical trajectory and demonstrate the qualitative improvement in the resulting spectrum when the leading-order quantum correction is included. Finally, we numerically simulate absorption spectra of a highly anharmonic shifted Morse potential model. We find that, while finite quantization and the dissociation limit are captured with reasonable accuracy, there is a qualitative breakdown of the quasi-classical trajectory ensemble's ability to describe the vibronic line shape when the relative shift in Morse potentials becomes large. The work presented here provides clarity on the origin of unphysical negative features known to contaminate absorption spectra computed with quasi-classical trajectory ensembles.",
                    "score": 0.8478089570999146
                },
                {
                    "id": 21614434,
                    "contents": "Solving the Schrödinger equation of the hydrogen molecule with the free-complement variational theory: essentially exact potential curves and vibrational levels of the ground and excited states of Π symmetry.\nFollowing a previous study of the Σ states (Phys. Chem. Chem. Phys., 2019, 21, 6327), we solved the Schrödinger equation (SE) of the hydrogen molecule in the ground and excited Π states using the free complement (FC) variational method. This method is a general method to solve the SE: the energies obtained are highly accurate and the potential energy curves dissociate correctly. The calculated energies are upper bound to the exact energies, and the wave functions at any distance are always orthogonal and Hamiltonian-orthogonal to those in the different states calculated in this study. Using the essentially exact potential energy curves, the vibrational energy levels of each state were calculated by solving the vibrational Schrödinger equation.",
                    "score": 0.8468332886695862
                },
                {
                    "id": 23761816,
                    "contents": "The <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mml:mi>γ</mml:mi></mml:math> function in quantum theory II. Mathematical challenges and paradoxa.\nWhile the square root of Dirac's <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:miδ</mml:mi</mml:math is not defined in any standard mathematical formalism, postulating its existence with some further assumptions defines a generalized function called <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:miγ</mml:mi <mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo)</mml:mo</mml:mrow </mml:math which permits a quasi-classical treatment of simple systems like the H atom or the 1D harmonic oscillator for which accurate quantum mechanical energies were previously reported. The so-defined <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:miγ</mml:mi <mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo)</mml:mo</mml:mrow </mml:math is neither a traditional function nor a distribution, and it remains to be seen that any consistent mathematical approaches can be set up to deal with it rigorously. A straightforward use of <mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"<mml:mrow<mml:miγ</mml:mi <mml:mo(</mml:mo <mml:mix</mml:mi <mml:mo)</mml:mo</mml:mrow </mml:math generates several paradoxical situations which are collected here. The help of the scientific community is sought to resolve these paradoxa.",
                    "score": 0.8465154767036438
                },
                {
                    "id": 18032108,
                    "contents": "Bound state solutions of Schrödinger equation with modified Mobius square potential (MMSP) and its thermodynamic properties.\nWe solved the Schrödinger equation with the modified Mobius square potential model using the modified factorization method. Within the framework of the Greene-Aldrich approximation for the centrifugal term and using a suitable transformation scheme, we obtained the energy eigenvalues equation and the corresponding eigenfunction in terms of the hypergeometric function. Using the resulting eigenvalues equation, we calculated the vibrational partition function and other relevant thermodynamic properties. We also showed that the modified Mobius square potential can be reduced to the Hua potential model using appropriate potential constant values.",
                    "score": 0.8463529944419861
                },
                {
                    "id": 21320302,
                    "contents": "Position-dependent mass Schrödinger equation for exponential-type potentials.\nIn quantum chemical calculations, there are two facts of particular relevance: the position-dependent mass Schrödinger equation (PDMSE) and the exponential-type potentials used in the theoretical study of vibrational properties for diatomic molecules. Accordingly, in this work, the treatment of exactly solvable PDMSE for exponential-type potentials is presented. The proposal is based on the exactly solvable constant mass Schrödinger equation (CMSE) for a class of multiparameter exponential-type potentials, adapted to the position-dependent-mass (PDM) kinetic energy operator in the O von Roos formulation. As a useful application, we consider a PDM distribution of the form [Formula: see text], where the different parameters can be adjusted depending on the potential under study. The principal advantage of the method is that solution of different specific PDM exponential potential models are obtained as particular cases from the proposal by means of a simple choice of the involved exponential parameters. This means that is not necessary resort to specialized methods for solving second-order differential equations as usually done for each specific potential. Also, the usefulness of our results is shown with the calculation of s-waves scattering cross-section for the Hulthén potential although this kind of study can be extended to other specific potential models such as PDM deformed potentials.",
                    "score": 0.8455624580383301
                },
                {
                    "id": 16427892,
                    "contents": "[In Process Citation].\nA novel model for the analysis of the rovibrational structure of a molecule based on anharmonic ladder operators associated with the vibrational degrees of freedom is presented. This is devised as an alternative method for the global spectral analysis of rovibrational data considering vibrational anharmonicities from the outset. The present method is thought up with an effective rovibrational Hamiltonian written in terms of angular momentum components and anharmonic Morse ladder operators, associated with rotational and vibrational degrees of freedom, respectively. The resulting Hamiltonian is diagonalized in a symmetry-adapted basis set expressed as a product of rotational states and individual 1D-Morse wave functions for each local vibrational degree of freedom. This approach has been successfully applied to the study of the vibrational structure (up to polyad 14) and the rovibrational structure (up to polyad 2 and J(max) = 20) of hydrogen sulfide. It was shown that this new global analysis formalism is able to reduce considerably the number of fitted parameters with respect to the spectral analysis carried out for separate polyads. ",
                    "score": 0.8450338840484619
                },
                {
                    "id": 15496582,
                    "contents": "Effect of curve crossing induced dissociation on absorption and resonance Raman spectra: An analytically solvable model.\nAn analytically solvable model for the crossing of a harmonic and a Morse potential coupled by Dirac Delta function has been proposed. Further we explore the electronic absorption spectra and resonance Raman excitation profile using this model and found that curve crossing had significant effect on the resonance Raman excitation profile. ",
                    "score": 0.8448349833488464
                },
                {
                    "id": 21902264,
                    "contents": "Balancing long-range interactions and quantum pressure: Solitons in the Hamiltonian mean-field model.\nThe Hamiltonian mean-field (HMF) model describes particles on a ring interacting via a cosine interaction, or equivalently, rotors coupled by infinite-range XY interactions. Conceived as a generic statistical mechanical model for long-range interactions such as gravity (of which the cosine is the first Fourier component), it has recently been used to account for self-organization in experiments on cold atoms with long-range optically mediated interactions. The significance of the HMF model lies in its ability to capture the universal effects of long-range interactions and yet be exactly solvable in the canonical ensemble. In this work we consider the quantum version of the HMF model in one dimension and provide a classification of all possible stationary solutions of its generalized Gross-Pitaevskii equation (GGPE), which is both nonlinear and nonlocal. The exact solutions are Mathieu functions that obey a nonlinear relation between the wave function and the depth of the mean-field potential, and we identify them as bright solitons. Using a Galilean transformation these solutions can be boosted to finite velocity and are increasingly localized as the mean-field potential becomes deeper. In contrast to the usual local GPE, the HMF case features a tower of solitons, each with a different number of nodes. Our results suggest that long-range interactions support solitary waves in a novel manner relative to the short-range case.",
                    "score": 0.8441942930221558
                },
                {
                    "id": 6133489,
                    "contents": "Bosonization, vicinal surfaces, and hydrodynamic fluctuation theory.\nThrough a Euclidean path integral we establish that the density fluctuations of a Fermi fluid in one dimension are related to vicinal surfaces and to the stochastic dynamics of particles interacting through long range forces with inverse distance decay. In the surface picture one easily obtains the Haldane relation, and identifies the scaling exponents governing the low energy, Luttinger liquid behavior. For the stochastic particle model we develop a hydrodynamic fluctuation theory, through which in some cases the large distance Gaussian fluctuations are proved nonperturbatively.",
                    "score": 0.8437831401824951
                },
                {
                    "id": 11187357,
                    "contents": "Spectral and entropic characterizations of Wigner functions: applications to model vibrational systems.\nThe Wigner function for the pure quantum states is used as an integral kernel of the non-Hermitian operator K, to which the standard singular value decomposition (SVD) is applied. It provides a set of the squared singular values treated as probabilities of the individual phase-space processes, the latter being described by eigenfunctions of KK(+) (for coordinate variables) and K(+)K (for momentum variables). Such a SVD representation is employed to obviate the well-known difficulties in the definition of the phase-space entropy measures in terms of the Wigner function that usually allows negative values. In particular, the new measures of nonclassicality are constructed in the form that automatically satisfies additivity for systems composed of noninteracting parts. Furthermore, the emphasis is given on the geometrical interpretation of the full entropy measure as the effective phase-space volume in the Wigner picture of quantum mechanics. The approach is exemplified by considering some generic vibrational systems. Specifically, for eigenstates of the harmonic oscillator and a superposition of coherent states, the singular value spectrum is evaluated analytically. Numerical computations are given for the nonlinear problems (the Morse and double well oscillators, and the Henon-Heiles system). We also discuss the difficulties in implementation of a similar technique for electronic problems.",
                    "score": 0.8434095978736877
                },
                {
                    "id": 2177174,
                    "contents": "A modification to the COSMIC parameterisation using ab initio constrained potential functions.\nThe H..H non-bonded potential employed in the current COSMIC force field has been contrasted with H..H potentials used in a number of other force fields. Initial conversion of the variety of functions to a Morse format, achieved using a simple graphical fitting procedure, allowed a direct comparison to be made, showing the COSMIC potential to differ considerably from the other potentials. This difference was reflected in the failure of COSMIC to reproduce ab initio and experimental energies for molecules with significant H..H interactions, with particular reference to the energy curves of benzophenone and diphenyl ether. Considerable improvement in these energies is produced by the use of a Morse function originally based on the H..H potential used in MM3.",
                    "score": 0.8432241082191467
                },
                {
                    "id": 11337156,
                    "contents": "Exactly and quasi-exactly solvable 'discrete' quantum mechanics.\nA brief introduction to discrete quantum mechanics is given together with the main results on various exactly solvable systems. Namely, the intertwining relations, shape invariance, Heisenberg operator solutions, annihilation/creation operators and dynamical symmetry algebras, including the q-oscillator algebra and the Askey-Wilson algebra. A simple recipe to construct exactly and quasi-exactly solvable (QES) Hamiltonians in one-dimensional 'discrete' quantum mechanics is presented. It reproduces all the known Hamiltonians whose eigenfunctions consist of the Askey scheme of hypergeometric orthogonal polynomials of a continuous or a discrete variable. Several new exactly and QES Hamiltonians are constructed. The sinusoidal coordinate plays an essential role.",
                    "score": 0.842420220375061
                },
                {
                    "id": 13715364,
                    "contents": "The Ehrenfest force field: Topology and consequences for the definition of an atom in a molecule.\nThe Ehrenfest force is the force acting on the electrons in a molecule due to the presence of the other electrons and the nuclei. There is an associated force field in three-dimensional space that is obtained by the integration of the corresponding Hermitian quantum force operator over the spin coordinates of all of the electrons and the space coordinates of all of the electrons but one. This paper analyzes the topology induced by this vector field and its consequences for the definition of molecular structure and of an atom in a molecule. Its phase portrait reveals: that the nuclei are attractors of the Ehrenfest force, the existence of separatrices yielding a dense partitioning of three-dimensional space into disjoint regions, and field lines connecting the attractors through these separatrices. From the numerical point of view, when the Ehrenfest force field is obtained as minus the divergence of the kinetic stress tensor, the induced topology was found to be highly sensitive to choice of gaussian basis sets at long range. Even the use of large split valence and highly uncontracted basis sets can yield spurious critical points that may alter the number of attraction basins. Nevertheless, at short distances from the nuclei, in general, the partitioning of three-dimensional space with the Ehrenfest force field coincides with that induced by the gradient field of the electron density. However, exceptions are found in molecules where the electron density yields results in conflict with chemical intuition. In these cases, the molecular graphs of the Ehrenfest force field reveal the expected atomic connectivities. This discrepancy between the definition of an atom in a molecule between the two vector fields casts some doubts on the physical meaning of the integration of Ehrenfest forces over the basins of the electron density.",
                    "score": 0.8419668674468994
                },
                {
                    "id": 22591323,
                    "contents": "Spectral Functions of the Holstein Polaron: Exact and Approximate Solutions.\nIt is generally accepted that the dynamical mean field theory gives a good solution of the Holstein model, but only in dimensions greater than two. Here, we show that this theory, which becomes exact in the weak coupling and in the atomic limit, provides an excellent, numerically cheap, approximate solution for the spectral function of the Holstein model in the whole range of parameters, even in one dimension. To establish this, we make a detailed comparison with the spectral functions that we obtain using the newly developed momentum-space numerically exact hierarchical equations of motion method, which yields electronic correlation functions directly in real time. We crosscheck these conclusions with our path integral quantum Monte Carlo and exact diagonalization results, as well as with the available numerically exact results from the literature.",
                    "score": 0.8418914079666138
                },
                {
                    "id": 18331342,
                    "contents": "The topology of the Coulomb potential density. A comparison with the electron density, the virial energy density, and the Ehrenfest force density.\nThe topology of the Coulomb potential density has been studied within the context of the theory of Atoms in Molecules and has been compared with the topologies of the electron density, the virial energy density and the Ehrenfest force density. The Coulomb potential density is found to be mainly structurally homeomorphic with the electron density. The Coulomb potential density reproduces the non-nuclear attractor which is observed experimentally in the molecular graph of the electron density of a Mg dimer, thus, for the first time ever providing an alternative and energetic foundation for the existence of this critical point. © 2017 Wiley Periodicals, Inc.",
                    "score": 0.840950608253479
                },
                {
                    "id": 18828377,
                    "contents": "Connecting the Dunham Expansion to the Dissociation Limit for Interatomic Potentials: Application to Lennard-Jones m- n Potentials.\nDunham generated the expansion for energy levels of a rotating, vibrating diatomic molecule from an expansion of the potential about the equilibrium position. For partition functions, however, the energy levels are needed all the way to dissociation. Analytic Morse oscillator energies are not very useful because the exponential decay of the Morse potential is much too short-ranged for any physical system. The longer-range Lennard-Jones 12-6 potential could be used, but quantum energies have not previously been conveniently fit. I show how Dunham coefficients begin a set of asymptotic functions for any interaction potential, one function arising from each successive term in the WKB expansion. I apply this to the family of Lennard-Jones m- n (LJ m- n) potentials with an R<sup-m</sup repulsive term and R<sup-n</sup attractive term ( m &gt; n) and demonstrate how m can be used as a parameter to adjust either the equilibrium distance or harmonic frequency. I present an empirical parametrization of LJ m- n vibrotor energies starting with Dunham coefficients generated from four terms in the WKB expansion. This information is combined with data from numerically solved energies and asymptotic limits to fit the functions all the way to dissociation. One can also treat exp-6 and similar model potentials with different repulsive parts using the same method because the expansion form is controlled by the long-range part of the potential.",
                    "score": 0.8407560586929321
                },
                {
                    "id": 21571118,
                    "contents": "Koopman wavefunctions and classical-quantum correlation dynamics.\nUpon revisiting the Hamiltonian structure of classical wavefunctions in Koopman-von Neumann theory, this paper addresses the long-standing problem of formulating a dynamical theory of classical-quantum coupling. The proposed model not only describes the influence of a classical system onto a quantum one, but also the reverse effect-the quantum backreaction. These interactions are described by a new Hamiltonian wave equation overcoming shortcomings of currently employed models. For example, the density matrix of the quantum subsystem is always positive definite. While the Liouville density of the classical subsystem is generally allowed to be unsigned, its sign is shown to be preserved in time for a specific infinite family of hybrid classical-quantum systems. The proposed description is illustrated and compared with previous theories using the exactly solvable model of a degenerate two-level quantum system coupled to a classical harmonic oscillator.",
                    "score": 0.8407450914382935
                },
                {
                    "id": 13238919,
                    "contents": "Natural occupation numbers: when do they vanish?\nThe non-vanishing of the natural orbital (NO) occupation numbers of the one-particle density matrix of many-body systems has important consequences for the existence of a density matrix-potential mapping for nonlocal potentials in reduced density matrix functional theory and for the validity of the extended Koopmans' theorem. On the basis of Weyl's theorem we give a connection between the differentiability properties of the ground state wavefunction and the rate at which the natural occupations approach zero when ordered as a descending series. We show, in particular, that the presence of a Coulomb cusp in the wavefunction leads, in general, to a power law decay of the natural occupations, whereas infinitely differentiable wavefunctions typically have natural occupations that decay exponentially. We analyze for a number of explicit examples of two-particle systems that in case the wavefunction is non-analytic at its spatial diagonal (for instance, due to the presence of a Coulomb cusp) the natural orbital occupations are non-vanishing. We further derive a more general criterium for the non-vanishing of NO occupations for two-particle wavefunctions with a certain separability structure. On the basis of this criterium we show that for a two-particle system of harmonically confined electrons with a Coulombic interaction (the so-called Hookium) the natural orbital occupations never vanish. ",
                    "score": 0.840564489364624
                },
                {
                    "id": 12323486,
                    "contents": "Polyad quantum numbers and multiple resonances in anharmonic vibrational studies of polyatomic molecules.\nIn the theory of anharmonic vibrations of a polyatomic molecule, mixing the zero-order vibrational states due to cubic, quartic and higher-order terms in the potential energy expansion leads to the appearance of more-or-less isolated blocks of states (also called polyads), connected through multiple resonances. Such polyads of states can be characterized by a common secondary integer quantum number. This polyad quantum number is defined as a linear combination of the zero-order vibrational quantum numbers, attributed to normal modes, multiplied by non-negative integer polyad coefficients, which are subject to definition for any particular molecule. According to Kellman's method [J. Chem. Phys. 93, 6630 (1990)], the corresponding formalism can be conveniently described using vector algebra. In the present work, a systematic consideration of polyad quantum numbers is given in the framework of the canonical Van Vleck perturbation theory (CVPT) and its numerical-analytic operator implementation for reducing the Hamiltonian to the quasi-diagonal form, earlier developed by the authors. It is shown that CVPT provides a convenient method for the systematic identification of essential resonances and the definition of a polyad quantum number. The method presented is generally suitable for molecules of significant size and complexity, as illustrated by several examples of molecules up to six atoms. The polyad quantum number technique is very useful for assembling comprehensive basis sets for the matrix representation of the Hamiltonian after removal of all non-resonance terms by CVPT. In addition, the classification of anharmonic energy levels according to their polyad quantum numbers provides an additional means for the interpretation of observed vibrational spectra. ",
                    "score": 0.8403521776199341
                },
                {
                    "id": 7833191,
                    "contents": "On the emergence of molecular structure from atomic shape in the 1/r2 harmonium model.\nThe formal similarity of the three-body Hamiltonians for helium and the hydrogen molecule ion is used to demonstrate the unfolding of a rotating dumbbell-like proton distribution from a (1s)2-type electron distribution by smooth variation of the particles' masses in the 1/r2 harmonium model. The 1/r2 harmonium is an exactly solvable modification of the harmonium model (also known as Hooke's law atom) where the attraction between different particles is harmonic and the repulsion between the two equal particles is given by a 1/r2 potential. The dumbbell-like molecular structure appears as an expression of increasing spatial correlation due to increasing mass. It gradually appears in the one-density distribution of the two equal particles if their mass exceeds a critical value depending on the mass of the third particle. For large mass of the equal particles, their one-density distribution approaches an asymptotic form derived from the Born-Oppenheimer treatment of H2+ in the 1/r2 harmonium model. Below the critical value, the one density is a spherical, Gaussian-type atomic density distribution with a maximum at the center of mass. The topological transition at the critical value separates molecular structure and atomic shape as two qualitatively different manifestations of spatial structure.",
                    "score": 0.8403252363204956
                },
                {
                    "id": 7783523,
                    "contents": "Charged particle in a magnetic field: Jarzynski equality.\nWe describe some solvable models which illustrate the Jarzynski theorem and related fluctuation theorems. We consider a charged particle in the presence of a magnetic field in a two-dimensional harmonic well. In the first case the center of the harmonic potential is translated with a uniform velocity, while in the other case the particle is subjected to an ac force. We show that the Jarzynski identity complements the Bohr-van Leeuwen theorem on the absence of diamagnetism in an equilibrium classical system.",
                    "score": 0.8398331999778748
                },
                {
                    "id": 5249404,
                    "contents": "von neumann equations with time-dependent hamiltonians and supersymmetric quantum mechanics\nStarting with a time-independent Hamiltonian h and an appropriately chosen solution of the von Neumann equation irho;(t)=[h,rho(t)] we construct its binary-Darboux partner h(1)(t) and an exact scattering solution of irho;(1)(t)=[h(1)(t),rho(1)(t)], where h(1)(t) is time dependent and not isospectral to h. The method is analogous to supersymmetric quantum mechanics but is based on a different version of a Darboux transformation. We illustrate the technique by the example where h corresponds to a one-dimensional harmonic oscillator. The resulting h(1)(t) represents a scattering of a solitonlike pulse on a three-level system.",
                    "score": 0.8397855758666992
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_36",
        "question": " In the infrared spectrum of $\\mathrm{H}^{127} \\mathrm{I}$, there is an intense line at $2309 \\mathrm{~cm}^{-1}$. Calculate the force constant of $\\mathrm{H}^{127} \\mathrm{I}$.",
        "golden_answers": [
            "313"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 7644135,
                    "contents": "The electronic spectrum of AuO: a combined theoretical and experimental study.\nThe near-infrared electronic spectrum of AuO(1) has been re-examined in light of the new microwave data on the v = 0 and v = 1 vibrations of the X(2)Pi(3/2) state of AuO. The two observed bands in the spectrum, with red-degraded bandheads located at 10726 and 10665 cm(-1), have been reanalyzed. New theoretical work on AuO clarifies the electronic structure, and the bands in the infrared are now assigned as the (0,1) and (1,2) bands of the a(4)Sigma(-)(3/2) - X(2)Pi(3/2) transition, respectively.",
                    "score": 0.8729975819587708
                },
                {
                    "id": 22817396,
                    "contents": "Infrared intensities of [Formula: see text]: a true challenge for DFT methods.\nAbsolute infrared intensities of [Formula: see text] were evaluated with a great variety of DFT and ab initio methods and basis sets. It is shown that the intensities calculated by different levels of theory may not agree with each other even in the qualitative (weak/strong) sense. Geometrical parameters, as well as net atomic charges evaluated from multiple partition schemes, did not vary as much as the intensities and thus cannot explain the tremendous differences found for the latter. As there are no experimental estimates for the intensities to guide the theoretical evaluation, deciding on the best level of theory is reduced to comparisons between the different DFT methods and QCISD or CCSD, believed to be the best theoretical estimates in the set. The differences found among the various DFT methods suggest the development of new methods, instead of converging to a focal point, is rather diverging.",
                    "score": 0.8681044578552246
                },
                {
                    "id": 4766640,
                    "contents": "The Far Infrared Spectrum of HOCl: Line Positions and Intensities.\nThe far infrared spectrum of HOCl has been recorded at high resolution between 20 and 360 cm-1 by means of Fourier transform spectroscopy, and it was possible to observe pure rotation lines involving rotational levels with high Ka quantum numbers (up to Ka = 9). These lines combined with microwave and tunable far infrared data available in the literature were least squares fitted using a Watson-type Hamiltonian. The fitting leads to precise sets of rotational and centrifugal distortion constants for the ground states of both isotopomers HO35Cl and HO37Cl. Also relative line intensities were measured and their fitting allowed the determination of rotational corrections to the b-component of the permanent transition moment. Finally, to get Hamiltonian constants consistent with the newly determined ground state constants for the (100), (010), (001) vibrational states, available data concerning the nu1, nu2, and nu3 bands were refitted. Three interesting points are to be stressed. For the (001) state, we were able to complete the existing data with rotation lines observed in our spectra up to rather high Ka values (Ka = 7). For HO35Cl, we were able to show that some (010) and (100) levels are perturbed by levels of the (002) and (030) states, respectively, through Coriolis-type interactions. This allows the determination of the band centers of these two dark states. Copyright 1998 Academic Press.",
                    "score": 0.8639422059059143
                },
                {
                    "id": 15682944,
                    "contents": "A VPT2 route to near-infrared spectroscopy: the role of mechanical and electrical anharmonicity.\nFollowing the previous developments to simulate fully anharmonic spectra within the vibrational second-order perturbation level of theory [ J. Chem. Phys. 2012 , 126 , 134108 ], an extension to transitions up to three quanta is presented here. A general formulation including the mechanical and electrical anharmonicities is adopted to facilitate the support of additional properties, and thus spectroscopies. In addition to providing more accurate theoretical band shapes, inclusion of overtones and combination bands up to three quanta paves the way to a more complete interpretation of near-infrared spectra. ",
                    "score": 0.8636001348495483
                },
                {
                    "id": 14398063,
                    "contents": "Theory untangles the high-resolution infrared spectrum of the ortho-H2-CO van der Waals complex.\nRovibrational spectroscopy of molecules boasts extremely high precision, but its usefulness relies on the assignment of spectral features to corresponding quantum mechanical transitions. In the case of ortho-H(2)-CO, a weakly bound complex abundant in the interstellar medium (although not yet observed there), the rather complex spectrum has been unexplained for more than a decade. We assigned this spectrum by comparison with a purely ab initio calculation. For most lines, agreement to within 0.01 centimeter(-1) between experiment and theory was achieved. Our results show that the applicability of rovibrational spectroscopy can be extended with the assistance of high-accuracy quantum mechanical computations.",
                    "score": 0.8633352518081665
                },
                {
                    "id": 17501904,
                    "contents": "An effective semiclassical approach to IR spectroscopy.\nWe present a novel approach to calculate molecular infrared (IR) spectra based on semiclassical (SC) molecular dynamics. The main advance from a previous SC method [M. Micciarelli et al. J. Chem. Phys. 149, 064115 (2018)] consists of the possibility to avoid state-to-state calculations making applications to systems characterized by sizable densities of vibrational states feasible. Furthermore, this new method accounts not only for positions and intensities of the several absorption bands which make up the IR spectrum but also for their shapes. We show that accurate SC IR spectra including quantum effects and anharmonicities for both frequencies and intensities can be obtained starting from SC power spectra. The approach is first tested against the water molecule and then applied to the 10-atom glycine amino acid.",
                    "score": 0.8620766997337341
                },
                {
                    "id": 20288457,
                    "contents": "Infrared and NMR Spectroscopic Fingerprints of the Asymmetric H<sub>7</sub> <sup>+</sup> O<sub>3</sub> Complex in Solution.\nThe front cover artwork is provided by the groups of Prof. Ehud Pines (BGU, Israel) and Dr. Benjamin Fingerhut (MBI, Berlin). The image shows a scientist integrating experiments with theory for resolving the structural diffusion of the aqueous proton in acetonitrile providing a novel view on the Grotthuss mechanism. Read the full text of the Article at 10.1002/cphc.202001046.",
                    "score": 0.8619014620780945
                },
                {
                    "id": 20863164,
                    "contents": "Advances in Near-Infrared Spectroscopy and Related Computational Methods.\nOver the last few decades, near-infrared (NIR) spectroscopy has distinguished itself as one of the most rapidly advancing spectroscopic techniques [...].",
                    "score": 0.8614599108695984
                },
                {
                    "id": 6603389,
                    "contents": "Electron transfer and dynamic infrared-band coalescence: it looks like dynamic NMR spectroscopy, but a billion times faster.\nBroadening and coalescence of infrared bands can occur due to chemical exchange processes occurring on very fast, femtosecond-to-picosecond timescales. One such fast process of recent investigation is intramolecular electron transfer in transition-metal complexes with strong communication between electron-donor and -acceptor sites. The observation of partial coalescence of metal-carbonyl stretching bands in hexanuclear ruthenium mixed-valence complexes due to electron-transfer rates on the order of 10(11)-10(12) s(-1) is chronicled here. Several important advances have been made with the aid of dynamic infrared-band coalescence in these complexes, including the observation of dynamic solvent relaxation effects on electron-transfer rates, the determination of the equilibrium constant between charge-transfer isomers, and a reconsideration of the theory of electron transfer and delocalization in bridged, near-delocalized electron-transfer systems.",
                    "score": 0.8598666787147522
                },
                {
                    "id": 10966478,
                    "contents": "Infrared spectrometry.\nA brief history of the early work on Fourier spectroscopy at the Johns Hopkins University is given as well as a general description of the techniques of Fourier and Hadamard transform spectroscopy. The techniques of tunable diode laser spectroscopy and the difference frequency technique for IR spectral studies are also briefly described including some of their characteristics.",
                    "score": 0.8594970703125
                },
                {
                    "id": 5416544,
                    "contents": "Radiofrequency, Centimeter-Wave, Millimeter-Wave, and Infrared Spectra of SiHF(3): Investigation of the Ground, v(4) = 1, and v(6) = 1 Vibrational States.\nThe present paper deals with the analysis of the microwave, millimeter-wave, and infrared spectra of (28)SiHF(3) in its ground, v(6) = 1 and v(4) = 1 excited states. The former was observed up to 1055 GHz leading to the determination of one octic centrifugal distortion constant, L(J) = -0.0749(55) µHz. Furthermore the &lt;k ||H ||k +/- 6&gt; interaction term ||h(3,GS) || = 1.1032(70) mHz has been fitted from splittings of six K = 3 lines. The excited states have been regarded as isolated ones. This enabled fits according the Q-, D-, and QD-reduction schemes proposed by E. I. Lobodenko, O. N. Sulakshina, V. I. Perevalov, and Vl. G. Tyuterev, (J. Mol. Spectrosc. 126, 159-170 (1987)) and further developed by J. K. G. Watson, C. Gerke, H. Harder, and K. Sarka, (J. Mol. Spectrosc. 187, 131-141 (1997)) and Harder (J. Mol. Spectrosc. 194, 145 (1999)). A multiple fit analysis was performed confirming the assumption that the excited states are not affected by intervibrational resonances. Finally the millimeter spectrum of (29)SiHF(3) and (30)SiHF(3) in their ground state was also measured up to 460 GHz and accurate rotational and centrifugal distortion parameters were derived. Copyright 2000 Academic Press.",
                    "score": 0.8592695593833923
                },
                {
                    "id": 5397356,
                    "contents": "Rovibrational Intensities of the (00(0)3) &lt;-- (10(0)0) Dyad Absorption Bands of (12)C(16)O(2).\nAbsolute line intensities of (12)C(16)O(2) are experimentally measured for the first time for the (00(0)3)(I) &lt;-- (10(0)0)(II) band at 5687.17 cm(-1) and the (00(0)3)(I) &lt;-- (10(0)0)(I) band at 5584.39 cm(-1). The spectra were obtained using a Bomem DA8 Fourier transform spectrometer and a 25-m base-path White cell at NASA-Ames Research Center. The rotationless bandstrengths at a temperature of 296 K and the Herman-Wallis parameters are S(0)(vib) = 6.68(30) x 10(-25) cm(-1)/(molecule/cm(2)); A(1) = 1.4(9) x 10(-4), and A(2) = -1.1(5) x 10(-5) for the (00(0)3)(I) &lt;-- (10(0)0)(II) band and S(0)(vib) = 6.07(22) x 10(-25) cm(-1)/(molecule/cm(2)); A(1) = 5.2(1.5) x 10(-4) and A(2) = -4.0(7) x 10(-5) for the (00(0)3)(I) &lt;-- (10(0)0)(I) band.",
                    "score": 0.8591902256011963
                },
                {
                    "id": 12406243,
                    "contents": "Far-infrared spectrum of S(CN)2 measured with synchrotron radiation: global analysis of the available high-resolution spectroscopic data.\nThe high resolution Fourier transform spectrum of the chemically challenging sulfur dicyanide, S(CN)2, molecule was recorded at the far-infrared beamline of the synchrotron at the Canadian Light Source. The spectrum covered 50-350 cm(-1), and transitions in three fundamentals, ν4, ν7, and ν8, as well as in the hot-band sequence (n + 1)ν4 - nν4, n = 1-4, have been assigned and measured. Global analysis of over 21,300 pure rotation and rotation vibration transitions allowed determination of precise energies for 12 of the lowest vibrationally excited states of S(CN)2, including the five lowest fundamentals. These results constitute an extensive set of benchmarks for ab initio anharmonic force field calculations and the observed and calculated vibration-rotation constants and anharmonic frequencies are compared. The semiexperimental equilibrium, r(e)(SE), geometry of S(CN)2 has also been evaluated. In the course of the measurements, new information concerning the physical chemistry of S(CN)2 has been obtained.",
                    "score": 0.8578945398330688
                },
                {
                    "id": 5361901,
                    "contents": "Absolute Line Intensities in the 2nu3 Band of 16O12C32S\nThe strengths of 100 lines in the 2nu3 band of 16O12C32S have been measured at high resolution in the spectral range 4069-4118 cm-1, using a tunable difference-frequency laser spectrometer. These intensities were obtained by fitting Voigt profiles to the measured shapes of the lines. The vibrational transition moment [(2.141 &amp;plusmn; 0.020) x 10(-2) D] and the absolute intensity (16.19 &amp;plusmn; 0.24 cm-2 atm-1 at 296 K) of the 2nu3 band of 16O12C32S are determined from these linestrength measurements. Copyright 1997 Academic Press. Copyright 1997Academic Press",
                    "score": 0.8574656248092651
                },
                {
                    "id": 5825730,
                    "contents": "Infrared Absorption Spectroscopy of HNC in the Region 2.6 to 3.1 &amp;mgr;m\nThe HNC molecule was generated by the reaction of translationally hot H atoms with either ClCN or BrCN. The energetically rich HNC products were probed by time-resolved infrared laser absorption spectroscopy. This allowed for the spectroscopic analysis of 16 vibrational bands in the wavelength region 2.6 to 3.1 &amp;mgr;m and the identification of 8 new bands for HNC. The dependence of Gv, Bv, and Dv was fit to appropriate polynomials in the vibrational quantum numbers and l. No bands were identified in which the bend, nu2, and CN stretch, nu3, were simultaneously excited so that the spectroscopic constants depending on the interaction between these two vibrations could not be experimentally measured. Nevertheless, the observations of this work allow for an almost complete experimental determination of the quadratic spectroscopic constants of this simple but important molecule. Copyright 1997 Academic Press. Copyright 1997Academic Press",
                    "score": 0.857136607170105
                },
                {
                    "id": 16706384,
                    "contents": "Determination of spectroscopic band shapes using second derivatives, part I: theory.\nThe molecular spectra of water, aqueous solutions, hydrogen-bonded systems, and others have massive bands that contain many overlapping components. To decipher the spectra for molecular interpretation, it is necessary to separate these. Several attempts to do this have been made without clear success. To surmount some of the difficulties, we present a novel method, which consists of quantitatively evaluating the spectral band second-derivative profiles. This aids in the determination of the original band profiles: Gaussian, Lorentzian (Cauchy), and Gauss-Lorentz products. Then the number of components in a massive absorption, their shapes, and their positions can be determined. We tested the usefulness of the method in the visible region using calibration standards: a light emitting diode emission spectrum and a holmium chloride (HoCl2) solution. To verify its utility in the infrared region, we used liquid propanol, liquid acetonitrile, and aqueous acetone. ",
                    "score": 0.8559487462043762
                },
                {
                    "id": 9037032,
                    "contents": "Resolved: electronic states underneath broad absorptions.\nThe far UV absorption spectra of many polyatomic molecules show featureless, broad bands, even though the lifetimes of the underlying electronic states can be long enough to render the states observable. Using photoionization from Rydberg states we measure electron binding energies, thereby referencing the electronic spectra to the adiabatic ionization energy. In trimethylamine, we find that the 3s, the 3p(x,y), and the 3p(z) Rydberg states have binding energies of 3.087, 2.251, and 2.204 eV, respectively. Vibrational motions excited while preparing the Rydberg states do not interfere with the spectra.",
                    "score": 0.8557850122451782
                },
                {
                    "id": 4946716,
                    "contents": "The (22(0)1-00(0)0) Band of CO(2) at 6348 cm(-1): Linestrengths, Broadening Parameters, and Pressure Shifts.\nThe (22(0)1-00(0)0) combination band of CO(2) around 6348 cm(-1) is studied with diode-laser spectroscopy, and linestrengths, collision-broadening parameters, and pressure shifts are determined. Linestrengths are modeled with a third-order Herman-Wallis expansion, and discrepancies with values reported in the literature are explained. Copyright 2000 Academic Press.",
                    "score": 0.8553181886672974
                },
                {
                    "id": 12640340,
                    "contents": "Raman second hyperpolarizability determination using computational Raman activities and a comparison with experiments.\nDoubly vibrationally enhanced (DOVE) four-wave mixing spectroscopy, an optical analogue to 2D NMR, involves two infrared transitions and a Raman transition. The magnitude of the DOVE second hyperpolarizability γ (or third-order susceptibility χ((3))) can be theoretically estimated if the values of the dipolar moments of the two infrared transitions and the γ of the Raman transition are known. The Raman γ can be measured by using the four-wave mixing interferometric method or conventional Raman spectroscopy in the presence of an internal standard. In this work, we examine if one can use the Raman activity computed from density functional theory calculation to determine the Raman γ of selected vibrational modes of several samples including deuterated benzene, acetonitrile, tetrahydrofuran, and sodium benzoate aqueous solution. The 992 cm(-1) Raman band of benzene serves as an internal standard for organic solvents, and the 880 cm(-1) Raman band of hydrogen peroxide is for the aqueous solution sample with known γ values. We have found that the predicted Raman γ values from the computational Raman activities match experimental data reasonably well, suggesting a facile approach to predict the Raman γ of interested systems. ",
                    "score": 0.8533970713615417
                },
                {
                    "id": 20683807,
                    "contents": "Infrared Spectroscopy-Mid-infrared, Near-infrared, and Far-infrared/Terahertz Spectroscopy.\nThis article aims to overview infrared (IR) spectroscopy. Simultaneously, it outlines mid-infrared (MIR), near-infrared (NIR), and far-infrared (FIR) or terahertz (THz) spectroscopy separately, and compares them in terms of principles, characteristics, advantages, and applications. MIR spectroscopy is the central spectroscopic technique in the IR region, and is mainly concerned with the fundamentals of molecular vibrations. NIR spectroscopy incorporates both electronic and vibrational spectroscopy; however, in this review, I have chiefly discussed vibrational NIR spectroscopy, where bands due to overtones and combination modes appear. FIR or THz spectroscopy contains both vibrational and rotational spectroscopy. However, only vibrational FIR or THz spectroscopy has been discussed in this review. These three spectroscopy cover wide areas in their applications, making it rather difficult to describe these various topics simultaneously. Hence, I have selected three key topics: hydrogen bond studies, applications of quantum chemical calculations, and imaging. The perspective of the three spectroscopy has been discussed in the last section.",
                    "score": 0.8529643416404724
                },
                {
                    "id": 5656731,
                    "contents": "The Far-Infrared Spectrum of ClNO2 Studied by High-Resolution Fourier-Transform Spectroscopy.\nThe far-infrared spectrum of nitryl chloride was studied using high-resolution Fourier-transform spectroscopy in the 300-525 cm-1 region. Vibrational band centers of fundamental, hot, and difference bands were determined. Furthermore, rotational and centrifugal distortion constants up to fourth order for the nu3 bands of 35ClNO2 and 37ClNO2 (centered at 370 and 364 cm-1, respectively) were obtained. The nu5 fundamental of ClNO2 (predicted around 410 cm-1) is very weak and overlapped by difference bands. Copyright 1998 Academic Press.",
                    "score": 0.8529599905014038
                },
                {
                    "id": 5839016,
                    "contents": "High-Resolution Study of the Mid-Infrared Region of FNO(2).\nOf the gas-phase IR spectrum of nitrylfluoride, FNO(2), between 1200 and 1900 cm(-1), the bands nu(4), 2nu(6), nu(2) + nu(3), and nu(1) have been studied at a resolution of ca. 0.003 cm(-1). Improved ground state rotational and centrifugal distortion constants have been obtained from a simultaneous analysis of the data from F. Hegelund, H. Bürger, and G. Pawelke [J. Mol. Spectrosc. 184, 350-361 (1997)] and the present data from nu(4) and nu(1). The nu(4) and 2nu(6) bands are free from local perturbations, and upper state spectroscopic constants have been obtained from the conventional Watson Hamiltonian. The bands nu(1) and nu(2) + nu(3) are strongly perturbed by Coriolis interactions with the nearby dark levels nu(5) + nu(6), nu(3) + nu(6), and nu(2) + nu(5). Upper state constants for nu(1) and nu(2) + nu(3) are obtained from triad and tetrad models, respectively, including Coriolis resonances within this system. In addition Coriolis interaction parameters and the vibrational energies for the three dark states together with some of their rotational constants are determined from the observed perturbation effects on nu(1) and nu(2) + nu(3). Copyright 2000 Academic Press.",
                    "score": 0.852882981300354
                },
                {
                    "id": 4623568,
                    "contents": "Line Positions and Strengths of N(2)O between 3515 and 7800 cm(-1).\nThe line positions and strengths of N(2)O were measured from absorption spectra obtained at high spectral resolution (0.011 cm(-1)) in the region between 3515 and 7800 cm(-1). Measurements include line frequencies and strengths of several N(2)O isotopes, a few of which are reported for the first time, to my knowledge. Also in this category are two pi-pi bands, six Delta-Delta bands, and five Sigma-Sigma bands of (14)N(2)(16)O. Measurements also include eight (14)N(2)(16)O bands of which several transitions of each band were perturbed due to resonance interactions with transitions of a perturbing band. For most cases, the positions and strengths of the strongest interacting transitions of the perturbing bands were measured. Copyright 1999 Academic Press.",
                    "score": 0.8524907231330872
                },
                {
                    "id": 8398364,
                    "contents": "Infrared overtone spectroscopy and vibrational analysis of a Fermi resonance in nitric acid: Experiment and theory.\nHigh resolution infrared spectra of nitric acid have been recorded in the first OH overtone region under jet-cooled conditions using a sequential IR-UV excitation method. Vibrational bands observed at 6933.39(3), 6938.75(4), and 6951.985(3) cm(-1) (origins) with relative intensities of 0.42(1), 0.38(1), and 0.20(1) are attributed to strongly mixed states involved in a Fermi resonance. A vibrational deperturbation analysis suggests that the optically bright OH overtone stretch (2nu1) at 6939.2(1) cm(-1) is coupled directly to the nu1 + 2nu2 state at 6946.4(1) cm(-1) and indirectly to the 3nu2 + nu3 + nu7 state at 6938.5(1) cm(-1). Both the identity of the zero-order states and the indirect coupling scheme are deduced from complementary CCSD(T) calculations in conjunction with second-order vibrational perturbation theory. The deperturbation analysis also yields the experimental coupling between 2nu1 and nu1 + 2nu2 of -6.9(1) cm(-1), and that between the two dark states of +5.0(1) cm(-1). The calculated vibrational energies and couplings are in near quantitative agreement with experimentally derived values except for a predicted twofold stronger coupling of 2nu1 to nu1 + 2nu2. Weaker coupling of the strongly mixed states to a dense background of vibrational states via intramolecular vibrational energy redistribution is evident from the experimental linewidths of 0.08 and 0.25 cm(-1) for the higher energy and two overlapping lower energy bands, respectively. A comprehensive rotational analysis of the higher energy band yields spectroscopic parameters and the direction of the OH overtone transition dipole moment.",
                    "score": 0.8523145914077759
                },
                {
                    "id": 14197710,
                    "contents": "Combination transitions due to stretching and librations of OH⁻ ions in LiNbO₃.\nA new absorption band has been detected at 4009 cm⁻¹ in stoichiometric LiNbO₃ single crystals. Based on present and earlier experiments and recent calculations, this band has been assigned as a combination transition involving the OH stretching and an OH librational mode. The librational mode participating in this combination is of lower fundamental frequency than that contributing to the combination band at 4415 cm¹ observed by Gröne and Kapphan [J. Phys. Condens. Matter 7, 3051 (1995)].",
                    "score": 0.8522363901138306
                },
                {
                    "id": 9801799,
                    "contents": "High-resolution Fourier-transform infrared spectroscopy of the Coriolis coupled ground state and ν7 mode of ketenimine.\nHigh resolution FTIR spectra of the short lived species ketenimine have been recorded in the regions 390-1300 cm(-1) and 20-110 cm(-1) using synchrotron radiation. Two thousand six hundred sixty transitions of the ν(7) band centered at 693 cm(-1) and 126 far-IR rotational transitions have been assigned. Rotational and centrifugal distortion parameters for the ν(7) mode were determined and local Fermi and b-axis Coriolis interactions with 2ν(12) are treated. A further refinement of the ground state, ν(12) and ν(8) parameters was also achieved, including the treatment of previously unrecognized ac-axis and ab-axis second order perturbations to the ground state.",
                    "score": 0.8509389162063599
                },
                {
                    "id": 5806307,
                    "contents": "LaseRitz: Far-Infrared Laser Line Assignment and Prediction by the Ritz Combination Principle, with Application to Methanol and Hydrazine.\nA \"LaseRitz\" program is described for the systematic assignment and prediction of far-infrared laser (FIRL) transitions for a given molecule, such as methanol or hydrazine, which can be generated by optical pumping with known laser lines. The input data set for the program consists of identified molecular energy levels in ground and excited vibrational states, as compiled by our Ritz assignment program from the analysis of infrared (IR) bands and the FIR ground state spectrum. The program scans the data set for appropriate IR matches with an input list of laser pump lines for CO(2), N(2)O, etc., and generates an output table of all possible FIRL lines consistent with the molecular selection rules and lying within a prescribed wavenumber range. Initial tests on CH(3)OH have led to three likely new FIRL assignments; for N(2)H(4), assignments have been found for 14 new FIRL transition systems and verified for five others. Lists have been produced (deposited as supplementary data with the JMS archive reached at www.idealibrary.com or available on request from the authors) of CH(3)OH and N(2)H(4) FIRL lines potentially accessible by optical pumping with regular, sequence-band, hot-band, and isotopic CO(2) lines, plus N(2)O lines for N(2)H(4). The systematic approach with the LaseRitz program is more global and rigorous than earlier line-by-line studies, permitting calculation of all FIRL wavenumbers to spectroscopic accuracy. Copyright 2000 Academic Press.",
                    "score": 0.8509056568145752
                },
                {
                    "id": 12193769,
                    "contents": "FTIR spectroscopy of metalloproteins.\nAbsorption of infrared radiation by proteins gives important information about their structure and function. The most intense infrared bands correspond to the overlap of all the peptide bond absorption. Additionally, in many metalloproteins their prosthetic groups have intrinsic ligands or bind substrates/inhibitors that absorb intensively in the infrared. Here, we describe thoroughly several Fourier transform infrared methods for studying structure-function relationships in metalloproteins, using hydrogenases as an example. ",
                    "score": 0.8507248759269714
                },
                {
                    "id": 8966075,
                    "contents": "[A spectroscopic method using mixed states].\nWe introduce a method by use of atomic mixed states for the study of atomic spectroscopy.",
                    "score": 0.8507174253463745
                },
                {
                    "id": 16093776,
                    "contents": "Determination of Spectroscopic Band Shapes by Second Derivatives, Part II: Infrared Spectra of Liquid Light and Heavy Water.\nSecond derivative and band simulation techniques are used in a synergetic relationship to identify components in the infrared (IR) spectra of liquid light and heavy water. Nine Gaussian components are retrieved in massive OH and OD stretch absorption. In this context, ν1 and ν3 are the principal components along with satellites derived from harmonic and combination bands. The Raman spectrum of light water matches the IR components with intensity variations as expected. ",
                    "score": 0.850691556930542
                },
                {
                    "id": 5361907,
                    "contents": "High-Resolution Study of the Infrared Spectrum of H3SiI in the Regions 330-680 and 1070-1360 cm-1: Accurate Determination of the Ground State Constants\nHigh-resolution FTIR spectra of H3SiI have been recorded in the regions 330-680 cm-1 (nu3/nu6) and 1070-1360 cm-1 (2nu6). A detailed rovibrational study was carried out for the nu3 and nu6 fundamental bands, 2nu6-/+2 and 2nu60 overtone bands, and two hot bands, 2nu6+/-2 - nu6+/-1 and 2nu60 - nu6. A local resonance between the v6 = 2 and v2 = v3 = 1 states was observed. Ground state combination differences deduced from the nu3, nu6, 2nu6-/+2, and 2nu60 bands allowed us to obtain accurate B0, DJ0, and DJK0 constants. The nu6, 2nu6+/-2 - nu6+/-1, and 2nu6-/+2 bands were used for the experimental determination of the A0 and DK0 constants, whereas the hot band 2nu60 - nu6 served to make the internal calibration coherent. Ground state differences DeltaK(J) = E0(J, K) - E0(J, K - 3) were calculated with K up to 12. By a least-squares fit, we obtained the following results:A0 = 2.8426037(14) cm-1 and DK0 = 2.75840(99) x 10(-5) cm-1.Copyright 1997 Academic Press. Copyright 1997Academic Press",
                    "score": 0.8503202795982361
                },
                {
                    "id": 9801745,
                    "contents": "High-resolution Fourier transform infrared absorption spectroscopy of the ν6 band of c-C3H2.\nThe gas-phase high-resolution absorption spectrum of the ν(6) band of cyclopropenylidene (c-C(3)H(2)) has been observed using a Fourier transform infrared spectrometer for the first time. The molecule has been produced by microwave discharge in an allene (3.3 Pa) and Ar (4.0 Pa) mixture inside a side arm glass tube. The observed spectrum shows a pattern of c-type ro-vibrational transitions in which the Q-branch lines strongly and distinctly stand out in the spectrum. A combined least-squares analysis of the observed 216 ro-vibrational transitions together with 28 millimeter-wave rotational transitions from the previous study has resulted in an accurate determination of the molecular constants in the ν(6) state. The band center is found to be at 776.11622(13) cm(-1) with one standard deviation in parentheses, which is 2.3% lower than the matrix isolation value. The intensity ratio I(3)(ν(3))/I(6)(ν(6)) obtained from the observed ν(3) and ν(6) bands, 1.90(9), is somewhat lower than the ratio estimated from ab initio (2.4-2.6) and DFT (2.8) calculations.",
                    "score": 0.8497081995010376
                },
                {
                    "id": 5596377,
                    "contents": "Fourier Transform Infrared Emission Spectroscopy of NaCl and KCl\nThe infrared emission spectra of NaCl and KCl have been recorded at high resolution with a Fourier transform spectrometer. A total of 929 lines belonging to 8 vibrational bands, 1-0 to 8-7, for Na35 Cl, 252 lines of 1-0, 2-1, and 3-2 bands of Na37 Cl, and 355 lines of 1-0, 2-1, 3-2, and 4-3 bands of K35 Cl have been measured and combined with the existing microwave and millimeter-wave data to obtain a set of refined molecular constants. The data for Na35 Cl and Na37 Cl have also been fitted to determine the Dunham Yij constants and mass-reduced Dunham constants Uij . In one fit all Uij 's were treated as adjustable parameters while in a second fit only Ui 0 's and Ui 1 's were allowed to vary freely with the remaining Uij constants determined by the constraints imposed by the Dunham model. In addition, the internuclear potential energy parameters were determined by fitting the entire NaCl data set to the eigenvalues of the Schrodinger equation containing a parameterized potential energy function.",
                    "score": 0.8496716618537903
                },
                {
                    "id": 10305337,
                    "contents": "Line intensities and broadening parameters of the 11101 ? 10002 band of (12)C(16)O(2).\nIntensities and broadening parameters of lines belonging to the 11101 ? 10002 band of (12)C(16)O(2) have been measured using Fourier transform spectroscopy spectra. From the measured line intensities it has been possible to determine the variation with respect to m or J of the squared transition dipole moment |micro|(2) as |micro|(2) = 1.323 x 10(-3) [1 + 1.0 x 10(-3) m - 1.6 x 10(-5)J (J + 1)](2) for P- and R-branches and |micro| = 1.323x10-5 J(J(2) = 1.323 x 10(-3) [1 - 3.5 x 10(-3)[1 - 3.5 x 10-5] J(J + 1)](2) for the Q-branch. Moreover, self-, nitrogen-, and oxygen-broadening parameters have been measured and they are compared with previously published values.",
                    "score": 0.8494163155555725
                },
                {
                    "id": 8034960,
                    "contents": "High-resolution FTIR, microwave, and ab initio investigations of CH2 79BrF: ground, v(5) = 1, and v(6) = 1, 2 state constants.\nA spectroscopic study of CH279BrF in the infrared and microwave regions has been carried out. The rovibrational spectrum of the nu5 fundamental interacting with 2nu6 has been investigated by high-resolution FTIR spectroscopy. Owing to the weakness of the 2nu6 band, the v6 = 2 state constants have been derived from v6 = 1. For this reason, the rotational spectra of the ground and v6 = 1 states have been observed by means of microwave spectroscopy. Highly accurate ab initio computations have also been performed at the CCSD(T) level of theory in order to support the experimental investigation. As far as the nu5 band is concerned, the analysis of the rovibrational structure led to the identification of more than 3000 transitions, allowing the determination of a set of spectroscopic parameters up to sextic distortion terms and pointing out first-order c-type Coriolis interaction with the v6 = 2 state. With regard to the pure rotational spectra measurements, the assignment of several DeltaJ = 0, +1 transitions allowed the determination of the rotational, all the quartic, and most of the sextic centrifugal distortion constants, as well as the full bromine quadrupole coupling tensor for both the ground and v6 = 1 states.",
                    "score": 0.8492704629898071
                },
                {
                    "id": 9290111,
                    "contents": "Optical spectroscopy of RuC: 18,000-24,000 cm(-1).\nThe optical spectrum of diatomic RuC has been recorded from 17 800 to 24 200 cm(-1). Three previously unidentified excited electronic states were analyzed and identified as having Omega' = 0, Omega' = 2, and Omega' = 3. The Omega' = 3 state was determined to be a 3Delta3 state that is suggested to arise from a mixture of the 10sigma(2)11sigma(2)5pi(3)2delta(3)12sigma(1)6pi(1) and 10sigma(2)11sigma(1)5pi(3)2delta(3)12sigma(2)6pi(1) electronic configurations. Three additional bands belonging to the previously observed [18.1] (1)Pi&lt;--X (1)Sigma(+) system were analyzed to obtain B(e) (')=0.558 244(48) cm(-1), alpha(e) (')=0.004 655(27) cm(-1), omegae' = 887.201(37) cm(-1), and omega(e) 'xe' = 5.589(7) cm(-1) for the 102Ru 12C isotopomer (1sigma error limits). A Rydberg-Klein-Rees analysis was then performed using the determined spectroscopic constants of the [18.1] 1Pi state, and similar analyses were performed for the previously observed states. The resulting potential energy curves are provided for the 100Ru 12C, 101Ru 12C, 102Ru 12C, and 104Ru 12C isotopic species.",
                    "score": 0.8490709066390991
                },
                {
                    "id": 7890729,
                    "contents": "Observation and rovibrational analysis of the intermolecular NH3 libration band nu9(1) of H3N-HCN.\nThe high-resolution far-infrared absorption spectrum of the gaseous molecular complex H(3)N-HCN is recorded by means of static gas-phase Fourier transform far-infrared spectroscopy at 247 K, using a synchrotron radiation source. The spectrum contains distinct rotational structures which are assigned to the intermolecular NH(3) libration band nu9(1) (nu(B)) of the pyramidal H(3)N-HCN complex. A rovibrational analysis based on a standard semirigid symmetric top molecule model yields the band origin of 260.03(10) cm(-1), together with values for the upper state rotational constant B' and the upper state quartic centrifugal distortion constants D'(J) and D'(JK). The values for the upper state spectroscopic constants indicate that the hydrogen bond in the H(3)N-HCN complex is destabilized by 5% and elongates by 0.010 A upon excitation of a quantum of libration of the hydrogen bond acceptor molecule.",
                    "score": 0.8486744165420532
                },
                {
                    "id": 11469371,
                    "contents": "The development of soviet optics and spectroscopy during the past fifty years.\nA history of Soviet spectroscopy is given, with special emphasis on various areas indicating the earliest workers in each specialty and their principal successors; for example, the work of Rozhdestvenskii (anomalous dispersion); Fok (self-consistant field calculations), Terenin (photochemistry, atomic beams), Mandelstam (combination scattering), Vavilov (luminescence, quantum properties of light), Cerenkov (radiation), Chaika (atomic lifetimes), Gross (excitons), and Volkenstein (molecular vibrations).",
                    "score": 0.8485327363014221
                },
                {
                    "id": 5393540,
                    "contents": "Absolute Line Intensities in the 2nu(0)(2) Band of Cyanogen Chloride at 12.8 µm.\nAbsolute line intensities were measured at high resolution with a tunable diode laser. This work concerns the 2nu(0)(2) band of cyanogen chloride ClCN in the region 780 cm(-1). Thirty-two absorption lines were recorded for the isotopomer (35)ClCN and 26 lines for (37)ClCN. From the analysis of these lines, we determined the bandstrengths: S(0)(v) = 19.14 cm(-2) atm(-1) for (35)ClCN and S(0)(v) = 17.84 cm(-2) atm(-1) for (37)ClCN. Copyright 2000 Academic Press.",
                    "score": 0.8479691743850708
                },
                {
                    "id": 6042404,
                    "contents": "Absolute Intensity of the NH(3) nu(2) Band.\nAbsolute line intensities of NH(3) in the nu(2) band were measured for a number of rovibrational lines using a high-resolution Fourier transform infrared spectrometer. The transition dipole moments calculated from the absolute intensities showed significant and systematic deviations from the usual rotational dependencies predicted from the J, K dependence of the direction-cosine matrix elements. The anomalous rotational dependencies may be explained by vibration-rotation interactions, and the Herman-Wallis-type rotational correction factors for a symmetric top molecule were determined experimentally for the first time in the present study. The self-broadening coefficients were determined as well. Copyright 1999 Academic Press.",
                    "score": 0.8475573062896729
                },
                {
                    "id": 5839009,
                    "contents": "High-Resolution Study of Strongly Interacting Vibrational Bands of HDO in the Region 7600-8100 cm(-1).\nThe high-resolution Fourier transform spectrum of the HDO molecule was recorded and analyzed in the region 7600-8100 cm(-1) where the weak vibration-rotation bands 3nu(1) and nu(1) + nu(2) + nu(3) are located. Because of the presence of strong local resonance interactions, transitions belonging to the 3nu(2) + nu(3) and 6nu(2) bands were assigned as well. Spectroscopic parameters of all four bands were estimated, which reproduce initial line positions with accuracy close to experimental uncertainties. Copyright 2000 Academic Press.",
                    "score": 0.8475317358970642
                },
                {
                    "id": 4558764,
                    "contents": "High-Resolution Infrared Spectrum of H3SiI in the nu1/nu4 Region near 2200 cm-1\nThe Fourier transform infrared spectrum of H3SiI has been recorded in the nu1/nu4 region from 2075 to 2315 cm-1 at an optical resolution of 2.3 x 10(-3) cm-1. The nu1/nu4 fundamental bands and the (nu1 + nu3) - nu3/(nu4 + nu3) - nu3 hot bands have been rotationally investigated. Numerous local perturbations have been observed in the nu1 and nu4 bands and in the hot bands. Without the lines involved in perturbations, more than 2900 transitions of the nu1/nu4 bands were used to determine the band origins and the vibration-rotation parameters of the nu1 = 1 and nuv4 = 1 states. A least-squares fit of 766 apparently unperturbed transitions of the hot bands gave the parameters of the nu1 = nu3 = 1 and nu4 = nu3 = 1 states. The l(2, 2) resonance in nu4 and the A1-E Coriolis coupling between nu1 and nu4 have been investigated. Most of the local perturbations have been studied individually using a simple model by which the main perturber for each resonance was identified. Copyright 1998 Academic Press.",
                    "score": 0.8474205732345581
                },
                {
                    "id": 16902065,
                    "contents": "IR Spectroscopic Techniques to Study Isolated Biomolecules.\nThe combination of mass spectrometry, infrared action spectroscopy and quantum-chemical calculations provides a variety of approaches to the study of the structure of biologically relevant molecules in vacuo. This chapter reviews some of the experimental methods that are currently in use, which can roughly be divided into two main categories: (1) low-temperature neutral molecules in a molecular beam environment, which can be investigated in a conformationally selective manner by the application of double-resonance laser spectroscopy and (2) ionized species which can conveniently be manipulated and selected by mass spectrometric methods and which can be investigated spectroscopically by wavelength-dependent photo-dissociation. Both approaches rely on the application of infrared tunable laser spectroscopy and the laser sources most commonly used in current studies are briefly reviewed in Sect. 3. Along with quantum-chemical calculations, reviewed in Chapter 3 of this book (Gaigeot and Spezia, Top Curr Chem doi:10.1007/128_2014_620), the experimental IR spectra reveal a wealth of information on the structural properties of the biological species. ",
                    "score": 0.8474026918411255
                },
                {
                    "id": 17325664,
                    "contents": "Breakthrough Potential in Near-Infrared Spectroscopy: Spectra Simulation. A Review of Recent Developments.\nNear-infrared (12,500-4,000 cm<sup-1</sup; 800-2,500 nm) spectroscopy is the hallmark for one of the most rapidly advancing analytical techniques over the last few decades. Although it is mainly recognized as an analytical tool, near-infrared spectroscopy has also contributed significantly to physical chemistry, e.g., by delivering invaluable data on the anharmonic nature of molecular vibrations or peculiarities of intermolecular interactions. In all these contexts, a major barrier in the form of an intrinsic complexity of near-infrared spectra has been encountered. A large number of overlapping vibrational contributions influenced by anharmonic effects create complex patterns of spectral dependencies, in many cases hindering our comprehension of near-infrared spectra. Quantum mechanical calculations commonly serve as a major support to infrared and Raman studies; conversely, near-infrared spectroscopy has long been hindered in this regard due to practical limitations. Advances in anharmonic theories in hyphenation with ever-growing computer technology have enabled feasible theoretical near-infrared spectroscopy in recent times. Accordingly, a growing number of quantum mechanical investigations aimed at near-infrared region has been witnessed. The present review article summarizes these most recent accomplishments in the emerging field. Applications of generalized approaches, such as vibrational self-consistent field and vibrational second order perturbation theories as well as their derivatives, and dense grid-based studies of vibrational potential, are overviewed. Basic and applied studies are discussed, with special attention paid to the ones which aim at improving analytical spectroscopy. A remarkable potential arises from the growing applicability of anharmonic computations to solving the problems which arise in both basic and analytical near-infrared spectroscopy. This review highlights an increased value of quantum mechanical calculations to near-infrared spectroscopy in relation to other kinds of vibrational spectroscopy.",
                    "score": 0.8472262620925903
                },
                {
                    "id": 10370781,
                    "contents": "Infrared spectra, integrated band intensities, and anharmonic force field of H2C=CHF.\nThe gas-phase infrared spectra of vinyl fluoride, H(2)C=CHF, have been examined at medium resolution in the range 400-8000 cm(-1). The assignment of the absorptions in terms of fundamental, overtone, and combination bands, assisted by quantum chemical calculations, is consistent all over the region investigated. Spectroscopic parameters, obtained from the analysis of partially resolved rotational structure of some bands, have been derived and compared with the corresponding calculated values. Accurate values of integrated band intensities have also been determined for the first time. High-level ab initio calculations with large basis sets have been performed. Correlated harmonic force fields have been obtained from coupled cluster CCSD(T) calculations with the cc-pVQZ basis set, while anharmonic force constants have been computed employing the less resource demanding cc-pVTZ basis set. A good agreement between the computed and the experimental data has been obtained including those for the integrated infrared band intensities.",
                    "score": 0.8469823598861694
                },
                {
                    "id": 17475916,
                    "contents": "The Right Answer for the Right Reason: My Personal Goal for Quantum Chemistry.\nA brief history of quantum theory is given to illustrate the barriers to progress caused by preconceived ideas. The biases in my own thinking which I had to overcome to approach the right answer for the right reason are discussed. This is followed by a personal autobiography illustrating how I have led a life of serendipity with no real sense of purpose. Chance events have shaped my life. The algorithms for which I am best known are briefly discussed. Then highlights from the many applications of theory to excited states, bonding in ice, spin properties and magnetism, (e,2e) shake-up spectra, and organic reactions are mentioned. This wide range of applications is mostly due to accidental collaboration with colleagues who sought my help. My real interest was in developing methods which could address these problems.",
                    "score": 0.8466281890869141
                },
                {
                    "id": 21077196,
                    "contents": "Infrared spectroscopy probes ion binding geometries.\nInfrared (IR) spectroscopy is a well-established technique for probing the structure, behavior, and surroundings of molecules in their native environments. Its characteristics-most specifically high structural sensitivity, ready applicability to aqueous samples, and broad availability-make it a valuable enzymological technique, particularly for the interrogation of ion binding sites. While IR spectroscopy of the \"garden variety\" (steady state at room temperature with wild-type proteins) is versatile and powerful in its own right, the combination of IR spectroscopy with specialized experimental schemes for leveraging ultrafast time resolution, protein labeling, and other enhancements further extends this utility. This book chapter provides the fundamental physical background and literature context essential for harnessing IR spectroscopy in the general context of enzymology with specific focus on interrogation of ion binding. Studies of lanthanide ions binding to calmodulin are highlighted as illustrative examples of this process. Appropriate sample preparation, data collection, and spectral interpretation are discussed from a detail-oriented and practical perspective with the goal of facilitating the reader's rapid progression from reading words in a book to collecting and analyzing their own data in the lab.",
                    "score": 0.8463332653045654
                },
                {
                    "id": 6042402,
                    "contents": "The High-Resolution Infrared Spectrum of 1,2,4-Triazine Vapor between 550 and 1700 cm(-1).\nThe Fourier transform gas-phase IR spectrum of 1,2,4-triazine between 550 and 1700 cm(-1) was measured with a resolution of ca. 0.003 cm(-1). Comparing with the liquid-phase IR and Raman spectra and using ab initio predictions, most of the fundamental bands of 1,2,4-triazine below 1600 cm(-1) were assigned. From the high-resolution gas-phase spectra, 12 of the fundamental bands were analyzed by the Watson Hamiltonian model to yield upper state spectroscopic constants. A number of local resonances were identified and explained. From a simultaneous ground state combination difference analysis of four of the bands, a set of ground state rotational and centrifugal distortion constants were obtained. Copyright 1999 Academic Press.",
                    "score": 0.8459756374359131
                },
                {
                    "id": 6042405,
                    "contents": "Rovibrational Constants for the nu(6) and 2nu(9) Bands of HCOOD by Fourier Transform Infrared Spectroscopy.\nThe Fourier transform infrared spectrum of the nu(6) and 2nu(9) bands of deuterated formic acid (HCOOD) was recorded with an apodized resolution of 0.004 cm(-1) in the frequency range of 930-1040 cm(-1). These two bands with band centers 40 cm(-1) apart were mutually coupled by Coriolis and Fermi interactions. By fitting a total of 1076 infrared transitions of both nu(6) and 2nu(9) with a standard deviation of 0.00075 cm(-1) using a Watson's A-reduced Hamiltonian in the I(r) representation with the inclusion of c-type Coriolis and a Fermi-resonance term, two sets of rovibrational constants for v(6) = 1, and v(9) = 2 states were derived for the first time. Both nu(6) and 2nu(9) bands are A type with band centers at 972.8520 +/- 0.0001 and 1011.6766 +/- 0.0001 cm(-1), respectively. Copyright 1999 Academic Press.",
                    "score": 0.8459036946296692
                },
                {
                    "id": 4766637,
                    "contents": "High-Resolution Infrared Study of the nu14, nu17, and nu18 Bands of 11B2H6 and 10B11BH6.\nUsing high-resolution Fourier transform spectra, a thorough analysis of the nu14 c-type, nu17 a-type, and nu18 a-type bands of both 11B2H6 and 10B11BH6 has been carried in the 10.3-, 6.2-, and 8.5-µm spectral regions, respectively. From this analysis a large set of precise ground state combination differences with J values up to 36 (31) and Ka values extending to 18 (18) was derived for 11B2H6(10B11BH6). These data were fitted using a Watson-type Hamiltonian leading to accurate ground state rotational constants. An rs value for the B-B distance has been determined to be 1.7645(10) Å. The determination of upper state Hamiltonian constants proved to be much more difficult since the corresponding rotational levels of each of the bands are strongly perturbed by nearby dark states. To account for these strong localized resonances, it was necessary to introduce the relevant interacting terms in the Hamiltonian matrix. As a result it was possible to calculate the upper state energy levels quite satisfactorily. From these fits, estimates of the band centers and a few of the rotational constants of the resonating dark states were obtained. Copyright 1998 Academic Press.",
                    "score": 0.8458304405212402
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_37",
        "question": "Calculate the percentage difference between $e^x$ and $1+x$ for $x=0.0050$",
        "golden_answers": [
            " 1.25"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 22607444,
                    "contents": "XXXXXXXXXXX.\nXXXXXXXXXXX.",
                    "score": 0.8877217173576355
                },
                {
                    "id": 6405172,
                    "contents": "Run for your money.\nThe DoH's efficiency index is criticised for being crude, biased and inaccurate. John Appleby, Trevor Sheldon and Aileen Clarke discuss NAHAT's consultation and suggest some improvements.",
                    "score": 0.8824707865715027
                },
                {
                    "id": 322562,
                    "contents": "Looking above the bottom line: decisions in economic evaluation.\nEconomics can be a complex mix of formulae based on data with varying degrees of accuracy and assumptions. A realistic picture of costs and benefits will assist decision making and facilitate more accurate expectations and criteria for success.",
                    "score": 0.8815935850143433
                },
                {
                    "id": 11107397,
                    "contents": "The crux of the method: assumptions in ordinary least squares and logistic regression.\nLogistic regression has increasingly become the tool of choice when analyzing data with a binary dependent variable. While resources relating to the technique are widely available, clear discussions of why logistic regression should be used in place of ordinary least squares regression are difficult to find. The current paper compares and contrasts the assumptions of ordinary least squares with those of logistic regression and explains why logistic regression's looser assumptions make it adept at handling violations of the more important assumptions in ordinary least squares.",
                    "score": 0.8792832493782043
                },
                {
                    "id": 7958854,
                    "contents": "Multiple linear regression.\nThis chapter describes multiple linear regression, a statistical approach used to describe the simultaneous associations of several variables with one continuous outcome. Important steps in using this approach include estimation and inference, variable selection in model building, and assessing model fit. The special cases of regression with interactions among the variables, polynomial regression, regressions with categorical (grouping) variables, and separate slopes models are also covered. Examples in microbiology are used throughout.",
                    "score": 0.8788758516311646
                },
                {
                    "id": 20324467,
                    "contents": "Insert here, the title of your paper, Capitalize first letter.\nInsert here your abstract text.",
                    "score": 0.8748408555984497
                },
                {
                    "id": 9617527,
                    "contents": "Strong consistency of least squares estimates in multiple regression.\nThe strong consistency of least squares estimates in multiple regression models with independent errors is obtained under minimal assumptions on the design and weak moment conditions on the errors.",
                    "score": 0.8743428587913513
                },
                {
                    "id": 4360905,
                    "contents": "Article 5. An introduction to estimation--2: from z to t.\nProvided the sample size is large enough (that is, n greater than 100), the z statistic can be used to determine the confidence interval estimation of the population mean even when the sigma is not known. In these cases the estimation of the standard error of the mean is used. The z statistic is also valid when determining the population's proportion based upon a large sample. However, when dealing with smaller samples, the z statistic is replaced by the t statistic. This makes it possible to estimate, in a population with an unknown standard deviation: The probability of getting a sample mean greater than or equal to a particular value The value of a sample mean with a particular probability of occurring The probability of getting a sample mean between two particular values The confidence interval for the estimation of the population mean can also be determined using the t statistic.",
                    "score": 0.8741797208786011
                },
                {
                    "id": 16311689,
                    "contents": "Neither fixed nor random: weighted least squares meta-analysis.\nThis study challenges two core conventional meta-analysis methods: fixed effect and random effects. We show how and explain why an unrestricted weighted least squares estimator is superior to conventional random-effects meta-analysis when there is publication (or small-sample) bias and better than a fixed-effect weighted average if there is heterogeneity. Statistical theory and simulations of effect sizes, log odds ratios and regression coefficients demonstrate that this unrestricted weighted least squares estimator provides satisfactory estimates and confidence intervals that are comparable to random effects when there is no publication (or small-sample) bias and identical to fixed-effect meta-analysis when there is no heterogeneity. When there is publication selection bias, the unrestricted weighted least squares approach dominates random effects; when there is excess heterogeneity, it is clearly superior to fixed-effect meta-analysis. In practical applications, an unrestricted weighted least squares weighted average will often provide superior estimates to both conventional fixed and random effects.",
                    "score": 0.8733870983123779
                },
                {
                    "id": 6357297,
                    "contents": "Economics 101: exploring the land of costs.\nThe word \"cost\" is a slippery, chameleon-like beast that changes its meaning to suit the occasion. The author's \"economish\" dictionary will help you survive the purchasing jungle.",
                    "score": 0.8730688095092773
                },
                {
                    "id": 8448773,
                    "contents": "Beyond the P IV: gain confidence in confidence intervals.\nThis is the last in a 4-part series discussing the proper use, interpretation, and limitations of P values.",
                    "score": 0.8730580806732178
                },
                {
                    "id": 20468723,
                    "contents": "\n[This corrects the article doi: 10.1590/0102-311X00086819].",
                    "score": 0.8727953433990479
                },
                {
                    "id": 21402899,
                    "contents": "\n[This corrects the article doi: 10.1590/0102-311X00050818].",
                    "score": 0.8722444176673889
                },
                {
                    "id": 17132486,
                    "contents": "May the odds be ever in your favour.\nProbability and chance are essential concepts, not just in statistics but in real life. We present an adaptable activity which investigates what we mean by bias, how we can identify bias, and how we can use it to our advantage!",
                    "score": 0.872053861618042
                },
                {
                    "id": 7457817,
                    "contents": "G*Power 3: a flexible statistical power analysis program for the social, behavioral, and biomedical sciences.\nG*Power (Erdfelder, Faul, &amp; Buchner, 1996) was designed as a general stand-alone power analysis program for statistical tests commonly used in social and behavioral research. G*Power 3 is a major extension of, and improvement over, the previous versions. It runs on widely used computer platforms (i.e., Windows XP, Windows Vista, and Mac OS X 10.4) and covers many different statistical tests of the t, F, and chi2 test families. In addition, it includes power analyses for z tests and some exact tests. G*Power 3 provides improved effect size calculators and graphic options, supports both distribution-based and design-based input modes, and offers all types of power analyses in which users might be interested. Like its predecessors, G*Power 3 is free.",
                    "score": 0.8720530271530151
                },
                {
                    "id": 4578301,
                    "contents": "COMMENT.\nCopyright",
                    "score": 0.8719896078109741
                },
                {
                    "id": 19143746,
                    "contents": "Corrigendum.\n[This corrects the article DOI: 10.1002/ams2.198.].",
                    "score": 0.8718772530555725
                },
                {
                    "id": 18799840,
                    "contents": "WASP (Write a Scientific Paper): Multivariate analysis.\nLinear regression is the equation which provides of straight line that best describes the association between two continuous variables, x and y. However, it is often the case that the dependent variable y is influenced by more than one variable and not just a single x variable. Multivariate analysis is a statistical modeling technique wherein multiple x variables are analysed simultaneously for their effect on y, resulting in an additive model (via an equation) that explains the observation/s and corrects for confounding association/s using one dependent and several independent variables, assigning a gradient to each of these independent variables, and with all product terms of gradient and magnitude of the independent variables adding up to estimate 'y'. This paper outlines these various techniques and applications.",
                    "score": 0.8717560768127441
                },
                {
                    "id": 20176766,
                    "contents": "\n[This corrects the article doi: 10.1590/0102-311X00006720].",
                    "score": 0.8716480135917664
                },
                {
                    "id": 21198693,
                    "contents": "Corrigendum.\n[This corrects the article DOI: 10.1002/ams2.486.].",
                    "score": 0.8716200590133667
                },
                {
                    "id": 7404951,
                    "contents": "Method of fitting logistic curve.\n\"The paper presents a simple method of fitting the Logistic Curve by estimating the parameters in a different way than the methods known in the literature.\"",
                    "score": 0.8712961077690125
                },
                {
                    "id": 18179801,
                    "contents": "Corrigendum.\n[This corrects the article DOI: 10.1093/ofid/ofy063.].",
                    "score": 0.8711647391319275
                },
                {
                    "id": 19249430,
                    "contents": "\n[This corrects the article doi: 10.1590/0102-311x00037316].",
                    "score": 0.8708664178848267
                },
                {
                    "id": 19677938,
                    "contents": "\n[This corrects the article doi: 10.1590/0102-311X00212920].",
                    "score": 0.8707846403121948
                },
                {
                    "id": 15302521,
                    "contents": "A Version of Quadratic Regression with Interpretable Parameters.\nThe quadratic regression model is popular and effective in describing a wide variety of data, but it is based on a function whose parameters are not easy to interpret. We suggest an alternative form of the quadratic model that has the same expectation function, but also has the useful feature that its parameters are interpretable. Examples are provided of a simple regression problem and also of a nonlinear mixed-effects model. The models can be estimated with available software. ",
                    "score": 0.8705896735191345
                },
                {
                    "id": 21330496,
                    "contents": "Corrigendum.\n[This corrects the article DOI: 10.1002/ams2.522.].",
                    "score": 0.8705170154571533
                },
                {
                    "id": 7257863,
                    "contents": "An introduction to power and sample size estimation.\nThe importance of power and sample size estimation for study design and analysis.",
                    "score": 0.8704873323440552
                },
                {
                    "id": 20339094,
                    "contents": "\n[This corrects the article doi: 10.1590/0102-311X00228519].",
                    "score": 0.8704236745834351
                },
                {
                    "id": 19581491,
                    "contents": "[Short comment to \"Entirely and For Nothing\"].\nNo abstract available.",
                    "score": 0.8704091310501099
                },
                {
                    "id": 21962719,
                    "contents": "Transformation based on likelihood ratio.\nWe respond here on a recent letter in this journal, on the transformation based on likelihood ratio.",
                    "score": 0.8703943490982056
                },
                {
                    "id": 20287565,
                    "contents": "Corrigendum.\n[This corrects the article DOI: 10.1002/ams2.635.].",
                    "score": 0.8703117370605469
                },
                {
                    "id": 19209629,
                    "contents": "The sum of standardized residuals: Goodness-of-fit test for binary response models.\nWe propose a new goodness-of-fit statistic for evaluating generalized linear models with binary responses on the basis of the sum of standardized residuals. We derive the asymptotic distribution of the sum of standardized residuals statistic and argue that, despite its relative simplicity, it typically outperforms many of the more sophisticated currently used goodness-of-fit statistics.",
                    "score": 0.8699097037315369
                },
                {
                    "id": 4991527,
                    "contents": "The Fisher-Pitman permutation test: an attractive alternative to the F test.\nThe Fisher-Pitman permutation test is shown to possess significant advantages over conventional alternatives when analyzing differences among independent samples with unequal variances.",
                    "score": 0.8695024847984314
                },
                {
                    "id": 20694100,
                    "contents": "\n[This corrects the article doi: 10.1590/0102-311X00031420].",
                    "score": 0.8694928884506226
                },
                {
                    "id": 2373567,
                    "contents": "Multifit: a flexible non-linear least squares regression program in BASIC.\nMULTIFIT, a program in BASIC for implementation on microcomputers, has been developed for non-linear least squares regression fitting of enzyme kinetic, pharmacokinetic and other data to specific models. The program contains a simple procedure for insertion of model equations with up to five parameters (to be fitted) up to 3 independent variables and 1 dependent variable, and can be used to generate a family of programs with pre-set model functions.",
                    "score": 0.8694585561752319
                },
                {
                    "id": 19435743,
                    "contents": "Corrigendum.\n[This corrects the article DOI: 10.1002/ams2.6.].",
                    "score": 0.8693000078201294
                },
                {
                    "id": 20554795,
                    "contents": "The Big 5-0: Highlights From ASCP's 50th Annual Meeting &amp; Exhibition.\nASCP's 2019 Annual Meeting &amp; Exhibition marked an historic moment - the Society's 50th annual conference. From the thought-provoking keynotes, brand-reveal announcement, and VIP experiences, ASCP's 50th Annual Meeting &amp; Exhibition was an exceptional event. More than 1,100 attendees convened in Grapevine, Texas, for #ASCP50. We've rounded up a few of our favorite highlights from this year's meeting.",
                    "score": 0.8692858815193176
                },
                {
                    "id": 23194751,
                    "contents": "\n[This corrects the article doi: 10.1590/0102-311X00205120].",
                    "score": 0.8692284226417542
                },
                {
                    "id": 17550037,
                    "contents": "\n[This corrects the article doi: 10.1590/0102-311X00165716].",
                    "score": 0.8691617846488953
                },
                {
                    "id": 15994680,
                    "contents": "\n[This corrects the article doi: 10.1590/1980-5497201500060006].",
                    "score": 0.8689818978309631
                },
                {
                    "id": 11142505,
                    "contents": "Statistical power analyses using G*Power 3.1: tests for correlation and regression analyses.\nG*Power is a free power analysis program for a variety of statistical tests. We present extensions and improvements of the version introduced by Faul, Erdfelder, Lang, and Buchner (2007) in the domain of correlation and regression analyses. In the new version, we have added procedures to analyze the power of tests based on (1) single-sample tetrachoric correlations, (2) comparisons of dependent correlations, (3) bivariate linear regression, (4) multiple linear regression based on the random predictor model, (5) logistic regression, and (6) Poisson regression. We describe these new features and provide a brief introduction to their scope and handling.",
                    "score": 0.8689738512039185
                },
                {
                    "id": 19888966,
                    "contents": "\n[This corrects the article doi: 10.1590/0102-311X00174019].",
                    "score": 0.8686160445213318
                },
                {
                    "id": 16839657,
                    "contents": "ENB lists new proposals.\nTHE ENB has outlined major new proposals which would increase its responsibilities under the NHS White Paper plans. ",
                    "score": 0.8683897256851196
                },
                {
                    "id": 6469901,
                    "contents": "[Significance, effect size, and confidence interval].\nThe term \"statistical significance\" is often misunderstood. The result of a study may be labelled to be \"highly significant\" as if implying \"highly important\". Statistically significant, however, does only mean that a study result might have been found with a predefined probability (conventionally set at 5 %) even when the null hypothesis is true in the population, i. e. the effect found in the study sample does not exist in reality. Whether a result proves to be significant or not largely depends on sample size. Thus, in a large sample minimal effects of no practical relevance may turn out significant whereas in a small sample even large, important effects may fail to reach the significance level. As a consequence, when presenting the results of a study the effect size should be reported together with a confidence interval indicating the probable range that contains the population effect.",
                    "score": 0.8680683970451355
                },
                {
                    "id": 17592870,
                    "contents": "Hypothesis Testing, <i>p</i> Values, Confidence Intervals, Measures of Effect Size, and Bayesian Methods in Light of Modern Robust Techniques.\nThe article provides perspectives on <ip</i values, null hypothesis testing, and alternative techniques in light of modern robust statistical methods. Null hypothesis testing and <ip</i values can provide useful information provided they are interpreted in a sound manner, which includes taking into account insights and advances that have occurred during the past 50 years. There are, of course, limitations to what null hypothesis testing and <ip</i values reveal about data. But modern advances make it clear that there are serious limitations and concerns associated with conventional confidence intervals, standard Bayesian methods, and commonly used measures of effect size. Many of these concerns can be addressed using modern robust methods.",
                    "score": 0.8680388331413269
                },
                {
                    "id": 6416181,
                    "contents": "The significance of non-significance.\nWe discuss the implications of empirical results that are statistically non-significant. Figures illustrate the interrelations among effect size, sample sizes and their dispersion, and the power of the experiment. All calculations (detailed in Appendix) are based on actual noncentral t-distributions, with no simplifying mathematical or statistical assumptions, and the contribution of each tail is determined separately. We emphasize the importance of reporting, wherever possible, the a priori power of a study so that the reader can see what the chances were of rejecting a null hypothesis that was false. As a practical alternative, we propose that non-significant inference be qualified by an estimate of the sample size that would be required in a subsequent experiment in order to attain an acceptable level of power under the assumption that the observed effect size in the sample is the same as the true effect size in the population; appropriate plots are provided for a power of 0.8. We also point out that successive outcomes of independent experiments each of which may not be statistically significant on its own, can be easily combined to give an overall p value that often turns out to be significant. And finally, in the event that the p value is high and the power sufficient, a non-significant result may stand and be published as such.",
                    "score": 0.8680263757705688
                },
                {
                    "id": 20808808,
                    "contents": "\n[This corrects the article doi: 10.1590/0103-6440202003643].",
                    "score": 0.8679932355880737
                },
                {
                    "id": 6689504,
                    "contents": "[Equivalence test and its performance with computer software].\nFollowing brief introduction of the equivalence test, a sample is given to exemplify its performance with EquivTestTM 2.0 software and with the major results were interpreted.",
                    "score": 0.8679429888725281
                },
                {
                    "id": 13857438,
                    "contents": "From the guest editor.\nNo abstract available for this article. ",
                    "score": 0.8677998185157776
                },
                {
                    "id": 21419315,
                    "contents": "\n[This corrects the article doi: 10.1590/0102-311X00190418].",
                    "score": 0.8672912120819092
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_38",
        "question": " Calculate (a) the wavelength and kinetic energy of an electron in a beam of electrons accelerated by a voltage increment of $100 \\mathrm{~V}$ ",
        "golden_answers": [
            " 1.602"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 23109414,
                    "contents": "Photoelectron energy peaks shift against the radiation pressure in strong-field ionization.\nThe photoelectric effect describes the ejection of an electron upon absorption of one or several photons. The kinetic energy of this electron is determined by the photon energy reduced by the binding energy of the electron and, if strong laser fields are involved, by the ponderomotive potential in addition. It has therefore been widely taken for granted that for atoms and molecules, the photoelectron energy does not depend on the electron's emission direction, but theoretical studies have questioned this since 1990. Here, we provide experimental evidence that the energies of photoelectrons emitted against the light propagation direction are shifted toward higher values, while those electrons that are emitted along the light propagation direction are shifted to lower values. We attribute the energy shift to a nondipole contribution to the ponderomotive potential that is due to the interaction of the moving electrons with the incident photons.",
                    "score": 0.88692706823349
                },
                {
                    "id": 22566436,
                    "contents": "Extreme Electron Acceleration with Fixed Radiation Energy.\nWe examine the extreme situation of radiation from an electron that is asymptotically accelerated to the speed of light, resulting in finite emission energy. The analytic solution explicitly demonstrates the difference between radiation power loss and kinetic power loss (null).",
                    "score": 0.8829888701438904
                },
                {
                    "id": 9553079,
                    "contents": "The efficiency curve: a new function.\nWorking from first principles, an efficiency curve function has been developed by considering the physics of photon transport through matter. The function has been compared to other function in popular usage and been found to fit the data better especially about the knee of the curve. The main disadvantage of the new function is that it is data hungry, but this can be overcome by use of Monte Carlo simulations.",
                    "score": 0.8802709579467773
                },
                {
                    "id": 4736833,
                    "contents": "Observation of the Kapitza-Dirac effect.\nIn their famous 1927 experiment, Davisson and Germer observed the diffraction of electrons by a periodic material structure, so showing that electrons can behave like waves. Shortly afterwards, Kapitza and Dirac predicted that electrons should also be diffracted by a standing light wave. This Kapitza-Dirac effect is analogous to the diffraction of light by a grating, but with the roles of the wave and matter reversed. The electron and the light grating interact extremely weakly, via the 'ponderomotive potential', so attempts to measure the Kapitza-Dirac effect had to wait for the development of the laser. The idea that the underlying interaction with light is resonantly enhanced for electrons in an atom led to the observation that atoms could be diffracted by a standing wave of light. Deflection of electrons by high-intensity laser light, which is also a consequence of the Kapitza-Dirac effect, has also been demonstrated. But the coherent interference that characterizes wave diffraction has not hitherto been observed. Here we report the diffraction of free electrons from a standing light wave-a realization of the Kapitza-Dirac effect as originally proposed.",
                    "score": 0.8761266469955444
                },
                {
                    "id": 6490065,
                    "contents": "Electromagnetic fields on a quantum scale. I.\nThis is the first in a series of two articles, the second of which provides an exact electro-magnetic field description of photon emission, absorption, and radiation pattern. Photon energy exchanges are analyzed and shown to be the triggered, regenerative response of a non-local eigenstate electron. This first article presents a model-based, hidden variable analysis of quantum theory that provides the statistical nature of wave functions. The analysis uses the equations of classical electro-magnetism and conservation of energy while modeling an eigenstate electron as a nonlocal entity. Essential to the analysis are physical properties that were discovered and analyzed only after the historical interpretation of quantum mechanics was established: electron non-locality and the standing electro-magnetic energy that accompanies and encompasses an active, electrically small volume. The standing energy produces a driving radiation reaction force that, under certain circumstances, is many orders of magnitude larger than currently accepted values. These properties provide a sufficient basis for the Schrödinger equation as a descriptor of non-relativistic eigenstate electrons in or near equilibrium. The uncertainty principle follows, as does the exclusion principle. The analysis leads to atomic stability and causality in the sense that the status of physical phenomena at any instant specifies the status an instant later.",
                    "score": 0.87225741147995
                },
                {
                    "id": 2094351,
                    "contents": "Theoretical research on electron optics.\nThis paper summarizes theoretical research on electron optics in the field of electron microscopy that has been carried out by the author and his colleagues over a long period of time. The main topics to be discussed include the rotationally symmetrical imaging system and its aberrations; the method of matrix algebraic calculation and its applications to electron optics; new developments in scanning electron beam systems, i.e., the combined electromagnetic focusing-deflection system with superimposed fields; the electromagnetic multipole system and its aberrations; the ion optical system with a curvilinear axis and its aberrations; and the phase retrieval in Fourier electron microscopy. This review may help to promote a better understanding of the present state of, and trends in, Chinese electron optics research.",
                    "score": 0.8716230392456055
                },
                {
                    "id": 11469371,
                    "contents": "The development of soviet optics and spectroscopy during the past fifty years.\nA history of Soviet spectroscopy is given, with special emphasis on various areas indicating the earliest workers in each specialty and their principal successors; for example, the work of Rozhdestvenskii (anomalous dispersion); Fok (self-consistant field calculations), Terenin (photochemistry, atomic beams), Mandelstam (combination scattering), Vavilov (luminescence, quantum properties of light), Cerenkov (radiation), Chaika (atomic lifetimes), Gross (excitons), and Volkenstein (molecular vibrations).",
                    "score": 0.8714193105697632
                },
                {
                    "id": 10673696,
                    "contents": "Multiphoton absorption and emission by interaction of swift electrons with evanescent light fields.\nWe introduce a theory to describe the interaction of swift electrons with strong evanescent light fields. This allows us to explain recent experimental results of multiple energy losses and gains for electrons passing near illuminated nanostructures. A complex evolution of the electron state over attosecond time scales is unveiled, giving rise to non-Poissonian distributions of multiphoton features in the electron spectra. Prospects for application to nanoscale-resolved transmission electron microscopy and spectroscopy are discussed.",
                    "score": 0.8694734573364258
                },
                {
                    "id": 13955594,
                    "contents": "A surprise in the first Born approximation for electron scattering.\nA standard textbook derivation for the scattering of electrons by a weak potential under the first Born approximation suggests that the far-field scattered wave should be in phase with the incident wave. However, it is well known that waves scattered from a weak phase object should be phase-shifted by π/2 relative to the incident wave. A disturbing consequence of this missing phase is that, according to the Optical Theorem, the total scattering cross section would be zero in the first Born approximation. We resolve this mystery pedagogically by showing that the first Born approximation fails to conserve electrons even to first order. Modifying the derivation to conserve electrons introduces the correct phase without changing the scattering amplitude. We also show that the far-field expansion for the scattered waves used in many texts is inappropriate for computing an exit wave from a sample, and that the near-field expansion also give the appropriately phase-shifted result.",
                    "score": 0.8690396547317505
                },
                {
                    "id": 21057275,
                    "contents": "Author Correction: Analysis of laser radiation using the Nonlinear Fourier transform.\nAn amendment to this paper has been published and can be accessed via a link at the top of the paper.",
                    "score": 0.8680171370506287
                },
                {
                    "id": 17831700,
                    "contents": "Electron energy analysis by phase-space shaping with THz field cycles.\nTime-resolved electron energy analysis and loss spectroscopy can reveal a wealth of information about material properties and dynamical light-matter interactions. Here, we report an all-optical concept for measuring energy spectra of femtosecond electron pulses with sub-eV resolution. Laser-generated terahertz radiation is used to measure arrival time differences within electron pulses with few-femtosecond precision. Controlled dispersion and subsequent compression of the electron pulses provide almost any desired compromise of energy resolution, signal strength, and time resolution. A proof-of-concept experiment on aluminum reveals an energy resolution of &lt;3.5 eV (rms) at 70-keV after a drift distance of only 0.5 m. Simulations of a two-stage scheme reveal that pre-stretched pulses can be used to achieve &lt;10 meV resolution, independent of the source's initial energy spread and limited only by the achievable THz field strength and measuring time.",
                    "score": 0.8676766753196716
                },
                {
                    "id": 7977198,
                    "contents": "Ultrashort electron pulses for diffraction, crystallography and microscopy: theoretical and experimental resolutions.\nPulsed electron beams allow for the direct atomic-scale observation of structures with femtosecond to picosecond temporal resolution in a variety of fields ranging from materials science to chemistry and biology, and from the condensed phase to the gas phase. Motivated by recent developments in ultrafast electron diffraction and imaging techniques, we present here a comprehensive account of the fundamental processes involved in electron pulse propagation, and make comparisons with experimental results. The electron pulse, as an ensemble of charged particles, travels under the influence of the space-charge effect and the spread of the momenta among its electrons. The shape and size, as well as the trajectories of the individual electrons, may be altered. The resulting implications on the spatiotemporal resolution capabilities are discussed both for the N-electron pulse and for single-electron coherent packets introduced for microscopy without space-charge.",
                    "score": 0.8674318790435791
                },
                {
                    "id": 13178664,
                    "contents": "Time-resolved spectra from millivolt EELS data.\nThe millivolt energy resolution now obtainable in electron energy-loss spectra (EELS) on the latest monochromated scanning transmission electron microscope corresponds, via the uncertainty principle, to a time range of 414 fs (for 10 meV resolution), and a time resolution of 0.138 fs (for energy range of 30 eV). (Thus, the width of an EELS peak is inversely related to the lifetime of an excitation.) This compares favorably with the latest X-ray free electron lasers. The time evolution of a Drude-Lorentz oscillator may be obtained from an EELS using logarithmic deconvolution followed by Kramers-Kronig analysis to extract the frequency-dependent dielectric function, and a final Fourier transform from frequency to time domain. This time-dependent dielectric function was interpreted as the impulse response of electrons, phonons, or ions based on the Drude-Lorentz theory. The time evolution of electronic oscillators from ice and protein, extracted from low resolution experimental data, were compared. Using higher energy resolution data we have also extracted the time-resolved spectra from excitons in an alkali halide, BaF2. Despite the small scanning transmission electron microscope probe size, delocalization limits the spatial resolution to about 50 nm, which is, nevertheless, better than the millimeter resolution of infrared absorption spectroscopy or Raman spectroscopy. ",
                    "score": 0.8672971725463867
                },
                {
                    "id": 6729924,
                    "contents": "Electron interference: mystery and reality.\nInterference of electron waves has developed from a fascinating phenomenon in basic physics to a key method for the highly sophisticated investigation of both electric and magnetic structures in solid-state materials. After more than 20 years of development, electron holography in the transmission electron microscope is now a very powerful technique for the analysis of micro-fields down to atomic dimensions. The applications extend from highly sensitive measurements in semiconductor technology to the quantitative characterization of atomic structures.",
                    "score": 0.866274356842041
                },
                {
                    "id": 10367730,
                    "contents": "Controlling the velocity of light pulses.\nIt is now possible to exercise a high degree of control over the velocity at which light pulses pass through material media. This velocity, known as the group velocity, can be made to be very different from the speed of light in a vacuum c. Specifically, the group velocity of light can be made much smaller than c, greater than c, or even negative. We present a survey of methods for establishing extreme values of the group velocity, concentrating especially on methods that work in room-temperature solids. We also describe some applications of slow light.",
                    "score": 0.8649511337280273
                },
                {
                    "id": 11231225,
                    "contents": "Studying atomic structures by aberration-corrected transmission electron microscopy.\nSeventy-five years after its invention, transmission electron microscopy has taken a great step forward with the introduction of aberration-corrected electron optics. An entirely new generation of instruments enables studies in condensed-matter physics and materials science to be performed at atomic-scale resolution. These new possibilities are meeting the growing demand of nanosciences and nanotechnology for the atomic-scale characterization of materials, nanosynthesized products and devices, and the validation of expected functions. Equipped with electron-energy filters and electron-energy-loss spectrometers, the new instruments allow studies not only of structure but also of elemental composition and chemical bonding. The energy resolution is about 100 milli-electron volts, and the accuracy of spatial measurements has reached a few picometers. However, understanding the results is generally not straightforward and only possible with extensive quantum-mechanical computer calculations.",
                    "score": 0.8649077415466309
                },
                {
                    "id": 7897791,
                    "contents": "Surface microanalysis with slow electrons.\nMicroanalysis on the 10-nm level using imaging, diffraction, and spectroscopy of slow photo-emitted and reflected electrons is discussed. The instrumentation that uses a cathode lens is briefly reviewed, and a number of applications illustrate the power of this microanalysis method.",
                    "score": 0.864407479763031
                },
                {
                    "id": 5292338,
                    "contents": "An empirical energy loss equation of electrons.\nA modified Love-Cox-Scott (1978) equation of electron energy loss has been suggested. The stopping powers predicted by the modified Love-Cox-Scott equation are compared with those by the Tung et al. (1979) model, the Joy and Luo (1989) equation, and the experimental data given in database of Joy at: http://web.ukt. edu/-scrutk. In the energy range of E0&lt; or = 5 keV, the Monte Carlo simulations of the electron scattering in Al, Ag, and Au have been performed, applying the Mott cross section for elastic scattering and the modified Love-Cox-Scott equation (1978) and the equations by Love et al. (1978) and Joy and Luo (1989), respectively, for the inelastic scattering. The calculated results on the backscattering coefficients, the energy distributions of the backscattered electrons, and the energy dissipation of the electron based on the three equations are compared.",
                    "score": 0.8643093109130859
                },
                {
                    "id": 11469361,
                    "contents": "Hakenmethode.\nThe experimental technique and the general theory of the hakenmethode (hook method or dispersion method) is reviewed. The review presents the basic experimental arrangement for the formation of hooks in a crossed interferometer-spectrometer system and the experimental parameters of importance of an f-value measurement by the hakenmethode. The significance of the complex index of refraction of a dispersive and dissipative medium and its relation to the hakenmethode technique, as applied to single- and multiple-line spectra is described in some detail. Penkin's total absorption method for measuring absolute f values by combining the hakenmethode with absorption measurements is reviewed. A method (similar to a Voigt profile analysis) is introduced for studying the formation of hooks about spectral lines whose absorption widths may be an appreciable fraction of the hook separation.",
                    "score": 0.864205002784729
                },
                {
                    "id": 21831030,
                    "contents": "Observing the Quantum Wave Nature of Free Electrons through Spontaneous Emission.\nWe investigate, both experimentally and theoretically, the interpretation of the free-electron wave function using spontaneous emission. We use a transversely wide single-electron wave function to describe the spatial extent of transverse coherence of an electron beam in a standard transmission electron microscope. When the electron beam passes next to a metallic grating, spontaneous Smith-Purcell radiation is emitted. We then examine the effect of the electron wave function transversal size on the emitted radiation. Two interpretations widely used in the literature are considered: (1) radiation by a continuous current density attributed to the quantum probability current, equivalent to the spreading of the electron charge continuously over space; and (2) interpreting the square modulus of the wave function as a probability distribution of finding a point particle at a certain location, wherein the electron charge is always localized in space. We discuss how these two interpretations give contradictory predictions for the radiation pattern in our experiment, comparing the emission from narrow and wide wave functions with respect to the emitted radiation's wavelength. Matching our experiment with a new quantum-electrodynamics derivation, we conclude that the measurements can be explained by the probability distribution approach wherein the electron interacts with the grating as a classical point charge. Our findings clarify the transition between the classical and quantum regimes and shed light on the mechanisms that take part in general light-matter interactions.",
                    "score": 0.8612637519836426
                },
                {
                    "id": 10633824,
                    "contents": "Optical emission from the interaction of fast electrons with metallic films containing a circular aperture: a study of radiative decoherence of fast electrons.\nLight emission resulting from the interaction of swift electrons with a distant material is shown to produce an unexpectedly large fraction of decoherence in the moving charges. The decoherence probability diverges for an electron passing through a hole drilled in a perfectly conducting metal film, regardless of the size of the opening. This divergence, which is logarithmic in the ratio of film radius to aperture radius, originates in an infrared catastrophe that differs from other sources of decoherence (e.g., bremsstrahlung radiation). Our results provide new avenues for controlling and assessing the role of coherence during electron acceleration (for example, in transmission electron microscopes) and for exploiting partial quantum interference of fast electrons.",
                    "score": 0.8608931303024292
                },
                {
                    "id": 3213775,
                    "contents": "A new method to determine ratios of electron stopping powers to an improved accuracy.\nA new method is presented to determine the ratio of electron stopping powers which is effective in the transfer of absorbed dose from one medium to another. The method involves an accurate measurement of the electron range in each of the media combined with a full Monte Carlo simulation of each experimental geometry. For the specific case of graphite and water, the uncertainty attainable is estimated to be around +/- 0.5% at the 95% confidence level, which is approximately a factor of three better than the best methods currently in use.",
                    "score": 0.8604910373687744
                },
                {
                    "id": 8655580,
                    "contents": "Motion of an electron from a point source in parallel electric and magnetic fields.\nNegative ions undergoing near-threshold photodetachment in a weak laser field provide an almost pointlike, isotropic source of low-energy electrons. External fields exert forces on the emitted coherent electron wave and direct its motion. Here, we examine the spatial distribution of photodetached electrons in uniform, parallel electric and magnetic fields. The interplay of the electric and magnetic forces leads to a surprising intricate shape of the refracted electron wave, and multiple interfering trajectories generate complex fringe patterns in the matter wave. The exact quantum solution is best understood in terms of the classical electron motion.",
                    "score": 0.8600263595581055
                },
                {
                    "id": 19635127,
                    "contents": "The coherence of light is fundamentally tied to the quantum coherence of the emitting particle.\nCoherent emission of light by free charged particles is believed to be successfully captured by classical electromagnetism in all experimental settings. However, recent advances triggered fundamental questions regarding the role of the particle wave function in these processes. Here, we find that even in seemingly classical experimental regimes, light emission is fundamentally tied to the quantum coherence and correlations of the emitting particle. We use quantum electrodynamics to show how the particle's momentum uncertainty determines the optical coherence of the emitted light. We find that the temporal duration of Cherenkov radiation, envisioned for almost a century as a shock wave of light, is limited by underlying entanglement between the particle and light. Our findings enable new capabilities in electron microscopy for measuring quantum correlations of shaped electrons. Last, we propose new Cherenkov detection schemes, whereby measuring spectral photon autocorrelations can unveil the wave function structure of any charged high-energy particle.",
                    "score": 0.8596950769424438
                },
                {
                    "id": 15845265,
                    "contents": "Electron dynamics controlled via self-interaction.\nThe dynamics of an electron in a strong laser field can be significantly altered by radiation reaction. This usually results in a strongly damped motion, with the electron losing a large fraction of its initial energy. Here we show that the electron dynamics in a bichromatic laser pulse can be indirectly controlled by a comparatively small radiation reaction force through its interplay with the Lorentz force. By changing the relative phase between the two frequency components of the bichromatic laser field, an ultrarelativistic electron bunch colliding head-on with the laser pulse can be deflected in a controlled way, with the deflection angle being independent of the initial electron energy. The effect is predicted to be observable with laser powers and intensities close to those of current state-of-the-art petawatt laser systems. ",
                    "score": 0.8596493005752563
                },
                {
                    "id": 16008519,
                    "contents": "Erratum: The NIST Length Scale Interferometer.\n[This corrects the article on p. 225 in vol. 104.].",
                    "score": 0.8593559265136719
                },
                {
                    "id": 14583760,
                    "contents": "The refractive index in electron microscopy and the errors of its approximations.\nIn numerical calculations for electron diffraction often a simplified form of the electron-optical refractive index, linear in the electric potential, is used. In recent years improved calculation schemes have been proposed, aiming at higher accuracy by including higher-order terms of the electric potential. These schemes start from the relativistically corrected Schrödinger equation, and use a second simplified form, now for the refractive index squared, being linear in the electric potential. The second and higher-order corrections thus determined have, however, a large error, compared to those derived from the relativistically correct refractive index. The impact of the two simplifications on electron diffraction calculations is assessed through numerical comparison of the refractive index at high-angle Coulomb scattering and of cross-sections for a wide range of scattering angles, kinetic energies, and atomic numbers.",
                    "score": 0.8593024015426636
                },
                {
                    "id": 12891787,
                    "contents": "Direct optical measurements of the evolving spatio-temporal charge density in ultrashort electron pulses.\nThe temporal evolution of the charge density distribution in femtosecond laser produced electron pulses was studied using electron-laser pulse cross correlation techniques and compared to analytical predictions and simulations. The influence of propagation time and weak magnetic focusing were both investigated. Our results show that ultrashort electron pulses develop a relatively uniform internal charge density as they propagate, which is in good agreement with analytical predictions, and that weakly focusing an ultrashort electron pulse results in an increased internal charge density towards the leading edge of the pulse.",
                    "score": 0.8588508367538452
                },
                {
                    "id": 23547850,
                    "contents": "An electron walks into a quantum bar….\nQuantum electron-light interaction may find use in microscopy applications.",
                    "score": 0.8586446046829224
                },
                {
                    "id": 16687789,
                    "contents": "Subpicosecond and Sub-Angstrom Time and Space Studies by Means of Light, X-ray, and Electron Interaction with Matter.\nThis Perspective article considers an experimental system that consists of ultrafast optical, electron, and X-ray time-resolved components. These techniques are used simultaneously on the same sample to study, in real time, the events that occur immediately upon disturbance with an ultrafast optical pulse. Excited states and metastable species are generated on the surface, and the electrical and mechanical waves propagating through the sample are recorded with subpicosecond and sub-Angstrom resolution. The characteristic of each technique is briefly described as a means of introducing the experimental system that intergrates these techniques. The processes evolved after femtosecond excitation of a Au single crystal have been monitored by these techniques. The data presented show changes with a resolution of 0.3 ± 0.1 ps in optical thermoreflectance, 1.0 ± 0.2 ps in electron Bragg diffraction, and 0.6 ± 0.1 ps in X-ray diffraction intensity accompanying shift and broadening. ",
                    "score": 0.8584102392196655
                },
                {
                    "id": 16740215,
                    "contents": "Optics. Spatially structured photons that travel in free space slower than the speed of light.\nThat the speed of light in free space is constant is a cornerstone of modern physics. However, light beams have finite transverse size, which leads to a modification of their wave vectors resulting in a change to their phase and group velocities. We study the group velocity of single photons by measuring a change in their arrival time that results from changing the beam's transverse spatial structure. Using time-correlated photon pairs, we show a reduction in the group velocity of photons in both a Bessel beam and photons in a focused Gaussian beam. In both cases, the delay is several micrometers over a propagation distance of ~1 meter. Our work highlights that, even in free space, the invariance of the speed of light only applies to plane waves. ",
                    "score": 0.8583563566207886
                },
                {
                    "id": 22165692,
                    "contents": "The pre-exponential voltage-exponent as a sensitive test parameter for field emission theories.\nFor field electron emission (FE), an empirical equation for measured current <iI</i <subm</sub as a function of measured voltage <iV</i <subm</sub has the form <iI</i <subm</sub = <iCV</i <subm</sub <i<supk</sup</i exp[-<iB</i/<iV</i <subm</sub], where <iB</i is a constant and <iC</i and <ik</i are constants or vary weakly with <iV</i <subm</sub. Values for <ik</i can be extracted (i) from simulations based on some specific FE theory, and in principle (ii) from current-voltage measurements of sufficiently high quality. This paper shows that a comparison of theoretically derived and experimentally derived <ik-</ivalues could provide a sensitive and useful tool for comparing FE theory and experiment, and for choosing between alternative theories. Existing methods of extracting <ik</i-values from experimental or simulated current-voltage data are discussed, including a modernized 'least residual' method, and existing knowledge concerning <ik</i-values is summarized. Exploratory simulations are reported. Where an analytical result for <ik</i is independently known, this value is reliably extracted. More generally, extracted <ik</i-values are sensitive to details of the emission theory used, but also depend on assumed emitter shape; these two influences will need to be disentangled by future research, and a range of emitter shapes will need examination. Other procedural conclusions are reported. Some scientific issues that this new tool may eventually be able to help investigate are indicated.",
                    "score": 0.8581632375717163
                },
                {
                    "id": 17642017,
                    "contents": "Asymmetry and non-dispersivity in the Aharonov-Bohm effect.\nDecades ago, Aharonov and Bohm showed that electrons are affected by electromagnetic potentials in the absence of forces due to fields. Zeilinger's theorem describes this absence of classical force in quantum terms as the \"dispersionless\" nature of the Aharonov-Bohm effect. Shelankov predicted the presence of a quantum \"force\" for the same Aharonov-Bohm physical system as elucidated by Berry. Here, we report an experiment designed to test Shelankov's prediction and we provide a theoretical analysis that is intended to elucidate the relation between Shelankov's prediction and Zeilinger's theorem. The experiment consists of the Aharonov-Bohm physical system; free electrons pass a magnetized nanorod and far-field electron diffraction is observed. The diffraction pattern is asymmetric confirming one of Shelankov's predictions and giving indirect experimental evidence for the presence of a quantum \"force\". Our theoretical analysis shows that Zeilinger's theorem and Shelankov's result are both special cases of one theorem.",
                    "score": 0.8581523895263672
                },
                {
                    "id": 21084269,
                    "contents": "Quantum optics with swift electrons.\nStimulated and spontaneous interactions of electron wavepackets with optical near fields were explored with complementary techniques. In striking agreement with theory, scientists have demonstrated the dependence of spontaneous and stimulated quantum mechanical processes on the spatial distribution of optical modes.",
                    "score": 0.8579046130180359
                },
                {
                    "id": 4203003,
                    "contents": "The tracks of the Compton effect.\nThe observation of scattered radiations of larger wavelength than the primary had been repeatedly rejected or explained away by many researchers, including Compton. After years of vacillations, he recognized the effect named after him and was the first to develop a quantal equation predicting the wavelength of scattered radiation. It became one of the most significant contributions to modern radiation physics, opening the doors of quantum mechanics.",
                    "score": 0.8578495979309082
                },
                {
                    "id": 16298996,
                    "contents": "Unveiling the orbital angular momentum and acceleration of electron beams.\nNew forms of electron beams have been intensively investigated recently, including vortex beams carrying orbital angular momentum, as well as Airy beams propagating along a parabolic trajectory. Their traits may be harnessed for applications in materials science, electron microscopy, and interferometry, and so it is important to measure their properties with ease. Here, we show how one may immediately quantify these beams' parameters without need for additional fabrication or nonstandard microscopic tools. Our experimental results are backed by numerical simulations and analytic derivation. ",
                    "score": 0.8578336238861084
                },
                {
                    "id": 17717604,
                    "contents": "Progress in ultrahigh energy resolution EELS.\nElectron energy loss spectroscopy (EELS) in the electron microscope has progressed remarkably in the last five years. Advances in monochromator and spectrometer design have improved the energy resolution attainable in a scanning transmission electron microscope (STEM) to 4.2 meV, and new applications of ultrahigh energy resolution EELS have not lagged behind. They include vibrational spectroscopy in the electron microscope, a field that did not exist 5 years ago but has now grown very substantially. Notable examples include vibrational mapping with about 1 nm spatial resolution, analyzing the momentum dependence of vibrational states in very small volumes, determining the local temperature of the sample from the ratio of energy gains to energy losses, detecting hydrogen and analyzing its bonding, probing radiation-sensitive materials with minimized damage by aloof spectroscopy and leap-frog scanning, and identifying biological molecules with different isotopic substitutions. We review the instrumentation advances, provide a summary of key applications, and chart likely future directions.",
                    "score": 0.8577644228935242
                },
                {
                    "id": 3239887,
                    "contents": "A solution to the Yang equation with electron energy loss following Harder's formula.\nThe Yang diffusion transport equation for charged particles was modified to allow the linear angular scattering power to vary with penetration depth in the scattering medium. Assuming charged particle energy loss to be a linear function of depth, conditional solutions to this transport equation have been found for the two cases of interest specified by Yang. The normalized excess path length distributions predicted for a 10-MeV electron beam show a shift toward larger excess path lengths compared to Yang's solutions.",
                    "score": 0.8577452898025513
                },
                {
                    "id": 15144670,
                    "contents": "Ruling Engines, Diffraction Gratings and Wavelength Measurements before the Rowland Era.\nDiffraction gratings have contributed enormously to modern science. Although some historians have written about them, there is much more to be brought to light. This paper discusses their development and use in the period up to about 1880 before Rowland began to produce them. Rittenhouse described the action of a diffraction grating in 1786, but no explanation was possible until the wave theory of light was developed. Fraunhofer discovered the dark lines in the solar spectrum in 1814, and then investigated diffraction, producing the first ruled gratings, making detailed measurements and calculating the wavelengths of prominent spectral lines. After Bunsen and Kirchhoff showed the association between spectral lines and chemical elements there was an upsurge of interest in measuring wavelengths. The gratings used in this work almost all came from one source, a relatively unknown instrument maker called Nobert, who made them by an extremely laborious process using a machine he had built himself. The most significant wavelength measurements were made by Ångström, but Mascart, Van der Willigen, Stefan, Ditscheiner and Cornu also did important work. Nobert gratings were investigated by Quincke, copied photographically by Rayleigh, and were known and discussed in the USA. Nobert's work helped to advance spectroscopy much more than has been acknowledged. ",
                    "score": 0.8575212359428406
                },
                {
                    "id": 8261280,
                    "contents": "Photon correlation and scattering: introduction to the feature issue.\nThis feature issue of Applied Optics contains 31 research papers on photon correlation and scattering, many of which were presented at an OSA Topical Meeting that was held 21-23 August 2000 in Whistler, British Columbia, Canada. These papers focus on research in dynamic light scattering, surface light scattering, photon correlation, and laser velocimetry and their applications to physical, chemical, and biological processes.",
                    "score": 0.857424795627594
                },
                {
                    "id": 10059428,
                    "contents": "Single-photon generation by electron beams.\nWe propose a drastically new method for generating single photons in a deterministic way by interaction of electron beams with optical waveguides. We find a single swift electron to produce a guided photon with large probability. The change in energy and propagation direction of the electron reveals the creation of a photon, with the photon energy directly read from the energy-loss spectrum or the beam displacement. Our study demonstrates the viability of deterministically creating single guided photons using electron beams with better than picosecond time uncertainty, thus opening a new avenue for making room temperature, heralded frequency-tunable sources affordable for scientific and commercial developments.",
                    "score": 0.8573479652404785
                },
                {
                    "id": 9405778,
                    "contents": "Infrared reststrahlen revisited: commonly disregarded optical details related to n&lt;1.\nSpectral ellipsometry has developed into a routine method applicable to the infrared spectral range. It can give both the refractive index (n) and the absorption index (k), which has so far only been determined for a limited number of compounds. It turns out that vibrations that have a dispersion with an interval of n&lt;1 are by no means restricted to crystals, but occur with numerous compounds including polymers and liquids. In conventional infrared spectroscopy, one usually is not aware of such a situation and so the consequences are disregarded. These include the so-called reststrahlen (residual rays) bands and specific phenomena that occur when n matches the absorption index (the Berreman effect) or the refractive index of ambient air (vanishing reflection, the Christiansen effect). These and some typical applications are discussed, including model calculations and experimental data.",
                    "score": 0.8570225238800049
                },
                {
                    "id": 17114908,
                    "contents": "Author Correction: Poisson's ratio and modern materials.\nIn the version of this Review Article originally published, parentheses were misplaced and the longitudinal and transverse speeds were inverted in two expressions for Poisson's ratio in Box 2; the expressions should have read, respectively, ν = (3B/G - 2)/(6B/G + 2) and ν = [½(V<subl</sub/V<subt</sub)<sup2</sup - 1]/[(V<subl</sub/V<subt</sub)<sup2</sup - 1].",
                    "score": 0.8569632172584534
                },
                {
                    "id": 10456023,
                    "contents": "Ludvig Lorenz and nineteenth century optical theory: the work of a great Danish scientist.\nThe career of the Danish physicist Ludvig V. Lorenz (1829-1891) is outlined and his contributions to optical theory between 1860 and 1891 are discussed: the elastic theory of light (1860-1861), the phenomenological wave equation (1862-1864), the electrodynamic theory of light (1867), the Lorenz-Lorentz refraction theory (1869), and the theory of scattering of plane waves by spherical particles (1890). The differences between the Lorenz and the Maxwell theories of light are pointed out, and it is argued that Lorenz's phenomenological attitude and indifference to Maxwellian theory were the main reasons why his mature works in optics exerted little influence.",
                    "score": 0.8568986058235168
                },
                {
                    "id": 1646793,
                    "contents": "Is the electron wavelength an observable?\nThis paper is concerned with a problem often overlooked; it stems from the fact that the electron wave is also influenced by the magnetic vector potential. If one considers this influence, problems arise from the ambiguities in the gauge of the vector potential. They bear on the question of whether the electron wavelength can be considered observable or not. The answer lies, probably, in the definition of measurability.",
                    "score": 0.8568387031555176
                },
                {
                    "id": 18937114,
                    "contents": "Tunneling Flight Time, Chemistry, and Special Relativity.\nAttosecond ionization experiments have not resolved the question \"What is the tunneling time?\". Different definitions of tunneling time lead to different results. Second, a zero tunneling time for a material particle suggests that the nonrelativistic theory includes speeds greater than the speed of light. Chemical reactions, occurring via tunneling, should then not be considered in terms of a nonrelativistic quantum theory calling into question quantum dynamics computations on tunneling reactions. To answer these questions, we define a new experimentally measurable paradigm, the tunneling flight time, and show that it vanishes for scattering through an Eckart or a square barrier, irrespective of barrier length or height, generalizing the Hartman effect. We explain why this result does not lead to experimental measurement of speeds greater than the speed of light. We show that this tunneling is an incoherent process by comparing a classical Wigner theory with exact quantum mechanical computations.",
                    "score": 0.8567047119140625
                },
                {
                    "id": 14324693,
                    "contents": "Reexamination of the Doppler effect through Maxwell's equations.\nIn this work, the electric field emitted from a moving source, an electric point dipole, is analyzed for the purpose of illustrating the physics behind the Doppler effect. It is found that if the (translational) motion of the source is nonrelativistic, the Doppler effect is realized in two steps: the motion of the source first causes the dyadic Green function associated with the electric field to acquire an oscillation frequency in the far-field region of the source, and then the frequency leads to the Doppler effect. It is also demonstrated that the Doppler effect is observable only in the far-field region of the source.",
                    "score": 0.8566336035728455
                },
                {
                    "id": 7350948,
                    "contents": "Standard radiation spectrum of relativistic electrons: beyond the synchrotron approximation.\nRadiation emitted by an electron in arbitrary, extreme relativistic motion, has been described for the first time in terms of a standard spectrum of nonsynchrotron type. Ultimately, such a nonsynchrotron spectrum is dependent not only on instantaneous trajectory curvature, but also upon its first two time derivatives and helicity, to provide a basic correction to the synchrotron approximation (SA). A strong deviation from SA has been predicted for above GeV electrons in oriented crystals.",
                    "score": 0.8566235303878784
                },
                {
                    "id": 9961089,
                    "contents": "Maxwell's Scientific Papers.\nThis article is a review of a reprint of the 1890 commemoration edition of The Scientific Papers of James Clerk Maxwell (Dover Publications, Inc., New York), $12.50. Vol. 1, 607 pp.; Vol.2, 806 pp. One hundred and one of Maxwell's shorter papers, articles, speeches, and reviews on electricity and magnetism, the dynamical theory of gases, theory of light, color vision and other optical problems, elastic solids, molecular physics, etc., are in this reprint; his longer treatises on electricity and magnetism, heat, and matter and motion are not included. This review is illustrated with photographs from the Maxwell family archives which have not been published before.",
                    "score": 0.8564832210540771
                },
                {
                    "id": 10656539,
                    "contents": "Comment on: Quantum optics with particles of light.\nErrors in the recent article, \"Quantum optics with particles of light,\" are discussed. \"Dispersed states\" resulting from linear optics are simply coherent states, and have no interesting quantum statistics.",
                    "score": 0.8564453721046448
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    }
]