[
    {
        "id": "test_0",
        "question": "Radiation from an X-ray source consists of two components of wavelengths $154.433 \\mathrm{pm}$ and $154.051 \\mathrm{pm}$. Calculate the difference in glancing angles $(2 \\theta)$ of the diffraction lines arising from the two components in a diffraction pattern from planes of separation $77.8 \\mathrm{pm}$.",
        "golden_answers": [
            " 2.14"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1337571,
                    "contents": "X-ray crystallography\nHence the atomic nuclei, which are much heavier than an electron, contribute negligibly to the scattered X-rays. Development from 1912 to 1920 After Von Laue's pioneering research, the field developed rapidly, most notably by physicists William Lawrence Bragg and his father William Henry Bragg. In 1912–1913, the younger Bragg developed Bragg's law, which connects the observed scattering with reflections from evenly spaced planes within the crystal. The Braggs, father and son, shared the 1915 Nobel Prize in Physics for their work in crystallography. The earliest structures were generally simple and marked by one-dimensional symmetry. However, as computational and experimental methods improved over the next decades, it became feasible to deduce reliable atomic positions for more complicated two- and three-dimensional arrangements of atoms in the unit-cell.",
                    "score": 0.9337050914764404
                },
                {
                    "id": 1337978,
                    "contents": "X-ray\nX-rays have much shorter wavelengths than visible light, which makes it possible to probe structures much smaller than can be seen using a normal microscope. This property is used in X-ray microscopy to acquire high-resolution images, and also in X-ray crystallography to determine the positions of atoms in crystals. Interaction with matter X-rays interact with matter in three main ways, through photoabsorption, Compton scattering, and Rayleigh scattering. The strength of these interactions depends on the energy of the X-rays and the elemental composition of the material, but not much on chemical properties, since the X-ray photon energy is much higher than chemical binding energies. Photoabsorption or photoelectric absorption is the dominant interaction mechanism in the soft X-ray regime and for the lower hard X-ray energies. At higher energies, Compton scattering dominates.",
                    "score": 0.9322240948677063
                },
                {
                    "id": 1337590,
                    "contents": "X-ray crystallography\nX-rays range in wavelength from 10 to 0.01 nanometers; a typical wavelength used for crystallography is 1 Å (0.1 nm), which is on the scale of covalent chemical bonds and the radius of a single atom. Longer-wavelength photons (such as ultraviolet radiation) would not have sufficient resolution to determine the atomic positions. At the other extreme, shorter-wavelength photons such as gamma rays are difficult to produce in large numbers, difficult to focus, and interact too strongly with matter, producing particle-antiparticle pairs. Therefore, X-rays are the \"sweetspot\" for wavelength when determining atomic-resolution structures from the scattering of electromagnetic radiation.",
                    "score": 0.9282167553901672
                },
                {
                    "id": 8692357,
                    "contents": "X-ray optics\nSimilar diffraction patterns can be produced by scattering electrons or neutrons. X-rays are usually not diffracted from atomic nuclei, but only from the electrons surrounding them. Interference X-ray interference is the addition (superposition) of two or more X-ray waves that results in a new wave pattern. X-ray interference usually refers to the interaction of waves that are correlated or coherent with each other, either because they come from the same source or because they have the same or nearly the same frequency. Two non-monochromatic X-ray waves are only fully coherent with each other if they both have exactly the same range of wavelengths and the same phase differences at each of the constituent wavelengths.",
                    "score": 0.927487313747406
                },
                {
                    "id": 1337566,
                    "contents": "X-ray crystallography\nHere d is the spacing between diffracting planes, is the incident angle, n is any integer, and λ is the wavelength of the beam. These specific directions appear as spots on the diffraction pattern called reflections. Thus, X-ray diffraction results from an electromagnetic wave (the X-ray) impinging on a regular array of scatterers (the repeating arrangement of atoms within the crystal).",
                    "score": 0.9262446761131287
                },
                {
                    "id": 1337644,
                    "contents": "X-ray crystallography\nIntuitive understanding by Bragg's law An intuitive understanding of X-ray diffraction can be obtained from the Bragg model of diffraction. In this model, a given reflection is associated with a set of evenly spaced sheets running through the crystal, usually passing through the centers of the atoms of the crystal lattice. The orientation of a particular set of sheets is identified by its three Miller indices (h, k, l), and let their spacing be noted by d. William Lawrence Bragg proposed a model in which the incoming X-rays are scattered specularly (mirror-like) from each plane; from that assumption, X-rays scattered from adjacent planes will combine constructively (constructive interference) when the angle θ between the plane and the X-ray results in a path-length difference that is an integer multiple n of the X-ray wavelength λ.",
                    "score": 0.9252398014068604
                },
                {
                    "id": 1337593,
                    "contents": "X-ray crystallography\nThe Laue back reflection mode records X-rays scattered backwards from a broad spectrum source. This is useful if the sample is too thick for X-rays to transmit through it. The diffracting planes in the crystal are determined by knowing that the normal to the diffracting plane bisects the angle between the incident beam and the diffracted beam. A Greninger chart can be used to interpret the back reflection Laue photograph. Electron and neutron diffraction Other particles, such as electrons and neutrons, may be used to produce a diffraction pattern. Although electron, neutron, and X-ray scattering are based on different physical processes, the resulting diffraction patterns are analyzed using the same coherent diffraction imaging techniques.",
                    "score": 0.9238529205322266
                },
                {
                    "id": 1337563,
                    "contents": "X-ray crystallography\nWilhelm Röntgen discovered X-rays in 1895, just as the studies of crystal symmetry were being completed. Physicists were uncertain of the nature of X-rays, but soon suspected that they were waves of electromagnetic radiation, a form of light. The Maxwell theory of electromagnetic radiation was well accepted among scientists, and experiments by Charles Glover Barkla showed that X-rays exhibited phenomena associated with electromagnetic waves, including transverse polarization and spectral lines akin to those observed in the visible wavelengths. Barkla created the x-ray notation, as well, noting in 1909 two separate types of diffraction beams, at first, naming them “A” and “B” and then supposing that there may be lines prior to “A”, he started an alphabet numbering beginning with “K.” Single-slit experiments in the laboratory of Arnold Sommerfeld suggested that X-rays had a wavelength of about 1 angstrom. X-rays are not only waves but are also photons, and have particle properties",
                    "score": 0.923763632774353
                },
                {
                    "id": 2875284,
                    "contents": "Manne Siegbahn\nX-ray spectroscopy Manne Siegbahn began his studies of X-ray spectroscopy in 1914. Initially he used the same type of spectrometer as Henry Moseley had done for finding the relationship between the wavelength of some elements and their place at the periodic system. Shortly thereafter he developed improved experimental apparatus which allowed him to make very accurate measurements of the X-ray wavelengths produced by atoms of different elements. Also, he found that several of the spectral lines that Moseley had discovered consisted of more components. By studying these components and improving the spectrometer, Siegbahn got an almost complete understanding of the electron shell. He developed a convention for naming the different spectral lines that are characteristic to elements in X-ray spectroscopy, the Siegbahn notation. Siegbahn's precision measurements drove many developments in quantum theory and atomic physics.",
                    "score": 0.9213265180587769
                },
                {
                    "id": 1337567,
                    "contents": "X-ray crystallography\nX-rays are used to produce the diffraction pattern because their wavelength λ is typically the same order of magnitude (1–100 angstroms) as the spacing d between planes in the crystal. In principle, any wave impinging on a regular array of scatterers produces diffraction, as predicted first by Francesco Maria Grimaldi in 1665. To produce significant diffraction, the spacing between the scatterers and the wavelength of the impinging wave should be similar in size. For illustration, the diffraction of sunlight through a bird's feather was first reported by James Gregory in the later 17th century. The first artificial diffraction gratings for visible light were constructed by David Rittenhouse in 1787, and Joseph von Fraunhofer in 1821. However, visible light has too long a wavelength (typically, 5500 angstroms) to observe diffraction from crystals. Prior to the first X-ray diffraction experiments, the spacings between lattice planes in a crystal were not known with certainty.",
                    "score": 0.9211574196815491
                },
                {
                    "id": 8692356,
                    "contents": "X-ray optics\nX-ray diffraction is a form of elastic scattering in the forward direction; the outgoing X-rays have the same energy, and thus the same wavelength, as the incoming X-rays, only with altered direction. By contrast, inelastic scattering occurs when energy is transferred from the incoming X-ray to an inner-shell electron, exciting it to a higher energy level. Such inelastic scattering reduces the energy (or increases the wavelength) of the outgoing beam. Inelastic scattering is useful for probing such electron excitation, but not in determining the distribution of atoms within the crystal. Longer-wavelength photons (such as ultraviolet radiation) would not have sufficient resolution to determine the atomic positions. At the other extreme, shorter-wavelength photons such as gamma rays are difficult to produce in large numbers, difficult to focus, and interact too strongly with matter, producing particle–antiparticle pairs.",
                    "score": 0.9210877418518066
                },
                {
                    "id": 4058630,
                    "contents": "Wavelength-dispersive X-ray spectroscopy\nX-ray measurement According to Bragg's law, when an X-ray beam of wavelength \"λ\" strikes the surface of a crystal at an angle \"Θ\" and the crystal has atomic lattice planes a distance \"d\" apart, then constructive interference will result in a beam of diffracted x-rays that will be emitted from the crystal at angle \"Θ\" if nλ = 2d sin Θ, where n is an integer. This means that a crystal with a known lattice size will deflect a beam of x-rays from a specific type of sample at a pre-determined angle. The x-ray beam can be measured by placing a detector (usually a scintillation counter or a proportional counter) in the path of the deflected beam and, since each element has a distinctive x-ray wavelength, multiple elements can be determined by having multiple crystals and multiple detectors.",
                    "score": 0.9210762977600098
                },
                {
                    "id": 3086296,
                    "contents": "Arthur Compton\nCompton's first book, X-Rays and Electrons, was published in 1926. In it he showed how to calculate the densities of diffracting materials from their X-ray diffraction patterns. He revised his book with the help of Samuel K. Allison to produce X-Rays in Theory and Experiment (1935). This work remained a standard reference for the next three decades.",
                    "score": 0.9202073812484741
                },
                {
                    "id": 8692346,
                    "contents": "X-ray optics\nX-ray optics is the branch of optics that manipulates X-rays instead of visible light. It deals with focusing and other ways of manipulating the X-ray beams for research techniques such as X-ray crystallography, X-ray fluorescence, small-angle X-ray scattering, X-ray microscopy, X-ray phase-contrast imaging, X-ray astronomy etc. Since X-rays and visible light are both electromagnetic waves they propagate in space in the same way, but because of the much higher frequency and photon energy of X-rays they interact with matter very differently. Visible light is easily redirected using lenses and mirrors, but because the real part of the complex refractive index of all materials is very close to 1 for X-rays, they instead tend to initially penetrate and eventually get absorbed in most materials without changing direction much.",
                    "score": 0.9200481176376343
                },
                {
                    "id": 15669900,
                    "contents": "Yvette Cauchois\nResearch on x-rays and crystals In the early 1930s, Cauchois established the fundamental principles of a new x-ray spectrometer that was both easy to use and had a high resolution, satisfying the Bragg reflection condition. The new spectrometer was named after her, and from 1934 she used it to observe gas emissions and multiplets. The new technique was used around the world for the analysis of x-rays and gamma rays and prompted a wave of new scholarship in radiation studies. Cauchois pioneered developments in x-ray imaging and observed that x-ray radiation could be focused using curved crystal for use in monochromators and x-ray scattering. Cauchois' work on soft x-ray distributions was the first step in determining the photo-absorption spectra. She used the radiation reflected from crystals to study the electronic structure of materials.",
                    "score": 0.9189803004264832
                },
                {
                    "id": 8692354,
                    "contents": "X-ray optics\nThe ratio of reflected intensity to incident intensity is the X-ray reflectivity for the surface. If the interface is not perfectly sharp and smooth, the reflected intensity will deviate from that predicted by the Fresnel reflectivity law. The deviations can then be analyzed to obtain the density profile of the interface normal to the surface. For films with multiple layers, X-ray reflectivity may show oscillations with wavelength, analogous to the Fabry–Pérot effect. These oscillations can be used to infer layer thicknesses and other properties. Diffraction In X-ray diffraction a beam strikes a crystal and diffracts into many specific directions. The angles and intensities of the diffracted beams indicate a three-dimensional density of electrons within the crystal. X-rays produce a diffraction pattern because their wavelength typically has the same order of magnitude (0.1–10.0 nm) as the spacing between the atomic planes in the crystal.",
                    "score": 0.9185188412666321
                },
                {
                    "id": 16552728,
                    "contents": "Abram Alikhanov\ndoes not undergo allotropic transformation when X-rayed at 550–600°C. He also did a \"study of the total internal reflection of X rays from thin layers and the estimation of the depth of their penetration into the medium. Alikhanov also proved that the laws of classical optics can be applied to the reflection of hard X rays.\" Alikhanov summarized the results in a 1933 monograph titled X-Ray Optics (Оптика рентгеновских лучей).",
                    "score": 0.9171469807624817
                },
                {
                    "id": 4058629,
                    "contents": "Wavelength-dispersive X-ray spectroscopy\nTheory Wavelength-dispersive X-ray spectroscopy is based on known principles of how the characteristic x-rays are generated by a sample and how the x-rays are measured. X-ray generation X-rays are generated when an electron beam of high enough energy dislodges an electron from an inner orbital within an atom or ion, creating a void. This void is filled when an electron from a higher orbital releases energy and drops down to replace the dislodged electron. The energy difference between the two orbitals is characteristic of the electron configuration of the atom or ion and can be used to identify the atom or ion. The lightest elements, hydrogen, helium, lithium, Beryllium up to atomic number 5, do not have electrons in outer orbitals to replace an electron displaced by the electron beam and thus cannot be detected using this technique.",
                    "score": 0.9170098900794983
                },
                {
                    "id": 4498898,
                    "contents": "X-ray spectroscopy\nAn X-ray spectrograph consists of a high voltage power supply (50 kV or 100 kV), a broad band X-ray tube, usually with a tungsten anode and a beryllium window, a specimen holder, an analyzing crystal, a goniometer, and an X-ray detector device. These are arranged as shown in Fig. 1.",
                    "score": 0.9163296222686768
                },
                {
                    "id": 4498881,
                    "contents": "X-ray spectroscopy\nIn electron microscopy an electron beam excites X-rays; there are two main techniques for analysis of spectra of characteristic X-ray radiation: energy-dispersive X-ray spectroscopy (EDS) and wavelength dispersive X-ray spectroscopy (WDS). In X-Ray Transmission (XRT), the equivalent atomic composition (Zeff) is captured based on photoelectric and Compton effects.",
                    "score": 0.9162188172340393
                },
                {
                    "id": 1337971,
                    "contents": "X-ray\nEnergy ranges Soft and hard X-rays X-rays with high photon energies above 5–10 keV (below 0.2–0.1 nm wavelength) are called hard X-rays, while those with lower energy (and longer wavelength) are called soft X-rays. The intermediate range with photon energies of several keV is often referred to as tender X-rays. Due to their penetrating ability, hard X-rays are widely used to image the inside of objects, e.g., in medical radiography and airport security. The term X-ray is metonymically used to refer to a radiographic image produced using this method, in addition to the method itself. Since the wavelengths of hard X-rays are similar to the size of atoms, they are also useful for determining crystal structures by X-ray crystallography. By contrast, soft X-rays are easily absorbed in air; the attenuation length of 600 eV (~2 nm) X-rays in water is less than 1 micrometer.",
                    "score": 0.9157835245132446
                },
                {
                    "id": 8636679,
                    "contents": "X-ray reflectivity\nHistory The technique appears to have first been applied to X-rays by Lyman G. Parratt in 1954. Parratt's initial work explored the surface of copper-coated glass, but since that time the technique has been extended to a wide range of both solid and liquid interfaces. Approximation When an interface is not perfectly sharp, but has an average electron density profile given by , then the X-ray reflectivity can be approximated by: Here is the reflectivity, , is the X-ray wavelength (typically copper's K-alpha peak at 0.154056 nm), is the density deep within the material and is the angle of incidence. Below the critical angle (derived from Snell's law), 100% of incident radiation is reflected, . For , . Typically one can then use this formula to compare parameterized models of the average density profile in the z-direction with the measured X-ray reflectivity and then vary the parameters until the theoretical profile matches the measurement.",
                    "score": 0.9150853157043457
                },
                {
                    "id": 1206476,
                    "contents": "Radiation\nX-rays are electromagnetic waves with a wavelength less than about 10−9 m (greater than 3x1017 Hz and 1,240 eV). A smaller wavelength corresponds to a higher energy according to the equation E=h c/λ. (\"E\" is Energy; \"h\" is Planck's constant; \"c\" is the speed of light; \"λ\" is wavelength.) When an X-ray photon collides with an atom, the atom may absorb the energy of the photon and boost an electron to a higher orbital level or if the photon is extremely energetic, it may knock an electron from the atom altogether, causing the atom to ionize. Generally, larger atoms are more likely to absorb an X-ray photon since they have greater energy differences between orbital electrons. The soft tissue in the human body is composed of smaller atoms than the calcium atoms that make up bone, so there is a contrast in the absorption of X-rays. X-ray machines are specifically designed to take advantage of the absorption difference between bone and soft tissue, allowing physicians to examine structure",
                    "score": 0.9142410159111023
                },
                {
                    "id": 4498899,
                    "contents": "X-ray spectroscopy\nThe continuous X-spectrum emitted from the tube irradiates the specimen and excites the characteristic spectral X-ray lines in the specimen. Each of the 92 elements emits a characteristic spectrum. Unlike the optical spectrum, the X-ray spectrum is quite simple. The strongest line, usually the Kalpha line, but sometimes the Lalpha line, suffices to identify the element. The existence of a particular line betrays the existence of an element, and the intensity is proportional to the amount of the particular element in the specimen. The characteristic lines are reflected from a crystal, the analyzer, under an angle that is given by the Bragg condition. The crystal samples all the diffraction angles theta by rotation, while the detector rotates over the corresponding angle 2-theta. With a sensitive detector, the X-ray photons are counted individually. By stepping the detectors along the angle, and leaving it in position for a known time, the number of counts at each angular position gives",
                    "score": 0.9140016436576843
                },
                {
                    "id": 1337569,
                    "contents": "X-ray crystallography\nAfter being developed, the plate showed a large number of well-defined spots arranged in a pattern of intersecting circles around the spot produced by the central beam. Von Laue developed a law that connects the scattering angles and the size and orientation of the unit-cell spacings in the crystal, for which he was awarded the Nobel Prize in Physics in 1914.",
                    "score": 0.9135615229606628
                },
                {
                    "id": 1337642,
                    "contents": "X-ray crystallography\nThe Fourier transform F(q) is generally a complex number, and therefore has a magnitude |F(q)| and a phase φ(q) related by the equation The intensities of the reflections observed in X-ray diffraction give us the magnitudes |F(q)| but not the phases φ(q). To obtain the phases, full sets of reflections are collected with known alterations to the scattering, either by modulating the wavelength past a certain absorption edge or by adding strongly scattering (i.e., electron-dense) metal atoms such as mercury. Combining the magnitudes and phases yields the full Fourier transform F(q), which may be inverted to obtain the electron density f(r).",
                    "score": 0.9132001996040344
                },
                {
                    "id": 1337650,
                    "contents": "X-ray crystallography\nSince Euler's formula states that eix = cos(x) + i sin(x), the inverse Fourier transform can be separated into a sum of a purely real part and a purely imaginary part The function f(r) is real if and only if the second integral Isin is zero for all values of r. In turn, this is true if and only if the above constraint is satisfied since Isin = −Isin implies that Isin = 0. Ewald's sphere",
                    "score": 0.9131470918655396
                },
                {
                    "id": 1666826,
                    "contents": "Crystallography\nX-rays interact with the spatial distribution of electrons in the sample. Electrons are charged particles and therefore interact with the total charge distribution of both the atomic nuclei and the electrons of the sample. Neutrons are scattered by the atomic nuclei through the strong nuclear forces, but in addition, the magnetic moment of neutrons is non-zero. They are therefore also scattered by magnetic fields. When neutrons are scattered from hydrogen-containing materials, they produce diffraction patterns with high noise levels. However, the material can sometimes be treated to substitute deuterium for hydrogen. Because of these different forms of interaction, the three types of radiation are suitable for different crystallographic studies. Theory",
                    "score": 0.9125595092773438
                },
                {
                    "id": 4498896,
                    "contents": "X-ray spectroscopy\nThe schools were well attended by academic and industrial R&D scientists. The engineering department was also a new product development group. It added an X-ray spectrograph to the product line very quickly and contributed other related products for the next 8 years.",
                    "score": 0.9122669696807861
                },
                {
                    "id": 1338015,
                    "contents": "X-ray\nSee also Backscatter X-ray Detective quantum efficiency High-energy X-rays Macintyre's X-Ray Film – 1896 documentary radiography film N ray Neutron radiation NuSTAR Radiographer Reflection (physics) Resonant inelastic X-ray scattering (RIXS) Small-angle X-ray scattering (SAXS) The X-Rays – 1897 British short silent comedy film X-ray absorption spectroscopy X-ray marker X-ray nanoprobe X-ray reflectivity X-ray vision X-ray welding References External links Röntgen’s discovery of X-rays (English translation) Electromagnetic spectrum IARC Group 1 carcinogens Ionizing radiation Medical physics Radiography Wilhelm Röntgen 1895 in science 1895 in Germany",
                    "score": 0.9121535420417786
                },
                {
                    "id": 26118858,
                    "contents": "X-ray emission spectroscopy\nWilliam Lawrence Bragg later found a relation between the energy of a photon and its diffraction within a crystal. The formula he established, says that an X-ray photon with a certain energy bends at a precisely defined angle within a crystal. Equipment Analyzers A special kind of monochromator is needed to diffract the radiation produced in X-Ray-Sources. This is because X-rays have a refractive index n ≈ 1. Bragg came up with the equation that describes x-ray/neutron diffraction when those particles pass a crystal lattice.(X-ray diffraction)",
                    "score": 0.9119433164596558
                },
                {
                    "id": 1337592,
                    "contents": "X-ray crystallography\nThese scattering methods generally use monochromatic X-rays, which are restricted to a single wavelength with minor deviations. A broad spectrum of X-rays (that is, a blend of X-rays with different wavelengths) can also be used to carry out X-ray diffraction, a technique known as the Laue method. This is the method used in the original discovery of X-ray diffraction. Laue scattering provides much structural information with only a short exposure to the X-ray beam, and is therefore used in structural studies of very rapid events (Time resolved crystallography). However, it is not as well-suited as monochromatic scattering for determining the full atomic structure of a crystal and therefore works better with crystals with relatively simple atomic arrangements.",
                    "score": 0.9118101000785828
                },
                {
                    "id": 1337641,
                    "contents": "X-ray crystallography\nDiffraction theory The main goal of X-ray crystallography is to determine the density of electrons f(r) throughout the crystal, where r represents the three-dimensional position vector within the crystal. To do this, X-ray scattering is used to collect data about its Fourier transform F(q), which is inverted mathematically to obtain the density defined in real space, using the formula where the integral is taken over all values of q. The three-dimensional real vector q represents a point in reciprocal space, that is, to a particular oscillation in the electron density as one moves in the direction in which q points. The length of q corresponds to divided by the wavelength of the oscillation. The corresponding formula for a Fourier transform will be used below where the integral is summed over all possible values of the position vector r within the crystal.",
                    "score": 0.9117999076843262
                },
                {
                    "id": 1337570,
                    "contents": "X-ray crystallography\nScattering As described in the mathematical derivation below, the X-ray scattering is determined by the density of electrons within the crystal. Since the energy of an X-ray is much greater than that of a valence electron, the scattering may be modeled as Thomson scattering, the interaction of an electromagnetic ray with a free electron. This model is generally adopted to describe the polarization of the scattered radiation. The intensity of Thomson scattering for one particle with mass m and elementary charge q is: Hence the atomic nuclei, which are much heavier than an electron, contribute negligibly to the scattered X-rays. Development from 1912 to 1920",
                    "score": 0.9113786220550537
                },
                {
                    "id": 1776774,
                    "contents": "Henry Moseley\nMoseley participated in the design and development of early X-ray spectrometry equipment, learning some techniques from William Henry Bragg and William Lawrence Bragg at the University of Leeds, and developing others himself. Many of the techniques of X-ray spectroscopy were inspired by the methods that are used with visible light spectroscopes and spectrograms, by substituting crystals, ionization chambers, and photographic plates for their analogs in light spectroscopy. In some cases, Moseley found it necessary to modify his equipment to detect particularly soft [lower frequency] X-rays that could not penetrate either air or paper, by working with his instruments in a vacuum chamber.",
                    "score": 0.9112126231193542
                },
                {
                    "id": 8692348,
                    "contents": "X-ray optics\nX-ray beams are often collimated or reduced in size using pinholes or movable slits typically made out of tungsten or some other high-Z material. Narrow parts of an X-ray spectrum can be selected with monochromators based on one or multiple Bragg reflections by crystals. X-ray spectra can also be manipulated by having the X-rays pass through a filter (optics). This will typically reduce the low-energy part of the spectrum, and possibly parts above absorption edges of the elements used for the filter.",
                    "score": 0.9109749794006348
                },
                {
                    "id": 13614764,
                    "contents": "Anomalous X-ray scattering\nAnomalous X-ray scattering (AXRS or XRAS) is a non-destructive determination technique within X-ray diffraction that makes use of the anomalous dispersion that occurs when a wavelength is selected that is in the vicinity of an absorption edge of one of the constituent elements of the sample. It is used in materials research to study nanometer sized differences in structure. Atomic scattering factors In X-ray diffraction the scattering factor f for an atom is roughly proportional to the number of electrons that it possesses. However, for wavelengths that approximate those for which the atom strongly absorbs radiation the scattering factor undergoes a change due to anomalous dispersion. The dispersion not only affects the magnitude of the factor but also imparts a phase shift in the elastic collision of the photon. The scattering factor can therefore best be described as a complex number f= fo + Δf' + i.Δf\" Contrast variation",
                    "score": 0.9107557535171509
                },
                {
                    "id": 4498900,
                    "contents": "X-ray spectroscopy\ndetector, the X-ray photons are counted individually. By stepping the detectors along the angle, and leaving it in position for a known time, the number of counts at each angular position gives the line intensity. These counts may be plotted on a curve by an appropriate display unit. The characteristic X-rays come out at specific angles, and since the angular position for every X-ray spectral line is known and recorded, it is easy to find the sample's composition.",
                    "score": 0.9095098972320557
                },
                {
                    "id": 2122818,
                    "contents": "Wide-angle X-ray scattering\nIn X-ray crystallography, wide-angle X-ray scattering (WAXS) or wide-angle X-ray diffraction (WAXD) is the analysis of Bragg peaks scattered to wide angles, which (by Bragg's law) are caused by sub-nanometer-sized structures. It is an X-ray-diffraction method and commonly used to determine a range of information about crystalline materials. The term WAXS is commonly used in polymer sciences to differentiate it from SAXS but many scientists doing \"WAXS\" would describe the measurements as Bragg/X-ray/powder diffraction or crystallography.",
                    "score": 0.9094960689544678
                },
                {
                    "id": 6968617,
                    "contents": "Samuel King Allison\nX-Rays In 1930 Allison returned to the University of Chicago, where he became a professor in 1942, and the Frank P. Hixon Distinguished Service Professor of Physics in 1959. He studied the Compton effect and the dynamical theory of x-ray diffraction. At the time x-rays were an important means of investigating atomic structures, but the concept that light had both wave and particle properties, as demonstrated by Arthur Compton, was not universally accepted. William Duane from Harvard spearheaded an effort to prove that Compton's interpretation of the Compton effect was wrong, and Allison became part of this effort. Duane carried out a series of meticulous experiments to disprove Compton, but instead found overwhelming evidence that Compton was correct. To his credit, Duane conceded that this was the case.",
                    "score": 0.9089560508728027
                },
                {
                    "id": 20524598,
                    "contents": "X-ray detector\nX-ray detectors are devices used to measure the flux, spatial distribution, spectrum, and/or other properties of X-rays. Detectors can be divided into two major categories: imaging detectors (such as photographic plates and X-ray film (photographic film), now mostly replaced by various digitizing devices like image plates or flat panel detectors) and dose measurement devices (such as ionization chambers, Geiger counters, and dosimeters used to measure the local radiation exposure, dose, and/or dose rate, for example, for verifying that radiation protection equipment and procedures are effective on an ongoing basis). X-ray imaging",
                    "score": 0.9086483716964722
                },
                {
                    "id": 1337649,
                    "contents": "X-ray crystallography\nThe equality of their magnitudes ensures that the Friedel mates have the same intensity |F|2. This symmetry allows one to measure the full Fourier transform from only half the reciprocal space, e.g., by rotating the crystal slightly more than 180° instead of a full 360° revolution. In crystals with significant symmetry, even more reflections may have the same intensity (Bijvoet mates); in such cases, even less of the reciprocal space may need to be measured. In favorable cases of high symmetry, sometimes only 90° or even only 45° of data are required to completely explore the reciprocal space. The Friedel-mate constraint can be derived from the definition of the inverse Fourier transform Since Euler's formula states that eix = cos(x) + i sin(x), the inverse Fourier transform can be separated into a sum of a purely real part and a purely imaginary part",
                    "score": 0.9082018136978149
                },
                {
                    "id": 1337564,
                    "contents": "X-ray crystallography\nSingle-slit experiments in the laboratory of Arnold Sommerfeld suggested that X-rays had a wavelength of about 1 angstrom. X-rays are not only waves but are also photons, and have particle properties causing Sommerfeld to coin the name, Bremsstrahlung, for this wavelike type of diffraction. Albert Einstein introduced the photon concept in 1905, but it was not broadly accepted until 1922, when Arthur Compton confirmed it by the scattering of X-rays from electrons. The particle-like properties of X-rays, such as their ionization of gases, had prompted William Henry Bragg to argue in 1907 that X-rays were not electromagnetic radiation. Bragg's view proved unpopular and the observation of X-ray diffraction by Max von Laue in 1912 confirmed for most scientists that X-rays are a form of electromagnetic radiation.",
                    "score": 0.9081797003746033
                },
                {
                    "id": 1337948,
                    "contents": "X-ray\nHermann von Helmholtz formulated mathematical equations for X-rays. He postulated a dispersion theory before Röntgen made his discovery and announcement. He based it on the electromagnetic theory of light. However, he did not work with actual X-rays. In 1894, Nikola Tesla noticed damaged film in his lab that seemed to be associated with Crookes tube experiments and began investigating this invisible, radiant energy. After Röntgen identified the X-ray, Tesla began making X-ray images of his own using high voltages and tubes of his own design, as well as Crookes tubes. Discovery by Röntgen",
                    "score": 0.9079415798187256
                },
                {
                    "id": 26817256,
                    "contents": "Rachinger correction\nCause of the double peak For diffraction experiments with X-rays radiation is usually used with the Wavelength of the anode material . However, this is a doublet, so in reality two slightly different wavelengths. According to the diffraction conditions of the Laue or Bragg equation, both wavelengths each generate an intensity maximum. These maxima are very close to each other, with their distance depending on the diffraction angle . For larger angles, the distance of the intensity maxima is greater. Procedure Basics The wavelengths of and radiation are also known to increase their energy through the relationship: From this, the angular distance can be determined for each diffraction angle determine the two Kα peaks. Furthermore, it is known how the intensities of and behave in the diffraction pattern. This ratio is determined quantum mechanically and is for all anode materials: Calculation The total intensity is: ,",
                    "score": 0.9078635573387146
                },
                {
                    "id": 1666828,
                    "contents": "Crystallography\nUnfortunately, focusing X-rays with conventional optical lens can be a challenge. Scientists have had some success focusing X-rays with microscopic Fresnel zone plates made from gold, and by critical-angle reflection inside long tapered capillaries. Diffracted X-ray or neutron beams cannot be focused to produce images, so the sample structure must be reconstructed from the diffraction pattern. Diffraction patterns arise from the constructive interference of incident radiation (x-rays, electrons, neutrons), scattered by the periodic, repeating features of the sample. Because of their highly ordered and repetitive atomic structure (Bravais lattice), crystals diffract x-rays in a coherent manner, also referred to as Bragg's reflection. Notation",
                    "score": 0.9076828360557556
                },
                {
                    "id": 4143803,
                    "contents": "X-ray microscope\nAn X-ray microscope uses electromagnetic radiation in the soft X-ray band to produce magnified images of objects. Since X-rays penetrate most objects, there is no need to specially prepare them for X-ray microscopy observations. Unlike visible light, X-rays do not reflect or refract easily and are invisible to the human eye. Therefore, an X-ray microscope exposes film or uses a charge-coupled device (CCD) detector to detect X-rays that pass through the specimen. It is a contrast imaging technology using the difference in absorption of soft X-rays in the water window region (wavelengths: 2.34–4.4 nm, energies: 280–530 eV) by the carbon atom (main element composing the living cell) and the oxygen atom (an element of water). Microfocus X-ray also achieves high magnification by projection. A microfocus X-ray tube produces X-rays from an extremely small focal spot (5 μm down to 0.1 μm). The X-rays are in the more conventional X-ray range (20 to 300 keV) and are not re-focused.",
                    "score": 0.9075877666473389
                },
                {
                    "id": 4498883,
                    "contents": "X-ray spectroscopy\nWavelength-dispersive X-ray spectroscopy In a wavelength-dispersive X-ray spectrometer, a single crystal diffracts the photons according to Bragg's law, which are then collected by a detector. By moving the diffraction crystal and detector relative to each other, a wide region of the spectrum can be observed. To observe a large spectral range, three of four different single crystals may be needed. In contrast to EDS, WDS is a method of sequential spectrum acquisition. While WDS is slower than EDS and more sensitive to the positioning of the sample in the spectrometer, it has superior spectral resolution and sensitivity. WDS is widely used in microprobes (where X-ray microanalysis is the main task) and in XRF; it is widely used in the field of X-ray diffraction to calculate various data such as interplanar spacing and wavelength of the incident X-ray using Bragg's law.",
                    "score": 0.907323956489563
                },
                {
                    "id": 4498882,
                    "contents": "X-ray spectroscopy\nEnergy-dispersive X-ray spectroscopy In an energy-dispersive X-ray spectrometer, a semiconductor detector measures energy of incoming photons. To maintain detector integrity and resolution it should be cooled with liquid nitrogen or by Peltier cooling. EDS is widely employed in electron microscopes (where imaging rather than spectroscopy is a main task) and in cheaper and/or portable XRF units. Wavelength-dispersive X-ray spectroscopy",
                    "score": 0.9073042273521423
                },
                {
                    "id": 4143816,
                    "contents": "X-ray microscope\nshown its great ability to circumvent the diffractive limit of classic light microscopes; however, further enhancement of the resolution is limited by detector pixels, optical instruments, and source sizes.",
                    "score": 0.9069581031799316
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_1",
        "question": "A chemical reaction takes place in a container of cross-sectional area $50 \\mathrm{~cm}^2$. As a result of the reaction, a piston is pushed out through $15 \\mathrm{~cm}$ against an external pressure of $1.0 \\mathrm{~atm}$. Calculate the work done by the system.",
        "golden_answers": [
            " -75"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1903880,
                    "contents": "Reaction rate\nIn practice, the matter can be complicated because the partial molar volumes and the activation volume can themselves be a function of pressure. Reactions can increase or decrease their rates with pressure, depending on the value of ΔV‡. As an example of the possible magnitude of the pressure effect, some organic reactions were shown to double the reaction rate when the pressure was increased from atmospheric (0.1 MPa) to 50 MPa (which gives ΔV‡ = −0.025 L/mol). See also Rate of solution Dilution (equation) Diffusion-controlled reaction Steady state approximation Collision theory and transition state are chemical theories that attempt to predict and explain reaction rates. Isothermal microcalorimetry Notes",
                    "score": 0.8777832388877869
                },
                {
                    "id": 1903863,
                    "contents": "Reaction rate\nFor a single reaction in a closed system of varying volume the so-called rate of conversion can be used, in order to avoid handling concentrations. It is defined as the derivative of the extent of reaction with respect to time. Here νi is the stoichiometric coefficient for substance i, equal to a, b, p, and q in the typical reaction above. Also V is the volume of reaction and Ci is the concentration of substance i. When side products or reaction intermediates are formed, the IUPAC recommends the use of the terms the rate of increase of concentration and rate of the decrease of concentration for products and reactants, properly.",
                    "score": 0.8765153884887695
                },
                {
                    "id": 1903871,
                    "contents": "Reaction rate\nFor gas phase reaction the rate equation is often alternatively expressed in terms of partial pressures. In these equations k(T) is the reaction rate coefficient or rate constant, although it is not really a constant, because it includes all the parameters that affect reaction rate, except for time and concentration. Of all the parameters influencing reaction rates, temperature is normally the most important one and is accounted for by the Arrhenius equation. The exponents n and m are called reaction orders and depend on the reaction mechanism. For an elementary (single-step) reaction, the order with respect to each reactant is equal to its stoichiometric coefficient. For complex (multistep) reactions, however, this is often not true and the rate equation is determined by the detailed mechanism, as illustrated below for the reaction of H2 and NO.",
                    "score": 0.8706284761428833
                },
                {
                    "id": 4617099,
                    "contents": "Chemical reactor\nA chemical reactor is an enclosed volume in which a chemical reaction takes place. In chemical engineering, it is generally understood to be a process vessel used to carry out a chemical reaction, which is one of the classic unit operations in chemical process analysis. The design of a chemical reactor deals with multiple aspects of chemical engineering. Chemical engineers design reactors to maximize net present value for the given reaction. Designers ensure that the reaction proceeds with the highest efficiency towards the desired output product, producing the highest yield of product while requiring the least amount of money to purchase and operate. Normal operating expenses include energy input, energy removal, raw material costs, labor, etc. Energy changes can come in the form of heating or cooling, pumping to increase pressure, frictional pressure loss or agitation.Chemical reaction engineering is the branch of chemical engineering which deals with chemical reactors and their",
                    "score": 0.8697328567504883
                },
                {
                    "id": 1638832,
                    "contents": "Chemical thermodynamics\nA gas-phase reaction at constant temperature and pressure which results in an increase in the number of molecules will lead to an increase in volume. Inside a cylinder closed with a piston, it can proceed only by doing work on the piston. The extent variable for the reaction can increase only if the piston moves out, and conversely if the piston is pushed inward, the reaction is driven backwards.",
                    "score": 0.8665043711662292
                },
                {
                    "id": 1903870,
                    "contents": "Reaction rate\nStirring can have a strong effect on the rate of reaction for heterogeneous reactions. Some reactions are limited by diffusion. All the factors that affect a reaction rate, except for concentration and reaction order, are taken into account in the reaction rate coefficient (the coefficient in the rate equation of the reaction). Rate equation For a chemical reaction a A + b B → p P + q Q, the rate equation or rate law is a mathematical expression used in chemical kinetics to link the rate of a reaction to the concentration of each reactant. For a closed system at constant volume, this is often of the form For reactions that go to completion (which implies very small kr), or if only the initial rate is analyzed (with initial vanishing product concentrations), this simplifies to the commonly quoted form For gas phase reaction the rate equation is often alternatively expressed in terms of partial pressures.",
                    "score": 0.8645780086517334
                },
                {
                    "id": 1336957,
                    "contents": "Wilhelm Ostwald\nCatalysis Through his research on chemical reaction rates and velocities and his studies of acids and bases, Ostwald found that the concentration of acid or the concentration of base in a solution of certain chemical reactants can have a strong influence of the rate of chemical processes. He realized that this is manifestation of the concept of chemical catalysis first articulated by Berzelius. Ostwald articulated the idea that a catalyst is a substance that accelerates the rate of a chemical reaction without being a part of either the reactants or the products. Ostwald's advances in the understanding of chemical catalysis were widely applicable in biological processes such as enzymatic catalysis and also in many industrial processes. A catalyst is used in the nitric acid process that Ostwald invented.",
                    "score": 0.8640251159667969
                },
                {
                    "id": 2204330,
                    "contents": "Standard enthalpy of reaction\n(a) Constant volume and temperature: heat , where (sometimes written as ) is the internal energy of the system (b) Constant pressure and temperature: heat , where is the enthalpy of the system The magnitudes of the heat effects in these two conditions are different. In the first case the volume of the system is kept constant during the course of the measurement by carrying out the reaction in a closed and rigid container, and as there is no change in the volume no work is involved. From the first law of thermodynamics, , where W is the work done by the system. When only expansion work is possible for a process we have ; this implies that the heat of reaction at constant volume is equal to the change in the internal energy of the reacting system. The thermal change that occurs in a chemical reaction is only due to the difference between the sum of internal energy of the products and the sum of the internal energy of reactants. We have",
                    "score": 0.8626369833946228
                },
                {
                    "id": 1903862,
                    "contents": "Reaction rate\nThe above definition is only valid for a single reaction, in a closed system of constant volume, an assumption which should be stated explicitly in the definition. If water is added to a pot containing salty water, the concentration of salt decreases, although there is no chemical reaction. For an open system, the full mass balance must be taken into account: , where FA0 is the inflow rate of A in molecules per second, FA the outflow, and v is the instantaneous reaction rate of A (in number concentration rather than molar) in a given differential volume, integrated over the entire system volume V at a given moment. When applied to the closed system at constant volume considered previously, this equation reduces to: , where the concentration [A] is related to the number of molecules NA by [A] = . Here N0 is the Avogadro constant.",
                    "score": 0.8620402812957764
                },
                {
                    "id": 19372247,
                    "contents": "Pouillet effect\nIn physics and chemical engineering, the term Pouillet effect refers to an exothermic reaction that takes place when a liquid is added to a powder. Strictly speaking, the heat generated is caused by adhesion of the liquid to the surface of the particles rather than by a chemical reaction. It was first observed in 1802 by Leslie, who noted that heat was evolved when dry sawdust was wetted with water. Claude Pouillet later described this phenomenon in 1822, and it subsequently became known as the \"Pouillet effect\" in France, and then elsewhere. Negative Pouillet effect Under certain conditions, a negative Pouillet effect is possible, i.e., heat can be absorbed instead of being released. G. Schwalbe showed that below 4 degrees Celsius, the temperature of the system decreases. Joseph Mellor argued that this is due to the negative thermal expansion coefficient of water between 0 and 4 degrees Celsius, with the temperature change given by",
                    "score": 0.8608437776565552
                },
                {
                    "id": 2661325,
                    "contents": "Isobaric process\nIn thermodynamics, an isobaric process is a type of thermodynamic process in which the pressure of the system stays constant: ΔP = 0. The heat transferred to the system does work, but also changes the internal energy (U) of the system. This article uses the physics sign convention for work, where positive work is work done by the system. Using this convention, by the first law of thermodynamics, where W is work, U is internal energy, and Q is heat. Pressure-volume work by the closed system is defined as: where Δ means change over the whole process, whereas d denotes a differential. Since pressure is constant, this means that . Applying the ideal gas law, this becomes with R representing the gas constant, and n representing the amount of substance, which is assumed to remain constant (e.g., there is no phase transition during a chemical reaction). According to the equipartition theorem, the change in internal energy is related to the temperature of the system by ,",
                    "score": 0.8607125878334045
                },
                {
                    "id": 1903865,
                    "contents": "Reaction rate\nReaction rate increases with concentration, as described by the rate law and explained by collision theory. As reactant concentration increases, the frequency of collision increases. The rate of gaseous reactions increases with pressure, which is, in fact, equivalent to an increase in concentration of the gas. The reaction rate increases in the direction where there are fewer moles of gas and decreases in the reverse direction. For condensed-phase reactions, the pressure dependence is weak. The order of the reaction controls how the reactant concentration (or pressure) affects reaction rate.",
                    "score": 0.8592172861099243
                },
                {
                    "id": 1638417,
                    "contents": "Catalysis\nGenerally speaking, anything that increases the rate of a process is a \"catalyst\", a term derived from Greek καταλύειν, meaning \"to annul,\" or \"to untie,\" or \"to pick up.\" The concept of catalysis was invented by chemist Elizabeth Fulhame and described in a 1794 book, based on her novel work in oxidation-reduction experiments. The first chemical reaction in organic chemistry that utilized a catalyst was studied in 1811 by Gottlieb Kirchhoff who discovered the acid-catalyzed conversion of starch to glucose. The term catalysis was later used by Jöns Jakob Berzelius in 1835 to describe reactions that are accelerated by substances that remain unchanged after the reaction. Fulhame, who predated Berzelius, did work with water as opposed to metals in her reduction experiments. Other 18th century chemists who worked in catalysis were Eilhard Mitscherlich who referred to it as contact processes, and Johann Wolfgang Döbereiner who spoke of contact action. He developed Döbereiner's lamp, a",
                    "score": 0.8588876724243164
                },
                {
                    "id": 1644346,
                    "contents": "Chemical reaction\nwhere Ea is the activation energy and kB is the Boltzmann constant. One of the simplest models of reaction rate is the collision theory. More realistic models are tailored to a specific problem and include the transition state theory, the calculation of the potential energy surface, the Marcus theory and the Rice–Ramsperger–Kassel–Marcus (RRKM) theory. Reaction types Four basic types Synthesis In a synthesis reaction, two or more simple substances combine to form a more complex substance. These reactions are in the general form: A + B -> AB Two or more reactants yielding one product is another way to identify a synthesis reaction. One example of a synthesis reaction is the combination of iron and sulfur to form iron(II) sulfide: 8Fe + S8 -> 8FeS Another example is simple hydrogen gas combined with simple oxygen gas to produce a more complex substance, such as water. Decomposition",
                    "score": 0.8584073185920715
                },
                {
                    "id": 1624964,
                    "contents": "Chemistry\nA reaction is said to be exergonic if the final state is lower on the energy scale than the initial state; in the case of endergonic reactions the situation is the reverse. A reaction is said to be exothermic if the reaction releases heat to the surroundings; in the case of endothermic reactions, the reaction absorbs heat from the surroundings. Chemical reactions are invariably not possible unless the reactants surmount an energy barrier known as the activation energy. The speed of a chemical reaction (at given temperature T) is related to the activation energy E, by the Boltzmann's population factor – that is the probability of a molecule to have energy greater than or equal to E at the given temperature T. This exponential dependence of a reaction rate on temperature is known as the Arrhenius equation. The activation energy necessary for a chemical reaction to occur can be in the form of heat, light, electricity or mechanical force in the form of ultrasound.",
                    "score": 0.8573668599128723
                },
                {
                    "id": 20624945,
                    "contents": "Defining equation (physical chemistry)\nKinetics and equilibria The defining formulae for the equilibrium constants Kc (all reactions) and Kp (gaseous reactions) apply to the general chemical reaction: {\\nu_1 X1} + {\\nu_2 X2} + \\cdots + \\nu_\\mathit{r} X_\\mathit{r} <=> {\\eta_1 Y1} + {\\eta_2 Y2} + \\cdots + \\eta_\\mathit{p} {Y}_\\mathit{p} and the defining equation for the rate constant k applies to the simpler synthesis reaction (one product only): {\\nu_1 X1} + {\\nu_2 X2} + \\cdots + \\nu_\\mathit{r} X_\\mathit{r} -> \\eta {Y} where: i = dummy index labelling component i of reactant mixture, j = dummy index labelling component i of product mixture, Xi = component i of the reactant mixture, Yj = reactant component j of the product mixture, r (as an index) = number of reactant components, p (as an index) = number of product components, νi = stoichiometry number for component i in product mixture, ηj = stoichiometry number for component j in product mixture, σi = order of reaction for component i in reactant mixture.",
                    "score": 0.8570134043693542
                },
                {
                    "id": 16433813,
                    "contents": "Pressure reactor\nA pressure reactor, sometimes referred to as a pressure tube, or a sealed tube, is a chemical reaction vessel which can conduct a reaction under pressure. A pressure reactor is a special application of a pressure vessel. The pressure can be caused by the reaction itself or created by an external source, like hydrogen in catalytic transfer hydrogenation. Advantages A pressure reactor can offer several advantages over the conventional round-bottom flask. Firstly, it can conduct a reaction above the boiling point of a solvent. Secondly, the pressure can reduce the reaction volume, including the liquid phase, and in turn increase concentration and collision frequency, and accelerate a reaction.",
                    "score": 0.8565523624420166
                },
                {
                    "id": 1644332,
                    "contents": "Chemical reaction\nRegarding the organic chemistry, it was long believed that compounds obtained from living organisms were too complex to be obtained synthetically. According to the concept of vitalism, organic matter was endowed with a \"vital force\" and distinguished from inorganic materials. This separation was ended however by the synthesis of urea from inorganic precursors by Friedrich Wöhler in 1828. Other chemists who brought major contributions to organic chemistry include Alexander William Williamson with his synthesis of ethers and Christopher Kelk Ingold, who, among many discoveries, established the mechanisms of substitution reactions. Characteristics The general characteristics of chemical reactions are: Evolution of a gas Formation of a precipitate Change in temperature Change in state Equations",
                    "score": 0.8565306067466736
                },
                {
                    "id": 3531918,
                    "contents": "Jean Charles Galissard de Marignac\nIn physical chemistry he carried out extensive research on the nature and process of solutions, investigating in particular the thermal effects produced by the dilution of saline solutions, the variation of the specific heat of saline solutions with temperature and concentration, and the phenomena of liquid diffusion. References Further reading 1817 births 1894 deaths People from Geneva Discoverers of chemical elements Swiss physical chemists Recipients of the Pour le Mérite (civil class) Foreign Members of the Royal Society 19th-century Swiss people 19th-century chemists Ytterbium Gadolinium Rare earth scientists",
                    "score": 0.8560564517974854
                },
                {
                    "id": 24866434,
                    "contents": "Residence time\nReactants continuously enter and leave a tank where they are mixed. Consequently, the reaction proceeds at a rate dependent on the outlet concentration:",
                    "score": 0.8559293746948242
                },
                {
                    "id": 2204332,
                    "contents": "Standard enthalpy of reaction\n(work) If is only pressure–volume work, then at constant pressure Assuming that the change in state variables is due solely to a chemical reaction, we have As enthalpy or heat content is defined by , we have By convention, the enthalpy of each element in its standard state is assigned a value of zero. If pure preparations of compounds or ions are not possible, then special further conventions are defined. Regardless, if each reactant and product can be prepared in its respective standard state, then the contribution of each species is equal to its molar enthalpy of formation multiplied by its stoichiometric coefficient in the reaction, and the enthalpy of reaction at constant (standard) pressure and constant temperature (usually 298 K) may be written as As shown above, at constant pressure the heat of the reaction is exactly equal to the enthalpy change, , of the reacting system.",
                    "score": 0.855758547782898
                },
                {
                    "id": 5606395,
                    "contents": "History of chemistry\nBoyle also tried to purify chemicals to obtain reproducible reactions. He was a vocal proponent of the mechanical philosophy proposed by René Descartes to explain and quantify the physical properties and interactions of material substances. Boyle was an atomist, but favoured the word corpuscle over atoms. He commented that the finest division of matter where the properties are retained is at the level of corpuscles. He also performed numerous investigations with an air pump, and noted that the mercury fell as air was pumped out. He also observed that pumping the air out of a container would extinguish a flame and kill small animals placed inside. Boyle helped to lay the foundations for the Chemical Revolution with his mechanical corpuscular philosophy. Boyle repeated the tree experiment of van Helmont, and was the first to use indicators which changed colors with acidity. Development and dismantling of phlogiston",
                    "score": 0.8557323217391968
                },
                {
                    "id": 2284593,
                    "contents": "Chemical kinetics\nThe physical state (solid, liquid, or gas) of a reactant is also an important factor of the rate of change. When reactants are in the same phase, as in aqueous solution, thermal motion brings them into contact. However, when they are in separate phases, the reaction is limited to the interface between the reactants. Reaction can occur only at their area of contact; in the case of a liquid and a gas, at the surface of the liquid. Vigorous shaking and stirring may be needed to bring the reaction to completion. This means that the more finely divided a solid or liquid reactant the greater its surface area per unit volume and the more contact it with the other reactant, thus the faster the reaction. To make an analogy, for example, when one starts a fire, one uses wood chips and small branches — one does not start with large logs right away. In organic chemistry, on water reactions are the exception to the rule that homogeneous reactions take place faster than heterogeneous reactions (",
                    "score": 0.8554136753082275
                },
                {
                    "id": 4617100,
                    "contents": "Chemical reactor\nor cooling, pumping to increase pressure, frictional pressure loss or agitation.Chemical reaction engineering is the branch of chemical engineering which deals with chemical reactors and their design, especially by application of chemical kinetics to industrial systems.",
                    "score": 0.8553071022033691
                },
                {
                    "id": 1644347,
                    "contents": "Chemical reaction\nAnother example is simple hydrogen gas combined with simple oxygen gas to produce a more complex substance, such as water. Decomposition A decomposition reaction is when a more complex substance breaks down into its more simple parts. It is thus the opposite of a synthesis reaction, and can be written as AB -> A + B One example of a decomposition reaction is the electrolysis of water to make oxygen and hydrogen gas: 2H2O -> 2H2 + O2 Single replacement In a single replacement reaction, a single uncombined element replaces another in a compound; in other words, one element trades places with another element in a compound These reactions come in the general form of: A + BC -> AC + B One example of a single displacement reaction is when magnesium replaces hydrogen in water to make magnesium hydroxide and hydrogen gas: Mg + 2H2O -> Mg(OH)2 + H2 (^)",
                    "score": 0.8549959659576416
                },
                {
                    "id": 2938041,
                    "contents": "Henry Louis Le Chatelier\nLe Chatelier's principle Le Chatelier's Principle states that a system always acts to oppose changes in chemical equilibrium; to restore equilibrium, the system will favor a chemical pathway to reduce or eliminate the disturbance so as to restabilize at thermodynamic equilibrium. Put another way, If a chemical system at equilibrium experiences a change in concentration, temperature or total pressure, the equilibrium will shift in order to minimize that change. This qualitative law enables one to envision the displacement of equilibrium of a chemical reaction. For example: a change in concentration of a reaction in equilibrium for the following equation: N2(g) + 3H2(g) ⇌ 2NH3(g) If one increases the pressure of the reactants, the reaction will tend to move towards the products to decrease the pressure of the reaction. However consider another example: in the contact process for the production of sulfuric acid, the second stage is a reversible reaction:",
                    "score": 0.8547046184539795
                },
                {
                    "id": 14996210,
                    "contents": "Chemical reaction engineering\nBooks The Engineering of Chemical Reactions (2nd Edition), Lanny Schmidt, 2004, Oxford University Press, Chemical Reaction Engineering (3rd Edition), Octave Levenspiel, 1999, John Wiley & Sons, , Elements of Chemical Reaction Engineering (4th Edition), H. Scott Fogler, 2005, Prentice Hall, , Chemical Reactor Analysis and Design (2nd Edition), Gilbert F. Froment and Kenneth B. Bischoff, 1990, John Wiley & Sons, , Fundamentals of Chemical Reaction Engineering (1st Edition), Mark E. Davis and Robert J. Davis, 2003, The McGraw-Hill Companies, Inc., ,",
                    "score": 0.8545737862586975
                },
                {
                    "id": 1903859,
                    "contents": "Reaction rate\nFormal definition Consider a typical chemical reaction: {\\mathit{a}A} + {\\mathit{b}B} -> {\\mathit{p}P} + {\\mathit{q}Q} The lowercase letters (a, b, p, and q) represent stoichiometric coefficients, while the capital letters represent the reactants (A and B) and the products (P and Q). According to IUPAC's Gold Book definition the reaction rate v for a chemical reaction occurring in a closed system at constant volume, without a build-up of reaction intermediates, is defined as: where [X] denotes the concentration of the substance X (= A, B, P or Q). Reaction rate thus defined has the units of mol/L/s.",
                    "score": 0.8544354438781738
                },
                {
                    "id": 11853711,
                    "contents": "Perry's Chemical Engineers' Handbook\nSubjects The subjects covered in the book include: physical properties of chemicals and other materials; mathematics; thermodynamics; heat transfer; mass transfer; fluid dynamics; chemical reactors and chemical reaction kinetics; transport and storage of fluid; heat transfer equipment; psychrometry and evaporative cooling; distillation; gas absorption; liquid-liquid extraction; adsorption and ion exchange; gas–solid, liquid–solid and solid–solid operations; biochemical engineering; waste management, materials of construction, process economics and cost estimation; process safety and many others.",
                    "score": 0.8532881736755371
                },
                {
                    "id": 746629,
                    "contents": "Dalton's law\nDalton's law (also called Dalton's law of partial pressures) states that in a mixture of non-reacting gases, the total pressure exerted is equal to the sum of the partial pressures of the individual gases. This empirical law was observed by John Dalton in 1801 and published in 1802. Dalton's law is related to the ideal gas laws. Formula Mathematically, the pressure of a mixture of non-reactive gases can be defined as the summation: where p1, p2, …, pn represent the partial pressures of each component. where xi is the mole fraction of the ith component in the total mixture of n components. Volume-based concentration The relationship below provides a way to determine the volume-based concentration of any individual gaseous component where ci is the concentration of component i.",
                    "score": 0.8527615070343018
                },
                {
                    "id": 13155220,
                    "contents": "Augustus George Vernon Harcourt\nChemical kinetics In a long partnership, Harcourt and William Esson studied the rates of chemical reactions. Among the processes they investigated was the acid-catalyzed iodine clock reaction (iodide and hydrogen peroxide). Their work showed that the reaction's changing rate was proportional to the concentration of reactants present. This result was later formalised by Guldberg and Waage as the law of mass action. Harcourt and Esson also studied the reaction between oxalic acid and potassium permanganate. Other scientific work Harcourt's other activities included inventing a device to safely administer chloroform as an anesthesic, and the analysis and purification of coal gas, used for illumination. Harcourt also invented pentane-burning lamps that served as photometric standards. Honours and activities 1863: Fellow of the Royal Society 1865–1873: Secretary of the Chemical Society 1895: President of the Chemical Society References",
                    "score": 0.8523855209350586
                },
                {
                    "id": 7593859,
                    "contents": "Chemical process\nAlthough this type of chemical process may sometimes involve only one step, often multiple steps, referred to as unit operations, are involved. In a plant, each of the unit operations commonly occur in individual vessels or sections of the plant called units. Often, one or more chemical reactions are involved, but other ways of changing chemical (or material) composition may be used, such as mixing or separation processes. The process steps may be sequential in time or sequential in space along a stream of flowing or moving material; see Chemical plant. For a given amount of a feed (input) material or product (output) material, an expected amount of material can be determined at key steps in the process from empirical data and material balance calculations. These amounts can be scaled up or down to suit the desired capacity or operation of a particular chemical plant built for such a process. More than one chemical plant may use the same chemical process, each plant perhaps at",
                    "score": 0.8523826599121094
                },
                {
                    "id": 1379355,
                    "contents": "Le Chatelier's principle\nChanging total pressure by adding an inert gas at constant volume does not affect the equilibrium concentrations (see Effect of adding an inert gas below). Changing total pressure by changing the volume of the system changes the partial pressures of the products and reactants and can affect the equilibrium concentrations (see §Effect of change in volume below). Effect of change in volume Changing the volume of the system changes the partial pressures of the products and reactants and can affect the equilibrium concentrations. With a pressure increase due to a decrease in volume, the side of the equilibrium with fewer moles is more favorable and with a pressure decrease due to an increase in volume, the side with more moles is more favorable. There is no effect on a reaction where the number of moles of gas is the same on each side of the chemical equation. Considering the reaction of nitrogen gas with hydrogen gas to form ammonia: ⇌ ΔH = −92kJ mol−1",
                    "score": 0.851670503616333
                },
                {
                    "id": 28630283,
                    "contents": "Fickett–Jacobs cycle\nThe ideal FJ cycle consists of five processes: Reactants are isentropically compressed: Applying external work to move one piston at velocity up instantaneously initiating a detonation front at the piston's surface. The detonation wave propagates, and the decomposition products follows it in a uniform state at velocity up. Once it reaches the second piston, the entire piston-cylinder arrangement moves at a constant velocity up. The kinetic energy produced during the first process is converted into external work. Adiabatical expansion: The gaseous detonation products return to a final pressure equal to the initial pressure, Ρ0. Heat extraction: The gaseous products are reversibly cooled at a constant pressure to reach the initial temperature Τ0. The cycle is completed by converting the products into reactants, as in the initial conditions. The entire cycle is shown in Figure 1.",
                    "score": 0.8515272736549377
                },
                {
                    "id": 5460730,
                    "contents": "Rate equation\nwhere the reaction starts with an initial concentration of reactant A, [A]0, and an initial concentration of 0 for product P at time t=0. Then the constant K at equilibrium is expressed as: Where and are the concentrations of A and P at equilibrium, respectively. The concentration of A at time t, , is related to the concentration of P at time t, , by the equilibrium reaction equation: [A]_\\mathit{t} = [A]0 - [P]_\\mathit{t} The term [P]0 is not present because, in this simple example, the initial concentration of P is 0. This applies even when time t is at infinity; i.e., equilibrium has been reached: [A]_\\mathit{e} = [A]0 - [P]_\\mathit{e} then it follows, by the definition of K, that and, therefore, These equations allow us to uncouple the system of differential equations, and allow us to solve for the concentration of A alone. The reaction equation was given previously as: For A <=> P this is simply",
                    "score": 0.8513110280036926
                },
                {
                    "id": 1903879,
                    "contents": "Reaction rate\nPressure dependence The pressure dependence of the rate constant for condensed-phase reactions (i.e., when reactants and products are solids or liquid) is usually sufficiently weak in the range of pressures normally encountered in industry that it is neglected in practice. The pressure dependence of the rate constant is associated with the activation volume. For the reaction proceeding through an activation-state complex: A + B |A⋯B|‡ → P the activation volume, ΔV‡, is: where V̄ denotes the partial molar volume of a species and ‡ indicates the activation-state complex. For the above reaction, one can expect the change of the reaction rate constant (based either on mole fraction or on molar concentration) with pressure at constant temperature to be: In practice, the matter can be complicated because the partial molar volumes and the activation volume can themselves be a function of pressure.",
                    "score": 0.8512751460075378
                },
                {
                    "id": 10034369,
                    "contents": "Walter Reppe\nTo work with acetylene safely, Reppe designed special test tubes, the so-called \"Reppe glasses\" — stainless steel spheres with screw-type cap, which permitted high pressure experiments. The efforts ended finally with a large number of interrelated reactions, known as Reppe chemistry. \"Reppe chemie\" The high pressure reactions catalysed by heavy metal acetylides, especially copper acetylide, or metal carbonyls are called Reppe Chemistry. Reactions can be classified into four large classes: The vinylization according to the equation: Catalytic ethynylation of aldehydes: Reactions with carbon monoxide: This simple synthesis was used to prepare acrylic acid derivatives for the production of acrylic glass.",
                    "score": 0.8511962890625
                },
                {
                    "id": 2661330,
                    "contents": "Isobaric process\nIn the first process example, a cylindrical chamber 1 m2 in area encloses 81.2438 mol of an ideal diatomic gas of molecular mass 29 g mol−1 at 300 K. The surrounding gas is at 1 atm and 300 K, and separated from the cylinder gas by a thin piston. For the limiting case of a massless piston, the cylinder gas is also at 1 atm pressure, with an initial volume of 2 m3. Heat is added slowly until the gas temperature is uniformly 600 K, after which the gas volume is 4 m3 and the piston is 2 m above its initial position. If the piston motion is sufficiently slow, the gas pressure at each instant will have practically the same value (psys = 1 atm) throughout. For a thermally perfect diatomic gas, the molar specific heat capacity at constant pressure (cp) is 7/2R or 29.1006 J mol−1 deg−1. The molar heat capacity at constant volume (cv) is 5/2R or 20.7862 J mol−1 deg−1. The ratio of the two heat capacities is 1.4. The heat Q required to bring the gas from 300 to 600 K is .",
                    "score": 0.8511396646499634
                },
                {
                    "id": 9909134,
                    "contents": "Flow chemistry\nThe residence time of the reagents in the reactor (i.e. the amount of time that the reaction is heated or cooled) is calculated from the volume of the reactor and the flow rate through it: Therefore, to achieve a longer residence time, reagents can be pumped more slowly and/or a larger volume reactor used. Production rates can vary from nanoliters to liters per minute. Some examples of flow reactors are spinning disk reactors; spinning tube reactors; multi-cell flow reactors; oscillatory flow reactors; microreactors; hex reactors; and 'aspirator reactors'. In an aspirator reactor a pump propels one reagent, which causes a reactant to be sucked in. This type of reactor was patented around 1941 by the Nobel company for the production of nitroglycerin.",
                    "score": 0.8502724170684814
                },
                {
                    "id": 9293949,
                    "contents": "Van 't Hoff equation\nThe isotherm can also be used at fixed temperature to describe the Law of Mass Action. When a reaction is at equilibrium, and . Otherwise, the Van 't Hoff isotherm predicts the direction that the system must shift in order to achieve equilibrium; when , the reaction moves in the forward direction, whereas when , the reaction moves in the backwards direction. See Chemical equilibrium. Van 't Hoff plot For a reversible reaction, the equilibrium constant can be measured at a variety of temperatures. This data can be plotted on a graph with on the -axis and on the axis. The data should have a linear relationship, the equation for which can be found by fitting the data using the linear form of the Van 't Hoff equation This graph is called the \"Van 't Hoff plot\" and is widely used to estimate the enthalpy and entropy of a chemical reaction. From this plot, is the slope, and is the intercept of the linear fit.",
                    "score": 0.8501391410827637
                },
                {
                    "id": 16858697,
                    "contents": "List of German inventors and discoverers\nO Hermann Oberth: Pioneer of rocket science and discoverer of the Oberth effect. Georg Ohm: physicist and mathematician, discoverer of the Ohm's law and Ohm's acoustic law August Oetker: Pharmacist. He was the first to sell baking powder in small packets to households instead of bakeries (as others before him) and thus made it the popular product we know today. Hans Joachim Pabst von Ohain: The modern jet engine in 1933, patented in 1936. Frank Whittle had developed a similar concept independently in 1928/1929. Wilhelm Ostwald: German chemist who received the Nobel Prize in Chemistry in 1909 for his work on catalysis, chemical equilibria and reaction velocities. Ostwald, Jacobus Henricus van 't Hoff, and Svante Arrhenius are usually credited with being the modern founders of the field of physical chemistry. Nicolaus August Otto: Inventor of the first internal-combustion engine to efficiently burn fuel directly in a piston chamber. P",
                    "score": 0.8500655889511108
                },
                {
                    "id": 970276,
                    "contents": "Arrhenius equation\nEquation The Arrhenius equation gives the dependence of the rate constant of a chemical reaction on the absolute temperature as where is the rate constant (frequency of collisions resulting in a reaction), is the absolute temperature (in degrees Kelvin or Rankine), is the pre-exponential factor. Arrhenius originally considered A to be a temperature-independent constant for each chemical reaction. However more recent treatments include some temperature dependence - see Modified Arrhenius equation below. is the activation energy for the reaction (in the same units as RT), is the universal gas constant. Alternatively, the equation may be expressed as where is the activation energy for the reaction (in the same units as kBT), is the Boltzmann constant.",
                    "score": 0.8498455286026001
                },
                {
                    "id": 1644339,
                    "contents": "Chemical reaction\nThe reaction yield stabilizes at equilibrium, but can be increased by removing the product from the reaction mixture or changed by increasing the temperature or pressure. A change in the concentrations of the reactants does not affect the equilibrium constant, but does affect the equilibrium position. Thermodynamics Chemical reactions are determined by the laws of thermodynamics. Reactions can proceed by themselves if they are exergonic, that is if they release energy. The associated free energy of the reaction is composed of two different thermodynamic quantities, enthalpy and entropy: . : free energy, : enthalpy, : temperature, : entropy, : difference(change between original and product)",
                    "score": 0.8495338559150696
                },
                {
                    "id": 739443,
                    "contents": "Boyle's law\nBoyle's law, also referred to as the Boyle–Mariotte law, or Mariotte's law (especially in France), is an experimental gas law that describes how the pressure of a gas tends to decrease as the volume of the container increases. A modern statement of Boyle's law is: The absolute pressure exerted by a given mass of an ideal gas is inversely proportional to the volume it occupies if the temperature and amount of gas remain unchanged within a closed system.Levine, Ira. N. (1978), p. 12 gives the original definition. Mathematically, Boyle's law can be stated as: or where is the pressure of the gas, is the volume of the gas, and is a constant. The equation states that the product of pressure and volume is a constant for a given mass of confined gas and this holds as long as the temperature is constant. For comparing the same substance under two different sets of conditions, the law can be usefully expressed as:",
                    "score": 0.8495199084281921
                },
                {
                    "id": 1903868,
                    "contents": "Reaction rate\nMany reactions take place in solution and the properties of the solvent affect the reaction rate. The ionic strength also has an effect on reaction rate. Electromagnetic radiation is a form of energy. As such, it may speed up the rate or even make a reaction spontaneous as it provides the particles of the reactants with more energy. This energy is in one way or another stored in the reacting particles (it may break bonds, promote molecules to electronically or vibrationally excited states...) creating intermediate species that react easily. As the intensity of light increases, the particles absorb more energy and hence the rate of reaction increases. For example, when methane reacts with chlorine in the dark, the reaction rate is slow. It can be sped up when the mixture is put under diffused light. In bright sunlight, the reaction is explosive.",
                    "score": 0.849425196647644
                },
                {
                    "id": 2894935,
                    "contents": "Gay-Lussac's law\nor where: P is the pressure of the gas, T is the temperature of the gas (measured in kelvins), k is a constant. This law holds true because temperature is a measure of the average kinetic energy of a substance; as the kinetic energy of a gas increases, its particles collide with the container walls more rapidly, thereby exerting increased pressure. For comparing the same substance under two different sets of conditions, the law can be written as:",
                    "score": 0.8491309881210327
                },
                {
                    "id": 19923973,
                    "contents": "Entropy production\nIntroducing the concentration x = na/nt = Va/Vt we arrive at the well known expression Joule expansion The Joule expansion is similar to the mixing described above. It takes place in an adiabatic system consisting of a gas and two rigid vessels (a and b) of equal volume, connected by a valve. Initially, the valve is closed. Vessel (a) contains the gas under high pressure while the other vessel (b) is empty. When the valve is opened the gas flows from vessel (a) into (b) until the pressures in the two vessels are equal. The volume, taken by the gas, is doubled while the internal energy of the system is constant (adiabatic and no work done). Assuming that the gas is ideal the molar internal energy is given by Um = CVT. As CV is constant, constant U means constant T. The molar entropy of an ideal gas, as function of the molar volume Vm and T, is given by",
                    "score": 0.8489764928817749
                },
                {
                    "id": 6760936,
                    "contents": "Mass balance\nThe rate at which substance A is produced is thus and since, at equilibrium, the concentration of A is constant we get or, rearranged Ideal tank reactor/continuously stirred tank reactor The continuously mixed tank reactor is an open system with an influent stream of reactants and an effluent stream of products. A lake can be regarded as a tank reactor, and lakes with long turnover times (e.g. with low flux-to-volume ratios) can for many purposes be regarded as continuously stirred (e.g. homogeneous in all respects). The mass balance then becomes where Q0 and Q denote the volumetric flow in and out of the system respectively and CA,0 and CA the concentration of A in the inflow and outflow respective. In an open system we can never reach a chemical equilibrium. We can, however, reach a steady state where all state variables (temperature, concentrations, etc.) remain constant ().",
                    "score": 0.8485979437828064
                },
                {
                    "id": 1627204,
                    "contents": "Chemical equilibrium\nenergy at constant volume reactions) is the \"driving force\" for the composition of the mixture to change until equilibrium is reached. The equilibrium constant can be related to the standard Gibbs free energy change for the reaction by the equation",
                    "score": 0.84828782081604
                },
                {
                    "id": 1627203,
                    "contents": "Chemical equilibrium\nJ. W. Gibbs suggested in 1873 that equilibrium is attained when the Gibbs free energy of the system is at its minimum value (assuming the reaction is carried out at a constant temperature and pressure). What this means is that the derivative of the Gibbs energy with respect to reaction coordinate (a measure of the extent of reaction that has occurred, ranging from zero for all reactants to a maximum for all products) vanishes, signaling a stationary point. This derivative is called the reaction Gibbs energy (or energy change) and corresponds to the difference between the chemical potentials of reactants and products at the composition of the reaction mixture. This criterion is both necessary and sufficient. If a mixture is not at equilibrium, the liberation of the excess Gibbs energy (or Helmholtz energy at constant volume reactions) is the \"driving force\" for the composition of the mixture to change until equilibrium is reached. The equilibrium constant can be related to the standard",
                    "score": 0.8482597470283508
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_2",
        "question": "A mixture of water and ethanol is prepared with a mole fraction of water of 0.60 . If a small change in the mixture composition results in an increase in the chemical potential of water by $0.25 \\mathrm{~J} \\mathrm{~mol}^{-1}$, by how much will the chemical potential of ethanol change?",
        "golden_answers": [
            " -0.38"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 8119587,
                    "contents": "Volume fraction\nIn the case of a mixture of ethanol and water, which are miscible in all proportions, the designation of solvent and solute is arbitrary. The volume of such a mixture is slightly less than the sum of the volumes of the components. Thus, by the above definition, the term \"40% alcohol by volume\" refers to a mixture of 40 volume units of ethanol with enough water to make a final volume of 100 units, rather than a mixture of 40 units of ethanol with 60 units of water. See also Alcohol by volume Alcohol meter Alcohol proof Apparent molar property For non-ideal mixtures, see Partial molar volume and Excess molar quantity Percentage References Dimensionless numbers of chemistry Physical chemistry Thermodynamics Analytical chemistry",
                    "score": 0.9102476835250854
                },
                {
                    "id": 1704095,
                    "contents": "Ethanol\nMixtures of ethanol and water form an azeotrope at about 89 mole-% ethanol and 11 mole-% water or a mixture of 95.6 percent ethanol by mass (or about 97% alcohol by volume) at normal pressure, which boils at 351K (78 °C). This azeotropic composition is strongly temperature- and pressure-dependent and vanishes at temperatures below 303 K. Hydrogen bonding causes pure ethanol to be hygroscopic to the extent that it readily absorbs water from the air. The polar nature of the hydroxyl group causes ethanol to dissolve many ionic compounds, notably sodium and potassium hydroxides, magnesium chloride, calcium chloride, ammonium chloride, ammonium bromide, and sodium bromide. Sodium and potassium chlorides are slightly soluble in ethanol. Because the ethanol molecule also has a nonpolar end, it will also dissolve nonpolar substances, including most essential oils and numerous flavoring, coloring, and medicinal agents.",
                    "score": 0.9038217067718506
                },
                {
                    "id": 1704094,
                    "contents": "Ethanol\nEthanol's miscibility with water contrasts with the immiscibility of longer-chain alcohols (five or more carbon atoms), whose water miscibility decreases sharply as the number of carbons increases. The miscibility of ethanol with alkanes is limited to alkanes up to undecane: mixtures with dodecane and higher alkanes show a miscibility gap below a certain temperature (about 13 °C for dodecane). The miscibility gap tends to get wider with higher alkanes, and the temperature for complete miscibility increases. Ethanol-water mixtures have less volume than the sum of their individual components at the given fractions. Mixing equal volumes of ethanol and water results in only 1.92 volumes of mixture. Mixing ethanol and water is exothermic, with up to 777 J/mol being released at 298 K.",
                    "score": 0.884563148021698
                },
                {
                    "id": 1879026,
                    "contents": "Henry's law\nFor a water-ethanol mixture, the interaction parameter a13 has values around for ethanol concentrations (volume/volume) between 5% and 25% . Miscellaneous In geochemistry In geochemistry, a version of Henry's law applies to the solubility of a noble gas in contact with silicate melt. One equation used is where C is the number concentrations of the solute gas in the melt and gas phases, β = 1/kBT, an inverse temperature parameter (kB is the Boltzmann constant), µE is the excess chemical potentials of the solute gas in the two phases. Comparison to Raoult's law Henry's law is a limiting law that only applies for \"sufficiently dilute\" solutions, while Raoult's law is generally valid when the liquid phase is almost pure or for mixtures of similar substances. The range of concentrations in which Henry's law applies becomes narrower the more the system diverges from ideal behavior. Roughly speaking, that is the more chemically \"different\" the solute is from the solvent.",
                    "score": 0.8841708302497864
                },
                {
                    "id": 1083455,
                    "contents": "Azeotrope\nbe 80% ethanol and 20% water, which is closer to the azeotropic mixture than the original, which means the solution left behind will be poorer in ethanol. Distilling the 80/20% mixture produces a distillate that is 87% ethanol and 13% water. Further repeated distillations will produce mixtures that are progressively closer to the azeotropic ratio of 95.5/4.5%. No numbers of distillations will ever result in a distillate that exceeds the azeotropic ratio. Likewise, when distilling a mixture of ethanol and water that is richer in ethanol than the azeotrope, the distillate (contrary to intuition) will be poorer in ethanol than the original but still richer than the azeotrope.",
                    "score": 0.8785673379898071
                },
                {
                    "id": 14345408,
                    "contents": "Partial molar property\nDefinition The partial molar volume is broadly understood as the contribution that a component of a mixture makes to the overall volume of the solution. However, there is more to it than this: When one mole of water is added to a large volume of water at 25 °C, the volume increases by 18 cm3. The molar volume of pure water would thus be reported as 18 cm3 mol−1. However, addition of one mole of water to a large volume of pure ethanol results in an increase in volume of only 14 cm3. The reason that the increase is different is that the volume occupied by a given number of water molecules depends upon the identity of the surrounding molecules. The value 14 cm3 is said to be the partial molar volume of water in ethanol. In general, the partial molar volume of a substance X in a mixture is the change in volume per mole of X added to the mixture.",
                    "score": 0.8784055709838867
                },
                {
                    "id": 892662,
                    "contents": "Vapor pressure\nwhere is the mixture's vapor pressure, is the mole fraction of component in the liquid phase and is the mole fraction of component in the vapor phase respectively. is the vapor pressure of component . Raoult's law is applicable only to non-electrolytes (uncharged species); it is most appropriate for non-polar molecules with only weak intermolecular attractions (such as London forces). Systems that have vapor pressures higher than indicated by the above formula are said to have positive deviations. Such a deviation suggests weaker intermolecular attraction than in the pure components, so that the molecules can be thought of as being \"held in\" the liquid phase less strongly than in the pure liquid. An example is the azeotrope of approximately 95% ethanol and water. Because the azeotrope's vapor pressure is higher than predicted by Raoult's law, it boils at a temperature below that of either pure component.",
                    "score": 0.8745885491371155
                },
                {
                    "id": 2633270,
                    "contents": "Alcohol by volume\nVolume change Mixing two solutions of alcohol of different strengths usually causes a change in volume. Mixing pure water with a solution less than 24% by mass causes a slight increase in total volume, whereas the mixing of two solutions above 24% causes a decrease in volume. The phenomenon of volume changes due to mixing dissimilar solutions is called \"partial molar volume\". Water and ethanol are both polar solvents. When water is added to ethanol, the smaller water molecules are attracted to the ethanol's hydroxyl group, and each molecule alters the polarity field of the other. The attraction allows closer spacing between molecules than is usually found in non-polar mixtures.",
                    "score": 0.8741489052772522
                },
                {
                    "id": 6025677,
                    "contents": "Ethanol (data page)\nThis page provides supplementary chemical data on ethanol. Material Safety Data Sheet External MSDS Structure and properties Thermodynamic properties Spectral data Vapor pressure of liquid Density of ethanol at various temperatures Data obtained from These data correlate as ρ [g/cm3] = −8.461834 T [°C] + 0.8063372 with an R2 = 0.99999. Properties of aqueous ethanol solutions Data obtained from Boiling points of aqueous solutions Data obtained from CRC Handbook of Chemistry (Page 2117) ‡Azeotropic mixture Charts References Chemical data pages Data page Chemical data pages cleanup",
                    "score": 0.8720607161521912
                },
                {
                    "id": 1562151,
                    "contents": "Alcohol (chemistry)\nBecause of hydrogen bonding, alcohols tend to have higher boiling points than comparable hydrocarbons and ethers. The boiling point of the alcohol ethanol is 78.29 °C, compared to 69 °C for the hydrocarbon hexane, and 34.6 °C for diethyl ether. Occurrence in nature Simple alcohols are found widely in nature. Ethanol is the most prominent because it is the product of fermentation, a major energy-producing pathway. Other simple alcohols, chiefly fusel alcohols, are formed in only trace amounts. More complex alcohols however are pervasive, as manifested in sugars, some amino acids, and fatty acids. Production Ziegler and oxo processes In the Ziegler process, linear alcohols are produced from ethylene and triethylaluminium followed by oxidation and hydrolysis. An idealized synthesis of 1-octanol is shown: The process generates a range of alcohols that are separated by distillation.",
                    "score": 0.8720493912696838
                },
                {
                    "id": 1704121,
                    "contents": "Ethanol\nIn 1796, German-Russian chemist Johann Tobias Lowitz obtained pure ethanol by mixing partially purified ethanol (the alcohol-water azeotrope) with an excess of anhydrous alkali and then distilling the mixture over low heat. French chemist Antoine Lavoisier described ethanol as a compound of carbon, hydrogen, and oxygen, and in 1807 Nicolas-Théodore de Saussure determined ethanol's chemical formula. Fifty years later, Archibald Scott Couper published the structural formula of ethanol. It was one of the first structural formulas determined.",
                    "score": 0.8717255592346191
                },
                {
                    "id": 16022593,
                    "contents": "Apparent molar property\nIf the solution were ideal, its volume would be the sum of the unmixed components. The volume of 0.2 kg pure ethanol is 0.2 kg x 1.27 L/kg = 0.254 L, and the volume of 0.8 kg pure water is 0.8 kg x 1.0018 L/kg = 0.80144 L, so the ideal solution volume would be 0.254 L + 0.80144 L = 1.055 L. The nonideality of the solution is reflected by a slight decrease (roughly 2.2%, 1.0326 rather than 1.055 L/kg) in the volume of the combined system upon mixing. As the percent ethanol goes up toward 100%, the apparent molar volume rises to the molar volume of pure ethanol. Electrolyte – non-electrolyte systems Apparent quantities can underline interactions in electrolyte – non-electrolyte systems which show interactions like salting in and salting out, but also give insights in ion-ion interactions, especially by their dependence on temperature.",
                    "score": 0.871234655380249
                },
                {
                    "id": 25132767,
                    "contents": "Emily Fortey\non this work, published in 1898. There is also evidence that Fortey collaborated with William A. Tilden in 1902 on alcohol-water mixtures. The data generated by Fortey and Tilden contributed to the conclusion that no alcohol hydrates can be formed above 0 °C.",
                    "score": 0.869631826877594
                },
                {
                    "id": 3003946,
                    "contents": "Ideal solution\nIf the molecules are almost identical chemically, e.g., 1-butanol and 2-butanol, then the solution will be almost ideal. Since the interaction energies between A and B are almost equal, it follows that there is only a very small overall energy (enthalpy) change when the substances are mixed. The more dissimilar the nature of A and B, the more strongly the solution is expected to deviate from ideality. Formal definition Different related definitions of an ideal solution have been proposed. The simplest definition is that an ideal solution is a solution for which each component obeys Raoult's law for all compositions. Here is the vapor pressure of component above the solution, is its mole fraction and is the vapor pressure of the pure substance at the same temperature.",
                    "score": 0.868047297000885
                },
                {
                    "id": 1704110,
                    "contents": "Ethanol\nAbsolute alcohol Absolute or anhydrous alcohol refers to ethanol with a low water content. There are various grades with maximum water contents ranging from 1% to a few parts per million (ppm). If azeotropic distillation is used to remove water, it will contain trace amounts of the material separation agent (e.g. benzene). Absolute alcohol is not intended for human consumption. Absolute ethanol is used as a solvent for laboratory and industrial applications, where water will react with other chemicals, and as fuel alcohol. Spectroscopic ethanol is an absolute ethanol with a low absorbance in ultraviolet and visible light, fit for use as a solvent in ultraviolet-visible spectroscopy. Pure ethanol is classed as 200 proof in the US, equivalent to 175 degrees proof in the UK system.",
                    "score": 0.8679245710372925
                },
                {
                    "id": 1704111,
                    "contents": "Ethanol\nPure ethanol is classed as 200 proof in the US, equivalent to 175 degrees proof in the UK system. Rectified spirits Rectified spirit, an azeotropic composition of 96% ethanol containing 4% water, is used instead of anhydrous ethanol for various purposes. Spirits of wine are about 94% ethanol (188 proof). The impurities are different from those in 95% (190 proof) laboratory ethanol. Reactions Ethanol is classified as a primary alcohol, meaning that the carbon that its hydroxyl group attaches to has at least two hydrogen atoms attached to it as well. Many ethanol reactions occur at its hydroxyl group.",
                    "score": 0.8679181933403015
                },
                {
                    "id": 1704093,
                    "contents": "Ethanol\nEthanol is slightly more refractive than water, having a refractive index of 1.36242 (at λ=589.3 nm and ). The triple point for ethanol is at a pressure of . Solvent properties Ethanol is a versatile solvent, miscible with water and with many organic solvents, including acetic acid, acetone, benzene, carbon tetrachloride, chloroform, diethyl ether, ethylene glycol, glycerol, nitromethane, pyridine, and toluene. Its main use as a solvent is in making tincture of iodine, cough syrups etc. It is also miscible with light aliphatic hydrocarbons, such as pentane and hexane, and with aliphatic chlorides such as trichloroethane and tetrachloroethylene.",
                    "score": 0.8676386475563049
                },
                {
                    "id": 1254023,
                    "contents": "Solution (chemistry)\nLiquid solutions If the solvent is a liquid, then almost all gases, liquids, and solids can be dissolved. Here are some examples: Gas in liquid: Oxygen in water Carbon dioxide in water – a less simple example, because the solution is accompanied by a chemical reaction (formation of ions). The visible bubbles in carbonated water are not the dissolved gas, but only an effervescence of carbon dioxide that has come out of solution; the dissolved gas itself is not visible since it is dissolved on a molecular level. Liquid in liquid: The mixing of two or more substances of the same chemistry but different concentrations to form a constant. (Homogenization of solutions) Alcoholic beverages are basically solutions of ethanol in water. Solid in liquid: Sucrose (table sugar) in water Sodium chloride (NaCl) (table salt) or any other salt in water, which forms an electrolyte: When dissolving, salt dissociates into ions.",
                    "score": 0.8650362491607666
                },
                {
                    "id": 1379454,
                    "contents": "Solvent\nWhen one substance dissolves into another, a solution is formed. A solution is a homogeneous mixture consisting of a solute dissolved into a solvent. The solute is the substance that is being dissolved, while the solvent is the dissolving medium. Solutions can be formed with many different types and forms of solutes and solvents. Solvent classifications Solvents can be broadly classified into two categories: polar and non-polar. A special case is mercury, whose solutions are known as amalgams; also, other metal solutions exist which are liquid at room temperature. Generally, the dielectric constant of the solvent provides a rough measure of a solvent's polarity. The strong polarity of water is indicated by its high dielectric constant of 88 (at 0 °C). Solvents with a dielectric constant of less than 15 are generally considered to be nonpolar.",
                    "score": 0.8648881912231445
                },
                {
                    "id": 16022597,
                    "contents": "Apparent molar property\nSee also Volume fraction Ideal solution Regular solution Enthalpy change of solution Enthalpy of mixing Block design Heat of dilution Hydration energy Ion transport number Solvation shell Partial molar property Excess molar quantity Salting in Ternary plot Thermodynamic activity References External links Apparent Molar Properties: Solutions: Background The (p,ρ,T) Properties and Apparent Molar Volumes of ethanol solutions of LiI or ZnCl2 Apparent molar volumes and apparent molar heat capacities of Pr(NO3)3(aq), Gd(NO3)3(aq), Ho(NO3)3(aq), and Y(NO3)3(aq) at T = (288.15, 298.15, 313.15, and 328.15) K and p = 0.1 MPa Isotopic effects for electrolytes apparent properties Physical chemistry Thermodynamic properties",
                    "score": 0.863968014717102
                },
                {
                    "id": 1562152,
                    "contents": "Alcohol (chemistry)\nThe process generates a range of alcohols that are separated by distillation. Many higher alcohols are produced by hydroformylation of alkenes followed by hydrogenation. When applied to a terminal alkene, as is common, one typically obtains a linear alcohol: Such processes give fatty alcohols, which are useful for detergents. Hydration reactions Some low molecular weight alcohols of industrial importance are produced by the addition of water to alkenes. Ethanol, isopropanol, 2-butanol, and tert-butanol are produced by this general method. Two implementations are employed, the direct and indirect methods. The direct method avoids the formation of stable intermediates, typically using acid catalysts. In the indirect method, the alkene is converted to the sulfate ester, which is subsequently hydrolyzed. The direct hydration using ethylene (ethylene hydration) or other alkenes from cracking of fractions of distilled crude oil.",
                    "score": 0.8609570264816284
                },
                {
                    "id": 16022592,
                    "contents": "Apparent molar property\nAlcohol Another example of the apparent molar volume of the second component is less than its molar volume as a pure substance is the case of ethanol in water. For example, at 20 mass percents ethanol, the solution has a volume of 1.0326 liters per kg at 20 °C, while pure water is 1.0018 L/kg (1.0018 cc/g). The apparent volume of the added ethanol is 1.0326 L – 0.8 kg x 1.0018 L/kg = 0.2317 L. The number of moles of ethanol is 0.2 kg / (0.04607 kg/mol) = 4.341 mol, so that the apparent molar volume is 0.2317 L / 4.341 mol = 0.0532 L / mol = 53.2 cc/mole (1.16 cc/g). However pure ethanol has a molar volume at this temperature of 58.4 cc/mole (1.27 cc/g).",
                    "score": 0.8593155145645142
                },
                {
                    "id": 1254027,
                    "contents": "Solution (chemistry)\nAll solutions have a positive entropy of mixing. The interactions between different molecules or ions may be energetically favored or not. If interactions are unfavorable, then the free energy decreases with increasing solute concentration. At some point, the energy loss outweighs the entropy gain, and no more solute particles can be dissolved; the solution is said to be saturated. However, the point at which a solution can become saturated can change significantly with different environmental factors, such as temperature, pressure, and contamination. For some solute-solvent combinations, a supersaturated solution can be prepared by raising the solubility (for example by increasing the temperature) to dissolve more solute and then lowering it (for example by cooling).",
                    "score": 0.8581207990646362
                },
                {
                    "id": 4559328,
                    "contents": "Paul Walden\nAfter that, Walden became interested in electrochemistry of nonaqueous solutions. In 1902, he proposed a theory of autodissociation of inorganic and organic solvents. In 1905, he found a relationship between the maximum molecular conductivity and viscosity of the medium and in 1906, coined the term \"solvation\". Together with his work on stereochemistry, these results brought him to prominence; in particular, he was considered a candidate for the Nobel Prize in Chemistry in 1913 and 1914. Walden was also credited as a talented chemistry lecturer. In his memoirs, he wrote: \"My audience usually was crowded and the feedback of sympathetic listeners gave me strength ... my lectures I was giving spontaneously, to bring freshness to the subject ... I never considered teaching as a burden\".",
                    "score": 0.8572951555252075
                },
                {
                    "id": 13043985,
                    "contents": "Enthalpy of mixing\nWhen two substances are mixed the resulting enthalpy is not an addition of the pure component enthalpies, unless the substances form an ideal mixture. The interactions between each set of molecules determines the final change in enthalpy. For example, when compound “x” has a strong attractive interaction with compound “y” the resulting enthalpy is exothermic. In the case of alcohol and its interactions with a hydrocarbon, the alcohol molecule participates in hydrogen bonding with other alcohol molecules, and these hydrogen bonding interactions are much stronger than alcohol-hydrocarbon interactions, which results in an endothermic heat of mixing.",
                    "score": 0.8566381335258484
                },
                {
                    "id": 10406071,
                    "contents": "Vapor–liquid equilibrium\nThen for each component in the vapor phase: y1 = P1 / Ptot, y2 = P2 / Ptot, ... etc. where P1 = partial pressure of component 1, = partial pressure of component 2, etc. Raoult's law is approximately valid for mixtures of components between which there is very little interaction other than the effect of dilution by the other components. Examples of such mixtures includes mixtures of alkanes, which are non-polar, relatively inert compounds in many ways, so there is little attraction or repulsion between the molecules. Raoult's law states that for components 1, 2, etc. in a mixture: P1 = x1 P o1, P2 = x2 P o2, ... etc. where P o1, P o2, etc. are the vapor pressures of components 1, 2, etc. when they are pure, and x1, x2, etc. are mole fractions of the corresponding component in the liquid.",
                    "score": 0.8565989136695862
                },
                {
                    "id": 16806021,
                    "contents": "Superheated water\nWater is a polar molecule, where the centers of positive and negative charge are separated; so molecules will align with an electric field. The extensive hydrogen bonded network in water tends to oppose this alignment, and the degree of alignment is measured by the relative permittivity. Water has a high relative permittivity of about 80 at room temperature; because polarity shifts are rapidly transmitted through shifts in orientation of the linked hydrogen bonds. This allows water to dissolve salts, as the attractive electric field between ions is reduced by about 80–fold. Thermal motion of the molecules disrupts the hydrogen bonding network as temperature increases; so relative permittivity decreases with temperature to about 7 at the critical temperature. At 205 °C the relative permittivity falls to 33, the same as methanol at room temperature. Thus water behaves like a water–methanol mixture between 100 °C and 200 °C. Disruption of extended hydrogen bonding allows molecules to",
                    "score": 0.8564674854278564
                },
                {
                    "id": 221131,
                    "contents": "Mixture\nThe following table shows the main properties and examples for all possible phase combinations of the three \"families\" of mixtures: Homogeneous and heterogeneous mixtures Mixtures can be either homogeneous or heterogeneous: a mixture in which constituents are distributed uniformly, such as salt in water, is called homogeneous, whereas a mixture whose constituents are clearly separate from one another, such as sand in water, it is called heterogeneous. In addition, \"uniform mixture\" is another term for homogenous mixture and \"non-uniform mixture\" is another term for heterogeneous mixture. These terms are derived from the idea that a homogeneous mixture has a uniform appearance, or only one visible phase, because the particles are evenly distributed. However, a heterogeneous mixture has non-uniform composition and its constituent substances are easily distinguishable from one another (often, but not always, in different phases).",
                    "score": 0.8562061786651611
                },
                {
                    "id": 16806022,
                    "contents": "Superheated water\nfalls to 33, the same as methanol at room temperature. Thus water behaves like a water–methanol mixture between 100 °C and 200 °C. Disruption of extended hydrogen bonding allows molecules to move more freely (viscosity, diffusion and surface tension effects), and extra energy must be supplied to break the bonds (increased heat capacity).",
                    "score": 0.8558951020240784
                },
                {
                    "id": 10406058,
                    "contents": "Vapor–liquid equilibrium\nBinary mixtures are those having two components. Three-component mixtures are called ternary mixtures. There can be VLE data for mixtures with even more components, but such data is often hard to show graphically. VLE data is a function of the total pressure, such as 1 atm or at the pressure the process is conducted at.",
                    "score": 0.8552584052085876
                },
                {
                    "id": 1379453,
                    "contents": "Solvent\nIn addition to mixing, the substances in a solution interact with each other at the molecular level. When something is dissolved, molecules of the solvent arrange around molecules of the solute. Heat transfer is involved and entropy is increased making the solution more thermodynamically stable than the solute and solvent separately. This arrangement is mediated by the respective chemical properties of the solvent and solute, such as hydrogen bonding, dipole moment and polarizability. Solvation does not cause a chemical reaction or chemical configuration changes in the solute. However, solvation resembles a coordination complex formation reaction, often with considerable energetics (heat of solvation and entropy of solvation) and is thus far from a neutral process.",
                    "score": 0.8552526235580444
                },
                {
                    "id": 8188854,
                    "contents": "Entropy of mixing\nFor example, triethylamine and water are miscible in all proportions below 19 °C, but above this critical temperature, solutions of certain compositions separate into two phases at equilibrium with each other. This means that is negative for mixing of the two phases below 19 °C and positive above this temperature. Therefore, is negative for mixing of these two equilibrium phases. This is due to the formation of attractive hydrogen bonds between the two components that prevent random mixing. Triethylamine molecules cannot form hydrogen bonds with each other but only with water molecules, so in solution they remain associated to water molecules with loss of entropy. The mixing that occurs below 19 °C is due not to entropy but to the enthalpy of formation of the hydrogen bonds.",
                    "score": 0.8545868992805481
                },
                {
                    "id": 540406,
                    "contents": "Ethane\nThe name ethane is derived from the IUPAC nomenclature of organic chemistry. \"Eth-\" is derived from the German for potable alcohol (ethanol), e\" refers to the presence of a single bond between the carbon atoms. Properties At standard temperature and pressure, ethane is a colorless, odorless gas. It has a boiling point of and melting point of . Solid ethane exists in several modifications. On cooling under normal pressure, the first modification to appear is a plastic crystal, crystallizing in the cubic system. In this form, the positions of the hydrogen atoms are not fixed; the molecules may rotate freely around the long axis. Cooling this ethane below ca. changes it to monoclinic metastable ethane II (space group P 21/n). Ethane is only very sparingly soluble in water.",
                    "score": 0.8523123264312744
                },
                {
                    "id": 1254029,
                    "contents": "Solution (chemistry)\nThe properties of ideal solutions can be calculated by the linear combination of the properties of its components. If both solute and solvent exist in equal quantities (such as in a 50% ethanol, 50% water solution), the concepts of \"solute\" and \"solvent\" become less relevant, but the substance that is more often used as a solvent is normally designated as the solvent (in this example, water). Liquid In principle, all types of liquids can behave as solvents: liquid noble gases, molten metals, molten salts, molten covalent networks, and molecular liquids. In the practice of chemistry and biochemistry, most solvents are molecular liquids. They can be classified into polar and non-polar, according to whether their molecules possess a permanent electric dipole moment. Another distinction is whether their molecules can form hydrogen bonds (protic and aprotic solvents). Water, the most commonly used solvent, is both polar and sustains hydrogen bonds.",
                    "score": 0.8520864844322205
                },
                {
                    "id": 221133,
                    "contents": "Mixture\nA homogeneous mixture is characterized by uniform dispersion of its constituent substances throughout; the substances exist in equal proportion everywhere within the mixture. Differently put, a homogeneous mixture will be the same no matter from where in the mixture it is sampled. For example, if a solid-liquid solution is divided into two halves of equal volume, the halves will contain equal amounts of both the liquid medium and dissolved solid (solvent and solute). In physical chemistry and materials science, \"homogeneous\" more narrowly describes substances and mixtures which are in a single phase.",
                    "score": 0.8512588739395142
                },
                {
                    "id": 6161598,
                    "contents": "Water (data page)\nStandard conditions In the following table, material data are given for standard pressure of 0.1 MPa (equivalent to 1 bar). Up to 99.63 °C (the boiling point of water at 0.1 MPa), at this pressure water exists as a liquid. Above that, it exists as water vapor. Note that the boiling point of 100.0 °C is at a pressure of 0.101325 MPa (1 atm), which is the average atmospheric pressure. Triple point In the following table, material data are given with a pressure of 611.7 Pa (equivalent to 0.006117 bar). Up to a temperature of 0.01 °C, the triple point of water, water normally exists as ice, except for supercooled water, for which one data point is tabulated here. At the triple point, ice can exist together with both liquid water and vapor. At higher temperatures, the data are for water vapor only. Saturated vapor pressure",
                    "score": 0.8508901596069336
                },
                {
                    "id": 14503349,
                    "contents": "Isopropyl alcohol\nIt is used in the manufacture of a wide variety of industrial and household chemicals and is a common ingredient in chemicals such as antiseptics, disinfectants, and detergents. Properties Isopropyl alcohol is miscible in water, ethanol, and chloroform. It dissolves ethyl cellulose, polyvinyl butyral, many oils, alkaloids, gums and natural resins. Unlike ethanol or methanol, isopropyl alcohol is not miscible with salt solutions and can be separated from aqueous solutions by adding a salt such as sodium chloride. The process is colloquially called salting out, and causes concentrated isopropyl alcohol to separate into a distinct layer. Isopropyl alcohol forms an azeotrope with water, which gives a boiling point of and a composition of 87.7% by mass (91% by volume) isopropyl alcohol. Alcohol mixtures have depressed melting points. It has a slightly bitter taste, and is not safe to drink. Isopropyl alcohol becomes increasingly viscous with decreasing temperature and freezes at .",
                    "score": 0.8508379459381104
                },
                {
                    "id": 4331584,
                    "contents": "Aqueous solution\nAn aqueous solution is a solution in which the solvent is water. It is mostly shown in chemical equations by appending (aq) to the relevant chemical formula. For example, a solution of table salt, or sodium chloride (NaCl), in water would be represented as . The word aqueous (which comes from aqua) means pertaining to, related to, similar to, or dissolved in, water. As water is an excellent solvent and is also naturally abundant, it is a ubiquitous solvent in chemistry. Aqueous solution is water with a pH of 7.0 where the hydrogen ions () and hydroxide ions () are in Arrhenius balance (). A non-aqueous solution is a solution in which the solvent is a liquid, but is not water. (See also Solvent and Inorganic nonaqueous solvent.)",
                    "score": 0.8499971628189087
                },
                {
                    "id": 13043989,
                    "contents": "Enthalpy of mixing\nA regular solution or mixture has a non-zero enthalpy of mixing with an ideal entropy of mixing. Under this assumption, scales linearly with , and is equivalent to the excess internal energy. Mixing binary mixtures to form ternary mixtures The heat of mixing for binary mixtures to form ternary one can be expressed as a function of mixing ratios of binary mixtures: Intermolecular forces Intermolecular forces are the main constituent of changes in the enthalpy of a mixture. Stronger attractive forces between the mixed molecules, such as hydrogen-bonding, induced-dipole, and dipole-dipole interactions result in a lower enthalpy of the mixture and a release of heat. If strong interactions only exist between like-molecules, such as H-bonds between water in a water-hexane solution, the mixture will have a higher total enthalpy and absorb heat. See also Apparent molar property Enthalpy Enthalpy change of solution Excess molar quantity Entropy of mixing Calorimetry Miedema's Model",
                    "score": 0.8494234085083008
                },
                {
                    "id": 3003952,
                    "contents": "Ideal solution\nIn contrast to ideal solutions, where volumes are strictly additive and mixing is always complete, the volume of a non-ideal solution is not, in general, the simple sum of the volumes of the component pure liquids and solubility is not guaranteed over the whole composition range. By measurement of densities, thermodynamic activity of components can be determined. See also Activity coefficient Entropy of mixing Margules function Regular solution Coil-globule transition Apparent molar property Dilution equation Virial coefficient References Solutions Thermodynamics Chemical thermodynamics",
                    "score": 0.8490739464759827
                },
                {
                    "id": 1704092,
                    "contents": "Ethanol\nChemistry Chemical formula Ethanol is a 2-carbon alcohol. Its molecular formula is CH3CH2OH. An alternative notation is CH3−CH2−OH, which indicates that the carbon of a methyl group (CH3−) is attached to the carbon of a methylene group (−CH2–), which is attached to the oxygen of a hydroxyl group (−OH). It is a constitutional isomer of dimethyl ether. Ethanol is sometimes abbreviated as EtOH, using the common organic chemistry notation of representing the ethyl group (C2H5−) with Et. Physical properties Ethanol is a volatile, colorless liquid that has a slight odor. It burns with a smokeless blue flame that is not always visible in normal light. The physical properties of ethanol stem primarily from the presence of its hydroxyl group and the shortness of its carbon chain. Ethanol's hydroxyl group is able to participate in hydrogen bonding, rendering it more viscous and less volatile than less polar organic compounds of similar molecular weight, such as propane.",
                    "score": 0.8482294082641602
                },
                {
                    "id": 4331585,
                    "contents": "Aqueous solution\nA non-aqueous solution is a solution in which the solvent is a liquid, but is not water. (See also Solvent and Inorganic nonaqueous solvent.) Substances that are hydrophobic ('water-fearing') do not dissolve well in water, whereas those that are hydrophilic ('water-friendly') do. An example of a hydrophilic substance is sodium chloride. Acids and bases are aqueous solutions, as part of their Arrhenius definitions. The ability of a substance to dissolve in water is determined by whether the substance can match or exceed the strong attractive forces that water molecules generate between themselves. If the substance lacks the ability to dissolve in water, the molecules form a precipitate. Reactions in aqueous solutions are usually metathesis reactions. Metathesis reactions are another term for double-displacement; that is, when a cation displaces to form an ionic bond with the other anion. The cation bonded with the latter anion will dissociate and bond with the other anion.",
                    "score": 0.8480405807495117
                },
                {
                    "id": 221132,
                    "contents": "Mixture\nSeveral solid substances, such as salt and sugar, dissolve in water to form a special type of homogeneous mixture called a solution, in which there is both a solute (dissolved substance) and solvent (dissolving medium) present. Air is an example of a solution as well: a homogeneous mixture of gaseous nitrogen solvent, in which oxygen and smaller amounts of other gaseous solutes are dissolved. Mixtures are not limited in either their number of substances or the amounts of those substances, though in a homogeneous mixture the solute-to-solvent proportion can only reach a certain point before the mixture separates and becomes heterogeneous.",
                    "score": 0.8477800488471985
                },
                {
                    "id": 1704114,
                    "contents": "Ethanol\nC2H5OH (l) + 3 O2 (g) → 2 CO2 (g) + 3 H2O (g); −ΔHc = 1236 kJ/mol = 26.8 kJ/g = 295.4 kcal/mol = 6.41 kcal/g Specific heat = 2.44 kJ/(kg·K) Acid-base chemistry Ethanol is a neutral molecule and the pH of a solution of ethanol in water is nearly 7.00. Ethanol can be quantitatively converted to its conjugate base, the ethoxide ion (CH3CH2O−), by reaction with an alkali metal such as sodium: 2 CH3CH2OH + 2 Na → 2 CH3CH2ONa + H2 or a very strong base such as sodium hydride: CH3CH2OH + NaH → CH3CH2ONa + H2 The acidities of water and ethanol are nearly the same, as indicated by their pKa of 15.7 and 16 respectively. Thus, sodium ethoxide and sodium hydroxide exist in an equilibrium that is closely balanced: CH3CH2OH + NaOH CH3CH2ONa + H2O",
                    "score": 0.8473860025405884
                },
                {
                    "id": 1095678,
                    "contents": "Sodium hydroxide\nFor example, when a solution of NaOH and water with 1:2 mole ratio (52.6% NaOH by mass) is cooled, the monohydrate normally starts to crystallize (at about 22 °C) before the dihydrate. However, the solution can easily be supercooled down to −15 °C, at which point it may quickly crystallize as the dihydrate. When heated, the solid dihydrate might melt directly into a solution at 13.35 °C; however, once the temperature exceeds 12.58 °C. it often decomposes into solid monohydrate and a liquid solution. Even the n = 3.5 hydrate is difficult to crystallize, because the solution supercools so much that other hydrates become more stable. A hot water solution containing 73.1% (mass) of NaOH is an eutectic that solidifies at about 62.63 °C as an intimate mix of anhydrous and monohydrate crystals. A second stable eutectic composition is 45.4% (mass) of NaOH, that solidifies at about 4.9 °C into a mixture of crystals of the dihydrate and of the 3.5-hydrate.",
                    "score": 0.8472612500190735
                },
                {
                    "id": 19882494,
                    "contents": "List of water-miscible solvents\nThe following compounds are liquid at room temperature and are completely miscible with water; they are often used as solvents. Many of these compounds are hygroscopic. Organic Compounds Inorganic compounds See also :Category:Alcohol solvents External links Solvent miscibility table Diethylenetriamine Hydrazine Water-miscible solvents Solvents",
                    "score": 0.8470964431762695
                },
                {
                    "id": 15119676,
                    "contents": "PSRK\nPSRK describes this binary mixture quite well, the dew point curve, as well as the bubble point curve and the critical point of the mixture. Model weaknesses In a PSRK follow-up work (VTPR) some model weaknesses are quoted: The gradient of the Mathias–Copeman α-function is without any thermodynamic background and, if extrapolated to higher temperatures, the described vapor-pressure curve tends to diverge. The Soave–Redlich–Kwong equation of state describes the vapor densities of pure components and mixtures quite well, but the deviations of the liquid-density prediction are high. For the VLE prediction of mixtures with components that have very differing sizes (e. g. ethanol, C2H6O, and eicosane, C20H42) larger systematic errors are found. Heats of mixing and activity coefficients at infinite dilution are predicted poorly. Literature",
                    "score": 0.8469915986061096
                },
                {
                    "id": 17973477,
                    "contents": "Excess property\nIn chemical thermodynamics, excess properties are properties of mixtures which quantify the non-ideal behavior of real mixtures. They are defined as the difference between the value of the property in a real mixture and the value that would exist in an ideal solution under the same conditions. The most frequently used excess properties are the excess volume, excess enthalpy, and excess chemical potential. The excess volume, internal energy, and enthalpy are identical to the corresponding mixing properties; that is, These relationships hold because the volume, internal energy, and enthalpy changes of mixing are zero for an ideal solution. Definition By definition, excess properties are related to those of the ideal solution by: Here, the superscript IS denotes the value in the ideal solution, a superscript denotes the excess molar property, and denotes the particular property under consideration. From the properties of partial molar properties, substitution yields:",
                    "score": 0.845236599445343
                },
                {
                    "id": 1704096,
                    "contents": "Ethanol\nThe addition of even a few percent of ethanol to water sharply reduces the surface tension of water. This property partially explains the \"tears of wine\" phenomenon. When wine is swirled in a glass, ethanol evaporates quickly from the thin film of wine on the wall of the glass. As the wine's ethanol content decreases, its surface tension increases and the thin film \"beads up\" and runs down the glass in channels rather than as a smooth sheet.",
                    "score": 0.8442128300666809
                },
                {
                    "id": 16655827,
                    "contents": "Properties of water\nWater () is a polar inorganic compound that is at room temperature a tasteless and odorless liquid, which is nearly colorless apart from an inherent hint of blue. It is by far the most studied chemical compound and is described as the \"universal solvent\" and the \"solvent of life.\" It is the most abundant substance on the surface of Earth and the only common substance to exist as a solid, liquid, and gas on Earth's surface. It is also the third most abundant molecule in the universe (behind molecular hydrogen and carbon monoxide). Water molecules form hydrogen bonds with each other and are strongly polar. This polarity allows it to dissociate ions in salts and bond to other polar substances such as alcohols and acids, thus dissolving them. Its hydrogen bonding causes its many unique properties, such as having a solid form less dense than its liquid form, a relatively high boiling point of 100 °C for its molar mass, and a high heat capacity.",
                    "score": 0.8439949154853821
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_3",
        "question": "The enthalpy of fusion of mercury is $2.292 \\mathrm{~kJ} \\mathrm{~mol}^{-1}$, and its normal freezing point is $234.3 \\mathrm{~K}$ with a change in molar volume of $+0.517 \\mathrm{~cm}^3 \\mathrm{~mol}^{-1}$ on melting. At what temperature will the bottom of a column of mercury (density $13.6 \\mathrm{~g} \\mathrm{~cm}^{-3}$ ) of height $10.0 \\mathrm{~m}$ be expected to freeze?",
        "golden_answers": [
            " 234.4"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 16561928,
                    "contents": "Mercury (element)\nProperties Physical properties Mercury is a heavy, silvery-white liquid metal. Compared to other metals, it is a poor conductor of heat, but a fair conductor of electricity. It has a freezing point of −38.83 °C and a boiling point of 356.73 °C, both the lowest of any stable metal, although preliminary experiments on copernicium and flerovium have indicated that they have even lower boiling points. This effect is due to lanthanide contraction and relativistic contraction reducing the radius of the outermost electrons, and thus weakening the metallic bonding in mercury. Upon freezing, the volume of mercury decreases by 3.59% and its density changes from 13.69 g/cm3 when liquid to 14.184 g/cm3 when solid. The coefficient of volume expansion is 181.59 × 10−6 at 0 °C, 181.71 × 10−6 at 20 °C and 182.50 × 10−6 at 100 °C (per °C). Solid mercury is malleable and ductile and can be cut with a knife.",
                    "score": 0.8941333293914795
                },
                {
                    "id": 4721179,
                    "contents": "Relativistic quantum chemistry\nMercury Mercury (Hg) is a liquid down to −39 °C (see Melting point). Bonding forces are weaker for Hg–Hg bonds than for its immediate neighbors such as cadmium (m.p. 321 °C) and gold (m.p. 1064 °C). The lanthanide contraction only partially accounts for this anomaly. Mercury in the gas-phase is alone among metals in that it is quite typically found in a monomeric form as Hg(g). Hg22+(g) also forms, and it is a stable species due to the relativistic shortening of the bond. Hg2(g) does not form because the 6s2 orbital is contracted by relativistic effects and may therefore only weakly contribute to any bonding; in fact, Hg–Hg bonding must be mostly the result of van der Waals forces, which explains why the bonding for Hg–Hg is weak enough to allow for Hg to be a liquid at room temperature.",
                    "score": 0.8660051822662354
                },
                {
                    "id": 17656647,
                    "contents": "Enthalpy of fusion\nWhen liquid water is cooled, its temperature falls steadily until it drops just below the line of freezing point at 0 °C. The temperature then remains constant at the freezing point while the water crystallizes. Once the water is completely frozen, its temperature continues to fall. The enthalpy of fusion is almost always a positive quantity; helium is the only known exception. Helium-3 has a negative enthalpy of fusion at temperatures below 0.3 K. Helium-4 also has a very slightly negative enthalpy of fusion below . This means that, at appropriate constant pressures, these substances freeze with the addition of heat. In the case of 4He, this pressure range is between 24.992 and . These values are mostly from the CRC Handbook of Chemistry and Physics, 62nd edition. The conversion between cal/g and J/g in the above table uses the thermochemical calorie (calth) = 4.184 joules rather than the International Steam Table calorie (calINT) = 4.1868 joules. Examples",
                    "score": 0.8651620745658875
                },
                {
                    "id": 22893694,
                    "contents": "Metals close to the border between metals and nonmetals\nMercury is a liquid at room temperature. It has the weakest metallic bonding of all, as indicated by its bonding energy (61 kJ/mol) and melting point (−39 °C) which, together, are the lowest of all the metallic elements. Solid mercury (MH 1.5) has a distorted crystalline structure, with mixed metallic-covalent bonding, and a BCN of 6. \"All of the [Group 12] metals, but especially mercury, tend to form covalent rather than ionic compounds.\" The oxide of mercury in its preferred oxidation state (HgO; +2) is weakly amphoteric, as is the congener sulfide HgS. It forms anionic thiomercurates (such as Na2HgS2 and BaHgS3) in strongly basic solutions. It forms or is a part of Zintl phases such as NaHg and K8In10Hg. Mercury is a relatively inert metal, showing little oxide formation at room temperature.",
                    "score": 0.8639605045318604
                },
                {
                    "id": 1079138,
                    "contents": "Phase diagram\nWater is an exception which has a solid-liquid boundary with negative slope so that the melting point decreases with pressure. This occurs because ice (solid water) is less dense than liquid water, as shown by the fact that ice floats on water. At a molecular level, ice is less dense because it has a more extensive network of hydrogen bonding which requires a greater separation of water molecules. Other exceptions include antimony and bismuth. At very high pressures above 50 GPa (500 000 atm), liquid nitrogen undergoes a liquid-liquid phase transition to a polymeric form and becomes denser than solid nitrogen at the same pressure. Under these conditions therefore, solid nitrogen also floats in its liquid. The value of the slope dP/dT is given by the Clausius–Clapeyron equation for fusion (melting)",
                    "score": 0.8552972674369812
                },
                {
                    "id": 321856,
                    "contents": "Period 6 element\nMercuryMercury is a chemical element with the symbol Hg and atomic number 80. It is also known as quicksilver or hydrargyrum ( < Greek \"hydr-\" water and \"argyros\" silver). A heavy, silvery d-block element, mercury is the only metal that is liquid at standard conditions for temperature and pressure; the only other element that is liquid under these conditions is bromine, though metals such as caesium, francium, gallium, and rubidium melt just above room temperature. With a freezing point of −38.83 °C and boiling point of 356.73 °C, mercury has one of the narrowest ranges of its liquid state of any metal.",
                    "score": 0.8511821031570435
                },
                {
                    "id": 17780717,
                    "contents": "Liquid\nExamples Only two elements are liquid at standard conditions for temperature and pressure: mercury and bromine. Four more elements have melting points slightly above room temperature: francium, caesium, gallium and rubidium. Metal alloys that are liquid at room temperature include NaK, a sodium-potassium metal alloy, galinstan, a fusible alloy liquid, and some amalgams (alloys involving mercury). Pure substances that are liquid under normal conditions include water, ethanol and many other organic solvents. Liquid water is of vital importance in chemistry and biology; it is believed to be a necessity for the existence of life. Inorganic liquids include water, magma, inorganic nonaqueous solvents and many acids. Important everyday liquids include aqueous solutions like household bleach, other mixtures of different substances such as mineral oil and gasoline, emulsions like vinaigrette or mayonnaise, suspensions like blood, and colloids like paint and milk.",
                    "score": 0.8506608009338379
                },
                {
                    "id": 21117957,
                    "contents": "Mercury hydride\nMercury hydride may refer to: Mercury(I) hydride (HgH or Hg2H2), an extremely unstable gas Mercury(II) hydride (HgH2), a volatile, relatively stable white solid",
                    "score": 0.8503292202949524
                },
                {
                    "id": 17640560,
                    "contents": "William Douglas Allen\nPublications Some observations on the interface of mercury against water and aqueous solutions, with R.S. Burdon & J.W. Lillywhite, Australian and New Zealand Association for the Advancement of Science. Report of the Meeting., 23 (Auckland, 1937), 19. Spreading with uniform acceleration, with K. Grant & R.S. Burdon, Faraday Society, London. Transactions., 33 (1937), 1531–1532. Neutron detection, W.D. Allen, London : George Newnes, [c1960]. Gravitational radiation experiments at the University of Reading and the Rutherford Laboratory, with C. Christodoulides, J. Phys. A: Math. Gen., 8 (1975), 1726–33. Scholarships 1935 The John L. Young Scholarship 1937 Rhodes Scholarship Sources Allen, William Douglas (1914 – ), Bright Sparcs 'Allen, William Douglas', in Physics in Australia to 1945, R.W. Home, with the assistance of Paula J. Needham, Australian Science Archives Project, June 1995, http://www.asap.unimelb.edu.au/bsparcs/physics/P001585p.htm. William Douglas Allen's obituary",
                    "score": 0.8502745628356934
                },
                {
                    "id": 1865396,
                    "contents": "Mercury (planet)\nMercury is too small and hot for its gravity to retain any significant atmosphere over long periods of time; it does have a tenuous surface-bounded exosphere containing hydrogen, helium, oxygen, sodium, calcium, potassium and others at a surface pressure of less than approximately 0.5 nPa (0.005 picobars). This exosphere is not stable—atoms are continuously lost and replenished from a variety of sources. Hydrogen atoms and helium atoms probably come from the solar wind, diffusing into Mercury's magnetosphere before later escaping back into space. Radioactive decay of elements within Mercury's crust is another source of helium, as well as sodium and potassium. MESSENGER found high proportions of calcium, helium, hydroxide, magnesium, oxygen, potassium, silicon and sodium. Water vapor is present, released by a combination of processes such as: comets striking its surface, sputtering creating water out of hydrogen from the solar wind and oxygen from rock, and sublimation from reservoirs",
                    "score": 0.848682701587677
                },
                {
                    "id": 6885783,
                    "contents": "Isotopes of mercury\nHg-198 At roughly 10% of natural Mercury, Hg-198 is neither particularly abundant nor particularly rare. It has a non-negligible gamma ray cross section for the (γ,n) reaction with 10 Mega-Electronvolt Gamma Rays. This reaction, in addition to serving as a potential neutron source could also be used to produce Hg-197 and via electron capture produce - stable gold. Given that it is roughly two orders of magnitude more abundant that Hg-196, the required isotopic separation, even it required a further step of separating the lighter Hg-196 from the heavier Hg-198 could be achieved with a better yield for any given effort than for Hg-196. References Isotope masses from: Isotopic compositions and standard atomic masses from: Half-life, spin, and isomer data selected from the following sources. Mercury",
                    "score": 0.8458855152130127
                },
                {
                    "id": 892666,
                    "contents": "Vapor pressure\nThis method assumes that the heat of fusion is temperature-independent, ignores additional transition temperatures between different solid phases, and it gives a fair estimation for temperatures not too far from the melting point. It also shows that the sublimation pressure is lower than the extrapolated liquid vapor pressure (ΔfusH > 0) and the difference grows with increased distance from the melting point. Boiling point of water Like all liquids, water boils when its vapor pressure reaches its surrounding pressure. In nature, the atmospheric pressure is lower at higher elevations and water boils at a lower temperature. The boiling temperature of water for atmospheric pressures can be approximated by the Antoine equation: or transformed into this temperature-explicit form: where the temperature is the boiling point in degrees Celsius and the pressure is in Torr. Dühring's rule",
                    "score": 0.8453924059867859
                },
                {
                    "id": 1278297,
                    "contents": "Thallium\nOther uses A mercury–thallium alloy, which forms a eutectic at 8.5% thallium, is reported to freeze at −60 °C, some 20 °C below the freezing point of mercury. This alloy is used in thermometers and low-temperature switches. In organic synthesis, thallium(III) salts, as thallium trinitrate or triacetate, are useful reagents for performing different transformations in aromatics, ketones and olefins, among others. Thallium is a constituent of the alloy in the anode plates of magnesium seawater batteries. Soluble thallium salts are added to gold plating baths to increase the speed of plating and to reduce grain size within the gold layer.",
                    "score": 0.8443349599838257
                },
                {
                    "id": 1106217,
                    "contents": "Heike Kamerlingh Onnes\nOn 8 April 1911, Kamerlingh Onnes found that at 4.2 K the resistance in a solid mercury wire immersed in liquid helium suddenly vanished. He immediately realized the significance of the discovery (as became clear when his notebook was deciphered a century later). He reported that \"Mercury has passed into a new state, which on account of its extraordinary electrical properties may be called the superconductive state\". He published more articles about the phenomenon, initially referring to it as \"supraconductivity\" and, only later adopting the term \"superconductivity\". Kamerlingh Onnes received widespread recognition for his work, including the 1913 Nobel Prize in Physics for (in the words of the committee) \"his investigations on the properties of matter at low temperatures which led, inter alia, to the production of liquid helium\". Legacy",
                    "score": 0.8439677953720093
                },
                {
                    "id": 5853286,
                    "contents": "Heats of vaporization of the elements (data page)\nHeat of vaporization Notes Values refer to the enthalpy change in the conversion of liquid to gas at the boiling point (normal, 101.325 kPa). References Zhang et al. CRC As quoted from various sources in an online version of: David R. Lide (ed.), CRC Handbook of Chemistry and Physics, 84th Edition. CRC Press. Boca Raton, Florida, 2003; Section 6, Fluid Properties; Enthalpy of Vaporization GME Kugler HK & Keller C (eds) 1985, Gmelin handbook of inorganic and organometallic chemistry, 8th ed., 'At, Astatine', system no. 8a, Springer-Verlag, Berlin, , pp. 116–117 LNG As quoted from various sources in: J.A. Dean (ed.), Lange's Handbook of Chemistry (15th Edition), McGraw-Hill, 1999; Section 6, Thermodynamic Properties; Table 6.4, Heats of Fusion, Vaporization, and Sublimation and Specific Heat at Various Temperatures of the Elements and Inorganic Compounds",
                    "score": 0.8433999419212341
                },
                {
                    "id": 13712278,
                    "contents": "Atmosphere of Mercury\nThe temperature of Mercury's exosphere depends on species as well as geographical location. For exospheric atomic hydrogen, the temperature appears to be about 420 K, a value obtained by both Mariner 10 and MESSENGER. The temperature for sodium is much higher, reaching 750–1,500 K on the equator and 1,500–3,500 K at the poles. Some observations show that Mercury is surrounded by a hot corona of calcium atoms with temperature between 12,000 and 20,000 K. Tails",
                    "score": 0.8415809869766235
                },
                {
                    "id": 20575860,
                    "contents": "Mercury(II) hydride\nMercury(II) hydride (systematically named mercurane(2) and dihydridomercury) is an inorganic compound with the chemical formula (also written as ). It is both thermodynamically and kinetically unstable at ambient temperature, and as such, little is known about its bulk properties. However, it known as a white, crystalline solid, which is kinetically stable at temperatures below , which was synthesised for the first time in 1951. Mercury(II) hydride is the second simplest mercury hydride (after mercury(I) hydride). Due to its instability, it has no practical industrial uses. However, in analytical chemistry, mercury(II) hydride is fundamental to certain forms of spectrometric techniques used to determine mercury content. In addition, it is investigated for its effect on high sensitivity isotope-ratio mass spectrometry methods that involve mercury, such as MC-ICP-MS, when used to compare thallium to mercury. Properties",
                    "score": 0.8406983017921448
                },
                {
                    "id": 2250348,
                    "contents": "Liquid helium\nBecause of the very weak interatomic forces in helium, the element remains a liquid at atmospheric pressure all the way from its liquefaction point down to absolute zero. Liquid helium solidifies only under very low temperatures and great pressures. At temperatures below their liquefaction points, both helium-4 and helium-3 undergo transitions to superfluids. (See the table below.) Liquid helium-4 and the rare helium-3 are not completely miscible. Below 0.9 kelvin at their saturated vapor pressure, a mixture of the two isotopes undergoes a phase separation into a normal fluid (mostly helium-3) that floats on a denser superfluid consisting mostly of helium-4. This phase separation happens because the overall mass of liquid helium can reduce its thermodynamic enthalpy by separating.",
                    "score": 0.8405504822731018
                },
                {
                    "id": 1128026,
                    "contents": "Noble gas\nThe noble gases have weak interatomic force, and consequently have very low melting and boiling points. They are all monatomic gases under standard conditions, including the elements with larger atomic masses than many normally solid elements. Helium has several unique qualities when compared with other elements: its boiling point at 1 atm is lower than those of any other known substance; it is the only element known to exhibit superfluidity; and, it is the only element that cannot be solidified by cooling at atmospheric pressure (an effect explained by quantum mechanics as its zero point energy is too high to permit freezing) – a pressure of must be applied at a temperature of to convert it to a solid while a pressure of about 115 kbar is required at room temperature. The noble gases up to xenon have multiple stable isotopes. Radon has no stable isotopes; its longest-lived isotope, 222Rn, has a half-life of 3.8 days and decays to form helium and polonium, which ultimately decays to",
                    "score": 0.8405389785766602
                },
                {
                    "id": 8509934,
                    "contents": "Mercury(II) iodide\nHgCl2 + 2 KI → HgI2 + 2 KCl Properties Mercury(II) iodide displays thermochromism; when heated above 126 °C (400 K) it undergoes a phase transition, from the red alpha crystalline form to a pale yellow beta form. As the sample cools, it gradually reacquires its original colour. It has often been used for thermochromism demonstrations. A third form, which is orange, is also known; this can be formed by recrystallisation and is also metastable, eventually converting back to the red alpha form. The various forms can exist in a diverse range of crystal structures and as a result mercury(II) iodide possesses a surprisingly complex phase diagram. Uses Mercury(II) iodide is used for preparation of Nessler's reagent, used for detection of presence of ammonia. Mercury(II) iodide is a semiconductor material, used in some x-ray and gamma ray detection and imaging devices operating at room temperatures.",
                    "score": 0.8399671912193298
                },
                {
                    "id": 2156560,
                    "contents": "Henry Cavendish\nIn 1783, he published a paper on the temperature at which mercury freezes and in that paper made use of the idea of latent heat, although he did not use the term because he believed that it implied acceptance of a material theory of heat. He made his objections explicit in his 1784 paper on air. He went on to develop a general theory of heat, and the manuscript of that theory has been persuasively dated to the late 1780s. His theory was at once mathematical and mechanical: it contained the principle of the conservation of heat (later understood as an instance of conservation of energy) and even included the concept (although not the label) of the mechanical equivalent of heat. Density of the Earth",
                    "score": 0.8398187160491943
                },
                {
                    "id": 20575865,
                    "contents": "Mercury(II) hydride\nHistory Mercury(II) hydride was successfully synthesized and identified in 1951 by Egon Wiberg and Walter Henle, by the reaction of mercury(II) iodide and lithium tetrahydroaluminate in a mixture of petroleum ether and tetrahydrofuran. In 1993 Legay-Sommaire announced HgH2 production in cryogenic argon and krypton matrices with a KrF laser. In 2004, solid HgH2 was definitively synthesized and consequentially analysed, by Xuefeng Wang and Lester Andrews, by direct matrix isolation reaction of excited mercury with molecular hydrogen. In 2005, gaseous HgH2 was synthesized by Alireza Shayesteh et al, by the direct gas-phase reaction of excited mercury with molecular hydrogen at standard temperature; and Xuefeng Wang and Lester Andrews determined the structure of solid mercury HgH2, to be a molecular solid. References Mercury(II) compounds Metal hydrides",
                    "score": 0.8391951322555542
                },
                {
                    "id": 21530087,
                    "contents": "Liquid metal\nA liquid metal is a metal or a metal alloy which is liquid at or near room temperature. The only stable liquid elemental metal at room temperature is mercury (Hg), which is molten above −38.8 °C (234.3 K, −37.9 °F). Three more stable elemental metals melt just above room temperature: caesium (Cs), which has a melting point of 28.5 °C (83.3 °F); gallium (Ga) (30 °C [86 °F]); and rubidium (Rb) (39 °C [102 °F]). The radioactive metal francium (Fr) is probably liquid close to room temperature as well. Calculations predict that the radioactive metals copernicium (Cn) and flerovium (Fl) should also be liquid at room temperature. Alloys can be liquid if they form a eutectic, meaning that the alloy's melting point is lower than any of the alloy's constituent metals. The standard metal for creating liquid alloys used to be mercury, but gallium-based alloys, which are lower both in their vapor pressure at room temperature and toxicity, are being used as a replacement in various applications.",
                    "score": 0.8390291929244995
                },
                {
                    "id": 2823194,
                    "contents": "Group 12 element\nrequires a deep excursion into quantum physics, but it can be summarized as follows: mercury has a unique electronic configuration where electrons fill up all the available 1s, 2s, 2p, 3s, 3p, 3d, 4s, 4p, 4d, 4f, 5s, 5p, 5d and 6s subshells. As such configuration strongly resists removal of an electron, mercury behaves similarly to noble gas elements, which form weak bonds and thus easily melting solids. The stability of the 6s shell is due to the presence of a filled 4f shell. An f shell poorly screens the nuclear charge that increases the attractive Coulomb interaction of the 6s shell and the nucleus (see lanthanide contraction). The absence of a filled inner f shell is the reason for the somewhat higher melting temperature of cadmium and zinc, although both these metals still melt easily and, in addition, have unusually low boiling points. Gold has atoms with one less 6s electron than mercury. Those electrons are more easily removed and are shared between the gold atoms forming",
                    "score": 0.8373642563819885
                },
                {
                    "id": 16561925,
                    "contents": "Mercury (element)\nMercury is a chemical element with the symbol Hg and atomic number 80. It is commonly known as quicksilver and was formerly named hydrargyrum ( ) from the Greek words, hydor (water) and argyros (silver). A heavy, silvery d-block element, mercury is the only metallic element that is liquid at standard conditions for temperature and pressure; the only other element that is liquid under these conditions is the halogen bromine, though metals such as caesium, gallium, and rubidium melt just above room temperature. Mercury occurs in deposits throughout the world mostly as cinnabar (mercuric sulfide). The red pigment vermilion is obtained by grinding natural cinnabar or synthetic mercuric sulfide.",
                    "score": 0.8367620706558228
                },
                {
                    "id": 12961877,
                    "contents": "Mercury(IV) fluoride\nHg + 2 F2 → HgF4 HgF4 is only stable in matrix isolation at ; upon heating, or if the HgF4 molecules touch each other, it decomposes to mercury(II) fluoride and fluorine: HgF4 → HgF2 + F2 HgF4 is a diamagnetic, square planar molecule. The mercury atom has a formal 6s25d86p6 electron configuration, and as such obeys the octet rule but not the 18-electron rule. HgF4 is isoelectronic with the tetrafluoroaurate anion, , and is valence isoelectronic with the tetrachloroaurate (), tetrabromoaurate (), and tetrachloroplatinate () anions. References Mercury compounds Fluorides Metal halides Hypothetical chemical compounds Substances discovered in the 2000s",
                    "score": 0.8364602327346802
                },
                {
                    "id": 5489418,
                    "contents": "Millimetre of mercury\nHistory For much of human history, the pressure of gasses like air was ignored, denied, or taken for granted, but as early as the 6th century BC, Greek philosopher Anaximenes of Miletus claimed that all things are made of air that is simply changed by varying levels of pressure. He could observe water evaporating, changing to a gas, and felt that this applied even to solid matter. More condensed air made colder, heavier objects, and expanded air made lighter, hotter objects. This was akin to how gasses really do become less dense when warmer, more dense when cooler.",
                    "score": 0.8353220224380493
                },
                {
                    "id": 17656645,
                    "contents": "Enthalpy of fusion\nThe enthalpy of fusion of a substance, also known as (latent) heat of fusion is the change in its enthalpy resulting from providing energy, typically heat, to a specific quantity of the substance to change its state from a solid to a liquid, at constant pressure. For example, when melting 1 kg of ice (at 0 °C under a wide range of pressures), 333.55 kJ of energy is absorbed with no temperature change. The heat of solidification (when a substance changes from liquid to solid) is equal and opposite. This energy includes the contribution required to make room for any associated change in volume by displacing its environment against ambient pressure. The temperature at which the phase transition occurs is the melting point or the freezing point, according to context. By convention, the pressure is assumed to be unless otherwise specified.",
                    "score": 0.8349436521530151
                },
                {
                    "id": 16561942,
                    "contents": "Mercury (element)\nBeing a soft metal, mercury forms very stable derivatives with the heavier chalcogens. Preeminent is mercury(II) sulfide, HgS, which occurs in nature as the ore cinnabar and is the brilliant pigment vermillion. Like ZnS, HgS crystallizes in two forms, the reddish cubic form and the black zinc blende form. The latter sometimes occurs naturally as metacinnabar. Mercury(II) selenide (HgSe) and mercury(II) telluride (HgTe) are also known, these as well as various derivatives, e.g. mercury cadmium telluride and mercury zinc telluride being semiconductors useful as infrared detector materials. Mercury(II) salts form a variety of complex derivatives with ammonia. These include Millon's base (Hg2N+), the one-dimensional polymer (salts of )), and \"fusible white precipitate\" or [Hg(NH3)2]Cl2. Known as Nessler's reagent, potassium tetraiodomercurate(II) () is still occasionally used to test for ammonia owing to its tendency to form the deeply colored iodide salt of Millon's base.",
                    "score": 0.8348928093910217
                },
                {
                    "id": 5853284,
                    "contents": "Heats of fusion of the elements (data page)\nHeat of fusion Notes Values refer to the enthalpy change between the liquid phase and the most stable solid phase at the melting point (normal, 101.325 kPa). References CRC As quoted from various sources in an online version of: David R. Lide (ed), CRC Handbook of Chemistry and Physics, 84th Edition. CRC Press. Boca Raton, Florida, 2003; Section 6, Fluid Properties; Enthalpy of Fusion LNG As quoted from various sources in: J.A. Dean (ed), Lange's Handbook of Chemistry (15th Edition), McGraw-Hill, 1999; Section 6, Thermodynamic Properties; Table 6.4, Heats of Fusion, Vaporization, and Sublimation and Specific Heat at Various Temperatures of the Elements and Inorganic Compounds",
                    "score": 0.8346951603889465
                },
                {
                    "id": 17656646,
                    "contents": "Enthalpy of fusion\nOverview The 'enthalpy' of fusion is a latent heat, because, while melting, the heat energy needed to change the substance from solid to liquid at atmospheric pressure is latent heat of fusion, as the temperature remains constant during the process. The latent heat of fusion is the enthalpy change of any amount of substance when it melts. When the heat of fusion is referenced to a unit of mass, it is usually called the specific heat of fusion, while the molar heat of fusion refers to the enthalpy change per amount of substance in moles. The liquid phase has a higher internal energy than the solid phase. This means energy must be supplied to a solid in order to melt it and energy is released from a liquid when it freezes, because the molecules in the liquid experience weaker intermolecular forces and so have a higher potential energy (a kind of bond-dissociation energy for intermolecular forces).",
                    "score": 0.8342849612236023
                },
                {
                    "id": 16561941,
                    "contents": "Mercury (element)\nIndicative of its tendency to bond to itself, mercury forms mercury polycations, which consist of linear chains of mercury centers, capped with a positive charge. One example is . Compounds of mercury(II) Mercury(II) is the most common oxidation state and is the main one in nature as well. All four mercuric halides are known. They form tetrahedral complexes with other ligands but the halides adopt linear coordination geometry, somewhat like Ag+ does. Best known is mercury(II) chloride, an easily sublimating white solid. HgCl2 forms coordination complexes that are typically tetrahedral, e.g. . Mercury(II) oxide, the main oxide of mercury, arises when the metal is exposed to air for long periods at elevated temperatures. It reverts to the elements upon heating near 400 °C, as was demonstrated by Joseph Priestley in an early synthesis of pure oxygen. Hydroxides of mercury are poorly characterized, as they are for its neighbors gold and silver.",
                    "score": 0.8341447710990906
                },
                {
                    "id": 21538834,
                    "contents": "Mercury(I) hydride\nChemical properties Mercury(I) hydride is an unstable gas and is the heaviest group 12 monohydride. n mercury(I) hydride, the formal oxidation states of hydrogen and mercury are −1 and +1, respectively, because of the electronegativity of mercury is lower than that of hydrogen. The stability of the diatomic metal hydrides with the formula MH (M = Zn-Hg) increases as the atomic number of M increases. The Hg-H bond is very weak and therefore the compound has only been matrix isolated at temperatures up to 6 K. The dihydride, HgH2, has also been detected this way. A related compound is dimercurane(2), or bis(hydridomercury)(Hg—Hg), with the formula , which can be considered to be dimeric mercury(I) hydride. It spontaneously decomposes into the monomeric form.",
                    "score": 0.8339863419532776
                },
                {
                    "id": 1221572,
                    "contents": "Sodium\nThe melting (98 °C) and boiling (883 °C) points of sodium are lower than those of lithium but higher than those of the heavier alkali metals potassium, rubidium, and caesium, following periodic trends down the group. These properties change dramatically at elevated pressures: at 1.5 Mbar, the color changes from silvery metallic to black; at 1.9 Mbar the material becomes transparent with a red color; and at 3 Mbar, sodium is a clear and transparent solid. All of these high-pressure allotropes are insulators and electrides. In a flame test, sodium and its compounds glow yellow because the excited 3s electrons of sodium emit a photon when they fall from 3p to 3s; the wavelength of this photon corresponds to the D line at about 589.3 nm. Spin-orbit interactions involving the electron in the 3p orbital split the D line into two, at 589.0 and 589.6 nm; hyperfine structures involving both orbitals cause many more lines. Isotopes",
                    "score": 0.8335339426994324
                },
                {
                    "id": 1280684,
                    "contents": "Triple point\nIn thermodynamics, the triple point of a substance is the temperature and pressure at which the three phases (gas, liquid, and solid) of that substance coexist in thermodynamic equilibrium. It is that temperature and pressure at which the sublimation curve, fusion curve and the vaporisation curve meet. For example, the triple point of mercury occurs at a temperature of and a pressure of 0.165 mPa. In addition to the triple point for solid, liquid, and gas phases, a triple point may involve more than one solid phase, for substances with multiple polymorphs. Helium-4 is a special case that presents a triple point involving two different fluid phases (lambda point).",
                    "score": 0.8326493501663208
                },
                {
                    "id": 11305170,
                    "contents": "Hermann Lux\nAchievements Discovered a method of quantitative determination of 1 ppm quantities of mercury (1931, together with Alfred Stock) Extensively studied chemical reactions in molten salts, leading up to the Lux-Flood acid-base theory (1937) Invented the \"hanging melt\" method which made it possible to study extremely aggressive molten salt systems, such as alkali oxides. Investigated salts of metals in unusual oxidation states, such as bivalent chromium or pentavalent manganese. Published a number of books including \"Anorganisch-chemische Experimentierkunst\" (Inorganic-chemical experimental art) and \"Praktikum der quantitativen anorganischen Analyse\" (Practical course of the quantitative inorganic analysis) which were translated into many languages and used by many analytic chemists. References External links Books by Hermann Lux on amazon.de",
                    "score": 0.8311560153961182
                },
                {
                    "id": 1121121,
                    "contents": "Melting\nLow-temperature helium is the only known exception to the general rule. Helium-3 has a negative enthalpy of fusion at temperatures below 0.3 K. Helium-4 also has a very slightly negative enthalpy of fusion below 0.8 K. This means that, at appropriate constant pressures, heat must be removed from these substances in order to melt them. Criteria Among the theoretical criteria for melting, the Lindemann and Born criteria are those most frequently used as a basis to analyse the melting conditions.",
                    "score": 0.8309706449508667
                },
                {
                    "id": 18141098,
                    "contents": "Mercury(II) hydroxide\nMercury(II) hydroxide or mercuric hydroxide is the metal hydroxide with the chemical formula Hg(OH)2. The compound has not been isolated in pure form, although it has been the subject of several studies. Attempts to isolate Hg(OH)2 yield yellow solid HgO. The solid has produced it by irradiating a frozen mixture of mercury, oxygen and hydrogen. The mixture had been produced by evaporating mercury atoms at 50 °C into a gas consisting of neon, argon or deuterium (in separate experiments) plus 2 to 8% hydrogen and 0.2 to 2.0% oxygen. The mixture was then condensed at 5 kelvins onto a caesium iodide window, through which it could be irradiated. References Mercury(II) compounds Hydroxides",
                    "score": 0.8308321237564087
                },
                {
                    "id": 2408938,
                    "contents": "Mercury-in-glass thermometer\nTo define his scale Celsius used two fixed temperature points: the temperature of melting ice and the temperature of boiling water, both under atmospheric pressure of the standard atmosphere. This wasn't a new idea, since Isaac Newton was already working on something similar. The distinction of Celsius was to use the condition of melting and not that of freezing. The experiments for reaching a good calibration of his thermometer lasted for 2 winters. By performing the same experiment over and over again, he discovered that ice always melted at the same calibration mark on the thermometer. He found a similar fixed point in the calibration of boiling water to water vapour (when this is done to high precision, a variation will be seen with atmospheric pressure; Celsius noted this). At the moment that he removed the thermometer from the vapour, the mercury level climbed slightly. This was related to the rapid cooling (and contraction) of the glass.",
                    "score": 0.8301835060119629
                },
                {
                    "id": 20575861,
                    "contents": "Mercury(II) hydride\nProperties Structure In solid mercury(II) hydride, the HgH2 molecules are connected by mercurophilic bonds. Trimers and a lesser proportion of dimers are detected in the vapour. Unlike solid zinc(II), and cadmium(II) hydride, which are network solids, solid mercury(II) hydride is a covalently bound molecular solid. This is due to relativistic effects, which also accounts for the relatively low decomposition temperature of -125 °C. The HgH2 molecule is linear and symmetric in the form H-Hg-H. The bond length is 1.646543 Å. The antisymmetric stretching frequency, ν3 of the bond is 1912.8 cm−1, 57.34473 THz for isotopes 202Hg and 1H. The energy needed to break the Hg-H bond in HgH2 is 70 kcal/mol. The second bond in the resulting HgH is much weaker only needing 8.6 kcal/mol to break. Reacting two hydrogen atoms releases 103.3 kcal/mol, and so HgH2 formation from hydrogen molecules and Hg gas is endothermic at 24.2 kcal/mol.",
                    "score": 0.8299638628959656
                },
                {
                    "id": 1753394,
                    "contents": "Helium\nLiquid helium Unlike any other element, helium will remain liquid down to absolute zero at normal pressures. This is a direct effect of quantum mechanics: specifically, the zero point energy of the system is too high to allow freezing. Solid helium requires a temperature of 1–1.5 K (about −272 °C or −457 °F) at about 25 bar (2.5 MPa) of pressure. It is often hard to distinguish solid from liquid helium since the refractive index of the two phases are nearly the same. The solid has a sharp melting point and has a crystalline structure, but it is highly compressible; applying pressure in a laboratory can decrease its volume by more than 30%. With a bulk modulus of about 27 MPa it is ~100 times more compressible than water. Solid helium has a density of at 1.15 K and 66 atm; the projected density at 0 K and 25 bar (2.5 MPa) is . At higher temperatures, helium will solidify with sufficient pressure. At room temperature, this requires about 114,000 atm.",
                    "score": 0.8298052549362183
                },
                {
                    "id": 905506,
                    "contents": "Thermodynamic temperature\nAs stated above, the thermal energy required for a phase transition is called latent heat. In the specific cases of melting and freezing, it's called enthalpy of fusion or heat of fusion. If the molecular bonds in a crystal lattice are strong, the heat of fusion can be relatively great, typically in the range of 6 to 30 kJ per mole for water and most of the metallic elements. If the substance is one of the monatomic gases, (which have little tendency to form molecular bonds) the heat of fusion is more modest, ranging from 0.021 to 2.3 kJ per mole. Relatively speaking, phase transitions can be truly energetic events. To completely melt ice at 0 °C into water at 0 °C, one must add roughly 80 times the thermal energy as is required to increase the temperature of the same mass of liquid water by one degree Celsius. The metals' ratios are even greater, typically in the range of 400 to 1200 times. And the phase transition of boiling is much more energetic than freezing. For instance, the",
                    "score": 0.8296524286270142
                },
                {
                    "id": 1121119,
                    "contents": "Melting\nMelting, or fusion, is a physical process that results in the phase transition of a substance from a solid to a liquid. This occurs when the internal energy of the solid increases, typically by the application of heat or pressure, which increases the substance's temperature to the melting point. At the melting point, the ordering of ions or molecules in the solid breaks down to a less ordered state, and the solid \"melts\" to become a liquid. Substances in the molten state generally have reduced viscosity as the temperature increases. An exception to this principle is the element sulfur, whose viscosity increases in the range of 160 °C to 180 °C due to polymerization. Some organic compounds melt through mesophases, states of partial order between solid and liquid.",
                    "score": 0.8288396596908569
                },
                {
                    "id": 8509933,
                    "contents": "Mercury(II) iodide\nMercury(II) iodide is a chemical compound with the molecular formula HgI2. It is typically produced synthetically but can also be found in nature as the extremely rare mineral coccinite. Unlike the related mercury(II) chloride it is hardly soluble in water (<100 ppm). Production Mercury(II) iodide is produced by adding an aqueous solution of potassium iodide to an aqueous solution of mercury(II) chloride with stirring; the precipitate is filtered off, washed and dried at 70 °C. HgCl2 + 2 KI → HgI2 + 2 KCl",
                    "score": 0.8271506428718567
                },
                {
                    "id": 2408940,
                    "contents": "Mercury-in-glass thermometer\nThese points are adequate for approximate calibration, but both the freezing and boiling points of water vary with atmospheric pressure. Later thermometers that used a liquid other than mercury also gave slightly different temperature readings. In practice, these variations were very slight and remained close to the thermodynamic temperature, once the latter was discovered. These issues were explored experimentally with the gas thermometer. Until the discovery of true thermodynamic temperature, the mercury thermometer usually defined the temperature. Modern thermometers are often calibrated using the triple point of water instead of the freezing point; the triple point occurs at 273.16 kelvins (K), 0.01 °C. Maximum thermometer",
                    "score": 0.826323390007019
                },
                {
                    "id": 23071987,
                    "contents": "Torricelli's experiment\nConclusion Torricelli concluded that the mercury fluid in the tube is aided by the atmospheric pressure that is present on the surface of mercury fluid on the dish. He also stated that the changes of liquid level from day to day are caused by the variation of atmospheric pressure. The empty space in the tube is called the Torricellian vacuum. 760 mmHg = 1 atm 1 atm = 1 013 mbar or hPa 1 mbar or hPa = 0.7502467 mmHg 1 pascal = 1 Newton per square metre (SI unit) 1 hectapascal is 100 pascals Additional images References 1643 in science Science and technology in Italy Physics experiments Pressure",
                    "score": 0.8260490298271179
                },
                {
                    "id": 6704729,
                    "contents": "History of thermodynamics\nTo prove this theory, he filled a long glass tube (sealed at one end) with mercury and upended it into a dish also containing mercury. Only a portion of the tube emptied; ~30 inches of the liquid remained. As the mercury emptied, and a partial vacuum was created at the top of the tube. The gravitational force on the heavy element Mercury prevented it from filling the vacuum. Transition from chemistry to thermochemistry The theory of phlogiston arose in the 17th century, late in the period of alchemy. Its replacement by caloric theory in the 18th century is one of the historical markers of the transition from alchemy to chemistry. Phlogiston was a hypothetical substance that was presumed to be liberated from combustible substances during burning, and from metals during the process of rusting. Caloric, like phlogiston, was also presumed to be the \"substance\" of heat that would flow from a hotter body to a cooler body, thus warming it.",
                    "score": 0.8258265256881714
                },
                {
                    "id": 5688606,
                    "contents": "Mercury(II) oxide\nMercury(II) oxide, also called mercuric oxide or simply mercury oxide, has a formula of HgO. It has a red or orange color. Mercury(II) oxide is a solid at room temperature and pressure. The mineral form montroydite is very rarely found. History In 1774, Joseph Priestley discovered that oxygen was released by heating mercuric oxide, although he did not identify the gas as oxygen (rather, Priestley called it \"dephlogisticated air,\" as that was the paradigm that he was working under at the time). Synthesis The red form of HgO can be made by heating Hg in oxygen at roughly 350 °C, or by pyrolysis of Hg(NO3)2. The yellow form can be obtained by precipitation of aqueous Hg2+ with alkali. The difference in color is due to particle size, both forms have the same structure consisting of near linear O-Hg-O units linked in zigzag chains with an Hg-O-Hg angle of 108°.",
                    "score": 0.8256908655166626
                },
                {
                    "id": 1628626,
                    "contents": "Condensed matter physics\nIn 1823, Michael Faraday, then an assistant in Davy's lab, successfully liquefied chlorine and went on to liquefy all known gaseous elements, except for nitrogen, hydrogen, and oxygen. Shortly after, in 1869, Irish chemist Thomas Andrews studied the phase transition from a liquid to a gas and coined the term critical point to describe the condition where a gas and a liquid were indistinguishable as phases, and Dutch physicist Johannes van der Waals supplied the theoretical framework which allowed the prediction of critical behavior based on measurements at much higher temperatures. By 1908, James Dewar and Heike Kamerlingh Onnes were successfully able to liquefy hydrogen and then newly discovered helium, respectively.",
                    "score": 0.8253769874572754
                },
                {
                    "id": 16561940,
                    "contents": "Mercury (element)\nCompounds of mercury(I) Unlike its lighter neighbors, cadmium and zinc, mercury usually forms simple stable compounds with metal-metal bonds. Most mercury(I) compounds are diamagnetic and feature the dimeric cation, Hg. Stable derivatives include the chloride and nitrate. Treatment of Hg(I) compounds complexation with strong ligands such as sulfide, cyanide, etc. induces disproportionation to and elemental mercury. Mercury(I) chloride, a colorless solid also known as calomel, is really the compound with the formula Hg2Cl2, with the connectivity Cl-Hg-Hg-Cl. It is a standard in electrochemistry. It reacts with chlorine to give mercuric chloride, which resists further oxidation. Mercury(I) hydride, a colorless gas, has the formula HgH, containing no Hg-Hg bond. Indicative of its tendency to bond to itself, mercury forms mercury polycations, which consist of linear chains of mercury centers, capped with a positive charge. One example is .",
                    "score": 0.8252044916152954
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_4",
        "question": "Suppose a nanostructure is modelled by an electron confined to a rectangular region with sides of lengths $L_1=1.0 \\mathrm{~nm}$ and $L_2=2.0 \\mathrm{~nm}$ and is subjected to thermal motion with a typical energy equal to $k T$, where $k$ is Boltzmann's constant. How low should the temperature be for the thermal energy to be comparable to the zero-point energy？",
        "golden_answers": [
            " 5.5"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 16372444,
                    "contents": "List of software for nanostructures modeling\nThis is a list of computer programs that are used to model nanostructures at the levels of classical mechanics and quantum mechanics.",
                    "score": 0.8872227072715759
                },
                {
                    "id": 13547888,
                    "contents": "Nanomechanics\nQuantum effects also determine novel electrical, optical and chemical properties of nanostructures, and therefore they find even greater attention in adjacent areas of nanoscience and nanotechnology, such as nanoelectronics, advanced energy systems, and nanobiotechnology. See also Molecular machine Geometric phase (section Stochastic Pump Effect) Nanoelectromechanical relay References Sattler KD. Handbook of Nanophysics: Vol. 1 Principles and Methods. CRC Press, 2011. Bhushan B (editor). Springer Handbook of Nanotechnology, 2nd edition. Springer, 2007. Liu WK, Karpov EG, Park HS. Nano Mechanics and Materials: Theory, Multiscale Methods and Applications. Wiley, 2006. Cleland AN. Foundations of Nanomechanics. Springer, 2003. Nanotechnology ja:ナノマシン",
                    "score": 0.8825871348381042
                },
                {
                    "id": 10967575,
                    "contents": "Nanoscopic scale\nThe nanoscopic scale is sometimes marked as the point where the properties of a material change; above this point, the properties of a material are caused by 'bulk' or 'volume' effects, namely which atoms are present, how they are bonded, and in what ratios. Below this point, the properties of a material change, and while the type of atoms present and their relative orientations are still important, 'surface area effects' (also referred to as quantum effects) become more apparent – these effects are due to the geometry of the material (how thick it is, how wide it is, etc.), which, at these low dimensions, can have a drastic effect on quantized states, and thus the properties of a material.",
                    "score": 0.8765015006065369
                },
                {
                    "id": 1135423,
                    "contents": "Nanotechnology\nSeveral phenomena become pronounced as the size of the system decreases. These include statistical mechanical effects, as well as quantum mechanical effects, for example the \"quantum size effect\" where the electronic properties of solids are altered with great reductions in particle size. This effect does not come into play by going from macro to micro dimensions. However, quantum effects can become significant when the nanometer size range is reached, typically at distances of 100 nanometers or less, the so-called quantum realm. Additionally, a number of physical (mechanical, electrical, optical, etc.) properties change when compared to macroscopic systems. One example is the increase in surface area to volume ratio altering mechanical, thermal and catalytic properties of materials. Diffusion and reactions at nanoscale, nanostructures materials and nanodevices with fast ion transport are generally referred to nanoionics. Mechanical properties of nanosystems are of interest in the",
                    "score": 0.8747692108154297
                },
                {
                    "id": 19131119,
                    "contents": "Michael Roukes\nAfter earning his Ph.D., Roukes spent seven years as a Member of Technical Staff / Principal Investigator in the Quantum Structures Research group at Bell Communications Research in New Jersey, focusing on mesoscopic physics of electron transport in nanostructures. Roukes left Bellcore to become a tenured Associate Professor of Physics at Caltech in 1992, rising to full professorship in 1995, and subsequently became Professor of Physics, Applied Physics, and Bioengineering in 2000. Upon moving to Caltech, his principal research focus changed to nanoelectromechanical systems (NEMS). As the earliest pioneer in this field, DARPA engaged Roukes to organize the first international workshop on NEMS in 1999, followed by a large international conference and school on nanoscale and molecular mechanics in 2002. The many alumni from his group continue to advance this field at major universities in the U.S. and abroad. Roukes' other research efforts at Caltech have focused on thermal",
                    "score": 0.8740174770355225
                },
                {
                    "id": 5726452,
                    "contents": "Nanostructure\nA nanostructure is a structure of intermediate size between microscopic and molecular structures. Nanostructural detail is microstructure at nanoscale. In describing nanostructures, it is necessary to differentiate between the number of dimensions in the volume of an object which are on the nanoscale. Nanotextured surfaces have one dimension on the nanoscale, i.e., only the thickness of the surface of an object is between 0.1 and 100 nm. Nanotubes have two dimensions on the nanoscale, i.e., the diameter of the tube is between 0.1 and 100 nm; its length can be far more. Finally, spherical nanoparticles have three dimensions on the nanoscale, i.e., the particle is between 0.1 and 100 nm in each spatial dimension. The terms nanoparticles and ultrafine particles (UFP) are often used synonymously although UFP can reach into the micrometre range. The term nanostructure is often used when referring to magnetic technology. Nanoscale structure in biology is often called ultrastructure.",
                    "score": 0.873347818851471
                },
                {
                    "id": 13547884,
                    "contents": "Nanomechanics\nThese principles serve to provide a basic insight into novel mechanical properties of nanometer objects. Novelty is understood in the sense that these properties are not present in similar macroscale objects or much different from the properties of those (e.g., nanorods vs. usual macroscopic beam structures). In particular, smallness of the subject itself gives rise to various surface effects determined by higher surface-to-volume ratio of nanostructures, and thus affects mechanoenergetic and thermal properties (melting point, heat capacitance, etc.) of nanostructures. Discreteness serves a fundamental reason, for instance, for the dispersion of mechanical waves in solids, and some special behavior of basic elastomechanics solutions at small scales. Plurality of degrees of freedom and the rise of thermal fluctuations are the reasons for thermal tunneling of nanoparticles through potential barriers, as well as for the cross-diffusion of liquids and solids. Smallness and thermal",
                    "score": 0.8727716207504272
                },
                {
                    "id": 16225522,
                    "contents": "Thermodynamics of nanostructures\nDepending on the nanostructure size, the phonon mean free path values (Λ) may be comparable or larger than the object size, . When is larger than the phonon mean free path, Umklapp scattering process limits thermal conductivity (regime of diffusive thermal conductivity). When is comparable to or smaller than the mean free path (which is of the order 1 µm for carbon nanostructures), the continuous energy model used for bulk materials no longer applies and nonlocal and nonequilibrium aspects to heat transfer also need to be considered. In this case phonons in defectless structure could propagate without scattering and thermal conductivity becomes ballistic (similar to ballistic conductivity). More severe changes in thermal behavior are observed when the feature size shrinks further down to the wavelength of phonons. Nanowires",
                    "score": 0.869605541229248
                },
                {
                    "id": 3415863,
                    "contents": "Density of states\nSee also References Further reading Chen, Gang. Nanoscale Energy Transport and Conversion. New York: Oxford, 2005 Streetman, Ben G. and Sanjay Banerjee. Solid State Electronic Devices. Upper Saddle River, NJ: Prentice Hall, 2000. Muller, Richard S. and Theodore I. Kamins. Device Electronics for Integrated Circuits. New York: John Wiley and Sons, 2003. Kittel, Charles and Herbert Kroemer. Thermal Physics. New York: W.H. Freeman and Company, 1980 Sze, Simon M. Physics of Semiconductor Devices. New York: John Wiley and Sons, 1981 External links Online lecture:ECE 606 Lecture 8: Density of States by M. Alam Scientists shed light on glowing materials How to measure the Photonic LDOS Statistical mechanics Physical quantities Electronic band structures",
                    "score": 0.8695160746574402
                },
                {
                    "id": 1863306,
                    "contents": "Materials science\nNanostructure Materials, which atoms and molecules form constituents in the nanoscale (i.e., they form nanostructure) are called nanomaterials. Nanomaterials are subject of intense research in the materials science community due to the unique properties that they exhibit. Nanostructure deals with objects and structures that are in the 1 - 100 nm range. In many materials, atoms or molecules agglomerate together to form objects at the nanoscale. This causes many interesting electrical, magnetic, optical, and mechanical properties. In describing nanostructures, it is necessary to differentiate between the number of dimensions on the nanoscale. Nanotextured surfaces have one dimension on the nanoscale, i.e., only the thickness of the surface of an object is between 0.1 and 100 nm. Nanotubes have two dimensions on the nanoscale, i.e., the diameter of the tube is between 0.1 and 100 nm; its length could be much greater.",
                    "score": 0.8691438436508179
                },
                {
                    "id": 12291722,
                    "contents": "Nanometrology\nAt nanoscale due to the small dimensions various new physical phenomena can be observed. For example, when the crystal size is smaller than the electron mean free path the conductivity of the crystal changes. Another example is the discretization of stresses in the system. It becomes important to measure the physical parameters so as to apply these phenomena into engineering of nanosystems and manufacturing them. The measurement of length or size, force, mass, electrical and other properties is included in Nanometrology.",
                    "score": 0.8675522804260254
                },
                {
                    "id": 24099959,
                    "contents": "ISSPIC\nThe main theme of the first couple of ISSPIC symposiums was fundamental studies on the finite-size effects of atomic and molecular clusters. The discussion emphasized the physical aspects. At the beginning the conference was organized every fourth year but since 1988 it was held every two years. The conference has become a fundamental event on the area of the nanoscience and the research of nanoclusters during the last decades. Conference topics Scientists, such as chemists, physicists and nanotechnogists, who do the research on the area of atomic or molecular clusters and structures, nanoparticles and nanostructures, introduce and discuss about the latest results and scientific achievements in the ISSPIC conference. The discussion also provides new approaches into these topics.",
                    "score": 0.8659483194351196
                },
                {
                    "id": 16225535,
                    "contents": "Thermodynamics of nanostructures\nThermal conductivity is of particular interest in low-dimensional systems. For CNT, represented as 1-D ballistic electronic channel, the electronic conductance is quantized, with a universal value of Similarly, for a single ballistic 1-D channel, the thermal conductance is independent of materials parameters, and there exists a quantum of thermal conductance, which is linear in temperature: Possible conditions for observation of this quantum were examined by Rego and Kirczenow. In 1999, Keith Schwab, Erik Henriksen, John Worlock, and Michael Roukes carried out a series of experimental measurements that enabled first observation of the thermal conductance quantum. The measurements employed suspended nanostructures coupled to sensitive dc SQUID measurement devices. In 2008, a colorized electron micrograph of one of the Caltech devices was acquired for the permanent collection of the Museum of Modern Art in New York.",
                    "score": 0.8652094006538391
                },
                {
                    "id": 12291747,
                    "contents": "Nanometrology\nD = 6/(ρ*A) Where \"D\" is the effective diameter, \"ρ\" is the density and \"A\" is the surface area found from the B.E.T. method. See also Characterization of nanoparticles References General references Nanotechnology Metrology",
                    "score": 0.8649576902389526
                },
                {
                    "id": 26613396,
                    "contents": "Dresselhaus effect\nWhen treating 2D nanostructures where the width direction or [001] is finite, the Dresselhaus Hamiltonian can be separated into a linear and a cubic term. The linear Dresselhaus Hamiltonian is usually written as where is a coupling constant. The cubic Dresselhaus term is written as where is the width of the material. The Hamiltonian is generally derived using a combination of the k·p perturbation theory alongside the Kane model. See also Fine electronic structure Electric dipole spin resonance Spin–orbit interaction References Semiconductors Quantum magnetism Spintronics",
                    "score": 0.8646583557128906
                },
                {
                    "id": 24099958,
                    "contents": "ISSPIC\nISSPIC or International Symposium on Small Particles and Inorganic Clusters is an established biennial conference series on fundamental science of atomically small particles, organized since 1976. The conference topics typically include atomic and molecular clusters and their assemblies, supported and free-standing Nanostructures and -particles, and other nanometer-scale systems. History and development The first ISSPIC conference was held in 1976 in Lyon. The idea to organize an international meeting of scientists who research the nanomolecular and atomic structures was given by pioneers in nanophysics such as Jean Farges, Jacques Friedel, Walter Knight, Ryogo Kubo, and Bernhardt Mühlschlegel. Friedel was also the chairman of the first conference.",
                    "score": 0.8645439147949219
                },
                {
                    "id": 3564665,
                    "contents": "Potential well\nQuantum mechanics view The electronic and optical properties of materials are affected by size and shape. Well-established technical achievements including quantum dots were derived from size manipulation and investigation for their theoretical corroboration on quantum confinement effect. The major part of the theory is the behaviour of the exciton resembles that of an atom as its surrounding space shortens. A rather good approximation of an exciton's behaviour is the 3-D model of a particle in a box. The solution of this problem provides a sole mathematical connection between energy states and the dimension of space. Decreasing the volume or the dimensions of the available space, increases the energy of the states. Shown in the diagram is the change in electron energy level and bandgap between nanomaterial and its bulk state. The following equation shows the relationship between energy level and dimension spacing:",
                    "score": 0.8643633723258972
                },
                {
                    "id": 4153359,
                    "contents": "Nanoelectromechanical systems\nHistory Background As noted by Richard Feynman in his famous talk in 1959, \"There's Plenty of Room at the Bottom,\" there are many potential applications of machines at smaller and smaller sizes; by building and controlling devices at smaller scales, all technology benefits. The expected benefits include greater efficiencies and reduced size, decreased power consumption and lower costs of production in electromechanical systems.",
                    "score": 0.8636614084243774
                },
                {
                    "id": 13547881,
                    "contents": "Nanomechanics\nNanomechanics is a branch of nanoscience studying fundamental mechanical (elastic, thermal and kinetic) properties of physical systems at the nanometer scale. Nanomechanics has emerged on the crossroads of biophysics, classical mechanics, solid-state physics, statistical mechanics, materials science, and quantum chemistry. As an area of nanoscience, nanomechanics provides a scientific foundation of nanotechnology. Nanomechanics is that branch of nanoscience which deals with the study and application of fundamental mechanical properties of physical systems at the nanoscale, such as elastic, thermal and kinetic material properties.",
                    "score": 0.8634682893753052
                },
                {
                    "id": 27473660,
                    "contents": "Christian Schönenberger\nHe then joined the Philips Research Laboratories at Eindhoven in the Netherlands as a postdoctoral fellow and later as a permanent staff member. In 1995 he was appointed full professor (of experimental physics) at the University of Basel, where he heads the Nanoelectronics Group and is currently directing the Swiss Nanoscience Institute and the Swiss-NSF center on Nanoscale Science and Technology. Research After his early work on magnetic force microscopy, Schönenberger then used different force microscopy techniques to study single charges and, in particular, single electron tunneling. He studied electron transport in quantum wires and shot noise and noise reduction in electron transport. Subsequently, he and his group studied transport in increasingly smaller natural and engineered nanoscale devices operating in the quantum regime. These include quasi one-dimensional objects such as quantum wires, carbon nanotubes, and DNA-molecules or two-dimensional graphene.",
                    "score": 0.863251268863678
                },
                {
                    "id": 23021814,
                    "contents": "Nanocluster\nSize and number of atoms in metal nanoclusters According to the Japanese mathematical physicist Ryogo Kubo, the spacing of energy levels can be predicted by where EF is Fermi energy and N is the number of atoms. For quantum confinement 𝛿 can be estimated to be equal to the thermal energy (), where k is Boltzmann's constant and T is temperature. Stability",
                    "score": 0.863243818283081
                },
                {
                    "id": 15697808,
                    "contents": "Laboratory of Nano and Quantum Engineering\nNano engineering is the engineering on the nanoscale, i.e., the selective artificial fabrication of nanotechnology structures such as tiny transistors on computer chips. With nano engineering the closely related term quantum engineering aims to produce and manipulate a defined quantum state, such as the realization of a Bose-Einstein condensate or an electronic device with adjusted electron spin. The size of such systems is also often in the nanometer range. Nanomaterials of various shapes, composition and size in the nanometer range are produced and analyzed in the laboratory. Nanoparticles have due to their small size special chemical and physical properties that differ significantly from the properties of macroscopic particles and solids. The cause therefore is the large ratio of surface to volume of the nanoparticles, so that they strongly interact with their environment. Added where appropriate quantum mechanical effects.",
                    "score": 0.8631545901298523
                },
                {
                    "id": 25859293,
                    "contents": "Mark Eriksson\nMark Alan Eriksson is an American experimental physicist, focusing on experimental studies of nanostructures, especially nanoscale electronic systems, quantum computing; semiconductor membranes, many-body physics and interacting electrons in low-dimensional systems; application of nanoelectronics to biology, currently the John Bardeen Professor of Physics at University of Wisconsin and was elected a fellow of the American Association for the Advancement of Science in 2015. He was also elected a fellow of the American Physical Society. Education Eriksson received a masters and doctorate in physics at Harvard University in 1994 and 1997, respectively. He completed a bachelor's degree in mathematics and physics at the University of Wisconsin at Madison in 1992. References External links",
                    "score": 0.8622709512710571
                },
                {
                    "id": 16149208,
                    "contents": "Walter de Heer\nResearch De Heer and his research groups have made significant contributions to several important areas in nanoscopic physics. As a graduate student at UC-Berkeley, he participated in groundbreaking research on alkali metal clusters that demonstrated the electronic shell structure of metal clusters. This is a property of small metal clusters composed of few atoms that develop atom-like electronic properties (these clusters are also referred to as superatoms). In Switzerland, he developed methods of measuring the magnetic properties of cold metal clusters and described how magnetism develops in these clusters as their size increases from atomic to bulk. He is the author of the most highly cited review articles on metallic clusters.",
                    "score": 0.8602124452590942
                },
                {
                    "id": 10158505,
                    "contents": "Shubnikov–de Haas effect\nTheory Consider a two-dimensional quantum gas of electrons confined in a sample with given width and with edges. In the presence of a magnetic flux density B, the energy eigenvalues of this system are described by Landau levels. As shown in Fig 1, these levels are equidistant along the vertical axis. Each energy level is substantially flat inside a sample (see Fig 1). At the edges of a sample, the work function bends levels upwards. Fig 1 shows the Fermi energy EF located in between two Landau levels. Electrons become mobile as their energy levels cross the Fermi energy EF. With the Fermi energy EF in between two Landau levels, scattering of electrons will occur only at the edges of a sample where the levels are bent. The corresponding electron states are commonly referred to as edge channels.",
                    "score": 0.8601765036582947
                },
                {
                    "id": 10967579,
                    "contents": "Nanoscopic scale\nSee also Center for Probing the Nanoscale Center for Nanoscale Materials Nanomachines Nanomedicine References Condensed matter physics Nanotechnology",
                    "score": 0.8596094846725464
                },
                {
                    "id": 29455819,
                    "contents": "Supriyo Bandyopadhyay\nBibliography Books Physics of Nanostructured Solid State Devices (2012) ISBN 9781461411406 Introduction to Spintronics, Second edition (2015) ISBN 9781482255577 Problem Solving in Quantum Mechanics: From Basics to Real World Applications for Materials Scientists, Applied Physicists and Device Engineers (2017) ISBN 9781118988756",
                    "score": 0.8587177991867065
                },
                {
                    "id": 19776753,
                    "contents": "International Society for Nanoscale Science, Computation, and Engineering\nThe International Society for Nanoscale Science, Computation, and Engineering (ISNSCE, pronounced like \"essence\") is a scientific society specializing in nanotechnology and DNA computing. It was started in 2004 by Nadrian Seeman, founder of the field of DNA nanotechnology. According to the society, its purpose is \"to promote the study of the control of the arrangement of the atoms in matter, examine the principles that lead to such control, to develop tools and methods to increase such control, and to investigate the use of these principles for molecular computation, and for engineering on the finest possible scales.\"",
                    "score": 0.8574663400650024
                },
                {
                    "id": 13547886,
                    "contents": "Nanomechanics\nQuantum effects determine forces of interaction between individual atoms in physical objects, which are introduced in nanomechanics by means of some averaged mathematical models called interatomic potentials.",
                    "score": 0.8568083047866821
                },
                {
                    "id": 5715670,
                    "contents": "Nanocrystal\nA nanocrystal is a material particle having at least one dimension smaller than 100 nanometres, based on quantum dots (a nanoparticle) and composed of atoms in either a single- or poly-crystalline arrangement. The size of nanocrystals distinguishes them from larger crystals. For example, silicon nanocrystals can provide efficient light emission while bulk silicon does not and may be used for memory components. When embedded in solids, nanocrystals may exhibit much more complex melting behaviour than conventional solids and may form the basis of a special class of solids. They can behave as single-domain systems (a volume within the system having the same atomic or molecular arrangement throughout) that can help explain the behaviour of macroscopic samples of a similar material without the complicating presence of grain boundaries and other defects. Semiconductor nanocrystals having dimensions smaller than 10 nm are also described as quantum dots.",
                    "score": 0.8566393256187439
                },
                {
                    "id": 23687462,
                    "contents": "Jean-Pierre Leburton\nJean-Pierre Leburton (, Liège, Belgium-) is the Gregory E. Stillman Professor of Electrical and Computer Engineering and professor of Physics at the University of Illinois at Urbana–Champaign. He is also a full-time faculty member in the Nanoelectronics and Nanomaterials group of the Beckman Institute for Advanced Science and Technology. He is known for his work on semiconductor theory and simulation, and on nanoscale quantum devices including quantum wires, quantum dots, and quantum wells. He studies and develops nanoscale materials with potential electronic and biological applications. Early life and education Jean-Pierre Leburton was born on to Edmond Jules Leburton and Charlotte (Joniaux) Leburton in Liège, Belgium. His father, at one time Prime Minister of Belgium, sparked Jean-Pierre Leburton's interest in physics. Jean-Pierre Leburton received his Licence (B.Sc.) in Physics in 1971 and his Doctorat (Ph.D.) in 1978 from the University of Liège, Belgium.",
                    "score": 0.8566009998321533
                },
                {
                    "id": 9755495,
                    "contents": "Mesoscopic physics\nIn addition, quantum confinement effects consist of isolated islands of electrons that may be formed at the patterned interface between two different semiconducting materials. The electrons typically are confined to disk-shaped regions termed quantum dots. The confinement of the electrons in these systems changes their interaction with electromagnetic radiation significantly, as noted above. Because the electron energy levels of quantum dots are discrete rather than continuous, the addition or subtraction of just a few atoms to the quantum dot has the effect of altering the boundaries of the bandgap. Changing the geometry of the surface of the quantum dot also changes the bandgap energy, owing again to the small size of the dot, and the effects of quantum confinement.",
                    "score": 0.8560971021652222
                },
                {
                    "id": 16225534,
                    "contents": "Thermodynamics of nanostructures\nwhere C is the specific heat, and vz and are the group velocity and relaxation time of a given phonon state. At low temperatures (T is far less than Debye temperature), the relaxation time is determined by scattering of fixed impurities, defects, sample boundaries, etc. and is roughly constant. Therefore, in ordinary materials, the low-temperature thermal conductivity has the same temperature dependence as the specific heat. However, in anisotropic materials, this relationship does not strictly hold. Because the contribution of each state is weighted by the scattering time and the square of the velocity, the thermal conductivity preferentially samples states with large velocity and scattering time. For instance, in graphite, the thermal conductivity parallel to the basal planes is only weakly dependent on the interlayer phonons. In SWNT bundles, it is likely that k(T) depends only on the on-tube phonons, rather than the intertube modes.",
                    "score": 0.8558735251426697
                },
                {
                    "id": 1628627,
                    "contents": "Condensed matter physics\nPaul Drude in 1900 proposed the first theoretical model for a classical electron moving through a metallic solid. Drude's model described properties of metals in terms of a gas of free electrons, and was the first microscopic model to explain empirical observations such as the Wiedemann–Franz law. However, despite the success of Drude's free electron model, it had one notable problem: it was unable to correctly explain the electronic contribution to the specific heat and magnetic properties of metals, and the temperature dependence of resistivity at low temperatures.",
                    "score": 0.8550350069999695
                },
                {
                    "id": 28161443,
                    "contents": "Nanolattice\nAt the nanoscale, size effects and different dimensional constraints, like grain boundaries, dislocations, and distribution of voids, can tremendously change the properties of a material. Nanolattices possess unparalleled mechanical properties. Nanolattices are the strongest existing cellular materials despite being extremely light-weight. Though consisting of 50%-99% air, nanolattice can be as strong as steel. Its effective strength can reach up to 1 GPa. On the order of 50nm, the extremely small volume of their individual members, such as walls, nodes, and trusses, thereby statistically nearly eliminates the material flaw population and the base material of nanolattices can reach mechanical strengths on the order of the theoretical strength of an ideal, perfect crystal. While such effects are typically limited to individual, geometrically primitive structures like nanowires, the specific architecture allows nanolattices to exploit them in complex, three-dimensional structures of",
                    "score": 0.8547797203063965
                },
                {
                    "id": 16225533,
                    "contents": "Thermodynamics of nanostructures\nIn general, the thermal conductivity is a tensor quality, but for this discussion, it is only important to consider the diagonal elements: where C is the specific heat, and vz and are the group velocity and relaxation time of a given phonon state.",
                    "score": 0.8543478846549988
                },
                {
                    "id": 3840605,
                    "contents": "Nanomaterials\nin a liquid. Nanoparticles often have unexpected visual properties because they are small enough to confine their electrons and produce quantum effects. For example, gold nanoparticles appear deep red to black in solution.",
                    "score": 0.8541427850723267
                },
                {
                    "id": 10733355,
                    "contents": "Walther Kossel\nReferences Borisenko, Victor E. and Stefano Ossicini What is What in the Nanoworld: A Handbook on Nanoscience and Nanotechnology(Wiley-VCH, 2004) Cao, Gouzhong Nanostructures and Nanomaterials: Synthesis, Properties, and Applications (Imperial College Press, 2004) Gerhard Herzberg translated from German with the help of the author by J. W. T. Spinks Atomic Spectra and Atomic Structure (Dover, 1945) Mehra, Jagdish, and Helmut Rechenberg The Historical Development of Quantum Theory. Volume 1 Part 2 The Quantum Theory of Planck, Einstein, Bohr and Sommerfeld 1900 – 1925: Its Foundation and the Rise of Its Difficulties. (Springer, 2001) Mehra, Jagdish, and Helmut Rechenberg The Historical Development of Quantum Theory. Volume 5 Erwin Schrödinger and the Rise of Wave Mechanics. Part 2 Schrödinger in Vienna and Zurich 1887-1925. (Springer, 2001)",
                    "score": 0.8540647625923157
                },
                {
                    "id": 9755489,
                    "contents": "Mesoscopic physics\nMesoscopic physics is a subdiscipline of condensed matter physics that deals with materials of an intermediate size. These materials range in size between the nanoscale for a quantity of atoms (such as a molecule) and of materials measuring micrometres. The lower limit can also be defined as being the size of individual atoms. At the micrometre level are bulk materials. Both mesoscopic and macroscopic objects contain many atoms. Whereas average properties derived from constituent materials describe macroscopic objects, as they usually obey the laws of classical mechanics, a mesoscopic object, by contrast, is affected by thermal fluctuations around the average, and its electronic behavior may require modeling at the level of quantum mechanics.",
                    "score": 0.8538107872009277
                },
                {
                    "id": 12504098,
                    "contents": "David J. Smith (physicist)\nSelected publications Alone \"The realization of atomic resolution with the electron microscope\", Reports Progress Phys. 60, 1513–1580 (1997). \"Progress and perspectives for atomic-resolution electron microscopy\", Ultramicroscopy 108, 159–166 (2008). \"Development of aberration-corrected electron microscopy\", Microsc. Microanal. 14, 2–15 (2008). \"Ultimate resolution in the electron microscope?\", Materials Today 11 (Supp), 30–38 (2008). Collaborations McCartney, M.R., Dunin-Borkowski, R.E., Scheinfein, M.R., Smith, D.J., Gider, S. and Parkin, S.S., \"Origin of magnetization decay in spin-independent tunnel junctions\", Science 286, 1337–1340 (1999). Floyd, M., Zhang, Y., Drucker, J., Smith, D.J., Tari, S. and Sivananthan, S. \"Evolution of self-assembled Ge/Si (211) islands\", Appl. Phys. Lett. 79, 4518–4520 (2001). McCartney, M.R. and Smith, D.J., \"Electron holography: phase imaging with nanometer resolution\", Annu. Rev. Mater. Res. 37, 729–767 (2007).",
                    "score": 0.8535774350166321
                },
                {
                    "id": 19761751,
                    "contents": "Gerhard Klimeck\nBooks Computational Electronics: Semiclassical and Quantum Device Modeling and Simulation (2010) CRC Press, Honors and awards Klimeck won 9 NASA Tech Briefs from 2004–2007 2008, Purdue Engineering Team Award shared with Mark S. Lundstrom and Michael McLennan 2011, Gordon Bell Prize Competition Finalist Klimeck and physicist Michelle Simmons of the University of New South Wales \"devised a way to make a single-atom transistor\", which ranked #29 top invention of 2013 by Discover Magazine Selected works Learning and research in the cloud A single-atom transistor Ohm's Law Survives to the Atomic Scale nanoHUB.org: Advancing Education and Research in Nanotechnology Development of a Nanoelectronic 3-D (NEMO 3-D) Simulator for Multimillion Atom Simulations and Its Application to Alloyed Quantum Dots (INVITED) Quantum Device Simulation with a Generalized Tunneling Formula Conductance Spectroscopy in Coupled Quantum Dots References",
                    "score": 0.8535128235816956
                },
                {
                    "id": 15997942,
                    "contents": "Alex Zunger\nZunger’s research field is the condensed matter theory of real materials. He developed pseudopotentials for first-principles electronic structure calculations within the framework of density functional theory (1977), co-developed the momentum-space total-energy method (1978), co-developed what is now the most widely used exchange and correlation energy functional and the self-interaction correction (1981), and developed a novel theoretical method for simultaneous relaxation of atomic positions and charge densities in self-consistent local-density approximation calculations (1983). Recently he developed novel methods for calculating the electronic properties of semiconductor quantum nanostructures. These atomistic methods have enabled Zunger and his team to discover a range of many-body effects underlying the fundamental physics of the creation, multiplication, and annihilation of excitons.",
                    "score": 0.8525462746620178
                },
                {
                    "id": 28836653,
                    "contents": "Stephanie Reich\nStephanie Reich is a German physicist and Professor at the Free University of Berlin. Her research considers the physics of nanostructures, which she studies using experimental characterisation techniques and computational simulations. Early life and education Reich attended the Technical University of Berlin where she studied physics. She earned her undergraduate and master's diplomas in 1998, before embarking on a doctoral programme. After a year as a research assistant, Reich moved to the Institut de Ciència de Materials de Barcelona. In 2002 she was made a Fellow of the Berlin-Brandenburg Academy of Sciences and Humanities.",
                    "score": 0.8525204658508301
                },
                {
                    "id": 8365990,
                    "contents": "Low-energy electron diffraction\nHere d is the penetration depth, and denotes the inelastic mean free path, defined as the distance an electron can travel before its intensity has decreased by the factor 1/e. While the inelastic scattering processes and consequently the electronic mean free path depend on the energy, it is relatively independent of the material. The mean free path turns out to be minimal (5–10 Å) in the energy range of low-energy electrons (20–200 eV). This effective attenuation means that only a few atomic layers are sampled by the electron beam, and, as a consequence, the contribution of deeper atoms to the diffraction progressively decreases. Kinematic theory: single scattering Kinematic diffraction is defined as the situation where electrons impinging on a well-ordered crystal surface are elastically scattered only once by that surface. In the theory the electron beam is represented by a plane wave with a wavelength given by the de Broglie hypothesis:",
                    "score": 0.8519684076309204
                },
                {
                    "id": 18623945,
                    "contents": "Quantum nanoscience\nCoherence Quantum nanoscience explores and uses coherent quantum effects in engineered nanostructures. Coherence is the property of a quantum system that allows to predict its evolution in time, once it has been prepared in a superposition of different quantum states. This property is important when one intends to use the system for specific tasks, such as performing a sequence of logic operations in a quantum computer. Quantum coherence is fragile and can easily be lost if the system becomes too large or is subjected to uncontrolled interactions with the environment. Quantum coherence-enabled functionality holds the promise of making possible disruptive technologies such as quantum computing, quantum communication, quantum simulation, and quantum sensing. Coherent quantum effects at the nanoscale are relatively uncharted territory. Therefore, the field of quantum nanoscience is special among basic sciences because it provides a pathway into this frontier of human knowledge.",
                    "score": 0.851584792137146
                },
                {
                    "id": 11126341,
                    "contents": "Marvin L. Cohen\nIn the area of nanostructures, it was shown that the methods used for calculating bulk and surfaces properties were applicable for studies of nanoscale materials such as C60, nanotubes, and other low dimensional structures. These studies led to the successful prediction of the existence the BN nanotube and its properties. Seminal studies were done explaining and predicting properties of graphene nanoribbons and their energy gaps, and the properties of layered systems of graphene and BN sheets were calculated suggesting a path for fabrication of useful electronic materials. The first theoretical and experimental studies of the electronic and vibrational properties of one-dimensional isolated chains were done, and the underlying physics was determined for controlling the size and shape of 2D nanopores with applications for DNA sequencing, sieving, and quantum emission. Another nanoscience contribution was an important study of the physics of metallic clusters using electronic energies",
                    "score": 0.8514513969421387
                },
                {
                    "id": 29096811,
                    "contents": "Atom localization\nApplications The study of atom localization has offered practical applications to the area of nanolithography at the Heisenberg limit along with its fundamental importance to the areas of atom optics, and laser cooling and trapping of neutral atoms. Extending the atom localization schemes to two dimensions, optical lattices with tighter than usual confinement at each lattice point can be obtained. Such strongly confined lattice structures could be useful to study several predictions of the Bloch theory of solids, and Mott transitions in much cleaner systems as compared to conventional solids. Such tighter trapping potentials could have further applications to the area of quantum information specifically for the development of deterministic sources of single atoms and single-atom quantum register. Techniques of atom localization are also important to the subwavelength microscopy and imaging and determination of the center-of-mass wavefunction of atom-like entities. Footnotes",
                    "score": 0.8514325022697449
                },
                {
                    "id": 13547885,
                    "contents": "Nanomechanics\nand the rise of thermal fluctuations are the reasons for thermal tunneling of nanoparticles through potential barriers, as well as for the cross-diffusion of liquids and solids. Smallness and thermal fluctuations provide the basic reasons of the Brownian motion of nanoparticles. Increased importance of thermal fluctuations and configuration entropy at the nanoscale give rise to superelasticity, entropic elasticity (entropic forces), and other exotic types of elasticity of nanostructures. Aspects of configuration entropy are also of great interest in the context self-organization and cooperative behavior of open nanosystems.",
                    "score": 0.8511013984680176
                },
                {
                    "id": 9755494,
                    "contents": "Mesoscopic physics\nThe quantum confinement effect can be observed once the diameter of the particle is of the same magnitude as the wavelength of the electron's wave function. When materials are this small, their electronic and optical properties deviate substantially from those of bulk materials. As the material is miniaturized towards nano-scale the confining dimension naturally decreases. The characteristics are no longer averaged by bulk, and hence continuous, but are at the level of quanta and thus discrete. In other words, the energy spectrum becomes discrete, measured as quanta, rather than continuous as in bulk materials. As a result, the bandgap asserts itself: there is a small and finite separation between energy levels. This situation of discrete energy levels is called quantum confinement.",
                    "score": 0.8507225513458252
                },
                {
                    "id": 11198071,
                    "contents": "Mark Reed (physicist)\nMark Arthur Reed (January 4, 1955 - May 5, 2021) was an American physicist and professor at Yale University. He coined the term quantum dots, for demonstrating the first zero-dimensional electronic device that had fully quantized energy states. Reed does research in electronic transport in nanoscale and mesoscopic systems, artificially structured materials and devices, molecular electronics, biosensors and bioelectronic systems, and nanofluidics. He is the author of more than 200 publications, has given over 75 plenary and over 400 invited talks, and holds 33 U.S. and foreign patents on quantum effect, heterojunction, and molecular devices. He was the Editor in Chief of the journal Nanotechnology (2009-2019), is the present Editor in Chief of the journal Nano Futures, and holds numerous other editorial and advisory board positions. He died on May 5, 2021.",
                    "score": 0.850477933883667
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_5",
        "question": "Calculate the change in Gibbs energy of $35 \\mathrm{~g}$ of ethanol (mass density $0.789 \\mathrm{~g} \\mathrm{~cm}^{-3}$ ) when the pressure is increased isothermally from 1 atm to 3000 atm.",
        "golden_answers": [
            " 12"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 17353901,
                    "contents": "Antoine equation\nUnits The coefficients of Antoine's equation are normally given in mmHg—even today where the SI is recommended and pascals are preferred. The usage of the pre-SI units has only historic reasons and originates directly from Antoine's original publication. It is however easy to convert the parameters to different pressure and temperature units. For switching from degrees Celsius to kelvin it is sufficient to subtract 273.15 from the C parameter. For switching from millimeters of mercury to pascals it is sufficient to add the common logarithm of the factor between both units to the A parameter: The parameters for °C and mmHg for ethanol A, 8.20417 B, 1642.89 C, 230.300 are converted for K and Pa to A, 10.32907 B, 1642.89 C, −42.85 The first example calculation with TB = 351.47 K becomes A similarly simple transformation can be used if the common logarithm should be exchanged by the natural logarithm. It is sufficient to multiply the A and B parameters by ln(10) = 2.302585.",
                    "score": 0.8569267988204956
                },
                {
                    "id": 4977473,
                    "contents": "Equilibrium constant\nwhere ΔrGo is the reaction standard Gibbs energy, which is the sum of the standard Gibbs energies of the reaction products minus the sum of standard Gibbs energies of reactants. Here, the term \"standard\" denotes the ideal behaviour (i.e., an infinite dilution) and a hypothetical standard concentration (typically 1 mol/kg). It does not imply any particular temperature or pressure because, although contrary to IUPAC recommendation, it is more convenient when describing aqueous systems over wide temperature and pressure ranges. The standard Gibbs energy (for each species or for the entire reaction) can be represented (from the basic definitions) as: In the above equation, the effect of temperature on Gibbs energy (and thus on the equilibrium constant) is ascribed entirely to heat capacity. To evaluate the integrals in this equation, the form of the dependence of heat capacity on temperature needs to be known.",
                    "score": 0.8436915874481201
                },
                {
                    "id": 1878789,
                    "contents": "Gibbs free energy\nEach quantity in the equations above can be divided by the amount of substance, measured in moles, to form molar Gibbs free energy. The Gibbs free energy is one of the most important thermodynamic functions for the characterization of a system. It is a factor in determining outcomes such as the voltage of an electrochemical cell, and the equilibrium constant for a reversible reaction. In isothermal, isobaric systems, Gibbs free energy can be thought of as a \"dynamic\" quantity, in that it is a representative measure of the competing effects of the enthalpic and entropic driving forces involved in a thermodynamic process. The temperature dependence of the Gibbs energy for an ideal gas is given by the Gibbs–Helmholtz equation, and its pressure dependence is given by or more conveniently as its chemical potential: In non-ideal systems, fugacity comes into play.",
                    "score": 0.8421351909637451
                },
                {
                    "id": 6025677,
                    "contents": "Ethanol (data page)\nThis page provides supplementary chemical data on ethanol. Material Safety Data Sheet External MSDS Structure and properties Thermodynamic properties Spectral data Vapor pressure of liquid Density of ethanol at various temperatures Data obtained from These data correlate as ρ [g/cm3] = −8.461834 T [°C] + 0.8063372 with an R2 = 0.99999. Properties of aqueous ethanol solutions Data obtained from Boiling points of aqueous solutions Data obtained from CRC Handbook of Chemistry (Page 2117) ‡Azeotropic mixture Charts References Chemical data pages Data page Chemical data pages cleanup",
                    "score": 0.8337934017181396
                },
                {
                    "id": 1879026,
                    "contents": "Henry's law\nFor a water-ethanol mixture, the interaction parameter a13 has values around for ethanol concentrations (volume/volume) between 5% and 25% . Miscellaneous In geochemistry In geochemistry, a version of Henry's law applies to the solubility of a noble gas in contact with silicate melt. One equation used is where C is the number concentrations of the solute gas in the melt and gas phases, β = 1/kBT, an inverse temperature parameter (kB is the Boltzmann constant), µE is the excess chemical potentials of the solute gas in the two phases. Comparison to Raoult's law Henry's law is a limiting law that only applies for \"sufficiently dilute\" solutions, while Raoult's law is generally valid when the liquid phase is almost pure or for mixtures of similar substances. The range of concentrations in which Henry's law applies becomes narrower the more the system diverges from ideal behavior. Roughly speaking, that is the more chemically \"different\" the solute is from the solvent.",
                    "score": 0.8322056531906128
                },
                {
                    "id": 1878795,
                    "contents": "Gibbs free energy\nwhich relates the cell potential resulting from the reaction to the equilibrium constant and reaction quotient for that reaction (Nernst equation), where , Gibbs free energy change per mole of reaction, , Gibbs free energy change per mole of reaction for unmixed reactants and products at standard conditions (i.e. 298K, 100kPa, 1M of each reactant and product), , gas constant, , absolute temperature, , natural logarithm, , reaction quotient (unitless), , equilibrium constant (unitless), , electrical work in a reversible process (chemistry sign convention), , moles of electrons transferred in the reaction, , Faraday constant (charge per mole of electrons), , cell potential, , standard cell potential. Moreover, we also have: which relates the equilibrium constant with Gibbs free energy. This implies that at equilibrium and Standard energy change of formation",
                    "score": 0.8288283348083496
                },
                {
                    "id": 1704121,
                    "contents": "Ethanol\nIn 1796, German-Russian chemist Johann Tobias Lowitz obtained pure ethanol by mixing partially purified ethanol (the alcohol-water azeotrope) with an excess of anhydrous alkali and then distilling the mixture over low heat. French chemist Antoine Lavoisier described ethanol as a compound of carbon, hydrogen, and oxygen, and in 1807 Nicolas-Théodore de Saussure determined ethanol's chemical formula. Fifty years later, Archibald Scott Couper published the structural formula of ethanol. It was one of the first structural formulas determined.",
                    "score": 0.8276551961898804
                },
                {
                    "id": 1878779,
                    "contents": "Gibbs free energy\nA quantitative measure of the favorability of a given reaction at constant temperature and pressure is the change ΔG (sometimes written \"delta G\" or \"dG\") in Gibbs free energy that is (or would be) caused by the reaction. As a necessary condition for the reaction to occur at constant temperature and pressure, ΔG must be smaller than the non-pressure-volume (non-PV, e.g. electrical) work, which is often equal to zero (hence ΔG must be negative). ΔG equals the maximum amount of non-PV work that can be performed as a result of the chemical reaction for the case of reversible process. If analysis indicates a positive ΔG for a reaction, then energy — in the form of electrical or other non-PV work — would have to be added to the reacting system for ΔG to be smaller than the non-PV work and make it possible for the reaction to occur.",
                    "score": 0.8266335129737854
                },
                {
                    "id": 16022597,
                    "contents": "Apparent molar property\nSee also Volume fraction Ideal solution Regular solution Enthalpy change of solution Enthalpy of mixing Block design Heat of dilution Hydration energy Ion transport number Solvation shell Partial molar property Excess molar quantity Salting in Ternary plot Thermodynamic activity References External links Apparent Molar Properties: Solutions: Background The (p,ρ,T) Properties and Apparent Molar Volumes of ethanol solutions of LiI or ZnCl2 Apparent molar volumes and apparent molar heat capacities of Pr(NO3)3(aq), Gd(NO3)3(aq), Ho(NO3)3(aq), and Y(NO3)3(aq) at T = (288.15, 298.15, 313.15, and 328.15) K and p = 0.1 MPa Isotopic effects for electrolytes apparent properties Physical chemistry Thermodynamic properties",
                    "score": 0.8245484232902527
                },
                {
                    "id": 8119587,
                    "contents": "Volume fraction\nIn the case of a mixture of ethanol and water, which are miscible in all proportions, the designation of solvent and solute is arbitrary. The volume of such a mixture is slightly less than the sum of the volumes of the components. Thus, by the above definition, the term \"40% alcohol by volume\" refers to a mixture of 40 volume units of ethanol with enough water to make a final volume of 100 units, rather than a mixture of 40 units of ethanol with 60 units of water. See also Alcohol by volume Alcohol meter Alcohol proof Apparent molar property For non-ideal mixtures, see Partial molar volume and Excess molar quantity Percentage References Dimensionless numbers of chemistry Physical chemistry Thermodynamics Analytical chemistry",
                    "score": 0.8236944079399109
                },
                {
                    "id": 1704108,
                    "contents": "Ethanol\nOther techniques A variety of other techniques have been discussed, including the following: Salting using potassium carbonate to exploit its insolubility will cause a phase separation with ethanol and water. This offers a very small potassium carbonate impurity to the alcohol that can be removed by distillation. This method is very useful in purification of ethanol by distillation, as ethanol forms an azeotrope with water. Direct electrochemical reduction of carbon dioxide to ethanol under ambient conditions using copper nanoparticles on a carbon nanospike film as the catalyst; Extraction of ethanol from grain mash by supercritical carbon dioxide; Pervaporation; Fractional freezing is also used to concentrate fermented alcoholic solutions, such as traditionally made Applejack (beverage); Pressure swing adsorption. Grades of ethanol Denatured alcohol",
                    "score": 0.8222708106040955
                },
                {
                    "id": 5464637,
                    "contents": "Strain (chemistry)\nEnthalpy and entropy are related to Gibbs free energy through the equation (at a constant temperature):",
                    "score": 0.8194688558578491
                },
                {
                    "id": 1377672,
                    "contents": "Josiah Willard Gibbs\nInfluence Gibbs's most immediate and obvious influence was on physical chemistry and statistical mechanics, two disciplines which he greatly helped to found. During Gibbs's lifetime, his phase rule was experimentally validated by Dutch chemist H. W. Bakhuis Roozeboom, who showed how to apply it in a variety of situations, thereby assuring it of widespread use. In industrial chemistry, Gibbs's thermodynamics found many applications during the early 20th century, from electrochemistry to the development of the Haber process for the synthesis of ammonia.",
                    "score": 0.8192598223686218
                },
                {
                    "id": 9865639,
                    "contents": "Energy conversion efficiency\nChemical conversion efficiency The change of Gibbs energy of a defined chemical transformation at a particular temperature is the minimum theoretical quantity of energy required to make that change occur (if the change in Gibbs energy between reactants and products is positive) or the maximum theoretical energy that might be obtained from that change (if the change in Gibbs energy between reactants and products is negative). The energy efficiency of a process involving chemical change may be expressed relative to these theoretical minima or maxima.The difference between the change of enthalpy and the change of Gibbs energy of a chemical transformation at a particular temperature indicates the heat input required or the heat removal (cooling) required to maintain that temperature.",
                    "score": 0.818189799785614
                },
                {
                    "id": 1878796,
                    "contents": "Gibbs free energy\nMoreover, we also have: which relates the equilibrium constant with Gibbs free energy. This implies that at equilibrium and Standard energy change of formation The standard Gibbs free energy of formation of a compound is the change of Gibbs free energy that accompanies the formation of 1 mole of that substance from its component elements, at their standard states (the most stable form of the element at 25 °C and 100 kPa). Its symbol is ΔfG˚. All elements in their standard states (diatomic oxygen gas, graphite, etc.) have standard Gibbs free energy change of formation equal to zero, as there is no change involved. ΔfG = ΔfG˚ + RT ln Qf, where Qf is the reaction quotient. At equilibrium, ΔfG = 0, and Qf = K, so the equation becomes ΔfG˚ = −RT ln K, where K is the equilibrium constant.",
                    "score": 0.8178116679191589
                },
                {
                    "id": 1878777,
                    "contents": "Gibbs free energy\nThe Gibbs energy (symbol ) is also the thermodynamic potential that is minimized when a system reaches chemical equilibrium at constant pressure and temperature. Its derivative with respect to the reaction coordinate of the system vanishes at the equilibrium point. As such, a reduction in is necessary for a reaction to be spontaneous at constant pressure and temperature. The Gibbs free energy, originally called available energy, was developed in the 1870s by the American scientist Josiah Willard Gibbs. In 1873, Gibbs described this \"available energy\" as The initial state of the body, according to Gibbs, is supposed to be such that \"the body can be made to pass from it to states of dissipated energy by reversible processes\". In his 1876 magnum opus On the Equilibrium of Heterogeneous Substances, a graphical analysis of multi-phase chemical systems, he engaged his thoughts on chemical-free energy in full.",
                    "score": 0.8167691230773926
                },
                {
                    "id": 1878792,
                    "contents": "Gibbs free energy\nand the infinitesimal change in G is: The second law of thermodynamics states that for a closed system, and so it follows that: This means that for a system which is not in equilibrium, its Gibbs energy will always be decreasing, and when it is in equilibrium (i.e. no longer changing), the infinitesimal change dG will be zero. In particular, this will be true if the system is experiencing any number of internal chemical reactions on its path to equilibrium. In electrochemical thermodynamics When electric charge dQ is passed in an electrochemical cell the emf ℰ yields a thermodynamic work term that appears in the expression for the change in Gibbs energy: where G is the Gibbs' free energy, S is the entropy, V is the system volume, P is its pressure and T is its absolute temperature.",
                    "score": 0.8159896731376648
                },
                {
                    "id": 18252936,
                    "contents": "Gibbs–Thomson equation\nAs early as 1886, Robert von Helmholtz (son of the German physicist Hermann von Helmholtz) had observed that finely dispersed liquids have a higher vapor pressure. By 1906, the German physical chemist Friedrich Wilhelm Küster (1861–1917) had predicted that since the vapor pressure of a finely pulverized volatile solid is greater than the vapor pressure of the bulk solid, then the melting point of the fine powder should be lower than that of the bulk solid. Investigators such as the Russian physical chemists Pavel Nikolaevich Pavlov (or Pawlow (in German), 1872–1953) and Peter Petrovich von Weymarn (1879–1935), among others, searched for and eventually observed such melting point depression. By 1932, Czech investigator Paul Kubelka (1900–1956) had observed that the melting point of iodine in activated charcoal is depressed as much as 100 °C. Investigators recognized that the melting point depression occurred when the change in surface energy was significant compared to the latent",
                    "score": 0.8158809542655945
                },
                {
                    "id": 17353900,
                    "contents": "Antoine equation\nExample parameters Example calculation The normal boiling point of ethanol is TB = 78.32 °C. (760mmHg = 101.325kPa = 1.000atm = normal pressure) This example shows a severe problem caused by using two different sets of coefficients. The described vapor pressure is not continuous—at the normal boiling point the two sets give different results. This causes severe problems for computational techniques which rely on a continuous vapor pressure curve. Two solutions are possible: The first approach uses a single Antoine parameter set over a larger temperature range and accepts the increased deviation between calculated and real vapor pressures. A variant of this single set approach is using a special parameter set fitted for the examined temperature range. The second solution is switching to another vapor pressure equation with more than three parameters. Commonly used are simple extensions of the Antoine equation (see below) and the equations of DIPPR or Wagner.",
                    "score": 0.8152514696121216
                },
                {
                    "id": 13157514,
                    "contents": "Everclear\nAlcohol content Ethanol cannot be concentrated by ordinary distillation to greater than 97.2% by volume (95.6% by weight), because at that concentration, the vapor has the same ratio of water to alcohol as the liquid, a phenomenon known as azeotropy. The 190-proof variation of Everclear is 92.4% ethanol by weight and is thus produced at approximately the practical limit of distillation purity. Some U.S. states impose limits on maximum alcohol content, or have other restrictions that prohibit the sale of the 190-proof variation of Everclear, and several of those also effectively prohibit lower-proof Everclear.",
                    "score": 0.814015805721283
                },
                {
                    "id": 1562151,
                    "contents": "Alcohol (chemistry)\nBecause of hydrogen bonding, alcohols tend to have higher boiling points than comparable hydrocarbons and ethers. The boiling point of the alcohol ethanol is 78.29 °C, compared to 69 °C for the hydrocarbon hexane, and 34.6 °C for diethyl ether. Occurrence in nature Simple alcohols are found widely in nature. Ethanol is the most prominent because it is the product of fermentation, a major energy-producing pathway. Other simple alcohols, chiefly fusel alcohols, are formed in only trace amounts. More complex alcohols however are pervasive, as manifested in sugars, some amino acids, and fatty acids. Production Ziegler and oxo processes In the Ziegler process, linear alcohols are produced from ethylene and triethylaluminium followed by oxidation and hydrolysis. An idealized synthesis of 1-octanol is shown: The process generates a range of alcohols that are separated by distillation.",
                    "score": 0.8131553530693054
                },
                {
                    "id": 462772,
                    "contents": "Gibbs–Helmholtz equation\nThe Gibbs–Helmholtz equation is a thermodynamic equation used for calculating changes in the Gibbs energy of a system as a function of temperature. It is named after Josiah Willard Gibbs and Hermann von Helmholtz. The equation is: where H is the enthalpy, T the absolute temperature and G the Gibbs free energy of the system, all at constant pressure p. The equation states that the change in the G/T ratio at constant pressure as a result of an infinitesimally small change in temperature is a factor H/T2. Chemical reactions The typical applications are to chemical reactions. The equation reads: with ΔG as the change in Gibbs energy and ΔH as the enthalpy change (considered independent of temperature). The o denotes standard pressure (1 bar). Integrating with respect to T (again p is constant) it becomes:",
                    "score": 0.812673807144165
                },
                {
                    "id": 1377686,
                    "contents": "Josiah Willard Gibbs\nKenneth R. Jolls, a professor of chemical engineering at Iowa State University and an expert on graphical methods in thermodynamics, consulted on the design of the stamp honoring Gibbs. The stamp identifies Gibbs as a \"thermodynamicist\" and features a diagram from the 4th edition of Maxwell's Theory of Heat, published in 1875, which illustrates Gibbs's thermodynamic surface for water. Microprinting on the collar of Gibbs's portrait depicts his original mathematical equation for the change in the energy of a substance in terms of its entropy and the other state variables. Outline of principal work Physical chemistry: free energy, phase diagram, phase rule, transport phenomena Statistical mechanics: statistical ensemble, phase space, chemical potential, Gibbs entropy, Gibbs paradox Mathematics: Vector Analysis, convex analysis, Gibbs phenomenon Electromagnetism: Maxwell's equations, birefringence",
                    "score": 0.8122014999389648
                },
                {
                    "id": 1039016,
                    "contents": "Volumetric heat capacity\nFor most liquids, the volumetric heat capacity is narrower, for example octane at 1.64 MJ⋅K−1⋅m−3 or ethanol at 1.9. This reflects the modest loss of degrees of freedom for particles in liquids as compared with solids. However, water has a very high volumetric heat capacity, at 4.18 MJ⋅K−1⋅m−3, and ammonia is also fairly high: 3.3 MJ⋅K−1⋅m−3.",
                    "score": 0.8121747970581055
                },
                {
                    "id": 1878793,
                    "contents": "Gibbs free energy\nwhere G is the Gibbs' free energy, S is the entropy, V is the system volume, P is its pressure and T is its absolute temperature. The combination (ℰ, Q) is an example of a conjugate pair of variables. At constant pressure the above relationship produces a Maxwell relation that links the change in open cell voltage with temperature T (a measurable quantity) to the change in entropy S when charge is passed isothermally and isobarically. The latter is closely related to the reaction entropy of the electrochemical reaction that lends the battery its power. This Maxwell relation is: If a mole of ions goes into solution (for example, in a Daniell cell, as discussed below) the charge through the external circuit is: where n0 is the number of electrons/ion, and F0 is the Faraday constant and the minus sign indicates discharge of the cell. Assuming constant pressure and volume, the thermodynamic properties of the cell are related strictly to the behavior of its emf by:",
                    "score": 0.8120020627975464
                },
                {
                    "id": 1704094,
                    "contents": "Ethanol\nEthanol's miscibility with water contrasts with the immiscibility of longer-chain alcohols (five or more carbon atoms), whose water miscibility decreases sharply as the number of carbons increases. The miscibility of ethanol with alkanes is limited to alkanes up to undecane: mixtures with dodecane and higher alkanes show a miscibility gap below a certain temperature (about 13 °C for dodecane). The miscibility gap tends to get wider with higher alkanes, and the temperature for complete miscibility increases. Ethanol-water mixtures have less volume than the sum of their individual components at the given fractions. Mixing equal volumes of ethanol and water results in only 1.92 volumes of mixture. Mixing ethanol and water is exothermic, with up to 777 J/mol being released at 298 K.",
                    "score": 0.8114928603172302
                },
                {
                    "id": 1878797,
                    "contents": "Gibbs free energy\nGraphical interpretation by Gibbs Gibbs free energy was originally defined graphically. In 1873, American scientist Willard Gibbs published his first thermodynamics paper, \"Graphical Methods in the Thermodynamics of Fluids\", in which Gibbs used the two coordinates of the entropy and volume to represent the state of the body. In his second follow-up paper, \"A Method of Geometrical Representation of the Thermodynamic Properties of Substances by Means of Surfaces\", published later that year, Gibbs added in the third coordinate of the energy of the body, defined on three figures. In 1874, Scottish physicist James Clerk Maxwell used Gibbs' figures to make a 3D energy-entropy-volume thermodynamic surface of a fictitious water-like substance. Thus, in order to understand the concept of Gibbs free energy, it may help to understand its interpretation by Gibbs as section AB on his figure 3, and as Maxwell sculpted that section on his 3D surface figure.",
                    "score": 0.8107444047927856
                },
                {
                    "id": 1878798,
                    "contents": "Gibbs free energy\nSee also Bioenergetics Calphad (CALculation of PHAse Diagrams) Critical point (thermodynamics) Electron equivalent Enthalpy-entropy compensation Free entropy Gibbs–Helmholtz equation Grand potential Non-random two-liquid model (NRTL model) – Gibbs energy of excess and mixing calculation and activity coeffients Spinodal – Spinodal Curves (Hessian matrix) Standard molar entropy Thermodynamic free energy UNIQUAC model – Gibbs energy of excess and mixing calculation and activity coeffients Notes and references",
                    "score": 0.8106510639190674
                },
                {
                    "id": 3553141,
                    "contents": "Ethanol fuel\nDuring combustion, ethanol reacts with oxygen to produce carbon dioxide, water, and heat: C2H5OH + 3 O2 → 2 CO2 + 3 H2O + heat Starch and cellulose molecules are strings of glucose molecules. It is also possible to generate ethanol out of cellulosic materials. That, however, requires a pretreatment that splits the cellulose into glucose molecules and other sugars that subsequently can be fermented. The resulting product is called cellulosic ethanol, indicating its source. Ethanol is also produced industrially from ethylene by hydration of the double bond in the presence of a catalyst and high temperature. C2H4 + H2O → C2H5OH Most ethanol is produced by fermentation. Sources",
                    "score": 0.8106140494346619
                },
                {
                    "id": 8936815,
                    "contents": "Extent of reaction\nThe extent of a reaction is generally defined as zero at the beginning of the reaction. Thus the change of is the extent itself. Assuming that the system has come to equilibrium, Although in the example above the extent of reaction was positive since the system shifted in the forward direction, this usage implies that in general the extent of reaction can be positive or negative, depending on the direction that the system shifts from its initial composition. Relations The relation between the change in Gibbs reaction energy and Gibbs energy can be defined as the slope of the Gibbs energy plotted against the extent of reaction at constant pressure and temperature. This formula leads to the Nernst equation when applied to the oxidation-reduction reaction which generates the voltage of a voltaic cell. Analogously, the relation between the change in reaction enthalpy and enthalpy can be defined. For example,",
                    "score": 0.8105351328849792
                },
                {
                    "id": 2550649,
                    "contents": "Legendre transformation\nFor example, the internal energy is an explicit function of the extensive variables entropy, volume, and chemical composition which has a total differential Stipulating some common reference state, by using the (non-standard) Legendre transform of the internal energy, , with respect to volume, , the enthalpy may be defined by writing which is now explicitly function of the pressure , since The enthalpy is suitable for description of processes in which the pressure is controlled from the surroundings. It is likewise possible to shift the dependence of the energy from the extensive variable of entropy, , to the (often more convenient) intensive variable , resulting in the Helmholtz and Gibbs free energies. The Helmholtz free energy, , and Gibbs energy, , are obtained by performing Legendre transforms of the internal energy and enthalpy, respectively,",
                    "score": 0.8098830580711365
                },
                {
                    "id": 1879025,
                    "contents": "Henry's law\nThe standard chemical potential μm°, the activity coefficient γm and the Henry's law constant KH,b all have different numerical values when molalities are used in place of concentrations. Solvent mixtures Henry's law solubility constant for a gas 2 in a mixture M of two solvents 1 and 3 depends on the individual constants for each solvent, and according to: Where , are the molar ratios of each solvent in the mixture and a13 is the interaction parameter of the solvents from Wohl expansion of the excess chemical potential of the ternary mixtures. A similar relationship can be found for the volatility constant , by remembering that and that, both being positive real numbers, , thus: For a water-ethanol mixture, the interaction parameter a13 has values around for ethanol concentrations (volume/volume) between 5% and 25% . Miscellaneous In geochemistry",
                    "score": 0.8096936345100403
                },
                {
                    "id": 10856339,
                    "contents": "Kelvin equation\nLet and represent the Gibbs free energy of a molecule in the vapor and liquid phase respectively. The change in the Gibbs free energy is then: where is the Gibbs free energy associated with an interface with radius of curvature and surface tension . The equation can be rearranged to give Let and be the volume occupied by one molecule in the liquid phase and vapor phase respectively. If the drop is considered to be spherical, then The number of molecules in the drop is then given by The change in Gibbs energy is then The differential form of the Gibbs free energy of one molecule at constant temperature and constant number of molecules can be given by: If we assume that then The vapor phase is also assumed to behave like an ideal gas, so where is the Boltzmann constant. Thus, the change in the Gibbs free energy for one molecule is",
                    "score": 0.8094437718391418
                },
                {
                    "id": 1878794,
                    "contents": "Gibbs free energy\nwhere ΔH is the enthalpy of reaction. The quantities on the right are all directly measurable. Useful identities to derive the Nernst equation During a reversible electrochemical reaction at constant temperature and pressure, the following equations involving the Gibbs free energy hold: (see chemical equilibrium), (for a system at chemical equilibrium), (for a reversible electrochemical process at constant temperature and pressure), (definition of E°), and rearranging gives which relates the cell potential resulting from the reaction to the equilibrium constant and reaction quotient for that reaction (Nernst equation),",
                    "score": 0.8088912963867188
                },
                {
                    "id": 1377657,
                    "contents": "Josiah Willard Gibbs\nwhere T is the absolute temperature, p is the pressure, dS is an infinitesimal change in entropy and dV is an infinitesimal change of volume. The last term is the sum, over all the chemical species in a chemical reaction, of the chemical potential, μi, of the ith species, multiplied by the infinitesimal change in the number of moles, dNi of that species. By taking the Legendre transform of this expression, he defined the concepts of enthalpy, H and Gibbs free energy, G. This compares to the expression for Helmholtz free energy, A. When the Gibbs free energy for a chemical reaction is negative the reaction will proceed spontaneously. When a chemical system is at equilibrium, the change in Gibbs free energy is zero. An equilibrium constant is simply related to the free energy change when the reactants are in their standard states. Chemical potential is usually defined as partial molar Gibbs free energy. Gibbs also obtained what later came to be known as the \"Gibbs–Duhem equation\".",
                    "score": 0.8080971240997314
                },
                {
                    "id": 462773,
                    "contents": "Gibbs–Helmholtz equation\nIntegrating with respect to T (again p is constant) it becomes: This equation quickly enables the calculation of the Gibbs free energy change for a chemical reaction at any temperature T2 with knowledge of just the standard Gibbs free energy change of formation and the standard enthalpy change of formation for the individual components. Also, using the reaction isotherm equation, that is which relates the Gibbs energy to a chemical equilibrium constant, the van 't Hoff equation can be derived. Derivation Background The definition of the Gibbs function is where is the enthalpy defined by: Taking differentials of each definition to find and , then using the fundamental thermodynamic relation (always true for reversible or irreversible processes):",
                    "score": 0.8080772161483765
                },
                {
                    "id": 1704114,
                    "contents": "Ethanol\nC2H5OH (l) + 3 O2 (g) → 2 CO2 (g) + 3 H2O (g); −ΔHc = 1236 kJ/mol = 26.8 kJ/g = 295.4 kcal/mol = 6.41 kcal/g Specific heat = 2.44 kJ/(kg·K) Acid-base chemistry Ethanol is a neutral molecule and the pH of a solution of ethanol in water is nearly 7.00. Ethanol can be quantitatively converted to its conjugate base, the ethoxide ion (CH3CH2O−), by reaction with an alkali metal such as sodium: 2 CH3CH2OH + 2 Na → 2 CH3CH2ONa + H2 or a very strong base such as sodium hydride: CH3CH2OH + NaH → CH3CH2ONa + H2 The acidities of water and ethanol are nearly the same, as indicated by their pKa of 15.7 and 16 respectively. Thus, sodium ethoxide and sodium hydroxide exist in an equilibrium that is closely balanced: CH3CH2OH + NaOH CH3CH2ONa + H2O",
                    "score": 0.8078128099441528
                },
                {
                    "id": 1377646,
                    "contents": "Josiah Willard Gibbs\nGibbs's monograph rigorously and ingeniously applied his thermodynamic techniques to the interpretation of physico-chemical phenomena, explaining and relating what had previously been a mass of isolated facts and observations. The work has been described as \"the Principia of thermodynamics\" and as a work of \"practically unlimited scope\". It solidly laid the foundation for physical Chemistry. Wilhelm Ostwald, who translated Gibbs's monograph into German, referred to Gibbs as the \"founder of chemical energetics\". According to modern commentators, Gibbs continued to work without pay until 1880, when the new Johns Hopkins University in Baltimore, Maryland offered him a position paying $3,000 per year. In response, Yale offered him an annual salary of $2,000, which he was content to accept. Career, 1880–1903",
                    "score": 0.8077227473258972
                },
                {
                    "id": 10795751,
                    "contents": "Thermodynamic databases for pure substances\nin heat content symbols as 298). All of these terms mean the molar heat content for a substance in its normal standard state above a reference temperature of 298.15 K. Data for gases is for the hypothetical ideal gas at the designated standard pressure. The SI unit for enthalpy is J/mol, and is a positive number above the reference temperature. The heat content has been measured and tabulated for virtually all known substances, and is commonly expressed as a polynomial function of temperature. The heat content of an ideal gas is independent of pressure (or volume), but the heat content of real gases varies with pressure, hence the need to define the state for the gas (real or ideal) and the pressure. Note that for some thermodynamic databases such as for steam, the reference temperature is 273.15 K (0 °C).",
                    "score": 0.8076925873756409
                },
                {
                    "id": 1404488,
                    "contents": "Thermodynamic free energy\nThe Gibbs free energy is given by , where H is the enthalpy, T is the absolute temperature, and S is the entropy. , where U is the internal energy, p is the pressure, and V is the volume. G is the most useful for processes involving a system at constant pressure p and temperature T, because, in addition to subsuming any entropy change due merely to heat, a change in G also excludes the work needed to \"make space for additional molecules\" produced by various processes. Gibbs free energy change therefore equals work not associated with system expansion or compression, at constant temperature and pressure. (Hence its utility to solution-phase chemists, including biochemists.)",
                    "score": 0.8075644969940186
                },
                {
                    "id": 13510796,
                    "contents": "Mikkel Frandsen\nIn 1934, Frandsen, along with Washburn and Smith, also published \"On Change in Density, Index of Refraction, Boiling Point, and Freezing Point of Water after Electrolysis.\" National Bureau of Standards From 1931 to 1934, Frandsen authored or co-authored a series of experiments while at the National Bureau of Standards, the first of which was entitled, Cryoscopic Constant Heat of Fusion, and Heat Capacity of Camphor (1931). In 1932, Frederick Rossini, Washburn, and Frandsen authored \"The Calorimetric Determination of the Intrinsic Energy of Gases as a Function of the Pressure.\" This experiment resulted in the development of the Washburn Correction for bomb calorimetry, a decrease or correction of the results of a calorimetric procedure to normal states.",
                    "score": 0.8074273467063904
                },
                {
                    "id": 13043988,
                    "contents": "Enthalpy of mixing\nRelation to the Gibbs free energy of mixing The excess Gibbs free energy of mixing can be related to the enthalpy of mixing by the ușe of the Gibbs-Helmholtz equation: or equivalently In these equations, the excess and total enthalpies of mixing are equal because the ideal enthalpy of mixing is zero. This is not true for the corresponding Gibbs free energies however. Ideal and regular mixtures An ideal mixture is any in which the arithmetic mean (with respect to mole fraction) of the two pure substances is the same as that of the final mixture. Among other important thermodynamic simplifications, this means that enthalpy of mixing is zero: . Any gas that follows the ideal gas law can be assumed to mix ideally, as can hydrocarbons and liquids with similar molecular interactions and properties.",
                    "score": 0.8072646856307983
                },
                {
                    "id": 16806022,
                    "contents": "Superheated water\nfalls to 33, the same as methanol at room temperature. Thus water behaves like a water–methanol mixture between 100 °C and 200 °C. Disruption of extended hydrogen bonding allows molecules to move more freely (viscosity, diffusion and surface tension effects), and extra energy must be supplied to break the bonds (increased heat capacity).",
                    "score": 0.8072037100791931
                },
                {
                    "id": 1704124,
                    "contents": "Ethanol\nReferences Further reading . External links Alcohol (Ethanol) at The Periodic Table of Videos (University of Nottingham) International Labour Organization ethanol safety information National Pollutant Inventory – Ethanol Fact Sheet CDC – NIOSH Pocket Guide to Chemical Hazards – Ethyl Alcohol National Institute of Standards and Technology chemical data on ethanol Chicago Board of Trade news and market data on ethanol futures Calculation of vapor pressure, liquid density, dynamic liquid viscosity, surface tension of ethanol Ethanol History A look into the history of ethanol ChemSub Online: Ethyl alcohol Industrial ethanol production process flow diagram using ethylene and sulphuric acid Alcohol solvents Alkanols Anatomical preservation Commodity chemicals Disinfectants Hepatotoxins Household chemicals Human metabolites IARC Group 1 carcinogens Oxygenates Primary alcohols Rocket fuels Teratogens",
                    "score": 0.8071004152297974
                },
                {
                    "id": 1704092,
                    "contents": "Ethanol\nChemistry Chemical formula Ethanol is a 2-carbon alcohol. Its molecular formula is CH3CH2OH. An alternative notation is CH3−CH2−OH, which indicates that the carbon of a methyl group (CH3−) is attached to the carbon of a methylene group (−CH2–), which is attached to the oxygen of a hydroxyl group (−OH). It is a constitutional isomer of dimethyl ether. Ethanol is sometimes abbreviated as EtOH, using the common organic chemistry notation of representing the ethyl group (C2H5−) with Et. Physical properties Ethanol is a volatile, colorless liquid that has a slight odor. It burns with a smokeless blue flame that is not always visible in normal light. The physical properties of ethanol stem primarily from the presence of its hydroxyl group and the shortness of its carbon chain. Ethanol's hydroxyl group is able to participate in hydrogen bonding, rendering it more viscous and less volatile than less polar organic compounds of similar molecular weight, such as propane.",
                    "score": 0.8070147037506104
                },
                {
                    "id": 1704110,
                    "contents": "Ethanol\nAbsolute alcohol Absolute or anhydrous alcohol refers to ethanol with a low water content. There are various grades with maximum water contents ranging from 1% to a few parts per million (ppm). If azeotropic distillation is used to remove water, it will contain trace amounts of the material separation agent (e.g. benzene). Absolute alcohol is not intended for human consumption. Absolute ethanol is used as a solvent for laboratory and industrial applications, where water will react with other chemicals, and as fuel alcohol. Spectroscopic ethanol is an absolute ethanol with a low absorbance in ultraviolet and visible light, fit for use as a solvent in ultraviolet-visible spectroscopy. Pure ethanol is classed as 200 proof in the US, equivalent to 175 degrees proof in the UK system.",
                    "score": 0.8069453835487366
                },
                {
                    "id": 1704123,
                    "contents": "Ethanol\nEthanol intended for industrial use is often produced from ethylene. Ethanol has widespread use as a solvent of substances intended for human contact or consumption, including scents, flavorings, colorings, and medicines. In chemistry, it is both a solvent and a feedstock for the synthesis of other products. It has a long history as a fuel for heat and light, and more recently as a fuel for internal combustion engines. See also 1-Propanol Butanol fuel Ethanol-induced non-lamellar phases in phospholipids Ethenol Ethynol Isopropyl alcohol Methanol Rubbing alcohol tert-Butyl alcohol Timeline of alcohol fuel References Further reading . External links",
                    "score": 0.806607186794281
                },
                {
                    "id": 1910416,
                    "contents": "Hess's law\nAdding these equations and canceling out the common terms on both sides, we obtain 2B(s) + 3/2 O2(g) → B2O3(s) (ΔH = −1273 kJ/mol) Extension to free energy and entropy The concepts of Hess's law can be expanded to include changes in entropy and in Gibbs free energy, since these are also state functions. The Bordwell thermodynamic cycle is an example of such an extension that takes advantage of easily measured equilibria and redox potentials to determine experimentally inaccessible Gibbs free energy values. Combining ΔGo values from Bordwell thermodynamic cycles and ΔHo values found with Hess's law can be helpful in determining entropy values that have not been measured directly and therefore need to be calculated through alternative paths. For the free energy:",
                    "score": 0.8065800666809082
                },
                {
                    "id": 14912738,
                    "contents": "Lanny D. Schmidt\nThere is, however, a better way of storing the hydrogen needed for fuel cells: in ethanol, each molecule of which bundles six hydrogen atoms, two carbon atoms, and one oxygen atom into a package far more compact than gaseous hydrogen. Until recently, no one could figure out how to unbundle the ethanol molecules in an energy-efficient way. But Lanny Schmidt, a chemical engineer at the University of Minnesota, may now have found a silver bullet. He has developed a glass tube containing a series of metal plates about the size of a Bic lighter. Made out of the exotic metals rhodium and cerium, these plates can suck the hydrogen out of ethanol and feed it into a fuel cell. (Ironically, Schmidt had been looking for a catalyst that would strip hydrogen from plain old gasoline, but the ethanol turned out to work even better.)\" — Sam Jaffe, Washington Monthly",
                    "score": 0.806176483631134
                },
                {
                    "id": 16022592,
                    "contents": "Apparent molar property\nAlcohol Another example of the apparent molar volume of the second component is less than its molar volume as a pure substance is the case of ethanol in water. For example, at 20 mass percents ethanol, the solution has a volume of 1.0326 liters per kg at 20 °C, while pure water is 1.0018 L/kg (1.0018 cc/g). The apparent volume of the added ethanol is 1.0326 L – 0.8 kg x 1.0018 L/kg = 0.2317 L. The number of moles of ethanol is 0.2 kg / (0.04607 kg/mol) = 4.341 mol, so that the apparent molar volume is 0.2317 L / 4.341 mol = 0.0532 L / mol = 53.2 cc/mole (1.16 cc/g). However pure ethanol has a molar volume at this temperature of 58.4 cc/mole (1.27 cc/g).",
                    "score": 0.8060400485992432
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_6",
        "question": "The promotion of an electron from the valence band into the conduction band in pure $\\mathrm{TIO}_2$ by light absorption requires a wavelength of less than $350 \\mathrm{~nm}$. Calculate the energy gap in electronvolts between the valence and conduction bands.",
        "golden_answers": [
            " 3.54"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 22087811,
                    "contents": "Elliott formula\nThe concentration of charge carriers influence the shape of the absorption spectrum considerably. For high enough densities, all energies correspond to continuum states and some of the oscillators strengths may become negative-valued due to the Pauli-blocking effect. Physically, this can be understood as the elementary property of Fermions; if a given electronic state is already excited it cannot be excited a second time due to the Pauli exclusion among Fermions. Therefore, the corresponding electronic states can produce only photon emission that is seen as negative absorption, i.e., gain that is the prerequisite to realizing semiconductor lasers. Even though one can understand the principal behavior of semiconductor absorption on the basis of the Elliott formula, detailed predictions of the exact , , and requires a full many-body computation already for moderate carrier densities. Photoluminescence Elliott formula",
                    "score": 0.894606351852417
                },
                {
                    "id": 1169176,
                    "contents": "Photoelectric effect\nthe forbidden band, explained by the band gap model. Some materials such as gallium arsenide have an effective electron affinity that is below the level of the conduction band. In these materials, electrons that move to the conduction band all have sufficient energy to be emitted from the material, so the film that absorbs photons can be quite thick. These materials are known as negative electron affinity materials.",
                    "score": 0.8922332525253296
                },
                {
                    "id": 1643267,
                    "contents": "Electric current\nThe ease of exciting electrons in the semiconductor from the valence band to the conduction band depends on the band gap between the bands. The size of this energy band gap serves as an arbitrary dividing line (roughly 4 eV) between semiconductors and insulators.",
                    "score": 0.8894124627113342
                },
                {
                    "id": 1169137,
                    "contents": "Photoelectric effect\nEmission of conduction electrons from typical metals requires a few electron-volt (eV) light quanta, corresponding to short-wavelength visible or ultraviolet light. In extreme cases, emissions are induced with photons approaching zero energy, like in systems with negative electron affinity and the emission from excited states, or a few hundred keV photons for core electrons in elements with a high atomic number. Study of the photoelectric effect led to important steps in understanding the quantum nature of light and electrons and influenced the formation of the concept of wave–particle duality. Other phenomena where light affects the movement of electric charges include the photoconductive effect, the photovoltaic effect, and the photoelectrochemical effect.",
                    "score": 0.8870478868484497
                },
                {
                    "id": 17178219,
                    "contents": "Direct and indirect band gaps\nThis formula is valid only for light with photon energy larger, but not too much larger, than the band gap (more specifically, this formula assumes the bands are approximately parabolic), and ignores all other sources of absorption other than the band-to-band absorption in question, as well as the electrical attraction between the newly created electron and hole (see exciton). It is also invalid in the case that the direct transition is forbidden, or in the case that many of the valence band states are empty or conduction band states are full. On the other hand, for an indirect band gap, the formula is: where: is the energy of the phonon that assists in the transition is Boltzmann's constant is the thermodynamic temperature This formula involves the same approximations mentioned above.",
                    "score": 0.886850118637085
                },
                {
                    "id": 8827534,
                    "contents": "Franz–Keldysh effect\nSee also Quantum-confined Stark effect Notes References W. Franz, Einfluß eines elektrischen Feldes auf eine optische Absorptionskante, Z. Naturforschung 13a (1958) 484–489. L. V. Keldysh, Behaviour of Non-Metallic Crystals in Strong Electric Fields, J. Exptl. Theoret. Phys. (USSR) 33 (1957) 994–1003, translation: Soviet Physics JETP 6 (1958) 763–770. L. V. Keldysh, Ionization in the Field of a Strong Electromagnetic Wave, J. Exptl. Theoret. Phys. (USSR) 47 (1964) 1945–1957, translation: Soviet Physics JETP 20 (1965) 1307–1314. J. I. Pankove, Optical Processes in Semiconductors, Dover Publications Inc. New York (1971). H. Haug and S. W. Koch, \"Quantum Theory of the Optical and Electronic Properties of Semiconductors\", World Scientific (1994). C. Kittel, \"Introduction to Solid State Physics\", Wiley (1996). Optoelectronics Electronic engineering",
                    "score": 0.8831035494804382
                },
                {
                    "id": 691192,
                    "contents": "Photoluminescence\nThe fictive model structure for this discussion has two confined quantized electronic and two hole subbands, e1, e2 and h1, h2, respectively. The linear absorption spectrum of such a structure shows the exciton resonances of the first (e1h1) and the second quantum well subbands (e2, h2), as well as the absorption from the corresponding continuum states and from the barrier.",
                    "score": 0.8777529001235962
                },
                {
                    "id": 2751575,
                    "contents": "Wide-bandgap semiconductor\nOptical properties The connection between the wavelength and the bandgap is that the energy of the bandgap is the minimum energy that is needed to excite an electron into the conduction band. In order for an unassisted photon to cause this excitation, it must have at least that much energy. In the opposite process, when excited electron-hole pairs undergo recombination, photons are generated with energies that correspond to the magnitude of the bandgap.",
                    "score": 0.8770622611045837
                },
                {
                    "id": 8827533,
                    "contents": "Franz–Keldysh effect\n( where is the value in the direction of the principal axis of the reduced effective mass tensor) Using change of variables: then the solution is where For example, the solution is given by The dielectric constant can be obtained inserting this equation to the (**) (above block), and changing the summation with respect to λ to The integral with respect to is given by the joint density of states for the two-D band. (the Joint density of states is nothing but the meaning of DOS of both electron and hole at the same time.) where Then we put And think about the case we find , thus with the asymptotic solution for the Airy function in this limit. Finally, Therefore, the dielectric function for the incident photon energy below the band gap exist! These results indicate that absorption occurs for an incident photon. See also Quantum-confined Stark effect Notes",
                    "score": 0.8749199509620667
                },
                {
                    "id": 17178215,
                    "contents": "Direct and indirect band gaps\nImplications for light absorption The exact reverse of radiative recombination is light absorption. For the same reason as above, light with a photon energy close to the band gap can penetrate much farther before being absorbed in an indirect band gap material than a direct band gap one (at least insofar as the light absorption is due to exciting electrons across the band gap).",
                    "score": 0.8737102746963501
                },
                {
                    "id": 15611433,
                    "contents": "Free carrier absorption\nThe energy of free carriers is proportional to the square of momentum (). Using the band gap energy and the electron-hole distribution function, we can obtain the absorption coefficient with some mathematical calculation. The final result is This result is important to understand the optical measurement data and the electronic properties of metals and semiconductors. It is worth noting that the absorption coefficient is negative when the material supports stimulated emission, which is the basis for the operation of lasers, particularly semiconductor laser. References 1. H. Haug and S. W. Koch, \" \", World Scientific (1994). sec.5.4 a Quantum mechanics",
                    "score": 0.8735003471374512
                },
                {
                    "id": 8827526,
                    "contents": "Franz–Keldysh effect\nAs originally conceived, the Franz–Keldysh effect is the result of wavefunctions \"leaking\" into the band gap. When an electric field is applied, the electron and hole wavefunctions become Airy functions rather than plane waves. The Airy function includes a \"tail\" which extends into the classically forbidden band gap. According to Fermi's golden rule, the more overlap there is between the wavefunctions of a free electron and a hole, the stronger the optical absorption will be. The Airy tails slightly overlap even if the electron and hole are at slightly different potentials (slightly different physical locations along the field). The absorption spectrum now includes a tail at energies below the band gap and some oscillations above it. This explanation does, however, omit the effects of excitons, which may dominate optical properties near the band gap.",
                    "score": 0.8727928400039673
                },
                {
                    "id": 6211661,
                    "contents": "Band gap\nBased on the band structures, materials have either direct band gap or indirect band gap. If the momentum of the lowest energy state in the conduction band and the highest energy state of the valence band of a material are the same, the material has a direct bandgap. If they are not the same, then the material has an indirect band gap. For materials with a direct band gap, valence electrons can be directly excited into the conduction band by a photon whose energy is larger than the bandgap. In contrast, for materials with an indirect band gap, a photon and phonon must both be involved in a transition from the valence band top to the conduction band bottom. Therefore, direct bandgap materials tend to have stronger light emission and absorption properties. Other things equal, direct bandgap materials tend to be better for photovoltaics (PVs), light-emitting diodes (LEDs), and laser diodes; however, indirect bandgap materials are frequently used in PVs and LEDs when the materials have",
                    "score": 0.8710284233093262
                },
                {
                    "id": 15611430,
                    "contents": "Free carrier absorption\nFree carrier absorption occurs when a material absorbs a photon, and a carrier (electron or hole) is excited from an already-excited state to another, unoccupied state in the same band (but possibly a different subband). This intraband absorption is different from interband absorption because the excited carrier is already in an excited band, such as an electron in the conduction band or a hole in the valence band, where it is free to move. In interband absorption, the carrier starts in a fixed, nonconducting band and is excited to a conducting one. In the simplest approximation, the Drude model, free carrier absorption is proportional to the square of the wavelength.",
                    "score": 0.8709214925765991
                },
                {
                    "id": 25409100,
                    "contents": "Adiabatic electron transfer\nUnifying standard electrochemical electron-transfer processes with this type of solar energy harvesting, adiabatic electron-transfer theory also depicts a third application in which the donor and acceptor are both involved in light absorption, as sketched in Figure 3. Here, light absorption directly leads to charge separation D+-A−. Hush's theory for this process considers the donor-acceptor coupling , the energy required to rearrange the atoms from their initial geometry to the preferred local geometry and environment polarization of the charge-separated state, and the energy change associated with charge separation. In the weak-coupling limit ( ), Hush showed that the rate of light absorption (and hence charge separation) is given from the Einstein equation by … (1) This theory explained how the world's first modern synthetic dye, Prussian blue absorbes light, creating the field of intervalence charge transfer spectroscopy.",
                    "score": 0.8704043626785278
                },
                {
                    "id": 23329258,
                    "contents": "Valence and conduction bands\nSee also Electrical conduction for more information about conduction in solids, and another description of band structure. Fermi sea HOMO/LUMO Semiconductor for a full explanation of the band structure of materials. Valleytronics References Citations General references External links Direct Band Gap Energy Calculator Electronic band structures",
                    "score": 0.8702342510223389
                },
                {
                    "id": 2751573,
                    "contents": "Wide-bandgap semiconductor\nIn semiconductors, adding a small amount of energy pushes more electrons into the conduction band, making them more conductive and allowing current to flow like a conductor. Reversing the polarity of this applied energy pushes the electrons into the more widely separated bands, making them insulators and stopping the flow. Since the amount of energy needed to push the electrons between these two levels is very small, semiconductors allow switching with very little energy input. However, this switching process depends on the electrons being naturally distributed between the two states, so small inputs cause the population statistics to change rapidly. As the external temperature changes, due to the Maxwell–Boltzmann distribution, more and more electrons will normally find themselves in one state or the other, causing the switching action to occur on its own, or stop entirely.",
                    "score": 0.870163083076477
                },
                {
                    "id": 4849976,
                    "contents": "Organic semiconductor\nefficient photogeneration of charge carriers in neat systems in the bulk. Efficient photogeneration can only occur in binary systems due to charge transfer between donor and acceptor moieties. Otherwise neutral excitons decay radiatively to the ground state – thereby emitting photoluminescence – or non-radiatively. The optical absorption edge of organic semiconductors is typically 1.7–3 eV, equivalent to a spectral range from 700 to 400 nm (which corresponds to the visible spectrum).",
                    "score": 0.8701413869857788
                },
                {
                    "id": 6211656,
                    "contents": "Band gap\nIn semiconductors and insulators, electrons are confined to a number of bands of energy, and forbidden from other regions. The term \"band gap\" refers to the energy difference between the top of the valence band and the bottom of the conduction band. Electrons are able to jump from one band to another. However, in order for an electron to jump from a valence band to a conduction band, it requires a specific minimum amount of energy for the transition. The required energy differs with different materials. Electrons can gain enough energy to jump to the conduction band by absorbing either a phonon (heat) or a photon (light).",
                    "score": 0.8696326017379761
                },
                {
                    "id": 22087810,
                    "contents": "Elliott formula\nIn general, the exciton eigen energies consist of a series of bound states that emerge energetically well below the fundamental bandgap energy and a continuum of unbound states that appear for energies above the bandgap. Therefore, a typical semiconductor's low-density absorption spectrum shows a series of exciton resonances and then a continuum-absorption tail. For realistic situations, increases more rapidly than the exciton-state spacing so that one typically resolves only few lowest exciton resonances in actual experiments.",
                    "score": 0.8695173859596252
                },
                {
                    "id": 16010819,
                    "contents": "Quantum-confined Stark effect\nfor the conduction and valence band respectively, where has been introduced as a normalization constant. For any applied electric field we obtain . Thus, according to Fermi's golden rule, which says that transition probability depends on the above overlapping integral, optical transition strength is weakened. Excitons The description of quantum-confined Stark effect given by second order perturbation theory is extremely simple and intuitive. However to correctly depict QCSE the role of excitons has to be taken into account. Excitons are quasiparticles consisting of a bound state of an electron-hole pair, whose binding energy in a bulk material can be modelled as that of an hydrogenic atom",
                    "score": 0.8690198659896851
                },
                {
                    "id": 4849975,
                    "contents": "Organic semiconductor\nIn molecular crystals the energetic separation between the top of the valence band and the bottom conduction band, i.e. the band gap, is typically 2.5–4 eV, while in inorganic semiconductors the band gaps are typically 1–2 eV. This implies that they are, in fact, insulators rather than semiconductors in the conventional sense. They become semiconducting only when charge carriers are either injected from the electrodes or generated by intentional or unintentional doping. Charge carriers can also be generated in the course of optical excitation. It is important to realize, however, that the primary optical excitations are neutral excitons with a Coulomb-binding energy of typically 0.5–1.0 eV. The reason is that in organic semiconductors their dielectric constants are as low as 3–4. This impedes efficient photogeneration of charge carriers in neat systems in the bulk. Efficient photogeneration can only occur in binary systems due to charge transfer between donor and acceptor moieties.",
                    "score": 0.869019627571106
                },
                {
                    "id": 928883,
                    "contents": "Exciton\nAn exciton can form when a material absorbs a photon of higher energy than its bandgap. This excites an electron from the valence band into the conduction band. In turn, this leaves behind a positively charged electron hole (an abstraction for the location from which an electron was moved). The electron in the conduction band is then less attracted to this localized hole due to the repulsive Coulomb forces from large numbers of electrons surrounding the hole and excited electron. These repulsive forces provide a stabilizing energy balance. Consequently, the exciton has slightly less energy than the unbound electron and hole. The wavefunction of the bound state is said to be hydrogenic, an exotic atom state akin to that of a hydrogen atom. However, the binding energy is much smaller and the particle's size much larger than a hydrogen atom. This is because of both the screening of the Coulomb force by other electrons in the semiconductor (i.e., its relative permittivity), and the",
                    "score": 0.8686182498931885
                },
                {
                    "id": 691196,
                    "contents": "Photoluminescence\nThe dephasing of the polarization leads to creation of populations of electrons and holes in the conduction and the valence bands, respectively. The lifetime of the carrier populations is rather long, limited by radiative and non-radiative recombination such as Auger recombination. During this lifetime a fraction of electrons and holes may form excitons, this topic is still controversially discussed in the literature. The formation rate depends on the experimental conditions such as lattice temperature, excitation density, as well as on the general material parameters, e.g., the strength of the Coulomb-interaction or the exciton binding energy. The characteristic time-scales are in the range of hundreds of picoseconds in GaAs; they appear to be much shorter in wide-gap semiconductors.",
                    "score": 0.8681228756904602
                },
                {
                    "id": 22087816,
                    "contents": "Elliott formula\nIn contrast to optical absorption and photoluminescence, THz absorption may involve all exciton states. This can be seen from the spectral response function that contains the current-matrix elements between two exciton states. The unit vector is determined by the direction of the THz field. This leads to dipole selection rules among exciton states, in full analog to the atomic dipole selection rules. Each allowed transition produces a resonance in and the resonance width is determined by a dephasing constant that generally depends on exciton states involved and the THz frequency . The THz response also contains that stems from the decay constant of macroscopic THz currents.",
                    "score": 0.867944598197937
                },
                {
                    "id": 22087802,
                    "contents": "Elliott formula\nThe Elliott formula describes analytically, or with few adjustable parameters such as the dephasing constant, the light absorption or emission spectra of solids. It was originally derived by Roger James Elliott to describe linear absorption based on properties of a single electron–hole pair. The analysis can be extended to a many-body investigation with full predictive powers when all parameters are computed microscopically using, e.g., the semiconductor Bloch equations (abbreviated as SBEs) or the semiconductor luminescence equations (abbreviated as SLEs). Background",
                    "score": 0.8674207925796509
                },
                {
                    "id": 3366504,
                    "contents": "Copper(I) oxide\nAnother unusual feature of the ground state excitons is that all primary scattering mechanisms are known quantitatively. Cu2O was the first substance where an entirely parameter-free model of absorption linewidth broadening by temperature could be established, allowing the corresponding absorption coefficient to be deduced. It can be shown using Cu2O that the Kramers–Kronig relations do not apply to polaritons.",
                    "score": 0.8673575520515442
                },
                {
                    "id": 16010820,
                    "contents": "Quantum-confined Stark effect\nwhere is the Rydberg constant, is the reduced mass of the electron-hole pair and is the relative electric permittivity. The exciton binding energy has to be included in the energy balance of photon absorption processes: . Exciton generation therefore redshift the optical band gap towards lower energies. If an electric field is applied to a bulk semiconductor, a further redshift in the absorption spectrum is observed due to Franz–Keldysh effect. Due to their opposite electric charges, the electron and the hole constituting the exciton will be pulled apart under the influence of the external electric field. If the field is strong enough then excitons cease to exist in the bulk material. This somewhat limits the applicability of Franz-Keldysh for modulation purposes, as the redshift induced by the applied electric field is countered by shift towards higher energies due to the absence of exciton generations.",
                    "score": 0.8672622442245483
                },
                {
                    "id": 29751135,
                    "contents": "Urbach energy\nIntroduction In the simplest description of a semiconductor, a single parameter is used to quantify the onset of optical absorption: the band gap, . In this description, semiconductors are described as being able to absorb photons above , but are transparent to photons below . However, the density of states in 3 dimensional semiconductors increases further from the band gap (this is not generally true in lower dimensional semiconductors however). For this reason, the absorption coefficient, , increases with energy. The Urbach Energy quantifies the steepness of the onset of absorption near the band edge, and hence the broadness of the density of states. A sharper onset of absorption represents a lower Urbach Energy.",
                    "score": 0.867001473903656
                },
                {
                    "id": 22087812,
                    "contents": "Elliott formula\nPhotoluminescence Elliott formula After the semiconductor becomes electronically excited, the carrier system relaxes into a quasiequilibrium. At the same time, vacuum-field fluctuations trigger spontaneous recombination of electrons and holes (electronic vacancies) via spontaneous emission of photons. At quasiequilibrium, this yields a steady-state photon flux emitted by the semiconductor. By starting from the SLEs, the steady-state photoluminescence (abbreviated as PL) can be cast into the form that is very similar to the Elliott formula for the optical absorption. As a major difference, the numerator has a new contribution – the spontaneous-emission source that contains electron and hole distributions and , respectively, where is the carrier momentum. Additionally, contains also a direct contribution from exciton populations that describes truly bound electron–hole pairs.",
                    "score": 0.8664594292640686
                },
                {
                    "id": 9242959,
                    "contents": "Anderson's rule\nOnce the relative positions of the conduction and valence bands for both semiconductors are known, Anderson's rule allows the calculation of the band offsets of both the valence band () and the conduction band (). After applying Anderson's rule and discovering the bands' alignment at the junction, Poisson’s equation can then be used to calculate the shape of the band bending in the two semiconductors. Example: straddling gap Consider a heterojunction between semiconductor 1 and semiconductor 2. Suppose the conduction band of semiconductor 2 is closer to the vacuum level than that of semiconductor 1. The conduction band offset would then be given by the difference in electron affinity (energy from upper conducting band to vacuum level) of the two semiconductors: Next, suppose that the band gap of semiconductor 2 is large enough that the valence band of semiconductor 1 lies at a higher energy than that of semiconductor 2. Then the valence band offset is given by:",
                    "score": 0.8660637736320496
                },
                {
                    "id": 1237879,
                    "contents": "Semiconductor\nThe partial filling of the states at the bottom of the conduction band can be understood as adding electrons to that band. The electrons do not stay indefinitely (due to the natural thermal recombination) but they can move around for some time. The actual concentration of electrons is typically very dilute, and so (unlike in metals) it is possible to think of the electrons in the conduction band of a semiconductor as a sort of classical ideal gas, where the electrons fly around freely without being subject to the Pauli exclusion principle. In most semiconductors, the conduction bands have a parabolic dispersion relation, and so these electrons respond to forces (electric field, magnetic field, etc.) much as they would in a vacuum, though with a different effective mass. Because the electrons behave like an ideal gas, one may also think about conduction in very simplistic terms such as the Drude model, and introduce concepts such as electron mobility.",
                    "score": 0.8658638000488281
                },
                {
                    "id": 29851159,
                    "contents": "Kubelka-Munk theory\nSemiconductors The band gap energy of semiconductors is frequently determined from a Tauc plot where the quantify represented by the quantity is plotted against photon energy . Then the band gap energy can be obtained by extending the straight segment of the graph to the axis. There is a simpler method adapted from the Kubelka-Munk theory in which the band gap is calculated by plotting, versus , where is the absorption coefficient.",
                    "score": 0.8653983473777771
                },
                {
                    "id": 12688771,
                    "contents": "Photoinduced electron transfer\nProcess It is common to describe where electrons reside as electron bands in bulk materials and electron orbitals in molecules. For the sake of expedience the following description will be described in molecular terms. When a photon excites a molecule, an electron in a ground state orbital can be excited to a higher energy orbital. This excited state leaves a vacancy in a ground state orbital that can be filled by an electron donor. It produces an electron in a high energy orbital which can be donated to an electron acceptor. In these respects a photoexcited molecule can act as a good oxidizing agent or a good reducing agent. Photoinduced oxidation [MLn]2+ + hν → [MLn]2+* [MLn]2+* + donor → [MLn]+ + donor+ Photoinduced reduction [MLn]2+ + hν → [MLn]2+* [MLn]2+* + acceptor → [MLn]3+ + acceptor−",
                    "score": 0.8650147914886475
                },
                {
                    "id": 6211654,
                    "contents": "Band gap\nfrom the valence to the conduction band, then current can flow (see carrier generation and recombination). Therefore, the band gap is a major factor determining the electrical conductivity of a solid. Substances with large band gaps are generally insulators, those with smaller band gaps are semiconductors, while conductors either have very small band gaps or none, because the valence and conduction bands overlap.",
                    "score": 0.8648769855499268
                },
                {
                    "id": 1113707,
                    "contents": "Energy level\nCorrespondingly, many kinds of spectroscopy are based on detecting the frequency or wavelength of the emitted or absorbed photons to provide information on the material analyzed, including information on the energy levels and electronic structure of materials obtained by analyzing the spectrum. An asterisk is commonly used to designate an excited state. An electron transition in a molecule's bond from a ground state to an excited state may have a designation such as σ → σ*, π → π*, or n → π* meaning excitation of an electron from a σ bonding to a σ antibonding orbital, from a π bonding to a π antibonding orbital, or from an n non-bonding to a π antibonding orbital. Reverse electron transitions for all these types of excited molecules are also possible to return to their ground states, which can be designated as σ* → σ, π* → π, or π* → n.",
                    "score": 0.8645029067993164
                },
                {
                    "id": 22087818,
                    "contents": "Elliott formula\nAbsorption Semiconductor-luminescence equations Semiconductor Bloch equations Quantum-optical spectroscopy Wannier equation Photoluminescence Terahertz technology Further reading References Theoretical physics Semiconductor analysis Quantum mechanics Equations of physics",
                    "score": 0.8644006848335266
                },
                {
                    "id": 1169151,
                    "contents": "Photoelectric effect\nInner photoelectric effect in the bulk of the material that is a direct optical transition between an occupied and an unoccupied electronic state. This effect is subject to quantum-mechanical selection rules for dipole transitions. The hole left behind the electron can give rise to secondary electron emission, or the so-called Auger effect, which may be visible even when the primary photoelectron does not leave the material. In molecular solids phonons are excited in this step and may be visible as satellite lines in the final electron energy. Electron propagation to the surface in which some electrons may be scattered because of interactions with other constituents of the solid. Electrons that originate deeper in the solid are much more likely to suffer collisions and emerge with altered energy and momentum. Their mean-free path is a universal curve dependent on electron's energy.",
                    "score": 0.8642022609710693
                },
                {
                    "id": 2751574,
                    "contents": "Wide-bandgap semiconductor\nThe size of the atoms and the number of protons in the atom are the primary predictors of the strength and layout of the bandgaps. Materials with small atoms and strong atomic bonds are associated with wide bandgaps. With regard to III-V compounds, nitrides are associated with the largest bandgaps. Bandgaps can be engineered by alloying, and Vegard's law states that there is a linear relation between lattice constant and composition of a solid solution at constant temperature. The position of the conduction band minima versus maxima in the band structure determine whether a bandgap is direct or indirect, where direct bandgap materials absorb light strongly, and indirect bandgaps absorb less strongly. Likewise, direct bandgap material emit light strongly, while indirect bandgap semiconductor are poor light emitters, unless dopants are added which couple strongly to light. Optical properties",
                    "score": 0.8637149930000305
                },
                {
                    "id": 8827525,
                    "contents": "Franz–Keldysh effect\nThe Franz–Keldysh effect is a change in optical absorption by a semiconductor when an electric field is applied. The effect is named after the German physicist Walter Franz and Russian physicist Leonid Keldysh (nephew of Mstislav Keldysh). Karl W. Böer observed first the shift of the optical absorption edge with electric fields during the discovery of high-field domains and named this the Franz-effect. A few months later, when the English translation of the Keldysh paper became available, he corrected this to the Franz–Keldysh effect.",
                    "score": 0.8625456690788269
                },
                {
                    "id": 8827531,
                    "contents": "Franz–Keldysh effect\n(i, j are the band indices, and re, rh, ke, kh are the coordinates and wave vectors of the electron and hole respectively) And we can take a total wave vector K such that Then, Bloch functions of the electron and hole can be constructed with the phase term If V varies slowly over the distance of the integral, the term can be treated like following. here we assume that the conduction and valence bands are parabolic with scalar masses and that at the top of the valence band , i.e. ( is the energy gap) Now, The Fourier transform of and above (*), the effective mass equation for the exciton may be written as then the solution of eq is given by is called the envelope function of an exciton. The ground state of the exciton is given in analogy to the hydrogen atom. then, the dielectric function is detailed calculation is in.",
                    "score": 0.8625442981719971
                },
                {
                    "id": 928889,
                    "contents": "Exciton\nWannier–Mott exciton In semiconductors, the dielectric constant is generally large. Consequently, electric field screening tends to reduce the Coulomb interaction between electrons and holes. The result is a Wannier–Mott exciton, which has a radius larger than the lattice spacing. Small effective mass of electrons that is typical of semiconductors also favors large exciton radii. As a result, the effect of the lattice potential can be incorporated into the effective masses of the electron and hole. Likewise, because of the lower masses and the screened Coulomb interaction, the binding energy is usually much less than that of a hydrogen atom, typically on the order of . This type of exciton was named for Gregory Wannier and Nevill Francis Mott. Wannier–Mott excitons are typically found in semiconductor crystals with small energy gaps and high dielectric constants, but have also been identified in liquids, such as liquid xenon. They are also known as large excitons.",
                    "score": 0.8622177839279175
                },
                {
                    "id": 385335,
                    "contents": "OLED\nmore mobile than electrons. The decay of this excited state results in a relaxation of the energy levels of the electron, accompanied by emission of radiation whose frequency is in the visible region. The frequency of this radiation depends on the band gap of the material, in this case the difference in energy between the HOMO and LUMO.",
                    "score": 0.8621762990951538
                },
                {
                    "id": 6023961,
                    "contents": "Carrier generation and recombination\nFrom which we can also define the internal quantum efficiency or quantum yield, as: Radiative recombination Band-to-band radiative recombination Band-to-band recombination is the name for the process of electrons jumping down from the conduction band to the valence band in a radiative manner. During band-to-band recombination, a form of spontaneous emission, the energy absorbed by a material is released in the form of photons. Generally these photons contain the same or less energy than those initially absorbed. This effect is how LEDs create light. Because the photon carries relatively little momentum, radiative recombination is significant only in direct bandgap materials. This process is also known as bimolecular recombination. This type of recombination depends on the density of electrons and holes in the excited state, denoted by and respectively. Let us represent the radiative recombination as and the carrier generation rate as G.",
                    "score": 0.8612815737724304
                },
                {
                    "id": 21672992,
                    "contents": "Coherent effects in semiconductor optics\nA prominent and important result of the Coulomb interaction among the photoexcitations is the appearance of strongly absorbing discrete excitonic resonances which show up in the absorption spectra of semiconductors spectrally below the fundamental band gap frequency. Since an exciton consists of a negatively charged conduction band electron and a positively charged valence band hole (i.e., an electron missing in the valence band) which attract each other via the Coulomb interaction, excitons have a hydrogenic series of discrete absorption lines. Due to the optical selection rules of typical III-V semiconductors such as Galliumarsenide (GaAs) only the s-states, i.e., 1s, 2s, etc., can be optically excited and detected, see article on Wannier equation.",
                    "score": 0.8606493473052979
                },
                {
                    "id": 3368468,
                    "contents": "Quantum dot\nOptical properties In semiconductors, light absorption generally leads to an electron being excited from the valence to the conduction band, leaving behind a hole. The electron and the hole can bind to each other to form an exciton. When this exciton recombines (i.e. the electron resumes its ground state), the exciton's energy can be emitted as light. This is called fluorescence. In a simplified model, the energy of the emitted photon can be understood as the sum of the band gap energy between the highest occupied level and the lowest unoccupied energy level, the confinement energies of the hole and the excited electron, and the bound energy of the exciton (the electron–hole pair):",
                    "score": 0.8602864742279053
                },
                {
                    "id": 6211664,
                    "contents": "Band gap\nList of band gaps Below are band gap values for some selected materials. For a comprehensive list of band gaps in semiconductors, see List of semiconductor materials. Optical versus electronic bandgap In materials with a large exciton binding energy, it is possible for a photon to have just barely enough energy to create an exciton (bound electron–hole pair), but not enough energy to separate the electron and hole (which are electrically attracted to each other). In this situation, there is a distinction between \"optical band gap\" and \"electrical band gap\" (or \"transport gap\"). The optical bandgap is the threshold for photons to be absorbed, while the transport gap is the threshold for creating an electron–hole pair that is not bound together. The optical bandgap is at lower energy than the transport gap.",
                    "score": 0.8601521253585815
                },
                {
                    "id": 16010813,
                    "contents": "Quantum-confined Stark effect\nThe quantum-confined Stark effect (QCSE) describes the effect of an external electric field upon the light absorption spectrum or emission spectrum of a quantum well (QW). In the absence of an external electric field, electrons and holes within the quantum well may only occupy states within a discrete set of energy subbands. Only a discrete set of frequencies of light may be absorbed or emitted by the system. When an external electric field is applied, the electron states shift to lower energies, while the hole states shift to higher energies. This reduces the permitted light absorption or emission frequencies. Additionally, the external electric field shifts electrons and holes to opposite sides of the well, decreasing the overlap integral, which in turn reduces the recombination efficiency (i.e. fluorescence quantum yield) of the system.",
                    "score": 0.8601164221763611
                },
                {
                    "id": 696475,
                    "contents": "Cathodoluminescence\nelectrons and X-rays, which in turn can scatter as well. Such a cascade of scattering events leads to up to 103 secondary electrons per incident electron. These secondary electrons can excite valence electrons into the conduction band when they have a kinetic energy about three times the band gap energy of the material . From there the electron recombines with a hole in the valence band and creates a photon. The excess energy is transferred to phonons and thus heats the lattice. One of the advantages of excitation with an electron beam is that the band gap energy of materials that are investigated is not limited by the energy of the incident light as in the case of photoluminescence. Therefore, in cathodoluminescence, the \"semiconductor\" examined can, in fact, be almost any non-metallic material. In terms of band structure, classical semiconductors, insulators, ceramics, gemstones, minerals, and glasses can be treated the same way.",
                    "score": 0.8597298860549927
                },
                {
                    "id": 928902,
                    "contents": "Exciton\nInteraction Excitons are the main mechanism for light emission in semiconductors at low temperature (when the characteristic thermal energy kT is less than the exciton binding energy), replacing the free electron-hole recombination at higher temperatures. The existence of exciton states may be inferred from the absorption of light associated with their excitation. Typically, excitons are observed just below the band gap. When excitons interact with photons a so-called polariton (or more specifically exciton-polariton) is formed. These excitons are sometimes referred to as dressed excitons. Provided the interaction is attractive, an exciton can bind with other excitons to form a biexciton, analogous to a dihydrogen molecule. If a large density of excitons is created in a material, they can interact with one another to form an electron-hole liquid, a state observed in k-space indirect semiconductors.",
                    "score": 0.8591427803039551
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_7",
        "question": "Although the crystallization of large biological molecules may not be as readily accomplished as that of small molecules, their crystal lattices are no different. Tobacco seed globulin forms face-centred cubic crystals with unit cell dimension of $12.3 \\mathrm{~nm}$ and a density of $1.287 \\mathrm{~g} \\mathrm{~cm}^{-3}$. Determine its molar mass.",
        "golden_answers": [
            "3.61"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 19261869,
                    "contents": "Protein crystallization\nIn 1934, John Desmond Bernal and his student Dorothy Hodgkin discovered that protein crystals surrounded by their mother liquor gave better diffraction patterns than dried crystals. Using pepsin, they were the first to discern the diffraction pattern of a wet, globular protein. Prior to Bernal and Hodgkin, protein crystallography had only been performed in dry conditions with inconsistent and unreliable results. This is the first X‐ray diffraction pattern of a protein crystal. In 1958, the structure of myoglobin (a red protein containing heme), determined by X-ray crystallography, was first reported by John Kendrew. Kendrew shared the 1962 Nobel Prize in Chemistry with Max Perutz for this discovery. Now, based on the protein crystals, the structures of them play a significant role in biochemistry and translational medicine. The basics of protein crystallization",
                    "score": 0.8788604736328125
                },
                {
                    "id": 1337604,
                    "contents": "X-ray crystallography\nProtein crystals are almost always grown in solution. The most common approach is to lower the solubility of its component molecules very gradually; if this is done too quickly, the molecules will precipitate from solution, forming a useless dust or amorphous gel on the bottom of the container. Crystal growth in solution is characterized by two steps: nucleation of a microscopic crystallite (possibly having only 100 molecules), followed by growth of that crystallite, ideally to a diffraction-quality crystal. The solution conditions that favor the first step (nucleation) are not always the same conditions that favor the second step (subsequent growth). The crystallographer's goal is to identify solution conditions that favor the development of a single, large crystal, since larger crystals offer improved resolution of the molecule. Consequently, the solution conditions should disfavor the first step (nucleation) but favor the second (growth), so that only one large crystal forms per",
                    "score": 0.8764141201972961
                },
                {
                    "id": 19261867,
                    "contents": "Protein crystallization\nDevelopment of protein crystallization For over 150 years, scientists have known of the crystallization of protein molecules. In 1840, Friedrich Ludwig Hünefeld accidentally discovered the formation of crystalline material in samples of the earthworm blood held under two glass slides and occasionally observed small plate-like crystals in desiccated swine or human blood samples. These crystals were named as 'haemoglobin', by Felix Hoppe-Seyler in 1864. The seminal findings of Hünefeld inspired many scientists in the future.",
                    "score": 0.8704298734664917
                },
                {
                    "id": 19261885,
                    "contents": "Protein crystallization\nCrystallization of proteins can also be useful in the formulation of proteins for pharmaceutical purposes. See also Crystal engineering Crystal growth Crystal optics Crystal system Crystallization processes Crystallographic database Crystallographic group Diffraction Electron crystallography Electron diffraction Neutron crystallography Neutron diffraction Structural biology X-ray diffraction References External links \"Protein Crystallization and Dumb Luck\". An essay on the haphazard side of protein crystallization by Bob Cudney: http://www.rigaku.com/downloads/journal/Vol16.2.1999/cudney.pdf This page was reproduced (with modifications) with expressed consent from Dr. A. Malcolm Campbell. As of 2010, the original page can be found at http://www.bio.davidson.edu/Courses/Molbio/MolStudents/spring2003/Kogoy/protein.html Protein structure Crystallography",
                    "score": 0.8674607276916504
                },
                {
                    "id": 221787,
                    "contents": "Crystallization (disambiguation)\nCrystallization is the (natural or artificial) formation of highly organized, solid crystals. Crystallization or Crystallize may also refer to: Protein Crystallization, a technique required for protein X-Ray Crystallography Crystallize (Kylie Minogue song) Crystallize (Lindsey Stirling song) Crystallized (song), a song by Young the Giant Crystallised, a song by Haken Crystalised, song by The xx Crystallization (love), the \"falling in love\" process (Stendhal)",
                    "score": 0.8666990399360657
                },
                {
                    "id": 19261870,
                    "contents": "Protein crystallization\nThe theory of protein crystallization",
                    "score": 0.8663880228996277
                },
                {
                    "id": 8957304,
                    "contents": "Fine chemical\ncrystallization processes. In contrast to the isolation of small molecules, the isolation and purification of microbial proteins is tedious and often involves a number of expensive large-scale chromatographic operations.",
                    "score": 0.8659444451332092
                },
                {
                    "id": 4330850,
                    "contents": "Globular protein\nGlobular proteins or spheroproteins are spherical (\"globe-like\") proteins and are one of the common protein types (the others being fibrous, disordered and membrane proteins). Globular proteins are somewhat water-soluble (forming colloids in water), unlike the fibrous or membrane proteins. There are multiple fold classes of globular proteins, since there are many different architectures that can fold into a roughly spherical shape. The term globin can refer more specifically to proteins including the globin fold. Globular structure and solubility The term globular protein is quite old (dating probably from the 19th century) and is now somewhat archaic given the hundreds of thousands of proteins and more elegant and descriptive structural motif vocabulary. The globular nature of these proteins can be determined without the means of modern techniques, but only by using ultracentrifuges or dynamic light scattering techniques.",
                    "score": 0.8653197288513184
                },
                {
                    "id": 1640597,
                    "contents": "Crystal\nCrystallization is a complex and extensively-studied field, because depending on the conditions, a single fluid can solidify into many different possible forms. It can form a single crystal, perhaps with various possible phases, stoichiometries, impurities, defects, and habits. Or, it can form a polycrystal, with various possibilities for the size, arrangement, orientation, and phase of its grains. The final form of the solid is determined by the conditions under which the fluid is being solidified, such as the chemistry of the fluid, the ambient pressure, the temperature, and the speed with which all these parameters are changing. Specific industrial techniques to produce large single crystals (called boules) include the Czochralski process and the Bridgman technique. Other less exotic methods of crystallization may be used, depending on the physical properties of the substance, including hydrothermal synthesis, sublimation, or simply solvent-based crystallization.",
                    "score": 0.8611321449279785
                },
                {
                    "id": 8803075,
                    "contents": "History of molecular biology\nThe secondary and low-resolution tertiary structure of globular proteins was investigated initially by hydrodynamic methods, such as analytical ultracentrifugation and flow birefringence. Spectroscopic methods to probe protein structure (such as circular dichroism, fluorescence, near-ultraviolet and infrared absorbance) were developed in the 1950s. The first atomic-resolution structures of proteins were solved by X-ray crystallography in the 1960s and by NMR in the 1980s. , the Protein Data Bank has over 150,000 atomic-resolution structures of proteins. In more recent times, cryo-electron microscopy of large macromolecular assemblies has achieved atomic resolution, and computational protein structure prediction of small protein domains is approaching atomic resolution. See also History of biology History of biotechnology History of genetics References",
                    "score": 0.8610069751739502
                },
                {
                    "id": 19261884,
                    "contents": "Protein crystallization\nProtein engineering Proteins can be engineered to improve the chance of successful protein crystallization by using techniques like Surface Entropy Reduction or engineering in crystal contacts. Frequently, problematic cysteine residues can be replaced by alanine to avoid disulfide-mediated aggregation, and residues such as lysine, glutamate, and glutamine can be changed to alanine to reduce intrinsic protein flexibility, which can hinder crystallization.. Applications of protein crystallography Macromolecular structures can be determined from protein crystal using a variety of methods, including X-Ray Diffraction/X-ray crystallography, Cryogenic Electron Microscopy (CryoEM) (including Electron Crystallography and Microcrystal Electron Diffraction (MicroED)), Small-angle X-ray scattering, and Neutron diffraction. See also Structural biology. Crystallization of proteins can also be useful in the formulation of proteins for pharmaceutical purposes. See also",
                    "score": 0.8597410917282104
                },
                {
                    "id": 1666830,
                    "contents": "Crystallography\nTechniques Some materials that have been analyzed crystallographically, such as proteins, do not occur naturally as crystals. Typically, such molecules are placed in solution and allowed to slowly crystallize through vapor diffusion. A drop of solution containing the molecule, buffer, and precipitants is sealed in a container with a reservoir containing a hygroscopic solution. Water in the drop diffuses to the reservoir, slowly increasing the concentration and allowing a crystal to form. If the concentration were to rise more quickly, the molecule would simply precipitate out of solution, resulting in disorderly granules rather than an orderly and hence usable crystal.",
                    "score": 0.8593292236328125
                },
                {
                    "id": 25369164,
                    "contents": "Moses Kunitz\nIn addition to his work on crystallization of proteases, Kunitz also performed careful work in enzymology, characterizing the kinetics and thermodynamics of protease reactions. He worked on other proteins as well, in particular ribonucleases, which were popular model systems for their small size and ease of crystallization. During World War II he worked on government-assigned crystallization projects and was noted for the facility with which he crystallized hexokinase. Kunitz was widely recognized specifically for his craftsmanship and technical skill in the laboratory. References External links Kunitz' papers in the Rockefeller Archive 1887 births 1978 deaths American biochemists Rockefeller University faculty Members of the United States National Academy of Sciences Cooper Union alumni Columbia University alumni",
                    "score": 0.8572372198104858
                },
                {
                    "id": 1337608,
                    "contents": "X-ray crystallography\nSeveral factors are known to inhibit or mar crystallization. The growing crystals are generally held at a constant temperature and protected from shocks or vibrations that might disturb their crystallization. Impurities in the molecules or in the crystallization solutions are often inimical to crystallization. Conformational flexibility in the molecule also tends to make crystallization less likely, due to entropy. Molecules that tend to self-assemble into regular helices are often unwilling to assemble into crystals. Crystals can be marred by twinning, which can occur when a unit cell can pack equally favorably in multiple orientations; although recent advances in computational methods may allow solving the structure of some twinned crystals. Having failed to crystallize a target molecule, a crystallographer may try again with a slightly modified version of the molecule; even small changes in molecular properties can lead to large differences in crystallization behavior.",
                    "score": 0.857008159160614
                },
                {
                    "id": 25369163,
                    "contents": "Moses Kunitz\nResearch Kunitz is best known for his efforts in protein crystallization, successfully crystallizing a number of enzymes and enzyme precursor proteins, particularly proteases. Kunitz worked with trypsin and chymotrypsin and their precursors, as well as pepsin. He also studied protease inhibitors and devoted particular effort to the soybean trypsin inhibitor; the inhibitor protein, its domain family, and a soybean cultivar lacking this protein are all named after him. For their role in isolating, purifying, and crystallizing enzymes - a subject underscored by Kunitz' work with Northrop - John H. Northrop, Wendell M. Stanley, and James B. Sumner were awarded the Nobel Prize in Chemistry in 1946. Kunitz himself was nominated three times for a share of a Nobel for this work.",
                    "score": 0.8567995429039001
                },
                {
                    "id": 15427601,
                    "contents": "Cryo bio-crystallography\nCryo bio-crystallography is the application of crystallography to biological macromolecules at cryogenic temperatures. Basic principles Cryo crystallography enables X-ray data collection at cryogenic temperatures, typically 100K. Crystals are transferred from the solution they have grown in (called mother liquor) to a solution with a cryo-protectant to prevent ice formation. Crystals are mounted in a glass fiber (as opposed to a capillary.) Crystals are cooled by dipping directly into liquid nitrogen and then placed in a cryo cold stream. Cryo cooled macromolecular crystals show reduced radiation damage by more than 70 times that at room temperature. Advantages Significant improvement of resolution in data collection Reduced or eliminated radiation damage in crystals Usefulness and applications Crystallography of large biological macromolecules can be achieved while maintaining their solution state. The best known example is the ribosome. References See also Ada Yonath",
                    "score": 0.8561364412307739
                },
                {
                    "id": 1337603,
                    "contents": "X-ray crystallography\nSmall-molecule and macromolecular crystallography differ in the range of possible techniques used to produce diffraction-quality crystals. Small molecules generally have few degrees of conformational freedom, and may be crystallized by a wide range of methods, such as chemical vapor deposition and recrystallization. By contrast, macromolecules generally have many degrees of freedom and their crystallization must be carried out so as to maintain a stable structure. For example, proteins and larger RNA molecules cannot be crystallized if their tertiary structure has been unfolded; therefore, the range of crystallization conditions is restricted to solution conditions in which such molecules remain folded.",
                    "score": 0.8551056385040283
                },
                {
                    "id": 19261881,
                    "contents": "Protein crystallization\nChemical Additives Chemical additives are small chemical compounds that are added to the crystallization process to increase the yield of crystals. The role of small molecules in protein crystallization had not been well thought of in the early days since they were thought of as contaminants in most case. Smaller molecules crystallize better than macromolecules such as proteins, therefore, the use of chemical additives had been limited prior to the study by McPherson. However, this is a powerful aspect of the experimental parameters for crystallization that is important for biochemists and crystallographers to further investigate and apply. Technologies assisting protein crystallization",
                    "score": 0.8527341485023499
                },
                {
                    "id": 10911310,
                    "contents": "Cyclol\nThe cyclol model was consistent with the general properties then attributed to folded proteins. (1) Centrifugation studies had shown that folded proteins were significantly denser than water (~1.4 g/mL) and, thus, tightly packed; Wrinch assumed that dense packing should imply regular packing. (2) Despite their large size, some proteins crystallize readily into symmetric crystals, consistent with the idea of symmetric faces that match up upon association. (3) Proteins bind metal ions; since metal-binding sites must have specific bond geometries (e.g., octahedral), it was plausible to assume that the entire protein also had similarly crystalline geometry. (4) As described above, the cyclol model provided a simple chemical explanation of denaturation and the difficulty of cleaving folded proteins with proteases. (5) Proteins were assumed to be responsible for the synthesis of all biological molecules, including other proteins. Wrinch noted that a fixed, uniform structure would be",
                    "score": 0.8519028425216675
                },
                {
                    "id": 19261866,
                    "contents": "Protein crystallization\nProtein crystallization is the process of formation of a regular array of individual protein molecules stabilized by crystal contacts. If the crystal is sufficiently ordered, it will diffract. Some proteins naturally form crystalline arrays, like aquaporin in the lens of the eye. In the process of protein crystallization, proteins are dissolved in an aqueous environment and sample solution until they reach the supersaturated state. Different methods are used to reach that state such as vapor diffusion, microbatch, microdialysis, and free-interface diffusion. Developing protein crystals is a difficult process influenced by many factors, including pH, temperature, ionic strength in the crystallization solution, and even gravity. Once formed, these crystals can be used in structural biology to study the molecular structure of the protein, particularly for various industrial or medical purposes. Development of protein crystallization",
                    "score": 0.8514496088027954
                },
                {
                    "id": 1170334,
                    "contents": "Protein\nProteins may be purified from other cellular components using a variety of techniques such as ultracentrifugation, precipitation, electrophoresis, and chromatography; the advent of genetic engineering has made possible a number of methods to facilitate purification. Methods commonly used to study protein structure and function include immunohistochemistry, site-directed mutagenesis, X-ray crystallography, nuclear magnetic resonance and mass spectrometry. History and etymology Proteins were recognized as a distinct class of biological molecules in the eighteenth century by Antoine Fourcroy and others, distinguished by the molecules' ability to coagulate or flocculate under treatments with heat or acid. Noted examples at the time included albumin from egg whites, blood serum albumin, fibrin, and wheat gluten.",
                    "score": 0.8513781428337097
                },
                {
                    "id": 21251237,
                    "contents": "Macromolecular assembly\nThe study of MA structure and function is challenging, in particular because of their megadalton size, but also because of their complex compositions and varying dynamic natures. Most have had standard chemical and biochemical methods applied (methods of protein purification and centrifugation, chemical and electrochemical characterization, etc.). In addition, their methods of study include modern proteomic approaches, computational and atomic-resolution structural methods (e.g., X-ray crystallography), small-angle X-ray scattering (SAXS) and small-angle neutron scattering (SANS), force spectroscopy, and transmission electron microscopy and cryo-electron microscopy. Aaron Klug was recognized with the 1982 Nobel Prize in Chemistry for his work on structural elucidation using electron microscopy, in particular for protein-nucleic acid MAs including the tobacco mosaic virus (a structure containing a 6400 base ssRNA molecule and >2000 coat protein molecules). The crystallization and",
                    "score": 0.8505840301513672
                },
                {
                    "id": 8803068,
                    "contents": "History of molecular biology\nProteins were finally shown to be macromolecules of well-defined composition (and not colloidal mixtures) by Theodor Svedberg using analytical ultracentrifugation. The possibility that some proteins are non-covalent associations of such macromolecules was shown by Gilbert Smithson Adair (by measuring the osmotic pressure of hemoglobin) and, later, by Frederic M. Richards in his studies of ribonuclease S. The mass spectrometry of proteins has long been a useful technique for identifying posttranslational modifications and, more recently, for probing protein structure.",
                    "score": 0.8493557572364807
                },
                {
                    "id": 1337606,
                    "contents": "X-ray crystallography\nIt is extremely difficult to predict good conditions for nucleation or growth of well-ordered crystals. In practice, favorable conditions are identified by screening; a very large batch of the molecules is prepared, and a wide variety of crystallization solutions are tested. Hundreds, even thousands, of solution conditions are generally tried before finding the successful one. The various conditions can use one or more physical mechanisms to lower the solubility of the molecule; for example, some may change the pH, some contain salts of the Hofmeister series or chemicals that lower the dielectric constant of the solution, and still others contain large polymers such as polyethylene glycol that drive the molecule out of solution by entropic effects. It is also common to try several temperatures for encouraging crystallization, or to gradually lower the temperature so that the solution becomes supersaturated. These methods require large amounts of the target molecule, as they use high",
                    "score": 0.8486154675483704
                },
                {
                    "id": 11745470,
                    "contents": "Biology\nProteins are the most diverse of the macromolecules, which include enzymes, transport proteins, large signaling molecules, antibodies, and structural proteins. The basic unit (or monomer) of a protein is an amino acid, which has a central carbon atom that is covalently bonded to a hydrogen atom, an amino group, a carboxyl group, and a side chain (or R-group, \"R\" for residue). There are twenty amino acids that make up the building blocks of proteins, with each amino acid having its own unique side chain. The polarity and charge of the side chains affect the solubility of amino acids. An amino acid with a side chain that is polar and electrically charged is soluble as it is hydrophilic whereas an amino acid with a side chain that lacks a charged or an electronegative atom is hydrophobic and therefore tends to coalesce rather than dissolve in water. Proteins have four distinct levels of organization (primary, secondary, tertiary, and quartenary). The primary structure consists of a",
                    "score": 0.8477843403816223
                },
                {
                    "id": 19261873,
                    "contents": "Protein crystallization\nA molecular view going from solution to crystal Crystal formation requires two steps: nucleation and growth. Nucleation is the initiation step for crystallization. At the nucleation phase, protein molecules in solution come together as aggregates to form a stable solid nucleus. As the nucleus forms, the crystal grows bigger and bigger by molecules attaching to this stable nucleus. The nucleation step is critical for crystal formation since it is the first-order phase transition of samples moving from having a high degree of freedom to obtaining an ordered state (aqueous to solid). For the nucleation step to succeed, the manipulation of crystallization parameters is essential. The approach behind getting a protein to crystallize is to yield a lower solubility of the targeted protein in solution. Once the solubility limit is exceeded and crystals are present, crystallization is accomplished. Methods of protein crystallization Vapor diffusion",
                    "score": 0.8473852276802063
                },
                {
                    "id": 8803066,
                    "contents": "History of molecular biology\nThe minimum molecular weight suggested by Mulder's analyses was roughly 9 kDa, hundreds of times larger than other molecules being studied. Hence, the chemical structure of proteins (their primary structure) was an active area of research until 1949, when Fred Sanger sequenced insulin. The (correct) theory that proteins were linear polymers of amino acids linked by peptide bonds was proposed independently and simultaneously by Franz Hofmeister and Emil Fischer at the same conference in 1902. However, some scientists were sceptical that such long macromolecules could be stable in solution. Consequently, numerous alternative theories of the protein primary structure were proposed, e.g., the colloidal hypothesis that proteins were assemblies of small molecules, the cyclol hypothesis of Dorothy Wrinch, the diketopiperazine hypothesis of Emil Abderhalden and the pyrrol/piperidine hypothesis of Troensgard (1942). Most of these theories had difficulties in accounting for the fact that",
                    "score": 0.8473385572433472
                },
                {
                    "id": 8803070,
                    "contents": "History of molecular biology\nThe study of protein folding began in 1910 with a famous paper by Harriette Chick and C. J. Martin, in which they showed that the flocculation of a protein was composed of two distinct processes: the precipitation of a protein from solution was preceded by another process called denaturation, in which the protein became much less soluble, lost its enzymatic activity and became more chemically reactive. In the mid-1920s, Tim Anson and Alfred Mirsky proposed that denaturation was a reversible process, a correct hypothesis that was initially lampooned by some scientists as \"unboiling the egg\". Anson also suggested that denaturation was a two-state (\"all-or-none\") process, in which one fundamental molecular transition resulted in the drastic changes in solubility, enzymatic activity and chemical reactivity; he further noted that the free energy changes upon denaturation were much smaller than those typically involved in chemical reactions. In 1929, Hsien Wu hypothesized that",
                    "score": 0.8464911580085754
                },
                {
                    "id": 19269133,
                    "contents": "Crystallization of polymers\nA very different process is precipitation; it uses a solvent which dissolves individual monomers but not the resulting polymer. When a certain degree of polymerization is reached, the polymerized and partially crystallized product precipitates out of the solution. The rate of crystallization can be monitored by a technique which selectively probes the dissolved fraction, such as nuclear magnetic resonance.",
                    "score": 0.8443560004234314
                },
                {
                    "id": 18288294,
                    "contents": "Christian Cambillau\n• Direction: - Director of the Laboratory of Crystallography and Crystallization of Biological Macromolecules, URA 1296: 07/01/1990 to 12/31/1995 - Laboratory Director \"Architecture and Function of Biological Macromolecules\" (UPR9039 and UMR6098): 1996-2004. • Research management - Member of the Section 21 of the National Committee (1995–2000) - Member of the Jury of Admission Department Sciences de la Vie (2000–2002) - Member of the Scientific Department Sciences de la Vie (2003–2004) • Expertise national or international - Expert at the Directorate of International Research at CNRS (1998–2000). - Expert for orders from the research councils in various countries. - Expert for the Program files HSFP. - Expert for the records of the EU Marie Curie Research Training Grants. - Member of program committee of the international lines of the ESRF and D2AM. - Expert of the European Union (Panel of EOI for the 6th FP). • Consultant - SANOFI, 1990-1993.",
                    "score": 0.8439344763755798
                },
                {
                    "id": 19261874,
                    "contents": "Protein crystallization\nMethods of protein crystallization Vapor diffusion Vapor diffusion is the most commonly employed method of protein crystallization. In this method, droplets containing purified protein, buffer, and precipitant are allowed to equilibrate with a larger reservoir containing similar buffers and precipitants in higher concentrations. Initially, the droplet of protein solution contains comparatively low precipitant and protein concentrations, but as the drop and reservoir equilibrate, the precipitant and protein concentrations increase in the drop. If the appropriate crystallization solutions are used for a given protein, crystal growth occurs in the drop. This method is used because it allows for gentle and gradual changes in concentration of protein and precipitant concentration, which aid in the growth of large and well-ordered crystals.",
                    "score": 0.8434804677963257
                },
                {
                    "id": 12432905,
                    "contents": "History of biochemistry\nThis discovery, that enzymes could be crystallized, meant that scientists eventually could solve their structures by x-ray crystallography. This was first done for lysozyme, an enzyme found in tears, saliva, and egg whites that digests the coating of some bacteria; the structure was solved by a group led by David Chilton Phillips and published in 1965. This high-resolution structure of lysozyme marked the beginning of the field of structural biology and the effort to understand how enzymes work at an atomic level of detail. Metabolism Early metabolic interest",
                    "score": 0.8418617844581604
                },
                {
                    "id": 1690117,
                    "contents": "Enzyme\nThe discovery that enzymes could be crystallized eventually allowed their structures to be solved by x-ray crystallography. This was first done for lysozyme, an enzyme found in tears, saliva and egg whites that digests the coating of some bacteria; the structure was solved by a group led by David Chilton Phillips and published in 1965. This high-resolution structure of lysozyme marked the beginning of the field of structural biology and the effort to understand how enzymes work at an atomic level of detail. Classification and nomenclature Enzymes can be classified by two main criteria: either amino acid sequence similarity (and thus evolutionary relationship) or enzymatic activity. Enzyme activity. An enzyme's name is often derived from its substrate or the chemical reaction it catalyzes, with the word ending in -ase. Examples are lactase, alcohol dehydrogenase and DNA polymerase. Different enzymes that catalyze the same chemical reaction are called isozymes.",
                    "score": 0.8411264419555664
                },
                {
                    "id": 4712268,
                    "contents": "Water of crystallization\nCompared to inorganic salts, proteins crystallize with large amounts of water in the crystal lattice. A water content of 50% is not uncommon for proteins. Applications Knowledge of hydration is essential for calculating the masses for many compounds. The reactivity of many salt-like solids is sensitive to the presence of water. The hydration and dehydration of salts is central to the use of phase-change materials for energy storage. Nomenclature In molecular formulas water of crystallization is indicated in various ways, but is often vague. The terms hydrated compound and hydrate are generally vaguely defined. Position in the crystal structure A salt with associated water of crystallization is known as a hydrate. The structure of hydrates can be quite elaborate, because of the existence of hydrogen bonds that define polymeric structures.",
                    "score": 0.8405847549438477
                },
                {
                    "id": 25042553,
                    "contents": "List of biophysically important macromolecular crystal structures\n1960 - The Hemoglobin crystal structure showed a tetramer of two related chain types and was solved at much lower resolution than the monomeric myoglobin, but it clearly had the same basic 8-helix architecture (now called the \"globin fold\"). Further hemoglobin crystal structures at higher resolution [PDB 1MHB, 1DHB) soon showed the coupled change of both local and quaternary conformation between the oxy and deoxy states of hemoglobin, which explains the cooperativity of oxygen binding in the blood and the allosteric effect of factors such as pH and DPG. For decades hemoglobin was the primary teaching example for the concept of allostery, as well as being an intensive focus of research and discussion on allostery. In 1909, hemoglobin crystals from >100 species were used to relate taxonomy to molecular properties. That book was cited by Perutz in the 1938 report of horse hemoglobin crystals that began his long saga to solve the crystal structure. Hemoglobin crystals are pleochroic -",
                    "score": 0.8405379056930542
                },
                {
                    "id": 4331496,
                    "contents": "Macromolecule\nBecause of their size, macromolecules are not conveniently described in terms of stoichiometry alone. The structure of simple macromolecules, such as homopolymers, may be described in terms of the individual monomer subunit and total molecular mass. Complicated biomacromolecules, on the other hand, require multi-faceted structural description such as the hierarchy of structures used to describe proteins. In British English, the word \"macromolecule\" tends to be called \"high polymer\". Properties Macromolecules often have unusual physical properties that do not occur for smaller molecules. Another common macromolecular property that does not characterize smaller molecules is their relative insolubility in water and similar solvents, instead forming colloids. Many require salts or particular ions to dissolve in water. Similarly, many proteins will denature if the solute concentration of their solution is too high or too low.",
                    "score": 0.8398914337158203
                },
                {
                    "id": 1184636,
                    "contents": "Protein primary structure\nThus, several alternative hypotheses arose. The colloidal protein hypothesis stated that proteins were colloidal assemblies of smaller molecules. This hypothesis was disproved in the 1920s by ultracentrifugation measurements by Theodor Svedberg that showed that proteins had a well-defined, reproducible molecular weight and by electrophoretic measurements by Arne Tiselius that indicated that proteins were single molecules. A second hypothesis, the cyclol hypothesis advanced by Dorothy Wrinch, proposed that the linear polypeptide underwent a chemical cyclol rearrangement C=O + HN C(OH)-N that crosslinked its backbone amide groups, forming a two-dimensional fabric. Other primary structures of proteins were proposed by various researchers, such as the diketopiperazine model of Emil Abderhalden and the pyrrol/piperidine model of Troensegaard in 1942. Although never given much credence, these alternative models were finally disproved when Frederick Sanger successfully sequenced insulin and",
                    "score": 0.8396371006965637
                },
                {
                    "id": 6292529,
                    "contents": "Nucleation\nHowever, modern computers are powerful enough to calculate essentially exact nucleation rates for simple models. These have been compared with the classical theory, for example for the case of nucleation of the crystal phase in the model of hard spheres. This is a model of perfectly hard spheres in thermal motion, and is a simple model of some colloids. For the crystallization of hard spheres the classical theory is a very reasonable approximate theory. So for the simple models we can study, classical nucleation theory works quite well, but we do not know if it works equally well for (say) complex molecules crystallising out of solution.",
                    "score": 0.8392050862312317
                },
                {
                    "id": 1159036,
                    "contents": "Polymer\nWhen applied to polymers, the term crystalline has a somewhat ambiguous usage. In some cases, the term crystalline finds identical usage to that used in conventional crystallography. For example, the structure of a crystalline protein or polynucleotide, such as a sample prepared for x-ray crystallography, may be defined in terms of a conventional unit cell composed of one or more polymer molecules with cell dimensions of hundreds of angstroms or more. A synthetic polymer may be loosely described as crystalline if it contains regions of three-dimensional ordering on atomic (rather than macromolecular) length scales, usually arising from intramolecular folding or stacking of adjacent chains. Synthetic polymers may consist of both crystalline and amorphous regions; the degree of crystallinity may be expressed in terms of a weight fraction or volume fraction of crystalline material. Few synthetic polymers are entirely crystalline. The crystallinity of polymers is characterized by their",
                    "score": 0.8383502960205078
                },
                {
                    "id": 22949178,
                    "contents": "International Organization for Biological Crystallization\nThe International Organization for Biological Crystallization (IOBCr) is a non-profit, scientific organization for scientists who study the crystallization of biological macromolecules and develop crystallographic methodologies for their study. It was founded in 2002 to create a permanent organ for the organization of the International Conferences for the crystallization of Biological Macromolecules (ICCBM). The ICCBM conferences are organized biannually with venues that change regularly to maintain an international character. The objective of the IOBCr is the exchange of research results and encourage practical applications of biological crystallization. It organizes and supports interdisciplinary workshops. The attendance at the ICCBM meetings includes bio-crystallographers, biochemists, physicists, and engineers. The last International Conferences on Crystallization of Biological Macromolecules ICCBM15 was held in Hamburg, Germany. ICCBM meeting locations",
                    "score": 0.8381499648094177
                },
                {
                    "id": 1265118,
                    "contents": "Structural biology\nPepsin crystals were the first proteins to be crystallized for use in X-Ray diffraction, by Theodore Svedberg who received the 1962 Nobel Prize in Chemistry. The first tertiary protein structure, that of Myoglobin, was published in 1958 by John Kendrew. During this time, modeling of protein structures was done using balsa wood or wire models. With the invention of modeling software such as CCP4 in the late 1970s, modeling is now done with computer assistance. Recent developments in the field have included the generation of X-Ray free electron lasers, allowing analysis of previously hidden structures and the use of structural biology in assisting synthetic biology.",
                    "score": 0.8378657102584839
                },
                {
                    "id": 19261868,
                    "contents": "Protein crystallization\nIn 1851, Otto Funke described the process of producing human haemoglobin crystals by diluting red blood cells with solvents, such as pure water, alcohol or ether, followed by slow evaporation of the solvent from the protein solution. In 1871, William T. Preyer, Professor at University of Jena, published a book entitled Die Blutkrystalle (The Crystals of Blood), reviewing the features of haemoglobin crystals from around 50 species of mammals, birds, reptiles and fishes. In 1909, the physiologist Edward T. Reichert, together with the mineralogist Amos P. Brown, published a treatise on the preparation, physiology and geometrical characterization of haemoglobin crystals from several hundreds animals, including extinct species such as the Tasmanian wolf. Increasing protein crystals were found.",
                    "score": 0.8377017378807068
                },
                {
                    "id": 10911298,
                    "contents": "Cyclol\nX-ray crystallography had just begun as a discipline in 1911, and had advanced relatively rapidly from simple salt crystals to crystals of complex molecules such as cholesterol. However, even the smallest proteins have over 1000 atoms, which makes determining their structure far more complex. In 1934, Dorothy Crowfoot Hodgkin had taken crystallographic data on the structure of the small protein, insulin, although the structure of that and other proteins were not solved until the late 1960s. However, pioneering X-ray fiber diffraction data had been collected in the early 1930s for many natural fibrous proteins such as wool and hair by William Astbury, who proposed rudimentary models of secondary structure elements such as the alpha helix and the beta sheet.",
                    "score": 0.8374155759811401
                },
                {
                    "id": 4747602,
                    "contents": "Crystallization\nThe formation of a supersaturated solution does not guarantee crystal formation, and often a seed crystal or scratching the glass is required to form nucleation sites. A typical laboratory technique for crystal formation is to dissolve the solid in a solution in which it is partially soluble, usually at high temperatures to obtain supersaturation. The hot mixture is then filtered to remove any insoluble impurities. The filtrate is allowed to slowly cool. Crystals that form are then filtered and washed with a solvent in which they are not soluble, but is miscible with the mother liquor. The process is then repeated to increase the purity in a technique known as recrystallization. For biological molecules in which the solvent channels continue to be present to retain the three dimensional structure intact, microbatch crystallization under oil and vapor diffusion methods have been the common methods. Typical equipment Equipment for the main industrial processes for crystallization.",
                    "score": 0.8367953300476074
                },
                {
                    "id": 3694810,
                    "contents": "Protein structure\nProtein structure determination Around 90% of the protein structures available in the Protein Data Bank have been determined by X-ray crystallography. This method allows one to measure the three-dimensional (3-D) density distribution of electrons in the protein, in the crystallized state, and thereby infer the 3-D coordinates of all the atoms to be determined to a certain resolution. Roughly 9% of the known protein structures have been obtained by nuclear magnetic resonance (NMR) techniques. For larger protein complexes, cryo-electron microscopy can determine protein structures. The resolution is typically lower than that of X-ray crystallography, or NMR, but the maximum resolution is steadily increasing. This technique is still a particularly valuable for very large protein complexes such as virus coat proteins and amyloid fibers.",
                    "score": 0.8367893099784851
                },
                {
                    "id": 21479996,
                    "contents": "Alexander Dounce\nAlexander Latham Dounce (December 7, 1909 – April 24, 1997) was an American professor of biochemistry. Among his fields of study were the isolation and purification of cellular organelles, protein crystallization, enzymes (specifically catalase), DNA binding proteins, and the chemical basis of protein synthesis. He also invented the Dounce homogenizer, which was named after him. Biography",
                    "score": 0.8367009162902832
                },
                {
                    "id": 1666845,
                    "contents": "Crystallography\nWomen have written many textbooks and research papers in the field of X-ray crystallography. For many years Lonsdale edited the International Tables for Crystallography, which provide information on crystal lattices, symmetry, and space groups, as well as mathematical, physical and chemical data on structures. Olga Kennard of the University of Cambridge, founded and ran the Cambridge Crystallographic Data Centre, an internationally recognized source of structural data on small molecules, from 1965 until 1997. Jenny Pickworth Glusker, a British scientist, co-authored Crystal Structure Analysis: A Primer, first published in 1971 and as of 2010 in its third edition. Eleanor Dodson, an Australian-born biologist, who began as Dorothy Hodgkin's technician, was the main instigator behind CCP4, the collaborative computing project that currently shares more than 250 software tools with protein crystallographers worldwide.",
                    "score": 0.836066484451294
                },
                {
                    "id": 28231742,
                    "contents": "Florence Bell (scientist)\nDNA crystallography In 1937, Astbury became interested in DNA and directed Bell to work on the molecule. Bell came up with a method to stretch out the fibers to make dried films of purified DNA, with which she took x-ray diffraction photographs that were clearer than previous work. Her work confirmed it was a regular, ordered structure with periodicity of 3.3 - 3.4 Å along the axis. She studied the nucleic acids in yeast, pancreases, tobacco mosaic virus and calf thymus. She recognised that the \"beginnings of life are clearly associated with the interaction of proteins and nucleic acids\". Bell and Astbury published an X-ray study on DNA in 1938, describing the nucleotides as a \"Pile of Pennies\". Astbury presented their work at the Cold Spring Harbor Laboratory. At the time, they were unaware that DNA can change conformation from A to B-form with humidity, and as a result their photographs are more blurry than the later Photo 51 x-ray image taken by Gosling in 1952.",
                    "score": 0.8355823159217834
                },
                {
                    "id": 22300011,
                    "contents": "John Garside\nPublications John Garside & Roger Davey (2000) From Molecules to Crystallizers: An Introduction to Crystallization (Oxford Chemistry Primers) John Garside, Alfons Mersmann & Jaroslav Nyvlt (2002)Measurement of Crystal Growth Rates (IChemE, Rugby) S.J. Jancic, J. Garside (1975) \"On the determination of crystallization kinetics from crystal size distribution data\" Chemical Engineering Science, 30, (1975) 1299 S.J. Jancic, J. Garside (1976) \"A new technique for accurate crystal size distribution analysis in an MSMPR crystallizer\" Industrial Crystallization (edited by J.W. Mullin) Plenum Press, New York 1976 J. Garside, S.J. Jancic (1976) \"Prediction and measurement of crystal size distributions for size-dependent growth\", 69-th AICHE Annual Meeting, Chicago, 28 November – 2 December 1976 O. Söhnel, J. Garside, S.J. Jancic (1977) \"Crystallization from solution and the thermodynamics of electrolytes\", Journal of Crystal Growth 39, (1977), 307",
                    "score": 0.8349921107292175
                },
                {
                    "id": 1726021,
                    "contents": "Francis Crick\nMolecular biology In 1954, at the age of 37, Crick completed his PhD thesis: \"X-Ray Diffraction: Polypeptides and Proteins\" and received his degree. Crick then worked in the laboratory of David Harker at Brooklyn Polytechnic Institute, where he continued to develop his skills in the analysis of X-ray diffraction data for proteins, working primarily on ribonuclease and the mechanisms of protein synthesis. David Harker, the American X-ray crystallographer, was described as \"the John Wayne of crystallography\" by Vittorio Luzzati, a crystallographer at the Centre for Molecular Genetics in Gif-sur-Yvette near Paris, who had worked with Rosalind Franklin. After the discovery of the double helix model of DNA, Crick's interests quickly turned to the biological implications of the structure. In 1953, Watson and Crick published another article in Nature which stated: \"it therefore seems likely that the precise sequence of the bases is the code that carries the genetical information\".",
                    "score": 0.8346521854400635
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_8",
        "question": "An electron is accelerated in an electron microscope from rest through a potential difference $\\Delta \\phi=100 \\mathrm{kV}$ and acquires an energy of $e \\Delta \\phi$. What is its final speed?",
        "golden_answers": [
            " 1.88"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1694170,
                    "contents": "Electron\nThe electron microscope directs a focused beam of electrons at a specimen. Some electrons change their properties, such as movement direction, angle, and relative phase and energy as the beam interacts with the material. Microscopists can record these changes in the electron beam to produce atomically resolved images of the material. In blue light, conventional optical microscopes have a diffraction-limited resolution of about 200 nm. By comparison, electron microscopes are limited by the de Broglie wavelength of the electron. This wavelength, for example, is equal to 0.0037 nm for electrons accelerated across a 100,000-volt potential. The Transmission Electron Aberration-Corrected Microscope is capable of sub-0.05 nm resolution, which is more than enough to resolve individual atoms. This capability makes the electron microscope a useful laboratory instrument for high resolution imaging. However, electron microscopes are expensive instruments that are costly to maintain.",
                    "score": 0.9139252305030823
                },
                {
                    "id": 1698801,
                    "contents": "Electron microscope\nAn electron microscope is a microscope that uses a beam of accelerated electrons as a source of illumination. As the wavelength of an electron can be up to 100,000 times shorter than that of visible light photons, electron microscopes have a higher resolving power than light microscopes and can reveal the structure of smaller objects. A scanning transmission electron microscope has achieved better than 50 pm resolution in annular dark-field imaging mode and magnifications of up to about 10,000,000× whereas most light microscopes are limited by diffraction to about 200 nm resolution and useful magnifications below 2000×. Electron microscopes use shaped magnetic fields to form electron optical lens systems that are analogous to the glass lenses of an optical light microscope.",
                    "score": 0.9123210906982422
                },
                {
                    "id": 1698806,
                    "contents": "Electron microscope\nThe original form of the electron microscope, the transmission electron microscope (TEM), uses a high voltage electron beam to illuminate the specimen and create an image. The electron beam is produced by an electron gun, commonly fitted with a tungsten filament cathode as the electron source. The electron beam is accelerated by an anode typically at +100 keV (40 to 400 keV) with respect to the cathode, focused by electrostatic and electromagnetic lenses, and transmitted through the specimen that is in part transparent to electrons and in part scatters them out of the beam. When it emerges from the specimen, the electron beam carries information about the structure of the specimen that is magnified by the objective lens system of the microscope. The spatial variation in this information (the \"image\") may be viewed by projecting the magnified electron image onto a fluorescent viewing screen coated with a phosphor or scintillator material such as zinc sulfide. Alternatively, the image",
                    "score": 0.9065150022506714
                },
                {
                    "id": 200650,
                    "contents": "Electron diffraction\nwhere is the electron rest mass, is the elementary charge and is the speed of light. Substituting the momentum and velocity to the de Broglie equation we receive Relativistic theory In an electron microscope, the accelerating potential is usually several thousand volts, causing the electron to travel at an appreciable fraction of the speed of light. Scanning electron microscopes typically operate at an accelerating voltage of 10,000 volts (10 kV) giving an electron velocity approximately 20% of the speed of light, while a typical TEM operates at 200 kV raising the electron velocity to 70% the speed of light. Therefore, relativistic effects need to be taken into account. The relativistic relation between energy and momentum is It follows then, that the ratio between the electron mass and its rest mass (or Lorentz factor) is Then the relativistic velocity is given by the equation Substitution of the De Broglie equation to the above expression of energy gives",
                    "score": 0.9057863354682922
                },
                {
                    "id": 31590,
                    "contents": "Transmission electron microscopy\nwhere, h is Planck's constant, m0 is the rest mass of an electron and E is the kinetic energy of the accelerated electron. Electrons are usually generated in an electron microscope by a process known as thermionic emission from a filament, usually tungsten, in the same manner as a light bulb, or alternatively by field electron emission. The electrons are then accelerated by an electric potential (measured in volts) and focused by electrostatic and electromagnetic lenses onto the sample. The transmitted beam contains information about electron density, phase and periodicity; this beam is used to form an image. Electron source",
                    "score": 0.8984212875366211
                },
                {
                    "id": 31588,
                    "contents": "Transmission electron microscopy\nBackground Electrons Theoretically, the maximum resolution, d, that one can obtain with a light microscope has been limited by the wavelength of the photons (λ) that are being used to probe the sample and the numerical aperture NA of the system.",
                    "score": 0.8924567699432373
                },
                {
                    "id": 31582,
                    "contents": "Transmission electron microscopy\nAt the time, electrons were understood to be charged particles of matter; the wave nature of electrons was not fully realized until the publication of the De Broglie hypothesis in 1927. Knoll's research group was unaware of this publication until 1932, when they quickly realized that the De Broglie wavelength of electrons was many orders of magnitude smaller than that for light, theoretically allowing for imaging at atomic scales. (Even for electrons with a kinetic energy of just 1 volt the wavelength is already as short as 1.23 nm.) In April 1932, Ruska suggested the construction of a new electron microscope for direct imaging of specimens inserted into the microscope, rather than simple mesh grids or images of apertures. With this device successful diffraction and normal imaging of an aluminium sheet was achieved. However the magnification achievable was lower than with light microscopy. Magnifications higher than those available with a light microscope were achieved in September",
                    "score": 0.8906926512718201
                },
                {
                    "id": 31592,
                    "contents": "Transmission electron microscopy\nnear the sharp tip. The combination of the cathode and these first electrostatic lens elements is often collectively called the \"electron gun\". After it leaves the gun, the beam is typically accelerated by a series of electrostatic plates until it reaches its final voltage and enters the next part of the microscope: The condenser lens system. These upper lenses of the TEM then further focus the electron beam to the desired size and location on the sample.",
                    "score": 0.8894873261451721
                },
                {
                    "id": 4015375,
                    "contents": "Photoemission electron microscopy\nf is the frequency of the incident photon; is the work function; is the maximum kinetic energy of ejected electrons; f0 is the threshold frequency for the photoelectric effect to occur; m is the rest mass of the ejected electron; vm is the speed of the ejected electron. Electron emission microscopy Electron emission microscopy is a type of electron microscopy in which the information carrying beam of electrons originates from the specimen. The source of energy causing the electron emission can be heat (thermionic emission), light (photoelectron emission), ions, or neutral particles, but normally excludes field emission and other methods involving a point source or tip microscopy.",
                    "score": 0.8890724182128906
                },
                {
                    "id": 1862093,
                    "contents": "Microscope\nThe two major types of electron microscopes are transmission electron microscopes (TEMs) and scanning electron microscopes (SEMs). They both have series of electromagnetic and electrostatic lenses to focus a high energy beam of electrons on a sample. In a TEM the electrons pass through the sample, analogous to basic optical microscopy. This requires careful sample preparation, since electrons are scattered strongly by most materials. The samples must also be very thin (below 100 nm) in order for the electrons to pass through it. Cross-sections of cells stained with osmium and heavy metals reveal clear organelle membranes and proteins such as ribosomes. With a 0.1 nm level of resolution, detailed views of viruses (20 – 300 nm) and a strand of DNA (2 nm in width) can be obtained. In contrast, the SEM has raster coils to scan the surface of bulk objects with a fine electron beam. Therefore, the specimen do not necessarily need to be sectioned, but coating with a nanometric metal or",
                    "score": 0.8890218138694763
                },
                {
                    "id": 200651,
                    "contents": "Electron diffraction\nThen the relativistic velocity is given by the equation Substitution of the De Broglie equation to the above expression of energy gives which leads to the final expression for the relativistic wavelength The wavelength of the electrons in a 10 kV SEM is then 12.2 × 10−12 m (12.2 pm) while in a 200 kV TEM the wavelength is 2.5 pm. In comparison, the wavelength of X-rays usually used in X-ray diffraction is in the order of 100 pm (Cu Kα: λ=154 pm). Diffraction on atomic lattice Wavelength of the electron beam used in a typical electron microscope is sufficiently small, that crystal lattice acts as a diffraction grating. Therefore a diffraction pattern can be formed with beams diffracted under certain angles and intensities. Diffraction angles",
                    "score": 0.8882941603660583
                },
                {
                    "id": 1242827,
                    "contents": "Scanning electron microscope\nDetection of secondary electrons",
                    "score": 0.8877708911895752
                },
                {
                    "id": 1862078,
                    "contents": "Microscope\nElectron microscopes In the early 20th century a significant alternative to the light microscope was developed, an instrument that uses a beam of electrons rather than light to generate an image. The German physicist, Ernst Ruska, working with electrical engineer Max Knoll, developed the first prototype electron microscope in 1931, a transmission electron microscope (TEM). The transmission electron microscope works on similar principles to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses. Use of electrons, instead of light, allows for much higher resolution. Development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope by Max Knoll. Although TEMs were being used for research before WWII, and became popular afterwards, the SEM was not commercially available until 1965.",
                    "score": 0.8872690200805664
                },
                {
                    "id": 12603802,
                    "contents": "Low-energy electron microscopy\nIntroduction LEEM differs from conventional electron microscopes in four main ways:",
                    "score": 0.8871797323226929
                },
                {
                    "id": 31607,
                    "contents": "Transmission electron microscopy\nComponents A TEM is composed of several components, which include a vacuum system in which the electrons travel, an electron emission source for generation of the electron stream, a series of electromagnetic lenses, as well as electrostatic plates. The latter two allow the operator to guide and manipulate the beam as required. Also required is a device to allow the insertion into, motion within, and removal of specimens from the beam path. Imaging devices are subsequently used to create an image from the electrons that exit the system.",
                    "score": 0.8866948485374451
                },
                {
                    "id": 1242821,
                    "contents": "Scanning electron microscope\nThe electron beam, which typically has an energy ranging from 0.2 keV to 40 keV, is focused by one or two condenser lenses to a spot about 0.4 nm to 5 nm in diameter. The beam passes through pairs of scanning coils or pairs of deflector plates in the electron column, typically in the final lens, which deflect the beam in the x and y axes so that it scans in a raster fashion over a rectangular area of the sample surface.",
                    "score": 0.8865979909896851
                },
                {
                    "id": 4015378,
                    "contents": "Photoemission electron microscopy\nAs in any emission electron microscope, the objective or cathode lens determines the resolution. The latter is dependent on the electron-optical qualities, such as spherical aberrations, and the energy spread of the photoemitted electrons. The electrons are emitted into the vacuum with an angular distribution close to a cosine square function. A significant velocity component parallel to the surface will decrease the lateral resolution. The faster electrons, leaving the surface exactly along the center line of the PEEM, will also negatively influence the resolution due to the chromatic aberration of the cathode lens. The resolution is inversely proportional to the accelerating field strength at the surface but proportional to the energy spread of the electrons. So resolution r is approximately: In the equation, d is the distance between the specimen and the objective, ΔE is the distribution width of the initial electron energies and U is the accelerating voltage.",
                    "score": 0.8865782022476196
                },
                {
                    "id": 4015379,
                    "contents": "Photoemission electron microscopy\nIn the equation, d is the distance between the specimen and the objective, ΔE is the distribution width of the initial electron energies and U is the accelerating voltage. Besides the cathode or objective lens, situated on the left hand side of Figure 4, two more lenses are utilized to create an image of the specimen: an intermediate three-electrode lens is used to vary the total magnification between 100× if the lens is deactivated, and up to 1000× when needed. On the right-hand side of Figure 4 is the projector, a three electrode lens combined with a two-element deceleration lens. The main task of this lens combination is the deceleration of the fast 20 keV electrons to energies for which the has its highest sensitivity. Such an image intensifier has its best performance for impinging electrons with kinetic energies roughly about 1 keV.",
                    "score": 0.8862031102180481
                },
                {
                    "id": 6105648,
                    "contents": "Scanning transmission electron microscopy\nLow-voltage STEM A low-voltage electron microscope (LVEM) is an electron microscope that is designed to operate at relatively low electron accelerating voltages of between 0.5 and 30 kV. Some LVEMs can function as an SEM, a TEM and a STEM in a single compact instrument. Using a low beam voltage increases image contrast which is especially important for biological specimens. This increase in contrast significantly reduces, or even eliminates the need to stain biological samples. Resolutions of a few nm are possible in TEM, SEM and STEM modes. The low energy of the electron beam means that permanent magnets can be used as lenses and thus a miniature column that does not require cooling can be used. See also Electron beam induced deposition Transmission electron microscopy (TEM) Energy filtered transmission electron microscopy (EFTEM) High-resolution transmission electron microscopy (HRTEM) Scanning confocal electron microscopy (SCEM) Scanning electron microscope (SEM) References",
                    "score": 0.8850622773170471
                },
                {
                    "id": 31624,
                    "contents": "Transmission electron microscopy\nImaging methods Imaging methods in TEM use the information contained in the electron waves exiting from the sample to form an image. The projector lenses allow for the correct positioning of this electron wave distribution onto the viewing system. The observed intensity, I, of the image, assuming sufficiently high quality of imaging device, can be approximated as proportional to the time-averaged squared absolute value of the amplitude of the electron wavefunctions, where the wave that forms the exit beam is denoted by Ψ.",
                    "score": 0.8843674659729004
                },
                {
                    "id": 27871682,
                    "contents": "Correlative light-electron microscopy\nElectron microscope The electron microscope is used to obtain structural information at the nano-scale. Unlike an optical microscope, an electron microscope is able to surpass the diffraction limit of light. This is because the wavelength of accelerated electrons is much shorter than the wavelength of visible light. References Further reading Electron microscopy",
                    "score": 0.8833311796188354
                },
                {
                    "id": 1242801,
                    "contents": "Scanning electron microscope\nA scanning electron microscope (SEM) is a type of electron microscope that produces images of a sample by scanning the surface with a focused beam of electrons. The electrons interact with atoms in the sample, producing various signals that contain information about the surface topography and composition of the sample. The electron beam is scanned in a raster scan pattern, and the position of the beam is combined with the intensity of the detected signal to produce an image. In the most common SEM mode, secondary electrons emitted by atoms excited by the electron beam are detected using a secondary electron detector (Everhart-Thornley detector). The number of secondary electrons that can be detected, and thus the signal intensity, depends, among other things, on specimen topography. Some SEMs can achieve resolutions better than 1 nanometer.",
                    "score": 0.8833292722702026
                },
                {
                    "id": 1242822,
                    "contents": "Scanning electron microscope\nWhen the primary electron beam interacts with the sample, the electrons lose energy by repeated random scattering and absorption within a teardrop-shaped volume of the specimen known as the interaction volume, which extends from less than 100 nm to approximately 5 µm into the surface. The size of the interaction volume depends on the electron's landing energy, the atomic number of the specimen and the specimen's density. The energy exchange between the electron beam and the sample results in the reflection of high-energy electrons by elastic scattering, emission of secondary electrons by inelastic scattering and the emission of electromagnetic radiation, each of which can be detected by specialized detectors. The beam current absorbed by the specimen can also be detected and used to create images of the distribution of specimen current. Electronic amplifiers of various types are used to amplify the signals, which are displayed as variations in brightness on a computer monitor (or, for",
                    "score": 0.8831310868263245
                },
                {
                    "id": 1698802,
                    "contents": "Electron microscope\nElectron microscopes use shaped magnetic fields to form electron optical lens systems that are analogous to the glass lenses of an optical light microscope. Electron microscopes are used to investigate the ultrastructure of a wide range of biological and inorganic specimens including microorganisms, cells, large molecules, biopsy samples, metals, and crystals. Industrially, electron microscopes are often used for quality control and failure analysis. Modern electron microscopes produce electron micrographs using specialized digital cameras and frame grabbers to capture the images. History In 1926, Hans Busch developed the electromagnetic lens.",
                    "score": 0.8823091983795166
                },
                {
                    "id": 16992309,
                    "contents": "Electron mass\nThe electron mass (symbol: me) is the mass of a stationary electron, also known as the invariant mass of the electron. It is one of the fundamental constants of physics. It has a value of about or about , equivalent to an energy of about or about . Terminology The term \"rest mass\" is sometimes used because in special relativity the mass of an object can be said to increase in a frame of reference that is moving relative to that object (or if the object is moving in a given frame of reference). Most practical measurements are carried out on moving electrons. If the electron is moving at a relativistic velocity, any measurement must use the correct expression for mass. Such correction is only substantial for electrons accelerated by voltages of well over 100 kV.",
                    "score": 0.8817096948623657
                },
                {
                    "id": 31589,
                    "contents": "Transmission electron microscopy\nwhere n is the index of refraction of the medium in which the lens is working and α is the maximum half-angle of the cone of light that can enter the lens (see numerical aperture). Early twentieth century scientists theorized ways of getting around the limitations of the relatively large wavelength of visible light (wavelengths of 400–700 nanometers) by using electrons. Like all matter, electrons have both wave and particle properties (as theorized by Louis-Victor de Broglie), and their wave-like properties mean that a beam of electrons can be focused and diffracted much like light can. The wavelength of electrons is related to their kinetic energy via the de Broglie equation, which says that the wavelength is inversely proportional to the momentum. Taking into account relativistic effects (as in a TEM an electron's velocity is a substantial fraction of the speed of light, c) the wavelength is",
                    "score": 0.8815029263496399
                },
                {
                    "id": 9211045,
                    "contents": "High-resolution transmission electron microscopy\nThe interaction of the electron wave with the crystallographic structure of the sample is complex, but a qualitative idea of the interaction can readily be obtained. Each imaging electron interacts independently with the sample. Above the sample, the wave of an electron can be approximated as a plane wave incident on the sample surface. As it penetrates the sample, it is attracted by the positive atomic potentials of the atom cores, and channels along the atom columns of the crystallographic lattice (s-state model). At the same time, the interaction between the electron wave in different atom columns leads to Bragg diffraction. The exact description of dynamical scattering of electrons in a sample not satisfying the weak phase object approximation, which is almost all real samples, still remains the holy grail of electron microscopy. However, the physics of electron scattering and electron microscope image formation are sufficiently well known to allow accurate simulation of electron",
                    "score": 0.8813398480415344
                },
                {
                    "id": 1698812,
                    "contents": "Electron microscope\nThe SEM produces images by probing the specimen with a focused electron beam that is scanned across a rectangular area of the specimen (raster scanning). When the electron beam interacts with the specimen, it loses energy by a variety of mechanisms. The lost energy is converted into alternative forms such as heat, emission of low-energy secondary electrons and high-energy backscattered electrons, light emission (cathodoluminescence) or X-ray emission, all of which provide signals carrying information about the properties of the specimen surface, such as its topography and composition. The image displayed by an SEM maps the varying intensity of any of these signals into the image in a position corresponding to the position of the beam on the specimen when the signal was generated. In the SEM image of an ant shown below and to the right, the image was constructed from signals produced by a secondary electron detector, the normal or conventional imaging mode in most SEMs.",
                    "score": 0.8812440633773804
                },
                {
                    "id": 1698803,
                    "contents": "Electron microscope\nHistory In 1926, Hans Busch developed the electromagnetic lens. According to Dennis Gabor, the physicist Leó Szilárd tried in 1928 to convince him to build an electron microscope, for which he had filed a patent. The first prototype electron microscope, capable of four-hundred-power magnification, was developed in 1931 by the physicist Ernst Ruska and the electrical engineer Max Knoll at the Berlin Technische Hochschule or Berlin Technical University. The apparatus was the first practical demonstration of the principles of electron microscopy. In May of the same year, Reinhold Rudenberg, the scientific director of Siemens-Schuckertwerke, obtained a patent for an electron microscope. In 1932, Ernst Lubcke of Siemens & Halske built and obtained images from a prototype electron microscope, applying the concepts described in Rudenberg's patent.",
                    "score": 0.8807513117790222
                },
                {
                    "id": 7102653,
                    "contents": "Heisenberg's microscope\nQuantum mechanics questions whether an electron actually has a determinate position before it is disturbed by the measurement used to establish said determinate position. Under a more thorough quantum mechanical analysis, an electron has some probability of showing up at any point in the universe, though the probability that it will be far from where one expects becomes very low at great distances from the neighborhood in which it is originally found. In other words, the \"position\" of an electron can only be stated in terms of a probability distribution, as can predictions of where it may move. See also Atom localization Quantum mechanics Basics of quantum mechanics Interpretation of quantum mechanics Philosophical interpretation of classical physics Schrödinger's cat Uncertainty principle Quantum field theory Electromagnetic radiation References Sources External links History of Heisenberg's Microscope Lectures on Heisenberg's Microscope",
                    "score": 0.8803331255912781
                },
                {
                    "id": 14650223,
                    "contents": "Low-voltage electron microscope\nLow-voltage electron microscope (LVEM) is an electron microscope which operates at accelerating voltages of a few kiloelectronvolts or less. Traditional electron microscopes use accelerating voltages in the range of 10-1000 keV. Low voltage imaging in transmitted electrons is possible in many new scanning electron detector. Low cost alternative is dedicated table top low voltage transmission electron microscope. While its architecture is very similar to a conventional transmission electron microscope, it has a few key changes that enable it to take advantage of a 5 keV electron source, but trading off many advantages of higher voltage operations, including higher resolution, possibility of X-ray microanalysis and EELS, etc... Recently a new low voltage transmission electron microscope has been introduced that operates at variable voltage ranges between 6–25 kV. Advantages",
                    "score": 0.8793893456459045
                },
                {
                    "id": 6614930,
                    "contents": "Electron optics\nElectric fields In the case of an applied electrostatic field, an electron will deflect towards the positive gradient of the field. Notably, this crossing of electrostatic field lines means that electrons, as they move through electrostatic fields change the magnitude of their velocity, whereas in magnetic fields, only the velocity direction is modified. As electrons can exhibit non-particle (wave-like) effects such as diffraction, a full analysis of electron paths can be obtained by solving Maxwell's equation—however in many situations, the particle interpretation may provide a sufficient approximation with great reduction in complexity. One further property of electrons is that they interact strongly with matter as they are sensitive to not only the nucleus, but also the matter's electron charge cloud. Therefore, electrons require vacuum to propagate any reasonable distance, such as would be desirable in electron optic system.",
                    "score": 0.8793367743492126
                },
                {
                    "id": 6105627,
                    "contents": "Scanning transmission electron microscopy\nHistory In 1925, Louis de Broglie first theorized the wave-like properties of an electron, with a wavelength substantially smaller than visible light. This would allow the use of electrons to image objects much smaller than the previous diffraction limit set by visible light. The first STEM was built in 1938 by Baron Manfred von Ardenne, working in Berlin for Siemens. However, at the time the results were inferior to those of transmission electron microscopy, and von Ardenne only spent two years working on the problem. The microscope was destroyed in an air raid in 1944, and von Ardenne did not return to his work after World War II.",
                    "score": 0.878810703754425
                },
                {
                    "id": 11844764,
                    "contents": "Electrostatic force microscope\n. Since < 0 this force is always attractive. The electrostatic force can be probed by changing the voltage, and that force is parabolic with respect to the voltage. One note to make is that ΔV is not simply the voltage difference between the tip and sample. Since the tip and sample are often not the same material, and furthermore can be subject to trapped charges, debris, etc., there is a difference between the work functions of the two. This difference, when expressed in terms of a voltage, is called the contact potential difference, VCPD This causes the apex of the parabola to rest at ΔV = Vtip − Vsample − VCPD = 0. Typically, the value of VCPD is on the order of a few hundred millivolts. Forces as small as piconewtons can routinely be detected with this method.",
                    "score": 0.8786476254463196
                },
                {
                    "id": 9211058,
                    "contents": "High-resolution transmission electron microscopy\nBoth methods extend the point resolution of the microscope past the information limit, which is the highest possible resolution achievable on a given machine. The ideal defocus value for this type of imaging is known as Lichte defocus and is usually several hundred nanometers negative. See also Articles Topical review \"Optics of high-performance electron Microscopes\" Sci. Technol. Adv. Mater. 9 (2008) 014107 (30pages) free download CTF Explorer by Max V. Sidorov, freeware program to calculate the contrast transfer function High Resolution Transmission Electron Microscopy Overview Footnotes Electron microscopy techniques Scientific techniques",
                    "score": 0.8779116868972778
                },
                {
                    "id": 7102650,
                    "contents": "Heisenberg's microscope\nHeisenberg's argument Heisenberg supposes that an electron is like a classical particle, moving in the direction along a line below the microscope. Let the cone of light rays leaving the microscope lens and focusing on the electron make an angle with the electron. Let be the wavelength of the light rays. Then, according to the laws of classical optics, the microscope can only resolve the position of the electron up to an accuracy of",
                    "score": 0.8778235912322998
                },
                {
                    "id": 1698805,
                    "contents": "Electron microscope\nTypes Transmission electron microscope (TEM)",
                    "score": 0.8775333166122437
                },
                {
                    "id": 31593,
                    "contents": "Transmission electron microscopy\nManipulation of the electron beam is performed using two physical effects. The interaction of electrons with a magnetic field will cause electrons to move according to the left hand rule, thus allowing for electromagnets to manipulate the electron beam. The use of magnetic fields allows for the formation of a magnetic lens of variable focusing power, the lens shape originating due to the distribution of magnetic flux. Additionally, electrostatic fields can cause the electrons to be deflected through a constant angle. Coupling of two deflections in opposing directions with a small intermediate gap allows for the formation of a shift in the beam path, allowing for beam shifting in TEM, which is important for STEM. From these two effects, as well as the use of an electron imaging system, sufficient control over the beam path is possible for TEM operation. The optical configuration of a TEM can be rapidly changed, unlike that for an optical microscope, as lenses in the beam path can be",
                    "score": 0.8766613602638245
                },
                {
                    "id": 1694091,
                    "contents": "Electron\nThe electron is a subatomic particle (denoted by the symbol or ) whose electric charge is negative one elementary charge. Electrons belong to the first generation of the lepton particle family, and are generally thought to be elementary particles because they have no known components or substructure. The electron has a mass that is approximately 1/1836 that of the proton. Quantum mechanical properties of the electron include an intrinsic angular momentum (spin) of a half-integer value, expressed in units of the reduced Planck constant, ħ. Being fermions, no two electrons can occupy the same quantum state, in accordance with the Pauli exclusion principle. Like all elementary particles, electrons exhibit properties of both particles and waves: they can collide with other particles and can be diffracted like light. The wave properties of electrons are easier to observe with experiments than those of other particles like neutrons and protons because electrons have a lower mass and hence",
                    "score": 0.876348614692688
                },
                {
                    "id": 9211046,
                    "contents": "High-resolution transmission electron microscopy\nthe holy grail of electron microscopy. However, the physics of electron scattering and electron microscope image formation are sufficiently well known to allow accurate simulation of electron microscope images.",
                    "score": 0.8761699199676514
                },
                {
                    "id": 23216993,
                    "contents": "Geometric phase analysis\nSee also High-resolution transmission electron microscopy Fourier transform Transmission electron microscope CrysTBox References Condensed matter physics Electron microscopy Geometric measurement Digital signal processing Applied mathematics",
                    "score": 0.8758389949798584
                },
                {
                    "id": 31661,
                    "contents": "Transmission electron microscopy\nLow-voltage electron microscope A low-voltage electron microscope (LVEM) is operated at relatively low electron accelerating voltage between 5–25 kV. Some of these can be a combination of SEM, TEM and STEM in a single compact instrument. Low voltage increases image contrast which is especially important for biological specimens. This increase in contrast significantly reduces, or even eliminates the need to stain. Resolutions of a few nm are possible in TEM, SEM and STEM modes. The low energy of the electron beam means that permanent magnets can be used as lenses and thus a miniature column that does not require cooling can be used. Cryo-TEM Main article: Transmission electron cryomicroscopy",
                    "score": 0.8755996823310852
                },
                {
                    "id": 31574,
                    "contents": "Transmission electron microscopy\nTransmission electron microscopy (TEM) is a microscopy technique in which a beam of electrons is transmitted through a specimen to form an image. The specimen is most often an ultrathin section less than 100 nm thick or a suspension on a grid. An image is formed from the interaction of the electrons with the sample as the beam is transmitted through the specimen. The image is then magnified and focused onto an imaging device, such as a fluorescent screen, a layer of photographic film, or a sensor such as a scintillator attached to a charge-coupled device.",
                    "score": 0.8755750060081482
                },
                {
                    "id": 27118353,
                    "contents": "Direct methods (electron microscopy)\n, also known as the structure factor, is the Fourier transform of a three-dimensional periodic function (i.e. the periodic crystal potential), and it defines the intensity measured during a diffraction experiment. can also be written in a polar form , where is a specific reflection in reciprocal space. has an amplitude term (i.e. ) and a phase term (i.e. ). The phase term contains the position information in this form. During a diffraction experiment, the intensity of the reflections are measured as : This is a straightforward method of obtaining the amplitude term of the structure factor. However, the phase term, which contains position information from the crystal potential, is lost. Analogously, for electron diffraction performed in a transmission electron microscope, the exit wave function of the electron beam from the crystal in real and reciprocal space can be written respectively as:",
                    "score": 0.875479519367218
                },
                {
                    "id": 1698804,
                    "contents": "Electron microscope\nIn the following year, 1933, Ruska built the first electron microscope that exceeded the resolution attainable with an optical (light) microscope. Four years later, in 1937, Siemens financed the work of Ernst Ruska and Bodo von Borries, and employed Helmut Ruska, Ernst's brother, to develop applications for the microscope, especially with biological specimens. Also in 1937, Manfred von Ardenne pioneered the scanning electron microscope. Siemens produced the first commercial electron microscope in 1938. The first North American electron microscopes were constructed in the 1930, at the Washington State University by Anderson and Fitzsimmons and the University of Toronto, by Eli Franklin Burton and students Cecil Hall, James Hillier, and Albert Prebus. Siemens produced a transmission electron microscope (TEM) in 1939. Although current transmission electron microscopes are capable of two million-power magnification, as scientific instruments, they remain based upon Ruska's prototype.",
                    "score": 0.8749169707298279
                },
                {
                    "id": 6614928,
                    "contents": "Electron optics\nElectron optics is a mathematical framework for the calculation of electron trajectories along electromagnetic fields. The term optics is used because magnetic and electrostatic lenses act upon a charged particle beam similarly to optical lenses upon a light beam. Electron optics calculations are crucial for the design of electron microscopes and particle accelerators. In the paraxial approximation, trajectory calculations can be carried out using ray transfer matrix analysis. Electron properties Electrons are charged particles (point charges with rest mass) with spin 1/2 (hence they are fermions). Electrons can be accelerated by suitable electric (or magnetic) fields, thereby acquiring kinetic energy. Given sufficient voltage, the electron can be accelerated sufficiently fast to exhibit measurable relativistic effects. According to wave particle duality, electrons can also be considered as matter waves with properties such as wavelength, phase and amplitude.",
                    "score": 0.8744679689407349
                },
                {
                    "id": 31591,
                    "contents": "Transmission electron microscopy\nFrom the top down, the TEM consists of an emission source or cathode, which may be a tungsten filament or needle, or a lanthanum hexaboride (LaB6) single crystal source. The gun is connected to a high voltage source (typically ~100–300 kV) and, given sufficient current, the gun will begin to emit electrons either by thermionic or field electron emission into the vacuum. In the case of a thermionic source, the electron source is typically mounted in a Wehnelt cylinder to provide preliminary focus of the emitted electrons into a beam while also stabilizing the current using a passive feedback circuit. A field emission source uses instead electrostatic electrodes called an extractor, a suppressor, and a gun lens, with different voltages on each, to control the electric field shape and intensity near the sharp tip. The combination of the cathode and these first electrostatic lens elements is often collectively called the \"electron gun\". After it leaves the gun, the beam is typically",
                    "score": 0.8741964101791382
                },
                {
                    "id": 14650224,
                    "contents": "Low-voltage electron microscope\nAdvantages Higher contrast A substantial decrease of electron energy allows for a significant improvement of contrast of light elements. The comparison images below show that decreasing the acceleration voltage from 80 kV to 5 kV significantly enhances the contrast of test samples. The improved contrast is a direct result of increased electron scattering associated with a reduced accelerating voltage. LVEM brings an enhancement of imaging contrast nearly twenty times higher than for 100 kV. This is very promising for biological specimens which are composed from light elements and don't exhibit sufficient contrast in classical TEMs.",
                    "score": 0.8739610314369202
                },
                {
                    "id": 31602,
                    "contents": "Transmission electron microscopy\nwith implementation, with manufacturers using custom lens configurations, such as in spherical aberration corrected instruments, or TEMs using energy filtering to correct electron chromatic aberration.",
                    "score": 0.8737066984176636
                },
                {
                    "id": 1694106,
                    "contents": "Electron\nThe German-born British physicist Arthur Schuster expanded upon Crookes's experiments by placing metal plates parallel to the cathode rays and applying an electric potential between the plates. The field deflected the rays toward the positively charged plate, providing further evidence that the rays carried negative charge. By measuring the amount of deflection for a given level of current, in 1890 Schuster was able to estimate the charge-to-mass ratio of the ray components. However, this produced a value that was more than a thousand times greater than what was expected, so little credence was given to his calculations at the time. This is because it was assumed that the charge carriers were much heavier hydrogen or nitrogen atoms. Schuster's estimates would subsequently turn out to be largely correct. In 1892 Hendrik Lorentz suggested that the mass of these particles (electrons) could be a consequence of their electric charge.",
                    "score": 0.8734047412872314
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_9",
        "question": "The following data show how the standard molar constant-pressure heat capacity of sulfur dioxide varies with temperature. By how much does the standard molar enthalpy of $\\mathrm{SO}_2(\\mathrm{~g})$ increase when the temperature is raised from $298.15 \\mathrm{~K}$ to $1500 \\mathrm{~K}$ ?",
        "golden_answers": [
            " 62.2"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1249236,
                    "contents": "Specific heat capacity\nThe specific heat capacities of gases can be measured at constant volume, by enclosing the sample in a rigid container. On the other hand, measuring the specific heat capacity at constant volume can be prohibitively difficult for liquids and solids, since one often would need impractical pressures in order to prevent the expansion that would be caused by even small increases in temperature. Instead, the common practice is to measure the specific heat capacity at constant pressure (allowing the material to expand or contract as it wishes), determine separately the coefficient of thermal expansion and the compressibility of the material, and compute the specific heat capacity at constant volume from these data according to the laws of thermodynamics. Units",
                    "score": 0.89744633436203
                },
                {
                    "id": 1249245,
                    "contents": "Specific heat capacity\nFor example, the molar heat capacity of nitrogen at constant volume is (at 15 °C, 1 atm), which is . That is the value expected from theory if each molecule had 5 degrees of freedom. These turn out to be three degrees of the molecule's velocity vector, plus two degrees from its rotation about an axis through the center of mass and perpendicular to the line of the two atoms. Because of those two extra degrees of freedom, the specific heat capacity of (736 J⋅K−1⋅kg−1) is greater than that of an hypothetical monatomic gas with the same molecular mass 28 (445 J⋅K−1⋅kg−1), by a factor of .",
                    "score": 0.8962328433990479
                },
                {
                    "id": 1249246,
                    "contents": "Specific heat capacity\nThis value for the specific heat capacity of nitrogen is practically constant from below −150 °C to about 300 °C. In that temperature range, the two additional degrees of freedom that correspond to vibrations of the atoms, stretching and compressing the bond, are still \"frozen out\". At about that temperature, those modes begin to \"un-freeze\", and as a result starts to increase rapidly at first, then slower as it tends to another constant value. It is 35.5 J⋅K−1⋅mol−1 at 1500 °C, 36.9 at 2500 °C, and 37.5 at 3500 °C. The last value corresponds almost exactly to the predicted value for 7 degrees of freedom per molecule. Derivations of heat capacity Relation between specific heat capacitiesexpansion]], is the isothermal compressibility, and is density. A derivation is discussed in the article Relations between specific heats. For an ideal gas, if is expressed as molar density in the above equation, this equation reduces simply to Mayer's relation,",
                    "score": 0.8933402299880981
                },
                {
                    "id": 5597099,
                    "contents": "Molar heat capacity\nThe molar heat capacity of a chemical substance is the amount of energy that must be added, in the form of heat, to one mole of the substance in order to cause an increase of one unit in its temperature. Alternatively, it is the heat capacity of a sample of the substance divided by the amount of substance of the sample; or also the specific heat capacity of the substance times its molar mass. The SI unit of specific heat is joule per kelvin per mole, J⋅K−1⋅mol−1. Like the specific heat, measured the molar heat capacity of a substance, especially a gas, may be significantly higher when the sample is allowed to expand as it is heated (at constant pressure, or isobaric) than when is heated in a closed vessel that prevents expansion (at constant volume, or isochoric). The ratio between the two, however, is the same heat capacity ratio obtained from the corresponding specific heat capacities.",
                    "score": 0.8908977508544922
                },
                {
                    "id": 25882714,
                    "contents": "Table of specific heat capacities\nIn the last column, major departures of solids at standard temperatures from the Dulong–Petit law value of 3 R, are usually due to low atomic weight plus high bond strength (as in diamond) causing some vibration modes to have too much energy to be available to store thermal energy at the measured temperature. For gases, departure from 3 R per mole of atoms is generally due to two factors: (1) failure of the higher quantum-energy-spaced vibration modes in gas molecules to be excited at room temperature, and (2) loss of potential energy degree of freedom for small gas molecules, simply because most of their atoms are not bonded maximally in space to other atoms, as happens in many solids. A Assuming an altitude of 194 metres above mean sea level (the worldwide median altitude of human habitation), an indoor temperature of 23 °C, a dewpoint of 9 °C (40.85% relative humidity), and 760 mmHg sea level–corrected barometric pressure (molar water vapor content = 1.16%).",
                    "score": 0.8903714418411255
                },
                {
                    "id": 1249247,
                    "contents": "Specific heat capacity\nFor an ideal gas, if is expressed as molar density in the above equation, this equation reduces simply to Mayer's relation, where and are intensive property heat capacities expressed on a per mole basis at constant pressure and constant volume, respectively. Specific heat capacity The specific heat capacity of a material on a per mass basis is which in the absence of phase transitions is equivalent to where is the heat capacity of a body made of the material in question, is the mass of the body, is the volume of the body, and is the density of the material.",
                    "score": 0.8900946974754333
                },
                {
                    "id": 5597130,
                    "contents": "Molar heat capacity\nAnother way of stating this, is that the volume-specific heat capacity (volumetric heat capacity) of solid elements is roughly a constant. The molar volume of solid elements is very roughly constant, and (even more reliably) so also is the molar heat capacity for most solid substances. These two factors determine the volumetric heat capacity, which as a bulk property may be striking in consistency. For example, the element uranium is a metal that has a density almost 36 times that of the metal lithium, but uranium's specific heat capacity on a volumetric basis (i.e. per given volume of metal) is only 18% larger than lithium's.",
                    "score": 0.888858437538147
                },
                {
                    "id": 5597107,
                    "contents": "Molar heat capacity\nIn chemistry, heat amounts are still often measured in calories. Confusingly, two units with that name, denoted \"cal\" or \"Cal\", have been commonly used to measure amounts of heat: the \"small calorie\" (or \"gram-calorie\", \"cal\") is 4.184 J, exactly. The \"grand calorie\" (also \"kilocalorie\", \"kilogram-calorie\", or \"food calorie\"; \"kcal\" or \"Cal\") is 1000 small calories, that is, 4184 J, exactly. When heat is measured in these units, the unit of specific heat is usually 1 cal/(°C⋅mol) (\"small calorie\") = 4.184 J⋅K−1⋅mol−1 1 kcal/(°C⋅mol) (\"large calorie\") = 4184 J⋅K−1⋅mol−1. The molar heat capacity of a substance has the same dimension as the heat capacity of an object; namely, L2⋅M⋅T−2⋅Θ−1, or M(L/T)2/Θ. (Indeed, it is the heat capacity of the object that consists of an Avogadro number of molecules of the substance.) Therefore, the SI unit J⋅K−1⋅mol−1 is equivalent to kilogram metre squared per second squared per kelvin (kg⋅m2⋅K−1⋅s−2). Physical basis of molar heat capacity",
                    "score": 0.8883338570594788
                },
                {
                    "id": 5597131,
                    "contents": "Molar heat capacity\nHowever, the average atomic volume in solid elements is not quite constant, so there are deviations from this principle. For instance, arsenic, which is only 14.5% less dense than antimony, has nearly 59% more specific heat capacity on a mass basis. In other words; even though an ingot of arsenic is only about 17% larger than an antimony one of the same mass, it absorbs about 59% more heat for a given temperature rise. The heat capacity ratios of the two substances closely follows the ratios of their molar volumes (the ratios of numbers of atoms in the same volume of each substance); the departure from the correlation to simple volumes, in this case, is due to lighter arsenic atoms being significantly more closely packed than antimony atoms, instead of similar size. In other words, similar-sized atoms would cause a mole of arsenic to be 63% larger than a mole of antimony, with a correspondingly lower density, allowing its volume to more closely mirror its heat capacity behavior.",
                    "score": 0.8880793452262878
                },
                {
                    "id": 1249230,
                    "contents": "Specific heat capacity\nThe term specific heat may also refer to the ratio between the specific heat capacities of a substance at a given temperature and of a reference substance at a reference temperature, such as water at 15 °C; much in the fashion of specific gravity. Specific heat capacity is also related to other intensive measures of heat capacity with other denominators. If the amount of substance is measured as a number of moles, one gets the molar heat capacity instead, whose SI unit is joule per kelvin per mole, J⋅mol−1⋅K−1. If the amount is taken to be the volume of the sample (as is sometimes done in engineering), one gets the volumetric heat capacity, whose SI unit is joule per kelvin per cubic meter, J⋅m−3⋅K−1. One of the first scientists to use the concept was Joseph Black, an 18th-century medical doctor and professor of medicine at Glasgow University. He measured the specific heat capacities of many substances, using the term capacity for heat.",
                    "score": 0.8874543309211731
                },
                {
                    "id": 5597124,
                    "contents": "Molar heat capacity\nThe following table shows the experimental molar heat capacities at constant pressure cP,m of the above polyatomic gases at standard temperature (25 °C = 298 K), at 500 °C, and at 5000 °C, and the apparent number of degrees of freedom f* estimated by the formula f* = 2cP,m/R − 2: (*) At 3000C Specific heat of solids",
                    "score": 0.8869216442108154
                },
                {
                    "id": 1039013,
                    "contents": "Volumetric heat capacity\nThis quantity is used almost exclusively for liquids and solids, since for gases it may be confused with the \"specific heat capacity at constant volume\", which generally has very different values. International standards now recommend that \"specific heat capacity\" always refer to capacity per unit of mass. Therefore, the word \"volumetric\" should always be used for this quantity.",
                    "score": 0.8867108821868896
                },
                {
                    "id": 646155,
                    "contents": "Standard molar entropy\nMolar entropy is not same for all gases. Under identical conditions, it is greater for a heavier gas. See also Entropy Heat Gibbs free energy Helmholtz free energy Standard state Third law of thermodynamics References External links Standard Thermodynamic Properties of Chemical Substances Table Chemical properties Thermodynamic entropy",
                    "score": 0.8858902454376221
                },
                {
                    "id": 5823422,
                    "contents": "Heat capacities of the elements (data page)\nSpecific heat capacity Notes All values refer to 25 °C and to the thermodynamically stable standard state at that temperature unless noted. Values from CRC refer to \"100 kPa (1 bar or 0.987 standard atmospheres)\". Lange indirectly defines the values to be at a standard state pressure of \"1 atm (101325 Pa)\", although citing the same NBS and JANAF sources among others. It is assumed this inexactly refers to \"ambient pressure\". References CRC As quoted in an online version of: David R. Lide (ed), CRC Handbook of Chemistry and Physics, 84th Edition. CRC Press. Boca Raton, Florida, 2003; Section 4, Properties of the Elements and Inorganic Compounds; Heat Capacity of the Elements at 25 °C",
                    "score": 0.8847076892852783
                },
                {
                    "id": 10795751,
                    "contents": "Thermodynamic databases for pure substances\nin heat content symbols as 298). All of these terms mean the molar heat content for a substance in its normal standard state above a reference temperature of 298.15 K. Data for gases is for the hypothetical ideal gas at the designated standard pressure. The SI unit for enthalpy is J/mol, and is a positive number above the reference temperature. The heat content has been measured and tabulated for virtually all known substances, and is commonly expressed as a polynomial function of temperature. The heat content of an ideal gas is independent of pressure (or volume), but the heat content of real gases varies with pressure, hence the need to define the state for the gas (real or ideal) and the pressure. Note that for some thermodynamic databases such as for steam, the reference temperature is 273.15 K (0 °C).",
                    "score": 0.8834932446479797
                },
                {
                    "id": 3450276,
                    "contents": "William Giauque\nHis researches and that of his students included a large number of entropy determinations from low temperature measurements, particularly on condensed gases. The entropies and other thermodynamic properties of many gases were also determined from quantum statistics and molecular energy levels available from band spectra as well as other sources. His correlated investigations of the entropy of oxygen with Dr. Herrick L. Johnston, led to the discovery of oxygen isotopes 17 and 18 in the Earth's atmosphere and showed that physicists and chemists had been using different scales of atomic weight for years without recognising it. Personal life In 1932, Giauque married Dr. Muriel Frances Ashley and they had two sons. He died on March 28, 1982, in Berkeley, California. Notes References External links National Academy of Sciences biography including the Nobel Lecture on December 12, 1949 Some Consequences of Low Temperature Research in Chemical Thermodynamics .",
                    "score": 0.8832413554191589
                },
                {
                    "id": 1249273,
                    "contents": "Specific heat capacity\nIdeal gas For an ideal gas, evaluating the partial derivatives above according to the equation of state, where R is the gas constant, for an ideal gas Substituting this equation reduces simply to Mayer's relation: The differences in heat capacities as defined by the above Mayer relation is only exact for an ideal gas and would be different for any real gas. See also Specific heat of melting (Enthalpy of fusion) Specific heat of vaporization (Enthalpy of vaporization) Frenkel line Heat capacity ratio Heat equation Heat transfer coefficient History of thermodynamics Joback method (Estimation of heat capacities) Latent heat Material properties (thermodynamics) Quantum statistical mechanics R-value (insulation) Specific heat of vaporization Specific melting heat Statistical mechanics Table of specific heat capacities Thermal mass Thermodynamic databases for pure substances Thermodynamic equations Volumetric heat capacity Notes References",
                    "score": 0.8824635744094849
                },
                {
                    "id": 5597120,
                    "contents": "Molar heat capacity\nOn the other hand, electrons and nuclei can exist in excited states and, in a few exceptional cases, they may be active even at room temperature, or even at cryogenic temperatures. Polyatomic gases The set of all possible ways to infinitesimally displace the n atoms of a polyatomic gas molecule is a linear space of dimension 3n, because each atom can be independently displaced in each of three orthogonal axis directions. However, some three of these dimensions are just translation of the molecule by an infinitesimal displacement vector, and others are just rigid rotations of it by an infinitesimal angle about some axis. Still others may correspond to relative rotation of two parts of the molecule about a single bond that connects them.",
                    "score": 0.8817130327224731
                },
                {
                    "id": 905492,
                    "contents": "Thermodynamic temperature\nDifferent molecules absorb different amounts of internal energy for each incremental increase in temperature; that is, they have different specific heat capacities. High specific heat capacity arises, in part, because certain substances’ molecules possess more internal degrees of freedom than others do. For instance, room-temperature nitrogen, which is a diatomic molecule, has five active degrees of freedom: the three comprising translational motion plus two rotational degrees of freedom internally. Not surprisingly, in accordance with the equipartition theorem, nitrogen has five-thirds the specific heat capacity per mole (a specific number of molecules) as do the monatomic gases. Another example is gasoline (see table showing its specific heat capacity). Gasoline can absorb a large amount of heat energy per mole with only a modest temperature change because each molecule comprises an average of 21 atoms and therefore has many internal degrees of freedom. Even larger, more complex",
                    "score": 0.8812304735183716
                },
                {
                    "id": 5597126,
                    "contents": "Molar heat capacity\nIt follows that, in molecular solids, the heat capacity per mole of molecules will usually be close to 3nR, where n is the number of atoms per molecule. Thus n atoms of a solid should in principle store twice as much energy as n atoms of a monatomic gas. One way to look at this result is to observe that the monatomic gas can only store energy as kinetic energy of the atoms, whereas the solid can store it also as potential energy of the bonds strained by the vibrations. The atom-molar heat capacity of a polyatomic gas approaches that of a solid as the number n of atoms per molecule increases. As in the case f gases, some of the vibration modes will be \"frozen out\" at low temperatures, especially in solids with light and tightly bound atoms, causing the atom-molar heat capacity to be less than this theoretical limit. Indeed, the atom-molar (or specific) heat capacity of a solid substance tends toward zero, as the temperature approaches absolute zero.",
                    "score": 0.8811084032058716
                },
                {
                    "id": 1249241,
                    "contents": "Specific heat capacity\nPhysical basis of specific heat capacity The temperature of a sample of a substance reflects the average kinetic energy of its constituent particles (atoms or molecules) relative to its center of mass. However, not all energy provided to a sample of a substance will go into raising its temperature, exemplified via the equipartition theorem. Monatomic gases Quantum mechanics predicts that, at room temperature and ordinary pressures, an isolated atom in a gas cannot store any significant amount of energy except in the form of kinetic energy. Thus, heat capacity per mole is the same for all monatomic gases (such as the noble gases). More precisely, and , where is the ideal gas unit (which is the product of Boltzmann conversion constant from kelvin microscopic energy unit to the macroscopic energy unit joule, and the Avogadro number).",
                    "score": 0.8810244202613831
                },
                {
                    "id": 6465470,
                    "contents": "Carbon dioxide (data page)\nPhase diagram Liquid/vapor equilibrium thermodynamic data The table below gives thermodynamic data of liquid CO2 in equilibrium with its vapor at various temperatures. Heat content data, heat of vaporization, and entropy values are relative to the liquid state at 0 °C temperature and 3483 kPa pressure. To convert heat values to joules per mole values, multiply by 44.095 g/mol. To convert densities to moles per liter, multiply by 22.678 cm3 mol/(L·g). Data obtained from CRC Handbook of Chemistry and Physics, 44th ed. pages 2560–2561, except for critical temperature line (31.1 °C) and temperatures −30 °C and below, which are taken from Lange's Handbook of Chemistry, 10th ed. page 1463. Spectral data Notes References Carbon dioxide Chemical data pages Chemical data pages cleanup",
                    "score": 0.8809024095535278
                },
                {
                    "id": 1249262,
                    "contents": "Specific heat capacity\nFrom the results of the previous section, dividing through by the mass gives the relation A related parameter to is , the volumetric heat capacity. In engineering practice, for solids or liquids often signifies a volumetric heat capacity, rather than a constant-volume one. In such cases, the specific heat capacity is often explicitly written with the subscript , as . Of course, from the above relationships, for solids one writes For pure homogeneous chemical compounds with established molecular or molar mass, or a molar quantity, heat capacity as an intensive property can be expressed on a per-mole basis instead of a per-mass basis by the following equations analogous to the per mass equations: where n is the number of moles in the body or thermodynamic system. One may refer to such a per-mole quantity as molar heat capacity to distinguish it from specific heat capacity on a per-mass basis.",
                    "score": 0.8807137608528137
                },
                {
                    "id": 680041,
                    "contents": "Gas constant\nHowever, following the 2019 redefinition of the SI base units, R now has an exact value defined in terms of other exactly defined physical constants. Specific gas constant The specific gas constant of a gas or a mixture of gases (Rspecific) is given by the molar gas constant divided by the molar mass (M) of the gas or mixture. Just as the ideal gas constant can be related to the Boltzmann constant, so can the specific gas constant by dividing the Boltzmann constant by the molecular mass of the gas. Another important relationship comes from thermodynamics. Mayer's relation relates the specific gas constant to the specific heat capacities for a calorically perfect gas and a thermally perfect gas. where cp is the specific heat capacity for a constant pressure and cv is the specific heat capacity for a constant volume.",
                    "score": 0.8805280923843384
                },
                {
                    "id": 1039015,
                    "contents": "Volumetric heat capacity\nTypical values The volumetric heat capacity of solid materials at room temperatures and above varies widely, from about 1.2 MJ⋅K−1⋅m−3 (for example bismuth) to 3.4 MJ⋅K−1⋅m−3 (for example iron). This is mostly due to differences in the physical size of atoms. Atoms vary greatly in density, with the heaviest often being more dense, and thus are closer to taking up the same average volume in solids than their mass alone would predict. If all atoms were the same size, molar and volumetric heat capacity would be proportional and differ by only a single constant reflecting ratios of the atomic molar volume of materials (their atomic density). An additional factor for all types of specific heat capacities (including molar specific heats) then further reflects degrees of freedom available to the atoms composing the substance, at various temperatures.",
                    "score": 0.8803219795227051
                },
                {
                    "id": 1249242,
                    "contents": "Specific heat capacity\nTherefore, the specific heat capacity (per unit of mass, not per mole) of a monatomic gas will be inversely proportional to its (adimensional) atomic weight . That is, approximately, For the noble gases, from helium to xenon, these computed values are Polyatomic gases On the other hand, a polyatomic gas molecule (consisting of two or more atoms bound together) can store heat energy in other forms besides its kinetic energy. These forms include rotation of the molecule, and vibration of the atoms relative to its center of mass.",
                    "score": 0.8798607587814331
                },
                {
                    "id": 1039018,
                    "contents": "Volumetric heat capacity\nVolumetric heat capacity of gases Large complex gas molecules may have high heat capacities per mole (of molecules), but their heat capacities per mole of atoms are very similar to those of liquids and solids, again differing by less than a factor of two per mole of atoms. This factor of two represents vibrational degrees of freedom available in solids vs. gas molecules of various complexities.",
                    "score": 0.8797105550765991
                },
                {
                    "id": 5597125,
                    "contents": "Molar heat capacity\n(*) At 3000C Specific heat of solids In most solids (but not all), the molecules have a fixed mean position and orientation, and therefore the only degrees of freedom available are the vibrations of the atoms. Thus the specific heat is proportional to the number of atoms (not molecules) per unit of mass, which is the Dulong–Petit law. Other contributions may come from magnetic degrees of freedom in solids, but these rarely make substantial contributions. and electronic Since each atom of the solid contributes one independent vibration mode, the number of degrees of freedom in n atoms is 6n. Therefore, the heat capacity of a sample of a solid substance is expected to be 3RNa, or (24.94 J/K)Na, where Na is the number of moles of atoms in the sample, not molecules. Said another way, the atom-molar heat capacity of a solid substance is expected to be 3R = 24.94 J⋅K−1⋅mol−1, where \"amol\" denotes an amount of the solid that contains the Avogadro number of atoms.",
                    "score": 0.879692554473877
                },
                {
                    "id": 5597106,
                    "contents": "Molar heat capacity\nThe value of cV,m is always less than the value of cP,m. This difference is particularly notable in gases where values under constant pressure are typically 30% to 66.7% greater than those at constant volume. All methods for the measurement of specific heat apply to molar heat capacity as well. Units The SI unit of molar heat capacity heat is joule per kelvin per mole (J/(K⋅mol), J/(K mol), J K−1 mol−1, etc.). Since an increment of temperature of one degree Celsius is the same as an increment of one kelvin, that is the same as joule per degree Celsius per mole (J/(°C⋅mol)).",
                    "score": 0.8796917200088501
                },
                {
                    "id": 1002181,
                    "contents": "Standard enthalpy of formation\nFor example, the standard enthalpy of formation of carbon dioxide would be the enthalpy of the following reaction under the above conditions: C(s, graphite) + O2(g) → CO2(g) All elements are written in their standard states, and one mole of product is formed. This is true for all enthalpies of formation. The standard enthalpy of formation is measured in units of energy per amount of substance, usually stated in kilojoule per mole (kJ mol−1), but also in kilocalorie per mole, joule per mole or kilocalorie per gram (any combination of these units conforming to the energy per mass or amount guideline). All elements in their standard states (oxygen gas, solid carbon in the form of graphite, etc.) have a standard enthalpy of formation of zero, as there is no change involved in their formation.",
                    "score": 0.8785437345504761
                },
                {
                    "id": 5597110,
                    "contents": "Molar heat capacity\nTherefore, the specific heat (per unit of mass, not per mole) of a monatomic gas will be inversely proportional to its (adimensional) atomic weight A. That is, approximately, cV = (12470 J⋅K−1⋅kg−1)/A cP = (20786 J⋅K−1⋅kg−1)/A Molar heat capacity of polyatomic gases Degrees of freedom A polyatomic molecule (consisting of two or more atoms bound together) can store heat energy in other forms besides its kinetic energy. These forms include rotation of the molecule, and vibration of the atoms relative to its center of mass.",
                    "score": 0.878093957901001
                },
                {
                    "id": 14764560,
                    "contents": "Relations between heat capacities\nIn thermodynamics, the heat capacity at constant volume, , and the heat capacity at constant pressure, , are extensive properties that have the magnitude of energy divided by temperature. Relations The laws of thermodynamics imply the following relations between these two heat capacities (Gaskell 2003:23): Here is the thermal expansion coefficient: is the isothermal compressibility (the inverse of the bulk modulus): and is the isentropic compressibility: A corresponding expression for the difference in specific heat capacities (intensive properties) at constant volume and constant pressure is: where ρ is the density of the substance under the applicable conditions. The corresponding expression for the ratio of specific heat capacities remains the same since the thermodynamic system size-dependent quantities, whether on a per mass or per mole basis, cancel out in the ratio because specific heat capacities are intensive properties. Thus:",
                    "score": 0.8777260780334473
                },
                {
                    "id": 5597108,
                    "contents": "Molar heat capacity\nPhysical basis of molar heat capacity Molar heat capacity of monatomic gases The temperature of a sample of a substance reflects the average kinetic energy of its constituent particles (atoms or molecules) relative to its center of mass. Quantum mechanics predicts that, at room temperature and ordinary pressures, an isolated atom in a gas cannot store any significant amount of energy except in the form of kinetic energy. Therefore, when a certain number N of atoms of a monatomic gas receives an input ΔQ of heat energy, in a container of fixed volume, the kinetic energy of each atom will increase by ΔQ/N, independently of the atom's mass. This assumption is the foundation of the theory of ideal gases.",
                    "score": 0.8774203658103943
                },
                {
                    "id": 1249271,
                    "contents": "Specific heat capacity\nThen, from the fundamental thermodynamic relation it follows that This equation can be rewritten as where is the coefficient of thermal expansion, is the isothermal compressibility, both depending on the state . The heat capacity ratio, or adiabatic index, is the ratio of the heat capacity at constant pressure to heat capacity at constant volume. It is sometimes also known as the isentropic expansion factor.",
                    "score": 0.8764524459838867
                },
                {
                    "id": 5597101,
                    "contents": "Molar heat capacity\nA closely related property of a substance is the heat capacity per mole of atoms, or atom-molar heat capacity, in which the heat capacity of the sample is divided by the number of moles of atoms instead of moles of molecules. So, for example, the atom-molar heat capacity of water is 1/3 of its molar heat capacity, namely 25.3 J⋅K−1⋅mol−1. In informal chemistry contexts, the molar heat capacity may be called just \"heat capacity\" or \"specific heat\". However, international standards now recommend that \"specific heat capacity\" always refer to capacity per unit of mass, to avoid possible confusion. Therefore, the word \"molar\", not \"specific\", should always be used for this quantity. Molar specific gas of presser Cp Def:- The amount of heat required raise temperature of One mole of gas throw 1℃ &1°K at constant pressure is called molar specific gas of pressure",
                    "score": 0.8761489987373352
                },
                {
                    "id": 1039024,
                    "contents": "Volumetric heat capacity\nvery roughly constant, and (even more reliably) so also is the molar heat capacity for most solid substances. These two factors determine the volumetric heat capacity, which as a bulk property may be striking in consistency. For example, the element uranium is a metal which has a density almost 36 times that of the metal lithium, but uranium's volumetric heat capacity is only about 20% larger than lithium's.",
                    "score": 0.8760824799537659
                },
                {
                    "id": 1249234,
                    "contents": "Specific heat capacity\nThe value of is usually less than the value of . This difference is particularly notable in gases where values under constant pressure are typically 30% to 66.7% greater than those at constant volume. Hence the heat capacity ratio of gases is typically between 1.3 and 1.67. Applicability The specific heat capacity can be defined and measured for gases, liquids, and solids of fairly general composition and molecular structure. These include gas mixtures, solutions and alloys, or heterogenous materials such as milk, sand, granite, and concrete, if considered at a sufficiently large scale. The specific heat capacity can be defined also for materials that change state or composition as the temperature and pressure change, as long as the changes are reversible and gradual. Thus, for example, the concepts are definable for a gas or liquid that dissociates as the temperature increases, as long as the products of the dissociation promptly and completely recombine when it drops.",
                    "score": 0.8758227825164795
                },
                {
                    "id": 1039017,
                    "contents": "Volumetric heat capacity\nFor gases at room temperature, the range of volumetric heat capacities per atom (not per molecule) only varies between different gases by a small factor less than two, because every ideal gas has the same molar volume. Thus, each gas molecule occupies the same mean volume in all ideal gases, regardless of the type of gas (see kinetic theory). This fact gives each gas molecule the same effective \"volume\" in all ideal gases (although this volume/molecule in gases is far larger than molecules occupy on average in solids or liquids). Thus, in the limit of ideal gas behavior (which many gases approximate except at low temperatures and/or extremes of pressure) this property reduces differences in gas volumetric heat capacity to simple differences in the heat capacities of individual molecules. As noted, these differ by a factor depending on the degrees of freedom available to particles within the molecules.",
                    "score": 0.8756207227706909
                },
                {
                    "id": 1249239,
                    "contents": "Specific heat capacity\nCalories In chemistry, heat amounts were often measured in calories. Confusingly, two units with that name, denoted \"cal\" or \"Cal\", have been commonly used to measure amounts of heat: the \"small calorie\" (or \"gram-calorie\", \"cal\") is 4.184 J, exactly. It was originally defined so that the specific heat capacity of liquid water would be 1 cal⋅°C−1⋅g−1. The \"grand calorie\" (also \"kilocalorie\", \"kilogram-calorie\", or \"food calorie\"; \"kcal\" or \"Cal\") is 1000 small calories, that is, 4184 J, exactly. It was originally defined so that the specific heat capacity of water would be 1 Cal⋅°C−1⋅kg−1. While these units are still used in some contexts (such as kilogram calorie in nutrition), their use is now deprecated in technical and scientific fields. When heat is measured in these units, the unit of specific heat capacity is usually 1 cal⋅°C−1⋅g−1 (\"small calorie\") = 1 Cal⋅°C−1⋅kg−1 = 1 kcal⋅°C−1⋅kg−1 (\"large calorie\") = 4184 J⋅kg−1⋅K−1.",
                    "score": 0.8753464818000793
                },
                {
                    "id": 5597119,
                    "contents": "Molar heat capacity\nAccording to classical mechanics, since atoms have non-zero size, they should also have three rotational degrees of freedom, or f = 6 in total. Likewise, the diatomic nitrogen molecule should have an additional rotation mode, namely about the line of the two atoms; and thus have f = 6 too. In the classical view, each of these modes should store an equal share of the heat energy. However, according to quantum mechanics, the energy difference between the allowed (quantized) rotation states is inversely proportional to the moment of inertia about the corresponding axis of rotation. Because the moment of inertia of a single atom is exceedingly small, the activation temperature for its rotational modes is extremely high. The same applies to the moment of inertia of a diatomic molecule (or a linear polyatomic one) about the internuclear axis, which is why that mode of rotation is not active in general.",
                    "score": 0.8740577697753906
                },
                {
                    "id": 2969565,
                    "contents": "Germain Henri Hess\nLike most of his colleagues, Hess was primarily an experimental chemist interested in the discovery and analysis of new substances. However, he also developed a strong interest for theoretical investigations. In particular, he wondered how chemical affinity relates to heat in chemical reactions. His experiments on various hydrates of sulfuric acid showed that the heat released when they formed was always the same, whether the reactions proceeded directly or through intermediates (1840). Hess thus formulated a special case of the conservation of energy two years before Julius Robert von Mayer stated a more general principle, in 1842. Hess was fully aware of the importance of his own contribution. In 1842, Hess proposed the law of thermoneutrality, which states that no heat is evolved in the exchange reactions of neutral salts in aqueous solution. A full explanation would only be given 45 years later, in terms of electrolytic dissociation, by the Swedish chemist Svante Arrhenius.",
                    "score": 0.8737553954124451
                },
                {
                    "id": 1039014,
                    "contents": "Volumetric heat capacity\nHistory Dulong and Petit predicted in 1818 that the product of solid substance density and specific heat capacity (ρcp) would be constant for all solids. This amounted to a prediction that volumetric heat capacity in solids would be constant. In 1819 they found that volumetric heat capacities were not quite constant, but that the most constant quantity was the heat capacity of solids adjusted by the presumed weight of the atoms of the substance, as defined by Dalton (the Dulong–Petit law). This quantity was proportional to the heat capacity per atomic weight (or per molar mass), which suggested that it is the heat capacity per atom (not per unit of volume) which is closest to being a constant in solids. Eventually it became clear that heat capacities per particle for all substances in all states are the same, to within a factor of two, so long as temperatures are not in the cryogenic range.",
                    "score": 0.8735794425010681
                },
                {
                    "id": 6465469,
                    "contents": "Carbon dioxide (data page)\nVapor pressure of solid and liquid Table data obtained from CRC Handbook of Chemistry and Physics 44th ed. Annotation \"(s)\" indicates equilibrium temperature of vapor over solid. Otherwise temperature is equilibrium of vapor over liquid. For kPa values, where datum is whole numbers of atmospheres exact kPa values are given, elsewhere 2 significant figures derived from mm Hg data. Phase diagram",
                    "score": 0.8724751472473145
                },
                {
                    "id": 26909407,
                    "contents": "Specific quantity\nSpecific gas constant, per molar mass Specific gravity, relative density with respect to water (density per water density) Specific heat of vaporization, enthalpy of vaporization, vaporizing heat per mole Specific humidity, mass of water vapor per unit mass dry air Specific impulse, impulse (momentum change) per unit of propellant (either per unit of propellant mass, or per unit of propellant by Earth-weight) Specific mass, actually meaning volume-specific mass, or mass per unit volume. Same as density Specific melting heat, enthalpy of fusion; melting heat per mole Specific modulus, elastic modulus per mass density Specific properties of a substance Specific resistance (disambiguation), several scientific meanings Specific rotation of a chemical, angle of optical rotation α of plane-polarized light per standard sample with a path length of one decimeter and a sample concentration of one gram per millilitre",
                    "score": 0.8724634647369385
                },
                {
                    "id": 1249251,
                    "contents": "Specific heat capacity\nHeat capacity at absolute zero From the definition of entropy the absolute entropy can be calculated by integrating from zero kelvins temperature to the final temperature Tf The heat capacity must be zero at zero temperature in order for the above integral not to yield an infinite absolute entropy, thus violating the third law of thermodynamics. One of the strengths of the Debye model is that (unlike the preceding Einstein model) it predicts the proper mathematical form of the approach of heat capacity toward zero, as absolute zero temperature is approached.",
                    "score": 0.8722800016403198
                },
                {
                    "id": 5597137,
                    "contents": "Molar heat capacity\nSee also Quantum statistical mechanics Heat capacity ratio Statistical mechanics Thermodynamic equations Thermodynamic databases for pure substances Heat equation Heat transfer coefficient Heat of mixing Latent heat Material properties (thermodynamics) Joback method (Estimation of heat capacities) Specific heat of melting (Enthalpy of fusion) Specific heat of vaporization (Enthalpy of vaporization) Volumetric heat capacity Thermal mass R-value (insulation) Storage heater Frenkel line References Physical quantities Thermodynamic properties",
                    "score": 0.8716995716094971
                },
                {
                    "id": 2675698,
                    "contents": "Chemical energy\nthe measured heat change is not always equal to the internal energy change, because pressure-volume work also releases or absorbs energy. (The heat change at constant pressure is equal to the enthalpy change, in this case the enthalpy of reaction, if initial and final temperatures are equal).",
                    "score": 0.8715877532958984
                },
                {
                    "id": 1701685,
                    "contents": "Equation of state\nIn 1787 the French physicist Jacques Charles found that oxygen, nitrogen, hydrogen, carbon dioxide, and air expand to roughly the same extent over the same 80-kelvin interval. This is known today as Charles's law. Later, in 1802, Joseph Louis Gay-Lussac published results of similar experiments, indicating a linear relationship between volume and temperature:Dalton's law (1801) of partial pressure states that the pressure of a mixture of gases is equal to the sum of the pressures of all of the constituent gases alone.",
                    "score": 0.8712772130966187
                },
                {
                    "id": 5743729,
                    "contents": "Heat capacity ratio\nReal-gas relations As temperature increases, higher-energy rotational and vibrational states become accessible to molecular gases, thus increasing the number of degrees of freedom and lowering . For a real gas, both and increase with increasing temperature, while continuing to differ from each other by a fixed constant (as above, ), which reflects the relatively constant difference in work done during expansion for constant pressure vs. constant volume conditions. Thus, the ratio of the two values, , decreases with increasing temperature. For more information on mechanisms for storing heat in gases, see the gas section of specific heat capacity. While at 273 K (0 °C), Monatomic gases such as the noble gases He, Ne, and Ar all have the same value of , that being 1.664. Thermodynamic expressions",
                    "score": 0.8708996772766113
                },
                {
                    "id": 19923972,
                    "contents": "Entropy production\nwith CV the molar heat capacity at constant volume and R the molar ideal gas constant. The system is an adiabatic closed system, so the entropy increase during the mixing of the two gases is equal to the entropy production. It is given by As the initial and final temperature are the same the temperature terms plays no role, so we can focus on the volume terms. The result is Introducing the concentration x = na/nt = Va/Vt we arrive at the well known expression",
                    "score": 0.8706215620040894
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_10",
        "question": "Suppose that the normalized wavefunction for an electron in a carbon nanotube of length $L=10.0 \\mathrm{~nm}$ is: $\\psi=(2 / L)^{1 / 2} \\sin (\\pi x / L)$. Calculate the probability that the electron is between $x=4.95 \\mathrm{~nm}$ and $5.05 \\mathrm{~nm}$.",
        "golden_answers": [
            " 0.020"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1627503,
                    "contents": "Carbon nanotube\nIn theory, a nanotorus is a carbon nanotube bent into a torus (doughnut shape). Nanotori are predicted to have many unique properties, such as magnetic moments 1000 times larger than that previously expected for certain specific radii. Properties such as magnetic moment, thermal stability, etc. vary widely depending on the radius of the torus and the radius of the tube.",
                    "score": 0.9016318917274475
                },
                {
                    "id": 1627512,
                    "contents": "Carbon nanotube\nBecause of its nanoscale cross-section, electrons propagate only along the tube's axis. As a result, carbon nanotubes are frequently referred to as one-dimensional conductors. The maximum electrical conductance of a single-walled carbon nanotube is 2G0, where G0 = 2e2/h is the conductance of a single ballistic quantum channel.",
                    "score": 0.9002100229263306
                },
                {
                    "id": 18504583,
                    "contents": "Ballistic conduction in single-walled carbon nanotubes\nFor a system with dense states, the discrete sum can be approximated by an integral: In CNT FETs, the charge carriers move either left (negative velocity) or right (positive velocity) and the resulting net current is called drain current. The source potential controls the right-moving, and the drain potential - the left moving carriers and if the source potential is set to zero, the Fermi energy at the drain subsequently decreases to yield positive drain voltage. The total drain current is computed as a sum of all contributing subbands in the semiconductor CNT, but given the low voltages used with nanoscale electronics, higher subbands can be effectively ignored and the drain current is given only by the contribution of the first subband: where and is the quantum resistance. The expression for gives the ballistic current dependence on the voltage in a CNT FET with ideal contacts.",
                    "score": 0.8868223428726196
                },
                {
                    "id": 9147910,
                    "contents": "Fermi point\nFermi point (Nanoscience) The Fermi point is one particular electron state. The Fermi point refers to an event chirality of electrons is involved and the diameter of a carbon nanotube for which the nanotube becomes metallic. As the structure of a carbon nanotube determines the energy levels that the carbon's electrons may occupy, the structure affects macroscopic properties of the nanotube structure, most notably electrical and thermal conductivity. Flat graphite is a conductor except when rolled up into small cylinders. This circular structure inhibits the internal flow of electrons and the graphite becomes a semiconductor; a transition point forms between the valence band and conduction band. This point is called the Fermi point. If the diameter of the carbon nanotube is sufficiently great, the necessary transition phase disappears and the nanotube may be considered a conductor.",
                    "score": 0.8835268616676331
                },
                {
                    "id": 1627494,
                    "contents": "Carbon nanotube\nThe thinnest carbon nanotube proper is the armchair structure with type (2,2), which has a diameter of 0.3 nm. This nanotube was grown inside a multi-walled carbon nanotube. Assigning of the carbon nanotube type was done by a combination of high-resolution transmission electron microscopy (HRTEM), Raman spectroscopy, and density functional theory (DFT) calculations. The thinnest freestanding single-walled carbon nanotube is about 0.43 nm in diameter. Researchers suggested that it can be either (5,1) or (4,2) SWCNT, but the exact type of the carbon nanotube remains questionable. (3,3), (4,3), and (5,1) carbon nanotubes (all about 0.4 nm in diameter) were unambiguously identified using aberration-corrected high-resolution transmission electron microscopy inside double-walled CNTs. Length",
                    "score": 0.8823872804641724
                },
                {
                    "id": 17593008,
                    "contents": "Carbon nanotube quantum dot\nA carbon nanotube quantum dot (CNT QD) is a small region of a carbon nanotube in which electrons are confined. Formation A CNT QD is formed when electrons are confined to a small region within a carbon nanotube. This is normally accomplished by application of a voltage to a gate electrode, dragging the valence band of the CNT down in energy, thereby causing electrons to pool in a region in the vicinity of the electrode. Experimentally this is accomplished by laying a CNT on a silicon dioxide surface, sitting on a doped silicon wafer. This can be done by chemical vapor deposition using carbon monoxide. The silicon wafer serves as the gate electrode. Metallic leads can then be laid over the nanotube in order to connect the CNT QD up to an electrical circuit. Electronic structure",
                    "score": 0.8786852955818176
                },
                {
                    "id": 16225531,
                    "contents": "Thermodynamics of nanostructures\nThermal conductance is then calculated using the Landauer formula: Carbon nanotubes As nanoscale graphitic structures, carbon nanotubes are of great interest for their thermal properties. The low-temperature specific heat and thermal conductivity show direct evidence of 1-D quantization of the phonon band structure. Modeling of the low-temperature specific heat allows determination of the on-tube phonon velocity, the splitting of phonon subbands on a single tube, and the interaction between neighboring tubes in a bundle.",
                    "score": 0.8781114816665649
                },
                {
                    "id": 1627482,
                    "contents": "Carbon nanotube\nStructure of SWNTs Basic details The structure of an ideal (infinitely long) single-walled carbon nanotube is that of a regular hexagonal lattice drawn on an infinite cylindrical surface, whose vertices are the positions of the carbon atoms. Since the length of the carbon-carbon bonds is fairly fixed, there are constraints on the diameter of the cylinder and the arrangement of the atoms on it.",
                    "score": 0.8774417042732239
                },
                {
                    "id": 15382604,
                    "contents": "Optical properties of carbon nanotubes\nThe pairs (n,m) that describe distinct tube structures are those with 0 ≤ m ≤ n and n > 0. All geometric properties of the tube, such as diameter, chiral angle, and symmetries, can be computed from these indices. The type also determines the electronic structure of the tube. Specifically, the tube behaves like a metal if |m–n| is a multiple of 3, and like a semiconductor otherwise. Zigzag and armchair tubes Tubes of type (n,m) with n=m (chiral angle = 30°) are called \"armchair\" and those with m=0 (chiral angle = 0°) \"zigzag\". These tubes have mirror symmetry, and can be viewed as stacks of simple closed paths (\"zigzag\" and \"armchair\" paths, respectively). Electronic structure The optical properties of carbon nanotubes are largely determined by their unique electronic structure. The rolling up of the graphene lattice affects that structure in ways that depend strongly on the geometric structure type (n,m). Van Hove singularities",
                    "score": 0.8763279318809509
                },
                {
                    "id": 15382606,
                    "contents": "Optical properties of carbon nanotubes\nThe energies between the Van Hove singularities depend on the nanotube structure. Thus by varying this structure, one can tune the optoelectronic properties of carbon nanotube. Such fine tuning has been experimentally demonstrated using UV illumination of polymer-dispersed CNTs. Optical transitions are rather sharp (~10 meV) and strong. Consequently, it is relatively easy to selectively excite nanotubes having certain (n, m) indices, as well as to detect optical signals from individual nanotubes. Kataura plot",
                    "score": 0.8761166334152222
                },
                {
                    "id": 1627493,
                    "contents": "Carbon nanotube\nwhich must evaluate to integers. Physical limits Narrowest examples If n and m are too small, the structure described by the pair (n,m) will describe a molecule that cannot be reasonably called a \"tube\", and may not even be stable. For example, the structure theoretically described by the pair (1,0) (the limiting \"zigzag\" type) would be just a chain of carbons. That is a real molecule, the carbyne; which has some characteristics of nanotubes (such as orbital hybridization, high tensile strength, etc.) — but has no hollow space, and may not be obtainable as a condensed phase. The pair (2,0) would theoretically yield a chain of fused 4-cycles; and (1,1), the limiting \"armchair\" structure, would yield a chain of bi-connected 4-rings. These structures may not be realizable.",
                    "score": 0.8745935559272766
                },
                {
                    "id": 17593009,
                    "contents": "Carbon nanotube quantum dot\nElectronic structure The CNT QD has interesting properties as a result of the strong correlation between the confined electrons. In addition to this the electrons possess orbital angular momentum, as is characteristic of CNT electrons. Spin-orbit coupling has also been shown to be significant in these systems. These properties are often probed by connecting the nanotube to two metallic leads and measuring the conductance of the system. Many-body systems The CNT QD connected to metallic leads constitutes a genuine many-body system, due to the electron correlations. Therefore, Wilson's Numerical renormalization group is often used to study the CNT QD. The CNT QD is modelled as an Anderson-type model, which can be reduced by Schrieffer-Wolff transformation to an effective Kondo-type model at low temperature.",
                    "score": 0.8744207620620728
                },
                {
                    "id": 15382607,
                    "contents": "Optical properties of carbon nanotubes\nKataura plot The band structure of carbon nanotubes having certain (n, m) indexes can be easily calculated. A theoretical graph based on these calculations was designed in 1999 by Hiromichi Kataura to rationalize experimental findings. A Kataura plot relates the nanotube diameter and its bandgap energies for all nanotubes in a diameter range. The oscillating shape of every branch of the Kataura plot reflects the intrinsic strong dependence of the SWNT properties on the (n, m) index rather than on its diameter. For example, (10, 1) and (8, 3) tubes have almost the same diameter, but very different properties: the former is a metal, but the latter is a semiconductor. Optical properties Optical absorption",
                    "score": 0.874163031578064
                },
                {
                    "id": 27473661,
                    "contents": "Christian Schönenberger\nIn 1999 he published three of his most-cited and most impactful papers that report key experiments in nanoelectronics. He demonstrated electronic quantum interference by measuring the Aharonov–Bohm effect in multi-walled carbon nanotubes and by realizing the quantum optical Hanbury Brown and Twiss effect for the first time with electrons and demonstrated the anti-bunching effects arising from their fermionic statistics and he demonstrated electron transport through DNA molecules.",
                    "score": 0.8713112473487854
                },
                {
                    "id": 15382603,
                    "contents": "Optical properties of carbon nanotubes\nThe (n,m) notation Alternatively, the structure can be described by two integer indices (n,m) that describe the width and direction of that hypothetical strip as coordinates in a fundamental reference frame of the graphene lattice. If the atoms around any 6-member ring of the graphene are numbered sequentially from 1 to 6, the two vectors u and v of that frame are the displacements from atom 1 to atoms 3 and 5, respectively. Those two vectors have the same length, and their directions are 60 degrees apart. The vector w = n u + m v is then interpreted as the circumference of the unrolled tube on the graphene lattice; it relates each point A1 on one edge of the strip to the point A2 on the other edge that will be identified with it as the strip is rolled up. The chiral angle α is then the angle between u and w.",
                    "score": 0.8712090849876404
                },
                {
                    "id": 1627478,
                    "contents": "Carbon nanotube\nCarbon nanotubes (CNTs) are tubes made of carbon with diameters typically measured in nanometers. Carbon nanotubes often refer to single-wall carbon nanotubes (SWCNTs) with diameters in the range of a nanometer. They were discovered independently in 1993 by Iijima and and Bethune et al. in carbon arc chambers similar to those used to produce fullerenes. Single-wall carbon nanotubes are one of the allotropes of carbon, intermediate between fullerene cages and flat graphene. Although not made this way, single-wall carbon nanotubes can be idealized as cutouts from a two-dimensional hexagonal lattice of carbon atoms rolled up along one of the Bravais lattice vectors of the hexagonal lattice to form a hollow cylinder. In this construction, periodic boundary conditions are imposed over the length of this roll up vector to yield a helical lattice of seamlessly bonded carbon atoms on the cylinder surface.",
                    "score": 0.8709304332733154
                },
                {
                    "id": 16225538,
                    "contents": "Thermodynamics of nanostructures\nPhonon density of states for nanotubes The phonon density of states is to calculated through band structure of isolated nanotubes, which is studied in Saito et al. and Sanchez-Portal et al. When a graphene sheet is ‘‘rolled’’ into a nanotube, the 2-D band structure folds into a large number of 1-D subbands. In a (10,10) tube, for instance, the six phonon bands (three acoustic and three optical) of the graphene sheet become 66 separate 1-D subbands. A direct result of this folding is that the nanotube density of states has a number of sharp peaks due to 1-D van Hove singularities, which are absent in graphene and graphite. Despite the presence of these singularities, the overall density of states is similar at high energies, so that the high temperature specific heat should be roughly equal as well. This is to be expected: the high-energy phonons are more reflective of carbon–carbon bonding than the geometry of the graphene sheet.",
                    "score": 0.8707252740859985
                },
                {
                    "id": 1627490,
                    "contents": "Carbon nanotube\nnanotube has exactly one pair (n,m) that satisfies those conditions, which is called the tube's type. Conversely, for every type there is a hypothetical nanotube. In fact, two nanotubes have the same type if and only if one can be conceptually rotated and translated so as to match the other exactly. Instead of the type (n,m), the structure of a carbon nanotube can be specified by giving the length of the vector w (that is, the circumference of the nanotube), and the angle α between the directions of u and w, which may range from 0 (inclusive) to 60 degrees clockwise (exclusive). If the diagram is drawn with u horizontal, the latter is the tilt of the strip away from the vertical.",
                    "score": 0.8701297044754028
                },
                {
                    "id": 1627485,
                    "contents": "Carbon nanotube\nthe directions of their three bonds. Half the atoms have their three bonds directed the same way, and half have their three bonds rotated 180 degrees relative to the first half. The atoms A1 and A2, which correspond to the same atom A on the cylinder, must be in the same class. It follows that the circumference of the tube and the angle of the strip are not arbitrary, because they are constrained to the lengths and directions of the lines that connect pairs of graphene atoms in the same class.",
                    "score": 0.8701189160346985
                },
                {
                    "id": 15382613,
                    "contents": "Optical properties of carbon nanotubes\nThe spectral range of PL is rather wide. Emission wavelength can vary between 0.8 and 2.1 micrometers depending on the nanotube structure. Excitons are apparently delocalized over several nanotubes in single chirality bundles as the photoluminescence spectrum displays a splitting consistent with intertube exciton tunneling. Interaction between nanotubes or between a nanotube and another material may quench or increase PL. No PL is observed in multi-walled carbon nanotubes. PL from double-wall carbon nanotubes strongly depends on the preparation method: CVD grown DWCNTs show emission both from inner and outer shells. However, DWCNTs produced by encapsulating fullerenes into SWNTs and annealing show PL only from the outer shells. Isolated SWNTs lying on the substrate show extremely weak PL which has been detected in few studies only. Detachment of the tubes from the substrate drastically increases PL.",
                    "score": 0.8700746297836304
                },
                {
                    "id": 21070935,
                    "contents": "Carbon nanotube field-effect transistor\nA carbon nanotube’s bandgap is directly affected by its chiral angle and diameter. If those properties can be controlled, CNTs would be a promising candidate for future nano-scale transistor devices. Moreover, because of the lack of boundaries in the perfect and hollow cylinder structure of CNTs, there is no boundary scattering. CNTs are also quasi-1D materials in which only forward scattering and back scattering are allowed, and elastic scattering means that free paths in carbon nanotubes are long, typically on the order of micrometers. As a result, quasi-ballistic transport can be observed in nanotubes at relatively long lengths and low fields.",
                    "score": 0.8692026734352112
                },
                {
                    "id": 1627505,
                    "contents": "Carbon nanotube\nProperties Many properties of single-walled carbon nanotubes depend significantly on the (n,m) type, and this dependence is non-monotonic (see Kataura plot). In particular, the band gap can vary from zero to about 2 eV and the electrical conductivity can show metallic or semiconducting behavior. Mechanical",
                    "score": 0.8687476515769958
                },
                {
                    "id": 1627516,
                    "contents": "Carbon nanotube\nCarbon nanotubes are unique \"one-dimensional systems\" which can be envisioned as rolled single sheets of graphite (or more precisely graphene). This rolling can be done at different angles and curvatures resulting in different nanotube properties. The diameter typically varies in the range 0.4–40 nm (i.e., \"only\" ~100 times), but the length can vary ~100,000,000,000 times, from 0.14 nm to 55.5 cm. The nanotube aspect ratio, or the length-to-diameter ratio, can be as high as 132,000,000:1, which is unequalled by any other material. Consequently, all the properties of the carbon nanotubes relative to those of typical semiconductors are extremely anisotropic (directionally dependent) and tunable.",
                    "score": 0.8679035902023315
                },
                {
                    "id": 17754605,
                    "contents": "Mechanical properties of carbon nanotubes\nEExperimental observation; TTheoretical prediction Radial elasticity On the other hand, there was evidence that in the radial direction they are rather soft. The first transmission electron microscope observation of radial elasticity suggested that even the van der Waals forces can deform two adjacent nanotubes. Later, nanoindentations with atomic force microscope were performed by several groups to quantitatively measure radial elasticity of multiwalled carbon nanotubes and tapping/contact mode atomic force microscopy was also performed on single-walled carbon nanotubes. Young's modulus of on the order of several GPa showed that CNTs are in fact very soft in the radial direction. A complete phase diagram giving the transition to the radially collapsed geometry as function of diameter, pressure and number of tube-walls has been produced from semiempirical grounds.",
                    "score": 0.8675272464752197
                },
                {
                    "id": 21070934,
                    "contents": "Carbon nanotube field-effect transistor\nThe band gaps of semiconducting carbon nanotubes with depend predominately on their diameters. In fact, according to a single-particle tight-binding description of the electronic structure of these nanotubes where is the nearest-neighbor hopping matrix element. That this result is an excellent approximation so long as is a lot less than one has been verified both by all-electron first principles local density functional calculations and experiment. Scatter plots of the band gaps of carbon nanotubes with diameters up to three nanometers calculated using an all valence tight binding model that includes curvature effects appeared early in carbon nanotube research and were reprinted in a review. Motivations for transistor applications",
                    "score": 0.8660955429077148
                },
                {
                    "id": 1627486,
                    "contents": "Carbon nanotube\nLet u and v be two linearly independent vectors that connect the graphene atom A1 to two of its nearest atoms with the same bond directions. That is, if one numbers consecutive carbons around a graphene cell with C1 to C6, then u can be the vector from C1 to C3, and v be the vector from C1 to C5. Then, for any other atom A2 with same class as A1, the vector from A1 to A2 can be written as a linear combination n u + m v, where n and m are integers. And, conversely, each pair of integers (n,m) defines a possible position for A2. Given n and m, one can reverse this theoretical operation by drawing the vector w on the graphene lattice, cutting a strip of the latter along lines perpendicular to w through its endpoints A1 and A2, and rolling the strip into a cylinder so as to bring those two points together. If this construction is applied to a pair (k,0), the result is a zigzag nanotube, with closed zigzag paths of 2k atoms. If it is applied to a pair (k,k), one obtains an armchair tube,",
                    "score": 0.8649840354919434
                },
                {
                    "id": 17754608,
                    "contents": "Mechanical properties of carbon nanotubes\nKinetic properties Multi-walled nanotubes are multiple concentric nanotubes precisely nested within one another. These exhibit a striking telescoping property whereby an inner nanotube core may slide, almost without friction, within its outer nanotube shell, thus creating an atomically perfect linear or rotational bearing. This is one of the first true examples of molecular nanotechnology, the precise positioning of atoms to create useful machines. Already, this property has been utilized to create the world's smallest rotational motor. Future applications such as a gigahertz mechanical oscillator are also envisioned.",
                    "score": 0.8645185232162476
                },
                {
                    "id": 18504577,
                    "contents": "Ballistic conduction in single-walled carbon nanotubes\nAssuming no scattering and ideal (transparent) contacts, the conductance of the one-dimensional system is given by G = G0NT, where T is the probability that an electron will be transmitted along the channel, N is the number of the channels available for transport, and G0 is the conductance quantum 2e2/h = (12.9kΩ)−1. Perfect contacts, with reflection R = 0, and no back scattering along the channel result in transmission probability T = 1 and the conductance of the system becomes G = (2e2/h) N. Thus each channel contributes 2G0 to the total conductance. For metallic armchair nanotubes, there are two subbands, which cross the Fermi level, and for semiconducting nanotubes – bands which don't cross the Fermi level. Thus there are two conducting channels and each band accommodates two electrons of opposite spin. Thus the value of the conductance is G = 2G0 = (6.45 kΩ)−1.",
                    "score": 0.864361584186554
                },
                {
                    "id": 1135420,
                    "contents": "Nanotechnology\nOne nanometer (nm) is one billionth, or 10−9, of a meter. By comparison, typical carbon-carbon bond lengths, or the spacing between these atoms in a molecule, are in the range , and a DNA double-helix has a diameter around 2 nm. On the other hand, the smallest cellular life-forms, the bacteria of the genus Mycoplasma, are around 200 nm in length. By convention, nanotechnology is taken as the scale range following the definition used by the National Nanotechnology Initiative in the US. The lower limit is set by the size of atoms (hydrogen has the smallest atoms, which are approximately a quarter of a nm kinetic diameter) since nanotechnology must build its devices from atoms and molecules. The upper limit is more or less arbitrary but is around the size below which the phenomena not observed in larger structures start to become apparent and can be made use of in the nano device. These new phenomena make nanotechnology distinct from devices which are merely miniaturised versions of an",
                    "score": 0.8641891479492188
                },
                {
                    "id": 20909159,
                    "contents": "Single-walled carbon nanohorn\nper C atom) is larger than that of multiwall carbon nanotubes (MWNTs) by one magnitude, while the Pauli susceptibility is comparable to that of MWNTs. On the other hand, a large suppression of the paramagnetic susceptibility is observed below 17 K. This phenomenon implies an antiferromagnetic correlation between the localized electrons, in which the localized spins pair into antiferromagnetic singlet pairs. However, the concentration of the localized electrons is too low. To explain this, Garaj et al. suggested that the singlet coupling was mediated by conducting electrons.",
                    "score": 0.8639460802078247
                },
                {
                    "id": 2123516,
                    "contents": "CNT\nScience and technology Carbon nanotube, an allotrope of carbon with a cylindrical nanostructure Classical nucleation theory Computer Network Technology Corporation, an enterprise acquired by McData in January 2005; see Ultra Network Technologies Columbia Non-neutral Torus, a small stellarator at the Columbia University Plasma Physics Laboratory in New York City Television Central Nacional de Televisão (CNT), or Central National Television, a Brazilian television network in Curitiba/Paraná, Brazil CNT EP, the public telecommunications company in Ecuador Conglomerated National Television, a fictional television network in HD Universe of Grand Theft Auto series.",
                    "score": 0.8635642528533936
                },
                {
                    "id": 21070932,
                    "contents": "Carbon nanotube field-effect transistor\nThus, the circumference of such a carbon nanotube can be expressed in terms of its rollup vector: Ĉh=nâ1+mâ2 that connects two crystallographically equivalent sites of the two-dimensional graphene sheet. Here and are integers and â1 and â2 are primitive lattice vectors of the hexagonal lattice. Therefore, the structure of any carbon nanotube can be described by an index with a pair of integers that define its rollup vector. In terms of the integers , the nanotube diameter and the chiral angle are given by: ; and, , where is the C—C bond distance. Differences in the chiral angle and the diameter cause the differences in the properties of the various carbon nanotubes. For example, it can be shown that an carbon nanotube is metallic when , is a small band gap semiconductor when and , and is a moderate band gap semiconductor when , where is an integer.",
                    "score": 0.8635294437408447
                },
                {
                    "id": 5541130,
                    "contents": "Quantum wire\nThe structure of a nanotube strongly affects its electrical properties. For a given (n,m) nanotube, if n = m, the nanotube is metallic; if n − m is a multiple of 3, then the nanotube is semiconducting with a very small band gap, otherwise the nanotube is a moderate semiconductor. Thus all armchair (n = m) nanotubes are metallic, and nanotubes (6,4), (9,1), etc. are semiconducting. See also Conductance quantum Quantum point contact Quantum well Quantum dot References Nanowire Quantum electronics Semiconductor structures Mesoscopic physics",
                    "score": 0.8633325695991516
                },
                {
                    "id": 1627553,
                    "contents": "Carbon nanotube\nIn 1952, L. V. Radushkevich and V. M. Lukyanovich published clear images of 50 nanometer diameter tubes made of carbon in the Journal of Physical Chemistry Of Russia. This discovery was largely unnoticed, as the article was published in Russian, and Western scientists' access to Soviet press was limited during the Cold War. Monthioux and Kuznetsov mentioned in their Carbon editorial:",
                    "score": 0.8631839752197266
                },
                {
                    "id": 18504575,
                    "contents": "Ballistic conduction in single-walled carbon nanotubes\nSingle-walled carbon nanotubes in the fields of quantum mechanics and nanoelectronics, have the ability to conduct electricity. This conduction can be ballistic, diffusive, or based on scattering. When ballistic in nature conductance can be treated as if the electrons experience no scattering. Conductance quantization and Landauer formula",
                    "score": 0.8631043434143066
                },
                {
                    "id": 18504576,
                    "contents": "Ballistic conduction in single-walled carbon nanotubes\nConductance quantization and Landauer formula Conduction in single-walled carbon nanotubes is quantized due to their one-dimensionality and the number of allowed electronic states is limited, if compared to bulk graphite. The nanotubes behave consequently as quantum wires and charge carriers are transmitted through discrete conduction channels. This conduction mechanism can be either ballistic or diffusive in nature, or based on tunneling. When ballistically conducted, the electrons travel through the nanotubes channel without experiencing scattering due to impurities, local defects or lattice vibrations. As a result, the electrons encounter no resistance and no energy dissipation occurs in the conduction channel. In order to estimate the current in the carbon nanotube channel, the Landauer formula can be applied, which considers a one-dimensional channel, connected to two contacts – source and drain.",
                    "score": 0.8629475831985474
                },
                {
                    "id": 13126867,
                    "contents": "Selective chemistry of single-walled nanotubes\nTwo main components of the tangential mode include G+ at 1590 cm−1 and G− at 1570 cm−1. G+ feature is associated with carbon atom vibrations along the nanotube axis. The G− feature is associated with vibrations of carbon atoms along the circumferential direction. The G-band frequency can be used (1) to distinguish between metallic and semiconducting SWNTs, and (2) to probe charge transfer arising from doping a SWNT. Frequency of G+ is sensitive to charge transfer. It upshifts for acceptors and downshifts for donors. Lineshape of G− is highly sensitive to whether SWNT is metallic (Breit-Wigner-Fano lineshape) or semiconducting (Lorentzian lineshape).",
                    "score": 0.8618641495704651
                },
                {
                    "id": 1627492,
                    "contents": "Carbon nanotube\nFrom n and m one can also compute the circumference c, which is the length of the vector w, which turns out to be: in picometres. The diameter of the tube is then , that is also in picometres. (These formulas are only approximate, especially for small n and m where the bonds are strained; and they do not take into account the thickness of the wall.) The tilt angle α between u and w and the circumference c are related to the type indices n and m by: where arg(x,y) is the clockwise angle between the X-axis and the vector (x,y); a function that is available in many programming languages as atan2(y,x). Conversely, given c and α, one can get the type (n,m) by the formulas: which must evaluate to integers. Physical limits Narrowest examples",
                    "score": 0.8617995977401733
                },
                {
                    "id": 10861584,
                    "contents": "Paul McEuen\nPaul McEuen (born 1963) is an American physicist. He received his B.S. in engineering physics at the University of Oklahoma (1985), and his Ph.D. in applied physics at Yale University (1991). After postdoctoral work at MIT (1990–1991), he became an assistant professor at the University of California, Berkeley. He moved to Cornell University in 2001, where he is currently the Goldwin Smith Professor of Physics. He is one of the experts on the electrical property of carbon nanotubes and is a member of the National Academy of Sciences. Research focus Paul McEuen studies the electrical and mechanical properties of carbon nanotubes, scanning probe microscopy of nanostructures, molecular electronics, and applications of nanoelectronics in chemistry and biology. His group publishes their work frequently in Nature and Science, and Paul has a Hirsch number of 53.",
                    "score": 0.8617119193077087
                },
                {
                    "id": 26471061,
                    "contents": "Elisa Molinari\nS. Kalliakos et al, \"A molecular state of correlated electrons in a quantum dot\", Nature Physics 4, 467 - 471 (2008) D. Prezzi et al, \"Optical properties of graphene nanoribbons: The role of many-body effects\", Phys Rev B77, 041404 (2008) A. Ferretti et al, \"Mixing of electronic states in pentacene adsorption on copper\", Phys Rev Lett 99, 046802 (2007) J. Maultzsch et al, \"Exciton binding energies in carbon nanotubes from two-photon photoluminescence\", Phys Rev B 72, 241402 (2005) A. Ferretti et al, \"First-principles theory of correlated transport through nanojunctions\", Phys Rev Lett 94, 116802 (2005)",
                    "score": 0.8606510758399963
                },
                {
                    "id": 11909993,
                    "contents": "Timeline of carbon nanotubes\n1993 Groups led by Donald S. Bethune at IBM and Sumio Iijima at NEC independently discover single-wall carbon nanotubes and methods to produce them using transition-metal catalysts. 1995 Swiss researchers are the first to demonstrate the electron emission properties of carbon nanotubes. German inventors Till Keesmann and Hubert Grosse-Wilde predicted this property of carbon nanotubes earlier in the year in their patent application. 1997 First carbon nanotube single-electron transistors (operating at low temperature) are demonstrated by groups at Delft University and UC Berkeley. The first suggestion of using carbon nanotubes as optical antennas is made in the patent application of inventor Robert Crowley filed in January 1997. 1998 First carbon nanotube field-effect transistors are demonstrated by groups at Delft University and IBM. 2000 First demonstration proving that bending carbon nanotubes changes their resistance",
                    "score": 0.8591200113296509
                },
                {
                    "id": 15382602,
                    "contents": "Optical properties of carbon nanotubes\nGeometric structure Chiral angle A single-walled carbon nanotubes (SWCNT) can be envisioned as strip of a graphene molecule (a single sheet of graphite) rolled and joined into a seamless cylinder. The structure of the nanotube can be characterized by the width of this hypothetical strip (that is, the circumference c or diameter d of the tube) and the angle α of the strip relative to the main symmetry axes of the hexagonal graphene lattice. This angle, which may vary from 0 to 30 degrees, is called the \"chiral angle\" of the tube. The (n,m) notation",
                    "score": 0.8590948581695557
                },
                {
                    "id": 1627558,
                    "contents": "Carbon nanotube\nrelating to fullerenes. The discovery of nanotubes remains a contentious issue. Many believe that Iijima's report in 1991 is of particular importance because it brought carbon nanotubes into the awareness of the scientific community as a whole.",
                    "score": 0.8588483333587646
                },
                {
                    "id": 21070947,
                    "contents": "Carbon nanotube field-effect transistor\nwhere Qt represents the charge stored in terminal capacitances, and the total terminal capacitance CΣ is the sum of the gate, drain, source, and substrate capacitances shown in the figure above. The standard approach to the solution to the self-consistent voltage equation is to use the Newton-Raphson iterative method. According to the CNT ballistic transport theory, the drain current caused by the transport of the nonequilibrium charge across the nanotube can be calculated using the Fermi–Dirac statistics. Here F0 represents the Fermi–Dirac integral of order 0, k is the Boltzmann’s constant, T is the temperature, and ℏ the reduced Planck’s constant. This equation can be solved easily as long as the self-consistent voltage is known. However the calculation could be time-consuming when it needs to solve the self-consistent voltage with the iterative method, and this is the main drawback of this calculation. Key advantages",
                    "score": 0.8585347533226013
                },
                {
                    "id": 15382600,
                    "contents": "Optical properties of carbon nanotubes\nThe optical properties of carbon nanotubes are highly relevant for materials science. The way those materials interact with electromagnetic radiation is unique in many respects, as evidenced by their peculiar absorption, photoluminescence (fluorescence), and Raman spectra. Carbon nanotubes are unique \"one-dimensional\" materials, whose hollow fibers (tubes) have a unique and highly ordered atomic and electronic structure, and can be made in a wide range of dimension. The diameter typically varies from 0.4 to 40 nm (i.e., a range of ~100 times). However, the length can reach , implying a length-to-diameter ratio as high as 132,000,000:1; which is unequaled by any other material. Consequently, all the electronic, optical, electrochemical and mechanical properties of the carbon nanotubes are extremely anisotropic (directionally dependent) and tunable.",
                    "score": 0.8582518100738525
                },
                {
                    "id": 1627484,
                    "contents": "Carbon nanotube\nThe zigzag and armchair configurations are not the only structures that a single-walled nanotube can have. To describe the structure of a general infinitely long tube, one should imagine it being sliced open by a cut parallel to its axis, that goes through some atom A, and then unrolled flat on the plane, so that its atoms and bonds coincide with those of an imaginary graphene sheet—more precisely, with an infinitely long strip of that sheet. The two halves of the atom A will end up on opposite edges of the strip, over two atoms A1 and A2 of the graphene. The line from A1 to A2 will correspond to the circumference of the cylinder that went through the atom A, and will be perpendicular to the edges of the strip. In the graphene lattice, the atoms can be split into two classes, depending on the directions of their three bonds. Half the atoms have their three bonds directed the same way, and half have their three bonds rotated 180 degrees relative to the first half. The atoms A1 and A2,",
                    "score": 0.8568544387817383
                },
                {
                    "id": 4161031,
                    "contents": "Graphene\nHowever, if the in-plane direction is no longer infinite, but confined, its electronic structure would change. They are referred to as graphene nanoribbons. If it is \"zig-zag\", the bandgap would still be zero. If it is \"armchair\", the bandgap would be non-zero. Graphene's hexagonal lattice can be regarded as two interleaving triangular lattices. This perspective was successfully used to calculate the band structure for a single graphite layer using a tight-binding approximation. Electronic spectrum Electrons propagating through graphene's honeycomb lattice effectively lose their mass, producing quasi-particles that are described by a 2D analogue of the Dirac equation rather than the Schrödinger equation for spin- particles. Dispersion relation",
                    "score": 0.8567143678665161
                },
                {
                    "id": 3025414,
                    "contents": "Carbon nanofoam\nEach cluster is about 6 nanometers wide and consists of about 4000 carbon atoms linked in graphite-like sheets that are given negative curvature by the inclusion of heptagons among the regular hexagonal pattern. This is the opposite of what happens in the case of buckminsterfullerenes in which carbon sheets are given positive curvature by the inclusion of pentagons. The large-scale structure of carbon nanofoam is similar to that of an aerogel, but with 1% of the density of previously produced carbon aerogels—or only a few times the density of air at sea level. Unlike carbon aerogels, carbon nanofoam is a poor electrical conductor. The nanofoam contains numerous unpaired electrons, which Rode and colleagues propose is due to carbon atoms with only three bonds that are found at topological and bonding defects. This gives rise to what is perhaps carbon nanofoam's most unusual feature: it is attracted to magnets, and below −183 °C can itself be made magnetic.",
                    "score": 0.8564362525939941
                },
                {
                    "id": 1627508,
                    "contents": "Carbon nanotube\nOn the other hand, there was evidence that in the radial direction they are rather soft. The first transmission electron microscope observation of radial elasticity suggested that even van der Waals forces can deform two adjacent nanotubes. Later, nanoindentations with an atomic force microscope were performed by several groups to quantitatively measure radial elasticity of multiwalled carbon nanotubes and tapping/contact mode atomic force microscopy was also performed on single-walled carbon nanotubes. Young's modulus of on the order of several GPa showed that CNTs are in fact very soft in the radial direction. Electrical",
                    "score": 0.856089174747467
                },
                {
                    "id": 1627481,
                    "contents": "Carbon nanotube\nRolling up a hexagonal lattice along different directions to form different infinitely long single-wall carbon nanotubes shows that all of these tubes not only have helical but also translational symmetry along the tube axis and many also have nontrivial rotational symmetry about this axis. In addition, most are chiral, meaning the tube and its mirror image cannot be superimposed. This construction also allows single-wall carbon nanotubes to be labeled by a pair of integers. A special group of achiral single-wall carbon nanotubes are metallic, but all the rest are either small or moderate band gap semiconductors. These electrical properties, however, do not depend on whether the hexagonal lattice is rolled from its back to front or from its front to back and hence are the same for the tube and its mirror image. Structure of SWNTs Basic details",
                    "score": 0.855500340461731
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_11",
        "question": "A sample of the sugar D-ribose of mass $0.727 \\mathrm{~g}$ was placed in a calorimeter and then ignited in the presence of excess oxygen. The temperature rose by $0.910 \\mathrm{~K}$. In a separate experiment in the same calorimeter, the combustion of $0.825 \\mathrm{~g}$ of benzoic acid, for which the internal energy of combustion is $-3251 \\mathrm{~kJ} \\mathrm{~mol}^{-1}$, gave a temperature rise of $1.940 \\mathrm{~K}$. Calculate the enthalpy of formation of D-ribose.",
        "golden_answers": [
            " -1270"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1868957,
                    "contents": "Monosaccharide\nGlucose, used as an energy source and for the synthesis of starch, glycogen and cellulose, is a hexose. Ribose and deoxyribose (in RNA and DNA respectively) are pentose sugars. Examples of heptoses include the ketoses, mannoheptulose and sedoheptulose. Monosaccharides with eight or more carbons are rarely observed as they are quite unstable. In aqueous solutions monosaccharides exist as rings if they have more than four carbons. Linear-chain monosaccharides Simple monosaccharides have a linear and unbranched carbon skeleton with one carbonyl (C=O) functional group, and one hydroxyl (OH) group on each of the remaining carbon atoms. Therefore, the molecular structure of a simple monosaccharide can be written as H(CHOH)n(C=O)(CHOH)mH, where n + 1 + m = x; so that its elemental formula is CxH2xOx.",
                    "score": 0.8493008613586426
                },
                {
                    "id": 4005321,
                    "contents": "Ribitol\nRibitol, or adonitol, is a crystalline pentose alcohol (C5H12O5) formed by the reduction of ribose. It occurs naturally in the plant Adonis vernalis as well as in the cell walls of some Gram-positive bacteria, in the form of ribitol phosphate, in teichoic acids. It also forms part of the chemical structure of riboflavin and flavin mononucleotide (FMN), which is a nucleotide coenzyme used by many enzymes, the so-called flavoproteins. References External links GMD MS Spectrum Safety MSDS data Biological Magnetic Resonance Data Bank Sugar alcohols",
                    "score": 0.8430019617080688
                },
                {
                    "id": 28154118,
                    "contents": "Ribose\nThe ribonucleosides adenosine, cytidine, guanosine, and uridine are all derivatives of β--ribofuranose. Metabolically-important species that include phosphorylated ribose include ADP, ATP, coenzyme A, and NADH. cAMP and cGMP serve as secondary messengers in some signaling pathways and are also ribose derivatives. The ribose moiety appears in some pharmaceutical agents, including the antibiotics neomycin and paromomycin. Synthesis and sources Ribose as its 5-phosphate ester is typically produced from glucose by the pentose phosphate pathway. In at least some archaea, alternative pathways have been identified. Ribose can be synthesized chemically, but commercial production relies on fermentation of glucose. Using genetically modified strains of B. subtilis, 90 g/liter of ribose can be produced from 200 g of glucose. The conversion entails the intermediacy of gluconate and ribulose. Ribose has been detected in meteorites.",
                    "score": 0.8369438052177429
                },
                {
                    "id": 3522943,
                    "contents": "Sugar alcohol\nCommon sugar alcohols Ethylene glycol (2-carbon) Glycerol (3-carbon) Erythritol (4-carbon) Threitol (4-carbon) Arabitol (5-carbon) Xylitol (5-carbon) Ribitol (5-carbon) Mannitol (6-carbon) Sorbitol (6-carbon) Galactitol (6-carbon) Fucitol (6-carbon) Iditol (6-carbon) Inositol (6-carbon; a cyclic sugar alcohol) Volemitol (7-carbon) Isomalt (12-carbon) Maltitol (12-carbon) Lactitol (12-carbon) Maltotriitol (18-carbon) Maltotetraitol (24-carbon) Polyglycitol Both disaccharides and monosaccharides can form sugar alcohols; however, sugar alcohols derived from disaccharides (e.g. maltitol and lactitol) are not entirely hydrogenated because only one aldehyde group is available for reduction. Sugar alcohols as food additives This table presents the relative sweetness and food energy of the most widely used sugar alcohols. Despite the variance in food energy content of sugar alcohols, EU labeling requirements assign a blanket value of 2.4 kcal/g to all sugar alcohols.",
                    "score": 0.8328964114189148
                },
                {
                    "id": 1748511,
                    "contents": "Glucose\nThe metabolic pathway that begins with molecules containing two to four carbon atoms (C) and ends in the glucose molecule containing six carbon atoms is called gluconeogenesis and occurs in all living organisms. The smaller starting materials are the result of other metabolic pathways. Ultimately almost all biomolecules come from the assimilation of carbon dioxide in plants during photosynthesis. The free energy of formation of α--glucose is 917.2 kilojoules per mole. In humans, gluconeogenesis occurs in the liver and kidney, but also in other cell types. In the liver about of glycogen are stored, in skeletal muscle about . However, the glucose released in muscle cells upon cleavage of the glycogen can not be delivered to the circulation because glucose is phosphorylated by the hexokinase, and a glucose-6-phosphatase is not expressed to remove the phosphate group. Unlike for glucose, there is no transport protein for glucose-6-phosphate. Gluconeogenesis allows the organism to build",
                    "score": 0.831285297870636
                },
                {
                    "id": 28803454,
                    "contents": "1-O-Acetyl-2,3,5-tri-O-benzoyl-beta-D-ribofuranose\nIn the patented formation of 1-O-acetyl-2,3,5-tri-O-benzoyl-beta-L-ribofuranose, a reactor containing thionyl chloride (5 ml) and methyl alcohol (100 ml) is stirred at 0-5 °C for 10-15 minutes. After this period, 10 g (ratio-wise) of ribose is added to the flask. The flask is then stirred and maintained at its temperature for 8 hours. During this period, a methylation reaction will occur on the ribose. After the 8-hour period of methylation, the flask will be filled with 150 ml of ethyl acetate, 5 ml pyridine, and 30 g potassium carbonate. The flask will then be heated to 60-70 °C. Over 99 minutes at this temperature, 30 ml of the chemical benzyl chloride will be intermittently dripped into the flask to react with the ribose directly. After this period, the flask will be left for 4-8 hours to continue reacting. The subsequent solid nonacetylated ribose benzyl glycoside will be isolated by neutralizing the flask liquid by addition of sulfuric acid, then suction of the precipitate (the",
                    "score": 0.8311966061592102
                },
                {
                    "id": 12221166,
                    "contents": "Wilbur Olin Atwater\nthose nutrients under various conditions of rest and work. The calorimeter measured human metabolism by analyzing the heat produced by a person performing certain physical activities; in 1896 they began the first of what would accumulate into close to 500 experiments. Through their experiments, they were able to create a system - which became known as the Atwater system, to measure the energy in units, known as food calories. With the machine, the dynamics of metabolism could be quantified and the relationship between food intake and energy output could be measured. \"The experiments are made with a man inside a cabinet, or a respiration chamber, as it is called. It is in fact a box of copper incased [sic] in walls of zinc and wood. In this chamber he lives—eats, drinks, works, rests, and sleeps. There is a constant supply of fresh air for ventilation. The temperature is kept at the point most agreeable to the occupant. Within the chamber are a small folding cot-bed, a chair, and a",
                    "score": 0.8308937549591064
                },
                {
                    "id": 1170770,
                    "contents": "Purine\nPatented Aug. 20, 1968, the current recognized method of industrial-scale production of adenine is a modified form of the formamide method. This method heats up formamide under 120 degree Celsius conditions within a sealed flask for 5 hours to form adenine. The reaction is heavily increased in quantity by using a phosphorus oxychloride (phosphoryl chloride) or phosphorus pentachloride as an acid catalyst and sunlight or ultraviolet conditions. After the 5 hours have passed and the formamide-phosphorus oxychloride-adenine solution cools down, water is put into the flask containing the formamide and now-formed adenine. The water-formamide-adenine solution is then poured through a filtering column of activated charcoal. The water and formamide molecules, being small molecules, will pass through the charcoal and into the waste flask; the large adenine molecules, however, will attach or “adsorb” to the charcoal due to the van der waals forces that interact between the adenine and the",
                    "score": 0.8297443389892578
                },
                {
                    "id": 743686,
                    "contents": "Hexose\nIn particular, the \"α\" and \"β\" forms can convert to into each other by returning to the open-chain form and then closing in the opposite configuration. This process is called mutarotation. Chemical properties Although all hexoses have similar structures and share some general properties, each enantiomer pair has its own chemistry. Fructose is soluble in water, alcohol, and ether. The two enantiomers of each pair generally have vastly different biological properties. 2-Ketohexoses are stable over a wide pH range, and with a primary pKa of 10.28, will only deprotonate at high pH, so are marginally less stable than aldohexoses in solution. Natural occurrence and uses The aldohexose that is most important in biochemistry is -glucose, which is the main \"fuel\" for metabolism in many living organisms. The 2-ketohexoses psicose, fructose and tagatose occur naturally as the -isomers, whereas sorbose occurs naturally as the -isomer.",
                    "score": 0.8296455144882202
                },
                {
                    "id": 1748489,
                    "contents": "Glucose\nWith six carbon atoms, it is classed as a hexose, a subcategory of the monosaccharides. -Glucose is one of the sixteen aldohexose stereoisomers. The -isomer, -glucose, also known as dextrose, occurs widely in nature, but the -isomer, -glucose, does not. Glucose can be obtained by hydrolysis of carbohydrates such as milk sugar (lactose), cane sugar (sucrose), maltose, cellulose, glycogen, etc. Dextrose is commonly commercially manufactured from cornstarch in the US and Japan, from potato and wheat starch in Europe, and from tapioca starch in tropical areas. The manufacturing process uses hydrolysis via pressurized steaming at controlled pH in a jet followed by further enzymatic depolymerization. Unbonded glucose is one of the main ingredients of honey. All forms of glucose are colorless and easily soluble in water, acetic acid, and several other solvents. They are only sparingly soluble in methanol and ethanol. Structure and nomenclature",
                    "score": 0.8279942274093628
                },
                {
                    "id": 1009726,
                    "contents": "Sucrose\nHydrolysis Hydrolysis breaks the glycosidic bond converting sucrose into glucose and fructose. Hydrolysis is, however, so slow that solutions of sucrose can sit for years with negligible change. If the enzyme sucrase is added, however, the reaction will proceed rapidly. Hydrolysis can also be accelerated with acids, such as cream of tartar or lemon juice, both weak acids. Likewise, gastric acidity converts sucrose to glucose and fructose during digestion, the bond between them being an acetal bond which can be broken by an acid. Given (higher) heats of combustion of 1349.6 kcal/mol for sucrose, 673.0 for glucose, and 675.6 for fructose, hydrolysis releases about per mole of sucrose, or about 3 small calories per gram of product.",
                    "score": 0.8265101313591003
                },
                {
                    "id": 1603661,
                    "contents": "Biochemistry\nThe simplest type of carbohydrate is a monosaccharide, which among other properties contains carbon, hydrogen, and oxygen, mostly in a ratio of 1:2:1 (generalized formula CnH2nOn, where n is at least 3). Glucose (C6H12O6) is one of the most important carbohydrates; others include fructose (C6H12O6), the sugar commonly associated with the sweet taste of fruits, and deoxyribose (C5H10O4), a component of DNA. A monosaccharide can switch between acyclic (open-chain) form and a cyclic form. The open-chain form can be turned into a ring of carbon atoms bridged by an oxygen atom created from the carbonyl group of one end and the hydroxyl group of another. The cyclic molecule has a hemiacetal or hemiketal group, depending on whether the linear form was an aldose or a ketose.",
                    "score": 0.8262179493904114
                },
                {
                    "id": 6489750,
                    "contents": "Okadaic acid\nIn Isobe's synthesis, the molecule was broken into 3 pieces, along the C14-C15 bonds, and the C27-C28 bonds. This formed fragments A, B, and C, which were all synthesized separately, after which the B and C fragments were combined, and then combined with the A fragment. This synthesis contained 106 steps, with a longest linear sequence of 54 steps. The precursors to all three fragments were all glucose derivatives obtained from the chiral pool. Spiroketals were obtained from precursor ketone diols, and were therefore formed thermally in acid.",
                    "score": 0.8260474801063538
                },
                {
                    "id": 7825199,
                    "contents": "Viktor Meyer\nProposing glucose is an aldehyde and not a ketone, hereby correcting von Baeyer and van't Hoff (1880). Synthesis of aldoximes and ketoximes from hydroxylamine and aldehydes or ketones, hereby discovering a new structural identification and elucidation method (1882, together with Alois Janny). Identification of thiophene as a contaminant in benzene derived from coal (1882). Benzene produced by decarboxylation of benzoic acid did not contain this impurity. First reliable synthesis of pure sulfur mustard (1886, also see Meyer's account on sulfur mustard) Coining of the concepts of stereochemistry and dipole in 1888. Meyer had always been interested in stereochemical problems and was one of the first ones to instruct his pupils with van't Hoff's theory of asymmetric carbon and the Hantzsch-Werner theory. Discovery of iodoso compounds in 1892 by reacting o-iodobenzoic acid with nitric acid.",
                    "score": 0.8255453705787659
                },
                {
                    "id": 14568636,
                    "contents": "L-Glucose\n{{DISPLAYTITLE:L-Glucose}} -Glucose is an organic compound with formula C6H12O6 or O=CH[CH(OH)]5H, specifically one of the aldohexose monosaccharides. As the -isomer of glucose, it is the enantiomer of the more common -glucose. -Glucose does not occur naturally in living organisms, but can be synthesized in the laboratory. -Glucose is indistinguishable in taste from -glucose, but cannot be used by living organisms as a source of energy because it cannot be phosphorylated by hexokinase, the first enzyme in the glycolysis pathway. One of the known exceptions is in Burkholderia caryophylli, a plant pathogenic bacterium, which contains the enzyme -threo-aldose 1-dehydrogenase which is capable of oxidizing -glucose.",
                    "score": 0.8240861296653748
                },
                {
                    "id": 697674,
                    "contents": "Deoxyribose\nHistory Deoxyribose was discovered in 1929 by Phoebus Levene. Structure Several isomers exist with the formula H−(C=O)−(CH2)−(CHOH)3−H, but in deoxyribose all the hydroxyl groups are on the same side in the Fischer projection. The term \"2-deoxyribose\" may refer to either of two enantiomers: the biologically important -2-deoxyribose and to the rarely encountered mirror image -2-deoxyribose. -2-deoxyribose is a precursor to the nucleic acid DNA. 2-deoxyribose is an aldopentose, that is, a monosaccharide with five carbon atoms and having an aldehyde functional group. In aqueous solution, deoxyribose primarily exists as a mixture of three structures: the linear form H−(C=O)−(CH2)−(CHOH)3−H and two ring forms, deoxyribofuranose (\"C3′-endo\"), with a five-membered ring, and deoxyribopyranose (\"C2′-endo\"), with a six-membered ring. The latter form is predominant (whereas the C3′-endo form is favored for ribose).",
                    "score": 0.8229014873504639
                },
                {
                    "id": 1638685,
                    "contents": "Carbohydrate\nThe most important carbohydrate is glucose, a simple sugar (monosaccharide) that is metabolized by nearly all known organisms. Glucose and other carbohydrates are part of a wide variety of metabolic pathways across species: plants synthesize carbohydrates from carbon dioxide and water by photosynthesis storing the absorbed energy internally, often in the form of starch or lipids. Plant components are consumed by animals and fungi, and used as fuel for cellular respiration. Oxidation of one gram of carbohydrate yields approximately 16 kJ (4 kcal) of energy, while the oxidation of one gram of lipids yields about 38 kJ (9 kcal). The human body stores between 300 and 500 g of carbohydrates depending on body weight, with the skeletal muscle contributing to a large portion of the storage. Energy obtained from metabolism (e.g., oxidation of glucose) is usually stored temporarily within cells in the form of ATP. Organisms capable of anaerobic and aerobic respiration metabolize glucose and",
                    "score": 0.8217180967330933
                },
                {
                    "id": 1868956,
                    "contents": "Monosaccharide\nThe monosaccharide glucose plays a pivotal role in metabolism, where the chemical energy is extracted through glycolysis and the citric acid cycle to provide energy to living organisms. Some other monosaccharides can be converted in the living organism to glucose. Structure and nomenclature With few exceptions (e.g., deoxyribose), monosaccharides have this chemical formula: (CH2O)x, where conventionally x ≥ 3. Monosaccharides can be classified by the number x of carbon atoms they contain: triose (3), tetrose (4), pentose (5), hexose (6), heptose (7), and so on.",
                    "score": 0.8214043974876404
                },
                {
                    "id": 1396206,
                    "contents": "Adenine\nPatented Aug. 20, 1968, the current recognized method of industrial-scale production of adenine is a modified form of the formamide method. This method heats up formamide under 120 degree Celsius conditions within a sealed flask for 5 hours to form adenine. The reaction is heavily increased in quantity by using a phosphorus oxychloride (phosphoryl chloride) or phosphorus pentachloride as an acid catalyst and sunlight or ultraviolet conditions. After the 5 hours have passed and the formamide-phosphorus oxychloride-adenine solution cools down, water is put into the flask containing the formamide and now-formed adenine. The water-formamide-adenine solution is then poured through a filtering column of activated charcoal. The water and formamide molecules, being small molecules, will pass through the charcoal and into the waste flask; the large adenine molecules, however, will attach or “adsorb” to the charcoal due to the van der waals forces that interact between the adenine and the",
                    "score": 0.8202950954437256
                },
                {
                    "id": 8871712,
                    "contents": "Atwater system\nFats Analogously the experimental evidence is limited, but since the fatty acids differ in their heats of combustion one should expect fats to vary in heats of combustion. These differences are, however, relatively small – for example, breast milk fat has a calculated heat of combustion of 9.37 kcal/g (39.2 kJ/g) compared with that of cow milk fat of 9.19 kcal/g (38.5 kJ/g). Carbohydrates Monosaccharides have heats of combustion of around 3.75 kcal/g (15.7 kJ/g), disaccharides 3.95 kcal/g (16.5 kJ/g) and polysaccharides 4.15 to 4.20 kcal/g (17.4 to 17.6 kJ/g). The heat of hydrolysis is very small and these values are essentially equivalent when calculated on a monosaccharide basis. Thus 100 g sucrose gives on hydrolysis 105.6 g monosaccharide and 100 g starch gives on hydrolysis 110 g glucose.",
                    "score": 0.8201970458030701
                },
                {
                    "id": 1868970,
                    "contents": "Monosaccharide\nFor many monosaccharides (including glucose), the cyclic forms predominate, in the solid state and in solutions, and therefore the same name commonly is used for the open- and closed-chain isomers. Thus, for example, the term \"glucose\" may signify glucofuranose, glucopyranose, the open-chain form, or a mixture of the three. Cyclization creates a new stereogenic center at the carbonyl-bearing carbon. The −OH group that replaces the carbonyl's oxygen may end up in two distinct positions relative to the ring's midplane. Thus each open-chain monosaccharide yields two cyclic isomers (anomers), denoted by the prefixes α- and β-. The molecule can change between these two forms by a process called mutarotation, that consists in a reversal of the ring-forming reaction followed by another ring formation.",
                    "score": 0.8188080787658691
                },
                {
                    "id": 19613219,
                    "contents": "Triacetic acid lactone\nTriacetic acid lactone (TAL; 4-hydroxy-6-methyl-2-pyrone) is an organic compound derived enzymatically from glucose. It is a light yellow solid that is soluble in organic solvents. Structure Triacetic acid lactone consists of two main tautomers. The tautomer on the left, featuring a 4-hydroxy group, the C4 carbon, is dominant. Triacetic acid lactone is classified as a 2-pyrone compound owing to the ketone group on the C2 carbon in its dominant form. Synthesis Triacetic acid lactone is synthesized either from dehydroacetic acid, another 2-pyrone derivative, or from glucose by enzymatic catalysis. In its original synthesis, triacetic acid lactone was obtained by treatment of dehydroacetic acid with sulfuric acid at 135 °C. Dehydroacetic acid undergoes ring-opening and hydration to form \"tetracetic acid\". Upon cooling, triacetic acid reverts to a lactone ring similar to the dehydroacetic acid structure, and the triacetic acid lactone is recovered by crystallization in cold water.",
                    "score": 0.818713903427124
                },
                {
                    "id": 3098765,
                    "contents": "Glucoside\nThe simplest glucosides are the alkyl ethers which have been obtained by reacting hydrochloric acid on alcoholic glucose solutions. A better method of preparation is to dissolve solid anhydrous glucose in methanol containing hydrochloric acid. A mixture of alpha- and beta-methylglucoside results. Classification of the glucosides is a matter of some intricacy. One method based on the chemical constitution of the non-glucose part of the molecules has been proposed that posits four groups: (I) alkyl derivatives, (2) benzene derivatives, (3) styrolene derivatives, and (4) anthracene derivatives. A group may also be constructed to include the cyanogenic glucosides, i.e. those containing prussic acid. Alternate classifications follow a botanical classification, which has several advantages; in particular, plants of allied genera contain similar compounds. In this article the chemical classification will be followed, and only the more important compounds will be discussed herein.",
                    "score": 0.8178336024284363
                },
                {
                    "id": 3098764,
                    "contents": "Glucoside\nThe name was originally given to plant products of this nature, in which the other part of the molecule was, in the greater number of cases, an aromatic aldehydic or phenolic compound (exceptions are sinigrin and jalapin or scammonin). It has now been extended to include synthetic ethers, such as those obtained by acting on alcoholic glucose solutions with hydrochloric acid, and also the polysaccharoses, e.g. cane sugar, which appear to be ethers also. Although glucose is the most common sugar present in glucosides, many are known which yield rhamnose or iso-dulcite; these may be termed pentosides. Much attention has been given to the non-sugar parts (aglyca) of the molecules; the constitutions of many have been determined, and the compounds synthesized; and in some cases the preparation of the synthetic glucoside effected.",
                    "score": 0.8175318241119385
                },
                {
                    "id": 1237976,
                    "contents": "Sugar\nMonosaccharides in a closed-chain form can form glycosidic bonds with other monosaccharides, creating disaccharides (such as sucrose) and polysaccharides (such as starch). Enzymes must hydrolyze or otherwise break these glycosidic bonds before such compounds become metabolized. After digestion and absorption the principal monosaccharides present in the blood and internal tissues include glucose, fructose, and galactose. Many pentoses and hexoses can form ring structures. In these closed-chain forms, the aldehyde or ketone group remains non-free, so many of the reactions typical of these groups cannot occur. Glucose in solution exists mostly in the ring form at equilibrium, with less than 0.1% of the molecules in the open-chain form.",
                    "score": 0.8169859051704407
                },
                {
                    "id": 1009725,
                    "contents": "Sucrose\nThis reaction is somewhat simplified though. Some of the carbon does get fully oxidized to carbon dioxide, and other reactions, such as the water-gas shift reaction also take place. A more accurate theoretical equation is: Sucrose burns with chloric acid, formed by the reaction of hydrochloric acid and potassium chlorate: Sucrose can be dehydrated with sulfuric acid to form a black, carbon-rich solid, as indicated in the following idealized equation: The formula for sucrose's decomposition can be represented as a two-step reaction: the first simplified reaction is dehydration of sucrose to pure carbon and water, and then carbon oxidises to with from air.",
                    "score": 0.8166106343269348
                },
                {
                    "id": 1748493,
                    "contents": "Glucose\nThe reaction between C-1 and C-5 yields a six-membered heterocyclic system called a pyranose, which is a monosaccharide sugar (hence \"-ose\") containing a derivatised pyran skeleton. The (much rarer) reaction between C-1 and C-4 yields a five-membered furanose ring, named after the cyclic ether furan. In either case, each carbon in the ring has one hydrogen and one hydroxyl attached, except for the last carbon (C-4 or C-5) where the hydroxyl is replaced by the remainder of the open molecule (which is or respectively).",
                    "score": 0.8161501884460449
                },
                {
                    "id": 1748520,
                    "contents": "Glucose\nglucose, depending on the source, is 16.2 kilojoules per gram or 15.7 kJ/g (3.74 kcal/g). The high availability of carbohydrates from plant biomass has led to a variety of methods during evolution, especially in microorganisms, to utilize glucose for energy and carbon storage. Differences exist in which end product can no longer be used for energy production. The presence of individual genes, and their gene products, the enzymes, determine which reactions are possible. The metabolic pathway of glycolysis is used by almost all living beings. An essential difference in the use of glycolysis is the recovery of NADPH as a reductant for anabolism that would otherwise have to be generated indirectly.",
                    "score": 0.8160895109176636
                },
                {
                    "id": 22812332,
                    "contents": "Calvin Adam Buehler\nPublications In completing his Ph.D. in the Graduate School of Ohio State University, Calvin Buehler published his dissertation in 1922 titled The Oxidation of Lactose, Glucose, and Galactose by Means of Neutral and Alkaline Potassium Permanganate. His research was conducted under Dr. W. L. Evans and worked alongside C.W. Kreger. Over the span of his career, Buehler would publish over forty-two scholarly articles. Buehler was the co-author of the book Survey of Organic Syntheses, published by Wiley-Interscience publications in 1970. The book was written with co-author Donald E. Pearson, an organic chemist from Vanderbilt University. The main focus of the text is the synthesis of particular classes of hydrocarbons or functional groups from other functional groups. In 1977, Buehler and Pearson published a second volume of Survey of Organic Syntheses. The second volume expands the contents of the first, adding new methods of syntheses not previously mentioned in the first volume.",
                    "score": 0.8151934742927551
                },
                {
                    "id": 3248647,
                    "contents": "Théophile-Jules Pelouze\nAfter the coup d'état in 1851 he resigned his appointments, but continued to conduct an experimental laboratory-school he had started in 1846. There he worked with the explosive material guncotton and other nitrosulphates. His student Ascanio Sobrero was the discoverer of nitroglycerin (1847), and another student, Alfred Nobel, was to take that discovery on to great heights in the form of commercial explosives including dynamite. He was a major inspiration for both students. Though Pelouze made no discovery of outstanding importance, he was a busy investigator, his work including researches on salicin, on beetroot sugar, on various organic acids (gallic, malic, tartaric, butyric, lactic, etc.), on oenanthic ether (with Liebig), on the nitrosulphates, on guncotton, and on the composition and manufacture of glass.",
                    "score": 0.8143742084503174
                },
                {
                    "id": 3509560,
                    "contents": "Ketose\nA ketose is a monosaccharide containing one ketone group per molecule. The simplest ketose is dihydroxyacetone, which has only three carbon atoms, and it is the only one with no optical activity. All monosaccharide ketoses are reducing sugars, because they can tautomerize into aldoses via an enediol intermediate, and the resulting aldehyde group can be oxidised, for example in the Tollens' test or Benedict's test. Ketoses that are bound into glycosides, for example in the case of the fructose moiety of sucrose, are nonreducing sugars. Examples of ketoses All ketoses listed here are 2-ketoses, in other words, the carbonyl group is on the second carbon atom from the end: Trioses: dihydroxyacetone Tetroses: erythrulose Pentoses: ribulose, xylulose Hexoses: fructose, psicose, sorbose, tagatose Heptoses: sedoheptulose Octoses: D-manno-octulose (the basis for KDO) Nonoses: D-glycero-D-galacto-nonulose (the basis for neuraminic acid)",
                    "score": 0.8141515254974365
                },
                {
                    "id": 1237975,
                    "contents": "Sugar\nChemistry Scientifically, sugar loosely refers to a number of carbohydrates, such as monosaccharides, disaccharides, or oligosaccharides. Monosaccharides are also called \"simple sugars\", the most important being glucose. Most monosaccharides have a formula that conforms to with n between 3 and 7 (deoxyribose being an exception). Glucose has the molecular formula . The names of typical sugars end with -ose, as in \"glucose\" and \"fructose\". Sometimes such words may also refer to any types of carbohydrates soluble in water. The acyclic mono- and disaccharides contain either aldehyde groups or ketone groups. These carbon-oxygen double bonds (C=O) are the reactive centers. All saccharides with more than one ring in their structure result from two or more monosaccharides joined by glycosidic bonds with the resultant loss of a molecule of water () per bond.",
                    "score": 0.8140742182731628
                },
                {
                    "id": 24144658,
                    "contents": "Strontian process\nThere are two types of strontium saccharide: one at low temperature, the strontium monosaccharide; and the second at high temperature, the strontium disaccharide. History Molasses is the first stage output of several different sugar production processes, and contains more than 50% sugar. The French chemists Hippolyte Leplay and Augustin-Pierre Dubrunfaut developed a process for extracting sugar from molasses, reacting them with barium oxide, to give the insoluble barium-saccharates. In 1849, they expanded their patent to include strontium salts. Apparently, this patent application had the only purpose to legally secure the so-called baryte process, since the strontian process from Leplay and Dubrunfaut probably wouldn't work as described. Only later, through the works of Carl Scheibler, was it possible to apply the strontian process in an industrial basis. According to Scheibler the procedure must be carried out at boiling temperatures.",
                    "score": 0.8137896060943604
                },
                {
                    "id": 3122005,
                    "contents": "1843 in science\nChemistry Jean-Baptiste Dumas names lactose. Carl Mosander discovers the chemical elements Terbium and Erbium. John J. Waterston produces an account of the kinetic theory of gases. Mathematics September – Ada Lovelace translates and expands Menabrea’s notes on Charles Babbage's analytical engine, including an algorithm for calculating a sequence of Bernoulli numbers, regarded as the world's first computer program. October 16 – William Rowan Hamilton discovers the calculus of quaternions and deduces that they are non-commutative. Arthur Cayley and James Joseph Sylvester found the algebraic invariant theory. John T. Graves discovers the octonions. Pierre-Alphonse Laurent discovers and presents the Laurent expansion theorem. Physics James Prescott Joule experimentally finds the mechanical equivalent of heat. Ohm's acoustic law was proposed by German physicist Georg Ohm.",
                    "score": 0.8137549161911011
                },
                {
                    "id": 16966814,
                    "contents": "JoAnne Stubbe\nHer first two publications in scientific journals showed the mechanisms for reactions that involved the enzymes enolase that metabolizes carbohydrates, and pyruvate kinase. Her first groundbreaking experiments were carried out in the late 1970s and early 1980s, while she was at Yale, then the University of Wisconsin. She was trying to understand how the hydroxyl group at the 2’ position of the ribonucleotide's sugar was replaced by the hydrogen found in deoxyribonucleotides. To perform these experiments, she had to synthesize nucleotides that carried a heavy isotope at specific positions. Stubbe reportedly kept a bed in her office since she worked around the clock on her experiments. Stubbe pioneered the use of spectroscopic investigations of enzyme interactions and has devoted most of her career to elucidating the biochemical mechanisms behind free radicals. In her early work at Yale and then at the University of Wisconsin, Stubbe discovered how enzymes called ribonucleotide",
                    "score": 0.8137201070785522
                },
                {
                    "id": 26972,
                    "contents": "Aldose\nAn aldose is a monosaccharide (a simple sugar) with a carbon backbone chain with a carbonyl group on the endmost carbon atom, making it an aldehyde, and hydroxyl groups connected to all the other carbon atoms. Aldoses can be distinguished from ketoses, which have the carbonyl group away from the end of the molecule, and are therefore ketones. Structure Like most carbohydrates, simple aldoses have the general chemical formula Cn(H2O)n. Because formaldehyde (n=1) and glycolaldehyde (n=2) are not generally considered to be carbohydrates, the simplest possible aldose is the triose glyceraldehyde, which only contains three carbon atoms.",
                    "score": 0.8134105801582336
                },
                {
                    "id": 27601200,
                    "contents": "Cornelius O'Sullivan\nHe was elected a fellow of the Chemical Society in 1876, serving on the council from 1882 to 1885, and was awarded the Society's Longstaff Medal in 1884 for his researches on the chemistry of the carbohydrates. In 1885 he was elected a Fellow of the Royal Society, his nomination citation describing him as Distinguished as a chemist, especially for his researches on the Carbohydrates, which have thrown entirely new light on the constitution of this class of bodies and which are therefore of high importance in connexion with the chemistry of vital processes. He was an original member of the Institute of Chemistry, the Society of Chemical Industry and the Institute of Brewing and served on the council of each. He died at home in Burton-on-Trent in 1907 and was buried near Bandon. He had married in 1871 Edithe, the daughter of Joseph Nadin of Barrow Hall, near Derby, and had three sons (one of whom died in early youth) and one daughter. References",
                    "score": 0.813289999961853
                },
                {
                    "id": 1638661,
                    "contents": "Carbohydrate\nMonosaccharides are classified according to three different characteristics: the placement of its carbonyl group, the number of carbon atoms it contains, and its chiral handedness. If the carbonyl group is an aldehyde, the monosaccharide is an aldose; if the carbonyl group is a ketone, the monosaccharide is a ketose. Monosaccharides with three carbon atoms are called trioses, those with four are called tetroses, five are called pentoses, six are hexoses, and so on. These two systems of classification are often combined. For example, glucose is an aldohexose (a six-carbon aldehyde), ribose is an aldopentose (a five-carbon aldehyde), and fructose is a ketohexose (a six-carbon ketone).",
                    "score": 0.8131317496299744
                },
                {
                    "id": 743677,
                    "contents": "Hexose\nIn chemistry, a hexose is a monosaccharide (simple sugar) with six carbon atoms. The chemical formula for all hexoses is C6H12O6, and their molecular weight is 180.156 g/mol. Hexoses exist in two forms, open-chain or cyclic, that easily convert into each other in aqueous solutions. The open-chain form of a hexose, which usually is favored in solutions, has the general structure H–(CHOH)n−1–C(=O)–(CHOH)4−n–H, where n is 1, 2, or 3. Namely, five of the carbons have one hydroxyl functional group (–OH) each, connected by a single bond, and one has an oxo group (=O), forming a carbonyl group (C=O). The remaining bonds of the carbon atoms are satisfied by seven hydrogen atoms. The carbons are commonly numbered 1 to 6 starting at the end closest to the carbonyl.",
                    "score": 0.8128571510314941
                },
                {
                    "id": 743678,
                    "contents": "Hexose\nHexoses are extremely important in biochemistry, both as isolated molecules (such as glucose and fructose) and as building blocks of other compounds such as starch, cellulose, and glycosides. Hexoses can form dihexose (like sucrose) by a condensation reaction that makes 1,6-glycosidic bond. When the carbonyl is in position 1, forming an formyl group (–CH=O), the sugar is called an aldohexose, a special case of aldose. Otherwise, if the carbonyl position is 2 or 3, the sugar is a derivative of a ketone, and is called a ketohexose, a special case of ketose; specifically, an n-ketohexose. However, the 3-ketohexoses have not been observed in nature, and are difficult to synthesize; so the term \"ketohexose\" usually means 2-ketohexose.",
                    "score": 0.8127855658531189
                },
                {
                    "id": 1638667,
                    "contents": "Carbohydrate\nMonosaccharides are the major fuel source for metabolism, being used both as an energy source (glucose being the most important in nature as it is the product of photosynthesis in plants) and in biosynthesis. When monosaccharides are not immediately needed, they are often converted to more space-efficient (ie, less water soluble) forms, often polysaccharides. In many animals, including humans, this storage form is glycogen, especially in liver and muscle cells. In plants, starch is used for the same purpose. The most abundant carbohydrate, cellulose, is a structural component of the cell wall of plants and many forms of algae. Ribose is a component of RNA. Deoxyribose is a component of DNA. Lyxose is a component of lyxoflavin found in the human heart. Ribulose and xylulose occur in the pentose phosphate pathway. Galactose, a component of milk sugar lactose, is found in galactolipids in plant cell membranes and in glycoproteins in many tissues. Mannose occurs in human metabolism,",
                    "score": 0.8126782178878784
                },
                {
                    "id": 4236767,
                    "contents": "Reducing sugar\nA reducing sugar is any sugar that is capable of acting as a reducing agent. In an alkaline solution, a reducing sugar forms some aldehyde or ketone, which allows it to act as a reducing agent, for example in Benedict's reagent. In such a reaction, the sugar becomes a carboxylic acid. All monosaccharides are reducing sugars, along with some disaccharides, some oligosaccharides, and some polysaccharides. The monosaccharides can be divided into two groups: the aldoses, which have an aldehyde group, and the ketoses, which have a ketone group. Ketoses must first tautomerize to aldoses before they can act as reducing sugars. The common dietary monosaccharides galactose, glucose and fructose are all reducing sugars.",
                    "score": 0.8124637007713318
                },
                {
                    "id": 1638659,
                    "contents": "Carbohydrate\nMonosaccharides Monosaccharides are the simplest carbohydrates in that they cannot be hydrolyzed to smaller carbohydrates. They are aldehydes or ketones with two or more hydroxyl groups. The general chemical formula of an unmodified monosaccharide is (C•H2O)n, literally a \"carbon hydrate\". Monosaccharides are important fuel molecules as well as building blocks for nucleic acids. The smallest monosaccharides, for which n=3, are dihydroxyacetone and D- and L-glyceraldehydes.",
                    "score": 0.81230229139328
                },
                {
                    "id": 2006648,
                    "contents": "Pyrolysis\nBelow about 100 °C, volatiles, including some water, evaporate. Heat-sensitive substances, such as vitamin C and proteins, may partially change or decompose already at this stage. At about 100 °C or slightly higher, any remaining water that is merely absorbed in the material is driven off. This process consumes a lot of energy, so the temperature may stop rising until all water has evaporated. Water trapped in crystal structure of hydrates may come off at somewhat higher temperatures. Some solid substances, like fats, waxes, and sugars, may melt and separate.",
                    "score": 0.8118700385093689
                },
                {
                    "id": 1645971,
                    "contents": "Calorie\nThe lingering use in chemistry is largely due to the fact that the energy released by a reaction in aqueous solution, expressed in kilocalories per mole of reagent, is numerically close to the concentration of the reagent, in moles per liter, times the change in the temperature of the solution, in kelvin or degrees Celsius. However, this estimate assumes that the volumetric heat capacity of the solution is 1 kcal/L/K, which is not exact even for pure water. See also Basal metabolic rate Caloric theory Conversion of units of energy Empty calorie Food energy Nutrition facts label British Thermal Unit References Units of energy Heat transfer Non-SI metric units",
                    "score": 0.8118378520011902
                },
                {
                    "id": 28288349,
                    "contents": "John Edwin MacKenzie\nIn 1916 he was elected a Fellow of the Royal Society of Edinburgh. His proposers were Sir James Walker, Leonard Dobbin, Cargill Gilston Knott and Arthur Robinson. He served as Curator to the Society’s collections from 1939 to 1949 and as Secretary 1950 to 1953. He retired in 1938 and died in Edinburgh on 5 February 1955. Publications The Sugars and their Simple Derivatives (1913) Family He was married with two sons. References 1868 births 1955 deaths People from Helensburgh Scottish chemists Alumni of the University of Edinburgh Academics of the University of Edinburgh People educated at Larchfield Academy Fellows of the Royal Society of Edinburgh",
                    "score": 0.811241865158081
                },
                {
                    "id": 27890399,
                    "contents": "Carbon snake\nWhen sucrose is dehydrated, heat is given out to the surroundings in an exothermic reaction, while graphite and liquid water are produced by the decomposition of the sugar: C12H22O11 + H2SO4 + 1/2 O2 → 11 C + CO2 + 12 H2O + SO2 As the acid dehydrates the sucrose, the water produced will dilute the sulfuric acid, giving out energy in the form of heat. C12H22O11 → 12 C + 11 H2O Alternative experiment Paranitroaniline can be used instead of sugar, if the experiment is allowed to proceed under an obligatory fumehood. With this method the reaction phase prior to the black snake's appearance is longer, but once complete, the black snake itself rises from the container very rapidly. This reaction may cause an explosion if too much sulfuric acid is used. See also Elephant's toothpaste Black snake (firework) Chemical volcano Diet Coke and Mentos eruption References External links",
                    "score": 0.8109679818153381
                },
                {
                    "id": 10807272,
                    "contents": "Aldonic acid\nAn aldonic acid is any of a family of sugar acids obtained by oxidation of the aldehyde functional group of an aldose to form a carboxylic acid functional group. Thus, their general chemical formula is HOOC-(CHOH)n-CH2OH. Oxidation of the terminal hydroxyl group instead of the terminal aldehyde yields a uronic acid, while oxidation of both terminal ends yields an aldaric acid. Aldonic acids are typically prepared by oxidation of the sugar with bromine. They are generally found in their lactone form, with the ring structure essentially the same as in the original sugar's cyclic hemiacetal form, which is the form the sugar is usually found in. However, unlike hemiacetals, lactones do not have a chiral anomeric carbon, and they cannot form glycosidic linkages. Aldonic acids are found in many biological systems, and are the products of the oxidation of aldoses by Benedict's or Fehling's reagents. Their lactones are key intermediates in the Kiliani-Fischer synthesis of sugars.",
                    "score": 0.8108730912208557
                },
                {
                    "id": 1748497,
                    "contents": "Glucose\nThe open-chain form is thermodynamically unstable, and it spontaneously isomerizes to the cyclic forms. (Although the ring closure reaction could in theory create four- or three-atom rings, these would be highly strained, and are not observed in practice.) In solutions at room temperature, the four cyclic isomers interconvert over a time scale of hours, in a process called mutarotation. Starting from any proportions, the mixture converges to a stable ratio of α:β 36:64. The ratio would be α:β 11:89 if it were not for the influence of the anomeric effect. Mutarotation is considerably slower at temperatures close to .",
                    "score": 0.8103746771812439
                },
                {
                    "id": 13240817,
                    "contents": "Diose\nA diose is a monosaccharide containing two carbon atoms. Because the general chemical formula of an unmodified monosaccharide is (C·H2O)n, where n is three or greater, it does not meet the formal definition of a monosaccharide. However, since it does fit the formula (C·H2O)n, it is sometimes thought of as the most basic sugar. There is only one possible diose, glycolaldehyde (2-hydroxyethanal), which is an aldodiose (a ketodiose is not possible since there are only two carbons). See also Triose Tetrose Pentose Hexose Heptose References Monosaccharides",
                    "score": 0.8102986216545105
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_12",
        "question": "An electron confined to a metallic nanoparticle is modelled as a particle in a one-dimensional box of length $L$. If the electron is in the state $n=1$, calculate the probability of finding it in the following regions: $0 \\leq x \\leq \\frac{1}{2} L$.",
        "golden_answers": [
            " $\\frac{1}{2}$"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1628627,
                    "contents": "Condensed matter physics\nPaul Drude in 1900 proposed the first theoretical model for a classical electron moving through a metallic solid. Drude's model described properties of metals in terms of a gas of free electrons, and was the first microscopic model to explain empirical observations such as the Wiedemann–Franz law. However, despite the success of Drude's free electron model, it had one notable problem: it was unable to correctly explain the electronic contribution to the specific heat and magnetic properties of metals, and the temperature dependence of resistivity at low temperatures.",
                    "score": 0.8573725819587708
                },
                {
                    "id": 597145,
                    "contents": "Mean free path\nIn macroscopic charge transport, the mean free path of a charge carrier in a metal is proportional to the electrical mobility , a value directly related to electrical conductivity, that is: where q is the charge, is the mean free time, m* is the effective mass, and vF is the Fermi velocity of the charge carrier. The Fermi velocity can easily be derived from the Fermi energy via the non-relativistic kinetic energy equation. In thin films, however, the film thickness can be smaller than the predicted mean free path, making surface scattering much more noticeable, effectively increasing the resistivity. Electron mobility through a medium with dimensions smaller than the mean free path of electrons occurs through ballistic conduction or ballistic transport. In such scenarios electrons alter their motion only in collisions with conductor walls.",
                    "score": 0.8544837832450867
                },
                {
                    "id": 10158505,
                    "contents": "Shubnikov–de Haas effect\nTheory Consider a two-dimensional quantum gas of electrons confined in a sample with given width and with edges. In the presence of a magnetic flux density B, the energy eigenvalues of this system are described by Landau levels. As shown in Fig 1, these levels are equidistant along the vertical axis. Each energy level is substantially flat inside a sample (see Fig 1). At the edges of a sample, the work function bends levels upwards. Fig 1 shows the Fermi energy EF located in between two Landau levels. Electrons become mobile as their energy levels cross the Fermi energy EF. With the Fermi energy EF in between two Landau levels, scattering of electrons will occur only at the edges of a sample where the levels are bent. The corresponding electron states are commonly referred to as edge channels.",
                    "score": 0.853154182434082
                },
                {
                    "id": 3368497,
                    "contents": "Quantum dot\nTherefore, the sum of these energies can be represented as: where μ is the reduced mass, a is the radius of the quantum dot, me is the free electron mass, mh is the hole mass, and εr is the size-dependent dielectric constant. Although the above equations were derived using simplifying assumptions, they imply that the electronic transitions of the quantum dots will depend on their size. These quantum confinement effects are apparent only below the critical size. Larger particles do not exhibit this effect. This effect of quantum confinement on the quantum dots has been repeatedly verified experimentally and is a key feature of many emerging electronic structures. The Coulomb interaction between confined carriers can also be studied by numerical means when results unconstrained by asymptotic approximations are pursued.",
                    "score": 0.8493974208831787
                },
                {
                    "id": 5330392,
                    "contents": "Jellium\nJellium, also known as the uniform electron gas (UEG) or homogeneous electron gas (HEG), is a quantum mechanical model of interacting electrons in a solid where the positive charges (i.e. atomic nuclei) are assumed to be uniformly distributed in space; the electron density is a uniform quantity as well in space. This model allows one to focus on the effects in solids that occur due to the quantum nature of electrons and their mutual repulsive interactions (due to like charge) without explicit introduction of the atomic lattice and structure making up a real material. Jellium is often used in solid-state physics as a simple model of delocalized electrons in a metal, where it can qualitatively reproduce features of real metals such as screening, plasmons, Wigner crystallization and Friedel oscillations.",
                    "score": 0.8488730788230896
                },
                {
                    "id": 6082636,
                    "contents": "Atom cluster\nA gradual transition occurs between the properties of the molecular species and those of the corresponding bulk mix with increasing number N of atoms in the core, since the fraction of atoms adjacent to its surface will scale approximately as N−1/3. If N is 105, when the cluster can be considered a nanoparticle, only about 10% of the atoms in the core will be exposed at its surface. That is still significant percentage, which is part of the reason why the properties of nanoparticles are still significantly different from those of the bulk substance.",
                    "score": 0.8473929166793823
                },
                {
                    "id": 26100689,
                    "contents": "Characterization of nanoparticles\nBackground Nanotechnology is the manipulation of matter at the atomic scale to create materials, devices, or systems with new properties or functions. It has potential applications in energy, healthcare, industry, communications, agriculture, consumer products, and other sectors. Nanoparticles measure less than 100 nanometers in at least one of their external dimensions, and often have properties different from the bulk versions of their component materials, which make them technologically useful. This article uses a broad definition of nanoparticles which includes all free nanomaterials regardless of their shape or how many of their dimensions are nanoscale, rather than the more restrictive ISO/TS 80004 definition that only refers to round nano-objects.",
                    "score": 0.8467491865158081
                },
                {
                    "id": 1560692,
                    "contents": "Atom\nThe potential energy of an electron in an atom is negative relative to when the distance from the nucleus goes to infinity; its dependence on the electron's position reaches the minimum inside the nucleus, roughly in inverse proportion to the distance. In the quantum-mechanical model, a bound electron can occupy only a set of states centered on the nucleus, and each state corresponds to a specific energy level; see time-independent Schrödinger equation for a theoretical explanation. An energy level can be measured by the amount of energy needed to unbind the electron from the atom, and is usually given in units of electronvolts (eV). The lowest energy state of a bound electron is called the ground state, i.e. stationary state, while an electron transition to a higher level results in an excited state. The electron's energy increases along with n because the (average) distance to the nucleus increases. Dependence of the energy on is caused not by the electrostatic potential of the",
                    "score": 0.8436691761016846
                },
                {
                    "id": 4945948,
                    "contents": "Nanoparticle\nQuantum mechanics effects Quantum mechanics effects become noticeable for nanoscale objects. They include quantum confinement in semiconductor particles, localized surface plasmons in some metal particles, and superparamagnetism in magnetic materials. Quantum dots are nanoparticles of semiconducting material that are small enough (typically sub 10 nm or less) to have quantized electronic energy levels. Quantum effects are responsible for the deep-red to black color of gold or silicon nanopowders and nanoparticle suspensions. Absorption of solar radiation is much higher in materials composed of nanoparticles than in thin films of continuous sheets of material. In both solar PV and solar thermal applications, by controlling the size, shape, and material of the particles, it is possible to control solar absorption.",
                    "score": 0.8432285785675049
                },
                {
                    "id": 4443137,
                    "contents": "Free electron model\nThe name of the model comes from the first two assumptions, as each electron can be treated as free particle with a respective quadratic relation between energy and momentum. The crystal lattice is not explicitly taken into account in the free electron model, but a quantum-mechanical justification was given a year later (1928) by Bloch's theorem: an unbound electron moves in a periodic potential as a free electron in vacuum, except for the electron mass me becoming an effective mass m* which may deviate considerably from me (one can even use negative effective mass to describe conduction by electron holes). Effective masses can be derived from band structure computations that were not originally taken into account in the free electron model. From the Drude model",
                    "score": 0.8431683778762817
                },
                {
                    "id": 4721175,
                    "contents": "Relativistic quantum chemistry\nwhere is the reduced Planck's constant, and α is the fine-structure constant (a relativistic correction for the Bohr model). Arnold Sommerfeld calculated that, for a 1s orbital electron of a hydrogen atom with an orbiting radius of 0.0529 nm, α ≈ 1/137. That is to say, the fine-structure constant shows the electron traveling at nearly 1/137 the speed of light. One can extend this to a larger element with an atomic number Z by using the expression for a 1s electron, where v is its radial velocity, i.e., its instantaneous speed tangent to the radius of the atom. For gold with Z = 79, v ≈ 0.58c, so the 1s electron will be moving at 58% of the speed of light. Plugging this in for v/c in the equation for the relativistic mass, one finds that mrel = 1.22me, and in turn putting this in for the Bohr radius above one finds that the radius shrinks by 22%. If one substitutes the \"relativistic mass\" into the equation for the Bohr radius it can be written It follows that",
                    "score": 0.8421617746353149
                },
                {
                    "id": 4443143,
                    "contents": "Free electron model\nIf this was the case, the heat capacity of a metal could be much higher due to this electronic contribution. Nevertheless, such a large heat capacity was never measured, raising suspicions about the argument. By using Sommerfeld's expansion one can obtain corrections of the energy density at finite temperature and obtain the volumetric heat capacity of an electron gas, given by: ,",
                    "score": 0.8411538004875183
                },
                {
                    "id": 15072220,
                    "contents": "Two-electron atom\nIn atomic physics, a two-electron atom or helium-like ion is a quantum mechanical system consisting of one nucleus with a charge of Ze and just two electrons. This is the first case of many-electron systems where the Pauli exclusion principle plays a central role. It is an example of a three-body problem. The first few two-electron atoms are: Schrödinger equation The Schrödinger equation for any two-electron system, such as the neutral Helium atom (He, Z = 2), the negative Hydrogen ion (H−, Z = 1), or the positive Lithium ion (Li+, Z = 3) is: For a more rigorous mathematical derivation of Schrödinger's equation, see also. where r1 is the position of one electron (r1 = |r1| is its magnitude), r2 is the position of the other electron (r2 = |r2| is the magnitude), r12 = |r12| is the magnitude of the separation between them given by μ is the two-body reduced mass of an electron with respect to the nucleus of mass M and Z is the atomic number for the element (not a quantum number).",
                    "score": 0.8404446840286255
                },
                {
                    "id": 15546545,
                    "contents": "Holon (physics)\nOverview Electrons, being fermions, repel each other due to the Pauli exclusion principle. As a result, in order to move past each other in an extremely crowded environment, they are forced to modify their behavior. Research published in July 2009 by the University of Cambridge and the University of Birmingham in England showed that electrons could jump past each other by quantum tunneling, and in order to do so will separate into two particles, named spinons and holons by the researchers. Notes General References See also Condensed matter physics Tomonaga–Luttinger liquid Quasiparticles",
                    "score": 0.8397767543792725
                },
                {
                    "id": 22495769,
                    "contents": "Strictly-Correlated-Electrons density functional theory\nSuppose now that in this classical system one of the charges, which we can label as number “1”, is pinned at some arbitrary position inside the container. Clearly, the equilibrium position of the other charges will now not only depend on the shape of the container, but also on the position of the pinned charge. Thus, for a given confining geometry, one can write the position of the -th particle , , as a function of : .",
                    "score": 0.8390880227088928
                },
                {
                    "id": 2860537,
                    "contents": "Valence electron\nSimilar to a core electron, a valence electron has the ability to absorb or release energy in the form of a photon. An energy gain can trigger the electron to move (jump) to an outer shell; this is known as atomic excitation. Or the electron can even break free from its associated atom's shell; this is ionization to form a positive ion. When an electron loses energy (thereby causing a photon to be emitted), then it can move to an inner shell which is not fully occupied. Overview Electron configuration The electrons that determine valence – how an atom reacts chemically – are those with the highest energy.",
                    "score": 0.8378047943115234
                },
                {
                    "id": 4443146,
                    "contents": "Free electron model\nMean free path Notice that without the relaxation time approximation, there is no reason for the electrons to deflect their motion, as there are no interactions, thus the mean free path should be infinite. The Drude model considered the mean free path of electrons to be close to the distance between ions in the material, implying the earlier conclusion that the diffusive motion of the electrons was due to collisions with the ions. The mean free paths in the free electron model are instead given by (where is the Fermi speed) and are in the order of hundreds of ångströms, at least one order of magnitude larger than any possible classical calculation. The mean free path is then not a result of electron–ion collisions but instead is related to imperfections in the material, either due to defects and impurities in the metal, or due to thermal fluctuations.",
                    "score": 0.8373713493347168
                },
                {
                    "id": 4945925,
                    "contents": "Nanoparticle\nA nanoparticle or ultrafine particle is usually defined as a particle of matter that is between 1 and 100 nanometres (nm) in diameter. The term is sometimes used for larger particles, up to 500 nm, or fibers and tubes that are less than 100 nm in only two directions. At the lowest range, metal particles smaller than 1 nm are usually called atom clusters instead. Nanoparticles are usually distinguished from microparticles (1-1000 µm), \"fine particles\" (sized between 100 and 2500 nm), and \"coarse particles\" (ranging from 2500 to 10,000 nm), because their smaller size drives very different physical or chemical properties, like colloidal properties and ultrafast optical effects or electric properties. Being more subject to the brownian motion, they usually do not sediment, like colloidal particles that conversely are usually understood to range from 1 to 1000 nm.",
                    "score": 0.8373575210571289
                },
                {
                    "id": 6793053,
                    "contents": "Free electron\nFree electron in physics may refer to: Electron, as a free particle Solvated electron Charge carrier, as carriers of electric charge Valence electron, as an outer shell electron that is associated with an atom Valence and conduction bands, as a conduction band electron relative to the electronic band structure of a solid Fermi gas, as a particle of a non-interacting electron gas Free electron model, as a particle in the Drude-Sommerfeld model of metals Free-electron laser, as a particle in the electron beam See also Independent electron approximation Lone pair or free electron pair Nearly free electron model Orbital angular momentum of free electrons Unpaired electron",
                    "score": 0.8368067741394043
                },
                {
                    "id": 24099959,
                    "contents": "ISSPIC\nThe main theme of the first couple of ISSPIC symposiums was fundamental studies on the finite-size effects of atomic and molecular clusters. The discussion emphasized the physical aspects. At the beginning the conference was organized every fourth year but since 1988 it was held every two years. The conference has become a fundamental event on the area of the nanoscience and the research of nanoclusters during the last decades. Conference topics Scientists, such as chemists, physicists and nanotechnogists, who do the research on the area of atomic or molecular clusters and structures, nanoparticles and nanostructures, introduce and discuss about the latest results and scientific achievements in the ISSPIC conference. The discussion also provides new approaches into these topics.",
                    "score": 0.8367937803268433
                },
                {
                    "id": 4945927,
                    "contents": "Nanoparticle\nThe properties of nanoparticles often differ markedly from those of larger particles of the same substance. Since the typical diameter of an atom is between 0.15 and 0.6 nm, a large fraction of the nanoparticle's material lies within a few atomic diameters from its surface. Therefore, the properties of that surface layer may dominate over those of the bulk material. This effect is particularly strong for nanoparticles dispersed in a medium of different composition since the interactions between the two materials at their interface also becomes significant.",
                    "score": 0.8365399837493896
                },
                {
                    "id": 990779,
                    "contents": "Atomic radius\nExplanation of the general trends The way the atomic radius varies with increasing atomic number can be explained by the arrangement of electrons in shells of fixed capacity. The shells are generally filled in order of increasing radius, since the negatively charged electrons are attracted by the positively charged protons in the nucleus. As the atomic number increases along each row of the periodic table, the additional electrons go into the same outermost shell; whose radius gradually contracts, due to the increasing nuclear charge. In a noble gas, the outermost shell is completely filled; therefore, the additional electron of next alkali metal will go into the next outer shell, accounting for the sudden increase in the atomic radius.",
                    "score": 0.836535632610321
                },
                {
                    "id": 3368496,
                    "contents": "Quantum dot\nConfinement energy The exciton entity can be modeled using the particle in the box. The electron and the hole can be seen as hydrogen in the Bohr model with the hydrogen nucleus replaced by the hole of positive charge and negative electron mass. Then the energy levels of the exciton can be represented as the solution to the particle in a box at the ground level (n = 1) with the mass replaced by the reduced mass. Thus by varying the size of the quantum dot, the confinement energy of the exciton can be controlled. Bound exciton energy There is Coulomb attraction between the negatively charged electron and the positively charged hole. The negative energy involved in the attraction is proportional to Rydberg's energy and inversely proportional to square of the size-dependent dielectric constant of the semiconductor. When the size of the semiconductor crystal is smaller than the Exciton Bohr radius, the Coulomb interaction must be modified to fit the situation.",
                    "score": 0.8364974856376648
                },
                {
                    "id": 3564665,
                    "contents": "Potential well\nQuantum mechanics view The electronic and optical properties of materials are affected by size and shape. Well-established technical achievements including quantum dots were derived from size manipulation and investigation for their theoretical corroboration on quantum confinement effect. The major part of the theory is the behaviour of the exciton resembles that of an atom as its surrounding space shortens. A rather good approximation of an exciton's behaviour is the 3-D model of a particle in a box. The solution of this problem provides a sole mathematical connection between energy states and the dimension of space. Decreasing the volume or the dimensions of the available space, increases the energy of the states. Shown in the diagram is the change in electron energy level and bandgap between nanomaterial and its bulk state. The following equation shows the relationship between energy level and dimension spacing:",
                    "score": 0.8358995318412781
                },
                {
                    "id": 23021814,
                    "contents": "Nanocluster\nSize and number of atoms in metal nanoclusters According to the Japanese mathematical physicist Ryogo Kubo, the spacing of energy levels can be predicted by where EF is Fermi energy and N is the number of atoms. For quantum confinement 𝛿 can be estimated to be equal to the thermal energy (), where k is Boltzmann's constant and T is temperature. Stability",
                    "score": 0.8355218768119812
                },
                {
                    "id": 3465527,
                    "contents": "Drude model\nThe model can also be applied to positive (hole) charge carriers. In his original paper, Drude made an error, estimating the Lorenz number of Wiedemann–Franz law to be twice what it classically should have been, thus making it seem in agreement with the experimental value of the specific heat. This number is about 100 times smaller than the classical prediction but this factor cancels out with the mean electronic speed that is about 100 times bigger than Drude's calculation. See also Free electron model Arnold Sommerfeld Electrical conductivity Citations References General External links Condensed matter physics Electric and magnetic fields in matter",
                    "score": 0.835504412651062
                },
                {
                    "id": 752961,
                    "contents": "Electron configuration\nBohr was well aware of this shortcoming (and others), and had written to his friend Wolfgang Pauli to ask for his help in saving quantum theory (the system now known as \"old quantum theory\"). Pauli realized that the Zeeman effect must be due only to the outermost electrons of the atom, and was able to reproduce Stoner's shell structure, but with the correct structure of subshells, by his inclusion of a fourth quantum number and his exclusion principle (1925): {{Blockquote| It should be forbidden for more than one electron with the same value of the main quantum number n to have the same value for the other three quantum numbers k [], j [m] and m [ms].}}",
                    "score": 0.8351007699966431
                },
                {
                    "id": 20657483,
                    "contents": "Orbiton\nElectrons, being of like charge, repel each other. As a result, in order to move past each other in an extremely crowded environment, they are forced to modify their behavior. Research published in July 2009 by the University of Cambridge and the University of Birmingham in England showed that electrons could jump from the surface of a metal onto a closely located quantum wire by quantum tunneling, and upon doing so, will separate into two quasiparticles, named spinons and holons by the researchers.",
                    "score": 0.8346062302589417
                },
                {
                    "id": 1565158,
                    "contents": "Atomic physics\nElectrons that populate a shell are said to be in a bound state. The energy necessary to remove an electron from its shell (taking it to infinity) is called the binding energy. Any quantity of energy absorbed by the electron in excess of this amount is converted to kinetic energy according to the conservation of energy. The atom is said to have undergone the process of ionization. If the electron absorbs a quantity of energy less than the binding energy, it will be transferred to an excited state. After a certain time, the electron in an excited state will \"jump\" (undergo a transition) to a lower state. In a neutral atom, the system will emit a photon of the difference in energy, since energy is conserved.",
                    "score": 0.8343353271484375
                },
                {
                    "id": 8051557,
                    "contents": "Nearly free electron model\nMathematical formulation The nearly free electron model is a modification of the free-electron gas model which includes a weak periodic perturbation meant to model the interaction between the conduction electrons and the ions in a crystalline solid. This model, like the free-electron model, does not take into account electron–electron interactions; that is, the independent electron approximation is still in effect. As shown by Bloch's theorem, introducing a periodic potential into the Schrödinger equation results in a wave function of the form where the function uk has the same periodicity as the lattice: (where T is a lattice translation vector.) Because it is a nearly free electron approximation we can assume that where Ωr denotes the volume of states of fixed radius r (as described in Gibbs paradox). A solution of this form can be plugged into the Schrödinger equation, resulting in the central equation: where the kinetic energy is given by",
                    "score": 0.834227979183197
                },
                {
                    "id": 3326914,
                    "contents": "Effective nuclear charge\nSize of atom; The nuclear charge; The screening effect of the inner shells, and; The extent to which the outermost electron penetrates into the charge cloud set up by the inner lying electron. In the periodic table, Effective nuclear charge increases both down a group and left to right across a period. Calculations In an atom with one electron, that electron experiences the full charge of the positive nucleus. In this case, the effective nuclear charge can be calculated by Coulomb's law. However, in an atom with many electrons, the outer electrons are simultaneously attracted to the positive nucleus and repelled by the negatively charged electrons. The effective nuclear charge on such an electron is given by the following equation: where Z is the number of protons in the nucleus (atomic number), and S is the shielding constant.",
                    "score": 0.833409309387207
                },
                {
                    "id": 23021812,
                    "contents": "Nanocluster\nMaterials can be categorized into three different regimes, namely bulk, nanoparticles and nanoclusters. Bulk metals are electrical conductors and good optical reflectors and metal nanoparticles display intense colors due to surface plasmon resonance. However, when the size of metal nanoclusters is further reduced to form a nanocluster, the band structure becomes discontinuous and breaks down into discrete energy levels, somewhat similar to the energy levels of molecules. This gives nanoclusters similar qualities as a singular molecule and does not exhibit plasmonic behavior; nanoclusters are known as the bridging link between atoms and nanoparticles. Nanoclusters may also be referred to as molecular nanoparticles. History of nanoclusters",
                    "score": 0.832798421382904
                },
                {
                    "id": 16149208,
                    "contents": "Walter de Heer\nResearch De Heer and his research groups have made significant contributions to several important areas in nanoscopic physics. As a graduate student at UC-Berkeley, he participated in groundbreaking research on alkali metal clusters that demonstrated the electronic shell structure of metal clusters. This is a property of small metal clusters composed of few atoms that develop atom-like electronic properties (these clusters are also referred to as superatoms). In Switzerland, he developed methods of measuring the magnetic properties of cold metal clusters and described how magnetism develops in these clusters as their size increases from atomic to bulk. He is the author of the most highly cited review articles on metallic clusters.",
                    "score": 0.8326223492622375
                },
                {
                    "id": 17867621,
                    "contents": "Rigid-band model\nBasic concepts behind the Rigid-Band model In a pure metal of valence Z1, all atoms become positive ions with the valence +Z1 by releasing the outermost Z1 electrons per atom to form the valence band. As a result, conduction electrons carrying negative charges are uniformly distributed over any atomic site with equal probability densities and maintain charge neutrality with the array of ions with positive charges. When an impurity atom of valence Z2 is introduced, the periodic potential is disturbed, conduction electrons are scattered and a screening potential is formed where U(r) is the potential of the electrons in distance r, 1/λ is the screening radius and .",
                    "score": 0.8323834538459778
                },
                {
                    "id": 1694095,
                    "contents": "Electron\nInteractions involving electrons with other subatomic particles are of interest in fields such as chemistry and nuclear physics. The Coulomb force interaction between the positive protons within atomic nuclei and the negative electrons without, allows the composition of the two known as atoms. Ionization or differences in the proportions of negative electrons versus positive nuclei changes the binding energy of an atomic system. The exchange or sharing of the electrons between two or more atoms is the main cause of chemical bonding. In 1838, British natural philosopher Richard Laming first hypothesized the concept of an indivisible quantity of electric charge to explain the chemical properties of atoms. Irish physicist George Johnstone Stoney named this charge 'electron' in 1891, and J. J. Thomson and his team of British physicists identified it as a particle in 1897 during the cathode ray tube experiment. Electrons can also participate in nuclear reactions, such as nucleosynthesis",
                    "score": 0.8321239948272705
                },
                {
                    "id": 1177166,
                    "contents": "Particle in a box\nQuantum dots are useful for these functions due to their emission of brighter light, excitation by a wide variety of wavelengths, and higher resistance to light than other substances. Relativistic effects The probability density does not go to zero at the nodes if relativistic effects are taken to account via Dirac equation. See also History of Quantum Mechanics Finite potential well Delta function potential Gas in a box Particle in a ring Particle in a spherically symmetric potential Quantum harmonic oscillator Semicircle potential well Configuration integral (statistical mechanics) Configuration integral (statistical mechanics), 2008. this wiki site is down; see this article in the web archive on 2012 April 28. References Bibliography External links Quantum models Quantum mechanical potentials",
                    "score": 0.8320848941802979
                },
                {
                    "id": 3368498,
                    "contents": "Quantum dot\nThe Coulomb interaction between confined carriers can also be studied by numerical means when results unconstrained by asymptotic approximations are pursued. Besides confinement in all three dimensions (i.e., a quantum dot), other quantum confined semiconductors include: Quantum wires, which confine electrons or holes in two spatial dimensions and allow free propagation in the third. Quantum wells, which confine electrons or holes in one dimension and allow free propagation in two dimensions. Models A variety of theoretical frameworks exist to model optical, electronic, and structural properties of quantum dots. These may be broadly divided into quantum mechanical, semiclassical, and classical. Quantum mechanics Quantum mechanical models and simulations of quantum dots often involve the interaction of electrons with a pseudopotential or random matrix.",
                    "score": 0.8314990401268005
                },
                {
                    "id": 3368441,
                    "contents": "Quantum dot\nQuantum dots (QDs) are semiconductor particles a few nanometres in size, having optical and electronic properties that differ from larger particles due to quantum mechanics. They are a central topic in nanotechnology. When the quantum dots are illuminated by UV light, an electron in the quantum dot can be excited to a state of higher energy. In the case of a semiconducting quantum dot, this process corresponds to the transition of an electron from the valence band to the conductance band. The excited electron can drop back into the valence band releasing its energy by the emission of light. This light emission (photoluminescence) is illustrated in the figure on the right. The color of that light depends on the energy difference between the conductance band and the valence band, or transition between discretized energy states when band structure is no longer a good definition in QDs.",
                    "score": 0.8313162326812744
                },
                {
                    "id": 14311955,
                    "contents": "Electron localization function\nThe ELF was originally defined by Becke and Edgecombe in 1990. They first argued that a measure of the electron localization is provided by where ρ is the electron spin density and τ the kinetic energy density. The second term (negative term) is the bosonic kinetic energy density, so D is the contribution due to fermions. D is expected to be small in those regions of space where localized electrons are to be found. Given the arbitrariness of the magnitude of the localization measure provided by D, it is compared to the corresponding value for a uniform electron gas with spin density equal to ρ(r), which is given by The ratio, is a dimensionless localization index that expresses electron localization for the uniform electron gas. In the final step, the ELF is defined in terms of χ by mapping its values on to the range 0 ≤ ELF ≤ 1 by defining the electron localization function as ELF = 1 corresponding to perfect localization and ELF = ½ corresponding to the electron gas.",
                    "score": 0.8307974934577942
                },
                {
                    "id": 18504583,
                    "contents": "Ballistic conduction in single-walled carbon nanotubes\nFor a system with dense states, the discrete sum can be approximated by an integral: In CNT FETs, the charge carriers move either left (negative velocity) or right (positive velocity) and the resulting net current is called drain current. The source potential controls the right-moving, and the drain potential - the left moving carriers and if the source potential is set to zero, the Fermi energy at the drain subsequently decreases to yield positive drain voltage. The total drain current is computed as a sum of all contributing subbands in the semiconductor CNT, but given the low voltages used with nanoscale electronics, higher subbands can be effectively ignored and the drain current is given only by the contribution of the first subband: where and is the quantum resistance. The expression for gives the ballistic current dependence on the voltage in a CNT FET with ideal contacts.",
                    "score": 0.8302194476127625
                },
                {
                    "id": 4443150,
                    "contents": "Free electron model\nOther inadequacies are present in the Wiedemann–Franz law at intermediate temperatures and the frequency-dependence of metals in the optical spectrum. More exact values for the electrical conductivity and Wiedemann–Franz law can be obtained by softening the relaxation-time approximation by appealing to the Boltzmann transport equations or the Kubo formula. Spin is mostly neglected in the free electron model and its consequences can lead to emergent magnetic phenomena like Pauli paramagnetism and ferromagnetism. An immediate continuation to the free electron model can be obtained by assuming the empty lattice approximation, which forms the basis of the band structure model known as the nearly free electron model.",
                    "score": 0.8299046158790588
                },
                {
                    "id": 8051562,
                    "contents": "Nearly free electron model\nThe force between the ions and the electrons is greatest at very small distances. However, the conduction electrons are not \"allowed\" to get this close to the ion cores due to the Pauli exclusion principle: the orbitals closest to the ion core are already occupied by the core electrons. Therefore, the conduction electrons never get close enough to the ion cores to feel their full force. Furthermore, the core electrons shield the ion charge magnitude \"seen\" by the conduction electrons. The result is an effective nuclear charge experienced by the conduction electrons which is significantly reduced from the actual nuclear charge. See also Empty lattice approximation Electronic band structure Tight binding model Bloch's theorem Kronig–Penney model References Electronic band structures",
                    "score": 0.8297125697135925
                },
                {
                    "id": 1177140,
                    "contents": "Particle in a box\nIn quantum mechanics, the particle in a box model (also known as the infinite potential well or the infinite square well) describes a particle free to move in a small space surrounded by impenetrable barriers. The model is mainly used as a hypothetical example to illustrate the differences between classical and quantum systems. In classical systems, for example, a particle trapped inside a large box can move at any speed within the box and it is no more likely to be found at one position than another. However, when the well becomes very narrow (on the scale of a few nanometers), quantum effects become important. The particle may only occupy certain positive energy levels. Likewise, it can never have zero energy, meaning that the particle can never \"sit still\". Additionally, it is more likely to be found at certain positions than at others, depending on its energy level. The particle may never be detected at certain positions, known as spatial nodes.",
                    "score": 0.8293531537055969
                },
                {
                    "id": 23643468,
                    "contents": "Total position spread\nOverview The Localization Tensor (LT) is a per electron quantity proposed in the context of the theory of Kohn to characterize electrical conductivity properties. In 1964, Kohn realized that electrical conductivity is more related to the proper delocalization of the wave function than a simple bandgap. In fact, he proposed that a qualitative difference between insulators and conductors also manifests as a different organization of the electrons in their ground state where one has that: the wave function is strongly localized in insulators and very delocalized in conductors. The interesting outcome of this theory is: i) it relates the classical idea of localized electrons as a cause of insulating state; ii) the needed information can be recovered from the ground state wave function because in the insulated regime the wave function breaks down as a sum of disconnected terms.",
                    "score": 0.8288635015487671
                },
                {
                    "id": 2732536,
                    "contents": "Particle in a one-dimensional lattice\nFor a different and detailed calculation of the gap formula (i.e. for the gap between bands) and the level splitting of eigenvalues of the one-dimensional Schrödinger equation see Müller-Kirsten. Corresponding results for the cosine potential (Mathieu equation) are also given in detail in this reference. See also Free electron model Empty lattice approximation Nearly free electron model Crystal structure Mathieu function References External links \"The Kronig–Penney Model\" by Michael Croucher, an interactive calculation of 1d periodic potential band structure using Mathematica, from The Wolfram Demonstrations Project. Condensed matter physics Quantum models",
                    "score": 0.8288558125495911
                },
                {
                    "id": 17840354,
                    "contents": "Poole–Frenkel effect\nwhere is the zero-field electrical conductivity is a constant E is the applied electric field. In this model the conduction is supposed to be carried by a free electron system moving in a self-consistent periodic potential. On the contrary, Frenkel derived his formula describing the dielectric (or the semiconductor) as simply composed by neutral atoms acting as positively charged trap states (when empty, i.e. when the atoms are ionized). For localized trap states with Coulomb potentials, the barrier height that an electron must cross to move from one atom to another is the depth of the trap potential well. Without any externally applied electric field, the maximum value of the potential is zero and is located at infinite distance from the trap center. When an external electric field is applied, the height of the potential barrier is reduced on one side of the trap by the amount",
                    "score": 0.8286003470420837
                },
                {
                    "id": 752950,
                    "contents": "Electron configuration\nFor atoms with many electrons, this notation can become lengthy and so an abbreviated notation is used. The electron configuration can be visualized as the core electrons, equivalent to the noble gas of the preceding period, and the valence electrons: each element in a period differs only by the last few subshells. Phosphorus, for instance, is in the third period. It differs from the second-period neon, whose configuration is 1s2 2s2 2p6, only by the presence of a third shell. The portion of its configuration that is equivalent to neon is abbreviated as [Ne], allowing the configuration of phosphorus to be written as [Ne] 3s2 3p3 rather than writing out the details of the configuration of neon explicitly. This convention is useful as it is the electrons in the outermost shell that most determine the chemistry of the element.",
                    "score": 0.8285622596740723
                },
                {
                    "id": 19061649,
                    "contents": "Field effect (semiconductor)\nof electrons is shown, so a positive voltage penetrating the surface lowers the conduction edge. A dashed line depicts the occupancy situation: below this Fermi level the states are more likely to be occupied, the conduction band moves closer to the Fermi level, indicating more electrons are in the conducting band near the insulator.",
                    "score": 0.828409731388092
                },
                {
                    "id": 4945942,
                    "contents": "Nanoparticle\nDiffusion across the surface The high surface area of a material in nanoparticle form allows heat, molecules, and ions to diffuse into or out of the particles at very large rates. The small particle diameter, on the other hand, allows the whole material to reach homogeneous equilibrium with respect to diffusion in a very short time. Thus many processes that depend on diffusion, such as sintering can take place at lower temperatures and over shorter time scales inducing catalysis. Ferromagnetic and ferroelectric effects The small size of nanoparticles affects their magnetic and electric properties. The ferromagnetic materials in the micrometer range is a good example: widely used in magnetic recording media, for the stability of their magnetization state, those particles smaller than 10 nm are unstable and can change their state (flip) as the result of thermal energy at ordinary temperatures, thus making them unsuitable for that application.",
                    "score": 0.8283008337020874
                },
                {
                    "id": 1867481,
                    "contents": "Metallic bonding\nWith the advent of quantum mechanics, this picture was given a more formal interpretation in the form of the free electron model and its further extension, the nearly free electron model. In both models, the electrons are seen as a gas traveling through the structure of the solid with an energy that is essentially isotropic, in that it depends on the square of the magnitude, not the direction of the momentum vector k. In three-dimensional k-space, the set of points of the highest filled levels (the Fermi surface) should therefore be a sphere. In the nearly-free model, box-like Brillouin zones are added to k-space by the periodic potential experienced from the (ionic) structure, thus mildly breaking the isotropy.",
                    "score": 0.8282089233398438
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_13",
        "question": "The carbon-carbon bond length in diamond is $154.45 \\mathrm{pm}$. If diamond were considered to be a close-packed structure of hard spheres with radii equal to half the bond length, what would be its expected density? The diamond lattice is face-centred cubic and its actual density is $3.516 \\mathrm{~g} \\mathrm{~cm}^{-3}$.",
        "golden_answers": [
            " 7.654"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1671080,
                    "contents": "Diamond\nDiamond is a solid form of pure carbon with its atoms arranged in a crystal. Solid carbon comes in different forms known as allotropes depending on the type of chemical bond. The two most common allotropes of pure carbon are diamond and graphite. In graphite the bonds are sp2 orbital hybrids and the atoms form in planes, with each bound to three nearest neighbors 120 degrees apart. In diamond they are sp3 and the atoms form tetrahedra with each bound to four nearest neighbors. Tetrahedra are rigid, the bonds are strong, and of all known substances diamond has the greatest number of atoms per unit volume, which is why it is both the hardest and the least compressible. It also has a high density, ranging from 3150 to 3530 kilograms per cubic metre (over three times the density of water) in natural diamonds and 3520 kg/m in pure diamond. In graphite, the bonds between nearest neighbors are even stronger, but the bonds between parallel adjacent planes are weak, so the planes easily slip",
                    "score": 0.9374436140060425
                },
                {
                    "id": 1671087,
                    "contents": "Diamond\nThe nearest neighbour distance in the diamond lattice is 1.732a/4 where a is the lattice constant, usually given in Angstrøms as a = 3.567 Å, which is 0.3567 nm. A diamond cubic lattice can be thought of as two interpenetrating face-centered cubic lattices with one displaced by of the diagonal along a cubic cell, or as one lattice with two atoms associated with each lattice point. Viewed from a crystallographic direction, it is formed of layers stacked in a repeating ABCABC ... pattern. Diamonds can also form an ABAB ... structure, which is known as hexagonal diamond or lonsdaleite, but this is far less common and is formed under different conditions from cubic carbon. Crystal habit",
                    "score": 0.935100793838501
                },
                {
                    "id": 1671086,
                    "contents": "Diamond\nCrystal structure The most common crystal structure of diamond is called diamond cubic. It is formed of unit cells (see the figure) stacked together. Although there are 18 atoms in the figure, each corner atom is shared by eight unit cells and each atom in the center of a face is shared by two, so there are a total of eight atoms per unit cell. The length of each side of the unit cell is denoted by a and is 3.567 angstroms. The nearest neighbour distance in the diamond lattice is 1.732a/4 where a is the lattice constant, usually given in Angstrøms as a = 3.567 Å, which is 0.3567 nm.",
                    "score": 0.9266488552093506
                },
                {
                    "id": 1627069,
                    "contents": "Carbon\nCharacteristics The allotropes of carbon include graphite, one of the softest known substances, and diamond, the hardest naturally occurring substance. It bonds readily with other small atoms, including other carbon atoms, and is capable of forming multiple stable covalent bonds with suitable multivalent atoms. Carbon is known to form almost ten million compounds, a large majority of all chemical compounds. Carbon also has the highest sublimation point of all elements. At atmospheric pressure it has no melting point, as its triple point is at and , so it sublimes at about . Graphite is much more reactive than diamond at standard conditions, despite being more thermodynamically stable, as its delocalised pi system is much more vulnerable to attack. For example, graphite can be oxidised by hot concentrated nitric acid at standard conditions to mellitic acid, C6(CO2H)6, which preserves the hexagonal units of graphite while breaking up the larger structure.",
                    "score": 0.9139435291290283
                },
                {
                    "id": 4562537,
                    "contents": "Material properties of diamond\nDiamond is the allotrope of carbon in which the carbon atoms are arranged in the specific type of cubic lattice called diamond cubic. Diamond is crystal that is transparent to opaque and which is generally isotropic (no or very weak birefringence). Diamond is the hardest naturally occurring material known. Yet, due to important structural brittleness, bulk diamond's toughness is only fair to good. The precise tensile strength of bulk diamond is little known; however, compressive strength up to has been observed, and it could be as high as in the form of micro/nanometer-sized wires or needles (~ in diameter, micrometers long), with a corresponding maximum tensile elastic strain in excess of 9%. The anisotropy of diamond hardness is carefully considered during diamond cutting. Diamond has a high refractive index (2.417) and moderate dispersion (0.044) properties that give cut diamonds their brilliance. Scientists classify diamonds into four main types according to the nature of",
                    "score": 0.9129756689071655
                },
                {
                    "id": 3489620,
                    "contents": "Allotropes of carbon\nThe crystal structure of diamond is a face-centred cubic lattice having eight atoms per unit cell to form a diamond cubic structure. Each carbon atom is covalently bonded to four other carbons in a tetrahedral geometry. These tetrahedrons together form a 3-dimensional network of six-membered carbon rings in the chair conformation, allowing for zero bond angle strain. The bonding occurs through sp3 hybridized orbitals to give a C-C bond length of 154 pm. This network of unstrained covalent bonds makes diamond extremely strong. Diamond is thermodynamically less stable than graphite at pressures below .",
                    "score": 0.9116345643997192
                },
                {
                    "id": 5822758,
                    "contents": "Diamond cubic\nThe atomic packing factor of the diamond cubic structure (the proportion of space that would be filled by spheres that are centered on the vertices of the structure and are as large as possible without overlapping) is ≈ 0.34, significantly smaller (indicating a less dense structure) than the packing factors for the face-centered and body-centered cubic lattices. Zincblende structures have higher packing factors than 0.34 depending on the relative sizes of their two component atoms. The first-, second-, third-, fourth-, and fifth-nearest-neighbor distances in units of the cubic lattice constant are , , , 1 and , respectively. Mathematical structure Mathematically, the points of the diamond cubic structure can be given coordinates as a subset of a three-dimensional integer lattice by using a cubic unit cell four units across. With these coordinates, the points of the structure have coordinates (x, y, z) satisfying the equations x = y = z (mod 2), and x + y + z = 0 or 1 (mod 4).",
                    "score": 0.909572958946228
                },
                {
                    "id": 3489654,
                    "contents": "Allotropes of carbon\nDespite the hardness of diamonds, the chemical bonds that hold the carbon atoms in diamonds together are actually weaker than those that hold together graphite. The difference is that in diamond, the bonds form an inflexible three-dimensional lattice. In graphite, the atoms are tightly bonded into sheets, but the sheets can slide easily over each other, making graphite soft. See also Superdense carbon allotropes References External links Carbon",
                    "score": 0.9079962372779846
                },
                {
                    "id": 5822756,
                    "contents": "Diamond cubic\nThe diamond cubic crystal structure is a repeating pattern of 8 atoms that certain materials may adopt as they solidify. While the first known example was diamond, other elements in group 14 also adopt this structure, including α-tin, the semiconductors silicon and germanium, and silicon–germanium alloys in any proportion. There are also crystals, such as the high-temperature form of cristobalite, which have a similar structure, with one kind of atom (such as silicon in cristobalite) at the positions of carbon atoms in diamond but with another kind of atom (such as oxygen) halfway between those (see :Category:Minerals in space group 227). Although often called the diamond lattice, this structure is not a lattice in the technical sense of this word used in mathematics. Crystallographic structure",
                    "score": 0.906116783618927
                },
                {
                    "id": 1627067,
                    "contents": "Carbon\nThe atoms of carbon can bond together in diverse ways, resulting in various allotropes of carbon. Well-known allotropes include graphite, diamond, amorphous carbon and fullerenes. The physical properties of carbon vary widely with the allotropic form. For example, graphite is opaque and black while diamond is highly transparent. Graphite is soft enough to form a streak on paper (hence its name, from the Greek verb \"γράφειν\" which means \"to write\"), while diamond is the hardest naturally occurring material known. Graphite is a good electrical conductor while diamond has a low electrical conductivity. Under normal conditions, diamond, carbon nanotubes, and graphene have the highest thermal conductivities of all known materials. All carbon allotropes are solids under normal conditions, with graphite being the most thermodynamically stable form at standard temperature and pressure. They are chemically resistant and require high temperature to react even with oxygen.",
                    "score": 0.9057955741882324
                },
                {
                    "id": 5822757,
                    "contents": "Diamond cubic\nAlthough often called the diamond lattice, this structure is not a lattice in the technical sense of this word used in mathematics. Crystallographic structure Diamond's cubic structure is in the Fdm space group (space group 227), which follows the face-centered cubic Bravais lattice. The lattice describes the repeat pattern; for diamond cubic crystals this lattice is \"decorated\" with a motif of two tetrahedrally bonded atoms in each primitive cell, separated by of the width of the unit cell in each dimension. The diamond lattice can be viewed as a pair of intersecting face-centered cubic lattices, with each separated by of the width of the unit cell in each dimension. Many compound semiconductors such as gallium arsenide, β-silicon carbide, and indium antimonide adopt the analogous zincblende structure, where each atom has nearest neighbors of an unlike element. Zincblende's space group is F3m, but many of its structural properties are quite similar to the diamond structure.",
                    "score": 0.9045668840408325
                },
                {
                    "id": 1671077,
                    "contents": "Diamond\nDiamond is a solid form of the element carbon with its atoms arranged in a crystal structure called diamond cubic. At room temperature and pressure, another solid form of carbon known as graphite is the chemically stable form of carbon, but diamond converts to it extremely slowly. Diamond has the highest hardness and thermal conductivity of any natural material, properties that are used in major industrial applications such as cutting and polishing tools. They are also the reason that diamond anvil cells can subject materials to pressures found deep in the Earth.",
                    "score": 0.9043551087379456
                },
                {
                    "id": 5308084,
                    "contents": "List of diamonds\nDiamond A diamond is a solid form of the element carbon with its atoms arranged in a crystal structure called diamond cubic. At room temperature and pressure, another solid form of carbon known as graphite is the chemically stable form, but diamond almost never converts to it. Diamond has the highest hardness and thermal conductivity of any natural material, properties that are utilized in major industrial applications such as cutting and polishing tools. They are also the reason that diamond anvil cells can subject materials to pressures found deep in the Earth.",
                    "score": 0.9020376801490784
                },
                {
                    "id": 15901730,
                    "contents": "Atomic spacing\nExample Bond length can be determined between different elements in molecules by using the atomic radii of the atoms. Carbon bonds with itself to form two covalent network solids. Diamond's C-C bond has a distance of Sqrt[3]a/4 ≈ 0.154 nm away from each carbon since adiamond ≈ 0.357 nm, while graphite's C-C bond has a distance of a/Sqrt[3] ≈ 0.142 nm away from each carbon since agraphite ≈ 0.246 nm. Although both bonds are between the same pair of elements they can have different bond lengths. References Nuclear physics",
                    "score": 0.8997401595115662
                },
                {
                    "id": 1627082,
                    "contents": "Carbon\nOf the other discovered allotropes, carbon nanofoam is a ferromagnetic allotrope discovered in 1997. It consists of a low-density cluster-assembly of carbon atoms strung together in a loose three-dimensional web, in which the atoms are bonded trigonally in six- and seven-membered rings. It is among the lightest known solids, with a density of about 2 kg/m. Similarly, glassy carbon contains a high proportion of closed porosity, but contrary to normal graphite, the graphitic layers are not stacked like pages in a book, but have a more random arrangement. Linear acetylenic carbon has the chemical structure −(C:::C)n−. Carbon in this modification is linear with sp orbital hybridization, and is a polymer with alternating single and triple bonds. This carbyne is of considerable interest to nanotechnology as its Young's modulus is 40 times that of the hardest known material – diamond.",
                    "score": 0.8996944427490234
                },
                {
                    "id": 3489619,
                    "contents": "Allotropes of carbon\nDiamond Diamond is a well-known allotrope of carbon. The hardness, extremely high refractive index, and high dispersion of light make diamond useful for industrial applications and for jewelry. Diamond is the hardest known natural mineral. This makes it an excellent abrasive and makes it hold polish and luster extremely well. No known naturally occurring substance can cut or scratch diamond, except another diamond. In diamond form, carbon is one of the costliest elements.",
                    "score": 0.8975536823272705
                },
                {
                    "id": 4562570,
                    "contents": "Material properties of diamond\nDiamonds are carbon crystals that form deep within the Earth under high temperatures and extreme pressures. At surface air pressure (one atmosphere), diamonds are not as stable as graphite, and so the decay of diamond is thermodynamically favorable (δH = ). So, contrary to De Beers' ad campaign extending from 1948 to at least 2013 under the slogan \"A diamond is forever\", diamonds are definitely not forever. However, owing to a very large kinetic energy barrier, diamonds are metastable; they will not decay into graphite under normal conditions. See also Chemical vapor deposition of diamond Crystallographic defects in diamond Nitrogen-vacancy center Synthetic diamond References Further reading Pagel-Theisen, Verena. (2001). Diamond grading ABC: The manual (9th ed.), pp. 84–85. Rubin & Son n.v.; Antwerp, Belgium. Webster, Robert, and Jobbins, E. Allan (Ed.). (1998). Gemmologist's compendium, p. 21, 25, 31. St Edmundsbury Press Ltd, Bury St Edwards.",
                    "score": 0.8974376916885376
                },
                {
                    "id": 1671078,
                    "contents": "Diamond\nBecause the arrangement of atoms in diamond is extremely rigid, few types of impurity can contaminate it (two exceptions are boron and nitrogen). Small numbers of defects or impurities (about one per million of lattice atoms) color diamond blue (boron), yellow (nitrogen), brown (defects), green (radiation exposure), purple, pink, orange, or red. Diamond also has a very high refractive index and a relatively high optical dispersion. Most natural diamonds have ages between 1 billion and 3.5 billion years. Most were formed at depths between in the Earth's mantle, although a few have come from as deep as . Under high pressure and temperature, carbon-containing fluids dissolved various minerals and replaced them with diamonds. Much more recently (hundreds to tens of million years ago), they were carried to the surface in volcanic eruptions and deposited in igneous rocks known as kimberlites and lamproites.",
                    "score": 0.8965848684310913
                },
                {
                    "id": 1627071,
                    "contents": "Carbon\nCarbon is the sixth element, with a ground-state electron configuration of 1s22s22p2, of which the four outer electrons are valence electrons. Its first four ionisation energies, 1086.5, 2352.6, 4620.5 and 6222.7 kJ/mol, are much higher than those of the heavier group-14 elements. The electronegativity of carbon is 2.5, significantly higher than the heavier group-14 elements (1.8–1.9), but close to most of the nearby nonmetals, as well as some of the second- and third-row transition metals. Carbon's covalent radii are normally taken as 77.2 pm (C−C), 66.7 pm (C=C) and 60.3 pm (C≡C), although these may vary depending on coordination number and what the carbon is bonded to. In general, covalent radius decreases with lower coordination number and higher bond order.",
                    "score": 0.8959940671920776
                },
                {
                    "id": 5822763,
                    "contents": "Diamond cubic\nThe diamond cubic is sometimes called the \"diamond lattice\" but it is not, mathematically, a lattice: there is no translational symmetry that takes the point (0,0,0) into the point (3,3,3), for instance. However, it is still a highly symmetric structure: any incident pair of a vertex and edge can be transformed into any other incident pair by a congruence of Euclidean space. Moreover, the diamond crystal as a network in space has a strong isotropic property. Namely, for any two vertices x and y of the crystal net, and for any ordering of the edges adjacent to x and any ordering of the edges adjacent to y, there is a net-preserving congruence taking x to y and each x-edge to the similarly ordered y-edge. Another (hypothetical) crystal with this property is the Laves graph (also called the K4 crystal, (10,3)-a, or the diamond twin).",
                    "score": 0.8955727815628052
                },
                {
                    "id": 9021239,
                    "contents": "Structure factor\nDiamond crystal structure The diamond cubic crystal structure occurs for example diamond (carbon), tin, and most semiconductors. There are 8 atoms in the cubic unit cell. We can consider the structure as a simple cubic with a basis of 8 atoms, at positions But comparing this to the FCC above, we see that it is simpler to describe the structure as FCC with a basis of two atoms at (0, 0, 0) and (1/4, 1/4, 1/4). For this basis, Equation () becomes: And then the structure factor for the diamond cubic structure is the product of this and the structure factor for FCC above, (only including the atomic form factor once) with the result If h, k, ℓ are of mixed parity (odd and even values combined) the first (FCC) term is zero, so If h, k, ℓ are all even or all odd then the first (FCC) term is 4 if h+k+ℓ is odd then if h+k+ℓ is even and exactly divisible by 4 () then if h+k+ℓ is even but not exactly divisible by 4 () the second term is zero and",
                    "score": 0.8944432735443115
                },
                {
                    "id": 431378,
                    "contents": "Period 2 element\nCarbon is the chemical element with atomic number 6, occurring as 12C, 13C and 14C. At standard temperature and pressure, carbon is a solid, occurring in many different allotropes, the most common of which are graphite, diamond, the fullerenes and amorphous carbon. Graphite is a soft, hexagonal crystalline, opaque black semimetal with very good conductive and thermodynamically stable properties. Diamond however is a highly transparent colourless cubic crystal with poor conductive properties, is the hardest known naturally occurring mineral and has the highest refractive index of all gemstones. In contrast to the crystal lattice structure of diamond and graphite, the fullerenes are molecules, named after Richard Buckminster Fuller whose architecture the molecules resemble. There are several different fullerenes, the most widely known being the \"buckeyball\" C60. Little is known about the fullerenes and they are a current subject of research. There is also amorphous carbon, which is",
                    "score": 0.894443154335022
                },
                {
                    "id": 1627078,
                    "contents": "Carbon\nAt very high pressures, carbon forms the more compact allotrope, diamond, having nearly twice the density of graphite. Here, each atom is bonded tetrahedrally to four others, forming a 3-dimensional network of puckered six-membered rings of atoms. Diamond has the same cubic structure as silicon and germanium, and because of the strength of the carbon-carbon bonds, it is the hardest naturally occurring substance measured by resistance to scratching. Contrary to the popular belief that \"diamonds are forever\", they are thermodynamically unstable (ΔfG°(diamond, 298 K) = 2.9 kJ/mol) under normal conditions (298 K, 105 Pa) and should theoretically transform into graphite. But due to a high activation energy barrier, the transition into graphite is so slow at normal temperature that it is unnoticeable. However, at very high temperatures diamond will turn into graphite, and diamonds can burn up in a house fire. The bottom left corner of the phase diagram for carbon has not been scrutinized",
                    "score": 0.8937334418296814
                },
                {
                    "id": 1627079,
                    "contents": "Carbon\nHowever, at very high temperatures diamond will turn into graphite, and diamonds can burn up in a house fire. The bottom left corner of the phase diagram for carbon has not been scrutinized experimentally. Although a computational study employing density functional theory methods reached the conclusion that as and , diamond becomes more stable than graphite by approximately 1.1 kJ/mol, more recent and definitive experimental and computational studies show that graphite is more stable than diamond for , without applied pressure, by 2.7 kJ/mol at T = 0 K and 3.2 kJ/mol at T = 298.15 K. Under some conditions, carbon crystallizes as lonsdaleite, a hexagonal crystal lattice with all atoms covalently bonded and properties similar to those of diamond.",
                    "score": 0.8936200737953186
                },
                {
                    "id": 1627074,
                    "contents": "Carbon\nThe system of carbon allotropes spans a range of extremes: Allotropes Atomic carbon is a very short-lived species and, therefore, carbon is stabilized in various multi-atomic structures with diverse molecular configurations called allotropes. The three relatively well-known allotropes of carbon are amorphous carbon, graphite, and diamond. Once considered exotic, fullerenes are nowadays commonly synthesized and used in research; they include buckyballs, carbon nanotubes, carbon nanobuds and nanofibers. Several other exotic allotropes have also been discovered, such as lonsdaleite, glassy carbon, carbon nanofoam and linear acetylenic carbon (carbyne).",
                    "score": 0.8914393782615662
                },
                {
                    "id": 1739790,
                    "contents": "Graphite\nProperties Structure Solid carbon comes in different forms known as allotropes depending on the type of chemical bond. The two most common are diamond and graphite (less common ones include buckminsterfullerene). In diamond the bonds are sp3 orbital hybrids and the atoms form tetrahedra with each bound to four nearest neighbors. In graphite they are sp2 orbital hybrids and the atoms form in planes with each bound to three nearest neighbors 120 degrees apart.",
                    "score": 0.891327977180481
                },
                {
                    "id": 3489639,
                    "contents": "Allotropes of carbon\nAtomic and diatomic carbon Under certain conditions, carbon can be found in its atomic form. It can be formed by vaporizing graphite, by passing large electric currents to form a carbon arc under very low pressures. It is extremely reactive, but it is an intermediate product used in the creation of carbenes. Diatomic carbon can also be found under certain conditions. It is often detected via spectroscopy in extraterrestrial bodies, including comets and certain stars. Carbon nanofoam Carbon nanofoam is the fifth known allotrope of carbon, discovered in 1997 by Andrei V. Rode and co-workers at the Australian National University in Canberra. It consists of a low-density cluster-assembly of carbon atoms strung together in a loose three-dimensional web.",
                    "score": 0.891227662563324
                },
                {
                    "id": 1671084,
                    "contents": "Diamond\nAbove the graphite-diamond-liquid carbon triple point, the melting point of diamond increases slowly with increasing pressure; but at pressures of hundreds of GPa, it decreases. At high pressures, silicon and germanium have a BC8 body-centered cubic crystal structure, and a similar structure is predicted for carbon at high pressures. At , the transition is predicted to occur at .",
                    "score": 0.8895490765571594
                },
                {
                    "id": 12182757,
                    "contents": "Atomic carbon\nAtomic carbon, systematically named carbon and λ0-methane, also called monocarbon, is a colourless gaseous inorganic chemical with the chemical formula C (also written [C]). It is kinetically unstable at ambient temperature and pressure, being removed through autopolymerisation. Atomic carbon is the simplest form of carbon, and is also the progenitor of carbon clusters. In addition, it may be considered to be the monomer of all (condensed) carbon allotropes like graphite and diamond. Nomenclature",
                    "score": 0.8894308805465698
                },
                {
                    "id": 4562545,
                    "contents": "Material properties of diamond\nplay an important role in the formation of well-shaped euhedral crystals. The largest diamonds found, such as the Cullinan Diamond, were shapeless. These diamonds are pure (i.e. type II) and therefore contain little if any nitrogen.",
                    "score": 0.8892946839332581
                },
                {
                    "id": 6102258,
                    "contents": "Diamond-like carbon\nHardness",
                    "score": 0.8891499042510986
                },
                {
                    "id": 1417695,
                    "contents": "Archibald Scott Couper\nCouper published his \"New Chemical Theory\" in French in a condensed form on 14 June 1858, then in detailed papers simultaneously in French and English in August 1858. Couper's idea that carbon atoms can link to each other following valence regularities was independent of a paper by August Kekulé proposing the same concept. (Kekulé had already proposed the tetravalence of carbon in 1857.) However, through a misunderstanding with Wurtz, Kekulé's paper appeared in print first, in May 1858, and so Kekulé captured the priority for the discovery of the self-linking of carbon atoms. When Couper angrily confronted Wurtz, Wurtz expelled him from the laboratory.",
                    "score": 0.8879799842834473
                },
                {
                    "id": 6102259,
                    "contents": "Diamond-like carbon\nWithin the \"cobblestones\", nodules, clusters, or \"sponges\" (the volumes in which local bonding is sp3) bond angles may be distorted from those found in either pure cubic or hexagonal lattices because of intermixing of the two. The result is internal (compressive) stress that can appear to add to the hardness measured for a sample of DLC. Hardness is often measured by nanoindentation methods in which a finely pointed stylus of natural diamond is forced into the surface of a specimen. If the sample is so thin that there is only a single layer of nodules, then the stylus may enter the DLC layer between the hard cobblestones and push them apart without sensing the hardness of the sp3 bonded volumes. Measurements would be low. Conversely, if the probing stylus enters a film thick enough to have several layers of nodules so it cannot be spread laterally, or if it enters on top of a cobblestone in a single layer, then it will measure not only the real hardness of the diamond bonding, but an",
                    "score": 0.8873758316040039
                },
                {
                    "id": 19304259,
                    "contents": "Superdense carbon allotropes\nCarbon tetrahedra These new materials would have structures based on carbon tetrahedra, and represent the densest of such structures. On the opposite end of the density spectrum is a recently theorized tetrahedral structure called T-carbon. This is obtained by replacing carbon atoms in diamond with carbon tetrahedra. In contrast to superdense allotropes, T-carbon would have very low density and hardness. References External links SACADA - Samara Carbon Allotrope Database Allotropes of carbon",
                    "score": 0.8871119022369385
                },
                {
                    "id": 19068066,
                    "contents": "Chemistry: A Volatile History\nExactly 50 years later, a young Scottish chemist discovered there are no prizes in Science for coming second. Archibald Scott Couper formulates the theory of chemical bonds In 1856 Archibald Scott Couper went to work for a French chemist, Charles-Adolphe Wurtz. Whilst in Paris he came up with the idea of links between atoms that could explain how individual atoms formed compounds. He called these links bonds. Somehow, Couper realised that carbon can form four bonds, thereby attaching itself with different strengths to other carbon atoms in a compound: In diamond all four bonds are connected to other carbon atoms in three-dimensions, making it so hard. In graphite only three bonds are connected to other carbon atoms in a two-dimensional hexagonal lattice, allowing layers to slide over each other, making graphite soft.",
                    "score": 0.8870629668235779
                },
                {
                    "id": 3489653,
                    "contents": "Allotropes of carbon\nBetween diamond and graphite: Diamond crystallizes in the cubic system but graphite crystallizes in the hexagonal system. Diamond is clear and transparent, but graphite is black and opaque. Diamond is the hardest mineral known (10 on the Mohs scale), but graphite is one of the softest (1–2 on Mohs scale). Diamond is the ultimate abrasive, but graphite is soft and is a very good lubricant. Diamond is an excellent electrical insulator, but graphite is an excellent conductor. Diamond is an excellent thermal conductor, but some forms of graphite are used for thermal insulation (for example heat shields and firebreaks). At standard temperature and pressure, graphite is the thermodynamically stable form. Thus diamonds do not exist forever. The conversion from diamond to graphite, however, has a very high activation energy and is therefore extremely slow.",
                    "score": 0.8868921995162964
                },
                {
                    "id": 1867495,
                    "contents": "Metallic bonding\nHowever, a substance such as diamond, which conducts heat quite well, is not an electrical conductor. This is not a consequence of delocalization being absent in diamond, but simply that carbon is not electron deficient. Electron deficiency is important in distinguishing metallic from more conventional covalent bonding. Thus, we should amend the expression given above to: Metallic bonding is an extremely delocalized communal form of electron-deficient covalent bonding. Metallic radius The metallic radius is defined as one-half of the distance between the two adjacent metal ions in the metallic structure. This radius depends on the nature of the atom as well as its environment—specifically, on the coordination number (CN), which in turn depends on the temperature and applied pressure.",
                    "score": 0.8860708475112915
                },
                {
                    "id": 19068065,
                    "contents": "Chemistry: A Volatile History\nSmithson Tennant discovers what diamonds are made of In 1796 Smithson Tennant was experimenting on diamonds when he decided to burn one. Using only sunlight and a magnifying glass he managed to ignite a diamond sufficiently for it to produce a gas, which he collected and was able to identify as carbon dioxide. Having started with only diamond and oxygen, and produced a gas which contains only carbon and oxygen, Tennant had discovered that diamonds are made of carbon. Unaware of atomic theory at the time, scientists were unable to explain how carbon, already known to exist as one of the softest substances in the form of graphite, could also be the sole constituent element of the hardest known substance: diamond. Exactly 50 years later, a young Scottish chemist discovered there are no prizes in Science for coming second. Archibald Scott Couper formulates the theory of chemical bonds",
                    "score": 0.8859655857086182
                },
                {
                    "id": 2373005,
                    "contents": "Diamondoid\nIn chemistry, diamondoids are variants of the carbon cage molecule known as adamantane (C10H16), the smallest unit cage structure of the diamond crystal lattice. Diamondoids also known as nanodiamonds or condensed adamantanes may include one or more cages (adamantane, diamantane, triamantane, and higher polymantanes) as well as numerous isomeric and structural variants of adamantanes and polymantanes. These diamondoids occur naturally in petroleum deposits and have been extracted and purified into large pure crystals of polymantane molecules having more than a dozen adamantane cages per molecule. These species are of interest as molecular approximations of the diamond cubic framework, terminated with C−H bonds. Cyclohexamantane may be thought of as a nanometer-sized diamond of approximately . Examples",
                    "score": 0.8839825987815857
                },
                {
                    "id": 6754796,
                    "contents": "Bond length\nBond lengths in organic compounds The bond length between two atoms in a molecule depends not only on the atoms but also on such factors as the orbital hybridization and the electronic and steric nature of the substituents. The carbon–carbon (C–C) bond length in diamond is 154 pm. It is generally considered the average length for a carbon–carbon single bond, but is also the largest bond length that exists for ordinary carbon covalent bonds. Since one atomic unit of length(i.e., a Bohr radius) is 52.9177 pm, the C–C bond length is 2.91 atomic units, or approximately three Bohr radii long. Unusually long bond lengths do exist. Current record holder for the longest C-C bond with a length of 186.2 pm is 1,8-Bis(5-hydroxydibenzo[a,d]cycloheptatrien-5-yl)naphthalene, one of many molecules within a category of hexaaryl ethanes, which are derivatives based on hexaphenylethane skeleton. Bond is located between carbons C1 and C2 as depicted in a picture below.",
                    "score": 0.8836307525634766
                },
                {
                    "id": 20678972,
                    "contents": "Jemmis mno rules\nbetween tetracoordinate tetrahedral carbon compounds and diamond. The Jemmis mno rules reduce to Hückel's rule when restricted to two dimensions and reduce to Wade's rules when restricted to one polyhedron.",
                    "score": 0.883367657661438
                },
                {
                    "id": 3405843,
                    "contents": "Fallacy of composition\nIn chemistry and materials science, a single type of atom may form allotropes with different physical properties from each other, and from their individual constituent atoms, such as diamond and graphite each consisting of carbon atoms. What is true of a single carbon atom is not true of a collection of carbon atoms bonded into a material. Furthermore, the properties of an atom differ from the properties of the individual subatomic particles that constitute it.",
                    "score": 0.8831225633621216
                },
                {
                    "id": 1853205,
                    "contents": "Mineral\nDifferences in crystal structure and chemistry greatly influence other physical properties of the mineral. The carbon allotropes diamond and graphite have vastly different properties; diamond is the hardest natural substance, has an adamantine lustre, and belongs to the isometric crystal family, whereas graphite is very soft, has a greasy lustre, and crystallises in the hexagonal family. This difference is accounted for by differences in bonding. In diamond, the carbons are in sp3 hybrid orbitals, which means they form a framework where each carbon is covalently bonded to four neighbours in a tetrahedral fashion; on the other hand, graphite is composed of sheets of carbons in sp2 hybrid orbitals, where each carbon is bonded covalently to only three others. These sheets are held together by much weaker van der Waals forces, and this discrepancy translates to large macroscopic differences.",
                    "score": 0.8831220865249634
                },
                {
                    "id": 25182423,
                    "contents": "Diamond and Related Materials\nDiamond and Related Materials is a peer-reviewed scientific journal in materials science covering research on all forms of diamond and other related materials, including diamond-like carbons, carbon nanotubes, graphene, and boron and carbon nitrides. The journal is published by Elsevier and the editor-in-chief is Ken Haenen (University of Hasselt). Abstracting and indexing The journal is abstracted and indexing in: According to the Journal Citation Reports, the journal has a 2020 impact factor of 3.315. References External links English-language journals Materials science journals Elsevier academic journals Publications established in 1991",
                    "score": 0.8824194669723511
                },
                {
                    "id": 1643894,
                    "contents": "Covalent bond\nstarch. Network covalent structures (or giant covalent structures) contain large numbers of atoms linked in sheets (such as graphite), or 3-dimensional structures (such as diamond and quartz). These substances have high melting and boiling points, are frequently brittle, and tend to have high electrical resistivity. Elements that have high electronegativity, and the ability to form three or four electron pair bonds, often form such large macromolecular structures.",
                    "score": 0.8821788430213928
                },
                {
                    "id": 4562544,
                    "contents": "Material properties of diamond\nDiamonds crystallize in the diamond cubic crystal system (space group Fdm) and consist of tetrahedrally, covalently bonded carbon atoms. A second form called lonsdaleite, with hexagonal symmetry, has also been found, but it is extremely rare and forms only in meteorites or in laboratory synthesis. The local environment of each atom is identical in the two structures. From theoretical considerations, lonsdaleite is expected to be harder than diamond, but the size and quality of the available stones are insufficient to test this hypothesis. In terms of crystal habit, diamonds occur most often as euhedral (well-formed) or rounded octahedra and twinned, flattened octahedra with a triangular outline. Other forms include dodecahedra and (rarely) cubes. There is evidence that nitrogen impurities play an important role in the formation of well-shaped euhedral crystals. The largest diamonds found, such as the Cullinan Diamond, were shapeless. These diamonds are pure (i.e. type II) and",
                    "score": 0.8812107443809509
                },
                {
                    "id": 3093852,
                    "contents": "Cubical atom\nDouble bonds are formed by sharing a face between two cubic atoms. This results in sharing four electrons: Triple bonds could not be accounted for by the cubical atom model, because there is no way of having two cubes share three parallel edges. Lewis suggested that the electron pairs in atomic bonds have a special attraction, which result in a tetrahedral structure, as in the figure below (the new location of the electrons is represented by the dotted circles in the middle of the thick edges). This allows the formation of a single bond by sharing a corner, a double bond by sharing an edge, and a triple bond by sharing a face. It also accounts for the free rotation around single bonds and for the tetrahedral geometry of methane. See also History of the molecule References Obsolete theories in physics Atoms Chemical bonding",
                    "score": 0.8811333179473877
                },
                {
                    "id": 1146988,
                    "contents": "Organic compound\nIn chemical nomenclature, an organyl group, frequently represented by the letter R, refers to any monovalent substituent whose open valence is on a carbon atom. Definitions of organic vs inorganic For historical reasons discussed below, a few types of carbon-containing compounds, such as carbides, carbonates (excluding carbonate esters), simple oxides of carbon (for example, CO and CO2), and cyanides are considered inorganic. Different forms (allotropes) of pure carbon, such as diamond, graphite, fullerenes, and carbon nanotubes are also excluded because they are simple substances composed of only a single element and therefore are not generally considered to be chemical compounds. History Vitalism Vitalism was a widespread conception that substances found in organic nature are formed from the chemical elements by the action of a \"vital force\" or \"life-force\" (vis vitalis) that only living organisms possess.",
                    "score": 0.8802881836891174
                },
                {
                    "id": 2139175,
                    "contents": "Carbon group\nThe carbon group is a periodic table group consisting of carbon (C), silicon (Si), germanium (Ge), tin (Sn), lead (Pb), and flerovium (Fl). It lies within the p-block. In modern IUPAC notation, it is called group 14. In the field of semiconductor physics, it is still universally called group IV. The group was once also known as the tetrels (from the Greek word tetra, which means four), stemming from the Roman numeral IV in the group names, or (not coincidentally) from the fact that these elements have four valence electrons (see below). They are also known as the crystallogens or adamantogens. Characteristics Chemical Like other groups, the members of this family show patterns in electron configuration, especially in the outermost shells, resulting in trends in chemical behavior:",
                    "score": 0.8802551627159119
                },
                {
                    "id": 11419907,
                    "contents": "Coordination number\nα-Aluminium has a regular cubic close packed structure, fcc, where each aluminium atom has 12 nearest neighbors, 6 in the same plane and 3 above and below and the coordination polyhedron is a cuboctahedron. α-Iron has a body centered cubic structure where each iron atom has 8 nearest neighbors situated at the corners of a cube. The two most common allotropes of carbon have different coordination numbers. In diamond, each carbon atom is at the centre of a regular tetrahedron formed by four other carbon atoms, the coordination number is four, as for methane. Graphite is made of two-dimensional layers in which each carbon is covalently bonded to three other carbons; atoms in other layers are further away and are not nearest neighbours, giving a coordination number of 3.",
                    "score": 0.8801057934761047
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_14",
        "question": "A swimmer enters a gloomier world (in one sense) on diving to greater depths. Given that the mean molar absorption coefficient of seawater in the visible region is $6.2 \\times 10^{-3} \\mathrm{dm}^3 \\mathrm{~mol}^{-1} \\mathrm{~cm}^{-1}$, calculate the depth at which a diver will experience half the surface intensity of light.",
        "golden_answers": [
            " 0.87"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 27860776,
                    "contents": "Underwater Association\nthe early 1960s, and enjoyed close cooperation with the Royal Navy which provided compressed air and a recompression chamber. In 1965 five different scientific diving teams were active in Malta. The different teams were organised as follows: The Cambridge University Malta Expedition 1965, an undergraduate group studying diurnal behaviour in marine invertebrates (winners of the first ever Duke of Edinburgh/British Sub-Aqua Club award for diving science); and a group from Oxford University, studying mainly algae and geology. There was also a Vision Group from various institutions, studying the visibility of underwater objects and the perception of size and distance, a group led by John Woods from the Physics Department Imperial College London studying thermocline instability; and a Helium Group, led by Nic Flemming from Cambridge University, studying the psychological and ergonomic efficiency of divers breathing heliox and air at a depth of 60 m. In total, 32 divers were involved in",
                    "score": 0.8961448073387146
                },
                {
                    "id": 2779407,
                    "contents": "Diving physics\nSnell's law - the index of refraction of water is similar to that of the cornea of the eye—30% greater than air. This is the reason a diver cannot see clearly underwater without a diving mask with an internal airspace.",
                    "score": 0.8941362500190735
                },
                {
                    "id": 26113171,
                    "contents": "Physiology of underwater diving\nThe physiology of underwater diving is the physiological adaptations to diving of air-breathing vertebrates that have returned to the ocean from terrestrial lineages. They are a diverse group that include sea snakes, sea turtles, the marine iguana, saltwater crocodiles, penguins, pinnipeds, cetaceans, sea otters, manatees and dugongs. All known diving vertebrates dive to feed, and the extent of the diving in terms of depth and duration are influenced by feeding strategies, but also, in some cases, with predator avoidance. Diving behaviour is inextricably linked with the physiological adaptations for diving and often the behaviour leads to an investigation of the physiology that makes the behaviour possible, so they are considered together where possible. Most diving vertebrates make relatively short shallow dives. Sea snakes, crocodiles, and marine iguanas only dive in inshore waters and seldom dive deeper than 10 m. Some of these groups can make much deeper and longer dives. Emperor",
                    "score": 0.8931925296783447
                },
                {
                    "id": 27284303,
                    "contents": "Human physiology of underwater diving\nAir-breathing marine vertebrates that have returned to the ocean from terrestrial lineages are a diverse group that include sea snakes, sea turtles, the marine iguana, saltwater crocodiles, penguins, pinnipeds, cetaceans, sea otters, manatees and dugongs. Most diving vertebrates make relatively short shallow dives. Sea snakes, crocodiles and marine iguanas only dive in inshore waters and seldom dive deeper than 10 m, but both of these groups can make much deeper and longer dives. Emperor penguins regularly dive to depths of 400 to 500 m for 4 to 5 minutes, often dive for 8 to 12 minutes and have a maximum endurance of about 22 minutes. Elephant seals stay at sea for between 2 and 8 months and dive continuously, spending 90% of their time underwater and averaging 20 minutes per dive with less than 3 minutes at the surface between dives. Their maximum dive duration is about 2 hours and they routinely feed at depths between 300 and 600 m, though they can exceed depths of 1600 m. Beaked",
                    "score": 0.8921009302139282
                },
                {
                    "id": 26113251,
                    "contents": "Physiology of underwater diving\nAquatic birds have to overcome the drag created between their bodies and the surrounding water while swimming at the surface or underwater. At the surface, the wave-making resistance will increase substantially when the speed exceeds hull speed, when the bow wavelength equals the length of the body in the water, so surface swimming bird seldom exceeds this speed. Wave making resistance dissipates with depth below the surface, making underwater swimming much less energy-intensive for well-streamlined diving animals.",
                    "score": 0.8900874853134155
                },
                {
                    "id": 23579249,
                    "contents": "Shallow-water blackout\nUnderwater diving physiology",
                    "score": 0.8896620273590088
                },
                {
                    "id": 27284307,
                    "contents": "Human physiology of underwater diving\nBody size is a factor in diving ability. A larger body mass correlates to a relatively lower metabolic rate, while oxygen storage is directly proportional to body mass, so larger animals should be able to dive for longer, all other things being equal. Swimming efficiency also affects diving ability, as low drag and high propulsive efficiency requires less energy for the same dive. Burst and glide locomotion is also often used to minimise energy consumption, and may involve using positive or negative buoyancy to power part of the ascent or descent. References Sources CD-ROM prepared and distributed by the National Technical Information Service in partnership with NOAA and Best Publishing Company</ref>",
                    "score": 0.8894526362419128
                },
                {
                    "id": 5442209,
                    "contents": "Abyssal zone\nmoving down to the water's depths. This means that in the deep ocean, if any light remains then it is most likely blue light so animals wanting to capitalize on that light would need specialized eyes tuned to use it. Many organisms use other specialized organs or methods for sensing their surroundings, some in conjunction with specialized eyes. The ability to make their own light is called bioluminescence. Fishes and organisms living in the abyssal zone have developed this ability not only to produce light for vision, but also to lure in prey or a mate and conceal their silhouette. Scientists believe that over 90% of life in the abyssal zone use some form of bioluminescence. Many animals that are bioluminescent produce blue light, since it moves farther underwater than other colors of light, as explained earlier. Due to this lack of light, complex designs and bright colors are not needed. Most fish species have evolved to be transparent, red, or black so they better blend in with the",
                    "score": 0.8893215656280518
                },
                {
                    "id": 26113255,
                    "contents": "Physiology of underwater diving\nbetween 5 and 16 minutes, and maximum depths from 155 to 530 m, which requires a diving metabolic rate equivalent to resting at the surface to dive within aerobic limits. The internal temperature of king and gentoo penguins drops during dives, which may reduce oxygen requirements.",
                    "score": 0.8885931372642517
                },
                {
                    "id": 26113180,
                    "contents": "Physiology of underwater diving\nThere are differences in the diving strategies of marine mammals, which vary both with depth range and taxonomic grouping. Some of these remain inadequately explained. Some, such as Cuvier's beaked whale, routinely exceed their aerobic dive limit, making a relatively long recovery period necessary, while others, like elephant seals, appear to require very little recovery time between dives to similar depth, indicating that they tend to remain within their aerobic limits on almost all dives",
                    "score": 0.8881493210792542
                },
                {
                    "id": 27860784,
                    "contents": "Underwater Association\ndevelop their careers at a time when diving was not a common research method. The following selected citations illustrate some significant papers in the disciplines of Marine Physics, Psychology of perception, Geoarchaeology, Archaeology, Marine botany, Marine algae, Marine zoology, the psychology of memory in different environments, and diving physiology.",
                    "score": 0.8866310119628906
                },
                {
                    "id": 26113221,
                    "contents": "Physiology of underwater diving\nThe similar times of descent and ascent of the shallow post-foraging dives do not appear to be consistent with requirements for recompression. The relatively slow ascents from foraging dives are not adequately explained. These ascents involve active swimming and no feeding, with the lowest ascent rate occurring below the depth of lung collapse, which does not seem likely to help prevent bubble formation, and by current models of nitrogen diffusion, may increase the risk of decompression sickness.",
                    "score": 0.8863166570663452
                },
                {
                    "id": 23732213,
                    "contents": "James Nestor\nBy 2014, Nestor had published his first nonfiction book focused on the human connection to the ocean – mammalian diving reflex, electroreception, magnetoreception, abiogenesis. The book, Deep: Freediving, Renegade Science, and What the Ocean Tells Us about Ourselves, was released on June 24, 2014 and won several awards. Deep has been published in seven languages.",
                    "score": 0.8837518692016602
                },
                {
                    "id": 9921846,
                    "contents": "Water column\nThe term water column is also commonly used in scuba diving to describe the vertical space through which divers ascend and descend. See also Hydrological transport model Pelagic zone References External links Water column ecology Environmental science Hydrology Fisheries science",
                    "score": 0.8828644156455994
                },
                {
                    "id": 26113172,
                    "contents": "Physiology of underwater diving\nshort shallow dives. Sea snakes, crocodiles, and marine iguanas only dive in inshore waters and seldom dive deeper than 10 m. Some of these groups can make much deeper and longer dives. Emperor penguins regularly dive to depths of 400 to 500 m for 4 to 5 minutes, often dive for 8 to 12 minutes, and have a maximum endurance of about 22 minutes. Elephant seals stay at sea for between 2 and 8 months and dive continuously, spending 90% of their time underwater and averaging 20 minutes per dive with less than 3 minutes at the surface between dives. Their maximum dive duration is about 2 hours and they routinely feed at depths between 300 and 600 m, though they can exceed depths of 1600 m. Beaked whales have been found to routinely dive to forage at depths between 835 and 1070 m, and remain submerged for about 50 minutes. Their maximum recorded depth is 1888 m, and the maximum duration is 85 minutes.",
                    "score": 0.8826141953468323
                },
                {
                    "id": 242331,
                    "contents": "Deep diving\nDepth ranges in underwater diving Assumed is the surface of the waterbody to be at or near sea level and underlies atmospheric pressure. Not included are the differing ranges of freediving - without breathing during a dive.",
                    "score": 0.8824929594993591
                },
                {
                    "id": 26235682,
                    "contents": "Science of underwater diving\nPhysics Diving Physics are the aspects of physics which directly affect the underwater diver and which explain the effects that divers and their equipment are subject to underwater which differ from the normal human experience out of water. These effects are mostly consequences of immersion in water; buoyancy, the hydrostatic pressure of depth, the effects of the pressure on breathing gases and gas spaces in the diver and equipment, the inertial and viscous effects on diver movement, and the heat transfer effects. Other effects are the physical influences of the underwater environment on human sensory perception. An understanding of the physics is useful when considering the physiological effects of diving, the hazards and risks of diving, the working of underwater breathing apparatus, buoyancy control and buoyant lifting.",
                    "score": 0.8824489116668701
                },
                {
                    "id": 26113175,
                    "contents": "Physiology of underwater diving\nBody size is a factor in diving ability. A larger body mass correlates to a relatively lower metabolic rate, while oxygen storage is directly proportional to body mass, so larger animals should be able to dive for longer, all other things being equal. Swimming efficiency also affects diving ability, as low drag and high propulsive efficiency requires less energy for the same dive. Burst and glide locomotion is also often used to minimise energy consumption and may involve using positive or negative buoyancy to power part of the ascent or descent.",
                    "score": 0.8824474215507507
                },
                {
                    "id": 2779415,
                    "contents": "Diving physics\nWhere cold, fresh water enters a warmer sea the fresh water may float over the denser saline water, so the temperature rises as the diver descends. In lakes exposed to geothermal activity, the temperature of the deeper water may be warmer than the surface water. This will usually lead to convection currents. Water at near-freezing temperatures is less dense than slightly warmer water - maximum density of water is at about 4°C - so when near freezing, water may be slightly warmer at depth than at the surface.",
                    "score": 0.8823863863945007
                },
                {
                    "id": 27860783,
                    "contents": "Underwater Association\nThe Underwater Association provided a vehicle for marine scientists who used diving to pool experiences, learn different techniques, experiment with different breathing gas mixtures and diving gear, and to publish their results in a way that emphasised the effectiveness of diving, as well as the skills needed to work efficiently underwater. This achievement coexisted with routine publishing in the mainstream single-discipline refereed journals that demonstrate the high quality of the research. Published papers by Members in the Proceedings volumes and other academic journals included research on diving medicine, psychology, marine biology, fisheries, marine geology, marine physics, archaeology, and oceanographic engineering. The Underwater Association enabled many young marine scientists to develop their careers at a time when diving was not a common research method. The following selected citations illustrate some significant papers in the disciplines of Marine Physics, Psychology of",
                    "score": 0.8813460469245911
                },
                {
                    "id": 26113266,
                    "contents": "Physiology of underwater diving\nLeatherback The leatherback turtle Dermochelys coriacea is the deepest diving extant reptile. The dive profile is consistent, with an initial phase of fairly steep downward swimming at about a 40° descent angle, stroking at about once in 3 seconds with the flippers, followed by a gliding phase, which starts at a depth that varies with the maximum depth of the dive, suggesting that the inspired air volume is chosen depending on how deep the turtle intends to dive, similarly to hard-shelled turtles and penguins. During ascent, the turtles actively swim at a similar stroke rate, but at a lower pitch angle of about 26°, giving a fairly low ascent rate of about 0.4 m/s, or 24 m/min. This may be a strategy to avoid decompression sickness. The relatively low body temperature is conjectured to help reduce the risk of bubble formation by providing a higher solubility of nitrogen in the blood.",
                    "score": 0.8805424571037292
                },
                {
                    "id": 14617027,
                    "contents": "Outline of oceanography\nUnderwater diving – Descending below the surface of the water to interact with the environment Vacuum-anchor – Ocean bottom fasteners used to anchor deepwater oil platforms Vienna Standard Mean Ocean Water – A standard defining the isotopic composition of fresh water originating from ocean water Water quality modelling – The prediction of water pollution using mathematical simulation techniques",
                    "score": 0.8803730607032776
                },
                {
                    "id": 26235683,
                    "contents": "Science of underwater diving\nOther foundational knowledge of physics for diving include the properties of gases and breathing gas mixtures under variations of absolute pressure and temperature, and the solubility of gases in fluids. Physiology",
                    "score": 0.8796555995941162
                },
                {
                    "id": 26113229,
                    "contents": "Physiology of underwater diving\nDiving behaviour The short-beaked common dolphin (Delphinus delphis) is known to forage at depths up to 260 m for 8 minutes or more, but mostly stays above 90 m for dives of about 5 minutes duration. The pantropical spotted dolphin (Stenella attenuata) can dive to at least 170 m, but most dives are between 50 and 100 m for between 2 and 4 minutes. The long-finned pilot whale (Globicephalas melas) can dive to between 500 and 600 m for up to 16 minutes. Northern bottlenose whales dive to the seabed at 500 to 1500 m for more than 30 minutes, occasionally as long as 2 hours. White whales (Delphinapterus leucas) frequently dive to depths between 400 and 700 m, with the deepest at 872 m. for an average duration of 13 minutes and maximum of 23 minutes, and with dive duration increasing with body size. Narwhals (Monodon monoceros) routinely dive to 500 m, and occasionally to 1000m or more, but mostly shallower.",
                    "score": 0.8795743584632874
                },
                {
                    "id": 9529332,
                    "contents": "Marine ecosystem\nThe ocean's surface acts like a skin between the atmosphere above and the water below, and harbours an ecosystem unique to this environment. This sun-drenched habitat can be defined as roughly one metre in depth, as nearly half of UV-B is attenuated within this first meter. Organisms here must contend with wave action and unique chemical and physical properties. The surface is utilised by a wide range of species, from various fish and cetaceans, to species that ride on ocean debris (termed rafters). Most prominently, the surface is home to a unique community of free-living organisms, termed neuston (from the Greek word, υεω, which means both to swim and to float. Floating organisms are also sometimes referred to as pleuston, though neuston is more commonly used). Despite the diversity and importance of the ocean's surface in connecting disparate habitats, and the risks it faces, not a lot is known about neustonic life.",
                    "score": 0.8794299364089966
                },
                {
                    "id": 407605,
                    "contents": "Common kingfisher\nA challenge for any diving bird is the change in refraction between air and water. The eyes of many birds have two foveae (the fovea is the area of the retina with the greatest density of light receptors), and a kingfisher can switch from the main central fovea to the auxiliary fovea when it enters water; a retinal streak of high receptor density which connects the two foveae allows the image to swing temporally as the bird drops onto the prey. The egg-shaped lens of the eye points towards the auxiliary fovea, enabling the bird to maintain visual acuity underwater. Because of the positions of the foveae, the kingfisher has monocular vision in air, and binocular vision in water. The underwater vision is not as a sharp as in air, but the ability to judge the distance of moving prey is more important than the sharpness of the image.",
                    "score": 0.8793454170227051
                },
                {
                    "id": 4157895,
                    "contents": "Australian sea lion\nDiving behaviours indicate that the Australian Sea Lions worked extremely hard to exploit the benefits of their surrounding habitats. The Australian sea lion exceeds the limit (calculated aerobic dive limit) on 79% of dives. Australian sea lions spend 58% of time at sea diving and demonstrate high field metabolism, which allows the sea lions to maximise their time spent at or near the benthos, with 61% of each dive and 35% of their time at sea being spent at the deepest 20% of the dives. When diving, these animals are spending 57.9% of their time at sea spent at depths greater than or equal to 6 m, which can be considered as continuous diving. Seasonal variability in foraging energetics and dive behaviour is likely to be sensitive to regional oceanography, the maintenance costs of female sea lions and their offspring, and the distribution and behaviour of their prey.",
                    "score": 0.8792623281478882
                },
                {
                    "id": 5442208,
                    "contents": "Abyssal zone\nOther challenges faced by life in the abyssal zone are the pressure and darkness caused by the zone’s depth. Many organisms living in this zone have evolved to minimize internal air spaces, such as swim bladders. This adaptation helps to protect them from the extreme pressure, which can reach around 75 MPa (11,000 psi). The absence of light also spawned many different adaptations, such as having large eyes or the ability to produce their own light. Large eyes would allow the detection and use of any light available, no matter how small. Another eye adaptation is that many deep-sea organisms have evolved eyes that are extremely sensitive to blue light. This is because as sunlight shines into the ocean, the water absorbs red light, while blue light, with its short wavelength, continues moving down to the water's depths. This means that in the deep ocean, if any light remains then it is most likely blue light so animals wanting to capitalize on that light would need specialized eyes",
                    "score": 0.8789297342300415
                },
                {
                    "id": 26113261,
                    "contents": "Physiology of underwater diving\nAs air-breathing reptiles, sea turtles must surface to breathe. They spend most of their time underwater, so must be able to hold their breath for long periods to avoid frequent surfacing. Dive duration largely depends on the activity. A foraging sea turtle may typically spend 5–40 minutes under water while a sleeping sea turtle can remain underwater for 4–7 hours. Sea turtle respiration remains aerobic for the vast majority of voluntary dive time. When a sea turtle is forcibly submerged (e.g. entangled in a trawl net) its diving endurance is substantially reduced, so it is more susceptible to drowning.",
                    "score": 0.8786913156509399
                },
                {
                    "id": 8626403,
                    "contents": "Underwater diving\nIn 1965 Hugh LeMessurier and Brian Andrew Hills published their paper, A thermodynamic approach arising from a study on Torres Strait diving techniques, which suggested that decompression following schedules based on conventional models results in asymptomatic bubble formation which must then be re-dissolved at the decompression stops before it can be eliminated. This is slower than allowing the gas to be eliminated while it is still in solution, and indicates the importance of minimising bubble phase gas for efficient decompression.",
                    "score": 0.8784974813461304
                },
                {
                    "id": 26113218,
                    "contents": "Physiology of underwater diving\nIn beaked whales, the descent rate was consistently faster than ascent rate, at about 1.5 metres per second, regardless of dive depth, and at a steep angle of from 60 to 85 degrees, Fluke rate for Z cavirostris was higher at the start of the dive, but reduced by about 50 m depth, with a constant descent rate, consistent with buoyancy reduction due to lung compression. Ascents from deep foraging dives were at a low vertical speed averaging 0.7 metres per second at a low angle. Mesoplodon ascent rates varied with dive depth, with a faster ascent associated with deeper dives giving a relatively constant overall ascent time. For Ziphius, the ascent strategy is unclear: they tend to ascend rapidly in the first few hundred meters from deeper dives then slow down around 500 m and speed up again near the surface. Both species began their ascent faster from deeper dives, but there was no clear correlation apparent between ascent speed and dive depth in the top 200 m of the ascent.",
                    "score": 0.877891480922699
                },
                {
                    "id": 26119275,
                    "contents": "Anolis aquaticus\nThe water anole is unique in that it is able to stay underwater for long periods of time - a behavior that is described as “scuba diving.” Experiments have confirmed that this species has the ability to remain underwater for up to 16 minutes. Since these lizards have relatively slow running speeds compared to their predators, it has been hypothesized that these lizards have adapted this \"scuba diving\" to enable them to avoid predators. By submerging themselves underwater for prolonged periods of time, the water anole is able to remain invisible to its predator. These lizards often endure extreme hypoxia before returning to the surface if they perceive a predator and compromise their ability for future escape ability. It has also been confirmed that many of the insects found in the water anoles' stomachs live primarily underwater. The water anoles use this \"scuba diving\" ability to hunt prey that live underwater and would otherwise be inaccessible to the lizards. Therefore, the anoles",
                    "score": 0.8774353861808777
                },
                {
                    "id": 26113271,
                    "contents": "Physiology of underwater diving\nGreen turtles feed on seagrass in shallow water, generally less than 3 m deep, while most other dives occur during travel between the feeding ground and the resting place. During travel, turtles breathe while swimming, usually just one breath before submerging again. Surface swimming causes wave-making drag, and the animal must hold its head up in the air while breathing, causing more drag. Taking a single breath between dives while travelling appears to be energy efficient. Decompression sickness",
                    "score": 0.8774312138557434
                },
                {
                    "id": 25368854,
                    "contents": "Glass sea creatures\nLeopold felt a sense of quiet, inspirational, wonder at these luminescent ocean dwellers, a sense which he recorded and translated by Henri Reiling: \"It is a beautiful night in May. Hopeful, we look out over the darkness of the sea, which is as smooth as a mirror; there emerges all around in various places a flashlike bundle of light beams, as if it is surrounded by thousands of sparks, that form true bundles of fire and of other bright lighting spots, and the seemingly mirrored stars. There emerges close before us a small spot in a sharp greenish light, which becomes ever larger and larger and finally becomes a bright shining sunlike figure.\"",
                    "score": 0.877264142036438
                },
                {
                    "id": 26113258,
                    "contents": "Physiology of underwater diving\nSome marine reptiles, such as ichthyosaurs, plesiosaurs, metriorhynchid thalattosuchians, and mosasaurs became so well adapted to a marine lifestyle that they were incapable of venturing onto land and gave birth in the water. Others, such as sea turtles and saltwater crocodiles, return to shore to lay their eggs. Some marine reptiles also occasionally rest and bask on land. Sea snakes, crocodiles and marine iguanas only dive in inshore waters and seldom dive deeper than 10 m.",
                    "score": 0.8770147562026978
                },
                {
                    "id": 26113264,
                    "contents": "Physiology of underwater diving\nin 12 of 70 studies reviewed. The review also describes that some turtles change dive behaviour based on whether they are transiting. For example, turtles tend to use shallow waters during transit, with occasional deep dives possibly for resting or foraging en route, with the exception of the leatherback that showed longer and deeper dives during transit. Importantly, dive behaviour differed based on habitat type and geography.",
                    "score": 0.8769612312316895
                },
                {
                    "id": 1408565,
                    "contents": "Underwater environment\nAquatic ecosystems are characterised by the limitation on ambient lighting due to absorption by the water itself and by dissolved and suspended matter in the water column, and by the support provided by buoyancy. Nutrients usable by plants are dissolved in the water, making them easily available. Outside the euphotic zone, photosynthesis cannot occur and life must use other sources of energy than sunlight. History The Origin of water on Earth is unknown; oceans are thought to have formed in the Hadean eon and may have been the impetus for the emergence of life. Evolutionary pressures of the underwater environment Humans in the underwater environment Although a number of human activities are conducted underwater—such as research, underwater diving for work or recreation, and underwater warfare with submarines, the underwater environment is hostile to humans in many ways and therefore little explored.",
                    "score": 0.8767377138137817
                },
                {
                    "id": 26113265,
                    "contents": "Physiology of underwater diving\nTurtles can rest or sleep underwater for several hours at a time, but submergence time is much shorter while diving for food or to escape predators. Breath-holding ability is affected by activity and stress, which is why turtles quickly drown in shrimp trawlers and other fishing gear. During the night while sleeping and to protect themselves from potential predators, the adults wedge themselves under rocks below the surface and under ledges in reefs and coastal rocks. Many green sea turtles have been observed returning to the same sleeping location over successive nights. Leatherback",
                    "score": 0.876522958278656
                },
                {
                    "id": 26113247,
                    "contents": "Physiology of underwater diving\nDiving birds Aquatic birds are secondarily adapted to live and forage in water. Diving birds plunge into the water to catch their food. They may enter the water from the flight, as does the brown pelican and the gannet, or they may dive from the surface of the water. Some diving birds – for example, the extinct Hesperornithes of the Cretaceous Period – propelled themselves with their feet. They were large, streamlined, flightless birds with teeth for grasping slippery prey. Today, cormorants, loons, and grebes are the major groups of foot-propelled diving birds. Other diving birds are wing-propelled, most notably the penguins, dippers and auks.",
                    "score": 0.8765151500701904
                },
                {
                    "id": 15338467,
                    "contents": "Deep sea creature\nThe term deep sea creature refers to organisms that live below the photic zone of the ocean. These creatures must survive in extremely harsh conditions, such as hundreds of bars of pressure, small amounts of oxygen, very little food, no sunlight, and constant, extreme cold. Most creatures have to depend on food floating down from above. These creatures live in very demanding environments, such as the abyssal or hadal zones, which, being thousands of meters below the surface, are almost completely devoid of light. The water is between 3 and 10 degrees Celsius and has low oxygen levels. Due to the depth, the pressure is between 20 and 1,000 bar. Creatures that live hundreds or even thousands of meters deep in the ocean have adapted to the high pressure, lack of light, and other factors. Evolutionary adaptations of deep-sea creatures Lack of light The lack of light requires creatures to have special adaptations to find food, avoid predators, and find mates.",
                    "score": 0.8761072158813477
                },
                {
                    "id": 2779414,
                    "contents": "Diving physics\nOcean currents can transport water over thousands of kilometres, and may bring water with different temperature and salinity into a region. Some ocean currents have a huge effect on local climate, for instance the warm water of the North Atlantic drift moderates the climate of the north west coast of Europe. The speed of water movement can affect dive planning and safety. Thermoclines, or sudden changes in temperature. Where the air temperature is higher than the water temperature, shallow water may be warmed by the air and the sunlight but deeper water remains cold resulting in a lowering of temperature as the diver descends. This temperature change may be concentrated over a small vertical interval, when it is called a thermocline. Where cold, fresh water enters a warmer sea the fresh water may float over the denser saline water, so the temperature rises as the diver descends.",
                    "score": 0.875728964805603
                },
                {
                    "id": 5635792,
                    "contents": "Underwater habitat\nConshelf Two, the first ambitious attempt for men to live and work on the sea floor, was launched in 1963. In it, a half-dozen oceanauts lived down in the Red Sea off Sudan in a starfish-shaped house for 30 days. The undersea living experiment also had two other structures, one a submarine hangar that housed a small, two-man submarine named SP-350 Denise, often referred to as the \"diving saucer\" for its resemblance to a science fiction flying saucer, and a smaller \"deep cabin\" where two oceanauts lived at a depth of for a week. They were among the first to breathe heliox, a mixture of helium and oxygen, avoiding the normal nitrogen/oxygen mixture, which, when breathed under pressure, can cause narcosis. The deep cabin was also an early effort in saturation diving, in which the aquanauts' body tissues were allowed to become totally saturated by the helium in the breathing mixture, a result of breathing the gases under pressure. The necessary decompression from saturation was",
                    "score": 0.8752228021621704
                },
                {
                    "id": 2779408,
                    "contents": "Diving physics\nPhysical characteristics of water most relevant to divers",
                    "score": 0.8751583695411682
                },
                {
                    "id": 26113220,
                    "contents": "Physiology of underwater diving\nBoth Ziphius cavirostris and Mesoplodon densirostris, make long, deep dives to feed on a deep water source. Diving follows a distinct pattern with most deep foraging dives followed by a closely timed series of shallow dives and recovery near the surface. All foraging dives in these species appear to be much longer than the estimated aerobic dive limits, indicating that the whales generally return to the surface from them with an oxygen debt. It has been hypothesised that the series of shallow dives and the long periods between foraging dives are needed to recover from the oxygen debt in preparation for the next deep dive. The long intervals spent near the surface are considered to be inconsistent with the hypothesis that beaked whales are chronically supersaturated at high levels.",
                    "score": 0.875066339969635
                },
                {
                    "id": 26113257,
                    "contents": "Physiology of underwater diving\nThe earliest marine reptiles arose in the Permian period during the Paleozoic era. During the Mesozoic era, many groups of reptiles became adapted to life in the seas, including such familiar clades as the ichthyosaurs, plesiosaurs, mosasaurs, nothosaurs, placodonts, sea turtles, thalattosaurs and thalattosuchians. After the mass extinction at the end of the Cretaceous period, marine reptiles were less numerous, but there was still a high variety of species in the early Cenozoic, such as \"true\" sea turtles, bothremydids, palaeophiid snakes, a few choristoderes such as Simoedosaurus and dyrosaurid crocodylomorphs. Various types of marine gavialid crocodilians remained widespread as recently as the Late Miocene.",
                    "score": 0.8744637370109558
                },
                {
                    "id": 16002301,
                    "contents": "Aquatic locomotion\nThere are also a number of forms of swimming molluscs. Many free-swimming sea slugs, such as sea angels, flap fin-like structures. Some shelled molluscs, such as scallops can briefly swim by clapping their two shells open and closed. The molluscs most evolved for swimming are the cephalopods. Violet sea-snails exploit a buoyant foam raft stabilized by amphiphilic mucins to float at the sea surface. Among the Deuterostomia, there are a number of swimmers as well. Feather stars can swim by undulating their many arms Beautiful Swimming Feather Star en MSN Video. Salps move by pumping waters through their gelatinous bodies. The deuterostomes most evolved for swimming are found among the vertebrates, notably the fish. Jet propulsion",
                    "score": 0.874452531337738
                },
                {
                    "id": 26113263,
                    "contents": "Physiology of underwater diving\nThe deepest diving sea turtle is the leatherback which can reach 1250 m depth, while the record for the longest dive goes to loggerheads (Caretta caretta) in the Mediterranean at more than 10 hours. For many hard-shelled sea turtles, depths visited on average (i.e. outside of overwintering) range from 2–54 m; for leatherbacks, this ranges up to 150 m. The effect of temperature on sea turtles has been explored thoroughly and is shown to influence turtle metabolic rates, circulation and other physiological factors. Therefore, dive behaviour is presumed to shift based on needs for thermoregulation and in response to seasonal changes (longer dives with lower temperatures), although across species and regions the relationship between temperature and diving has differed and was only investigated in 12 of 70 studies reviewed. The review also describes that some turtles change dive behaviour based on whether they are transiting. For example, turtles tend to use shallow waters during transit,",
                    "score": 0.8735350370407104
                },
                {
                    "id": 1408563,
                    "contents": "Underwater environment\nEarth's hydrosphere, it is integral to life, forms part of the carbon cycle, and influences climate and weather patterns. The World Ocean is the habitat of 230,000 known species, but because much of it is unexplored, the number of species that exist in the ocean is much larger, possibly over two million.",
                    "score": 0.8733723759651184
                },
                {
                    "id": 26113219,
                    "contents": "Physiology of underwater diving\nFluke rate in both species for the last 40 m of the ascent was much lower than during descents which is consistent with the hypothesis that the final part of the ascent is largely powered by the buoyancy force of air expanding in the lungs.",
                    "score": 0.873021125793457
                },
                {
                    "id": 12165082,
                    "contents": "Open Water 2: Adrift\nFearing that sharks will be attracted by the blood, the now hysterical Michelle begins to swim away, but sinks underwater. Dan swims after her and sees her lifeless body drifting underwater. He dives after her, but he can't reach her, and her body disappears into the depths. After some time, Zach dies from blood loss in Lauren's arms. She reluctantly lets go of his body which floats away, face down. Out of guilt, Dan admits that he doesn't own the yacht. After much waiting, Lauren says she refuses to die treading water and attempts to swim back to shore to find help. Her fate after this is unknown.",
                    "score": 0.8729819059371948
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_15",
        "question": "Calculate the molar energy required to reverse the direction of an $\\mathrm{H}_2 \\mathrm{O}$ molecule located $100 \\mathrm{pm}$ from a $\\mathrm{Li}^{+}$ ion. Take the magnitude of the dipole moment of water as $1.85 \\mathrm{D}$.",
        "golden_answers": [
            " 1.07"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 3383103,
                    "contents": "Equipartition theorem\n3 cal/(mol·K) at very low temperatures. This disagreement between the equipartition prediction and the experimental value of the molar heat capacity cannot be explained by using a more complex model of the molecule, since adding more degrees of freedom can only increase the predicted specific heat, not decrease it. This discrepancy was a key piece of evidence showing the need for a quantum theory of matter.",
                    "score": 0.8539014458656311
                },
                {
                    "id": 5597123,
                    "contents": "Molar heat capacity\nA molecule with n atoms that is rigid and not linear has 3 translation modes and 3 non-trivial rotation modes, hence only 3n − 6 deformation modes. It therefore has f = 3 + 3 + 2(3n − 6) = 6n − 6 energy-absorbing degrees of freedom (one less than a linear molecule with the same atom count). Water (n = 3) is bent in its non-strained state, therefore it is predicted to have f = 12 degrees of freedom. Methane (n = 5) is tridimensional, and the formula predicts f = 24. Ethane (n = 8) has 4 degrees of rotational freedom: two about axes that are perpendicular to the central bond, and two more because each methyl group can rotate independently about that bond, with negligible resistance. Therefore, the number of independent deformation modes is 3n − 7, which gives f = 3 + 4 + 2(3n − 7) = 6n − 7 = 41.",
                    "score": 0.8536373376846313
                },
                {
                    "id": 117484,
                    "contents": "Johannes Diderik van der Waals\nThe effect of Van der Waals's work on molecular physics in the 20th century was direct and fundamental. By introducing parameters characterizing molecular size and attraction in constructing his equation of state, Van der Waals set the tone for modern molecular science. That molecular aspects such as size, shape, attraction, and multipolar interactions should form the basis for mathematical formulations of the thermodynamic and transport properties of fluids is presently considered an axiom. With the help of the Van der Waals's equation of state, the critical-point parameters of gases could be accurately predicted from thermodynamic measurements made at much higher temperatures. Nitrogen, oxygen, hydrogen, and helium subsequently succumbed to liquefaction. Heike Kamerlingh Onnes was significantly influenced by the pioneering work of Van der Waals. In 1908, Onnes became the first to make liquid helium; this led directly to his 1911 discovery of superconductivity. Biography",
                    "score": 0.8535845875740051
                },
                {
                    "id": 1707346,
                    "contents": "Enthalpy\nEnthalpy of atomization, defined as the enthalpy change required to separate one mole of a substance into its constituent atoms completely. Enthalpy of neutralization, defined as the enthalpy change observed in a constituent of a thermodynamic system when one mole of water is formed when an acid and a base react. Standard Enthalpy of solution, defined as the enthalpy change observed in a constituent of a thermodynamic system when one mole of a solute is dissolved completely in an excess of solvent, so that the solution is at infinite dilution. Standard enthalpy of Denaturation (biochemistry), defined as the enthalpy change required to denature one mole of compound. Enthalpy of hydration, defined as the enthalpy change observed when one mole of gaseous ions are completely dissolved in water forming one mole of aqueous ions.",
                    "score": 0.850678563117981
                },
                {
                    "id": 1404506,
                    "contents": "Thermodynamic free energy\nIn the 19th century, the French chemist Marcellin Berthelot and the Danish chemist Julius Thomsen had attempted to quantify affinity using heats of reaction. In 1875, after quantifying the heats of reaction for a large number of compounds, Berthelot proposed the principle of maximum work, in which all chemical changes occurring without intervention of outside energy tend toward the production of bodies or of a system of bodies which liberate heat.",
                    "score": 0.8501173853874207
                },
                {
                    "id": 5989110,
                    "contents": "Free-energy relationship\nChemical and physical properties A typical LFER relation for predicting the equilibrium concentration of a compound or solute in the vapor phase to a condensed (or solvent) phase can be defined as follows (following M.H. Abraham and co-workers):",
                    "score": 0.8482718467712402
                },
                {
                    "id": 905493,
                    "contents": "Thermodynamic temperature\nof heat energy per mole with only a modest temperature change because each molecule comprises an average of 21 atoms and therefore has many internal degrees of freedom. Even larger, more complex molecules can have dozens of internal degrees of freedom.",
                    "score": 0.84775710105896
                },
                {
                    "id": 9730898,
                    "contents": "Proton affinity\nDifference from pKa Both proton affinity and pKa are measures of the acidity of a molecule, and so both reflect the thermodynamic gradient between a molecule and the anionic form of that molecule upon removal of a proton from it. Implicit in the definition of pKa however is that the acceptor of this proton is water, and an equilibrium is being established between the molecule and bulk solution. More broadly, pKa can be defined with reference to any solvent, and many weak organic acids have measured pKa values in DMSO. Large discrepancies between pKa values in water versus DMSO (i.e., the pKa of water in water is 14, but water in DMSO is 32) demonstrate that the solvent is an active partner in the proton equilibrium process, and so pKa does not represent an intrinsic property of the molecule in isolation. In contrast, proton affinity is an intrinsic property of the molecule, without explicit reference to the solvent.",
                    "score": 0.8465991020202637
                },
                {
                    "id": 1404508,
                    "contents": "Thermodynamic free energy\nBased on these and other ideas, Berthelot and Thomsen, as well as others, considered the heat given out in the formation of a compound as a measure of the affinity, or the work done by the chemical forces. This view, however, was not entirely correct. In 1847, the English physicist James Joule showed that he could raise the temperature of water by turning a paddle wheel in it, thus showing that heat and mechanical work were equivalent or proportional to each other, i.e., approximately, . This statement came to be known as the mechanical equivalent of heat and was a precursory form of the first law of thermodynamics.",
                    "score": 0.8461588621139526
                },
                {
                    "id": 13262040,
                    "contents": "List of scientific publications by Albert Einstein\n| Annalen der Physik (ser. 4), 8, 798–814, link || Intermolecular forces. Einstein's second paper on a universal molecular energy function, this time applied to electrolytic solutions. No data are available for comparison. Einstein characterizes these two papers as \"worthless\" in 1907. |- | Schilpp 3; CP 2, 3 || 1902 || Kinetische Theorie des Wärmegleichgewichtes und des zweiten Hauptsatzes der Thermodynamik | Annalen der Physik (ser. 4), 9, 417–433, link || Statistical mechanics. Study of the equipartition theorem and the definitions of temperature and entropy. |- | Schilpp 4; CP 2, 4 || 1903 || Eine Theorie der Grundlagen der Thermodynamik | Annalen der Physik (ser. 4), 11, 170–187, link || Statistical mechanics. The problem of irreversibility in thermodynamics. |- | Schilpp 5; CP 2, 5 || 1904 || Allgemeine molekulare Theorie der Wärme",
                    "score": 0.8452982902526855
                },
                {
                    "id": 20764664,
                    "contents": "Hydration energy\nHydration energy (also hydration enthalpy) is the amount of energy released when one mole of ions undergoes hydration. Hydration energy is one component in the quantitative analysis of solvation. It is a particular special case of water. The value of hydration energies is one of the most challenging aspects of structural prediction. Upon dissolving a salt in water, the cations and anions interact with the positive and negative dipoles of the water. The trade-off of these interactions vs those within the crystalline solid comprises the hydration energy. Examples If the hydration energy is greater than the lattice energy, then the enthalpy of solution is negative (heat is released), otherwise it is positive (heat is absorbed).",
                    "score": 0.8452355265617371
                },
                {
                    "id": 27247585,
                    "contents": "Shimansky equation\nIn molecular physics, Shimansky equation describes the temperature dependence of the heat of vaporization (also known as the enthalpy of vaporization or the heat of evaporation): where is the latent heat of vaporization at the temperature , is the critical temperature, is the parameter that is equal to the heat of vaporization at zero temperature (). This equation was obtained in 1955 by Yu. I. Shimansky, at first empirically, and later derived theoretically. Shimansky equation does not contain any arbitrary constants, since the value of can be determined experimentally and can be calculated using (1) if has been measured experimentally for at least one given value of temperature . Shimansky equation describes quite well the heat of vaporization for a wide variety of liquids. For chemical compounds that belong to the same class (e.g. alcohols) the value of ratio remains constant. For each such class of liquids, Shimansky equation can be re-written in a form of where .",
                    "score": 0.8450888395309448
                },
                {
                    "id": 9896541,
                    "contents": "Merle Randall\nEducation Randall completed his Ph.D. at the Massachusetts Institute of Technology in 1912 with a dissertation on “Studies in Free Energy”. Related Based on work by J. Willard Gibbs, it was known that chemical reactions proceeded to an equilibrium determined by the free energy of the substances taking part. Using this theory, Gilbert Lewis spent 25 years determining free energies of various substances. In 1923, he and Randall published the results of this study and formalizing chemical thermodynamics. According to the Belgian thermodynamicist Ilya Prigogine, their influential 1923 textbook led to the replacement of the term “affinity” by the term “free energy” in much of the English-speaking world. See also Ionic strength References Further reading Thermodynamicists American physical chemists 1888 births 1950 deaths",
                    "score": 0.8449825644493103
                },
                {
                    "id": 10780407,
                    "contents": "Debye–Hückel theory\nThe coefficients and are fixed by the boundary conditions. As , must not diverge, so . At , which is the distance of the closest approach of ions, the force exerted by the charge should be balanced by the force of other ions, imposing , from which is found, yielding The electrostatic potential energy, , of the ion at is This is the potential energy of a single ion in a solution. The multiple-charge generalization from electrostatics gives an expression for the potential energy of the entire solution (see also: Debye–Hückel equation). The mean activity coefficient is given by the logarithm of this quantity as follows (see also: Extensions of the theory) where I is the ionic strength and a0 is a parameter that represents the distance of closest approach of ions. For aqueous solutions at 25 °C A = 0.51 mol−1/2dm3/2 and B = 3.29 nm−1mol−1/2dm3/2",
                    "score": 0.8447950482368469
                },
                {
                    "id": 11284209,
                    "contents": "Frederick Rossini\nAs a result of reading Lewis and Randall's classical 1923 textbook Thermodynamics and the Free Energy of Chemical Substances he wrote to Gilbert N. Lewis and as a result he was offered a teaching fellowship at the University of California at Berkeley. Among his teachers were Gilbert Lewis and William Giauque. Rossini's doctoral dissertation on the heat capacities of strong electrolytes in aqueous solution was supervised by Merle Randall. His Ph.D. degree was awarded in 1928, after only 21 months of graduate work, even though he continued to serve as a teaching fellow throughout this entire period. He worked at the National Bureau of Standards (Washington, DC) from 1928 to 1950.",
                    "score": 0.8443087935447693
                },
                {
                    "id": 1379455,
                    "contents": "Solvent\nThe dielectric constant measures the solvent's tendency to partly cancel the field strength of the electric field of a charged particle immersed in it. This reduction is then compared to the field strength of the charged particle in a vacuum. Heuristically, the dielectric constant of a solvent can be thought of as its ability to reduce the solute's effective internal charge. Generally, the dielectric constant of a solvent is an acceptable predictor of the solvent's ability to dissolve common ionic compounds, such as salts. Other polarity scales Dielectric constants are not the only measure of polarity. Because solvents are used by chemists to carry out chemical reactions or observe chemical and biological phenomena, more specific measures of polarity are required. Most of these measures are sensitive to chemical structure. The Grunwald–Winstein mY scale measures polarity in terms of solvent influence on buildup of positive charge of a solute during a chemical reaction.",
                    "score": 0.8442943096160889
                },
                {
                    "id": 11242068,
                    "contents": "Timeline of chemistry\n1912Peter Debye develops the concept of molecular dipole to describe asymmetric charge distribution in some molecules. 1913Niels Bohr introduces concepts of quantum mechanics to atomic structure by proposing what is now known as the Bohr model of the atom, where electrons exist only in strictly defined orbitals. 1913Henry Moseley, working from Van den Broek's earlier idea, introduces concept of atomic number to fix inadequacies of Mendeleev's periodic table, which had been based on atomic weight. 1913Frederick Soddy proposes the concept of isotopes, that elements with the same chemical properties may have differing atomic weights. 1913J. J. Thomson expanding on the work of Wien, shows that charged subatomic particles can be separated by their mass-to-charge ratio, a technique known as mass spectrometry. 1916Gilbert N. Lewis publishes \"The Atom and the Molecule\", the foundation of valence bond theory.",
                    "score": 0.8441593647003174
                },
                {
                    "id": 4559328,
                    "contents": "Paul Walden\nAfter that, Walden became interested in electrochemistry of nonaqueous solutions. In 1902, he proposed a theory of autodissociation of inorganic and organic solvents. In 1905, he found a relationship between the maximum molecular conductivity and viscosity of the medium and in 1906, coined the term \"solvation\". Together with his work on stereochemistry, these results brought him to prominence; in particular, he was considered a candidate for the Nobel Prize in Chemistry in 1913 and 1914. Walden was also credited as a talented chemistry lecturer. In his memoirs, he wrote: \"My audience usually was crowded and the feedback of sympathetic listeners gave me strength ... my lectures I was giving spontaneously, to bring freshness to the subject ... I never considered teaching as a burden\".",
                    "score": 0.8432712554931641
                },
                {
                    "id": 6019541,
                    "contents": "Debye–Hückel equation\nSimilarly, the Helmholtz free entropy is also divided into two parts: D&H state, without giving the logic, that It would seem that, without some justification, Without mentioning it specifically, D&H later give what might be the required (above) justification while arguing that , an assumption that the solvent is incompressible. The definition of the Gibbs free entropy is where is Gibbs free energy. D&H give the total differential of as At this point D&H note that, for water containing 1 mole per liter of potassium chloride (nominal pressure and temperature aren't given), the electric pressure amounts to 20 atmospheres. Furthermore, they note that this level of pressure gives a relative volume change of 0.001. Therefore, they neglect change in volume of water due to electric pressure, writing and put D&H say that, according to Planck, the classical part of the Gibbs free entropy is",
                    "score": 0.8432448506355286
                },
                {
                    "id": 3122157,
                    "contents": "Mpemba effect\nTao and co-workers proposed yet another possible explanation, on the basis of results from vibrational spectroscopy and modelling with density functional theory-optimized water clusters, they suggest that the reason might lie in the vast diversity and peculiar occurrence of different hydrogen bonds. Their key argument is that the number of strong hydrogen bonds increases as temperature is elevated. The existence of the small strongly-bonded clusters facilitates in turn the nucleation of hexagonal ice when warm water is rapidly cooled down.",
                    "score": 0.8412090539932251
                },
                {
                    "id": 15707707,
                    "contents": "Kelvin\n273.15 + 0.01 = 273.16 \"degrees Kelvin\" In 1967/1968, Resolution 3 of the 13th CGPM renamed the unit increment of thermodynamic temperature \"kelvin\", symbol K, replacing \"degree Kelvin\", symbol °K. Furthermore, feeling it useful to more explicitly define the magnitude of the unit increment, the 13th CGPM also held in Resolution 4 that \"The kelvin, unit of thermodynamic temperature, is equal to the fraction of the thermodynamic temperature of the triple point of water.\"",
                    "score": 0.8410549163818359
                },
                {
                    "id": 21705534,
                    "contents": "Frank Stillinger\nStillinger's research career has concentrated on condensed matter phenomena, both thermodynamic and kinetic. This research has included creation and computer simulation of molecular interaction potentials for water, silicon, and spontaneous-chiral-symmetry-breaking substances. These and other productive research topics have generated over 400 reviewed publications, involving more than 130 coauthors. Awards and honors Elliott Cresson Medal, Franklin Institute (1978) Elected Member, National Academy of Sciences (1984) Joel Hildebrand Prize, American Chemical Society (1986) Irving Langmuir Award, American Physical Society (1989) Peter Debye Award, American Chemical Society (1992) Onsager Medal, Norwegian University of Science and Technology, Trondheim (2002) Theoretical Chemistry Award, American Chemical Society (2013) Selected publications F. H. Stillinger, Energy Landscapes, Inherent Structures, and Condensed-Matter Phenomena. Princeton (2016). References",
                    "score": 0.8403095006942749
                },
                {
                    "id": 6019543,
                    "contents": "Debye–Hückel equation\nD&H don't say so, but the functional form for may be derived from the functional dependence of the chemical potential of a component of an ideal mixture upon its mole fraction. D&H note that the internal energy of a solution is lowered by the electrical interaction of its ions, but that this effect can't be determined by using the crystallographic approximation for distances between dissimilar atoms (the cube root of the ratio of total volume to the number of particles in the volume). This is because there is more thermal motion in a liquid solution than in a crystal. The thermal motion tends to smear out the natural lattice that would otherwise be constructed by the ions. Instead, D&H introduce the concept of an ionic atmosphere or cloud. Like the crystal lattice, each ion still attempts to surround itself with oppositely charged ions, but in a more free-form manner; at small distances away from positive ions, one is more likely to find negative ions and vice versa.",
                    "score": 0.8402788043022156
                },
                {
                    "id": 11433020,
                    "contents": "Water model\nSee also Water (properties) Water (data page) Water dimer Force field (chemistry) Comparison of force field implementations Molecular mechanics Molecular modelling Comparison of software for molecular mechanics modeling Solvent models References Water Computational chemistry",
                    "score": 0.8401975631713867
                },
                {
                    "id": 10432636,
                    "contents": "A. David Buckingham\nInitially he worked on dielectric properties of liquids, such as dipole moments of molecules in both solution and gas phases. He developed the theory of the interaction of molecules in liquids and gases with external electric and magnetic fields. In 1959, he proposed a direct method of measurement of molecular quadrupole moments of molecules (measured in buckinghams), which he demonstrated experimentally in 1963 on the carbon dioxide molecule. In 1960, he developed theories of solvent effects on nuclear magnetic resonance (NMR) spectra and vibrational spectra of molecules. In 1962 he considered the effect on NMR spectra of molecular orientation in a strong electric field, and developed a method to determine the absolute sign of the spin-spin coupling constant. In 1968, he determined the first accurate values of hyperpolarizability using the Kerr effect. In 1971 Buckingham and Laurence Barron pioneered the study of Raman optical activity, due to differences in the Raman scattering of",
                    "score": 0.8399118185043335
                },
                {
                    "id": 18647902,
                    "contents": "MOSCED\nThe authors found an average absolute deviation of 10.6% against their database of experimental data. The database contains limiting activity coefficients of binary systems of non-polar, polar and hydrogen compounds, but no water. As can be seen in the deviation chart, the systems with water deviate significantly.",
                    "score": 0.839762270450592
                },
                {
                    "id": 23905361,
                    "contents": "Mark Maroncelli\nResearch Prof. Maroncelli's research interests include solvation and solvent effects on chemical reaction, liquid-phase dynamics, electron and proton transfer reactions, supercritical fluids and expanded liquids, ionic liquids, ultrafast spectroscopy, and computer simulation.",
                    "score": 0.8396394848823547
                },
                {
                    "id": 20764666,
                    "contents": "Hydration energy\nThe hydration energies of the gaseous Li+, Na+, and Cs+ are respectively 520, 405, and 265 kJ/mol. See also Enthalpy of solution Heat of dilution Hydrate Hydrational fluid Ionization energy References Physical chemistry",
                    "score": 0.8388363122940063
                },
                {
                    "id": 5597112,
                    "contents": "Molar heat capacity\nIf the molecule could be entirely described using classical mechanics, then the theorem of equipartition of energy could be used to predict that each degree of freedom would have an average energy in the amount of kT, where k is Boltzmann's constant, and T is the temperature. If the number of degrees of freedom of the molecule is f, then each molecule would be holding, on average, a total energy equal to fkT. Then the molar heat capacity (at constant volume) would be cV,m = fR where R is the ideal gas constant. According to Mayer's relation, the molar heat capacity at constant pressure would be cP,m = cV,m + R = fR + R = (f + 2)R Thus, each additional degree of freedom will contribute R to the molar heat capacity of the gas (both cV,m and cP,m). In particular, each molecule of a monatomic gas has only f = 3 degrees of freedom, namely the components of its velocity vector; therefore cV,m = R and cP,m = R. Rotational modes of a diatomic molecule",
                    "score": 0.8386107087135315
                },
                {
                    "id": 13262039,
                    "contents": "List of scientific publications by Albert Einstein\n| Annalen der Physik (ser. 4), 4, 513–523, link || Intermolecular forces. The first of two papers in which Einstein proposed the (incorrect) theory that the interactions between all molecules are a universal function of distance, in analogy with the inverse-square force of gravity. Once parameterized, his theory makes reasonably accurate predictions for heavier hydrophobic molecules, but fails for lighter molecules. |- | Schilpp 2; CP 2, 2 || 1902 || Thermodynamische Theorie der Potentialdifferenz zwischen Metallen und vollständig dissoziierten Lösungen ihrer Salze, und eine elektrische Methode zur Erforschung der Molekularkräfte",
                    "score": 0.8385733366012573
                },
                {
                    "id": 1861869,
                    "contents": "Molecule\nEffective molecular radius is the size a molecule displays in solution. The table of permselectivity for different substances contains examples. Molecular formulas Chemical formula types The chemical formula for a molecule uses one line of chemical element symbols, numbers, and sometimes also other symbols, such as parentheses, dashes, brackets, and plus (+) and minus (−) signs. These are limited to one typographic line of symbols, which may include subscripts and superscripts.",
                    "score": 0.838331401348114
                },
                {
                    "id": 14345408,
                    "contents": "Partial molar property\nDefinition The partial molar volume is broadly understood as the contribution that a component of a mixture makes to the overall volume of the solution. However, there is more to it than this: When one mole of water is added to a large volume of water at 25 °C, the volume increases by 18 cm3. The molar volume of pure water would thus be reported as 18 cm3 mol−1. However, addition of one mole of water to a large volume of pure ethanol results in an increase in volume of only 14 cm3. The reason that the increase is different is that the volume occupied by a given number of water molecules depends upon the identity of the surrounding molecules. The value 14 cm3 is said to be the partial molar volume of water in ethanol. In general, the partial molar volume of a substance X in a mixture is the change in volume per mole of X added to the mixture.",
                    "score": 0.8381904363632202
                },
                {
                    "id": 1668667,
                    "contents": "Diatomic molecule\nAs early as 1805, Gay-Lussac and von Humboldt showed that water is formed of two volumes of hydrogen and one volume of oxygen, and by 1811 Amedeo Avogadro had arrived at the correct interpretation of water's composition, based on what is now called Avogadro's law and the assumption of diatomic elemental molecules. However, these results were mostly ignored until 1860, partly due to the belief that atoms of one element would have no chemical affinity toward atoms of the same element, and also partly due to apparent exceptions to Avogadro's law that were not explained until later in terms of dissociating molecules. At the 1860 Karlsruhe Congress on atomic weights, Cannizzaro resurrected Avogadro's ideas and used them to produce a consistent table of atomic weights, which mostly agree with modern values. These weights were an important prerequisite for the discovery of the periodic law by Dmitri Mendeleev and Lothar Meyer.",
                    "score": 0.8380375504493713
                },
                {
                    "id": 1749744,
                    "contents": "Gilbert N. Lewis\nat low temperatures. Richards too tried and failed, and not until Nernst succeeded in 1907 was it possible to calculate entropies unambiguously. Although Lewis’ fugacity-based system did not last, his early interest in free energy and entropy proved most fruitful, and much of his career was devoted to making these useful concepts accessible to practical chemists.",
                    "score": 0.8374612927436829
                },
                {
                    "id": 16655877,
                    "contents": "Properties of water\nSee also Chemical bonding of water Dihydrogen monoxide parody Double distilled water Electromagnetic absorption by water Fluid dynamics Hard water Heavy water Hydrogen polyoxide Ice Optical properties of water and ice Steam Superheated water Water cluster Water (data page) Water dimer Water model Water thread experiment Footnotes References Notes Bibliography Further reading External links Release on the IAPWS Formulation 1995 for the Thermodynamic Properties of Ordinary Water Substance for General and Scientific Use (simpler formulation) Online calculator using the IAPWS Supplementary Release on Properties of Liquid Water at 0.1 MPa, September 2008 Calculation of vapor pressure, liquid density, dynamic liquid viscosity, and surface tension of water Water Density Calculator Why does ice float in my drink?, NASA",
                    "score": 0.8372967839241028
                },
                {
                    "id": 24073414,
                    "contents": "Robert Zwanzig\nAn important result of the Zwanzig-Mori formalism, the Nakajima-Zwanzig equation, bears his name and reflects the important contributions of Sadao Nakajima made around the same time. Together with Tsu-Wei Nee he derived a theory for the dielectric function and dielectric friction of dipolar liquids based on an extension of Lars Onsager's work. Later he worked on the protein folding problem among other things. Awards and honors He received many awards, including the Peter Debye Award (1976), the Irving Langmuir Award (1985), the Joel H. Hildebrand Award (1994). He was a Fellow of the National Academy of Sciences and the American Chemical Society. Selected bibliography Nonequilibrium Statistical Mechanics, Oxford University Press 2001 References External links Obituary from the University of Maryland Biography",
                    "score": 0.8372748494148254
                },
                {
                    "id": 1759813,
                    "contents": "Hydrogen bond\nThe number of hydrogen bonds formed by a molecule of liquid water fluctuates with time and temperature. From TIP4P liquid water simulations at 25 °C, it was estimated that each water molecule participates in an average of 3.59 hydrogen bonds. At 100 °C, this number decreases to 3.24 due to the increased molecular motion and decreased density, while at 0 °C, the average number of hydrogen bonds increases to 3.69. Another study found a much smaller number of hydrogen bonds: 2.357 at 25 °C. The differences may be due to the use of a different method for defining and counting the hydrogen bonds. Where the bond strengths are more equivalent, one might instead find the atoms of two interacting water molecules partitioned into two polyatomic ions of opposite charge, specifically hydroxide (OH−) and hydronium (H3O+). (Hydronium ions are also known as \"hydroxonium\" ions.) H−O− H3O+",
                    "score": 0.8371919393539429
                },
                {
                    "id": 24462823,
                    "contents": "Hydration number\nThe hydration number, or solvation number of a compound is defined as the average number of molecules bound to the compound more strongly (by 13.3 kcal/mol or more) than they are bound to other water molecules. The hydration number is dependent on the concentration of the compound in solution, and the identity of the compound. When compounds are dissolved in water, the water molecules form a solvation shell surrounding the solute. For charged species, the orientation of water molecules around the solute is dependent on its ionic charge, with cations attracting water’s electronegative oxygen and anions attracting the hydrogens. Uncharged compounds such as methane can also be solvated by water and also have a hydration number. Although solvation shells can contain inner and outer shell solvent-solute interactions, the hydration number generally focuses on the inner shell solvent molecules that most directly interact with the solute.",
                    "score": 0.8370610475540161
                },
                {
                    "id": 5597119,
                    "contents": "Molar heat capacity\nAccording to classical mechanics, since atoms have non-zero size, they should also have three rotational degrees of freedom, or f = 6 in total. Likewise, the diatomic nitrogen molecule should have an additional rotation mode, namely about the line of the two atoms; and thus have f = 6 too. In the classical view, each of these modes should store an equal share of the heat energy. However, according to quantum mechanics, the energy difference between the allowed (quantized) rotation states is inversely proportional to the moment of inertia about the corresponding axis of rotation. Because the moment of inertia of a single atom is exceedingly small, the activation temperature for its rotational modes is extremely high. The same applies to the moment of inertia of a diatomic molecule (or a linear polyatomic one) about the internuclear axis, which is why that mode of rotation is not active in general.",
                    "score": 0.8370428681373596
                },
                {
                    "id": 428754,
                    "contents": "Molecular dynamics\nFurthermore, electrostatic interactions are usually calculated using the dielectric constant of vacuum, although the surrounding aqueous solution has a much higher dielectric constant. Using the macroscopic dielectric constant at short interatomic distances is questionable. Finally, van der Waals interactions in MD are usually described by Lennard-Jones potentials based on the Fritz London theory that is only applicable in a vacuum. However, all types of van der Waals forces are ultimately of electrostatic origin and therefore depend on dielectric properties of the environment. The direct measurement of attraction forces between different materials (as Hamaker constant) shows that \"the interaction between hydrocarbons across water is about 10% of that across vacuum\". The environment-dependence of van der Waals forces is neglected in standard simulations, but can be included by developing polarizable force fields.",
                    "score": 0.836734414100647
                },
                {
                    "id": 905531,
                    "contents": "Thermodynamic temperature\n1954: Resolution 3 of the 10th CGPM gave the kelvin scale its modern definition by choosing the triple point of water as its upper defining point (with no change to absolute zero being the null point) and assigning it a temperature of precisely 273.16 kelvins (what was actually written 273.16 degrees Kelvin at the time). This, in combination with Resolution 3 of the 9th CGPM, had the effect of defining absolute zero as being precisely zero kelvins and −273.15 °C. 1967/1968: Resolution 3 of the 13th CGPM renamed the unit increment of thermodynamic temperature kelvin, symbol K, replacing degree absolute, symbol °K. Further, feeling it useful to more explicitly define the magnitude of the unit increment, the 13th CGPM also decided in Resolution 4 that \"The kelvin, unit of thermodynamic temperature, is the fraction 1/273.16 of the thermodynamic temperature of the triple point of water\".",
                    "score": 0.8367131948471069
                },
                {
                    "id": 2204328,
                    "contents": "Standard enthalpy of reaction\nFor ions in aqueous solution, the standard state is often chosen such that the aqueous H+ ion at a concentration of exactly 1 mole/liter has a standard enthalpy of formation equal to zero, which makes possible the tabulation of standard enthalpies for cations and anions at the same standard concentration. This convention is consistent with the use of the standard hydrogen electrode in the field of electrochemistry. However, there are other common choices in certain fields, including a standard concentration for H+ of exactly 1 mole/(kg solvent) (widely used in chemical engineering) and mole/L (used in the field of biochemistry). For this reason it is important to note which standard concentration value is being used when consulting tables of enthalpies of formation.",
                    "score": 0.8364936709403992
                },
                {
                    "id": 111532,
                    "contents": "Molality\nOrigin The term molality is formed in analogy to molarity which is the molar concentration of a solution. The earliest known use of the intensive property molality and of its adjectival unit, the now-deprecated molal, appears to have been published by G. N. Lewis and M. Randall in the 1923 publication of Thermodynamics and the Free Energies of Chemical Substances. Though the two terms are subject to being confused with one another, the molality and molarity of a dilute aqueous solution are nearly the same, as one kilogram of water (solvent) occupies the volume of 1 liter at room temperature and a small amount of solute has little effect on the volume. Unit The SI unit for molality is moles per kilogram of solvent.",
                    "score": 0.8364868760108948
                },
                {
                    "id": 4258548,
                    "contents": "Molecular geometry\nThe influence of thermal excitation",
                    "score": 0.8364318013191223
                },
                {
                    "id": 471717,
                    "contents": "Van der Waals equation\nWhen the molar volume Vm is large, b becomes negligible in comparison with Vm, a/Vm2 becomes negligible with respect to P, and the Van der Waals equation reduces to the ideal gas law, PVm=RT. This equation approximates the behavior of real fluids above their critical temperatures and is qualitatively reasonable for their liquid and low-pressure gaseous states at low temperatures. However, near the phase transitions between gas and liquid, in the range of p, V, and T where the liquid phase and the gas phase are in equilibrium, the Van der Waals equation fails to accurately model observed experimental behavior. In particular, p is a constant function of V at given temperatures in these regions. As such, the Van der Waals model is not useful for calculations intended to predict real behavior in regions near critical points. Corrections to address these predictive deficiencies include the equal area rule and the principle of corresponding states.",
                    "score": 0.836386501789093
                },
                {
                    "id": 5597120,
                    "contents": "Molar heat capacity\nOn the other hand, electrons and nuclei can exist in excited states and, in a few exceptional cases, they may be active even at room temperature, or even at cryogenic temperatures. Polyatomic gases The set of all possible ways to infinitesimally displace the n atoms of a polyatomic gas molecule is a linear space of dimension 3n, because each atom can be independently displaced in each of three orthogonal axis directions. However, some three of these dimensions are just translation of the molecule by an infinitesimal displacement vector, and others are just rigid rotations of it by an infinitesimal angle about some axis. Still others may correspond to relative rotation of two parts of the molecule about a single bond that connects them.",
                    "score": 0.8363758325576782
                },
                {
                    "id": 1749734,
                    "contents": "Gilbert N. Lewis\nHarvard, Manila, and MIT After his stay in Nernst's lab, Lewis returned to Harvard in 1901 as an instructor for three more years. He was appointed instructor in thermodynamics and electrochemistry. In 1904 Lewis was granted a leave of absence and became Superintendent of Weights and Measures for the Bureau of Science in Manila, Philippines. The next year he returned to Cambridge, Massachusetts when the Massachusetts Institute of Technology (MIT) appointed him to a faculty position, in which he had a chance to join a group of outstanding physical chemists under the direction of Arthur Amos Noyes. He became an assistant professor in 1907, associate professor in 1908, and full professor in 1911.",
                    "score": 0.8362337350845337
                },
                {
                    "id": 13606210,
                    "contents": "Excess chemical potential\nSee also Apparent molar property References Note: the equations and presentation in this article are drawn from Excess Chemical Potential via the Widom Method Potentials Thermodynamics Chemical thermodynamics ro:Mărimi molare de exces",
                    "score": 0.8361088633537292
                },
                {
                    "id": 6338082,
                    "contents": "Entropic force\nHydrophobic force Another example of an entropic force is the hydrophobic force. At room temperature, it partly originates from the loss of entropy by the 3D network of water molecules when they interact with molecules of dissolved substance. Each water molecule is capable of donating two hydrogen bonds through the two protons accepting two more hydrogen bonds through the two sp3-hybridized lone pairs Therefore, water molecules can form an extended three-dimensional network. Introduction of a non-hydrogen-bonding surface disrupts this network. The water molecules rearrange themselves around the surface, so as to minimize the number of disrupted hydrogen bonds. This is in contrast to hydrogen fluoride (which can accept 3 but donate only 1) or ammonia (which can donate 3 but accept only 1), which mainly form linear chains.",
                    "score": 0.8359558582305908
                },
                {
                    "id": 5597114,
                    "contents": "Molar heat capacity\nBecause of those two extra degrees of freedom, the molar heat capacity cV,m of (20.6 J⋅K−1⋅mol−1) is greater than that of an hypothetical monatomic gas (12.5 J⋅K−1⋅mol−1) by a factor of . Frozen and active degrees of freedom According to classical mechanics, a diatomic molecule like nitrogen should have more degrees of internal freedom, corresponding to vibration of the two atoms that stretch and compress the bond between them. For thermodynamic purposes, each direction in which an atom can independently vibrate relative to the rest of the molecule introduces two degrees of freedom: one associated with the potential energy from distorting the bonds, and one for the kinetic energy of the atom's motion. In a diatomic molecule like , there is only one direction for the vibration, and the motions of the two atoms must be opposite but equal; so there are only two degrees of vibrational freedom. That would bring f up to 7, and cV,m to 3.5 R.",
                    "score": 0.8357136845588684
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_16",
        "question": "In an industrial process, nitrogen is heated to $500 \\mathrm{~K}$ at a constant volume of $1.000 \\mathrm{~m}^3$. The gas enters the container at $300 \\mathrm{~K}$ and $100 \\mathrm{~atm}$. The mass of the gas is $92.4 \\mathrm{~kg}$. Use the van der Waals equation to determine the approximate pressure of the gas at its working temperature of $500 \\mathrm{~K}$. For nitrogen, $a=1.39 \\mathrm{dm}^6 \\mathrm{~atm} \\mathrm{~mol}^{-2}, b=0.0391 \\mathrm{dm}^3 \\mathrm{~mol}^{-1}$.",
        "golden_answers": [
            " 140"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1128632,
                    "contents": "Nitrogen\nProduction Nitrogen gas is an industrial gas produced by the fractional distillation of liquid air, or by mechanical means using gaseous air (pressurised reverse osmosis membrane or pressure swing adsorption). Nitrogen gas generators using membranes or pressure swing adsorption (PSA) are typically more cost and energy efficient than bulk delivered nitrogen. Commercial nitrogen is often a byproduct of air-processing for industrial concentration of oxygen for steelmaking and other purposes. When supplied compressed in cylinders it is often called OFN (oxygen-free nitrogen). Commercial-grade nitrogen already contains at most 20 ppm oxygen, and specially purified grades containing at most 2 ppm oxygen and 10 ppm argon are also available. In a chemical laboratory, it is prepared by treating an aqueous solution of ammonium chloride with sodium nitrite. NH4Cl + NaNO2 → N2 + NaCl + 2 H2O",
                    "score": 0.9010211229324341
                },
                {
                    "id": 1128644,
                    "contents": "Nitrogen\nVessels containing liquid nitrogen can condense oxygen from air. The liquid in such a vessel becomes increasingly enriched in oxygen (boiling point −183 °C, higher than that of nitrogen) as the nitrogen evaporates, and can cause violent oxidation of organic material.",
                    "score": 0.9009719491004944
                },
                {
                    "id": 22107506,
                    "contents": "Rakesh Agrawal (chemical engineer)\nIn 2002, Agrawal was elected as a member of the National Academy of Engineering for contributions to the development and worldwide implementation of high-efficiency and high-purity cryogenic and non-cryogenic gas separation processes. Contributions to Separations and Gas Liquefaction While at Air Products and Chemicals, Agrawal made contributions that have improved the efficiency of natural gas liquefaction, electronic gases manufacturing, cryogenic processing and gas separation. He led the development of the APX process for natural gas liquefaction that more than doubled the production from a single train. For semiconductor applications, Agrawal invented Column-Plus and Double Column-Plus ultra high purity (UHP) nitrogen and UHP liquid oxygen processes that reduce product impurities to less than one part per billion. He invented an efficient process to recover refrigeration from liquefied natural gas to produce liquid nitrogen and oxygen.",
                    "score": 0.8965826630592346
                },
                {
                    "id": 1567810,
                    "contents": "Ammonia\nThis reaction is exothermic and results in decreased entropy, meaning that the reaction is favoured at lower temperatures and higher pressures. It is difficult and expensive to achieve, as lower temperatures result in slower reaction kinetics (hence a slower reaction rate) and high pressure requires high-strength pressure vessels that are not weakened by hydrogen embrittlement. Diatomic nitrogen is bound together by a triple bond, which makes it rather inert. Yield and efficiency are low, meaning that the output must be continuously separated and extracted for the reaction to proceed at an acceptable pace. Combined with the energy needed to produce hydrogen and purified atmospheric nitrogen, ammonia production is energy-intensive, accounting for 1 to 2% of global energy consumption, 3% of global carbon emissions, and 3 to 5% of natural gas consumption.",
                    "score": 0.8947669267654419
                },
                {
                    "id": 1414444,
                    "contents": "Liquid nitrogen\nProduction Liquid nitrogen is produced commercially from the cryogenic distillation of liquified air or from the liquefication of pure nitrogen derived from air using pressure swing adsorption. An air compressor is used to compress filtered air to high pressure; the high-pressure gas is cooled back to ambient temperature, and allowed to expand to a low pressure. The expanding air cools greatly (the Joule–Thomson effect), and oxygen, nitrogen, and argon are separated by further stages of expansion and distillation. Small-scale production of liquid nitrogen is easily achieved using this principle. Liquid nitrogen may be produced for direct sale, or as a byproduct of manufacture of liquid oxygen used for industrial processes such as steelmaking. Liquid-air plants producing on the order of tons per day of product started to be built in the 1930s but became very common after the Second World War; a large modern plant may produce 3000 tons/day of liquid air products.",
                    "score": 0.8876694440841675
                },
                {
                    "id": 7552282,
                    "contents": "Industrial gas\nHowever not all industrial gases are supplied in the gaseous phase. A few gases are vapors that can be liquefied at ambient temperature under pressure alone, so they can also be supplied as a liquid in an appropriate container. This phase change also makes these gases useful as ambient refrigerants and the most significant industrial gases with this property are ammonia (R717), propane (R290), butane (R600), and sulfur dioxide (R764). Chlorine also has this property but is too toxic, corrosive and reactive to ever have been used as a refrigerant. Some other gases exhibit this phase change if the ambient temperature is low enough; this includes ethylene (R1150), carbon dioxide (R744), ethane (R170), nitrous oxide (R744A), and sulfur hexafluoride; however, these can only be liquefied under pressure if kept below their critical temperatures which are 9 °C for C2H4 ; 31 °C for CO2 ; 32 °C for C2H6 ; 36 °C for N2O ; 45 °C for SF6. All of these substances are also provided as a gas (not a",
                    "score": 0.8863706588745117
                },
                {
                    "id": 1128633,
                    "contents": "Nitrogen\nIn a chemical laboratory, it is prepared by treating an aqueous solution of ammonium chloride with sodium nitrite. NH4Cl + NaNO2 → N2 + NaCl + 2 H2O Small amounts of the impurities NO and HNO3 are also formed in this reaction. The impurities can be removed by passing the gas through aqueous sulfuric acid containing potassium dichromate. Very pure nitrogen can be prepared by the thermal decomposition of barium azide or sodium azide. 2 NaN3 → 2 Na + 3 N2 Applications Gas The applications of nitrogen compounds are naturally extremely widely varied due to the huge size of this class: hence, only applications of pure nitrogen itself will be considered here. Two-thirds (2/3) of nitrogen produced by industry is sold as the gas and the remaining one-third (1/3) as the liquid.",
                    "score": 0.8855037093162537
                },
                {
                    "id": 7552283,
                    "contents": "Industrial gas\npressure if kept below their critical temperatures which are 9 °C for C2H4 ; 31 °C for CO2 ; 32 °C for C2H6 ; 36 °C for N2O ; 45 °C for SF6. All of these substances are also provided as a gas (not a vapor) at the 200 bar pressure in a gas cylinder because that pressure is above their critical pressure.",
                    "score": 0.8822063207626343
                },
                {
                    "id": 7552277,
                    "contents": "Industrial gas\nCryogenic technologies also allow the liquefaction of natural gas, hydrogen and helium. In natural-gas processing, cryogenic technologies are used to remove nitrogen from natural gas in a Nitrogen Rejection Unit; a process that can also be used to produce helium from natural gas where natural gas fields contain sufficient helium to make this economic. The larger industrial gas companies have often invested in extensive patent libraries in all fields of their business, but particularly in cryogenics.",
                    "score": 0.8806241750717163
                },
                {
                    "id": 1414433,
                    "contents": "Liquid nitrogen\nLiquid nitrogen—LN2—is nitrogen in a liquid state at low temperature. Liquid nitrogen has a boiling point of about . It is produced industrially by fractional distillation of liquid air. It is a colorless, low viscosity liquid that is widely used as a coolant. Physical properties The diatomic character of the N2 molecule is retained after liquefaction. The weak van der Waals interaction between the N2 molecules results in little interatomic interaction, manifested in its very low boiling point.",
                    "score": 0.8802450895309448
                },
                {
                    "id": 14889237,
                    "contents": "BMA process\nThe BMA process or Degussa process is a chemical process developed by the German chemical company Degussa for the production of hydrogen cyanide from methane and ammonia in presence of a platinum catalyst. Hydrogen cyanide is used in the chemical industry for the production of intermediate chemicals like acrylonitrile, methyl methacrylate, and adiponitrile. The name is abbreviated from Blausäure (hydrogen cyanide) from Methan (methane) and Ammoniak (ammonia) in German. The reaction equation is analog to the steam methane reforming (SMR) reaction of methane and water: CH4 + NH3 → HCN + 3 H2, ΔHR = 251 kJ / mol The reaction is extremely endothermic. The reactants react in a Platinum-covered pipe at approximately 1400 °C. The reaction mixture contains around 23 Vol.-% HCN and 72 Vol.-% H2 as well as minor quantities of ammonia, nitrogen, and unreacted methane.",
                    "score": 0.8790210485458374
                },
                {
                    "id": 8409261,
                    "contents": "Nitriding\nThe advantages of gas nitriding over other variants are: Precise control of chemical potential of nitrogen in the nitriding atmosphere by controlling gas flow rate of nitrogen and oxygen. All round nitriding effect (can be a disadvantage in some cases, compared with plasma nitriding) Large batch sizes possible - the limiting factor being furnace size and gas flow With modern computer control of the atmosphere the nitriding results can be closely controlled Relatively low equipment cost - especially compared with plasma The disadvantages of gas nitriding are:",
                    "score": 0.8787696957588196
                },
                {
                    "id": 8409260,
                    "contents": "Nitriding\nProcesses The processes are named after the medium used to donate. The three main methods used are: gas nitriding, salt bath nitriding, and plasma nitriding. Gas nitriding In gas nitriding the donor is a nitrogen-rich gas, usually ammonia (NH3), which is why it is sometimes known as ammonia nitriding. When ammonia comes into contact with the heated work piece it dissociates into nitrogen and hydrogen. The nitrogen then diffuses onto the surface of the material creating a nitride layer. This process has existed for nearly a century, though only in the last few decades has there been a concentrated effort to investigate the thermodynamics and kinetics involved. Recent developments have led to a process that can be accurately controlled. The thickness and phase constitution of the resulting nitriding layers can be selected and the process optimized for the particular properties required.",
                    "score": 0.8785833120346069
                },
                {
                    "id": 19207182,
                    "contents": "Endothermic gas\nChemical composition Chemistry of endothermic gas generators: N2 (nitrogen) → 45.1% (volume) CO (carbon monoxide) → 19.6% (volume) CO2 (carbon dioxide) → 0.4% (volume) H2 (hydrogen) → 34.6% (volume) CH4 (methane) → 0.3% (volume) Dew point → +20/+50 Gas ratio → 2.6:1 Applications Applications of endothermic gas generators: Annealing: iron and steel Brazing: copper and silver Carbon restoration: carburizing, carbonitriding, nitrocarburizing Neutral hardening: low, medium and high alloy carbon steels Normalizing: iron and steel Sintering: powder metals It is relatively simple to operate and maintain endothermic gas generators, however, maintenance such as the burnout process is often overlooked. See also Forming gas References Gases Industrial gases",
                    "score": 0.878118097782135
                },
                {
                    "id": 7552287,
                    "contents": "Industrial gas\nWhat defines an industrial gas Industrial gas is a group of materials that are specifically manufactured for use in industry and are also gaseous at ambient temperature and pressure. They are chemicals which can be an elemental gas or a chemical compound that is either organic or inorganic, and tend to be low molecular weight molecules. They could also be a mixture of individual gases. They have value as a chemical; whether as a feedstock, in process enhancement, as a useful end product, or for a particular use; as opposed to having value as a \"simple\" fuel.",
                    "score": 0.8774416446685791
                },
                {
                    "id": 1414445,
                    "contents": "Liquid nitrogen\nSee also Liquefaction of gases Industrial gas Computer cooling Cryogenic nitrogen plant Liquid nitrogen engine References Nitrogen Coolants Medical equipment Industrial gases Liquids Food and drink preparation Articles containing video clips",
                    "score": 0.8770977854728699
                },
                {
                    "id": 2938040,
                    "contents": "Henry Louis Le Chatelier\nLe Chatelier in 1901 attempted the direct combination of the two gases nitrogen and hydrogen at a pressure of 200 atm and 600 °C in the presence of metallic iron. An air compressor forced the mixture of gases into a steel Berthelot bomb, where a platinum spiral heated them and the reduced iron catalyst. A terrific explosion occurred which nearly killed an assistant. Le Chatelier found that the explosion was due to the presence of air in the apparatus used. And thus it was left for Haber to succeed where several noted French chemists, including Thenard, Sainte Claire Deville and even Berthelot had failed. Less than five years later, Haber and Claude were successful in producing ammonia on a commercial scale, acknowledging that the account of Le Chatelier's failed attempt had accelerated their research. Near the end of his life, Le Chatelier wrote, \"I let the discovery of the ammonia synthesis slip through my hands. It was the greatest blunder of my scientific career”.",
                    "score": 0.8770971298217773
                },
                {
                    "id": 1457072,
                    "contents": "Liquid oxygen\nLiquid nitrogen has a lower boiling point at −196 °C (77 K) than oxygen's −183 °C (90 K), and vessels containing liquid nitrogen can condense oxygen from air: when most of the nitrogen has evaporated from such a vessel, there is a risk that liquid oxygen remaining can react violently with organic material. Conversely, liquid nitrogen or liquid air can be oxygen-enriched by letting it stand in open air; atmospheric oxygen dissolves in it, while nitrogen evaporates preferentially. The surface tension of liquid oxygen at its normal pressure boiling point is 13.2 dyn/cm. Uses In commerce, liquid oxygen is classified as an industrial gas and is widely used for industrial and medical purposes. Liquid oxygen is obtained from the oxygen found naturally in air by fractional distillation in a cryogenic air separation plant.",
                    "score": 0.8769903182983398
                },
                {
                    "id": 7552295,
                    "contents": "Industrial gas\nAir gases nitrogen (N2) oxygen (O2) argon (Ar) Noble gases helium (He) neon (Ne) argon (Ar) krypton (Kr) xenon (Xe) radon (Rn) The other Elemental gases hydrogen (H2) chlorine (Cl2) (vapor) fluorine (F2) Other common industrial gases This list shows the other most common gases sold by industrial gas companies. Compound gases ammonia (NH3) carbon dioxide (CO2) carbon monoxide (CO) hydrogen chloride (HCl) nitrous oxide (N2O) nitrogen trifluoride (NF3) sulfur dioxide (SO2) sulfur hexafluoride (SF6) Hydrocarbon gases methane (CH4) acetylene (C2H2) ethane (C2H6) ethene (C2H4) propane (C3H8) propene (C3H6) butane (C4H10) butene (C4H8) Significant gas mixtures air breathing gases forming gas welding shielding gas synthesis gas Penning mixture Mixed Refrigerant used in LNG cycles There are many gas mixtures possible. Important liquefied gases This list shows the most important liquefied gases:",
                    "score": 0.8754032254219055
                },
                {
                    "id": 18045721,
                    "contents": "Matheson (compressed gas & equipment)\nIndustrial gas, Applications Technology, and Equipment, including on-site and merchant bulk gas and equipment and packaged gases and equipment for welding (argon) & cutting, construction, medical oxygen, laser, wine making, food processing & preservation nitrogen, beverage making (carbonation), helium supply & recovery, residential and commercial propane, and other areas. Specialty Gases and Equipment, including high purity gas, gas mixtures, environmental gas calibration standards, EPA Protocol Gases, and associated hardware and services – primarily serving the laboratory, process, and environmental gas user and other specialties. References External links Matheson website TNSC Air Separation Air Separation Plant Design, Engineering, Manufacturing, Installation. Chemical companies of the United States Industrial gases Mitsubishi Chemical Holdings",
                    "score": 0.8745360374450684
                },
                {
                    "id": 15503260,
                    "contents": "Nitrogen generator\nDependability: Gas separation units have no moving component parts, thus ensuring exceptional reliability. Membranes are highly resistant to vibration and shocks, chemically inert to greases, moisture-insensitive, and capable of operating over a wide temperature range of –40°С to +60°С. With appropriate maintenance, membrane unit useful life ranges between 130,000 and 180,000 hours (15 to 20 years of continuous operation). Disadvantages Limited capacity Relatively low purity compared to PSA units (95% to 99% purity as compared to 99.9995% - higher purity applications are available at lower flow rates ≤ 10L/min)",
                    "score": 0.873361349105835
                },
                {
                    "id": 7552273,
                    "contents": "Industrial gas\nOnce gases had been discovered and produced in modest quantities, the process of industrialisation spurred on innovation and invention of technology to produce larger quantities of these gases. Notable developments in the industrial production of gases include the electrolysis of water to produce hydrogen (in 1869) and oxygen (from 1888), the Brin process for oxygen production which was invented in the 1884, the chloralkali process to produce chlorine in 1892 and the Haber Process to produce ammonia in 1908.",
                    "score": 0.8726967573165894
                },
                {
                    "id": 5606465,
                    "contents": "History of chemistry\nLate 19th century German engineer Carl von Linde's invention of a continuous process of liquefying gases in large quantities formed a basis for the modern technology of refrigeration and provided both impetus and means for conducting scientific research at low temperatures and very high vacuums. He developed a dimethyl ether refrigerator (1874) and an ammonia refrigerator (1876). Though other refrigeration units had been developed earlier, Linde's were the first to be designed with the aim of precise calculations of efficiency. In 1895 he set up a large-scale plant for the production of liquid air. Six years later he developed a method for separating pure liquid oxygen from liquid air that resulted in widespread industrial conversion to processes utilizing oxygen (e.g., in steel manufacture).",
                    "score": 0.8718776106834412
                },
                {
                    "id": 1638414,
                    "contents": "Catalysis\nThe production of ammonia is one of the largest-scale and most energy-intensive processes. In the Haber process nitrogen is combined with hydrogen over an iron oxide catalyst. Methanol is prepared from carbon monoxide or carbon dioxide but using copper-zinc catalysts. Bulk polymers derived from ethylene and propylene are often prepared via Ziegler-Natta catalysis. Polyesters, polyamides, and isocyanates are derived via acid-base catalysis. Most carbonylation processes require metal catalysts, examples include the Monsanto acetic acid process and hydroformylation.",
                    "score": 0.8708812594413757
                },
                {
                    "id": 3817479,
                    "contents": "Bottled gas\nCase II The substance liquefies at standard temperature but increased pressure. Examples include: ammonia butane carbon dioxide (also packaged as a cryogenic gas, Case IV) chlorine nitrous oxide propane sulfur dioxide",
                    "score": 0.8703991174697876
                },
                {
                    "id": 15062554,
                    "contents": "Chemically inert\nInert gas The term inert may also be applied in a relative sense. For example, molecular nitrogen is an inert gas under ordinary conditions, existing as diatomic molecules, . The presence of a strong triple covalent bond in the molecule renders it unreactive under normal circumstances. Nevertheless, nitrogen gas does react with the alkali metal lithium to form compound lithium nitride (Li3N), even under ordinary conditions. Under high pressures and temperatures and with the right catalysts, nitrogen becomes more reactive; the Haber process uses such conditions to produce ammonia from atmospheric nitrogen. Main uses Inert atmospheres consisting of gases such as argon, nitrogen, or helium are commonly used in chemical reaction chambers and in storage containers for oxygen-sensitive or water-sensitive substances, to prevent unwanted reactions of these substances with oxygen or water.",
                    "score": 0.8696374297142029
                },
                {
                    "id": 15503266,
                    "contents": "Nitrogen generator\nPaint-and-varnish industry: Paint and varnish production uses nitrogen for the creation of an inert environment in process vessels to ensure safety, as well as for oxygen displacement during packing in order to prevent polymerization of drying oils. Petroleum industry: In the petroleum industry, nitrogen is an indispensable component in a number of processes. Most commonly, nitrogen is used to create an inert environment for preventing explosions and for fire safety and to support transportation and transfer of hydrocarbons. Additionally, nitrogen is used for pipeline testing and purging, cleaning technological vessels and cleaning liquefied gas carriers and hydrocarbon storage facilities. Pharmaceutical industry: In the pharmaceutical industry, nitrogen finds application in pharmaceuticals packaging, and ensuring against explosion and fire safety in activities where fine dispersed substances are used. See also Liquid nitrogen Industrial gas References",
                    "score": 0.8687834739685059
                },
                {
                    "id": 3790645,
                    "contents": "Gas lighting\nIt took nearly 200 years for gas to become accessible for commercial use. A Flemish alchemist, Jan Baptista van Helmont, was the first person to formally recognize gas as a state of matter. He would go on to identify several types of gases, including carbon dioxide. Over one hundred years later in 1733, Sir James Lowther had some of his miners working on a water pit for his mine. While digging the pit they hit a pocket of gas. Lowther took a sample of the gas and took it home to do some experiments. He noted, \"The said air being put into a bladder … and tied close, may be carried away, and kept some days, and being afterwards pressed gently through a small pipe into the flame of a candle, will take fire, and burn at the end of the pipe as long as the bladder is gently pressed to feed the flame, and when taken from the candle after it is so lighted, it will continue burning till there is no more air left in the bladder to supply the flame.\" Lowther had basically discovered the",
                    "score": 0.8681639432907104
                },
                {
                    "id": 18045716,
                    "contents": "Matheson (compressed gas & equipment)\nMatheson Tri-Gas, Inc. is a supplier of industrial and specialty gases, and gas handling equipment in the United States. The company offers semiconductor, medical gases, welding, atmospheric and bulk, and cylinder gases for customers using gas in their labs, fabs, plants, and processes. It also designs and manufactures gas purification systems, generators, delivery systems, filters, purifiers, detection equipment, control valves, and management accessories; and cylinder gas enclosures, source manifolds, and panels, as well as helium recovery solutions. In addition, the company provides support, engineering, and systems management services to analytical laboratories and semiconductor manufacturers worldwide. Matheson is the North American operating entity, and the largest subsidiary of Taiyo Nippon Sanso Corporation (), one of the top four suppliers of industrial gases in the world, and the largest in Japan. TNSC is an affiliate of Mitsubishi Chemical Holdings.",
                    "score": 0.8678147792816162
                },
                {
                    "id": 7552284,
                    "contents": "Industrial gas\nPermanent gases (those with a critical temperature below ambient) can only be supplied as liquid if they are also cooled. All gases can potentially be used as a refrigerant around the temperatures at which they are liquid; for example nitrogen (R728) and methane (R50) are used as refrigerant at cryogenic temperatures. Exceptionally carbon dioxide can be produced as a cold solid known as dry ice, which sublimes as it warms in ambient conditions, the properties of carbon dioxide are such that it cannot be liquid at a pressure below its triple point of 5.1 bar. Acetylene is also supplied differently. Since it is so unstable and explosive, this is supplied as a gas dissolved in acetone within a packing mass in a cylinder. Acetylene is also the only other common industrial gas that sublimes at atmospheric pressure. Gas delivery The major industrial gases can be produced in bulk and delivered to customers by pipeline, but can also be packaged and transported.",
                    "score": 0.8671484589576721
                },
                {
                    "id": 7552288,
                    "contents": "Industrial gas\nThe term “industrial gases” is sometimes narrowly defined as just the major gases sold, which are: nitrogen, oxygen, carbon dioxide, argon, hydrogen, acetylene and helium. Many names are given to gases outside of this main list by the different industrial gas companies, but generally the gases fall into the categories \"specialty gases\", “medical gases”, “fuel gases” or “refrigerant gases”. However gases can also be known by their uses or industries that they serve, hence \"welding gases\" or \"breathing gases\", etc.; or by their source, as in \"air gases\"; or by their mode of supply as in \"packaged gases\". The major gases might also be termed \"bulk gases\" or \"tonnage gases\".",
                    "score": 0.8666671514511108
                },
                {
                    "id": 744154,
                    "contents": "Solid-state chemistry\nGas reactions Many solids react vigorously with reactive gas species like chlorine, iodine, oxygen etc. Others form adducts with other gases, e.g. CO or ethylene. Such reactions are often conducted in a tube that is open ended on both sides and through which the gas is passed. A variation of this is to let the reaction take place inside a measuring device such as a TGA. In that case stoichiometric information can be obtained during the reaction, which helps identify the products. Chemical transport reactions are used to purify and to grow crystals of materials. The process is often carried out in a sealed ampoule. The transport process entails the addition small amount of a transport agent, e.g., iodine, which generates a volatile intermediate species that migrates (transports). The ampoule is then placed in an oven with two temperature zones.",
                    "score": 0.8663125038146973
                },
                {
                    "id": 1414434,
                    "contents": "Liquid nitrogen\nThe temperature of liquid nitrogen can readily be reduced to its freezing point by placing it in a vacuum chamber pumped by a vacuum pump. Liquid nitrogen's efficiency as a coolant is limited by the fact that it boils immediately on contact with a warmer object, enveloping the object in an insulating layer of nitrogen gas bubbles. This effect, known as the Leidenfrost effect, occurs when any liquid comes in contact with a surface which is significantly hotter than its boiling point. Faster cooling may be obtained by plunging an object into a slush of liquid and solid nitrogen rather than liquid nitrogen alone.",
                    "score": 0.8653706312179565
                },
                {
                    "id": 7552275,
                    "contents": "Industrial gas\nAlthough no one event marks the beginning of the industrial gas industry, many would take it to be the 1880s with the construction of the first high pressure gas cylinders. Initially cylinders were mostly used for carbon dioxide in carbonation or dispensing of beverages. In 1895 refrigeration compression cycles were further developed to enable the liquefaction of air, most notably by Carl von Linde allowing larger quantities of oxygen production and in 1896 the discovery that large quantities of acetylene could be dissolved in acetone and rendered nonexplosive allowed the safe bottling of acetylene. A particularly important use was the development of welding and metal cutting done with oxygen and acetylene from the early 1900s. As production processes for other gases were developed many more gases came to be sold in cylinders without the need for a gas generator. Gas production technology",
                    "score": 0.8647305965423584
                },
                {
                    "id": 4251161,
                    "contents": "Carl von Linde\nLinde followed development of air liquefaction equipment with equipment that also separated air into its constituent parts using distillation processes. Linde's inventions and developments spurred development in many areas of cryogenics, physics, chemistry and engineering. Patents CH10704 – 31 January 1896 – Gasverflüssigungs-maschine (Machine for the liquefaction of gas) (in German) – Switzerland GB189512528 – 16 May 1896 – Process and Apparatus for Liquefying Gases or Gaseous Mixtures, and for Producing Cold, more particularly applicable for Separating Oxygen from Atmospheric Air – UK – 12 May 1903 – Linde oxygen process – US – 12 May 1903 – Equipment for Linde oxygen process – US – 25 July 1905 – Equipment for Linde oxygen and nitrogen process – US Awards Wilhelm Exner Medal, 1922 See also Air separation Hampson–Linde cycle Industrial gas Linde–Frank–Caro process Oxyliquit Timeline of low-temperature technology German inventors and discoverers References",
                    "score": 0.8637412190437317
                },
                {
                    "id": 1128564,
                    "contents": "Nitrogen\nMany industrially important compounds, such as ammonia, nitric acid, organic nitrates (propellants and explosives), and cyanides, contain nitrogen. The extremely strong triple bond in elemental nitrogen (N≡N), the second strongest bond in any diatomic molecule after carbon monoxide (CO), dominates nitrogen chemistry. This causes difficulty for both organisms and industry in converting N2 into useful compounds, but at the same time it means that burning, exploding, or decomposing nitrogen compounds to form nitrogen gas releases large amounts of often useful energy. Synthetically produced ammonia and nitrates are key industrial fertilisers, and fertiliser nitrates are key pollutants in the eutrophication of water systems.",
                    "score": 0.8634021282196045
                },
                {
                    "id": 18045717,
                    "contents": "Matheson (compressed gas & equipment)\nHistory Matheson Gas Products was founded in 1927 in North Bergen, New Jersey, by Adam Matheson. By virtue of the founding of his company, Adam Matheson created the specialty gas business. Among Matheson's more notable accomplishments are the development of the lecture bottle, now used by virtually every major college and university in the world; and the supply of ultra-pure gases that served as standards for the first gas chromatographs. In 1966, Matheson acquired Grey Chemical of Gloucester, Massachusetts, USA, a producer of ultra-pure gas materials used in electronics manufacturing. In 1981, Matheson became the first commercial producer of Silane, for which it was awarded a “Semmy” Award by the Semiconductor Equipment and Materials Institute (the award is now known as a “Semi” and the organization has since changed its name to Semiconductor Equipment and Materials International).",
                    "score": 0.8633034229278564
                },
                {
                    "id": 1457075,
                    "contents": "Liquid oxygen\nHistory By 1845, Michael Faraday had managed to liquefy most gases then known to exist. Six gases, however, resisted every attempt at liquefaction and were known at the time as \"permanent gases\". They were oxygen, hydrogen, nitrogen, carbon monoxide, methane, and nitric oxide. In 1877, Louis Paul Cailletet in France and Raoul Pictet in Switzerland succeeded in producing the first droplets of liquid air. In 1883, Polish professors Zygmunt Wróblewski and Karol Olszewski produced the first measurable quantity of liquid oxygen. See also Oxygen storage Industrial gas Cryogenics Liquid hydrogen Liquid helium Liquid nitrogen List of Stoffs Natterer compressor Rocket fuel Solid oxygen Tetraoxygen References Rocket oxidizers Cryogenics Oxygen Industrial gases Liquids 1883 in science",
                    "score": 0.8628641366958618
                },
                {
                    "id": 1138411,
                    "contents": "Nitric acid\nThe industrial production of nitric acid from atmospheric air began in 1905 with the Birkeland–Eyde process, also known as the arc process. This process is based upon the oxidation of atmospheric nitrogen by atmospheric oxygen to nitric oxide with a very high temperature electric arc. Yields of up to approximately 4–5% nitric oxide were obtained at 3000 °C, and less at lower temperatures. The nitric oxide was cooled and oxidized by the remaining atmospheric oxygen to nitrogen dioxide, and this was subsequently absorbed in water in a series of packed column or plate column absorption towers to produce dilute nitric acid. The first towers bubbled the nitrogen dioxide through water and non-reactive quartz fragments. About 20% of the produced oxides of nitrogen remained unreacted so the final towers contained an alkali solution to neutralize the rest. The process was very energy intensive and was rapidly displaced by the Ostwald process once cheap ammonia became available.",
                    "score": 0.8627282381057739
                },
                {
                    "id": 7552296,
                    "contents": "Industrial gas\nThere are many gas mixtures possible. Important liquefied gases This list shows the most important liquefied gases: Produced from air liquid nitrogen (LIN) liquid oxygen (LOX) liquid argon (LAR) Produced from various sources liquid carbon dioxide Produced from hydrocarbon feedstock liquid hydrogen liquid helium Gas mixtures produced from hydrocarbon feedstock Liquefied natural gas (LNG) Liquefied petroleum gas (LPG) Industrial gas applications The uses of industrial gases are diverse. The following is a small list of areas of use: Companies AGA AB (part of The Linde Group) Airgas (part of Air Liquide) Air Liquide Air Products & Chemicals BASF BOC (part of The Linde Group) Gulf Cryo The Linde Group (formerly Linde AG) Messer Group MOX-Linde Gases Praxair (part of The Linde Group) Nippon Gases (part of Taiyo Nippon Sanso Corporation) Matheson Tri-Gas (part of Taiyo Nippon Sanso Corporation) Rotarex See also References External links",
                    "score": 0.8624972701072693
                },
                {
                    "id": 11140799,
                    "contents": "Nitrogen rejection unit\nA nitrogen rejection unit (NRU) selectively removes nitrogen from a gas. The name can be applied to any system that removes nitrogen from natural gas. For high flow-rate applications, typically above per day at standard pressure, cryogenic processing is the norm. This is a distillation process which utilizes the different volatilities of methane (boiling point of −161.6 °C) and nitrogen (boiling point of −195.69 °C) to achieve separation. In this process, a system of compression and distillation columns drastically reduces the temperature of the gas mixture to a point where methane is liquified and the nitrogen is not. For smaller applications, a series of heat exchangers may be used as an alternative to distillation columns.",
                    "score": 0.8613907694816589
                },
                {
                    "id": 1880754,
                    "contents": "Nitrogen dioxide\nPreparation and reactions Nitrogen dioxide typically arises via the oxidation of nitric oxide by oxygen in air: 2 NO + → 2 Nitrogen dioxide is formed in most combustion processes using air as the oxidant. At elevated temperatures nitrogen combines with oxygen to form nitric oxide: + → 2 In the laboratory, can be prepared in a two-step procedure where dehydration of nitric acid produces dinitrogen pentoxide, which subsequently undergoes thermal decomposition: 2 → + 2 → 4 + The thermal decomposition of some metal nitrates also affords : 2 → 2 PbO + 4 + Alternatively, reduction of concentrated nitric acid by metal (such as copper). 4 + Cu → + 2 + 2 Or finally by adding concentrated nitric acid over tin, hydrated stannic oxide is produced as byproduct. 4 HNO3 + Sn → H2O + H2SnO3 + 4 NO2 Main reactions Basic thermal properties exists in equilibrium with the colourless gas dinitrogen tetroxide (): 2",
                    "score": 0.8609938025474548
                },
                {
                    "id": 1128643,
                    "contents": "Nitrogen\nBecause the liquid-to-gas expansion ratio of nitrogen is 1:694 at 20 °C, a tremendous amount of force can be generated if liquid nitrogen is rapidly vaporised in an enclosed space. In an incident on January 12, 2006, at Texas A&M University, the pressure-relief devices of a tank of liquid nitrogen were malfunctioning and later sealed. As a result of the subsequent pressure buildup, the tank failed catastrophically. The force of the explosion was sufficient to propel the tank through the ceiling immediately above it, shatter a reinforced concrete beam immediately below it, and blow the walls of the laboratory 0.1–0.2 m off their foundations. Liquid nitrogen readily evaporates to form gaseous nitrogen, and hence the precautions associated with gaseous nitrogen also apply to liquid nitrogen. For example, oxygen sensors are sometimes used as a safety precaution when working with liquid nitrogen to alert workers of gas spills into a confined space.",
                    "score": 0.8608450293540955
                },
                {
                    "id": 1131521,
                    "contents": "Niobium\nThe reactivity of niobium with oxygen requires it to be worked in a vacuum or inert atmosphere, which significantly increases the cost and difficulty of production. Vacuum arc remelting (VAR) and electron beam melting (EBM), novel processes at the time, enabled the development of niobium and other reactive metals. The project that yielded C-103 began in 1959 with as many as 256 experimental niobium alloys in the \"C-series\" (possibly from columbium) that could be melted as buttons and rolled into sheet. Wah Chang had an inventory of hafnium, refined from nuclear-grade zirconium alloys, that it wanted to put to commercial use. The 103rd experimental composition of the C-series alloys, Nb-10Hf-1Ti, had the best combination of formability and high-temperature properties. Wah Chang fabricated the first 500 lb heat of C-103 in 1961, ingot to sheet, using EBM and VAR. The intended applications included turbine engines and liquid metal heat exchangers. Competing niobium alloys from that era",
                    "score": 0.8596433997154236
                },
                {
                    "id": 3751933,
                    "contents": "Liquefied natural gas\nThe key patents having to do with natural gas liquefaction were in 1915 and the mid-1930s. In 1915 Godfrey Cabot patented a method for storing liquid gases at very low temperatures. It consisted of a Thermos bottle-type design which included a cold inner tank within an outer tank; the tanks being separated by insulation. In 1937 Lee Twomey received patents for a process for large scale liquefaction of natural gas. The intention was to store natural gas as a liquid so it could be used for shaving peak energy loads during cold snaps. Because of large volumes it is not practical to store natural gas, as a gas, near atmospheric pressure. However, when liquefied, it can be stored in a volume 1/600th as large. This is a practical way to store it but the gas must be kept at .",
                    "score": 0.859615683555603
                },
                {
                    "id": 7552266,
                    "contents": "Industrial gas\nIndustrial gases are the gaseous materials that are manufactured for use in industry. The principal gases provided are nitrogen, oxygen, carbon dioxide, argon, hydrogen, helium and acetylene, although many other gases and mixtures are also available in gas cylinders. The industry producing these gases is also known as industrial gas, which is seen as also encompassing the supply of equipment and technology to produce and use the gases. Their production is a part of the wider chemical Industry (where industrial gases are often seen as \"specialty chemicals\").",
                    "score": 0.8587528467178345
                },
                {
                    "id": 3701317,
                    "contents": "Liquid air\nThe main constituents of air were liquefied for the first time by Polish scientists Karol Olszewski and Zygmunt Wróblewski in 1883. Devices for the production of liquid air are simple enough to be fabricated by the experimenter using commonly available materials. Process of manufacturing The most common process for the preparation of liquid air is the two-column Hampson–Linde cycle using the Joule–Thomson effect. Air is fed at high pressure (>) into the lower column, in which it is separated into pure nitrogen and oxygen-rich liquid. The rich liquid and some of the nitrogen are fed as reflux into the upper column, which operates at low pressure (<), where the final separation into pure nitrogen and oxygen occurs. A raw argon product can be removed from the middle of the upper column for further purification. Air can also be liquefied by Claude's process, which combines cooling by Joule–Thomson effect, isentropic expansion and regenerative cooling.",
                    "score": 0.8586798906326294
                },
                {
                    "id": 17321088,
                    "contents": "Sable Chemicals\nNitric acid making The nitric acid process produces nitric acid for use in making ammonium nitrate fertiliser. Using the Ostwald process, ammonia is vaporised and then oxidised over a 95% platinum and 5% rhodium catalyst at and to form nitric oxide and superheated steam. The reaction gases are cooled to before absorption by various heat recovery mechanisms. The cooled reaction gases are then passed through the bottom of an absorption column where a stream of air is added to oxidise nitric oxide to nitrogen dioxide. As the nitrogen dioxide passes up the column, it is absorbed by a stream of water flowing from the top of the absorption column to yield the desired product (57% nitric acid) which is then stored for downstream use.",
                    "score": 0.8583516478538513
                },
                {
                    "id": 2986201,
                    "contents": "Glovebox\nInert atmosphere work The gas in a glovebox is pumped through a series of treatment devices which remove solvents, water and oxygen from the gas. Copper metal (or some other finely divided metal) is commonly used to remove oxygen, this oxygen removing column is normally regenerated by passing a hydrogen/nitrogen mixture through it while it is heated: the water formed is passed out of the box with the excess hydrogen and nitrogen. It is common to use molecular sieves to remove water by absorbing it in the molecular sieves' pores. Such a box is often used by organometallic chemists to transfer dry solids from one container to another container.",
                    "score": 0.8583470582962036
                },
                {
                    "id": 15503261,
                    "contents": "Nitrogen generator\nDisadvantages Limited capacity Relatively low purity compared to PSA units (95% to 99% purity as compared to 99.9995% - higher purity applications are available at lower flow rates ≤ 10L/min) Applications of nitrogen generators Food and beverage industries: The moment food or beverages are produced, or fruits and vegetables harvested, an aging process kicks in until the complete decay of the products. This is caused by chemical reactions with oxygen, bacteria and other organisms. Generators are used to flood the products with N2 that displaces the oxygen and prolongs the product lifetime significantly because these organisms cannot develop. Furthermore, chemical degradation of food caused by oxidation can be eliminated or stopped. Analytical chemistry: Nitrogen generators are required for various forms of analytical chemistry such as liquid chromatography–mass spectrometry and gas chromatography where a stable and continuous supply of nitrogen is necessary.",
                    "score": 0.858035683631897
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_17",
        "question": "The chemical shift of the $\\mathrm{CH}_3$ protons in acetaldehyde (ethanal) is $\\delta=2.20$ and that of the $\\mathrm{CHO}$ proton is 9.80 . What is the difference in local magnetic field between the two regions of the molecule when the applied field is $1.5 \\mathrm{~T}$",
        "golden_answers": [
            " 11"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 5845280,
                    "contents": "Nuclear magnetic resonance spectroscopy\nFor example, in the proton spectrum for ethanol described above, the CH3 group is split into a triplet with an intensity ratio of 1:2:1 by the two neighboring CH2 protons. Similarly, the CH2 is split into a quartet with an intensity ratio of 1:3:3:1 by the three neighboring CH3 protons. In principle, the two CH2 protons would also be split again into a doublet to form a doublet of quartets by the hydroxyl proton, but intermolecular exchange of the acidic hydroxyl proton often results in a loss of coupling information.",
                    "score": 0.8706820607185364
                },
                {
                    "id": 4934239,
                    "contents": "Chemical shift\nThe protons in aromatic compounds are shifted downfield even further with a signal for benzene at 7.73 ppm as a consequence of a diamagnetic ring current. Alkyne protons by contrast resonate at high field in a 2–3 ppm range. For alkynes the most effective orientation is the external field in parallel with electrons circulation around the triple bond. In this way the acetylenic protons are located in the cone-shaped shielding zone hence the upfield shift. Magnetic properties of most common nuclei 1H and 13C are not the only nuclei susceptible to NMR experiments. A number of different nuclei can also be detected, although the use of such techniques is generally rare due to small relative sensitivities in NMR experiments (compared to 1H) of the nuclei in question, the other factor for rare use being their slender representation in nature and organic compounds.",
                    "score": 0.8661115765571594
                },
                {
                    "id": 505649,
                    "contents": "Carbonyl group\nThe polarity of C=O bond also enhances the acidity of any adjacent C-H bonds. The pKa values of acetaldehyde and acetone are 16.7 and 19 respectively, Spectroscopy Infrared spectroscopy: the C=O double bond absorbs infrared light at wavenumbers between approximately 1600–1900 cm−1(5263 nm to 6250 nm). The exact location of the absorption is well understood with respect to the geometry of the molecule. This absorption is known as the \"carbonyl stretch\" when displayed on an infrared absorption spectrum. In addition, the ultraviolet-visible spectra of propanone in water gives an absorption of carbonyl at 257 nm. Nuclear magnetic resonance: the C=O double-bond exhibits different resonances depending on surrounding atoms, generally a downfield shift. The 13C NMR of a carbonyl carbon is in the range of 160–220 ppm. See also Organic chemistry Functional group Bridging carbonyl Electrophilic addition References Further reading",
                    "score": 0.8652607202529907
                },
                {
                    "id": 7594564,
                    "contents": "Proton nuclear magnetic resonance\nSimple molecules have simple spectra. The spectrum of ethyl chloride consists of a triplet at 1.5 ppm and a quartet at 3.5 ppm in a 3:2 ratio. The spectrum of benzene consists of a single peak at 7.2 ppm due to the diamagnetic ring current. Together with carbon-13 NMR, proton NMR is a powerful tool for molecular structure characterization.",
                    "score": 0.8425199389457703
                },
                {
                    "id": 1174444,
                    "contents": "Pyridine\nthe lower electron density in the α- and γ-positions, which can be derived from the resonance structures. The situation is rather similar for the 13C NMR spectra of pyridine and benzene: pyridine shows a triplet at δ(α-C) = 150 ppm, δ(β-C) = 124 ppm and δ(γ-C) = 136 ppm, whereas benzene has a single line at 129 ppm. All shifts are quoted for the solvent-free substances. Pyridine is conventionally detected by the gas chromatography and mass spectrometry methods.",
                    "score": 0.8422179222106934
                },
                {
                    "id": 5845274,
                    "contents": "Nuclear magnetic resonance spectroscopy\nThe chemical shift provides information about the structure of the molecule. The conversion of the raw data to this information is called assigning the spectrum. For example, for the 1H-NMR spectrum for ethanol (CH3CH2OH), one would expect signals at each of three specific chemical shifts: one for the CH3 group, one for the CH2 group and one for the OH group. A typical CH3 group has a shift around 1 ppm, a CH2 attached to an OH has a shift of around 4 ppm and an OH has a shift anywhere from 2–6 ppm depending on the solvent used and the amount of hydrogen bonding. While the O atom does draw electron density away from the attached H through their mutual sigma bond, the electron lone pairs on the O bathe the H in their shielding effect. In paramagnetic NMR spectroscopy, measurements are conducted on paramagnetic samples. The paramagnetism gives rise to very diverse chemical shifts. In 1H NMR spectroscopy, the chemical shift range can span up to thousands of ppm.",
                    "score": 0.8412804007530212
                },
                {
                    "id": 26171021,
                    "contents": "C6H15NO2\n{{DISPLAYTITLE:C6H15NO2}} The molecular formula C6H15NO2 (molar mass: 133.189 g/mol, exact mass: 133.1103 u) may refer to: Aminoacetaldehyde_diethylacetal Diisopropanolamine Molecular formulas",
                    "score": 0.8362790942192078
                },
                {
                    "id": 5845275,
                    "contents": "Nuclear magnetic resonance spectroscopy\nBecause of molecular motion at room temperature, the three methyl protons average out during the NMR experiment (which typically requires a few ms). These protons become degenerate and form a peak at the same chemical shift. The shape and area of peaks are indicators of chemical structure too. In the example above—the proton spectrum of ethanol—the CH3 peak has three times the area of the OH peak. Similarly the CH2 peak would be twice the area of the OH peak but only 2/3 the area of the CH3 peak.",
                    "score": 0.8358144760131836
                },
                {
                    "id": 16459892,
                    "contents": "Nuclear magnetic resonance\nA chemist can determine the identity of a compound by comparing the observed nuclear precession frequencies to known frequencies. Further structural data can be elucidated by observing spin-spin coupling, a process by which the precession frequency of a nucleus can be influenced by the spin orientation of a chemically bonded nucleus. Spin-spin coupling is easily observed in NMR of hydrogen-1 ( NMR) since its natural abundance is nearly 100%. Because the nuclear magnetic resonance timescale is rather slow, compared to other spectroscopic methods, changing the temperature of a T2* experiment can also give information about fast reactions, such as the Cope rearrangement or about structural dynamics, such as ring-flipping in cyclohexane. At low enough temperatures, a distinction can be made between the axial and equatorial hydrogens in cyclohexane.",
                    "score": 0.8348654508590698
                },
                {
                    "id": 22302437,
                    "contents": "Gutmann–Beckett method\nThe 31P chemical shift (δ) of Et3PO is sensitive to chemical environment but can usually be found between +40 and +100 ppm. The O atom in Et3PO is a Lewis base, and its interaction with Lewis acid sites causes deshielding of the adjacent P atom. Gutmann, a chemist renowned for his work on non-aqueous solvents, described an acceptor-number scale for solvent Lewis acidity with two reference points relating to the 31P NMR chemical shift of Et3PO in the weakly Lewis acidic solvent hexane (δ = 41.0 ppm, AN 0) and in the strongly Lewis acidic solvent SbCl5 (δ = 86.1 ppm, AN 100). Acceptor numbers can be calculated from AN = 2.21 x (δsample – 41.0) and higher AN values indicate greater Lewis acidity. It is generally known that there is no one universal order of Lewis acid strengths (or Lewis base strengths) and that two parameters (or two properties) are needed (see HSAB theory and ECW model) to define acid and base strengths and that single parameter or property scales are limited to a",
                    "score": 0.8324847221374512
                },
                {
                    "id": 12124681,
                    "contents": "C5H11NO2\n{{DISPLAYTITLE:C5H11NO2}} The molecular formula C5H11NO2 may refer to: β-Alanine ethyl ester Amyl nitrite Isovaline N-Methylmorpholine N-oxide Norvaline Pentyl nitrite Trimethylglycine Valine",
                    "score": 0.832421064376831
                },
                {
                    "id": 12041779,
                    "contents": "C2H5NO\n{{DISPLAYTITLE:C2H5NO}} The molecular formula C2H5NO (molar mass: 59.07 g/mol, exact mass: 59.03711 u) may refer to: Acetaldoxime Acetamide Aminoacetaldehyde N-Methylformamide (NMF) Molecular formulas",
                    "score": 0.8311126232147217
                },
                {
                    "id": 12041780,
                    "contents": "C2H5NO2\n{{DISPLAYTITLE:C2H5NO2}} The molecular formula C2H5NO2 (molar mass: 75.07 g/mol) may refer to: Acetohydroxamic acid Ethyl nitrite Glycine Methyl carbamate Nitroethane Molecular formulas",
                    "score": 0.8306022882461548
                },
                {
                    "id": 19517339,
                    "contents": "Marjorie Constance Caserio\nShe collaborated with Roberts in writing an organic chemistry textbook, Basic Principles of Organic Chemistry, first published in 1964. Notable for its comprehensiveness and then-unusual emphasis on spectroscopy, it proved enormously influential in how the subject was taught. Also working with Roberts was chemist Fred Caserio. University of California, Irvine In 1964, Caserio was hired as the second faculty member in chemistry at the brand new University of California, Irvine. At UC Irvine she worked on addition reactions in allenes and bonding and reactions of sulfur compounds. She was one of the first scientists to employ nuclear magnetic resonance spectroscopy to study the kinetics and mechanisms of these organic reactions, and ion cyclotron resonance to study gas-phase reactions. Caserio became a full professor at UC Irvine in 1972, and chair of the chemistry department in 1987.",
                    "score": 0.8302774429321289
                },
                {
                    "id": 20936171,
                    "contents": "C9H11NO\n{{DISPLAYTITLE:C9H11NO}} The molecular formula C9H11NO (molar mass: 149.19 g/mol, exact mass: 149.0841 u) may refer to: 4'-Aminopropiophenone Cathinone para-Dimethylaminobenzaldehyde Molecular formulas",
                    "score": 0.829188346862793
                },
                {
                    "id": 23014701,
                    "contents": "Shoolery's rule\nShoolery's rule, which is named after James Nelson Shoolery, is a good approximation about Chemical shift δ of Methylene group in Nuclear magnetic resonance spectroscopy. We can calculate shift of A and B (A–CH2–B) . The increments S is calculated by empirical ways. External links Organic Spectroscopy: Principles and Applications, page 206 Nuclear magnetic resonance",
                    "score": 0.8290631175041199
                },
                {
                    "id": 11518158,
                    "contents": "Physical organic chemistry\nthe same fundamental technique. Unpaired electrons also have a net spin, and an external magnetic field allows for the extraction of similar information through electron paramagnetic resonance (EPR) spectroscopy.",
                    "score": 0.8288530707359314
                },
                {
                    "id": 4934237,
                    "contents": "Chemical shift\nFactors causing chemical shifts Important factors influencing chemical shift are electron density, electronegativity of neighboring groups and anisotropic induced magnetic field effects. Electron density shields a nucleus from the external field. For example, in proton NMR the electron-poor tropylium ion has its protons downfield at 9.17 ppm, those of the electron-rich cyclooctatetraenyl anion move upfield to 6.75 ppm and its dianion even more upfield to 5.56 ppm. A nucleus in the vicinity of an electronegative atom experiences reduced electron density and the nucleus is therefore deshielded. In proton NMR of methyl halides (CH3X) the chemical shift of the methyl protons increase in the order from 2.16 ppm to 4.26 ppm reflecting this trend. In carbon NMR the chemical shift of the carbon nuclei increase in the same order from around −10 ppm to 70 ppm. Also when the electronegative atom is removed further away the effect diminishes until it can be observed no longer.",
                    "score": 0.8288437724113464
                },
                {
                    "id": 14011778,
                    "contents": "C3H7NO2\n{{DISPLAYTITLE:C3H7NO2}} The molecular formula C3H7NO2 may refer to: Alanine beta-Alanine Ethyl carbamate Isopropyl nitrite Lactamide Nitropropanes 1-Nitropropane 2-Nitropropane Sarcosine",
                    "score": 0.8282324075698853
                },
                {
                    "id": 1867516,
                    "contents": "Methyl group\nRotation A methyl group may rotate around the R—C axis. This is a free rotation only in the simplest cases like gaseous CClH3. In most molecules, the remainder R breaks the C∞ symmetry of the R—C axis and creates a potential V(φ) that restricts the free motion of the three protons. For the model case of C2H6 this is discussed under the name ethane barrier. In condensed phases, neighbour molecules also contribute to the potential. Methyl group rotation can be experimentally studied using quasielastic neutron scattering. Etymology French chemists Jean-Baptiste Dumas and Eugene Peligot, after determining methanol's chemical structure, introduced \"methylene\" from the Greek methy \"wine\" and hȳlē \"wood, patch of trees\" with the intention of highlighting its origins, \"alcohol made from wood (substance)\". The term \"methyl\" was derived in about 1840 by back-formation from \"methylene\", and was then applied to describe \"methyl alcohol\" (which since 1892 is called \"methanol\").",
                    "score": 0.8278077244758606
                },
                {
                    "id": 3402766,
                    "contents": "Protonation\nIn chemistry, protonation (or hydronation) is the adding of a proton (or hydron, or hydrogen cation), (H+) to an atom, molecule, or ion, forming a conjugate acid. (The complementary process, when a proton is removed from a Brønsted–Lowry acid, is deprotonation.) Some examples include the protonation of water by sulfuric acid: H2SO4 + H2O H3O+ + the protonation of isobutene in the formation of a carbocation: (CH3)2C=CH2 + HBF4 (CH3)3C+ + the protonation of ammonia in the formation of ammonium chloride from ammonia and hydrogen chloride: NH3(g) + HCl(g) → NH4Cl(s)",
                    "score": 0.8277741074562073
                },
                {
                    "id": 7594574,
                    "contents": "Proton nuclear magnetic resonance\nBecause the nth row has n+1 components, this type of splitting is said to follow the \"n+1 rule\": a proton with n neighbors appears as a cluster of n+1 peaks. With 2-methylpropane, (CH3)3CH, as another example: the CH proton is attached to three identical methyl groups containing a total of 9 identical protons. The C-H signal in the spectrum would be split into ten peaks according to the (n + 1) rule of multiplicity. Below are NMR signals corresponding to several simple multiplets of this type. Note that the outer lines of the nonet (which are only 1/8 as high as those of the second peak) can barely be seen, giving a superficial resemblance to a septet.",
                    "score": 0.8272089958190918
                },
                {
                    "id": 2866380,
                    "contents": "Diethyl malonate\nThe hydrogen atoms on the carbon adjacent to the carbonyl group in a molecule is significantly more acidic than hydrogen atoms on a carbon adjacent to alkyl groups (up to 30 orders of magnitude). (This is known as the α position with respect to the carbonyl.) The hydrogen atoms on a carbon adjacent to two carbonyl groups are even more acidic because the carbonyl groups help stabilize the carbanion resulting from the removal of a proton from the methylene group between them. The extent of resonance stabilization of this compound's conjugate base is depicted by the three resonance forms below: Preparation Diethyl malonate may be prepared by reacting the sodium salt of chloroacetic acid with sodium cyanide, followed by base hydrolysis of the resultant nitrile to give the sodium salt of the malonic acid. Fischer esterification gives diethyl malonate: Reactions Malonic ester synthesis",
                    "score": 0.8267667293548584
                },
                {
                    "id": 4687682,
                    "contents": "Polarizability\nWater is a very polar molecule, but alkanes and other hydrophobic molecules are more polarizable. Water with its permanent dipole is less likely to change shape due to an external electric field. Alkanes are the most polarizable molecules. Although alkenes and arenes are expected to have larger polarizability than alkanes because of their higher reactivity compared to alkanes, alkanes are in fact more polarizable. This results because of alkene's and arene's more electronegative sp2 carbons to the alkane's less electronegative sp3 carbons. Ground state electron configuration models are often inadequate in studying the polarizability of bonds because dramatic changes in molecular structure occur in a reaction. Magnetic polarizability Magnetic polarizability defined by spin interactions of nucleons is an important parameter of deuterons and hadrons. In particular, measurement of tensor polarizabilities of nucleons yields important information about spin-dependent nuclear forces.",
                    "score": 0.82645183801651
                },
                {
                    "id": 1174443,
                    "contents": "Pyridine\nThe optical absorption spectrum of pyridine in hexane contains three bands at the wavelengths of 195 nm (π → π* transition, molar absorptivity ε = 7500 L·mol−1·cm−1), 251 nm (π → π* transition, ε = 2000 L·mol−1·cm−1) and 270 nm (n → π* transition, ε = 450 L·mol−1·cm−1). The 1H nuclear magnetic resonance (NMR) spectrum of pyridine contains three signals with the integral intensity ratio of 2:1:2 that correspond to the three chemically different protons in the molecule. These signals originate from the α-protons (positions 2 and 6, chemical shift 8.5 ppm), γ-proton (position 4, 7.5 ppm) and β-protons (positions 3 and 5, 7.1 ppm). The carbon analog of pyridine, benzene, has only one proton signal at 7.27 ppm. The larger chemical shifts of the α- and γ-protons in comparison to benzene result from the lower electron density in the α- and γ-positions, which can be derived from the resonance structures. The situation is rather similar for the 13C NMR spectra of pyridine and benzene: pyridine",
                    "score": 0.8264151811599731
                },
                {
                    "id": 6891029,
                    "contents": "Meldrum's acid\nThe ionization constant pKa is 4.97; which makes it behave as a monobasic acid even though it contains no carboxylic acid groups. In this and other properties, the compound resembles dimedone and barbituric acid. However, while dimedone exists in solution predominantly as the mono-enol tautomer, Meldrum's acid is almost entirely as the diketone form. The unusually high acidity of this compound was long considered anomalous—it is 8 orders of magnitude more acidic than the closely related compound dimethyl malonate. In 2004, Ohwada and coworkers determined that the energy-minimizing conformation structure of the compound places the alpha proton's σCH orbital in the proper geometry to align with the π*CO, so that the ground state poses unusually strong destabilization of the C-H bond. Preparation Original synthesis The compound was first made by Meldrum by a condensation reaction of acetone with malonic acid in acetic anhydride and sulfuric acid.",
                    "score": 0.8263654112815857
                },
                {
                    "id": 8052814,
                    "contents": "C2H6O\nThe molecular formula C2H6O (molar mass: 46.07 g/mol, exact mass: 46.04186 u) may refer to: Dimethyl ether (DME, or methoxymethane) Ethanol Other The name of an exhibition by Carla Arocha and Stéphane Schraenen Molecular formulas",
                    "score": 0.8259177207946777
                },
                {
                    "id": 7594567,
                    "contents": "Proton nuclear magnetic resonance\nNote that labile protons (-OH, -NH2, -SH) have no characteristic chemical shift. However, such resonances can be identified by the disappearance of a peak when reacted with D2O, as deuterium will replace a protium atom. This method is called a D2O shake. Acidic protons may also be suppressed when a solvent containing acidic deuterium ions (e.g. methanol-d4) is used. An alternate method for identifying protons that are not attached to carbons is the heteronuclear single quantum coherence (HSQC) experiment, which correlates protons and carbons that are one bond away from each other. A hydrogen that is not attached to a carbon can be identified because it does not have a crosspeak in the HSQC spectrum. Signal intensity",
                    "score": 0.8257818222045898
                },
                {
                    "id": 5590011,
                    "contents": "Acetic anhydride\nAcetic anhydride, or ethanoic anhydride, is the chemical compound with the formula (CH3CO)2O. Commonly abbreviated Ac2O, it is the simplest isolable anhydride of a carboxylic acid and is widely used as a reagent in organic synthesis. It is a colorless liquid that smells strongly of acetic acid, which is formed by its reaction with moisture in the air. Structure and properties Acetic anhydride, like most acid anhydrides, is a flexible molecule with a nonplanar structure. The pi system linkage through the central oxygen offers very weak resonance stabilization compared to the dipole-dipole repulsion between the two carbonyl oxygens. The energy barriers to bond rotation between each of the optimal aplanar conformations are quite low.",
                    "score": 0.8256797194480896
                },
                {
                    "id": 5845272,
                    "contents": "Nuclear magnetic resonance spectroscopy\npeak from an aldehyde is shifted ca. 10 ppm compared to a hydrocarbon peak, since as an electron-withdrawing group, the carbonyl deshields the proton by reducing the local electron density. The difference between 2.3487 T and 2.3488 T is therefore about 42 ppm. However a frequency scale is commonly used to designate the NMR signals, even though the spectrometer may operate by sweeping the magnetic field, and thus the 42 ppm is 4200 Hz for a 100 MHz reference frequency (rf).",
                    "score": 0.8255231380462646
                },
                {
                    "id": 8783294,
                    "contents": "Ronald Breslow\nNote that the above product can be protonated from either face with equal probability. The final acid is generated by hydrolysis of the imine. It's worth noting that the alpha keto acid is believed to be formed from a Strecker-like reaction, shown below. From figure 5, we see that the L alpha-methyl amino acids do not directly act as a chiral directing group to generate the normal L amino acid. Researchers hoped that a second molecule of the alpha-methy amino acid could act as a directing group, however they found that the D enantiomer was slightly favored when only L alpha-methyl amino acids were present. The figure below shows how the D enantiomer is favored.",
                    "score": 0.8251649141311646
                },
                {
                    "id": 16365729,
                    "contents": "C3H9NO\n{{DISPLAYTITLE:C3H9NO}} The molecular formula C3H9NO (molar mass: 75.11 g/mol, exact mass: 75.0684 u) may refer to: Alaninol 1-Amino-2-propanol 3-Amino-1-propanol N-Methylethanolamine Trimethylamine N-oxide",
                    "score": 0.8251634836196899
                },
                {
                    "id": 11242068,
                    "contents": "Timeline of chemistry\n1912Peter Debye develops the concept of molecular dipole to describe asymmetric charge distribution in some molecules. 1913Niels Bohr introduces concepts of quantum mechanics to atomic structure by proposing what is now known as the Bohr model of the atom, where electrons exist only in strictly defined orbitals. 1913Henry Moseley, working from Van den Broek's earlier idea, introduces concept of atomic number to fix inadequacies of Mendeleev's periodic table, which had been based on atomic weight. 1913Frederick Soddy proposes the concept of isotopes, that elements with the same chemical properties may have differing atomic weights. 1913J. J. Thomson expanding on the work of Wien, shows that charged subatomic particles can be separated by their mass-to-charge ratio, a technique known as mass spectrometry. 1916Gilbert N. Lewis publishes \"The Atom and the Molecule\", the foundation of valence bond theory.",
                    "score": 0.824659526348114
                },
                {
                    "id": 17841964,
                    "contents": "Acetic acid\nA common symbol for acetic acid is AcOH, where Ac is the pseudoelement symbol representing the acetyl group −C(=O)−; the conjugate base, acetate (−), is thus represented as AcO−. (The Ac is not to be confused with the symbol for the element actinium; the context prevents confusion among organic chemists). To better reflect its structure, acetic acid is often written as –C(O)OH, −C(=O)OH, COOH, and . In the context of acid–base reactions, the abbreviation HAc is sometimes used, where Ac in this case is a symbol for acetate (rather than acetyl). Acetate is the ion resulting from loss of from acetic acid. The name acetate can also refer to a salt containing this anion, or an ester of acetic acid. Properties",
                    "score": 0.8244160413742065
                },
                {
                    "id": 4934235,
                    "contents": "Chemical shift\nThe electrons around a nucleus will circulate in a magnetic field and create a secondary induced magnetic field. This field opposes the applied field as stipulated by Lenz's law and atoms with higher induced fields (i.e., higher electron density) are therefore called shielded, relative to those with lower electron density. The chemical milieu of an atom can influence its electron density through the polar effect. Electron-donating alkyl groups, for example, lead to increased shielding while electron-withdrawing substituents such as nitro groups lead to deshielding of the nucleus. Not only substituents cause local induced fields. Bonding electrons can also lead to shielding and deshielding effects. A striking example of this is the pi bonds in benzene. Circular current through the hyperconjugated system causes a shielding effect at the molecule's center and a deshielding effect at its edges. Trends in chemical shift are explained based on the degree of shielding or deshielding.",
                    "score": 0.8243968486785889
                },
                {
                    "id": 12041782,
                    "contents": "C2H6O2\nThe molecular formula C2H6O2 (molar mass: 62.07 g/mol, exact mass: 62.03678 u) may refer to: Ethylene glycol (ethane-1,2-diol) Ethyl hydroperoxide Methoxymethanol Molecular formulas",
                    "score": 0.8241860270500183
                },
                {
                    "id": 1327781,
                    "contents": "Water\nOther substances have a tetrahedral molecular structure, for example, methane () and hydrogen sulfide (). However, oxygen is more electronegative (holds on to its electrons more tightly) than most other elements, so the oxygen atom retains a negative charge while the hydrogen atoms are positively charged. Along with the bent structure, this gives the molecule an electrical dipole moment and it is classified as a polar molecule.",
                    "score": 0.8239729404449463
                },
                {
                    "id": 5606486,
                    "contents": "History of chemistry\nIn 1909, S. P. L. Sørensen invented the pH concept and developed methods for measuring acidity. In 1911, Antonius Van den Broek proposed the idea that the elements on the periodic table are more properly organized by positive nuclear charge rather than atomic weight. In 1911, the first Solvay Conference was held in Brussels, bringing together most of the most prominent scientists of the day. In 1912, William Henry Bragg and William Lawrence Bragg proposed Bragg's law and established the field of X-ray crystallography, an important tool for elucidating the crystal structure of substances. In 1912, Peter Debye used the concept of a molecular dipole to describe asymmetric charge distribution in some molecules. Niels Bohr",
                    "score": 0.8238891363143921
                },
                {
                    "id": 4517444,
                    "contents": "Conrotatory and disrotatory\nIn contrast, if a conrotation had been performed then one white lobe would overlap with one black lobe. This would have caused destructive interference and no new carbon-carbon bond would have been formed. In addition, the cis/trans geometry of the product can also be determined. When the p-orbitals were rotated inwards it also caused the two methyl groups to rotate upwards. Since both methyls are pointing \"up\", then the product is cis-dimethylcyclohexadiene. References Carey, Francis A.; Sundberg, Richard J.; (1984). Advanced Organic Chemistry Part A Structure and Mechanisms (2nd ed.). New York N.Y.: Plenum Press. . March Jerry; (1985). Advanced Organic Chemistry reactions, mechanisms and structure (3rd ed.). New York: John Wiley & Sons, inc. Physical organic chemistry",
                    "score": 0.8232183456420898
                },
                {
                    "id": 28962772,
                    "contents": "Aminoacetaldehyde diethylacetal\nAminoacetaldehyde diethylacetal is the organic compound with the formula (EtO)2CHCH2NH2. A colorless liquid, it is used as a surrogate for aminoacetaldehyde. See also Aminoaldehydes and aminoketones References Amines Acetals",
                    "score": 0.8232118487358093
                },
                {
                    "id": 7594572,
                    "contents": "Proton nuclear magnetic resonance\nIn consequence the CH peak at 2.5 ppm will be split twice by each proton from the CH2. The first proton will split the peak into two equal intensities and will go from one peak at 2.5 ppm to two peaks, one at 2.5 ppm + 3.5 Hz and the other at 2.5 ppm - 3.5 Hz—each having equal intensities. However these will be split again by the second proton. The frequencies will change accordingly: The 2.5 ppm + 3.5 Hz signal will be split into 2.5 ppm + 7 Hz and 2.5 ppm The 2.5 ppm - 3.5 Hz signal will be split into 2.5 ppm and 2.5 ppm - 7 Hz The net result is not a signal consisting of 4 peaks but three: one signal at 7 Hz above 2.5 ppm, two signals occur at 2.5 ppm, and a final one at 7 Hz below 2.5 ppm. The ratio of height between them is 1:2:1. This is known as a triplet and is an indicator that the proton is three-bonds from a CH2 group.",
                    "score": 0.8231217861175537
                },
                {
                    "id": 12112709,
                    "contents": "C4H6O3\n{{DISPLAYTITLE:C4H6O3}} The molecular formula C4H6O3 may refer to: Acetic anhydride Acetoacetic acid Dioxanones p-Dioxanone Trimethylene carbonate trans-4-Hydroxycrotonic acid α-Ketobutyric acid 2-Methyl-3-oxopropanoic acid Methyl pyruvate Propylene carbonate Succinic semialdehyde",
                    "score": 0.8230806589126587
                },
                {
                    "id": 9271133,
                    "contents": "Frank Westheimer\nFrank Henry Westheimer (January 15, 1912 – April 14, 2007) was an American chemist. He taught at the University of Chicago from 1936 to 1954, and at Harvard University from 1953 to 1983, becoming the Morris Loeb Professor of Chemistry in 1960, and Professor Emeritus in 1983. The Westheimer medal was established in his honor in 2002. Westheimer did pioneering work in physical organic chemistry, applying techniques from physical to organic chemistry and integrating the two fields. He explored the mechanisms of chemical and enzymatic reactions, and made fundamental theoretical advances. Westheimer worked with John Gamble Kirkwood on the Bjerrum electrostatic analysis of carboxylic acids; with Joseph Edward Mayer on the calculation of molecular mechanics; explored the mechanisms of enzyme catalysis with Birgit Vennesland and determined the mechanisms of chromic acid oxidations and kinetic isotope effects.",
                    "score": 0.823067307472229
                },
                {
                    "id": 6754773,
                    "contents": "Magic acid\nThe bridging methylene carbon atom is pentacoordinated, with three two-electron, two-center bonds, and one two-electron, three-center bond with its remaining sp3 orbital. Quantum mechanical calculations have also shown that the classical model is not an energy minimum. Reactions with alkanes Magic acid is capable of protonating alkanes. For instance, methane reacts to form the ion at 140 °C and atmospheric pressure, though some hydrocarbon ions of greater molecular weights are also formed as byproducts. Hydrogen gas is another reaction byproduct.",
                    "score": 0.8229942321777344
                },
                {
                    "id": 16092828,
                    "contents": "Deuterated solvent\nDeuterated solvents are a group of compounds where one or more hydrogen atoms are substituted by deuterium atoms. These compounds are often used in Nuclear magnetic resonance spectroscopy. Examples Heavy water Deuterated acetone Deuterated benzene Deuterated chloroform Deuterated dichloromethane Deuterated DMF Deuterated DMSO Deuterated ethanol Deuterated methanol Deuterated THF References",
                    "score": 0.8227440118789673
                },
                {
                    "id": 4934225,
                    "contents": "Chemical shift\nSome atomic nuclei possess a magnetic moment (nuclear spin), which gives rise to different energy levels and resonance frequencies in a magnetic field. The total magnetic field experienced by a nucleus includes local magnetic fields induced by currents of electrons in the molecular orbitals (note that electrons have a magnetic moment themselves). The electron distribution of the same type of nucleus (e.g. 1H, 13C, 15N) usually varies according to the local geometry (binding partners, bond lengths, angles between bonds, and so on), and with it the local magnetic field at each nucleus. This is reflected in the spin energy levels (and resonance frequencies). The variations of nuclear magnetic resonance frequencies of the same kind of nucleus, due to variations in the electron distribution, is called the chemical shift. The size of the chemical shift is given with respect to a reference frequency or reference sample (see also chemical shift referencing), usually a molecule with a barely",
                    "score": 0.8225736021995544
                },
                {
                    "id": 14659033,
                    "contents": "C11H13NO\n{{DISPLAYTITLE:C11H13NO}} The molecular formula C11H13NO (molar mass: 175.22 g/mol, exact mass: 175.099714 u) may refer to: 5-APB 6-APB (6-(2-aminopropyl)benzofuran) p-Dimethylaminocinnamaldehyde (DMACA) Molecular formulas",
                    "score": 0.8224771618843079
                },
                {
                    "id": 14478480,
                    "contents": "C6H13NO2\n{{DISPLAYTITLE:C6H13NO2}} The molecular formula C6H13NO2 (molar mass: 131.17 g/mol, exact mass: 131.0946 u) may refer to: Aminocaproic acid Isoleucine Leucine β-Leucine Norleucine Molecular formulas",
                    "score": 0.8223698735237122
                },
                {
                    "id": 11518143,
                    "contents": "Physical organic chemistry\nthe compound is more acidic, while a negative value indicates that the substituted version is less acidic. The ρ value is a measure of the sensitivity of the reaction to the change in substituent, but only measures inductive effects. Therefore, two new scales were produced that evaluate the stabilization of localized charge through resonance. One is σ+, which concerns substituents that stabilize positive charges via resonance, and the other is σ− which is for groups that stabilize negative charges via resonance. Hammett analysis can be used to help elucidate the possible mechanisms of a reaction. For example, if it is predicted that the transition state structure has a build-up of negative charge relative to the ground state structure, then electron-donating groups would be expected to increase the rate of the reaction.",
                    "score": 0.8222671747207642
                },
                {
                    "id": 15882565,
                    "contents": "C9H11NO2\n{{DISPLAYTITLE:C9H11NO2}} The molecular formula C9H11NO2 (molar mass: 165.18 g/mol, exact mass: 165.078979) may refer to: Benzocaine Ethenzamide Methylenedioxyphenethylamine Metolcarb Norsalsolinol 3,4-Methylenedioxy-N-methylbenzylamine, closely related to isosafrole. Phenylalanine References",
                    "score": 0.8220537900924683
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_18",
        "question": "Suppose that the junction between two semiconductors can be represented by a barrier of height $2.0 \\mathrm{eV}$ and length $100 \\mathrm{pm}$. Calculate the transmission probability of an electron with energy $1.5 \\mathrm{eV}$.",
        "golden_answers": [
            " 0.8"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 13106000,
                    "contents": "Metal–semiconductor junction\nThe critical parameter: Schottky barrier height Whether a given metal-semiconductor junction is an ohmic contact or a Schottky barrier depends on the Schottky barrier height, ΦB, of the junction. For a sufficiently large Schottky barrier height, where ΦB is significantly higher than the thermal energy kT, the semiconductor is depleted near the metal and behaves as a Schottky barrier. For lower Schottky barrier heights, the semiconductor is not depleted and instead forms an ohmic contact to the metal. The Schottky barrier height is defined differently for n-type and p-type semiconductors (being measured from the conduction band edge and valence band edge, respectively). The alignment of the semiconductor's bands near the junction is typically independent of the semiconductor's doping level, so the n-type and p-type Schottky barrier heights are ideally related to each other by: where Eg is the semiconductor's band gap.",
                    "score": 0.9094806909561157
                },
                {
                    "id": 13106001,
                    "contents": "Metal–semiconductor junction\nwhere Eg is the semiconductor's band gap. In practice, the Schottky barrier height is not precisely constant across the interface, and varies over the interfacial surface. Schottky–Mott rule and Fermi level pinning The Schottky–Mott rule of Schottky barrier formation predicts the Schottky barrier height based on the vacuum work function of the metal relative to the vacuum electron affinity (or vacuum ionization energy) of the semiconductor: This model is derived based on the thought experiment of bringing together the two materials in vacuum, and is closely related in logic to Anderson's rule for semiconductor-semiconductor junctions. Different semiconductors respect the Schottky–Mott rule to varying degrees.",
                    "score": 0.9083539247512817
                },
                {
                    "id": 13106002,
                    "contents": "Metal–semiconductor junction\nAlthough the Schottky–Mott model correctly predicted the existence of band bending in the semiconductor, it was found experimentally that it would give grossly incorrect predictions for the height of the Schottky barrier. A phenomenon referred to as \"Fermi level pinning\" caused some point of the band gap, at which finite DOS exists, to be locked (pinned) to the Fermi level. This made the Schottky barrier height almost completely insensitive to the metal's work function: where Ebandgap is the size of band gap in the semiconductor. In fact, empirically, it is found that neither of the above extremes is quite correct. The choice of metal does have some effect, and there appears to be a weak correlation between the metal work function and the barrier height, however the influence of the work function is only a fraction of that predicted by the Schottky-Mott rule.",
                    "score": 0.9044061899185181
                },
                {
                    "id": 13106003,
                    "contents": "Metal–semiconductor junction\nIt was noted in 1947 by John Bardeen that the Fermi level pinning phenomenon would naturally arise if there were chargeable states in the semiconductor right at the interface, with energies inside the semiconductor's gap. These would either be induced during the direct chemical bonding of the metal and semiconductor (metal-induced gap states) or be already present in the semiconductor–vacuum surface (surface states). These highly dense surface states would be able to absorb a large quantity of charge donated from the metal, effectively shielding the semiconductor from the details of the metal. As a result, the semiconductor's bands would necessarily align to a location relative to the surface states which are in turn pinned to the Fermi level (due to their high density), all without influence from the metal.",
                    "score": 0.8938148617744446
                },
                {
                    "id": 3372363,
                    "contents": "Schottky barrier\nTo a first approximation, the barrier between a metal and a semiconductor is predicted by the Schottky–Mott rule to be proportional to the difference of the metal-vacuum work function and the semiconductor-vacuum electron affinity. For an isolated metal, the work function is defined as the difference between its vacuum energy (i.e. the minimum energy that an electron must possess to completely free itself from the material) and the Fermi energy , and it is an invariant property of the specified metal: On the other hand, the work function of a semiconductor is defined as: Where is the electron affinity (i.e. the difference between the vacuum energy and the energy level of the conduction band). It is valuable to describe the work function of the semiconductor in terms of its electron affinity since this last one is an invariant fundamental property of the semiconductor, while the difference between the conduction band and the Fermi energy depends on the doping.",
                    "score": 0.8928278684616089
                },
                {
                    "id": 13106008,
                    "contents": "Metal–semiconductor junction\nThe first theory that predicted the correct direction of rectification of the metal–semiconductor junction was given by Nevill Mott in 1939. He found the solution for both the diffusion and drift currents of the majority carriers through the semiconductor surface space charge layer which has been known since about 1948 as the Mott barrier. Walter H. Schottky and Spenke extended Mott's theory by including a donor ion whose density is spatially constant through the semiconductor surface layer. This changed the constant electric field assumed by Mott to a linearly decaying electric field. This semiconductor space-charge layer under the metal is known as the Schottky barrier. A similar theory was also proposed by Davydov in 1939. Although it gives the correct direction of rectification, it has also been proven that the Mott theory and its Schottky-Davydov extension gives the wrong current limiting mechanism and wrong current-voltage formulae in silicon metal/semiconductor diode",
                    "score": 0.8922542333602905
                },
                {
                    "id": 13105999,
                    "contents": "Metal–semiconductor junction\nIn solid-state physics, a metal–semiconductor (M–S) junction is a type of electrical junction in which a metal comes in close contact with a semiconductor material. It is the oldest practical semiconductor device. M–S junctions can either be rectifying or non-rectifying. The rectifying metal–semiconductor junction forms a Schottky barrier, making a device known as a Schottky diode, while the non-rectifying junction is called an ohmic contact. (In contrast, a rectifying semiconductor–semiconductor junction, the most common semiconductor device today, is known as a p–n junction.) Metal–semiconductor junctions are crucial to the operation of all semiconductor devices. Usually an ohmic contact is desired, so that electrical charge can be conducted easily between the active region of a transistor and the external circuitry. Occasionally however a Schottky barrier is useful, as in Schottky diodes, Schottky transistors, and metal–semiconductor field effect transistors.",
                    "score": 0.8894685506820679
                },
                {
                    "id": 3372362,
                    "contents": "Schottky barrier\nPhysics of formation When a metal is put in direct contact with a semiconductor, a so called Schottky barrier can be formed, leading to a rectifying behavior of the electrical contact. This happens both when the semiconductor is n-type and its work function is smaller than the work function of the metal, and when the semiconductor is p-type and the opposite relation between work functions holds. At the basis of the description of the Schottky barrier formation through the band diagram formalism, there are three main assumptions: The contact between the metal and the semiconductor must be intimate and without the presence of any other material layer (such as an oxide). No interdiffusion of the metal and the semiconductor is taken into account. There are no impurities at the interface between the two materials.",
                    "score": 0.8856810927391052
                },
                {
                    "id": 3372365,
                    "contents": "Schottky barrier\nIn reality, what can happen is that charged interface states can pin the Fermi level at a certain energy value no matter the work function values, influencing the barrier height for both carriers. This is due to the fact that the chemical termination of the semiconductor crystal against a metal creates electron states within its band gap. The nature of these metal-induced gap states and their occupation by electrons tends to pin the center of the band gap to the Fermi level, an effect known as Fermi level pinning. Thus the heights of the Schottky barriers in metal–semiconductor contacts often show little dependence on the value of the semiconductor or metal work functions, in strong contrast to the Schottky–Mott rule. Different semiconductors exhibit this Fermi level pinning to different degrees, but a technological consequence is that ohmic contacts are usually difficult to form in important semiconductors such as silicon and gallium arsenide. Non-ohmic contacts present a parasitic",
                    "score": 0.8814283609390259
                },
                {
                    "id": 1925055,
                    "contents": "Walter H. Schottky\nLater, in the context of semiconductor devices, it was suggested that a similar barrier should exist at the junction of a metal and a semiconductor. Such barriers are now widely known as Schottky barriers, and considerations apply to the transfer of electrons across them that are analogous to the older considerations of how electrons are emitted from a metal into vacuum. (Basically, several emission regimes exist, for different combinations of field and temperature. The different regimes are governed by different approximate formulae.) When the whole behaviour of such interfaces is examined, it is found that they can act (asymmetrically) as a special form of electronic diode, now called a Schottky diode. In this context, the metal–semiconductor junction is known as a \"Schottky (rectifying) contact'\".",
                    "score": 0.8809792995452881
                },
                {
                    "id": 3372364,
                    "contents": "Schottky barrier\nWhen the two isolated materials are put into intimate contact, the equalization of the Fermi levels brings to the movement of charge from one material to the other, depending on the values of the work functions. This leads to the creation of an energy barrier, since at the interface between the materials some charge get collected. For electrons, the barrier height can be easily calculated as the difference between the metal work function and the electron affinity of the semiconductor: While the barrier height for holes is equal to the difference between the energy gap of the semiconductor and the energy barrier for electrons:",
                    "score": 0.8807373046875
                },
                {
                    "id": 2870029,
                    "contents": "P–n junction\nNon-rectifying junctions In the above diagrams, contact between the metal wires and the semiconductor material also creates metal–semiconductor junctions called Schottky diodes. In a simplified ideal situation a semiconductor diode would never function, since it would be composed of several diodes connected back-to-front in series. But, in practice, surface impurities within the part of the semiconductor that touches the metal terminals greatly reduces the width of those depletion layers, to such an extent that the metal-semiconductor junctions do not act as diodes. These non-rectifying junctions behave as ohmic contacts regardless of applied voltage polarity.",
                    "score": 0.880302369594574
                },
                {
                    "id": 3372371,
                    "contents": "Schottky barrier\nIntroducing a second semiconductor/metal interface and a gate stack overlapping both junctions, one can obtain a Schottky barrier field effect transistor (SB-FET). The gate steers the carrier injection inside the channel modulating the band bending at the interface, and thus the resistance of the Schottky barriers. Generally the most significantly resistive path for the current is represented by the Schottky barriers, and so the channel itself does not contribute significantly to the conduction when the transistor is turned on. This kind of device has an ambipolar behavior since when a positive voltage is applied to both junctions, their band diagram is bent downwards enabling an electron current from source to drain (the presence of a voltage is always implied) due to direct tunneling. In the opposite case of a negative voltage applied to both junctions the band diagram is bent upwards and holes can be injected and flow from the drain to the source. Setting the gate voltage to 0 V",
                    "score": 0.8753576874732971
                },
                {
                    "id": 8448389,
                    "contents": "Ohmic contact\nThe Schottky barrier height between a metal and semiconductor is naively predicted by the Schottky–Mott rule to be proportional to the difference of the metal-vacuum work function and the semiconductor-vacuum electron affinity. In practice, most metal–semiconductor interfaces do not follow this rule to the predicted degree. Instead, the chemical termination of the semiconductor crystal against a metal creates electron states within its band gap. The nature of these metal-induced gap states and their occupation by electrons tends to pin the center of the band gap to the Fermi level, an effect known as Fermi level pinning. Thus, the heights of the Schottky barriers in metal–semiconductor contacts often show little dependence on the value of the semiconductor or metal work functions, in stark contrast to the Schottky–Mott rule. Different semiconductors exhibit this Fermi level pinning to different degrees, but a technological consequence is that high quality (low resistance) ohmic",
                    "score": 0.8747406601905823
                },
                {
                    "id": 3279686,
                    "contents": "Heterojunction\nTersoff proposed a gap state model based on more familiar metal–semiconductor junctions where the conduction band offset is given by the difference in Schottky barrier height. This model includes a dipole layer at the interface between the two semiconductors which arises from electron tunneling from the conduction band of one material into the gap of the other (analogous to metal-induced gap states). This model agrees well with systems where both materials are closely lattice matched such as GaAs/AlGaAs. The 60:40 rule is a heuristic for the specific case of junctions between the semiconductor GaAs and the alloy semiconductor AlxGa1−xAs. As the x in the AlxGa1−xAs side is varied from 0 to 1, the ratio tends to maintain the value 60/40. For comparison, Anderson's rule predicts for a GaAs/AlAs junction (x=1).",
                    "score": 0.8738768696784973
                },
                {
                    "id": 3372361,
                    "contents": "Schottky barrier\nA Schottky barrier, named after Walter H. Schottky, is a potential energy barrier for electrons formed at a metal–semiconductor junction. Schottky barriers have rectifying characteristics, suitable for use as a diode. One of the primary characteristics of a Schottky barrier is the Schottky barrier height, denoted by ΦB (see figure). The value of ΦB depends on the combination of metal and semiconductor. Not all metal–semiconductor junctions form a rectifying Schottky barrier; a metal–semiconductor junction that conducts current in both directions without rectification, perhaps due to its Schottky barrier being too low, is called an ohmic contact. Physics of formation",
                    "score": 0.871366560459137
                },
                {
                    "id": 5784958,
                    "contents": "Depletion region\nIn semiconductor physics, the depletion region, also called depletion layer, depletion zone, junction region, space charge region or space charge layer, is an insulating region within a conductive, doped semiconductor material where the mobile charge carriers have been diffused away, or have been forced away by an electric field. The only elements left in the depletion region are ionized donor or acceptor impurities. This region of uncovered positive and negative ions is called the depletion region due to the depletion of carriers in this region. The depletion region is so named because it is formed from a conducting region by removal of all free charge carriers, leaving none to carry a current. Understanding the depletion region is key to explaining modern semiconductor electronics: diodes, bipolar junction transistors, field-effect transistors, and variable capacitance diodes all rely on depletion region phenomena. Formation in a p–n junction",
                    "score": 0.8683227300643921
                },
                {
                    "id": 2870010,
                    "contents": "P–n junction\nA p–n junction is a boundary or interface between two types of semiconductor materials, p-type and n-type, inside a single crystal of semiconductor. The \"p\" (positive) side contains an excess of holes, while the \"n\" (negative) side contains an excess of electrons in the outer shells of the electrically neutral atoms there. This allows electrical current to pass through the junction only in one direction. The p-n junction is created by doping, for example by ion implantation, diffusion of dopants, or by epitaxy (growing a layer of crystal doped with one type of dopant on top of a layer of crystal doped with another type of dopant). If two separate pieces of material were used, this would introduce a grain boundary between the semiconductors that would severely inhibit its utility by scattering the electrons and holes.",
                    "score": 0.8666903376579285
                },
                {
                    "id": 13106013,
                    "contents": "Metal–semiconductor junction\nSee also Schottky barrier References Further reading Semiconductor structures",
                    "score": 0.8650465607643127
                },
                {
                    "id": 3372374,
                    "contents": "Schottky barrier\nA bipolar junction transistor with a Schottky barrier between the base and the collector is known as a Schottky transistor. Because the junction voltage of the Schottky barrier is small, the transistor is prevented from saturating too deeply, which improves the speed when used as a switch. This is the basis for the Schottky and Advanced Schottky TTL families, as well as their low power variants. A MESFET or metal–semiconductor FET uses a reverse-biased Schottky barrier to provide a depletion region that pinches off a conducting channel buried inside the semiconductor (similar to the JFET where instead a p–n junction provides the depletion region). A variant of this device is the high-electron-mobility transistor (HEMT), which also utilizes a heterojunction to provide a device with extremely high conductance.",
                    "score": 0.8649410605430603
                },
                {
                    "id": 3372368,
                    "contents": "Schottky barrier\nUnder forward bias, there are many thermally excited electrons in the semiconductor that are able to pass over the barrier. The passage of these electrons over the barrier (without any electrons coming back) corresponds to a current in the opposite direction. The current rises very rapidly with bias, however at high biases the series resistance of the semiconductor can start to limit the current. Under reverse bias, there is a small leakage current as some thermally excited electrons in the metal have enough energy to surmount the barrier. To first approximation this current should be constant (as in the Shockley diode equation); however, current rises gradually with reverse bias due to a weak barrier lowering (similar to the vacuum Schottky effect). At very high biases, the depletion region breaks down. Note: the discussion above is for a Schottky barrier to an n-type semiconductor; similar considerations apply for a p-type semiconductor.",
                    "score": 0.8643143177032471
                },
                {
                    "id": 10340982,
                    "contents": "Surface-barrier transistor\nThe surface-barrier transistor is a type of transistor developed by Philco in 1953 as an improvement to the alloy-junction transistor and the earlier point-contact transistor. Like the modern Schottky transistor, it offered much higher speed than earlier transistors and used metal–semiconductor junctions (instead of semiconductor–semiconductor junctions), but unlike the schottky transistor, both junctions were metal–semiconductor junctions.",
                    "score": 0.8629984259605408
                },
                {
                    "id": 6176060,
                    "contents": "Coulomb blockade\nAn arrangement of two conductors with an insulating layer in between not only has a resistance, but also a finite capacitance. The insulator is also called dielectric in this context, the tunnel junction behaves as a capacitor. Due to the discreteness of electrical charge, current through a tunnel junction is a series of events in which exactly one electron passes (tunnels) through the tunnel barrier (we neglect cotunneling, in which two electrons tunnel simultaneously). The tunnel junction capacitor is charged with one elementary charge by the tunnelling electron, causing a voltage build up , where is the capacitance of the junction. If the capacitance is very small, the voltage build up can be large enough to prevent another electron from tunnelling. The electric current is then suppressed at low bias voltages and the resistance of the device is no longer constant. The increase of the differential resistance around zero bias is called the Coulomb blockade. Observation",
                    "score": 0.8621641397476196
                },
                {
                    "id": 3372366,
                    "contents": "Schottky barrier\ndegrees, but a technological consequence is that ohmic contacts are usually difficult to form in important semiconductors such as silicon and gallium arsenide. Non-ohmic contacts present a parasitic resistance to current flow that consumes energy and lowers device performance.",
                    "score": 0.8614684343338013
                },
                {
                    "id": 13106004,
                    "contents": "Metal–semiconductor junction\nThe Fermi level pinning effect is strong in many commercially important semiconductors (Si, Ge, GaAs), and thus can be problematic for the design of semiconductor devices. For example, nearly all metals form a significant Schottky barrier to n-type germanium and an ohmic contact to p-type germanium, since the valence band edge is strongly pinned to the metal's Fermi level. The solution to this inflexibility requires additional processing steps such as adding an intermediate insulating layer to unpin the bands. (In the case of germanium, germanium nitride has been used) History",
                    "score": 0.8602594137191772
                },
                {
                    "id": 3372372,
                    "contents": "Schottky barrier\nIn the opposite case of a negative voltage applied to both junctions the band diagram is bent upwards and holes can be injected and flow from the drain to the source. Setting the gate voltage to 0 V suppresses the tunneling current and enables only a lower current due to thermionic events. One of the main limitations of such a device is strongly related to the presence of this current that makes it difficult to properly switch it off. A clear advantage of such a device is that there is no need for channel doping and expensive technological steps like ion implantation and high temperature annealings can be avoided, keeping the thermal budget low. However the band bending due to the voltage difference between drain and gate often injects enough carriers to make impossible a proper switch off of the device. Also, low on-currents due to the intrinsic resistance of the Schottky contacts are typical of this kind of device just like a very hard and unreliable scalability due to the difficult",
                    "score": 0.8600800037384033
                },
                {
                    "id": 10930267,
                    "contents": "Band diagram\nAt the junction of a semiconductor and metal, the bands of the semiconductor are pinned to the metal's Fermi level. At the junction of a conductor and vacuum, the vacuum level (from vacuum electrostatic potential) is set by the material's work function and Fermi level. This also (usually) applies for the junction of a conductor to an insulator.",
                    "score": 0.8594966530799866
                },
                {
                    "id": 9242957,
                    "contents": "Anderson's rule\nAnderson's rule is used for the construction of energy band diagrams of the heterojunction between two semiconductor materials. Anderson's rule states that when constructing an energy band diagram, the vacuum levels of the two semiconductors on either side of the heterojunction should be aligned (at the same energy). It is also referred to as the electron affinity rule, and is closely related to the Schottky–Mott rule for metal–semiconductor junctions. Anderson's rule was first described by R. L. Anderson in 1960. Constructing energy band diagrams",
                    "score": 0.8587889075279236
                },
                {
                    "id": 3372369,
                    "contents": "Schottky barrier\nNote: the discussion above is for a Schottky barrier to an n-type semiconductor; similar considerations apply for a p-type semiconductor. The current-voltage relationship is qualitatively the same as with a p-n junction, however the physical process is somewhat different. Conduction values The thermionic emission can be formulated as following: While the tunneling current density can be expressed, for a triangular shaped barrier (considering WKB approximation) as: From both formulae it is clear that the current contributions are related to the barrier height for both electrons and holes. If a symmetric current profile for both n and p carriers is then needed, the barrier height must be ideally identical for electrons and holes.",
                    "score": 0.858662486076355
                },
                {
                    "id": 8448387,
                    "contents": "Ohmic contact\nStable contacts at semiconductor interfaces, with low contact resistance and linear I-V behavior, are critical for the performance and reliability of semiconductor devices, and their preparation and characterization are major efforts in circuit fabrication. Poorly prepared junctions to semiconductors can easily show rectifying behaviour by causing depletion of the semiconductor near the junction, rendering the device useless by blocking the flow of charge between those devices and the external circuitry. Ohmic contacts to semiconductors are typically constructed by depositing thin metal films of a carefully chosen composition, possibly followed by annealing to alter the semiconductor–metal bond. Physics of formation of metal–semiconductor ohmic contacts",
                    "score": 0.855869472026825
                },
                {
                    "id": 13106010,
                    "contents": "Metal–semiconductor junction\nIf a metal-semiconductor junction is formed by placing a droplet of mercury, as Braun did, onto a semiconductor, e.g.silicon, to form a Schottky barrier in a Schottky diode electrical setup – electrowetting can be observed, where the droplet spreads out with increasing voltage. Depending on the doping type and density in the semiconductor, the droplet spreading depends on the magnitude and sign of the voltage applied to the mercury droplet. This effect has been termed ‘Schottky electrowetting’, effectively linking electrowetting and semiconductor effects.",
                    "score": 0.8542608618736267
                },
                {
                    "id": 13106005,
                    "contents": "Metal–semiconductor junction\nHistory The rectification property of metal–semiconductor contacts was discovered by Ferdinand Braun in 1874 using mercury metal contacted with copper sulfide and iron sulfide semiconductors. Sir Jagadish Chandra Bose applied for a US patent for a metal-semiconductor diode in 1901. This patent was awarded in 1904. G.W. Pickard received a patent in 1906 on a point-contact rectifier using silicon. In 1907, George W. Pierce published a paper in Physical Review showing rectification properties of diodes made by sputtering many metals on many semiconductors. The use of the metal–semiconductor diode rectifier was proposed by Lilienfeld in 1926 in the first of his three transistor patents as the gate of the metal–semiconductor field effect transistors. The theory of the field-effect transistor using a metal/semiconductor gate was advanced by William Shockley in 1939.",
                    "score": 0.8534401059150696
                },
                {
                    "id": 1674453,
                    "contents": "Diode\nCurrent–voltage characteristic A semiconductor diode's behavior in a circuit is given by its current–voltage characteristic, or I–V graph (see graph below). The shape of the curve is determined by the transport of charge carriers through the so-called depletion layer or depletion region that exists at the p–n junction between differing semiconductors. When a p–n junction is first created, conduction-band (mobile) electrons from the N-doped region diffuse into the P-doped region where there is a large population of holes (vacant places for electrons) with which the electrons \"recombine\". When a mobile electron recombines with a hole, both hole and electron vanish, leaving behind an immobile positively charged donor (dopant) on the N side and negatively charged acceptor (dopant) on the P side. The region around the p–n junction becomes depleted of charge carriers and thus behaves as an insulator.",
                    "score": 0.852876603603363
                },
                {
                    "id": 8448388,
                    "contents": "Ohmic contact\nPhysics of formation of metal–semiconductor ohmic contacts Both ohmic contacts and Schottky barriers are dependent on the Schottky barrier height, which sets the threshold for the excess energy an electron requires to pass from the semiconductor to the metal. For the junction to admit electrons easily in both directions (ohmic contact), the barrier height must be small in at least some parts of the junction surface. To form an excellent ohmic contact (low resistance), the barrier height should be small everywhere and furthermore the interface should not reflect electrons.",
                    "score": 0.8518581390380859
                },
                {
                    "id": 894907,
                    "contents": "Semiconductor device\nShockley was incensed, and decided to demonstrate who was the real brains of the operation. A few months later he invented an entirely new, considerably more robust, type of transistor with a layer or 'sandwich' structure. This structure went on to be used for the vast majority of all transistors into the 1960s, and evolved into the bipolar junction transistor.",
                    "score": 0.8512288928031921
                },
                {
                    "id": 25932097,
                    "contents": "Mott–Schottky plot\nIn liquid junction the reference of potential is normally a standard reference electrode. In solid junctions, we can take as a reference the metal Fermi level, if the work function is known, which provides a full energy diagram in the physical scale. The Mott–Schottky plot is sensitive to the electrode surface in contact with solution, see Figure 2. A more accurate analysis considering the statistics of electrons provides the following result for the size of the depletion region (5) in this case the Mott–Schottky equation is (6) When the interfacial barrier is of the order , special care has to be taken to interpret the capacitance measurement. In fact at these small voltages the capacitance makes a peak that can be used for the determination of the built-in voltage. The Mott–Schottky analysis can more generally resolve a variable doping profile in the semiconductor as follows (7)",
                    "score": 0.850744366645813
                },
                {
                    "id": 18559842,
                    "contents": "Electrical junction\nAn electrical junction is a point or area where multiple conductors or semiconductors make physical contact. Electrical junctions types include thermoelectricity junctions, metal–semiconductor junctions and p–n junctions. Junctions are either rectifying or non-rectifying. Non-rectifying junctions are called ohmic contacts. Electronic components employing rectifying junctions include p–n diodes, Schottky diodes and bipolar junction transistors. (Electrical outlets ) See also Break junction Depletion region, also called junction region Junction voltage Heterojunction Homojunction Josephson junction Nodal analysis p–n junction isolation Electricity Semiconductor structures",
                    "score": 0.8507440090179443
                },
                {
                    "id": 13106011,
                    "contents": "Metal–semiconductor junction\nThe MOSFET (metal-oxide-semiconductor field-effect transistor) was invented by Mohamed Atalla and Dawon Kahng at Bell Labs in 1959, and presented in 1960. They extended their work on MOS technology to do pioneering work on hot carrier devices, which used what would later be called a Schottky barrier. The Schottky diode, also known as the Schottky-barrier diode, was theorized for years, but was first practically realized as a result of the work of Atalla and Kahng during 19601961. They published their results in 1962 and called their device the \"hot electron\" triode structure with semiconductor-metal emitter. It was one of the first metal-base transistors. Atalla continued research on Schottky diodes with Robert J. Archer at HP Associates. They developed high vacuum metal film deposition technology, and fabricated stable evaporated/sputtered contacts, publishing their results in January 1963. Their work was a breakthrough in metal–semiconductor junction and Schottky barrier research,",
                    "score": 0.8506545424461365
                },
                {
                    "id": 11742123,
                    "contents": "Band offset\nAnderson's rule states that when we construct the heterojunction, we need to have both semiconductors on an equal vacuum energy level. This ensures that the energy bands of both the semiconductors are being held to the same reference point, from which ΔEc and ΔEv, the conduction band offset and valence band offset can be calculated. By having the same reference point for both semiconductors, ΔEc becomes equal to the built-in potential, Vbi = Φ1 - Φ2, and the behaviour of the bands at the interface can be predicted as can be seen at the picture above.",
                    "score": 0.8504716157913208
                },
                {
                    "id": 1237877,
                    "contents": "Semiconductor\nA pure semiconductor, however, is not very useful, as it is neither a very good insulator nor a very good conductor. However, one important feature of semiconductors (and some insulators, known as semi-insulators) is that their conductivity can be increased and controlled by doping with impurities and gating with electric fields. Doping and gating move either the conduction or valence band much closer to the Fermi level and greatly increase the number of partially filled states.",
                    "score": 0.8500198721885681
                },
                {
                    "id": 12677987,
                    "contents": "Tunnel junction\nIn electronics/spintronics, a tunnel junction is a barrier, such as a thin insulating layer or electric potential, between two electrically conducting materials. Electrons (or quasiparticles) pass through the barrier by the process of quantum tunnelling. Classically, the electron has zero probability of passing through the barrier. However, according to quantum mechanics, the electron has a non-zero wave amplitude in the barrier, and hence it has some probability of passing through the barrier. Tunnel junctions serve a variety of different purposes. Multijunction photovoltaic cell In multijunction photovoltaic cells, tunnel junctions form the connections between consecutive p-n junctions. They function as an ohmic electrical contact in the middle of a semiconductor device. Magnetic tunnel junction In magnetic tunnel junctions, electrons tunnel through a thin insulating barrier from one magnetic material to another. This can serve as a basis for a magnetic detector.",
                    "score": 0.8494775295257568
                },
                {
                    "id": 9242960,
                    "contents": "Anderson's rule\nLimitations of Anderson's rule In real semiconductor heterojunctions, Anderson's rule fails to predict actual band offsets. In Anderson's idealized model the materials are assumed to behave as they would in the limit of a large vacuum separation, yet where the vacuum separation is taken to zero. It is that assumption that involves the use of the vacuum electron affinity parameter, even in a solidly filled junction where there is no vacuum. Much like with the Schottky–Mott rule, Anderson's rule ignores the real chemical bonding effects that occur with a small or nonexistent vacuum separation: interface states which may have a very large electrical polarization and defect states, dislocations and other perturbations caused by imperfect crystal lattice matches.",
                    "score": 0.8493955731391907
                },
                {
                    "id": 3279694,
                    "contents": "Heterojunction\nSee also Homojunction, p–n junction—a junction involving two types of the same semiconductor. Metal–semiconductor junction—a junction of a metal to a semiconductor. References Further reading , . A somewhat dated reference respect to applications, but always a good introduction to basic principles of heterojunction devices. Semiconductor structures",
                    "score": 0.84935462474823
                },
                {
                    "id": 25932095,
                    "contents": "Mott–Schottky plot\nIn semiconductor electrochemistry, a Mott–Schottky plot describes the reciprocal of the square of capacitance versus the potential difference between bulk semiconductor and bulk electrolyte. In many theories, and in many experimental measurements, the plot is linear. The use of Mott–Schottky plots to determine system properties (such as flatband potential, doping density or Helmholtz capacitance) is termed Mott–Schottky analysis. Consider the semiconductor/electrolyte junction shown in Figure 1. Under applied bias voltage the size of the depletion layer is (1) Here is the permittivity, is the elementary charge, is the doping density, is the built-in potential. The depletion region contains positive charge compensated by ionic negative charge at the semiconductor surface (in the liquid electrolyte side). Charge separation forms a dielectric capacitor at the interface of the metal/semiconductor contact. We calculate the capacitance for an electrode area as (2)",
                    "score": 0.8491636514663696
                },
                {
                    "id": 3812451,
                    "contents": "Contact electrification\nSemiconductor contact If a metal touches a semiconductor material, or if two different semiconductors are placed into contact, one becomes charged slightly positive and the other slightly negative. It is found that if this junction between semiconductors is connected to a power supply, and if the power supply is set to a voltage slightly higher than the natural voltage appearing because of contact electrification, then for one polarity of voltage there will be a current between the two semiconductor parts, but if the polarity is reversed, the current stops. Thus contact between materials lead to the invention of the semiconductor diode or rectifier and triggered the revolution in semiconductor electronics and physics.",
                    "score": 0.8487883806228638
                },
                {
                    "id": 13562232,
                    "contents": "Metal-induced gap states\n, where is the spin orbit splitting of at the point. is the indirect conduction band minimum. Metal–semiconductor contact point barrier height In order for the Fermi levels to match at the interface, there must be charge transfer between the metal and semiconductor. The amount of charge transfer was formulated by Linus Pauling and later revised to be: where and are the electronegativities of the metal and semiconductor, respectively. The charge transfer produces a dipole at the interface and thus a potential barrier called the Schottky barrier height. In the same derivation of the branching point mentioned above, Tersoff derives the barrier height to be: where is a parameter adjustable for the specific metal, dependent mostly on its electronegativity, . Tersoff showed that the experimentally measured fits his theoretical model for Au in contact with 10 common semiconductors, including Si, Ge, GaP, and GaAs.",
                    "score": 0.848760724067688
                },
                {
                    "id": 16782081,
                    "contents": "Superconducting tunnel junction\nThe superconducting tunnel junction (STJ) — also known as a superconductor–insulator–superconductor tunnel junction (SIS) — is an electronic device consisting of two superconductors separated by a very thin layer of insulating material. Current passes through the junction via the process of quantum tunneling. The STJ is a type of Josephson junction, though not all the properties of the STJ are described by the Josephson effect. These devices have a wide range of applications, including high-sensitivity detectors of electromagnetic radiation, magnetometers, high speed digital circuit elements, and quantum computing circuits. Quantum tunneling",
                    "score": 0.8485835790634155
                },
                {
                    "id": 2870027,
                    "contents": "P–n junction\nAnd thus, letting be the total width of the depletion region, we get can be written as , where we have broken up the voltage difference into the equilibrium plus external components. The equilibrium potential results from diffusion forces, and thus we can calculate by implementing the Einstein relation and assuming the semiconductor is nondegenerate (i.e., the product is independent of the Fermi energy): where T is the temperature of the semiconductor and k is Boltzmann constant. Current across depletion region",
                    "score": 0.8477487564086914
                },
                {
                    "id": 19841628,
                    "contents": "Man Singh Tyagi\nBooks Tyagi wrote one internationally acclaimed book Introduction to Semiconductor Materials and Devices, which is widely used in Electrical Engineering, semiconductor devices and material science undergraduate and postgraduate courses. It was published by John Wiley & Sons on 7 March 1991. M. S. Tyagi: Introduction to Semiconductor Materials and Devices. John Wiley & Sons. 311–320 (1991). Physics of Schottky Barrier Junction (first chapter in book Metal-semiconductor Schottky barrier junctions and their applications by B. L. Sharma, PlenumPress, New York (1984)) Publications He has contributed the first chapter in Metal-semiconductor Schottky barrier junctions and their applications, Plenum Press New York 1984. Professional membership Tyagi is a life fellow of IETE, Semiconductor society of India and Indian Society for Technical Education. References",
                    "score": 0.8477166891098022
                },
                {
                    "id": 14597558,
                    "contents": "Leakage (electronics)\nIn semiconductors In semiconductor devices, leakage is a quantum phenomenon where mobile charge carriers (electrons or holes) tunnel through an insulating region. Leakage increases exponentially as the thickness of the insulating region decreases. Tunneling leakage can also occur across semiconductor junctions between heavily doped P-type and N-type semiconductors. Other than tunneling via the gate insulator or junctions, carriers can also leak between source and drain terminals of a Metal Oxide Semiconductor (MOS) transistor. This is called subthreshold conduction. The primary source of leakage occurs inside transistors, but electrons can also leak between interconnects. Leakage increases power consumption and if sufficiently large can cause complete circuit failure.",
                    "score": 0.8474969863891602
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_19",
        "question": "The diffusion coefficient of a particular kind of t-RNA molecule is $D=1.0 \\times 10^{-11} \\mathrm{~m}^2 \\mathrm{~s}^{-1}$ in the medium of a cell interior. How long does it take molecules produced in the cell nucleus to reach the walls of the cell at a distance $1.0 \\mu \\mathrm{m}$, corresponding to the radius of the cell?",
        "golden_answers": [
            " 1.7"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1729354,
                    "contents": "Fick's laws of diffusion\nIn the ultrashort time limit, in the order of the diffusion time a2/D, where a is the particle radius, the diffusion is described by the Langevin equation. At a longer time, the Langevin equation merges into the Stokes–Einstein equation. The latter is appropriate for the condition of the diluted solution, where long-range diffusion is considered. According to the fluctuation-dissipation theorem based on the Langevin equation in the long-time limit and when the particle is significantly denser than the surrounding fluid, the time-dependent diffusion constant is: where kB is Boltzmann's constant. T is the absolute temperature. μ is the mobility of the particle in the fluid or gas, which can be calculated using the Einstein relation (kinetic theory). m is the mass of the particle. t is time. For a single molecule such as organic molecules or biomolecules (e.g. proteins) in water, the exponential term is negligible due to the small product of mμ in the picosecond region.",
                    "score": 0.8855437636375427
                },
                {
                    "id": 13491929,
                    "contents": "Diffusion-controlled reaction\nDerivation The following derivation is adapted from Foundations of Chemical Kinetics. This derivation assumes the reaction . Consider a sphere of radius , centered at a spherical molecule A, with reactant B flowing in and out of it. A reaction is considered to occur if molecules A and B touch, that is, when the distance between the two molecules is apart. If we assume a local steady state, then the rate at which B reaches is the limiting factor and balances the reaction. Therefore, the steady state condition becomes 1. where is the flux of B, as given by Fick's law of diffusion, 2. , where is the diffusion coefficient and can be obtained by the Stokes-Einstein equation, and the second term is the gradient of the chemical potential with respect to position. Note that [B] refers to the average concentration of B in the solution, while [B](r) is the \"local concentration\" of B at position r. Inserting 2 into 1 results in 3..",
                    "score": 0.8744468688964844
                },
                {
                    "id": 1681286,
                    "contents": "Molecular diffusion\nThe diffusion coefficients for these two types of diffusion are generally different because the diffusion coefficient for chemical diffusion is binary and it includes the effects due to the correlation of the movement of the different diffusing species. Non-equilibrium system Because chemical diffusion is a net transport process, the system in which it takes place is not an equilibrium system (i.e. it is not at rest yet). Many results in classical thermodynamics are not easily applied to non-equilibrium systems. However, there sometimes occur so-called quasi-steady states, where the diffusion process does not change in time, where classical results may locally apply. As the name suggests, this process is a not a true equilibrium since the system is still evolving.",
                    "score": 0.8728775978088379
                },
                {
                    "id": 1681288,
                    "contents": "Molecular diffusion\nConcentration dependent \"collective\" diffusion Collective diffusion is the diffusion of a large number of particles, most often within a solvent. Contrary to brownian motion, which is the diffusion of a single particle, interactions between particles may have to be considered, unless the particles form an ideal mix with their solvent (ideal mix conditions correspond to the case where the interactions between the solvent and particles are identical to the interactions between particles and the interactions between solvent molecules; in this case, the particles do not interact when inside the solvent).",
                    "score": 0.8714736104011536
                },
                {
                    "id": 29586146,
                    "contents": "Single-particle trajectory\nFor a Brownian motion, , where D is the diffusion coefficient, n is dimension of the space. Some other properties can also be recovered from long trajectories, such as the radius of confinement for a confined motion. The MSD has been widely used in early applications of long but not necessarily redundant single-particle trajectories in a biological context. However, the MSD applied to long trajectories suffers from several issues. First, it is not precise in part because the measured points could be correlated. Second, it cannot be used to compute any physical diffusion coefficient when trajectories consists of switching episodes for example alternating between free and confined diffusion. At low spatiotemporal resolution of the observed trajectories, the MSD behaves sublinearly with time, a process known as anomalous diffusion, which is due in part to the averaging of the different phases of the particle motion. In the context of cellular transport (ameoboid), high resolution",
                    "score": 0.8707201480865479
                },
                {
                    "id": 1681292,
                    "contents": "Molecular diffusion\n(only applicable for no bulk motion) where D is the diffusivity of A through B, proportional to the average molecular velocity and, therefore dependent on the temperature and pressure of gases. The rate of diffusion NA, is usually expressed as the number of moles diffusing across unit area in unit time. As with the basic equation of heat transfer, this indicates that the rate of force is directly proportional to the driving force, which is the concentration gradient. This basic equation applies to a number of situations. Restricting discussion exclusively to steady state conditions, in which neither dCA/dx or dCB/dx change with time, equimolecular counterdiffusion is considered first. Equimolecular counterdiffusion",
                    "score": 0.870497465133667
                },
                {
                    "id": 17839239,
                    "contents": "Diffusion\nwhere kB is the Boltzmann constant, T is the temperature, P is the pressure, is the mean free path, and vT is the mean thermal speed: We can see that the diffusion coefficient in the mean free path approximation grows with T as T3/2 and decreases with P as 1/P. If we use for P the ideal gas law P = RnT with the total concentration n, then we can see that for given concentration n the diffusion coefficient grows with T as T1/2 and for given temperature it decreases with the total concentration as 1/n. For two different gases, A and B, with molecular masses mA, mB and molecular diameters dA, dB, the mean free path estimate of the diffusion coefficient of A in B and B in A is:",
                    "score": 0.8698427081108093
                },
                {
                    "id": 1729344,
                    "contents": "Fick's laws of diffusion\nAs a quick approximation of the error function, the first two terms of the Taylor series can be used: If is time-dependent, the diffusion length becomes This idea is useful for estimating a diffusion length over a heating and cooling cycle, where varies with temperature. Example solution 2: Brownian particle and Mean squared displacement Another simple case of diffusion is the Brownian motion of one particle. The particle's Mean squared displacement from its original position is: where is the dimension of the particle's Brownian motion. For example, the diffusion of a molecule across a cell membrane 8 nm thick is 1-D diffusion because of the spherical symmetry; However, the diffusion of a molecule from the membrane to the center of a eukaryotic cell is a 3-D diffusion. For a cylindrical cactus, the diffusion from photosynthetic cells on its surface to its center (the axis of its cylindrical symmetry) is a 2-D diffusion.",
                    "score": 0.8654446601867676
                },
                {
                    "id": 1681278,
                    "contents": "Molecular diffusion\nMolecular diffusion, often simply called diffusion, is the thermal motion of all (liquid or gas) particles at temperatures above absolute zero. The rate of this movement is a function of temperature, viscosity of the fluid and the size (mass) of the particles. Diffusion explains the net flux of molecules from a region of higher concentration to one of lower concentration. Once the concentrations are equal the molecules continue to move, but since there is no concentration gradient the process of molecular diffusion has ceased and is instead governed by the process of self-diffusion, originating from the random motion of the molecules. The result of diffusion is a gradual mixing of material such that the distribution of molecules is uniform. Since the molecules are still in motion, but an equilibrium has been established, the result of molecular diffusion is called a \"dynamic equilibrium\". In a phase with uniform temperature, absent external net forces acting on the particles, the",
                    "score": 0.8633331060409546
                },
                {
                    "id": 17839215,
                    "contents": "Diffusion\nFrom the atomistic point of view, diffusion is considered as a result of the random walk of the diffusing particles. In molecular diffusion, the moving molecules are self-propelled by thermal energy. Random walk of small particles in suspension in a fluid was discovered in 1827 by Robert Brown, who found that minute particle suspended in a liquid medium and just large enough to be visible under an optical microscope exhibit a rapid and continually irregular motion of particles known as Brownian movement. The theory of the Brownian motion and the atomistic backgrounds of diffusion were developed by Albert Einstein. The concept of diffusion is typically applied to any subject matter involving random walks in ensembles of individuals.",
                    "score": 0.8626489639282227
                },
                {
                    "id": 17839233,
                    "contents": "Diffusion\nwhere x is the position. μ is the mobility of the particle in the fluid or gas, which can be calculated using the Einstein relation (kinetic theory). m is the mass of the particle. F is the random force applied to the particle. t is time. Solving this equation, one obtained the time-dependent diffusion constant in the long-time limit and when the particle is significantly denser than the surrounding fluid, where kB is Boltzmann's constant; T is the absolute temperature. μ is the mobility of the particle in the fluid or gas, which can be calculated using the Einstein relation (kinetic theory). m is the mass of the particle. t is time. Teorell formula for multicomponent diffusion The Teorell formula with combination of Onsager's definition of the diffusion force gives",
                    "score": 0.8614883422851562
                },
                {
                    "id": 17839230,
                    "contents": "Diffusion\nwhere D is the diffusion constant, μ is the \"mobility\", kB is Boltzmann's constant, T is the absolute temperature, and q is the elementary charge, that is, the charge of one electron. Below, to combine in the same formula the chemical potential μ and the mobility, we use for mobility the notation . The mobility-based approach was further applied by T. Teorell. In 1935, he studied the diffusion of ions through a membrane. He formulated the essence of his approach in the formula: the flux is equal to mobility × concentration × force per gram-ion. This is the so-called Teorell formula. The term \"gram-ion\" (\"gram-particle\") is used for a quantity of a substance that contains Avogadro's number of ions (particles). The common modern term is mole.",
                    "score": 0.8613905310630798
                },
                {
                    "id": 1729355,
                    "contents": "Fick's laws of diffusion\nWhen the area of interest is the size of a molecule (specifically, a long cylindrical molecule such as DNA), the adsorption rate equation represents the collision frequency of two molecules in a diluted solution, with one molecule a specific side and the other no steric dependence, i.e., a molecule (random orientation) hit one side of the other. The diffusion constant need to be updated to the relative diffusion constant between two diffusing molecules. This estimation is especially useful in studying the interaction between a small molecule and a larger molecule such as a protein. The effective diffusion constant is dominated by the smaller one whose diffusion constant can be used instead.",
                    "score": 0.8604958653450012
                },
                {
                    "id": 12048809,
                    "contents": "Itô diffusion\nwhere the partition function Z is given by Moreover, the density ρ∞ satisfies a variational principle: it minimizes over all probability densities ρ on Rn the free energy functional F given by where plays the role of an energy functional, and is the negative of the Gibbs-Boltzmann entropy functional. Even when the potential Ψ is not well-behaved enough for the partition function Z and the Gibbs measure μ∞ to be defined, the free energy F[ρ(t, ·)] still makes sense for each time t ≥ 0, provided that the initial condition has F[ρ(0, ·)] < +∞. The free energy functional F is, in fact, a Lyapunov function for the Fokker–Planck equation: F[ρ(t, ·)] must decrease as t increases. Thus, F is an H-function for the X-dynamics. Example Consider the Ornstein-Uhlenbeck process X on Rn satisfying the stochastic differential equation where m ∈ Rn and β, κ > 0 are given constants. In this case, the potential Ψ is given by",
                    "score": 0.8604417443275452
                },
                {
                    "id": 17839217,
                    "contents": "Diffusion\nBiologists often use the terms \"net movement\" or \"net diffusion\" to describe the movement of ions or molecules by diffusion. For example, oxygen can diffuse through cell membranes so long as there is a higher concentration of oxygen outside the cell. However, because the movement of molecules is random, occasionally oxygen molecules move out of the cell (against the concentration gradient). Because there are more oxygen molecules outside the cell, the probability that oxygen molecules will enter the cell is higher than the probability that oxygen molecules will leave the cell. Therefore, the \"net\" movement of oxygen molecules (the difference between the number of molecules either entering or leaving the cell) is into the cell. In other words, there is a net movement of oxygen molecules down the concentration gradient.",
                    "score": 0.8597521781921387
                },
                {
                    "id": 11163423,
                    "contents": "Anomalous diffusion\nAnomalous diffusion is a diffusion process with a non-linear relationship between the mean squared displacement (MSD), , and time. This behavior is in stark contrast to Brownian motion, the typical diffusion process described by Einstein and Smoluchowski, where the MSD is a linear in time (namely, with d being the number of dimensions and D the diffusion coefficient). Examples of anomalous diffusion in nature have been observed in biology in the cell nucleus, plasma membrane and cytoplasm. Unlike typical diffusion, anomalous diffusion is described by a power law, where is the so-called generalized diffusion coefficient and is the elapsed time. In Brownian motion, α = 1. If α > 1, the process is superdiffusive. Superdiffusion can be the result of active cellular transport processes or due to jumps with a heavy-tail distribution. If α < 1, the particle undergoes subdiffusion.",
                    "score": 0.8586691617965698
                },
                {
                    "id": 3232481,
                    "contents": "Diffusion equation\nwhere j is the flux of the diffusing material. The diffusion equation can be obtained easily from this when combined with the phenomenological Fick's first law, which states that the flux of the diffusing material in any part of the system is proportional to the local density gradient: If drift must be taken into account, the Smoluchowski equation provides an appropriate generalization. Discretization The diffusion equation is continuous in both space and time. One may discretize space, time, or both space and time, which arise in application. Discretizing time alone just corresponds to taking time slices of the continuous system, and no new phenomena arise. In discretizing space alone, the Green's function becomes the discrete Gaussian kernel, rather than the continuous Gaussian kernel. In discretizing both time and space, one obtains the random walk.",
                    "score": 0.8585735559463501
                },
                {
                    "id": 24969175,
                    "contents": "Continuous-time random walk\nIn mathematics, a continuous-time random walk (CTRW) is a generalization of a random walk where the wandering particle waits for a random time between jumps. It is a stochastic jump process with arbitrary distributions of jump lengths and waiting times. More generally it can be seen to be a special case of a Markov renewal process. Motivation CTRW was introduced by Montroll and Weiss as a generalization of physical diffusion process to effectively describe anomalous diffusion, i.e., the super- and sub-diffusive cases. An equivalent formulation of the CTRW is given by generalized master equations. A connection between CTRWs and diffusion equations with fractional time derivatives has been established. Similarly, time-space fractional diffusion equations can be considered as CTRWs with continuously distributed jumps or continuum approximations of CTRWs on lattices. Formulation A simple formulation of a CTRW is to consider the stochastic process defined by",
                    "score": 0.8582027554512024
                },
                {
                    "id": 12158929,
                    "contents": "Self-diffusion\nAccording to IUPAC definition, self-diffusion coefficient is the diffusion coefficient of species when the chemical potential gradient equals zero. It is linked to the diffusion coefficient by the equation: Here, is the activity of the species in the solution and is the concentration of . This term is commonly assumed to be equal to the tracer diffusion determined by watching the movement of an isotope in the material of interest. See also Brownian motion Diffusion Molecular diffusion References Diffusion",
                    "score": 0.8581897020339966
                },
                {
                    "id": 1681285,
                    "contents": "Molecular diffusion\nChemical diffusion occurs in a presence of concentration (or chemical potential) gradient and it results in net transport of mass. This is the process described by the diffusion equation. This diffusion is always a non-equilibrium process, increases the system entropy, and brings the system closer to equilibrium.",
                    "score": 0.8579838871955872
                },
                {
                    "id": 1681279,
                    "contents": "Molecular diffusion\nan equilibrium has been established, the result of molecular diffusion is called a \"dynamic equilibrium\". In a phase with uniform temperature, absent external net forces acting on the particles, the diffusion process will eventually result in complete mixing.",
                    "score": 0.8576843738555908
                },
                {
                    "id": 13262033,
                    "contents": "List of scientific publications by Albert Einstein\nIn 1905, Einstein proposed the existence of the photon, an elementary particle associated with electromagnetic radiation (light), which was the foundation of quantum theory. In 1909, Einstein showed that the photon carries momentum as well as energy and that electromagnetic radiation must have both particle-like and wave-like properties if Planck's law holds; this was a forerunner of the principle of wave–particle duality. He would go on to receive the 1921 Nobel Prize in Physics for this work. In 1905, Einstein developed a theory of Brownian motion in terms of fluctuations in the number of molecular collisions with an object, providing further evidence that matter was composed of atoms. A few weeks earlier, he had derived the Einstein relation for diffusion, which was the first example of the general fluctuation-dissipation theorem and allowed a good estimate of the Avogadro constant.",
                    "score": 0.856303870677948
                },
                {
                    "id": 17839214,
                    "contents": "Diffusion\nThere are two ways to introduce the notion of diffusion: either a phenomenological approach starting with Fick's laws of diffusion and their mathematical consequences, or a physical and atomistic one, by considering the random walk of the diffusing particles. In the phenomenological approach, diffusion is the movement of a substance from a region of high concentration to a region of low concentration without bulk motion. According to Fick's laws, the diffusion flux is proportional to the negative gradient of concentrations. It goes from regions of higher concentration to regions of lower concentration. Sometime later, various generalizations of Fick's laws were developed in the frame of thermodynamics and non-equilibrium thermodynamics.",
                    "score": 0.8562456369400024
                },
                {
                    "id": 1681282,
                    "contents": "Molecular diffusion\nFundamentally, two types of diffusion are distinguished:",
                    "score": 0.856177568435669
                },
                {
                    "id": 12048810,
                    "contents": "Itô diffusion\nExample Consider the Ornstein-Uhlenbeck process X on Rn satisfying the stochastic differential equation where m ∈ Rn and β, κ > 0 are given constants. In this case, the potential Ψ is given by and so the invariant measure for X is a Gaussian measure with density ρ∞ given by . Heuristically, for large t, Xt is approximately normally distributed with mean m and variance (βκ)−1. The expression for the variance may be interpreted as follows: large values of κ mean that the potential well Ψ has \"very steep sides\", so Xt is unlikely to move far from the minimum of Ψ at m; similarly, large values of β mean that the system is quite \"cold\" with little noise, so, again, Xt is unlikely to move far away from m. The martingale property In general, an Itô diffusion X is not a martingale. However, for any f ∈ C2(Rn; R) with compact support, the process M : [0, +∞) × Ω → R defined by",
                    "score": 0.8560250997543335
                },
                {
                    "id": 12048813,
                    "contents": "Itô diffusion\nIn general, if G is compactly embedded within Rn, then the harmonic measure (or hitting distribution) of X on the boundary ∂G of G is the measure μGx defined by for x ∈ G and F ⊆ ∂G. Returning to the earlier example of Brownian motion, one can show that if B is a Brownian motion in Rn starting at x ∈ Rn and D ⊂ Rn is an open ball centred on x, then the harmonic measure of B on ∂D is invariant under all rotations of D about x and coincides with the normalized surface measure on ∂D. The harmonic measure satisfies an interesting mean value property: if f : Rn → R is any bounded, Borel-measurable function and φ is given by then, for all Borel sets G ⊂⊂ H and all x ∈ G, The mean value property is very useful in the solution of partial differential equations using stochastic processes. The Green measure and Green formula",
                    "score": 0.8556193709373474
                },
                {
                    "id": 1612807,
                    "contents": "Brownian motion\nAn identical expression to Einstein's formula for the diffusion coefficient was also found by Walther Nernst in 1888 in which he expressed the diffusion coefficient as the ratio of the osmotic pressure to the ratio of the frictional force and the velocity to which it gives rise. The former was equated to the law of van 't Hoff while the latter was given by Stokes's law. He writes for the diffusion coefficient k, where is the osmotic pressure and k is the ratio of the frictional force to the molecular viscosity which he assumes is given by Stokes's formula for the viscosity. Introducing the ideal gas law per unit volume for the osmotic pressure, the formula becomes identical to that of Einstein's. The use of Stokes's law in Nernst's case, as well as in Einstein and Smoluchowski, is not strictly applicable since it does not apply to the case where the radius of the sphere is small in comparison with the mean free path.",
                    "score": 0.8549667596817017
                },
                {
                    "id": 1612801,
                    "contents": "Brownian motion\nThe second part of Einstein's theory relates the diffusion constant to physically measurable quantities, such as the mean squared displacement of a particle in a given time interval. This result enables the experimental determination of Avogadro's number and therefore the size of molecules. Einstein analyzed a dynamic equilibrium being established between opposing forces. The beauty of his argument is that the final result does not depend upon which forces are involved in setting up the dynamic equilibrium. In his original treatment, Einstein considered an osmotic pressure experiment, but the same conclusion can be reached in other ways.",
                    "score": 0.8547452092170715
                },
                {
                    "id": 1863747,
                    "contents": "Molecular nanotechnology\nDrexler and others extended the ideas of molecular nanotechnology with several other books. Unbounding the Future: the Nanotechnology Revolution and . Unbounding the Future is an easy-to-read book that introduces the ideas of molecular nanotechnology in a not-too-technical way. Other notable works in the same vein are Nanomedicine Vol. I and Vol. IIA by Robert Freitas and Kinematic Self-Replicating Machines by Robert Freitas and Ralph Merkle. Nanotechnology: Molecular Speculations on Global Abundance Edited by BC Crandall () offers interesting ideas for MNT applications.",
                    "score": 0.8539208173751831
                },
                {
                    "id": 1681281,
                    "contents": "Molecular diffusion\nSignificance Diffusion is part of the transport phenomena. Of mass transport mechanisms, molecular diffusion is known as a slower one. Biology In cell biology, diffusion is a main form of transport for necessary materials such as amino acids within cells. Diffusion of solvents, such as water, through a semipermeable membrane is classified as osmosis. Metabolism and respiration rely in part upon diffusion in addition to bulk or active processes. For example, in the alveoli of mammalian lungs, due to differences in partial pressures across the alveolar-capillary membrane, oxygen diffuses into the blood and carbon dioxide diffuses out. Lungs contain a large surface area to facilitate this gas exchange process. Tracer, self- and chemical diffusion",
                    "score": 0.8530016541481018
                },
                {
                    "id": 6630341,
                    "contents": "Bohm diffusion\nApproximate derivation Generally diffusion can be modeled as a random walk of steps of length and time . If the diffusion is collisional, then is the mean free path and is the inverse of the collision frequency. The diffusion coefficient D can be expressed variously as where is the velocity between collisions.",
                    "score": 0.852445125579834
                },
                {
                    "id": 6852146,
                    "contents": "What Is Life?\nWhat Is Life? The Physical Aspect of the Living Cell is a 1944 science book written for the lay reader by physicist Erwin Schrödinger. The book was based on a course of public lectures delivered by Schrödinger in February 1943, under the auspices of the Dublin Institute for Advanced Studies where he was Director of Theoretical Physics, at Trinity College, Dublin. The lectures attracted an audience of about 400, who were warned \"that the subject-matter was a difficult one and that the lectures could not be termed popular, even though the physicist’s most dreaded weapon, mathematical deduction, would hardly be utilized.\" Schrödinger's lecture focused on one important question: \"how can the events in space and time which take place within the spatial boundary of a living organism be accounted for by physics and chemistry?\"",
                    "score": 0.8521341681480408
                },
                {
                    "id": 8243521,
                    "contents": "Persistence length\nFor the case of a single molecule of DNA the persistence length can be measured using optical tweezers and atomic force microscopy.",
                    "score": 0.8520939946174622
                },
                {
                    "id": 9882662,
                    "contents": "Knudsen diffusion\nwhere and is the flux of component i. For cases where α = 0 (, i.e. countercurrent diffusion) or where is close to zero, the equation reduces to Knudsen self diffusion In the Knudsen diffusion regime, the molecules do not interact with one another, so that they move in straight lines between points on the pore channel surface. Self-diffusivity is a measure of the translational mobility of individual molecules. Under conditions of thermodynamic equilibrium, a molecule is tagged and its trajectory followed over a long time. If the motion is diffusive, and in a medium without long-range correlations, the squared displacement of the molecule from its original position will eventually grow linearly with time (Einstein’s equation). To reduce statistical errors in simulations, the self-diffusivity, , of a species is defined from ensemble averaging Einstein’s equation over a large enough number of molecules N. See also Knudsen flow Knudsen equation Atomic diffusion Mass diffusivity",
                    "score": 0.8515102863311768
                },
                {
                    "id": 1962883,
                    "contents": "Michaelis–Menten kinetics\nwhere is known as the Michaelis constant. Assumptions and limitations The first step in the derivation applies the law of mass action, which is reliant on free diffusion. However, in the environment of a living cell where there is a high concentration of proteins, the cytoplasm often behaves more like a viscous gel than a free-flowing liquid, limiting molecular movements by diffusion and altering reaction rates. Although the law of mass action can be valid in heterogeneous environments, it is more appropriate to model the cytoplasm as a fractal, in order to capture its limited-mobility kinetics.",
                    "score": 0.8514660596847534
                },
                {
                    "id": 13491930,
                    "contents": "Diffusion-controlled reaction\nInserting 2 into 1 results in 3.. It is convenient at this point to use the identity allowing us to rewrite 3 as 4. . Rearranging 4 allows us to write 5. Using the boundary conditions that , ie the local concentration of B approaches that of the solution at large distances, and consequently , as , we can solve 5 by separation of variables, we get 6. or 7. (where : ) For the reaction between A and B, there is an inherent reaction constant , so . Substitutiing this into 7 and rearranging yields 8. Limiting conditions Very fast intrinsic reaction Suppose is very large compared to the diffusion process, so A and B react immediately. This is the classic diffusion limited reaction, and the corresponding diffusion limited rate constant, can be obtained from 8 as . 8 can then be re-written as the \"diffusion influenced rate constant\" as 9.",
                    "score": 0.8514084815979004
                },
                {
                    "id": 28935257,
                    "contents": "Redundancy principle (biology)\nMathematical formulation: Computing the rate of arrival time for the fastest The mathematical analysis of large numbers of molecules, which are obviously redundant in the traditional activation theory, is used to compute the in vivo time scale of stochastic chemical reactions. The computation relies on asymptotics or probabilistic approaches to estimate the mean time of the fastest to reach a small target in various geometries. With N non-interacting i.i.d. Brownian trajectories (ions) in a bounded domain Ω that bind at a site, the shortest arrival time is by definition where are the independent arrival times of the N ions in the medium. The survival distribution of arrival time of the fastest is expressed in terms of a single particle, . Here is the survival probability of a single particle prior to binding at the target.This probability is computed from the solution of the diffusion equation in a domain :",
                    "score": 0.8513965606689453
                },
                {
                    "id": 17839243,
                    "contents": "Diffusion\ndescribes thermodiffusion, the diffusion flux caused by the temperature gradient.",
                    "score": 0.8512876033782959
                },
                {
                    "id": 17839246,
                    "contents": "Diffusion\nHere, is the diffusion coefficient matrix, is the thermal diffusion coefficient, is the body force per unit mass acting on the ith species, is the partial pressure fraction of the ith species (and is the partial pressure), is the mass fraction of the ith species, and Diffusion of electrons in solids When the density of electrons in solids is not in equilibrium, diffusion of electrons occurs. For example, when a bias is applied to two ends of a chunk of semiconductor, or a light shines on one end (see right figure), electrons diffuse from high density regions (center) to low density regions (two ends), forming a gradient of electron density. This process generates current, referred to as diffusion current. Diffusion current can also be described by Fick's first law where J is the diffusion current density (amount of substance) per unit area per unit time, n (for ideal mixtures) is the electron density, x is the position [length].",
                    "score": 0.8512340784072876
                },
                {
                    "id": 10250611,
                    "contents": "Diffuson\nThe diffuson is a mathematical object, which often appears in the theory of disordered electronic systems (a part of condensed matter physics). In a disordered system, the motion of an electron is not ballistic, but diffusive: i.e., the electron does not move along a straight line, but experiences a series of random scatterings off of impurities. This random motion (diffusion) is described by a differential equation, known as the diffusion equation. The diffuson is the Green's function of the diffusion equation. The diffuson plays an important role in the theory of electron transport in disordered systems, especially for phase coherent effects such as universal conductance fluctuations. Diffusion Mesoscopic physics",
                    "score": 0.850882887840271
                },
                {
                    "id": 12048807,
                    "contents": "Itô diffusion\nif g : Rn → R is bounded and continuous, then Rαg lies in DA and, for all α > 0, Invariant measures Sometimes it is necessary to find an invariant measure for an Itô diffusion X, i.e. a measure on Rn that does not change under the \"flow\" of X: i.e., if X0 is distributed according to such an invariant measure μ∞, then Xt is also distributed according to μ∞ for any t ≥ 0. The Fokker–Planck equation offers a way to find such a measure, at least if it has a probability density function ρ∞: if X0 is indeed distributed according to an invariant measure μ∞ with density ρ∞, then the density ρ(t, ·) of Xt does not change with t, so ρ(t, ·) = ρ∞, and so ρ∞ must solve the (time-independent) partial differential equation",
                    "score": 0.8507372140884399
                },
                {
                    "id": 21161059,
                    "contents": "Single-molecule FRET\nThe interpretation of the above equation is simply based on the assumption that each molecule is the same, the ergodic hypothesis. The existence of each state is just represented by its total time which is its \"concentration\". Thus, The rate of transition to any other state is the number of transition normalized by this concentration. Numerically, the time concentration can be converted to number concentration to mimic an ensemble measurement. Because the single molecules are the same to all other molecules, we can assume that the time trajectory is a random combination of a lot of molecules each only occupies a very short period of time, say 𝛿t. Thus, the \"concentration\" of the molecule at state n is cn = tn / 𝛿t. Among all these \"molecules\", if Nnf transfer to state f during this measuring time 𝛿t, the rate of transfer by definition is r = Nnf / 𝛿t = knf cn. Thus knf = Nnf / tn.",
                    "score": 0.8502901196479797
                },
                {
                    "id": 17839241,
                    "contents": "Diffusion\nwhere is the total density. For two gases, the difference between velocities, is given by the expression: where is the force applied to the molecules of the ith component and is the thermodiffusion ratio.",
                    "score": 0.8497363328933716
                },
                {
                    "id": 54814,
                    "contents": "Chemical potential\nA simple example is a system of dilute molecules diffusing in a homogeneous environment. In this system, the molecules tend to move from areas with high concentration to low concentration, until eventually, the concentration is the same everywhere. The microscopic explanation for this is based on kinetic theory and the random motion of molecules. However, it is simpler to describe the process in terms of chemical potentials: For a given temperature, a molecule has a higher chemical potential in a higher-concentration area and a lower chemical potential in a low concentration area. Movement of molecules from higher chemical potential to lower chemical potential is accompanied by a release of free energy. Therefore, it is a spontaneous process.",
                    "score": 0.8495745658874512
                },
                {
                    "id": 29586156,
                    "contents": "Single-particle trajectory\nwhere is the number of points of trajectory that fall in the square . Similarly, the components of the effective diffusion tensor are approximated by the empirical sums The moment estimation requires a large number of trajectories passing through each point, which agrees precisely with the massive data generated by the a certain types of super-resolution data such as those acquired by sptPALM technique on biological samples. The exact inversion of Lagenvin's equation demands in theory an infinite number of trajectories passing through any point x of interest. In practice, the recovery of the drift and diffusion tensor is obtained after a region is subdivided by a square grid of radius r or by moving sliding windows (of the order of 50 to 100 nm). References Cell biology Stochastic processes Biophysics Data analysis Neuroscience Applied mathematics Statistical physics",
                    "score": 0.8494650721549988
                },
                {
                    "id": 11928983,
                    "contents": "Rotational diffusion\nThe rotational version of Fick's law states . This partial differential equation (PDE) may be solved by expanding f(θ, φ, t) in spherical harmonics for which the mathematical identity holds . Thus, the solution of the PDE may be written , where Clm are constants fitted to the initial distribution and the time constants equal . See also Diffusion equation Perrin friction factors Rotational correlation time False diffusion References Further reading Diffusion Rotation",
                    "score": 0.8493296504020691
                },
                {
                    "id": 1762730,
                    "contents": "History of physics\nof moving molecules. The concept of thermal motion came two centuries later. Therefore, Boyle's publication in 1660 speaks about a mechanical concept: the air spring. Later, after the invention of the thermometer, the property temperature could be quantified. This tool gave Gay-Lussac the opportunity to derive his law, which led shortly later to the ideal gas law. But, already before the establishment of the ideal gas law, an associate of Boyle's named Denis Papin built in 1679 a bone digester, which is a closed vessel with a tightly fitting lid that confines steam until a high pressure is generated.",
                    "score": 0.8489400148391724
                },
                {
                    "id": 24624134,
                    "contents": "Classical diffusion\nIf one considers two such ions traveling along parallel axial paths, they can collide whenever their orbits intersect. In most geometries, this means there is a significant difference in the instantaneous velocities when they collide - one might be going \"up\" while the other would be going \"down\" in their helical paths. This causes the collisions to scatter the particles, making them random walks. Eventually, this process will cause any given ion to eventually leave the boundary of the field, and thereby escape \"confinement\". In a uniform magnetic field, a particle undergoes random walk across the field lines by the step size of gyroradius ρ≡vth/Ω, where vth denotes the thermal velocity, and Ω≡qB/m, the gyrofrequency. The steps are randomized by the collisions to lose the coherence. Thus, the time step, or the decoherence time, is the inverse of the collisional frequency νc. The rate of diffusion is given by νcρ2, with the rather favorable B−2 scaling law.",
                    "score": 0.848679780960083
                },
                {
                    "id": 17839221,
                    "contents": "Diffusion\nIn 1858, Rudolf Clausius introduced the concept of the mean free path. In the same year, James Clerk Maxwell developed the first atomistic theory of transport processes in gases. The modern atomistic theory of diffusion and Brownian motion was developed by Albert Einstein, Marian Smoluchowski and Jean-Baptiste Perrin. Ludwig Boltzmann, in the development of the atomistic backgrounds of the macroscopic transport processes, introduced the Boltzmann equation, which has served mathematics and physics with a source of transport process ideas and concerns for more than 140 years. In 1920–1921, George de Hevesy measured self-diffusion using radioisotopes. He studied self-diffusion of radioactive isotopes of lead in the liquid and solid lead.",
                    "score": 0.8486387729644775
                },
                {
                    "id": 1729359,
                    "contents": "Fick's laws of diffusion\nIn certain cases, the solutions are obtained for boundary conditions such as constant source concentration diffusion, limited source concentration, or moving boundary diffusion (where junction depth keeps moving into the substrate). See also Diffusion Osmosis Mass flux Maxwell–Stefan diffusion Churchill–Bernstein equation Nernst–Planck equation Gas exchange False diffusion Advection Notes References – reprinted in External links Fick's equations, Boltzmann's transformation, etc. (with figures and animations) Fick's Second Law on OpenStax Diffusion Statistical mechanics Physical chemistry Mathematics in medicine de:Diffusion#Erstes Fick'sches Gesetz",
                    "score": 0.8485437631607056
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_20",
        "question": "At what pressure does the mean free path of argon at $20^{\\circ} \\mathrm{C}$ become comparable to the diameter of a $100 \\mathrm{~cm}^3$ vessel that contains it? Take $\\sigma=0.36 \\mathrm{~nm}^2$",
        "golden_answers": [
            " 0.195"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 27473842,
                    "contents": "Effusive limit\nAn effusive limit in ultra-low pressure fluid flow is the limit at which a gas of certain molecular weight is able to expand into a vacuum such as a molecular beam line. References Fluid dynamics",
                    "score": 0.8683359026908875
                },
                {
                    "id": 4605241,
                    "contents": "Virial expansion\nThe second and third virial coefficients as functions of temperature are shown in the following figure for argon. Reduced temperature and reduced virial coefficients, scaled by respective critical properties, are all dimensionless. Notice in the figure that the second virial coefficient decreases monotonically as temperature is lowered. However, the third virial coefficient has a bell shape. It increases as temperature is lowered to the critical temperature, then it passes through a peak and decreases rapidly to zero as temperature is lowered from the critical point to the triple point. It is physically unreasonable for it to decrease below the critical temperature. This is because the third virial coefficient theoretically represents the repulsive force among molecules, which is expected to increase at lower temperature, as molecules are pressed together. The behaviors just described are similar for many other gases, as shown in a figure below.",
                    "score": 0.8666409254074097
                },
                {
                    "id": 17356069,
                    "contents": "Laplace pressure\nA common example of use is finding the pressure inside an air bubble in pure water, where = 72 mN/m at 25 °C (298 K). The extra pressure inside the bubble is given here for three bubble sizes: A 1 mm bubble has negligible extra pressure. Yet when the diameter is ~3 μm, the bubble has an extra atmosphere inside than outside. When the bubble is only several hundred nanometers, the pressure inside can be several atmospheres. One should bear in mind that the surface tension in the numerator can be much smaller in the presence of surfactants or contaminants. The same calculation can be done for small oil droplets in water, where even in the presence of surfactants and a fairly low interfacial tension = 5–10 mN/m, the pressure inside 100 nm diameter droplets can reach several atmospheres. See also Ostwald ripening Kelvin equation Laplace number Two balloon experiment References Pressure Fluid dynamics Bubbles (physics) Articles containing video clips",
                    "score": 0.8602380752563477
                },
                {
                    "id": 4605255,
                    "contents": "Virial expansion\nTo produce a solid phase in argon, the exponential value n must be very large, larger than 20; otherwise, the PVT isotherm would not bend to an S-shape between liquid and solid. The best estimation is that n = 30, , , and . The isotherm is shown in the right figure, in which three virial terms are plotted separately for clarity: In this figure, represents the sum of the first three virial terms, of the cubic virial equation, and it shows the behavior of argon in its gaseous and liquid phases. represents the potential contributed from the term, and represents the contributions from the term. When n < 30, would interfere with and lower significantly the volume of liquid.",
                    "score": 0.8563112616539001
                },
                {
                    "id": 27003137,
                    "contents": "Argon compounds\n+ CO2 → Ar + (yields 0.435 eV.) van der Waals molecules Neutral argon atoms bind very weakly to other neutral atoms or molecules to form van der Waals molecules. These can be made by expanding argon under high pressure mixed with the atoms of another element. The expansion happens through a tiny hole into a vacuum, and results in cooling to temperatures a few degrees above absolute zero. At higher temperatures the atoms will be too energetic to stay together by way of the weak London dispersion forces. The atoms that are to combine with argon can be produced by evaporation with a laser or alternatively by an electric discharge. The known molecules include AgAr, Ag2Ar, NaAr, KAr, MgAr, CaAr, SrAr, ZnAr, CdAr, HgAr, SiAr, InAr, CAr, GeAr, SnAr, and BAr. SiAr was made from silicon atoms derived from Si(CH3)4.",
                    "score": 0.8498657941818237
                },
                {
                    "id": 724863,
                    "contents": "Bernoulli's principle\ngas density will be proportional to the ratio of pressure and absolute temperature, however this ratio will vary upon compression or expansion, no matter what non-zero quantity of heat is added or removed. The only exception is if the net heat transfer is zero, as in a complete thermodynamic cycle, or in an individual isentropic (frictionless adiabatic) process, and even then this reversible process must be reversed, to restore the gas to the original pressure and specific volume, and thus density. Only then is the original, unmodified Bernoulli equation applicable. In this case the equation can be used if the flow speed of the gas is sufficiently below the speed of sound, such that the variation in density of the gas (due to this effect) along each streamline can be ignored. Adiabatic flow at less than Mach 0.3 is generally considered to be slow enough.",
                    "score": 0.8478365540504456
                },
                {
                    "id": 1560391,
                    "contents": "Argon\nApplications Argon has several desirable properties: Argon is a chemically inert gas. Argon is the cheapest alternative when nitrogen is not sufficiently inert. Argon has low thermal conductivity. Argon has electronic properties (ionization and/or the emission spectrum) desirable for some applications. Other noble gases would be equally suitable for most of these applications, but argon is by far the cheapest. Argon is inexpensive, since it occurs naturally in air and is readily obtained as a byproduct of cryogenic air separation in the production of liquid oxygen and liquid nitrogen: the primary constituents of air are used on a large industrial scale. The other noble gases (except helium) are produced this way as well, but argon is the most plentiful by far. The bulk of argon applications arise simply because it is inert and relatively cheap.",
                    "score": 0.8475560545921326
                },
                {
                    "id": 12206642,
                    "contents": "Total pressure\nIn physics, the term total pressure may indicate two different quantities, both having the dimensions of a pressure: Pressure Fluid dynamics Gases",
                    "score": 0.8475297689437866
                },
                {
                    "id": 4605256,
                    "contents": "Virial expansion\nIt is surprising that n has to be greater than 20 to produce a solid phase. It is well known that the Lenard-Jones 6-12 potential can be used to compute the second virial coefficient from quantum mechanical principles. Quantum mechanical reasoning relates the second virial coefficient to bimolecular attraction, and the third coefficients to tri-molecular repulsion, etc. In the liquid phase of argon, one atom is surrounded by 12 nearest neighbors, and up to 32 next-to-nearest neighbors. In the solid phase, all atoms are locked in place, and the number of interacting neighbors is infinite. Therefore, n = 30, or even greater, is reasonable. As a result, we have a virial equation of state to describe quantitatively the gas-liquid-solid equilibrium for argon, and all fluids which observe the principle of corresponding states, at its triple point:",
                    "score": 0.8472548723220825
                },
                {
                    "id": 6173713,
                    "contents": "Compressibility factor\nThe Real gas article features more theoretical methods to compute compressibility factors. Physical mechanism of temperature and pressure dependence Deviations of the compressibility factor, Z, from unity are due to attractive and repulsive intermolecular forces. At a given temperature and pressure, repulsive forces tend to make the volume larger than for an ideal gas; when these forces dominate Z is greater than unity. When attractive forces dominate, Z is less than unity. The relative importance of attractive forces decreases as temperature increases (see effect on gases). As seen above, the behavior of Z is qualitatively similar for all gases. Molecular nitrogen, N, is used here to further describe and understand that behavior. All data used in this section were obtained from the NIST Chemistry WebBook. It is useful to note that for N the normal boiling point of the liquid is 77.4 K and the critical point is at 126.2 K and 34.0 bar.",
                    "score": 0.8467048406600952
                },
                {
                    "id": 8092606,
                    "contents": "Pressure experiment\nReferences See also Orders of magnitude (pressure) Physics experiments",
                    "score": 0.846633791923523
                },
                {
                    "id": 18426964,
                    "contents": "Internal pressure\n{| class=\"toccolours\" width=\"60%\" style=\"text-align:left\" !Derivation of the thermodynamic equation of state |- | The fundamental thermodynamic equation states for the exact differential of the internal energy: Dividing this equation by at constant temperature gives: And using one of the Maxwell relations: , this gives |} Perfect gas In a perfect gas, there are no potential energy interactions between the particles, so any change in the internal energy of the gas is directly proportional to the change in the kinetic energy of its constituent species and therefore also to the change in temperature: . The internal pressure is taken to be at constant temperature, therefore , which implies and finally , i.e. the internal energy of a perfect gas is independent of the volume it occupies. The above relation can be used as a definition of a perfect gas.",
                    "score": 0.8450560569763184
                },
                {
                    "id": 6173716,
                    "contents": "Compressibility factor\nAs the pressure increases, the gas eventually reaches the gas-liquid coexistence curve, shown by the dashed line in the figure. When that happens, the attractive interactions have become strong enough to overcome the tendency of thermal motion to cause the molecules to spread out; so the gas condenses to form a liquid. Points on the vertical portions of the curves correspond to N2 being partly gas and partly liquid. On the coexistence curve, there are then two possible values for Z, a larger one corresponding to the gas and a smaller value corresponding to the liquid. Once all the gas has been converted to liquid, the volume decreases only slightly with further increases in pressure; then Z is very nearly proportional to pressure.",
                    "score": 0.8435751795768738
                },
                {
                    "id": 18426968,
                    "contents": "Internal pressure\nThe Joule experiment James Joule tried to measure the internal pressure of air in his expansion experiment by adiabatically pumping high pressure air from one metal vessel into another evacuated one. The water bath in which the system was immersed did not change its temperature, signifying that no change in the internal energy occurred. Thus, the internal pressure of the air was apparently equal to zero and the air acted as a perfect gas. The actual deviations from the perfect behaviour were not observed since they are very small and the specific heat capacity of water is relatively high. References Peter Atkins and Julio de Paula, Physical Chemistry 8th edition, pp. 60–61 Thermodynamic properties",
                    "score": 0.8433268666267395
                },
                {
                    "id": 2035072,
                    "contents": "High pressure\nIn science and engineering the study of high pressure examines its effects on materials and the design and construction of devices, such as a diamond anvil cell, which can create high pressure. By high pressure is usually meant pressures of thousands (kilobars) or millions (megabars) of times atmospheric pressure (about 1 bar or 100,000 Pa). History and overview Percy Williams Bridgman received a Nobel Prize in 1946 for advancing this area of physics by several magnitudes of pressure (400 MPa to 40,000 MPa). The list of founding fathers of this field includes also the names of Harry George Drickamer, Tracy Hall, Francis P. Bundy, Leonid F. Vereschagin, and Sergey M. Stishov.",
                    "score": 0.8432888388633728
                },
                {
                    "id": 6630757,
                    "contents": "Acentric factor\nThe definition of gives essentially zero for the noble gases argon, krypton, and xenon. is very close to zero for other spherical molecules. Values of correspond to vapor pressures above the critical pressure, and are non-physical. By definition, a van der Waals fluid has a critical compressibility of 3/8 and an acentric factor of about −0.302024, indicating a small ultra-spherical molecule. A Redlich-Kwong fluid has a critical compressibility of 1/3 and an acentric factor of about 0.058280, close to nitrogen; without the temperature dependence of its attractive term, its acentric factor would be only -0.293572. Values of some common gases See also Equation of state Reduced pressure Reduced temperature References Gas laws",
                    "score": 0.8432585000991821
                },
                {
                    "id": 4306493,
                    "contents": "Lawson criterion\nThis product must be greater than a value related to the minimum of T 3/2/<σv>. The same requirement is traditionally expressed in terms of mass density ρ = <nmi>: Satisfaction of this criterion at the density of solid deuterium–tritium (0.2 g/cm3) would require a laser pulse of implausibly large energy. Assuming the energy required scales with the mass of the fusion plasma (Elaser ~ ρR3 ~ ρ−2), compressing the fuel to 103 or 104 times solid density would reduce the energy required by a factor of 106 or 108, bringing it into a realistic range. With a compression by 103, the compressed density will be 200 g/cm3, and the compressed radius can be as small as 0.05 mm. The radius of the fuel before compression would be 0.5 mm. The initial pellet will be perhaps twice as large since most of the mass will be ablated during the compression.",
                    "score": 0.842052161693573
                },
                {
                    "id": 24068792,
                    "contents": "AI Mark VIII radar\ntook up development of the concept with Ward and Starr, initially trying helium and hydrogen, but eventually settling on a tiny amount of water vapour and argon. The resulting design, known as a soft Sutton tube, went into production as the CV43 and the first examples arrived in the summer of 1941.",
                    "score": 0.8420076370239258
                },
                {
                    "id": 17356068,
                    "contents": "Laplace pressure\nThe Laplace pressure is commonly used to determine the pressure difference in spherical shapes such as bubbles or droplets. In this case, = : For a gas bubble within a liquid, there is only one surface. For a gas bubble with a liquid wall, beyond which is again gas, there are two surfaces, each contributing to the total pressure difference. If the bubble is spherical and the outer radius differs from the inner radius by a small distance, , we find Examples A common example of use is finding the pressure inside an air bubble in pure water, where = 72 mN/m at 25 °C (298 K). The extra pressure inside the bubble is given here for three bubble sizes:",
                    "score": 0.8419816493988037
                },
                {
                    "id": 1128031,
                    "contents": "Noble gas\nThe noble gases are nearly ideal gases under standard conditions, but their deviations from the ideal gas law provided important clues for the study of intermolecular interactions. The Lennard-Jones potential, often used to model intermolecular interactions, was deduced in 1924 by John Lennard-Jones from experimental data on argon before the development of quantum mechanics provided the tools for understanding intermolecular forces from first principles. The theoretical analysis of these interactions became tractable because the noble gases are monatomic and the atoms spherical, which means that the interaction between the atoms is independent of direction, or isotropic. Chemical properties",
                    "score": 0.8419627547264099
                },
                {
                    "id": 4605253,
                    "contents": "Virial expansion\nNow, if we had a term to pull the PVT isotherm down in the liquid phase, and a terms to push it back up, a solid phase could be created, as these two terms producing another S shaped bend between liquid and solid. It was demonstrated that such an S shaped bend could be synthesized using a -function like Lorentzian function over a van der Waals equation of state. Such an equation of state is difficult to manipulate mathematically. In contrast, a virial equation is easier to handle. Argon is used to evaluate realistically this extended virial equation for gas-liquid-solid equilibrium. Data will be analyzed in the reduced forms. All PVT variables are scaled by their respective critical values. It is expect from the principle of corresponding states that the results would apply to other well behaved fluids. The relevant data of argon are summarized in the following table:",
                    "score": 0.8419556021690369
                },
                {
                    "id": 17780814,
                    "contents": "Gas\nSpecial topics Compressibility Thermodynamicists use this factor (Z) to alter the ideal gas equation to account for compressibility effects of real gases. This factor represents the ratio of actual to ideal specific volumes. It is sometimes referred to as a \"fudge-factor\" or correction to expand the useful range of the ideal gas law for design purposes. Usually this Z value is very close to unity. The compressibility factor image illustrates how Z varies over a range of very cold temperatures. Reynolds number In fluid mechanics, the Reynolds number is the ratio of inertial forces (vsρ) to viscous forces (μ/L). It is one of the most important dimensionless numbers in fluid dynamics and is used, usually along with other dimensionless numbers, to provide a criterion for determining dynamic similitude. As such, the Reynolds number provides the link between modeling results (design) and the full-scale actual conditions. It can also be used to characterize the flow. Viscosity",
                    "score": 0.841403603553772
                },
                {
                    "id": 4752485,
                    "contents": "Real gas\nor alternatively: where a and b are two empirical parameters that are not the same parameters as in the van der Waals equation. These parameters can be determined: The constants at critical point can be expressed as functions of the parameters a, b: Using the equation of state can be written in the reduced form: with Berthelot and modified Berthelot model The Berthelot equation (named after D. Berthelot) is very rarely used, but the modified version is somewhat more accurate Dieterici model This model (named after C. Dieterici) fell out of usage in recent years with parameters a, b, and Clausius model The Clausius equation (named after Rudolf Clausius) is a very simple three-parameter equation used to model gases. or alternatively: where where Vc is critical volume. Virial model The Virial equation derives from a perturbative treatment of statistical mechanics. or alternatively where A, B, C, A′, B′, and C′ are temperature dependent constants.",
                    "score": 0.8403457403182983
                },
                {
                    "id": 680040,
                    "contents": "Gas constant\nwhere N is the number of particles (molecules in this case), or to generalize to an inhomogeneous system the local form holds: where ρN is the number density. Measurement and replacement with defined value As of 2006, the most precise measurement of R had been obtained by measuring the speed of sound ca(P, T) in argon at the temperature T of the triple point of water at different pressures P, and extrapolating to the zero-pressure limit ca(0, T). The value of R is then obtained from the relation where: γ0 is the heat capacity ratio ( for monatomic gases such as argon); T is the temperature, TTPW = 273.16 K by the definition of the kelvin at that time; Ar(Ar) is the relative atomic mass of argon and Mu = as defined at the time. However, following the 2019 redefinition of the SI base units, R now has an exact value defined in terms of other exactly defined physical constants. Specific gas constant",
                    "score": 0.8399201035499573
                },
                {
                    "id": 3117583,
                    "contents": "1801 in science\nPhysics Dalton's law: John Dalton observes that the total pressure exerted by a gaseous mixture is equal to the sum of the partial pressures of each individual component in a gas mixture. Ultraviolet radiation is discovered by Johann Wilhelm Ritter. In optics, interference between light beams is discovered by Thomas Young, showing the wave nature of light.",
                    "score": 0.839897871017456
                },
                {
                    "id": 14294760,
                    "contents": "Viscosity\nPure gases {| class=\"toccolours collapsible collapsed\" width=\"60%\" style=\"text-align:left\" ! Elementary calculation of viscosity for a dilute gas |- | Consider a dilute gas moving parallel to the -axis with velocity that depends only on the coordinate. To simplify the discussion, the gas is assumed to have uniform temperature and density. Under these assumptions, the velocity of a molecule passing through is equal to whatever velocity that molecule had when its mean free path began. Because is typically small compared with macroscopic scales, the average velocity of such a molecule has the form where is a numerical constant on the order of . (Some authors estimate ; on the other hand, a more careful calculation for rigid elastic spheres gives .) Next, because half the molecules on either side are moving towards , and doing so on average with half the average molecular speed , the momentum flux from either side is The net momentum flux at is the difference of the two:",
                    "score": 0.8386156558990479
                },
                {
                    "id": 25085656,
                    "contents": "Rüchardt experiment\nThe Rüchardt experiment, invented by Eduard Rüchardt, is a famous experiment in thermodynamics, which determines the ratio of the molar heat capacities of a gas, i.e. the ratio of (heat capacity at constant pressure) and (heat capacity at constant volume) and is denoted by (gamma, for ideal gas) or (kappa, isentropic exponent, for real gas). It arises because the temperature of a gas changes as pressure changes. The experiment directly yields the heat capacity ratio or adiabatic index of the gas, which is the ratio of the heat capacity at constant pressure to heat capacity at constant volume. The results are sometimes also known as the isentropic expansion factor.",
                    "score": 0.8376688361167908
                },
                {
                    "id": 1749742,
                    "contents": "Gilbert N. Lewis\ndimensions of pressure which expressed the tendency of a substance to pass from one chemical phase to another. Lewis believed that fugacity was the fundamental principle from which a system of real thermodynamic relations could be derived. This hope was not realized, though fugacity did find a lasting place in the description of real gases.",
                    "score": 0.8375188708305359
                },
                {
                    "id": 932509,
                    "contents": "Partial pressure\nSymbol The symbol for pressure is usually or which may use a subscript to identify the pressure, and gas species are also referred to by subscript. When combined these subscripts are applied recursively. Examples: or = pressure at time 1 or = partial pressure of hydrogen or = venous partial pressure of oxygen Dalton's law of partial pressures Dalton's law expresses the fact that the total pressure of a mixture of ideal gases is equal to the sum of the partial pressures of the individual gases in the mixture. This equality arises from the fact that in an ideal gas the molecules are so far apart that they do not interact with each other. Most actual real-world gases come very close to this ideal. For example, given an ideal gas mixture of nitrogen (N2), hydrogen (H2) and ammonia (NH3): where: = total pressure of the gas mixture = partial pressure of nitrogen (N2) = partial pressure of hydrogen (H2) = partial pressure of ammonia (NH3)",
                    "score": 0.8367291688919067
                },
                {
                    "id": 1568612,
                    "contents": "Adiabatic process\nso the adiabatic constant for this example is about 6.31 Pa m4.2. The gas is now compressed to a 0.1 L (0.0001 m3) volume, which we assume happens quickly enough that no heat enters or leaves the gas through the walls. The adiabatic constant remains the same, but with the resulting pressure unknown We can now solve for the final pressure or 25.1 bar. This pressure increase is more than a simple 10:1 compression ratio would indicate; this is because the gas is not only compressed, but the work done to compress the gas also increases its internal energy, which manifests itself by a rise in the gas temperature and an additional rise in pressure above what would result from a simplistic calculation of 10 times the original pressure.",
                    "score": 0.8362002968788147
                },
                {
                    "id": 590376,
                    "contents": "Jacques Charles\nAround 1787 Charles did an experiment where he filled 5 balloons to the same volume with different gases. He then raised the temperature of the balloons to 80 °C (not at constant temperature) and noticed that they all increased in volume by the same amount. This experiment was referenced by Gay-Lussac in 1802 when he published a paper on the precise relationship between the volume and temperature of a gas. Charles' law states that under constant pressure, an ideal gas' volume is proportional to its absolute temperature. The volume of a gas at constant pressure increases linearly with the absolute temperature of the gas. The formula he created was V1/T1 = V2/T2. Career Jacques Charles was elected to the American Philosophical Society in 1786 and to the Académie des Sciences, in 1795. He subsequently became professor of physics at the Conservatoire des Arts et Métiers.",
                    "score": 0.8357565999031067
                },
                {
                    "id": 18582345,
                    "contents": "Equilibrium chemistry\nBy convention po is usually taken to be 1 bar. Fugacity can be expressed as the product of partial pressure, p, and a fugacity coefficient, Φ: Fugacity coefficients are dimensionless and can be obtained experimentally at specific temperature and pressure, from measurements of deviations from ideal gas behaviour. Equilibrium constants are defined in terms of fugacity. If the gases are at sufficiently low pressure that they behave as ideal gases, the equilibrium constant can be defined as a quotient of partial pressures.",
                    "score": 0.8352302312850952
                },
                {
                    "id": 10386171,
                    "contents": "Critical velocity\nCritical velocity may refer to Critical ionization velocity, relative velocity between a neutral gas and plasma at which the neutral gas will start to ionize Speed of sound, at the throat of a rocket (otherwise known as throat velocity) Landau critical velocity, constant velocity of a superfluid equivalent to the bandgap width divided by the fermi momentum Velocity at which a liquid transitions from subcritical flow to supercritical flow The break-up velocity of a rapidly spinning star Velocity at which leukocytes switch from rolling to freely flowing in a blood vessel",
                    "score": 0.8350350260734558
                },
                {
                    "id": 1128053,
                    "contents": "Noble gas\nSince the Hindenburg disaster in 1937, helium has replaced hydrogen as a lifting gas in blimps and balloons due to its lightness and incombustibility, despite an 8.6% decrease in buoyancy. In many applications, the noble gases are used to provide an inert atmosphere. Argon is used in the synthesis of air-sensitive compounds that are sensitive to nitrogen. Solid argon is also used for the study of very unstable compounds, such as reactive intermediates, by trapping them in an inert matrix at very low temperatures. Helium is used as the carrier medium in gas chromatography, as a filler gas for thermometers, and in devices for measuring radiation, such as the Geiger counter and the bubble chamber. Helium and argon are both commonly used to shield welding arcs and the surrounding base metal from the atmosphere during welding and cutting, as well as in other metallurgical processes and in the production of silicon for the semiconductor industry.",
                    "score": 0.8348751068115234
                },
                {
                    "id": 4394006,
                    "contents": "Joule–Thomson effect\nIn a gas expansion the pressure decreases, so the sign of is negative by definition. With that in mind, the following table explains when the Joule–Thomson effect cools or warms a real gas: Helium and hydrogen are two gases whose Joule–Thomson inversion temperatures at a pressure of one atmosphere are very low (e.g., about 45 K, −228 °C for helium). Thus, helium and hydrogen warm when expanded at constant enthalpy at typical room temperatures. On the other hand, nitrogen and oxygen, the two most abundant gases in air, have inversion temperatures of 621 K (348 °C) and 764 K (491 °C) respectively: these gases can be cooled from room temperature by the Joule–Thomson effect. For an ideal gas, is always equal to zero: ideal gases neither warm nor cool upon being expanded at constant enthalpy. Applications",
                    "score": 0.8346556425094604
                },
                {
                    "id": 22571524,
                    "contents": "Decompression theory\nat a specific radius depending on the pressure, the composition of the surface layer, and the supersaturation, or continue to grow indefinitely, if larger than the critical radius. Bubble formation can occur in the blood or other tissues.",
                    "score": 0.8345780372619629
                },
                {
                    "id": 1879006,
                    "contents": "Henry's law\nBackground Charles Coulston Gillispie states that John Dalton \"supposed that the separation of gas particles one from another in the vapor phase bears the ratio of a small whole number to their interatomic distance in solution. Henry's law follows as a consequence if this ratio is a constant for each gas at a given temperature.\" Applications of Henry's law",
                    "score": 0.8343603610992432
                },
                {
                    "id": 1316142,
                    "contents": "Vacuum\nThe quality of a vacuum is indicated by the amount of matter remaining in the system, so that a high quality vacuum is one with very little matter left in it. Vacuum is primarily measured by its absolute pressure, but a complete characterization requires further parameters, such as temperature and chemical composition. One of the most important parameters is the mean free path (MFP) of residual gases, which indicates the average distance that molecules will travel between collisions with each other. As the gas density decreases, the MFP increases, and when the MFP is longer than the chamber, pump, spacecraft, or other objects present, the continuum assumptions of fluid mechanics do not apply. This vacuum state is called high vacuum, and the study of fluid flows in this regime is called particle gas dynamics. The MFP of air at atmospheric pressure is very short, 70 nm, but at 100 mPa (~) the MFP of room temperature air is roughly 100 mm, which is on the order of everyday objects such",
                    "score": 0.8341280817985535
                },
                {
                    "id": 7737935,
                    "contents": "High vacuum\nHigh vacuum may refer to: A vacuum with pressure in the range from 100 mPa to 100 nPa High Vacuum, the 1957 novel by Charles Eric Maine See also: Ultra-high vacuum",
                    "score": 0.8340842723846436
                },
                {
                    "id": 1379355,
                    "contents": "Le Chatelier's principle\nChanging total pressure by adding an inert gas at constant volume does not affect the equilibrium concentrations (see Effect of adding an inert gas below). Changing total pressure by changing the volume of the system changes the partial pressures of the products and reactants and can affect the equilibrium concentrations (see §Effect of change in volume below). Effect of change in volume Changing the volume of the system changes the partial pressures of the products and reactants and can affect the equilibrium concentrations. With a pressure increase due to a decrease in volume, the side of the equilibrium with fewer moles is more favorable and with a pressure decrease due to an increase in volume, the side with more moles is more favorable. There is no effect on a reaction where the number of moles of gas is the same on each side of the chemical equation. Considering the reaction of nitrogen gas with hydrogen gas to form ammonia: ⇌ ΔH = −92kJ mol−1",
                    "score": 0.8337143659591675
                },
                {
                    "id": 13470731,
                    "contents": "Bubble point\nWhen Raoult's law and Dalton's law hold for the mixture, the K factor is defined as the ratio of the vapor pressure to the total pressure of the system: Given either of or and either the temperature or pressure of a two-component system, calculations can be performed to determine the unknown information. References See also Phase diagram Azeotrope Dew point Temperature Phase transitions Gases",
                    "score": 0.8333830237388611
                },
                {
                    "id": 27156790,
                    "contents": "Diargon\nBarker, J.A.; Fisher, R.A.; Watts, R.O., Liquid argon: Monte Carlo and molecular dynamics calculations, Mol. Phys., 1971, 21, 657. Maitland, G.C.; Smith, E.B., The intermolecular pair potential of argon, Mol. Phys., 1971, 22, 861. Present, R.D., Collision diameter and well depth of the Ar-Ar interaction, J. Chem. Phys., 1973, 58, 2659. Photoionization of Ar2 at high resolution The Journal of Chemical Physics 76, 1263 (1982); https://doi.org/10.1063/1.443144 P. M. Dehmer spectrum 800 to 850Å Ab initio pair potential energy curve for the argon atom pair and thermophysical properties for the dilute argon gas. II. Thermophysical properties for low-density argon Eckhard Vogel, Benjamin Jäger, Robert Hellmann & Eckard Bich Pages 3335–3352 Published 07 Oct 2010 https://doi.org/10.1080/00268976.2010.507557 (will use the formula and draw graph)",
                    "score": 0.8332027196884155
                },
                {
                    "id": 1028873,
                    "contents": "Antihydrogen\nThe ALPHA team made batches of antihydrogen, held them for 600 seconds and then tapered down the confinement field over 1.5 seconds while counting how many antihydrogen atoms were annihilated. They did this under three different experimental conditions: Resonance: – exposing the confined antihydrogen atoms to a laser source tuned to exactly half the transition frequency for 300 seconds for each of the two transitions, Off-resonance: – exposing the confined antihydrogen atoms to a laser source tuned 200 kilohertz below the two resonance frequencies for 300 seconds each, No-laser: – confining the antihydrogen atoms without any laser illumination. The two controls, off-resonance and no-laser, were needed to insure that the laser illumination itself was not causing annihilations, perhaps by liberating normal atoms from the confinement vessel surface that could then combine with the antihydrogen.",
                    "score": 0.8330816030502319
                },
                {
                    "id": 6173715,
                    "contents": "Compressibility factor\nTo better understand these curves, a closer look at the behavior for low temperature and pressure is given in the second figure. All of the curves start out with Z equal to unity at zero pressure and Z initially decreases as pressure increases. N is a gas under these conditions, so the distance between molecules is large, but becomes smaller as pressure increases. This increases the attractive interactions between molecules, pulling the molecules closer together and causing the volume to be less than for an ideal gas at the same temperature and pressure. Higher temperature reduces the effect of the attractive interactions and the gas behaves in a more nearly ideal manner.",
                    "score": 0.8327367305755615
                },
                {
                    "id": 680064,
                    "contents": "Ideal gas law\nb. In an isenthalpic process, system enthalpy (H) is constant. In the case of free expansion for an ideal gas, there are no molecular interactions, and the temperature remains constant. For real gasses, the molecules do interact via attraction or repulsion depending on temperature and pressure, and heating or cooling does occur. This is known as the Joule–Thomson effect. For reference, the Joule–Thomson coefficient μJT for air at room temperature and sea level is 0.22 °C/bar.",
                    "score": 0.8326919674873352
                },
                {
                    "id": 2636865,
                    "contents": "Isothermal process\nmotion is sufficiently slow such that at each instant during the expansion the gas temperature and pressure is uniform and conform to the ideal gas law. Figure 3 shows the relationship for = 2 [atm·m3] for isothermal expansion from 2 atm (state ) to 1 atm (state ).",
                    "score": 0.8325546979904175
                },
                {
                    "id": 8455616,
                    "contents": "Torricelli's law\nis equal to the height of the liquid's surface over the opening. and are typically both atmospheric pressure, so . Experimental evidence Torricelli's law can be demonstrated in the spouting-can experiment, which is designed to show that in a liquid with an open surface, pressure increases with depth. It consists of a tube with three separate holes and an open surface. The three holes are blocked, then the tube is filled with water. When it is full, the holes are unblocked. The lower a jet is on the tube, the more powerful it is. The fluid exit velocity is greater further down the tube. Ignoring viscosity and other losses, if the nozzles point vertically upward, then each jet will reach the height of the surface of the liquid in the container.",
                    "score": 0.8324759602546692
                },
                {
                    "id": 1169914,
                    "contents": "Pressure\nRestating this as energy equation, the energy per unit volume in an ideal, incompressible liquid is constant throughout its vessel. At the surface, gravitational potential energy is large but liquid pressure energy is low. At the bottom of the vessel, all the gravitational potential energy is converted to pressure energy. The sum of pressure energy and gravitational potential energy per unit volume is constant throughout the volume of the fluid and the two energy components change linearly with the depth. Mathematically, it is described by Bernoulli's equation, where velocity head is zero and comparisons per unit volume in the vessel are Terms have the same meaning as in section Fluid pressure.",
                    "score": 0.8323493003845215
                },
                {
                    "id": 4605254,
                    "contents": "Virial expansion\nWhen the variables P, V, and T are replaced by their reduced equivalents, , , and , the virial equation takes the following form: where , , , , and . We will be concerned mostly with condition at the triple point of argon, where b = 3.424 and c = 1.152 from an earlier study. must be slightly larger than the volume of solid argon, 0.33, and must be between the volumes of liquid and solid argon. Initially, is set to the volume of solid, to produce the last sharply rising edge of the isotherm where solid phase appears at very low volume. The exponential n must be then determined, so that the valley in the n-2n potential must fit between the volumes of solid (0.33) and liquid (0.378). After the exponential n is determined, the value of can be adjusted to satisfy the Gibbs Rule, which requires that the Gibbs free energy of liquid phase and that of solid phase must be equal under the triple point temperature and pressure.",
                    "score": 0.8319791555404663
                },
                {
                    "id": 892669,
                    "contents": "Vapor pressure\nReferences External links Fluid Characteristics Chart Hyperphysics MSDS Vapor Pressure Online vapor pressure calculation tool (Requires Registration) Prediction of Vapor Pressures of Pure Liquid Organic Compounds Thermodynamic properties Engineering thermodynamics Meteorological concepts Gases Pressure",
                    "score": 0.8319474458694458
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_21",
        "question": "The equilibrium pressure of $\\mathrm{O}_2$ over solid silver and silver oxide, $\\mathrm{Ag}_2 \\mathrm{O}$, at $298 \\mathrm{~K}$ is $11.85 \\mathrm{~Pa}$. Calculate the standard Gibbs energy of formation of $\\mathrm{Ag}_2 \\mathrm{O}(\\mathrm{s})$ at $298 \\mathrm{~K}$.",
        "golden_answers": [
            " -11.2"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1228301,
                    "contents": "Silver\nCompounds Oxides and chalcogenides Silver and gold have rather low chemical affinities for oxygen, lower than copper, and it is therefore expected that silver oxides are thermally quite unstable. Soluble silver(I) salts precipitate dark-brown silver(I) oxide, Ag2O, upon the addition of alkali. (The hydroxide AgOH exists only in solution; otherwise it spontaneously decomposes to the oxide.) Silver(I) oxide is very easily reduced to metallic silver, and decomposes to silver and oxygen above 160 °C. This and other silver(I) compounds may be oxidized by the strong oxidizing agent peroxodisulfate to black AgO, a mixed silver(I,III) oxide of formula AgIAgIIIO2. Some other mixed oxides with silver in non-integral oxidation states, namely Ag2O3 and Ag3O4, are also known, as is Ag3O which behaves as a metallic conductor.",
                    "score": 0.8739264011383057
                },
                {
                    "id": 9198648,
                    "contents": "Silver molybdate\nSilver molybdate (Ag2MoO4), a chemical compound, is a yellow, cubic crystalline substance often used in glass. Its crystals present two types of electronic structure, depending on the pressure conditions to which the crystal is subjected. At room temperature, Ag2MoO4 exhibits a spinel-type cubic structure, known as β-Ag2MoO4, which is more stable in nature. However, when exposed to high hydrostatic pressure, the tetragonal α-Ag2MoO4 forms as a metastable phase.",
                    "score": 0.8724474906921387
                },
                {
                    "id": 1228295,
                    "contents": "Silver\nCu+ is the reason why the former is the more stable in aqueous solution and solids despite lacking the stable filled d-subshell of the latter, with silver this effect is swamped by its larger second ionisation energy. Hence, Ag+ is the stable species in aqueous solution and solids, with Ag2+ being much less stable as it oxidizes water.",
                    "score": 0.8700557351112366
                },
                {
                    "id": 1228294,
                    "contents": "Silver\nSilver is a rather unreactive metal. This is because its filled 4d shell is not very effective in shielding the electrostatic forces of attraction from the nucleus to the outermost 5s electron, and hence silver is near the bottom of the electrochemical series (E0(Ag+/Ag) = +0.799 V). In group 11, silver has the lowest first ionization energy (showing the instability of the 5s orbital), but has higher second and third ionization energies than copper and gold (showing the stability of the 4d orbitals), so that the chemistry of silver is predominantly that of the +1 oxidation state, reflecting the increasingly limited range of oxidation states along the transition series as the d-orbitals fill and stabilize. Unlike copper, for which the larger hydration energy of Cu2+ as compared to Cu+ is the reason why the former is the more stable in aqueous solution and solids despite lacking the stable filled d-subshell of the latter, with silver this effect is swamped by its larger second",
                    "score": 0.8678066730499268
                },
                {
                    "id": 2578267,
                    "contents": "Nevill Francis Mott\nThe second book, with Ronald Wilfred Gurney, On the Physical Chemistry of Solids was more wide-ranging. It treated notably of the oxidation of metals at low temperatures, where it described the growth of the oxide layer as due to the electric field developed between the metal and absorbed oxygen ions, which could force the way of metallic or oxygen ions through a disordered oxide layer. The book also analysed the photographic reactions in ionic silver compound in terms of precipitation of silver ions into metallic clusters.",
                    "score": 0.8663461208343506
                },
                {
                    "id": 11828702,
                    "contents": "Native metal\nSilver Native silver occurs as elongated dendritic coatings or irregular masses. It may also occur as cubic, octahedral, or dodecahedral crystals. It may occur alloyed with gold as electrum. It often occurs with silver sulfide and sulfosalt minerals. Various amalgams of silver and mercury or other metals and mercury do occur rarely as minerals in nature. An example is the mineral eugenite (Ag11Hg2) and related forms. Silver nuggets, wires, and grains are relatively common, but there are also a large number of silver compound minerals owing to silver being more reactive than gold.",
                    "score": 0.8659533858299255
                },
                {
                    "id": 3685655,
                    "contents": "Silver bromide\nThe low activation energy in silver bromide can be attributed the silver ions' high quadrupolar polarizability; that is, it can easily deform from a sphere into an ellipsoid. This property, a result of the d9 electronic configuration of the silver ion, facilitates migration in both the silver ion and in silver-ion vacancies, thus giving the unusually low migration energy (for Agv−: 0.29–0.33 eV, compared to 0.65 eV for NaCl). Studies have demonstrated that the defect concentrations are strongly affected (up to several powers of 10) by crystal size. Most defects, such as interstitial silver ion concentration and surface kinks, are inversely proportional to crystal size, although vacancy defects are directly proportional. This phenomenon is attributed to changes in the surface chemistry equilibrium, and thus affects each defect concentration differently.",
                    "score": 0.8608302474021912
                },
                {
                    "id": 3685662,
                    "contents": "Silver bromide\nAgX(s) + 2 Na2S2O3(aq) → Na3[Ag(S2O3)2](aq) + NaX(aq) An indefinite number of positive prints can be generated from the negative by passing light through it and undertaking the same steps outlined above. Semiconductor properties As silver bromide is heated within 100 °C of its melting point, an Arrhenius plot of the ionic conductivity shows the value increasing and \"upward-turning.\" Other physical properties such as elastic moduli, specific heat, and the electronic energy gap also increase, suggesting the crystal is approaching instability. This behavior, typical of a semi-conductor, is attributed to a temperature-dependence of Frenkel defect formation, and, when normalized against the concentration of Frenkel defects, the Arrhenius plot linearizes. See also Photography Science of photography Silver chloride References Metal halides Bromides Silver compounds Photographic chemicals Light-sensitive chemicals Rock salt crystal structure",
                    "score": 0.86025071144104
                },
                {
                    "id": 1228296,
                    "contents": "Silver\nMost silver compounds have significant covalent character due to the small size and high first ionization energy (730.8 kJ/mol) of silver. Furthermore, silver's Pauling electronegativity of 1.93 is higher than that of lead (1.87), and its electron affinity of 125.6 kJ/mol is much higher than that of hydrogen (72.8 kJ/mol) and not much less than that of oxygen (141.0 kJ/mol). Due to its full d-subshell, silver in its main +1 oxidation state exhibits relatively few properties of the transition metals proper from groups 4 to 10, forming rather unstable organometallic compounds, forming linear complexes showing very low coordination numbers like 2, and forming an amphoteric oxide as well as Zintl phases like the post-transition metals. Unlike the preceding transition metals, the +1 oxidation state of silver is stable even in the absence of π-acceptor ligands.",
                    "score": 0.8592808246612549
                },
                {
                    "id": 98941,
                    "contents": "Silver nitrate\nQualitatively, decomposition is negligible below the melting point, but becomes appreciable around 250 °C and fully decomposes at 440 °C. Most metal nitrates thermally decompose to the respective oxides, but silver oxide decomposes at a lower temperature than silver nitrate, so the decomposition of silver nitrate yields elemental silver instead. Uses",
                    "score": 0.859004020690918
                },
                {
                    "id": 2828690,
                    "contents": "Silver sulfide\nStructure and properties Three forms are known: monoclinic acanthite (β-form), stable below 179 °C, body centered cubic so-called argentite (α-form), stable above 180 °C, and a high temperature face-centred cubic (γ-form) stable above 586 °C. The higher temperature forms are electrical conductors. It is found in nature as relatively low temperature mineral acanthite. Acanthite is an important ore of silver. The acanthite, monoclinic, form features two kinds of silver centers, one with two and the other with three near neighbour sulfur atoms. Argentite refers to a cubic form, which, due to instability in \"normal\" temperatures, is found in form of the pseudomorphosis of acanthite after argentite. History In 1833 Michael Faraday noticed that the resistance of silver sulfide decreased dramatically as temperature increased. This constituted the first report of a semiconducting material. Silver sulfide is a component of classical qualitative inorganic analysis. References",
                    "score": 0.8581399917602539
                },
                {
                    "id": 15480271,
                    "contents": "Solid state ionics\nIonic conductivity in silver halides Among several solid electrolytes described in the 19th and early 20th century, α-AgI, the high-temperature crystalline form of silver iodide, is widely regarded as the most important one. Its electrical conduction was characterized by Carl Tubandt and E. Lorenz in 1914. Their comparative study of AgI, AgCl and AgBr demonstrated that α-AgI, is thermally stable and highly conductive between 147 and 555 °C; the conductivity weakly increased with temperature in this range and then dropped upon melting. This behavior was fully reversible and excluded non-equilibrium effects. Tubandt and Lorenz described other materials with a similar behavior, such as α-CuI, α-CuBr, β-CuBr, and high-temperature phases of Ag2S, Ag2Se and Ag2Te. They associated the conductivity with cations in silver and cuprous halides and with ions and electrons in silver chalcogenides. Point defects in ionic crystals",
                    "score": 0.8576115369796753
                },
                {
                    "id": 1228306,
                    "contents": "Silver\nThe process is not reversible because the silver atom liberated is typically found at a crystal defect or an impurity site, so that the electron's energy is lowered enough that it is \"trapped\". Other inorganic compounds White silver nitrate, AgNO3, is a versatile precursor to many other silver compounds, especially the halides, and is much less sensitive to light. It was once called lunar caustic because silver was called luna by the ancient alchemists, who believed that silver was associated with the moon. It is often used for gravimetric analysis, exploiting the insolubility of the heavier silver halides which it is a common precursor to. Silver nitrate is used in many ways in organic synthesis, e.g. for deprotection and oxidations. Ag+ binds alkenes reversibly, and silver nitrate has been used to separate mixtures of alkenes by selective absorption. The resulting adduct can be decomposed with ammonia to release the free alkene.",
                    "score": 0.8573545217514038
                },
                {
                    "id": 1148193,
                    "contents": "Oxide\nReduction by heating Metals that are lower in the reactivity series can be reduced by heating alone. For example, silver oxide decomposes at 200 °C: 2 Ag2O → 4 Ag + O2 Reduction by displacement Metals that are more reactive displace the oxide of the metals that are less reactive. For example, zinc is more reactive than copper, so it displaces copper (II) oxide to form zinc oxide: Zn + CuO → ZnO + Cu Reduction by hydrogen Apart from metals, hydrogen can also displace metal oxides to form hydrogen oxide, also known as water: H2 + CuO → Cu + H2O Reduction by electrolysis Since metals that are reactive form oxides that are stable, some metal oxides must be electrolyzed to be reduced. This includes sodium oxide, potassium oxide, calcium oxide, magnesium oxide, and aluminium oxide. The oxides must be molten before immersing graphite electrodes in them: 2Al2O3 → 4Al + 3O2",
                    "score": 0.856415867805481
                },
                {
                    "id": 8323511,
                    "contents": "Silver oxide\nSilver(I) oxide is the chemical compound with the formula Ag2O. It is a fine black or dark brown powder that is used to prepare other silver compounds. Preparation Silver oxide can be prepared by combining aqueous solutions of silver nitrate and an alkali hydroxide. This reaction does not afford appreciable amounts of silver hydroxide due to the favorable energetics for the following reaction: 2 AgOH -> Ag2O + H2O (pK = 2.875) With suitably controlled conditions, this reaction can be used to prepare Ag2O powder with properties suitable for several uses including as a fine grained conductive paste filler.",
                    "score": 0.853217601776123
                },
                {
                    "id": 2035754,
                    "contents": "Metalloid\nParry RW, Steiner LE, Tellefsen RL & Dietz PM 1970, Chemistry: Experimental Foundations, Prentice-Hall/Martin Educational, Sydney, Partington 1944, A Text-book of Inorganic Chemistry, 5th ed., Macmillan, London Pashaey BP & Seleznev VV 1973, 'Magnetic Susceptibility of Gallium-Indium Alloys in Liquid State', Russian Physics Journal, vol. 16, no. 4, pp. 565–66, Patel MR 2012, Introduction to Electrical Power and Power Electronics CRC Press, Boca Raton, Paul RC, Puri JK, Sharma RD & Malhotra KC 1971, 'Unusual Cations of Arsenic', Inorganic and Nuclear Chemistry Letters, vol. 7, no. 8, pp. 725–28, Pauling L 1988, General Chemistry, Dover Publications, New York, Pearson WB 1972, The Crystal Chemistry and Physics of Metals and Alloys, Wiley-Interscience, New York, Perry DL 2011, Handbook of Inorganic Compounds, 2nd ed., CRC Press, Boca Raton, Florida,",
                    "score": 0.8528698086738586
                },
                {
                    "id": 1228311,
                    "contents": "Silver\nBy far the most important oxidation state for silver in complexes is +1. The Ag+ cation is diamagnetic, like its homologues Cu+ and Au+, as all three have closed-shell electron configurations with no unpaired electrons: its complexes are colourless provided the ligands are not too easily polarized such as I−. Ag+ forms salts with most anions, but it is reluctant to coordinate to oxygen and thus most of these salts are insoluble in water: the exceptions are the nitrate, perchlorate, and fluoride. The tetracoordinate tetrahedral aqueous ion [Ag(H2O)4]+ is known, but the characteristic geometry for the Ag+ cation is 2-coordinate linear. For example, silver chloride dissolves readily in excess aqueous ammonia to form [Ag(NH3)2]+; silver salts are dissolved in photography due to the formation of the thiosulfate complex [Ag(S2O3)2]3−; and cyanide extraction for silver (and gold) works by the formation of the complex [Ag(CN)2]−. Silver cyanide forms the linear polymer {Ag–C≡N→Ag–C≡N→};",
                    "score": 0.8528382182121277
                },
                {
                    "id": 11448403,
                    "contents": "Periodic trends\nMetallic and non-metallic properties Metallic properties generally increase down groups as decreasing attraction between the nuclei and outermost electrons cause these electrons to be more loosely bound and thus able to conduct heat and electricity. Across each period, from left to right, the increasing attraction between the nuclei and the outermost electrons causes the metallic character to decrease. Conversely, non-metallic character generally decreases down groups and increases across a period. Most metals are lustrous (when freshly fractured, polished or prepared), ductile, malleable and sonorous, while most nonmetals are not. See also List of elements by atomic properties History of the periodic table References Further reading ChemWiki - Periodic Trends Chemistry LibreTexts Periodic Trends Properties of chemical elements",
                    "score": 0.852802574634552
                },
                {
                    "id": 4810349,
                    "contents": "Silver chloride\nStructure and reactions The solid adopts the fcc NaCl structure, in which each Ag+ ion is surrounded by an octahedron of six chloride ligands. AgF and AgBr crystallize similarly. However, the crystallography depends on the condition of crystallization, primarily free silver ion concentration, as is shown on the pictures left (greyish tint and metallic lustre are due to partly reduced silver). AgCl dissolves in solutions containing ligands such as chloride, cyanide, triphenylphosphine, thiosulfate, thiocyanate and ammonia. Silver chloride reacts with these ligands according to the following illustrative equations: AgCl (s) + Cl^- (aq) -> AgCl2^- (aq) AgCl (s) + 2 S2O3^2- (aq) ->(Ag(S2O3)2)^3- (aq) + Cl^- (aq) AgCl (s) + 2 NH3(aq) -> Ag(NH3)2+ (aq) + Cl^- (aq) Silver chloride does not react with nitric acid. Most complexes derived from AgCl are two-, three-, and, in rare cases, four-coordinate, adopting linear, trigonal planar, and tetrahedral coordination geometries, respectively.",
                    "score": 0.8523654937744141
                },
                {
                    "id": 16360222,
                    "contents": "Silver nanoparticle\nand grows as more silver atoms diffuse through the solution and attach to the surface When the dissolved concentration of atomic silver decreases enough, it is no longer possible for enough atoms to bind together to form a stable nucleus. At this nucleation threshold, new nanoparticles stop being formed, and the remaining dissolved silver is absorbed by diffusion into the growing nanoparticles in the solution.",
                    "score": 0.852064847946167
                },
                {
                    "id": 8323512,
                    "contents": "Silver oxide\nStructure and properties Ag2O features linear, two-coordinate Ag centers linked by tetrahedral oxides. It is isostructural with Cu2O. It \"dissolves\" in solvents that degrade it. It is slightly soluble in water due to the formation of the ion and possibly related hydrolysis products. It is soluble in ammonia solution, producing active compound of Tollens' reagent. A slurry of Ag2O is readily attacked by acids: Ag2O + 2 HX -> 2 AgX + H2O where HX = HF, HCl, HBr, HI, or CF3COOH. It will also react with solutions of alkali chlorides to precipitate silver chloride, leaving a solution of the corresponding alkali hydroxide. Despite the photosensitivity of many silver compounds, silver oxide is not photosensitive, although it readily decomposes at temperatures above 280 °C.",
                    "score": 0.8516625165939331
                },
                {
                    "id": 2155620,
                    "contents": "Nonmetal\nMacKay KM, MacKay RA & Henderson W 2002, Introduction to Modern Inorganic Chemistry, 6th ed., Nelson Thornes, Cheltenham, Mackin M 2014, Study Guide to Accompany Basics for Chemistry, Elsevier Science, Saint Louis, Maosheng M 2020, \"Noble gases in solid compounds show a rich display of chemistry with enough pressure\", Frontiers in Chemistry, vol. 8, Massey AG 2000, Main group chemistry, 2nd ed., John Wiley & Sons, Chichester, Masterton W, Hurley C & Neth E 2011, Chemistry: Principles and Reactions, 7th ed., Brooks/Cole, Belmont, California, Matson M & Orbaek AW 2013, Inorganic Chemistry for Dummies, John Wiley & Sons: Hoboken, Matula RA 1979, \"Electrical resistivity of copper, gold, palladium, and silver\", Journal of Physical and Chemical Reference Data, vol. 8, no. 4, Mazej Z 2020, \"Noble-gas chemistry more than half a century after the first report of the noble-gas compound\", Molecules, vol. 25, no. 13, , ,",
                    "score": 0.8504911065101624
                },
                {
                    "id": 833929,
                    "contents": "Nihonium\npredicted to be more similar to silver(I) than thallium(I): the Nh+ ion is expected to more willingly bind anions, so that NhCl should be quite soluble in excess hydrochloric acid or ammonia; TlCl is not. In contrast to Tl+, which forms the strongly basic hydroxide (TlOH) in solution, the Nh+ cation should instead hydrolyse all the way to the amphoteric oxide Nh2O, which would be soluble in aqueous ammonia and weakly soluble in water.",
                    "score": 0.8500361442565918
                },
                {
                    "id": 1228300,
                    "contents": "Silver\nThe common oxidation states of silver are (in order of commonness): +1 (the most stable state; for example, silver nitrate, AgNO3); +2 (highly oxidising; for example, silver(II) fluoride, AgF2); and even very rarely +3 (extreme oxidising; for example, potassium tetrafluoroargentate(III), KAgF4). The +3 state requires very strong oxidising agents to attain, such as fluorine or peroxodisulfate, and some silver(III) compounds react with atmospheric moisture and attack glass. Indeed, silver(III) fluoride is usually obtained by reacting silver or silver monofluoride with the strongest known oxidizing agent, krypton difluoride. Compounds Oxides and chalcogenides",
                    "score": 0.8485823273658752
                },
                {
                    "id": 19407798,
                    "contents": "Herbert Newby McCoy\nAs early as 1911, McCoy introduced the term \"synthetic metals\". McCoy and William C. Moore attempted to use electrolysis to produce a metallic species from tetramethylammonium salts. Extending the work of Thomas Johann Seebeck (1770-1831) to organic quaternary amines, instead of simple ammonium salts, they reported what was believed to be the first organic metal. Electrolysis produced of a crystalline solid with a metallic luster which displayed electrical conductivity similar to that of metals. It was believed to be a mercury amalgam with the general formula HgN(CH3)4 until 1986, when Allen J. Bard proposed a more compelling explanation for the results.",
                    "score": 0.8472887873649597
                },
                {
                    "id": 2828691,
                    "contents": "Silver sulfide\nSilver sulfide is a component of classical qualitative inorganic analysis. References External links Tarnishing of Silver: A Short Review V&A Conservation Journal Images of silver whiskers NASA Sulfides Silver compounds Semiconductors",
                    "score": 0.8470524549484253
                },
                {
                    "id": 2155632,
                    "contents": "Nonmetal\nSteudel R 1977, Chemistry of the Non-metals: With an Introduction to atomic Structure and Chemical Bonding, Walter de Gruyter, Berlin, Steudel R & Eckert B 2003, \"Solid sulfur allotropes\", in Steudel R (ed.), Elemental Sulfur and Sulfur-rich Compounds I, Springer-Verlag, Berlin, Stewart D, Chemicool Periodic Table, www.chemicool.com. accessed July 10, 2021 Stott RWA 1956, Companion to Physical and Inorganic Chemistry, Longmans, Green and Co, London Strathern P 2000, Mendeleyev's dream: The Quest for the Elements, Hamish Hamilton, London, Su et al. 2020, \"Advances in photonics of recently developed Xenes\", Nanophotonics, vol. 9, no. 7, Suresh CH & Koga NA 2001, \"A consistent approach toward atomic radii”, Journal of Physical Chemistry A, vol. 105, no. 24. Tang et al. 2021, \"Synthesis of paracrystalline diamond\", Nature, vol. 599, pp. 605–610, Taylor MD 1960, First Principles of Chemistry, Van Nostrand, Princeton",
                    "score": 0.8460643291473389
                },
                {
                    "id": 526299,
                    "contents": "Period 5 element\nSilver Silver is a metallic chemical element with the chemical symbol Ag (, from the Indo-European root *arg- for \"grey\" or \"shining\") and atomic number 47. A soft, white, lustrous transition metal, it has the highest electrical conductivity of any element and the highest thermal conductivity of any metal. The metal occurs naturally in its pure, free form (native silver), as an alloy with gold and other metals, and in minerals such as argentite and chlorargyrite. Most silver is produced as a byproduct of copper, gold, lead, and zinc refining.",
                    "score": 0.8459681272506714
                },
                {
                    "id": 8801086,
                    "contents": "Silver(I,III) oxide\nStructure Although its empirical formula, AgO, suggests that the compound tetrasilver tetraoxide has silver in the +2 oxidation state, each unit has two monovalent silver atoms bonded to an oxygen atom, and two trivalent silver atoms bonded to three oxygen atoms, and it is in fact diamagnetic. X-ray diffraction studies show that the silver atoms adopt two different coordination environments, one having two collinear oxide neighbours and the other four coplanar oxide neighbours. tetrasilver tetraoxide is therefore formulated as AgIAgIIIO2 or Ag2O·Ag2O3. It has previously been called silver peroxide, which is incorrect since it does not contain the peroxide ion, O22−. References Silver compounds Mixed valence compounds Transition metal oxides",
                    "score": 0.8456156253814697
                },
                {
                    "id": 2035743,
                    "contents": "Metalloid\nMarković N, Christiansen C & Goldman AM 1998, 'Thickness-Magnetic Field Phase Diagram at the Superconductor-Insulator Transition in 2D', Physical Review Letters, vol. 81, no. 23, pp. 5217–20, Massey AG 2000, Main Group Chemistry, 2nd ed., John Wiley & Sons, Chichester, Masterton WL & Slowinski EJ 1977, Chemical Principles, 4th ed., W. B. Saunders, Philadelphia, Matula RA 1979, 'Electrical Resistivity of Copper, Gold, Palladium, and Silver,' Journal of Physical and Chemical Reference Data, vol. 8, no. 4, pp. 1147–298, McKee DW 1984, 'Tellurium – An Unusual Carbon Oxidation Catalyst', Carbon, vol. 22, no. 6, , pp. 513–16 McMurray J & Fay RC 2009, General Chemistry: Atoms First, Prentice Hall, Upper Saddle River, New Jersey, McQuarrie DA & Rock PA 1987, General Chemistry, 3rd ed., WH Freeman, New York, Mellor JW 1964, A Comprehensive Treatise on Inorganic and Theoretical Chemistry, vol. 9, John Wiley, New York",
                    "score": 0.8454654216766357
                },
                {
                    "id": 16360260,
                    "contents": "Silver nanoparticle\nNOTE: This paragraph is a general description of nanoparticle properties for catalysis; it is not exclusive to silver nanoparticles. The size of a nanoparticle greatly determines the properties that it exhibits due to various quantum effects. Additionally, the chemical environment of the nanoparticle plays a large role on the catalytic properties. With this in mind, it is important to note that heterogeneous catalysis takes place by adsorption of the reactant species to the catalytic substrate. When polymers, complex ligands, or surfactants are used to prevent coalescence of the nanoparticles, the catalytic ability is frequently hindered due to reduced adsorption ability. However, these compounds can also be used in such a way that the chemical environment enhances the catalytic ability.",
                    "score": 0.845352053642273
                },
                {
                    "id": 16360263,
                    "contents": "Silver nanoparticle\nSilver alloy – synergistic oxidation of carbon monoxide",
                    "score": 0.8451268672943115
                },
                {
                    "id": 16360221,
                    "contents": "Silver nanoparticle\nThe most common methods for nanoparticle synthesis fall under the category of wet chemistry, or the nucleation of particles within a solution. This nucleation occurs when a silver ion complex, usually AgNO3 or AgClO4, is reduced to colloidal Ag in the presence of a reducing agent. When the concentration increases enough, dissolved metallic silver ions bind together to form a stable surface. The surface is energetically unfavorable when the cluster is small, because the energy gained by decreasing the concentration of dissolved particles is not as high as the energy lost from creating a new surface. When the cluster reaches a certain size, known as the critical radius, it becomes energetically favorable, and thus stable enough to continue to grow. This nucleus then remains in the system and grows as more silver atoms diffuse through the solution and attach to the surface When the dissolved concentration of atomic silver decreases enough, it is no longer possible for enough atoms",
                    "score": 0.8448609709739685
                },
                {
                    "id": 13080108,
                    "contents": "Rubidium silver iodide\nThe researchers have recently discovered that the ionic conductivity of RbAg4I5 does not change with varying relative humidity. Rubidium silver iodide family is a group of compounds and solid solutions that are isostructural with the RbAg4I5 alpha modification. Examples of such advanced superionic conductors with mobile Ag+ and Cu+ cations include KAg4I5, NH4Ag4I5, K1−xCsxAg4I5, Rb1−xCsxAg4I5, CsAg4Br1−xI2+x, CsAg4ClBr2I2, CsAg4Cl3I2, RbCu4Cl3I2 and KCu4I5. References Metal halides Iodides Rubidium compounds Silver compounds Alkali metal iodides",
                    "score": 0.8439577221870422
                },
                {
                    "id": 27847291,
                    "contents": "Viola Birss\nEarly life and education Birss grew up in Crowsnest Pass, Alberta. She moved to Calgary at the age of five. When she was deciding what to study at college she felt that physics was \"too abstract\", and biology \"too descriptive\", so settled on chemistry. Having grown up with the wilderness close to her home, Birss was always aware of the environment, and interested in identifying clean ways of storing, converting and using energy. This attracted her to materials science and electrochemistry. Birss earned her doctorate at the University of Auckland as a Commonwealth Scholar, where she studied anodic films on silver electrodes. She was a postdoctoral researcher at the University of Ottawa, where she worked on the supercapacitive properties of hydrous metal oxides. During this post she specialised in Ruthenium(IV) oxide.",
                    "score": 0.8437526822090149
                },
                {
                    "id": 28969741,
                    "contents": "Metallization pressure\nMetallization pressure is the pressure required for a non-metallic chemical element to become a metal. Every material is predicted to turn into a metal if the pressure is high enough, and temperature low enough. See also Metallic hydrogen References Physical chemistry Allotropes",
                    "score": 0.8433604836463928
                },
                {
                    "id": 3685651,
                    "contents": "Silver bromide\nAgNO3(aq) + KBr(aq) → AgBr(s)+ KNO3(aq) Although less convenient, the salt can also be prepared directly from its elements. Modern preparation of a simple, light-sensitive surface involves forming an emulsion of silver halide crystals in a gelatine, which is then coated onto a film or other support. The crystals are formed by precipitation in a controlled environment to produce small, uniform crystals (typically < 1 μm in diameter and containing ~1012 Ag atoms) called grains. Reactions Silver bromide reacts readily with liquid ammonia to generate a variety of ammine complexes, like and . In general: AgBr + m NH3 + (n - 1) → Silver bromide reacts with triphenylphosphine to give a tris(triphenylphosphine) product: Physical properties Crystal structure AgF, AgCl, and AgBr all have face-centered cubic (fcc) rock-salt (NaCl) lattice structure with the following lattice parameters:",
                    "score": 0.8433458805084229
                },
                {
                    "id": 3153685,
                    "contents": "Silver iodide\nStructure The structure adopted by silver iodide is temperature dependent: Below 420 K, the β phase of AgI, with the wurtzite structure, is most stable. This phase is encountered in nature as the mineral iodargyrite. Above 420 K, the α phase becomes more stable. This motif is a body-centered cubic structure which has the silver centers distributed randomly between 6 octahedral, 12 tetrahedral and 24 trigonal sites. At this temperature, Ag+ ions can move rapidly through the solid, allowing fast ion conduction. The transition between the β and α forms represents the melting of the silver (cation) sublattice. The entropy of fusion for α-AgI is approximately half that for sodium chloride (a typical ionic solid). This can be rationalized by considering the AgI crystalline lattice to have already \"partly melted\" in the transition between α and β polymorphs. A metastable γ phase also exists below 420 K with the zinc blende structure.",
                    "score": 0.8426069021224976
                },
                {
                    "id": 2035722,
                    "contents": "Metalloid\nGray T 2010, 'Metalloids (7)', viewed 8 February 2013 Gray T, Whitby M & Mann N 2011, Mohs Hardness of the Elements, viewed 12 Feb 2012 Greaves GN, Knights JC & Davis EA 1974, 'Electronic Properties of Amorphous Arsenic', in J Stuke & W Brenig (eds), Amorphous and Liquid Semiconductors: Proceedings, vol. 1, Taylor & Francis, London, pp. 369–74, Greenwood NN 2001, 'Main Group Element Chemistry at the Millennium', Journal of the Chemical Society, Dalton Transactions, issue 14, pp. 2055–66, Greenwood NN & Earnshaw A 2002, Chemistry of the Elements, 2nd ed., Butterworth-Heinemann, Guan PF, Fujita T, Hirata A, Liu YH & Chen MW 2012, 'Structural Origins of the Excellent Glass-forming Ability of Pd40Ni40P20', Physical Review Letters, vol. 108, no. 17, pp. 175501–1–5, Gunn G (ed.) 2014, Critical Metals Handbook,John Wiley & Sons, Chichester, West Sussex,",
                    "score": 0.8424323797225952
                },
                {
                    "id": 98944,
                    "contents": "Silver nitrate\n(aq) + (aq) → AgX(s) where = , , or . Other silver salts with non-coordinating anions, namely silver tetrafluoroborate and silver hexafluorophosphate are used for more demanding applications. Similarly, this reaction is used in analytical chemistry to confirm the presence of chloride, bromide, or iodide ions. Samples are typically acidified with dilute nitric acid to remove interfering ions, e.g. carbonate ions and sulfide ions. This step avoids confusion of silver sulfide or silver carbonate precipitates with that of silver halides. The color of precipitate varies with the halide: white (silver chloride), pale yellow/cream (silver bromide), yellow (silver iodide). AgBr and especially AgI photo-decompose to the metal, as evidence by a grayish color on exposed samples.",
                    "score": 0.842313826084137
                },
                {
                    "id": 1104616,
                    "contents": "Faraday constant\nThe value of F was first determined by weighing the amount of silver deposited in an electrochemical reaction in which a measured current was passed for a measured time, and using Faraday's law of electrolysis. 2019 redefinition Since the 2019 redefinition of SI base units, which introduced exactly defined values for the elementary charge and the mole, the Faraday constant is exactly e × (1 mol) mol−1 = × = . Other common units 96.485 kJ per volt–gram-equivalent 23.061 kcal per volt–gram-equivalent 26.801 A·h/mol Faraday unit of charge Related to Faraday's constant is the \"faraday\", a unit of electrical charge. It is much less common than the coulomb, but sometimes used in electrochemistry. One faraday of charge is the magnitude of the charge of one mole of electrons, i.e. Expressed in faradays, the Faraday constant F equals \"1 faraday of charge per mole\". This faraday unit is not to be confused with the farad, an unrelated unit of capacitance ().",
                    "score": 0.8419702053070068
                },
                {
                    "id": 1867501,
                    "contents": "Metallic bonding\nMetals are insoluble in water or organic solvents, unless they undergo a reaction with them. Typically, this is an oxidation reaction that robs the metal atoms of their itinerant electrons, destroying the metallic bonding. However metals are often readily soluble in each other while retaining the metallic character of their bonding. Gold, for example, dissolves easily in mercury, even at room temperature. Even in solid metals, the solubility can be extensive. If the structures of the two metals are the same, there can even be complete solid solubility, as in the case of electrum, an alloy of silver and gold. At times, however, two metals will form alloys with different structures than either of the two parents. One could call these materials metal compounds. But, because materials with metallic bonding are typically not molecular, Dalton's law of integral proportions is not valid; and often a range of stoichiometric ratios can be achieved. It is better to abandon such concepts as",
                    "score": 0.8416920900344849
                },
                {
                    "id": 8179693,
                    "contents": "Barium oxide (data page)\nThis page provides supplementary chemical data on barium oxide. Material Safety Data Sheet SDS from Millipore Sigma Structure and properties Thermodynamic properties Spectral data References Chemical data pages Chemical data pages cleanup",
                    "score": 0.8416553735733032
                },
                {
                    "id": 28763056,
                    "contents": "List of nonmetal monographs\nSteudel R 2020, Chemistry of the Non-metals: Syntheses - Structures - Bonding - Applications, in collaboration with D Scheschkewitz, Berlin, Walter de Gruyter, . ▲ Twenty-three nonmetals, including B, Si, Ge, As, Se, Te, and At but not Sb (nor Po). The nonmetals are identified on the basis of their electrical conductivity at absolute zero putatively being close to zero, rather than finite as in the case of metals. That does not work for As however, which has the electronic structure of a semimetal (like Sb). Halka M & Nordstrom B 2010, \"Nonmetals\", Facts on File, New York, A reading level 9+ book covering H, C, N, O, P, S, Se. Complementary books by the same authors examine (a) the post-transition metals (Al, Ga, In, Tl, Sn, Pb and Bi) and metalloids (B, Si, Ge, As, Sb, Te and Po); and (b) the halogens and noble gases. Woolins JD 1988, Non-Metal Rings, Cages and Clusters, John Wiley & Sons, Chichester, .",
                    "score": 0.8415119647979736
                },
                {
                    "id": 9196099,
                    "contents": "Silver sulfate\nSilver sulfate is the inorganic compound with the formula Ag2SO4. It is a white solid with low solubility in water. Preparation and structure Silver sulfate precipitates as a solid when an aqueous solution of silver nitrate is treated with sulfuric acid: 2AgNO3 + H2SO4 → Ag2SO4 + 2HNO3 It is purified by recrystallization from concentrated sulfuric acid, a step that expels traces of nitrate. Silver sulfate and anhydrous sodium sulfate adopt the same structure. Silver(II) sulfate The synthesis of silver(II) sulfate (AgSO4) with a divalent silver ion instead of a monovalent silver ion was first reported in 2010 by adding sulfuric acid to silver(II) fluoride (HF escapes). It is a black solid that decomposes exothermally at 120 °C with evolution of oxygen and the formation of the pyrosulfate. References Silver compounds Sulfates",
                    "score": 0.8406926393508911
                },
                {
                    "id": 8323513,
                    "contents": "Silver oxide\nDespite the photosensitivity of many silver compounds, silver oxide is not photosensitive, although it readily decomposes at temperatures above 280 °C. Applications This oxide is used in silver-oxide batteries. In organic chemistry, silver oxide is used as a mild oxidizing agent. For example, it oxidizes aldehydes to carboxylic acids. Such reactions often work best when the silver oxide is prepared in situ from silver nitrate and alkali hydroxide. References External links Annealing of Silver Oxide – Demonstration experiment: Instruction and video Silver compounds Transition metal oxides",
                    "score": 0.8406639099121094
                },
                {
                    "id": 16360231,
                    "contents": "Silver nanoparticle\nParticles formed by reduction must have their surfaces stabilized to prevent undesirable particle agglomeration (when multiple particles bond together), growth, or coarsening. The driving force for these phenomena is the minimization of surface energy (nanoparticles have a large surface to volume ratio). This tendency to reduce surface energy in the system can be counteracted by adding species which will adsorb to the surface of the nanoparticles and lowers the activity of the particle surface thus preventing particle agglomeration according to the DLVO theory and preventing growth by occupying attachment sites for metal atoms. Chemical species that adsorb to the surface of nanoparticles are called ligands. Some of these surface stabilizing species are: NaBH4 in large amounts, poly(vinyl pyrrolidone) (PVP), sodium dodecyl sulfate (SDS), and/or dodecanethiol.",
                    "score": 0.8404167294502258
                },
                {
                    "id": 1228317,
                    "contents": "Silver\nSilver forms alloys with most other elements on the periodic table. The elements from groups 1–3, except for hydrogen, lithium, and beryllium, are very miscible with silver in the condensed phase and form intermetallic compounds; those from groups 4–9 are only poorly miscible; the elements in groups 10–14 (except boron and carbon) have very complex Ag–M phase diagrams and form the most commercially important alloys; and the remaining elements on the periodic table have no consistency in their Ag–M phase diagrams. By far the most important such alloys are those with copper: most silver used for coinage and jewellery is in reality a silver–copper alloy, and the eutectic mixture is used in vacuum brazing. The two metals are completely miscible as liquids but not as solids; their importance in industry comes from the fact that their properties tend to be suitable over a wide range of variation in silver and copper concentration, although most useful alloys tend to be richer in silver than",
                    "score": 0.840270459651947
                },
                {
                    "id": 26042262,
                    "contents": "Elisabeth Gwinn\nSelected publications In the area of silver nanoclusters: Prior research endeavors: Awards Lifetime Mentor Award of the American Association for the Advancement of Science, 2019 References American physicists American women physicists Living people University of California, Santa Barbara faculty Harvard University alumni Swarthmore College alumni Year of birth missing (living people) 21st-century American women",
                    "score": 0.8400443196296692
                },
                {
                    "id": 1114577,
                    "contents": "Solubility equilibrium\na considerable reduction from . In gravimetric analysis for silver, the reduction in solubility due to the common ion effect is used to ensure \"complete\" precipitation of AgCl. Particle size effect The thermodynamic solubility constant is defined for large monocrystals. Solubility will increase with decreasing size of solute particle (or droplet) because of the additional surface energy. This effect is generally small unless particles become very small, typically smaller than 1 μm. The effect of the particle size on solubility constant can be quantified as follows: where *KA is the solubility constant for the solute particles with the molar surface area A, *KA→0 is the solubility constant for substance with molar surface area tending to zero (i.e., when the particles are large), γ is the surface tension of the solute particle in the solvent, Am is the molar surface area of the solute (in m2/mol), R is the universal gas constant, and T is the absolute temperature.",
                    "score": 0.8397111892700195
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_22",
        "question": "When alkali metals dissolve in liquid ammonia, their atoms each lose an electron and give rise to a deep-blue solution that contains unpaired electrons occupying cavities in the solvent. These 'metal-ammonia solutions' have a maximum absorption at $1500 \\mathrm{~nm}$. Supposing that the absorption is due to the excitation of an electron in a spherical square well from its ground state to the next-higher state (see the preceding problem for information), what is the radius of the cavity?",
        "golden_answers": [
            " 0.69"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1555723,
                    "contents": "Alkali metal\nelectrical conductivity of these solutions. At low concentrations (below 3 M), the solution is dark blue and has ten times the conductivity of aqueous sodium chloride; at higher concentrations (above 3 M), the solution is copper-coloured and has approximately the conductivity of liquid metals like mercury. In addition to the alkali metal amide salt and solvated electrons, such ammonia solutions also contain the alkali metal cation (M+), the neutral alkali metal atom (M), diatomic alkali metal molecules (M2) and alkali metal anions (M−). These are unstable and eventually become the more thermodynamically stable alkali metal amide and hydrogen gas. Solvated electrons are powerful reducing agents and are often used in chemical synthesis.",
                    "score": 0.9016894698143005
                },
                {
                    "id": 1555722,
                    "contents": "Alkali metal\nThe alkali metals dissolve slowly in liquid ammonia, forming ammoniacal solutions of solvated metal cation M+ and solvated electron e−, which react to form hydrogen gas and the alkali metal amide (MNH2, where M represents an alkali metal): this was first noted by Humphry Davy in 1809 and rediscovered by W. Weyl in 1864. The process may be speeded up by a catalyst. Similar solutions are formed by the heavy divalent alkaline earth metals calcium, strontium, barium, as well as the divalent lanthanides, europium and ytterbium. The amide salt is quite insoluble and readily precipitates out of solution, leaving intensely coloured ammonia solutions of the alkali metals. In 1907, Charles Krause identified the colour as being due to the presence of solvated electrons, which contribute to the high electrical conductivity of these solutions. At low concentrations (below 3 M), the solution is dark blue and has ten times the conductivity of aqueous sodium chloride; at higher concentrations (above",
                    "score": 0.8965262174606323
                },
                {
                    "id": 1567780,
                    "contents": "Ammonia\nSolubility of salts Liquid ammonia is an ionising solvent, although less so than water, and dissolves a range of ionic compounds, including many nitrates, nitrites, cyanides, thiocyanates, metal cyclopentadienyl complexes and metal bis(trimethylsilyl)amides. Most ammonium salts are soluble and act as acids in liquid ammonia solutions. The solubility of halide salts increases from fluoride to iodide. A saturated solution of ammonium nitrate (Divers' solution, named after Edward Divers) contains 0.83 mol solute per mole of ammonia and has a vapour pressure of less than 1 bar even at . Solutions of metals Liquid ammonia will dissolve all of the alkali metals and other electropositive metals such as Ca, Sr, Ba, Eu, and Yb (also Mg using an electrolytic process). At low concentrations (<0.06 mol/L), deep blue solutions are formed: these contain metal cations and solvated electrons, free electrons that are surrounded by a cage of ammonia molecules.",
                    "score": 0.8917837142944336
                },
                {
                    "id": 1555714,
                    "contents": "Alkali metal\nThey may be obtained directly from the elements in liquid ammonia or when air is not present, and are colourless, water-soluble compounds that air oxidises quickly back to selenium or tellurium. The alkali metal polonides are all ionic compounds containing the Po2− ion; they are very chemically stable and can be produced by direct reaction of the elements at around 300–400 °C.",
                    "score": 0.8763787746429443
                },
                {
                    "id": 1555658,
                    "contents": "Alkali metal\nbecause of their low effective nuclear charge and the ability to attain a noble gas configuration by losing just one electron. Not only do the alkali metals react with water, but also with proton donors like alcohols and phenols, gaseous ammonia, and alkynes, the last demonstrating the phenomenal degree of their reactivity. Their great power as reducing agents makes them very useful in liberating other metals from their oxides or halides.",
                    "score": 0.8753153085708618
                },
                {
                    "id": 9275422,
                    "contents": "Solvated electron\nAmmonia solutions Liquid ammonia will dissolve all of the alkali metals and other electropositive metals such as Ca, Sr, Ba, Eu, and Yb (also Mg using an electrolytic process), giving characteristic blue solutions. For alkali metals in liquid ammonia, the solution is blue when dilute and copper-colored when more concentrated (> 3 molar). These solutions conduct electricity. The blue colour of the solution is due to ammoniated electrons, which absorb energy in the visible region of light. The diffusivity of the solvated electron in liquid ammonia can be determined using potential-step chronoamperometry. Solvated electrons in ammonia are the anions of salts called electrides. Na + 6 NH3 → [Na(NH3)6]+e- The reaction is reversible: evaporation of the ammonia solution produces a film of metallic sodium. Case study: Li in NH3",
                    "score": 0.872930645942688
                },
                {
                    "id": 1555704,
                    "contents": "Alkali metal\nLithium, the lightest of the alkali metals, is the only alkali metal which reacts with nitrogen at standard conditions, and its nitride is the only stable alkali metal nitride. Nitrogen is an unreactive gas because breaking the strong triple bond in the dinitrogen molecule (N2) requires a lot of energy. The formation of an alkali metal nitride would consume the ionisation energy of the alkali metal (forming M+ ions), the energy required to break the triple bond in N2 and the formation of N3− ions, and all the energy released from the formation of an alkali metal nitride is from the lattice energy of the alkali metal nitride. The lattice energy is maximised with small, highly charged ions; the alkali metals do not form highly charged ions, only forming ions with a charge of +1, so only lithium, the smallest alkali metal, can release enough lattice energy to make the reaction with nitrogen exothermic, forming lithium nitride. The reactions of the other alkali metals with nitrogen would",
                    "score": 0.8710095882415771
                },
                {
                    "id": 9275427,
                    "contents": "Solvated electron\nHistory The observation of the color of metal-electride solutions is generally attributed to Humphry Davy. In 1807–1809, he examined the addition of grains of potassium to gaseous ammonia (liquefaction of ammonia was invented in 1823). James Ballantyne Hannay and J. Hogarth repeated the experiments with sodium in 1879–1880. W. Weyl in 1864 and C. A. Seely in 1871 used liquid ammonia, whereas Hamilton Cady in 1897 related the ionizing properties of ammonia to that of water. Charles A. Kraus measured the electrical conductance of metal ammonia solutions and in 1907 attributed it to the electrons liberated from the metal. In 1918, G. E. Gibson and W. L. Argo introduced the solvated electron concept. They noted based on absorption spectra that different metals and different solvents (methylamine, ethylamine) produce the same blue color, attributed to a common species, the solvated electron. In the 1970s, solid salts containing electrons as the anion were characterized. References",
                    "score": 0.8704932332038879
                },
                {
                    "id": 1555652,
                    "contents": "Alkali metal\nThe physical and chemical properties of the alkali metals can be readily explained by their having an ns1 valence electron configuration, which results in weak metallic bonding. Hence, all the alkali metals are soft and have low densities, melting and boiling points, as well as heats of sublimation, vaporisation, and dissociation. They all crystallise in the body-centered cubic crystal structure, and have distinctive flame colours because their outer s electron is very easily excited. The ns1 configuration also results in the alkali metals having very large atomic and ionic radii, as well as very high thermal and electrical conductivity. Their chemistry is dominated by the loss of their lone valence electron in the outermost s-orbital to form the +1 oxidation state, due to the ease of ionising this electron and the very high second ionisation energy. Most of the chemistry has been observed only for the first five members of the group. The chemistry of francium is not well established",
                    "score": 0.8694934248924255
                },
                {
                    "id": 1555661,
                    "contents": "Alkali metal\nIn aqueous solution, the alkali metal ions form aqua ions of the formula [M(H2O)n]+, where n is the solvation number. Their coordination numbers and shapes agree well with those expected from their ionic radii. In aqueous solution the water molecules directly attached to the metal ion are said to belong to the first coordination sphere, also known as the first, or primary, solvation shell. The bond between a water molecule and the metal ion is a dative covalent bond, with the oxygen atom donating both electrons to the bond. Each coordinated water molecule may be attached by hydrogen bonds to other water molecules. The latter are said to reside in the second coordination sphere. However, for the alkali metal cations, the second coordination sphere is not well-defined as the +1 charge on the cation is not high enough to polarise the water molecules in the primary solvation shell enough for them to form strong hydrogen bonds with those in the second coordination sphere, producing a more",
                    "score": 0.8675110340118408
                },
                {
                    "id": 1555750,
                    "contents": "Alkali metal\nAmmonium and derivatives The ammonium ion () has very similar properties to the heavier alkali metals, acting as an alkali metal intermediate between potassium and rubidium, and is often considered a close relative. For example, most alkali metal salts are soluble in water, a property which ammonium salts share. Ammonium is expected to behave stably as a metal ( ions in a sea of delocalised electrons) at very high pressures (though less than the typical pressure where transitions from insulating to metallic behaviour occur around, 100 GPa), and could possibly occur inside the ice giants Uranus and Neptune, which may have significant impacts on their interior magnetic fields. It has been estimated that the transition from a mixture of ammonia and dihydrogen molecules to metallic ammonium may occur at pressures just below 25 GPa. Under standard conditions, ammonium can form a metallic amalgam with mercury.",
                    "score": 0.8670637607574463
                },
                {
                    "id": 1555705,
                    "contents": "Alkali metal\nthe smallest alkali metal, can release enough lattice energy to make the reaction with nitrogen exothermic, forming lithium nitride. The reactions of the other alkali metals with nitrogen would not release enough lattice energy and would thus be endothermic, so they do not form nitrides at standard conditions. Sodium nitride (Na3N) and potassium nitride (K3N), while existing, are extremely unstable, being prone to decomposing back into their constituent elements, and cannot be produced by reacting the elements with each other at standard conditions. Steric hindrance forbids the existence of rubidium or caesium nitride. However, sodium and potassium form colourless azide salts involving the linear anion; due to the large size of the alkali metal cations, they are thermally stable enough to be able to melt before decomposing.",
                    "score": 0.8654874563217163
                },
                {
                    "id": 1555711,
                    "contents": "Alkali metal\nmetals except lithium can form red ozonides (MO3) through low-temperature reaction of the powdered anhydrous hydroxide with ozone: the ozonides may be then extracted using liquid ammonia. They slowly decompose at standard conditions to the superoxides and oxygen, and hydrolyse immediately to the hydroxides when in contact with water. Potassium, rubidium, and caesium also form sesquioxides M2O3, which may be better considered peroxide disuperoxides, .",
                    "score": 0.8616077899932861
                },
                {
                    "id": 9275423,
                    "contents": "Solvated electron\nCase study: Li in NH3 A lithium–ammonia solution at −60 °C is saturated at about 15 mol% metal (MPM). When the concentration is increased in this range electrical conductivity increases from 10−2 to 104 ohm−1cm−1 (larger than liquid mercury). At around 8 MPM, a \"transition to the metallic state\" (TMS) takes place (also called a \"metal-to-nonmetal transition\" (MNMT)). At 4 MPM a liquid-liquid phase separation takes place: the less dense gold-colored phase becomes immiscible from a denser blue phase. Above 8 MPM the solution is bronze/gold-colored. In the same concentration range the overall density decreases by 30%.",
                    "score": 0.859350323677063
                },
                {
                    "id": 1555634,
                    "contents": "Alkali metal\nRubidium and caesium were the first elements to be discovered using the spectroscope, invented in 1859 by Robert Bunsen and Gustav Kirchhoff. The next year, they discovered caesium in the mineral water from Bad Dürkheim, Germany. Their discovery of rubidium came the following year in Heidelberg, Germany, finding it in the mineral lepidolite. The names of rubidium and caesium come from the most prominent lines in their emission spectra: a bright red line for rubidium (from the Latin word rubidus, meaning dark red or bright red), and a sky-blue line for caesium (derived from the Latin word caesius, meaning sky-blue).",
                    "score": 0.8593071699142456
                },
                {
                    "id": 1555763,
                    "contents": "Alkali metal\nThe coinage metals were traditionally regarded as a subdivision of the alkali metal group, due to them sharing the characteristic s1 electron configuration of the alkali metals (group 1: p6s1; group 11: d10s1). However, the similarities are largely confined to the stoichiometries of the +1 compounds of both groups, and not their chemical properties. This stems from the filled d subshell providing a much weaker shielding effect on the outermost s electron than the filled p subshell, so that the coinage metals have much higher first ionisation energies and smaller ionic radii than do the corresponding alkali metals. Furthermore, they have higher melting points, hardnesses, and densities, and lower reactivities and solubilities in liquid ammonia, as well as having more covalent character in their compounds. Finally, the alkali metals are at the top of the electrochemical series, whereas the coinage metals are almost at the very bottom. The coinage metals' filled d shell is much more",
                    "score": 0.858555257320404
                },
                {
                    "id": 1555718,
                    "contents": "Alkali metal\nThe alkali metals also react similarly with hydrogen to form ionic alkali metal hydrides, where the hydride anion acts as a pseudohalide: these are often used as reducing agents, producing hydrides, complex metal hydrides, or hydrogen gas. Other pseudohalides are also known, notably the cyanides. These are isostructural to the respective halides except for lithium cyanide, indicating that the cyanide ions may rotate freely. Ternary alkali metal halide oxides, such as Na3ClO, K3BrO (yellow), Na4Br2O, Na4I2O, and K4Br2O, are also known. The polyhalides are rather unstable, although those of rubidium and caesium are greatly stabilised by the feeble polarising power of these extremely large cations. Coordination complexes",
                    "score": 0.8584968447685242
                },
                {
                    "id": 1555747,
                    "contents": "Alkali metal\ncontrol both electrons. It was expected for some time that liquid hydrogen would show metallic properties; while this has been shown to not be the case, under extremely high pressures, such as those found at the cores of Jupiter and Saturn, hydrogen does become metallic and behaves like an alkali metal; in this phase, it is known as metallic hydrogen. The electrical resistivity of liquid metallic hydrogen at 3000 K is approximately equal to that of liquid rubidium and caesium at 2000 K at the respective pressures when they undergo a nonmetal-to-metal transition.",
                    "score": 0.8579292297363281
                },
                {
                    "id": 20137138,
                    "contents": "Properties of metals, metalloids and nonmetals\nWithin each category, elements can be found with one or two properties very different from the expected norm, or that are otherwise notable. Metals Sodium, potassium, rubidium, caesium, barium, platinum, gold The common notions that \"alkali metal ions (group 1A) always have a +1 charge\" and that \"transition elements do not form anions\" are textbook errors. The synthesis of a crystalline salt of the sodium anion Na− was reported in 1974. Since then further compounds (\"alkalides\") containing anions of all other alkali metals except Li and Fr, as well as that of Ba, have been prepared. In 1943, Sommer reported the preparation of the yellow transparent compound CsAu. This was subsequently shown to consist of caesium cations (Cs+) and auride anions (Au−) although it was some years before this conclusion was accepted. Several other aurides (KAu, RbAu) have since been synthesized, as well as the red transparent compound Cs2Pt which was found to contain Cs+ and Pt2− ions.",
                    "score": 0.8576483130455017
                },
                {
                    "id": 1555676,
                    "contents": "Alkali metal\nThe ionic radii of the alkali metals are much smaller than their atomic radii. This is because the outermost electron of the alkali metals is in a different electron shell than the inner electrons, and thus when it is removed the resulting atom has one fewer electron shell and is smaller. Additionally, the effective nuclear charge has increased, and thus the electrons are attracted more strongly towards the nucleus and the ionic radius decreases. First ionisation energy",
                    "score": 0.8575019836425781
                },
                {
                    "id": 1555709,
                    "contents": "Alkali metal\nThe smaller alkali metals tend to polarise the larger anions (the peroxide and superoxide) due to their small size. This attracts the electrons in the more complex anions towards one of its constituent oxygen atoms, forming an oxide ion and an oxygen atom. This causes lithium to form the oxide exclusively on reaction with oxygen at room temperature. This effect becomes drastically weaker for the larger sodium and potassium, allowing them to form the less stable peroxides. Rubidium and caesium, at the bottom of the group, are so large that even the least stable superoxides can form. Because the superoxide releases the most energy when formed, the superoxide is preferentially formed for the larger alkali metals where the more complex anions are not polarised. (The oxides and peroxides for these alkali metals do exist, but do not form upon direct reaction of the metal with oxygen at standard conditions.) In addition, the small size of the Li+ and O2− ions contributes to their forming a",
                    "score": 0.8572505712509155
                },
                {
                    "id": 1555761,
                    "contents": "Alkali metal\nthe alkali metals' \"group IA\". They are occasionally classified as post-transition metals. Their spectra are analogous to those of the alkali metals. Their monopositive ions are paramagnetic and contribute no colour to their salts, like those of the alkali metals.",
                    "score": 0.8544209003448486
                },
                {
                    "id": 1555715,
                    "contents": "Alkali metal\nHalides, hydrides, and pseudohalides",
                    "score": 0.8542909622192383
                },
                {
                    "id": 1555757,
                    "contents": "Alkali metal\nin the years immediately following its discovery, and was placed just after caesium as the sixth alkali metal in Dmitri Mendeleev's 1869 periodic table and Julius Lothar Meyer's 1868 periodic table. (Mendeleev's 1871 periodic table and Meyer's 1870 periodic table put thallium in its current position in the boron group and left the space below caesium blank.) However, thallium also displays the oxidation state +3, which no known alkali metal displays (although ununennium, the undiscovered seventh alkali metal, is predicted to possibly display the +3 oxidation state). The sixth alkali metal is now considered to be francium. While Tl+ is stabilised by the inert pair effect, this inert pair of 6s electrons is still able to participate chemically, so that these electrons are stereochemically active in aqueous solution. Additionally, the thallium halides (except TlF) are quite insoluble in water, and TlI has an unusual structure because of the presence of the stereochemically active inert",
                    "score": 0.8529177308082581
                },
                {
                    "id": 1555744,
                    "contents": "Alkali metal\nPseudo-alkali metals Many other substances are similar to the alkali metals in their tendency to form monopositive cations. Analogously to the pseudohalogens, they have sometimes been called \"pseudo-alkali metals\". These substances include some elements and many more polyatomic ions; the polyatomic ions are especially similar to the alkali metals in their large size and weak polarising power. Hydrogen The element hydrogen, with one electron per neutral atom, is usually placed at the top of Group 1 of the periodic table for convenience, but hydrogen is not normally considered to be an alkali metal; when it is considered to be an alkali metal, it is because of its atomic properties and not its chemical properties. Under typical conditions, pure hydrogen exists as a diatomic gas consisting of two atoms per molecule (H2); however, the alkali metals form diatomic molecules (such as dilithium, Li2) only at high temperatures, when they are in the gaseous state.",
                    "score": 0.8525927066802979
                },
                {
                    "id": 1555749,
                    "contents": "Alkali metal\nhydrogen species, being the foundation of acid-base chemistry. As an example of hydrogen's unorthodox properties stemming from its unusual electron configuration and small size, the hydrogen ion is very small (radius around 150 fm compared to the 50–220 pm size of most other atoms and ions) and so is nonexistent in condensed systems other than in association with other atoms or molecules. Indeed, transferring of protons between chemicals is the basis of acid-base chemistry. Also unique is hydrogen's ability to form hydrogen bonds, which are an effect of charge-transfer, electrostatic, and electron correlative contributing phenomena. While analogous lithium bonds are also known, they are mostly electrostatic. Nevertheless, hydrogen can take on the same structural role as the alkali metals in some molecular crystals, and has a close relationship with the lightest alkali metals (especially lithium).",
                    "score": 0.852530837059021
                },
                {
                    "id": 13813273,
                    "contents": "Alkali metal halide\nProperties The alkali metal halides exist as colourless crystalline solids, although as finely ground powders appear white. They melt at high temperature, usually several hundred degrees to colorless liquids. Their high melting point reflects their high lattice energies. At still higher temperatures, these liquids evaporate to give gases composed of diatomic molecules. These compounds dissolve in polar solvents to give ionic solutions that contain highly solvated anions and cations. Alkali halides dissolve large amounts of the corresponding alkali metal: caesium is completely miscible at all temperatures above the melting point. The table below provides links to each of the individual articles for these compounds. The numbers beside the compounds show the electronegativity difference between the elements based on the Pauling scale. The higher the number is, the more ionic the solid is. References Further reading Tastes of the alkali metal halides (except fluorides)",
                    "score": 0.8524529933929443
                },
                {
                    "id": 9275424,
                    "contents": "Solvated electron\nOther solvents Alkali metals also dissolve in some small primary amines, such as methylamine and ethylamine and hexamethylphosphoramide, forming blue solutions. THF solutions of diamines are effective. Solvated electron solutions of the alkaline earth metals magnesium, calcium, strontium and barium in ethylenediamine have been used to intercalate graphite with these metals. Water Solvated electrons are involved in the reaction of alkali metals with water, even thought the solvated electron has only a fleeting existence. Below pH = 9.6 the hydrated electron reacts with the hydronium ion giving atomic hydrogen, which in turn can react with the hydrated electron giving hydroxide ion and usual molecular hydrogen H2. Solvated electrons can be found even in the gas phase. This implies their possible existence in the upper atmosphere of Earth and involvement in nucleation and aerosol formation.",
                    "score": 0.8517671823501587
                },
                {
                    "id": 17868739,
                    "contents": "J J Lagowski\nHis research dealt with non-aqueous solutions and organometallic pi-complexes. In 1978 he published a paper in which he described the strange spectroscopic and electrochemical behaviour of caesium and gold solution in liquid ammonia - pale yellow instead of blue colour was observed. This confirmed the existence of the auride ion Au−, which is a rare example of a single noble metal anion. He was the sixth editor of the Journal of Chemical Education (1979–1996). Notes References University of Texas website Year of birth missing 2014 deaths American chemists Alumni of the University of Cambridge University of Illinois at Urbana–Champaign alumni University of Michigan alumni Michigan State University alumni",
                    "score": 0.8515868186950684
                },
                {
                    "id": 1555627,
                    "contents": "Alkali metal\nThe alkali metals are all shiny, soft, highly reactive metals at standard temperature and pressure and readily lose their outermost electron to form cations with charge +1. They can all be cut easily with a knife due to their softness, exposing a shiny surface that tarnishes rapidly in air due to oxidation by atmospheric moisture and oxygen (and in the case of lithium, nitrogen). Because of their high reactivity, they must be stored under oil to prevent reaction with air, and are found naturally only in salts and never as the free elements. Caesium, the fifth alkali metal, is the most reactive of all the metals. All the alkali metals react with water, with the heavier alkali metals reacting more vigorously than the lighter ones.",
                    "score": 0.851454496383667
                },
                {
                    "id": 1555636,
                    "contents": "Alkali metal\nAfter 1869, Dmitri Mendeleev proposed his periodic table placing lithium at the top of a group with sodium, potassium, rubidium, caesium, and thallium. Two years later, Mendeleev revised his table, placing hydrogen in group 1 above lithium, and also moving thallium to the boron group. In this 1871 version, copper, silver, and gold were placed twice, once as part of group IB, and once as part of a \"group VIII\" encompassing today's groups 8 to 11. After the introduction of the 18-column table, the group IB elements were moved to their current position in the d-block, while alkali metals were left in group IA. Later the group's name was changed to group 1 in 1988. The trivial name \"alkali metals\" comes from the fact that the hydroxides of the group 1 elements are all strong alkalis when dissolved in water.",
                    "score": 0.8512694239616394
                },
                {
                    "id": 1555687,
                    "contents": "Alkali metal\nelectrons. As the atoms increase in size going down the group (because their atomic radius increases), the nuclei of the ions move further away from the delocalised electrons and hence the metallic bond becomes weaker so that the metal can more easily melt and boil, thus lowering the melting and boiling points. (The increased nuclear charge is not a relevant factor due to the shielding effect.)",
                    "score": 0.8509750366210938
                },
                {
                    "id": 1560560,
                    "contents": "Americium\nChemical properties Americium metal readily reacts with oxygen and dissolves in aqueous acids. The most stable oxidation state for americium is +3,. The chemistry of americium(III) has many similarities to the chemistry of lanthanide(III) compounds. For example, trivalent americium forms insoluble fluoride, oxalate, iodate, hydroxide, phosphate and other salts. Compounds of americium in oxidation states 2, 4, 5, 6 and 7 have also been studied. This is the widest range that has been observed with actinide elements. The color of americium compounds in aqueous solution is as follows: Am3+ (yellow-reddish), Am4+ (yellow-reddish), AmV; (yellow), AmVI (brown) and AmVII (dark green). The absorption spectra have sharp peaks, due to f-f transitions' in the visible and near-infrared regions. Typically, Am(III) has absorption maxima at ca. 504 and 811 nm, Am(V) at ca. 514 and 715 nm, and Am(VI) at ca. 666 and 992 nm.",
                    "score": 0.8500744104385376
                },
                {
                    "id": 1555628,
                    "contents": "Alkali metal\nAll of the discovered alkali metals occur in nature as their compounds: in order of abundance, sodium is the most abundant, followed by potassium, lithium, rubidium, caesium, and finally francium, which is very rare due to its extremely high radioactivity; francium occurs only in minute traces in nature as an intermediate step in some obscure side branches of the natural decay chains. Experiments have been conducted to attempt the synthesis of ununennium (Uue), which is likely to be the next member of the group; none was successful. However, ununennium may not be an alkali metal due to relativistic effects, which are predicted to have a large influence on the chemical properties of superheavy elements; even if it does turn out to be an alkali metal, it is predicted to have some differences in physical and chemical properties from its lighter homologues.",
                    "score": 0.8500598669052124
                },
                {
                    "id": 1555654,
                    "contents": "Alkali metal\nThe alkali metals are more similar to each other than the elements in any other group are to each other. Indeed, the similarity is so great that it is quite difficult to separate potassium, rubidium, and caesium, due to their similar ionic radii; lithium and sodium are more distinct. For instance, when moving down the table, all known alkali metals show increasing atomic radius, decreasing electronegativity, increasing reactivity, and decreasing melting and boiling points as well as heats of fusion and vaporisation. In general, their densities increase when moving down the table, with the exception that potassium is less dense than sodium. One of the very few properties of the alkali metals that does not display a very smooth trend is their reduction potentials: lithium's value is anomalous, being more negative than the others. This is because the Li+ ion has a very high hydration energy in the gas phase: though the lithium ion disrupts the structure of water significantly, causing a",
                    "score": 0.8492562174797058
                },
                {
                    "id": 1555746,
                    "contents": "Alkali metal\nThe first ionisation energy of hydrogen (1312.0 kJ/mol) is much higher than that of the alkali metals. As only one additional electron is required to fill in the outermost shell of the hydrogen atom, hydrogen often behaves like a halogen, forming the negative hydride ion, and is very occasionally considered to be a halogen on that basis. (The alkali metals can also form negative ions, known as alkalides, but these are little more than laboratory curiosities, being unstable.) An argument against this placement is that formation of hydride from hydrogen is endothermic, unlike the exothermic formation of halides from halogens. The radius of the H− anion also does not fit the trend of increasing size going down the halogens: indeed, H− is very diffuse because its single proton cannot easily control both electrons. It was expected for some time that liquid hydrogen would show metallic properties; while this has been shown to not be the case, under extremely high pressures, such as those",
                    "score": 0.8492016196250916
                },
                {
                    "id": 1567760,
                    "contents": "Ammonia\nmiscible with water. The lone pair makes ammonia a base, a proton acceptor. Ammonia is moderately basic; a 1.0 M aqueous solution has a pH of 11.6, and if a strong acid is added to such a solution until the solution is neutral (pH = 7), 99.4% of the ammonia molecules are protonated. Temperature and salinity also affect the proportion of NH4+. The latter has the shape of a regular tetrahedron and is isoelectronic with methane.",
                    "score": 0.8487326502799988
                },
                {
                    "id": 1567768,
                    "contents": "Ammonia\nAmmonia can act as a ligand in transition metal complexes. It is a pure σ-donor, in the middle of the spectrochemical series, and shows intermediate hard–soft behaviour (see also ECW model). Its relative donor strength toward a series of acids, versus other Lewis bases, can be illustrated by C-B plots. For historical reasons, ammonia is named ammine in the nomenclature of coordination compounds. Some notable ammine complexes include tetraamminediaquacopper(II) ([Cu(NH3)4(H2O)2]2+), a dark blue complex formed by adding ammonia to a solution of copper(II) salts. Tetraamminediaquacopper(II) hydroxide is known as Schweizer's reagent, and has the remarkable ability to dissolve cellulose. Diamminesilver(I) ([Ag(NH3)2]+) is the active species in Tollens' reagent. Formation of this complex can also help to distinguish between precipitates of the different silver halides: silver chloride (AgCl) is soluble in dilute (2 M) ammonia solution, silver bromide (AgBr) is only soluble in concentrated",
                    "score": 0.8486418724060059
                },
                {
                    "id": 28548423,
                    "contents": "Sodium naphthalene\nSodium naphthalene is an organic salt with the chemical formula Na+. In the research laboratory, it is used as a reductant in the synthesis of organic, organometallic, and inorganic chemistry. It is usually generated in situ. When isolated, it invariably crystallizes as a solvate with ligands bound to Na+. Preparation and properties The alkali metal naphthalene salts are prepared by stirring the metal with naphthalene in an ethereal solvent, usually as tetrahydrofuran or dimethoxyethane. The resulting salt is dark green. The anion is a radical, giving a strong EPR signal near g = 2.0. Its deep green color arises from absorptions centered at 463 and 735 nm. Several solvates of sodium naphthalenide have been characterized by X-ray crystallography. The effects are subtle, the outer pair of CH−CH bonds contract by 3 pm and the other nine C−C bonds elongate by 2–3 pm. The net effect is that reduction weakens the bonding.",
                    "score": 0.8483995795249939
                },
                {
                    "id": 1737774,
                    "contents": "Gold\nCommon oxidation states of gold include +1 (gold(I) or aurous compounds) and +3 (gold(III) or auric compounds). Gold ions in solution are readily reduced and precipitated as metal by adding any other metal as the reducing agent. The added metal is oxidized and dissolves, allowing the gold to be displaced from solution and be recovered as a solid precipitate. Rare oxidation states Less common oxidation states of gold include −1, +2, and +5. The −1 oxidation state occurs in aurides, compounds containing the Au− anion. Caesium auride (CsAu), for example, crystallizes in the caesium chloride motif; rubidium, potassium, and tetramethylammonium aurides are also known. Gold has the highest electron affinity of any metal, at 222.8 kJ/mol, making Au− a stable species.",
                    "score": 0.8479688167572021
                },
                {
                    "id": 1555659,
                    "contents": "Alkali metal\nThe second ionisation energy of all of the alkali metals is very high as it is in a full shell that is also closer to the nucleus; thus, they almost always lose a single electron, forming cations. The alkalides are an exception: they are unstable compounds which contain alkali metals in a −1 oxidation state, which is very unusual as before the discovery of the alkalides, the alkali metals were not expected to be able to form anions and were thought to be able to appear in salts only as cations. The alkalide anions have filled s-subshells, which gives them enough stability to exist. All the stable alkali metals except lithium are known to be able to form alkalides, and the alkalides have much theoretical interest due to their unusual stoichiometry and low ionisation potentials. Alkalides are chemically similar to the electrides, which are salts with trapped electrons acting as anions. A particularly striking example of an alkalide is \"inverse sodium hydride\", H+Na− (both ions being",
                    "score": 0.8478813171386719
                },
                {
                    "id": 1128596,
                    "contents": "Nitrogen\n3 Ca + N2 → Ca3N2 3 Mg + 2 NH3 → Mg3N2 + 3 H2 (at 900 °C) 3 Zn(NH2)2 → Zn3N2 + 4 NH3 Many variants on these processes are possible. The most ionic of these nitrides are those of the alkali metals and alkaline earth metals, Li3N (Na, K, Rb, and Cs do not form stable nitrides for steric reasons) and M3N2 (M = Be, Mg, Ca, Sr, Ba). These can formally be thought of as salts of the N3− anion, although charge separation is not actually complete even for these highly electropositive elements. However, the alkali metal azides NaN3 and KN3, featuring the linear anion, are well-known, as are Sr(N3)2 and Ba(N3)2. Azides of the B-subgroup metals (those in groups 11 through 16) are much less ionic, have more complicated structures, and detonate readily when shocked.",
                    "score": 0.8478372693061829
                },
                {
                    "id": 1555663,
                    "contents": "Alkali metal\nthe sodium ion, forming the octahedral [Na(H2O)6]+ ion. While it was previously thought that the heavier alkali metals also formed octahedral hexaaqua ions, it has since been found that potassium and rubidium probably form the [K(H2O)8]+ and [Rb(H2O)8]+ ions, which have the square antiprismatic structure, and that caesium forms the 12-coordinate [Cs(H2O)12]+ ion.",
                    "score": 0.8476811647415161
                },
                {
                    "id": 1555767,
                    "contents": "Alkali metal\nadded to lower the melting point of the mixture. The heavier alkali metals, however, are more typically isolated in a different way, where a reducing agent (typically sodium for potassium and magnesium or calcium for the heaviest alkali metals) is used to reduce the alkali metal chloride. The liquid or gaseous product (the alkali metal) then undergoes fractional distillation for purification. Most routes to the pure alkali metals require the use of electrolysis due to their high reactivity; one of the few which does not is the pyrolysis of the corresponding alkali metal azide, which yields the metal for sodium, potassium, rubidium, and caesium and the nitride for lithium.",
                    "score": 0.8474253416061401
                },
                {
                    "id": 1555677,
                    "contents": "Alkali metal\nThe first ionisation energy of an element or molecule is the energy required to move the most loosely held electron from one mole of gaseous atoms of the element or molecules to form one mole of gaseous ions with electric charge +1. The factors affecting the first ionisation energy are the nuclear charge, the amount of shielding by the inner electrons and the distance from the most loosely held electron from the nucleus, which is always an outer electron in main group elements. The first two factors change the effective nuclear charge the most loosely held electron feels. Since the outermost electron of alkali metals always feels the same effective nuclear charge (+1), the only factor which affects the first ionisation energy is the distance from the outermost electron to the nucleus. Since this distance increases down the group, the outermost electron feels less attraction from the nucleus and thus the first ionisation energy decreases. (This trend is broken in francium due to the",
                    "score": 0.8473598957061768
                },
                {
                    "id": 755643,
                    "contents": "Ununennium\nUnunennium's position as the seventh alkali metal suggests that it would have similar properties to its lighter congeners. However, relativistic effects may cause some of its properties to differ from those expected from a straight application of periodic trends. For example, ununennium is expected to be less reactive than caesium and francium and closer in behavior to potassium or rubidium, and while it should show the characteristic +1 oxidation state of the alkali metals, it is also predicted to show the +3 oxidation state, which is unknown in any other alkali metal. Introduction",
                    "score": 0.8473511934280396
                },
                {
                    "id": 1555760,
                    "contents": "Alkali metal\nThe group 11 metals (or coinage metals), copper, silver, and gold, are typically categorised as transition metals given they can form ions with incomplete d-shells. Physically, they have the relatively low melting points and high electronegativity values associated with post-transition metals. \"The filled d subshell and free s electron of Cu, Ag, and Au contribute to their high electrical and thermal conductivity. Transition metals to the left of group 11 experience interactions between s electrons and the partially filled d subshell that lower electron mobility.\" Chemically, the group 11 metals behave like main-group metals in their +1 valence states, and are hence somewhat related to the alkali metals: this is one reason for their previously being labelled as \"group IB\", paralleling the alkali metals' \"group IA\". They are occasionally classified as post-transition metals. Their spectra are analogous to those of the alkali metals. Their monopositive ions are paramagnetic and",
                    "score": 0.8469308018684387
                },
                {
                    "id": 1555626,
                    "contents": "Alkali metal\nThe alkali metals consist of the chemical elements lithium (Li), sodium (Na), potassium (K), rubidium (Rb), caesium (Cs), and francium (Fr). Together with hydrogen they constitute group 1, which lies in the s-block of the periodic table. All alkali metals have their outermost electron in an s-orbital: this shared electron configuration results in their having very similar characteristic properties. Indeed, the alkali metals provide the best example of group trends in properties in the periodic table, with elements exhibiting well-characterised homologous behaviour. This family of elements is also known as the lithium family after its leading element.",
                    "score": 0.8463036417961121
                },
                {
                    "id": 1555712,
                    "contents": "Alkali metal\nRubidium and caesium can form a great variety of suboxides with the metals in formal oxidation states below +1. Rubidium can form Rb6O and Rb9O2 (copper-coloured) upon oxidation in air, while caesium forms an immense variety of oxides, such as the ozonide CsO3 and several brightly coloured suboxides, such as Cs7O (bronze), Cs4O (red-violet), Cs11O3 (violet), Cs3O (dark green), CsO, Cs3O2, as well as Cs7O2. The last of these may be heated under vacuum to generate Cs2O.",
                    "score": 0.846038818359375
                },
                {
                    "id": 1555680,
                    "contents": "Alkali metal\nThe reactivities of the alkali metals increase going down the group. This is the result of a combination of two factors: the first ionisation energies and atomisation energies of the alkali metals. Because the first ionisation energy of the alkali metals decreases down the group, it is easier for the outermost electron to be removed from the atom and participate in chemical reactions, thus increasing reactivity down the group. The atomisation energy measures the strength of the metallic bond of an element, which falls down the group as the atoms increase in radius and thus the metallic bond must increase in length, making the delocalised electrons further away from the attraction of the nuclei of the heavier alkali metals. Adding the atomisation and first ionisation energies gives a quantity closely related to (but not equal to) the activation energy of the reaction of an alkali metal with another substance. This quantity decreases going down the group, and so does the activation",
                    "score": 0.8448948860168457
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_23",
        "question": "Electron diffraction makes use of electrons with wavelengths comparable to bond lengths. To what speed must an electron be accelerated for it to have a wavelength of $100 \\mathrm{pm}$ ? ",
        "golden_answers": [
            " 7.27"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 200640,
                    "contents": "Electron diffraction\nElectron diffraction is a phenomenon of electron beam bending around atomic structures. This behaviour typical for waves is applicable to electrons due to the wave–particle duality stating that electrons behave as both, particles and waves. Since the diffracted beams interfere, they generate diffraction patterns widely used for analysis of the objects which caused the diffraction. Therefore, electron diffraction can also refer to derived experimental techniques used for material characterization. This technique is similar to X-ray and neutron diffraction.",
                    "score": 0.9302946329116821
                },
                {
                    "id": 8365979,
                    "contents": "Low-energy electron diffraction\nDavisson and Germer published notes of their electron-diffraction experiment result in Nature and in Physical Review in 1927. One month after Davisson and Germer's work appeared, Thompson and Reid published their electron-diffraction work with higher kinetic energy (thousand times higher than the energy used by Davisson and Germer) in the same journal. Those experiments revealed the wave property of electrons and opened up an era of electron-diffraction study.",
                    "score": 0.9168652892112732
                },
                {
                    "id": 200641,
                    "contents": "Electron diffraction\nElectron diffraction is most frequently used in solid state physics and chemistry to study crystalline, quasi-crystalline and amorphous materials using electron microscopes. In these instruments, electrons are accelerated by an electrostatic potential in order to gain energy and shorten their wavelength. With the wavelength sufficiently short, the atomic structure acts as a diffraction grating generating diffraction patterns, which carry the infrormation about the crystal orientation, lattice parameters, crystal defects etc.",
                    "score": 0.9136889576911926
                },
                {
                    "id": 4822644,
                    "contents": "Gas electron diffraction\nDiffraction occurs because the wavelength of electrons accelerated by a potential of a few thousand volts is of the same order of magnitude as internuclear distances in molecules. The principle is the same as that of other electron diffraction methods such as LEED and RHEED, but the obtainable diffraction pattern is considerably weaker than those of LEED and RHEED because the density of the target is about one thousand times smaller. Since the orientation of the target molecules relative to the electron beams is random, the internuclear distance information obtained is one-dimensional. Thus only relatively simple molecules can be completely structurally characterized by electron diffraction in the gas phase. It is possible to combine information obtained from other sources, such as rotational spectra, NMR spectroscopy or high-quality quantum-mechanical calculations with electron diffraction data, if the latter are not sufficient to determine the molecule's structure completely.",
                    "score": 0.905031681060791
                },
                {
                    "id": 8057562,
                    "contents": "Electron scattering\nThe first electron diffraction experiment was conducted in 1927 by Clinton Davisson and Lester Germer using what would come to be a prototype for modern LEED system. The experiment was able to demonstrate the wave-like properties of electrons, thus confirming the de Broglie hypothesis that matter particles have a wave-like nature. However, after this the interest in LEED diminished in favour of High-energy electron diffraction until the early 1960s when an interest in LEED was revived; of notable mention during this period is H. E. Farnsworth who continued to develop LEED techniques.",
                    "score": 0.9049111604690552
                },
                {
                    "id": 200645,
                    "contents": "Electron diffraction\nThe electron beam was discovered in 1869 by German physicist Johann Hittorf. He noticed a shadow cast by the anode on the tube wall behind the anode. He correctly induced that there must be rays emitted from the cathode. Another German scientist Eugen Goldstein named them cathode rays (German kathodenstrahlen). In 1897, Joseph Thomson measured the mass of cathode rays proving they were made of particles. These particles, however, were 1800 times lighter than the lightest particle known by then - a hydrogen atom. Therefore, the first subatomic particle was discovered, originally called corpuscle and later named electron. Thomson also showed electrons were identical with particles given off by photoelectric and radioactive materials..",
                    "score": 0.9040079712867737
                },
                {
                    "id": 8365978,
                    "contents": "Low-energy electron diffraction\nDavisson and Germer's discovery of electron diffraction The theoretical possibility of the occurrence of electron diffraction first emerged in 1924, when Louis de Broglie introduced wave mechanics and proposed the wavelike nature of all particles. In his Nobel-laureated work de Broglie postulated that the wavelength of a particle with linear momentum p is given by h/p, where h is Planck's constant. The de Broglie hypothesis was confirmed experimentally at Bell Labs in 1927, when Clinton Davisson and Lester Germer fired low-energy electrons at a crystalline nickel target and observed that the angular dependence of the intensity of backscattered electrons showed diffraction patterns. These observations were consistent with the diffraction theory for X-rays developed by Bragg and Laue earlier. Before the acceptance of the de Broglie hypothesis, diffraction was believed to be an exclusive property of waves.",
                    "score": 0.9025998115539551
                },
                {
                    "id": 8365990,
                    "contents": "Low-energy electron diffraction\nHere d is the penetration depth, and denotes the inelastic mean free path, defined as the distance an electron can travel before its intensity has decreased by the factor 1/e. While the inelastic scattering processes and consequently the electronic mean free path depend on the energy, it is relatively independent of the material. The mean free path turns out to be minimal (5–10 Å) in the energy range of low-energy electrons (20–200 eV). This effective attenuation means that only a few atomic layers are sampled by the electron beam, and, as a consequence, the contribution of deeper atoms to the diffraction progressively decreases. Kinematic theory: single scattering Kinematic diffraction is defined as the situation where electrons impinging on a well-ordered crystal surface are elastically scattered only once by that surface. In the theory the electron beam is represented by a plane wave with a wavelength given by the de Broglie hypothesis:",
                    "score": 0.902153730392456
                },
                {
                    "id": 200647,
                    "contents": "Electron diffraction\nUnderstanding to the nature of electron beam has fundamentally changed in 1925, when French physicist Louis de Broglie published his hypothesis. He stated that all matter particles can behave as waves and therefore, among other important implications, can be diffracted. The de Broglie hypothesis was experimentally confirmed for electrons in two experiments performed independently by George Paget Thomson and Clinton Joseph Davisson. This sparked a rapid development of electron-based analytical techniques in 1930s from gas electron diffraction invented by Herman Mark to the first electron microscopes developed by Ernst Ruska. Theory Electron interaction with matter",
                    "score": 0.9013990163803101
                },
                {
                    "id": 200648,
                    "contents": "Electron diffraction\nTheory Electron interaction with matter In order to get diffracted, electrons needs to interact with matter. Due to their negative electric charge, their interactions differ form other radiations used in diffraction studies of materials such as X-rays and neutrons. Negative electrons are scattered due to Coulomb forces when they interact with positively charged atomic core. In comparison, X-rays are scattered after interactions with valence electrons, while neutrons are scattered by the atomic nuclei through the strong nuclear forces. Electron diffraction occurs as result of an elastic scattering, when the incident electrons do not lose their kinetic energy in their interactions with atoms. In some cases, however, even inelastically scattered electrons can be diffracted as result of a following elastic interaction.",
                    "score": 0.8991373181343079
                },
                {
                    "id": 8365976,
                    "contents": "Low-energy electron diffraction\nLow-energy electron diffraction (LEED) is a technique for the determination of the surface structure of single-crystalline materials by bombardment with a collimated beam of low-energy electrons (30–200 eV) and observation of diffracted electrons as spots on a fluorescent screen. LEED may be used in one of two ways: Qualitatively, where the diffraction pattern is recorded and analysis of the spot positions gives information on the symmetry of the surface structure. In the presence of an adsorbate the qualitative analysis may reveal information about the size and rotational alignment of the adsorbate unit cell with respect to the substrate unit cell. Quantitatively, where the intensities of diffracted beams are recorded as a function of incident electron beam energy to generate the so-called I–V curves. By comparison with theoretical curves, these may provide accurate information on atomic positions on the surface at hand.",
                    "score": 0.8980311751365662
                },
                {
                    "id": 200659,
                    "contents": "Electron diffraction\nwhere is the atomic distance between two atoms, is the mean square amplitude of vibration between the two atoms, is the anharmonicity constant and is a phase factor which is important for atomic pairs with very different nuclear charges. The summation is performed over all atom pairs. Atomic triplet intensity is negligible in most cases. Applications In transmission electron microscope Electron diffraction in a transmission electron microscope (TEM) is a versatile technique allowing to determine a wide range of crystallographic quantities. The versatility of TEM is originates from its ability to form the electron beam using complex electron optics. Good control of the beam geometry allows to perform various diffraction techniques enabling to measure the crystal lattice constants, study crystal defects or even to reconstruct an unknown crystal structure.",
                    "score": 0.8969534635543823
                },
                {
                    "id": 1680388,
                    "contents": "Diffraction\nParticle diffraction According to quantum theory every particle exhibits wave properties. In particular, massive particles can interfere with themselves and therefore diffract. Diffraction of electrons and neutrons stood as one of the powerful arguments in favor of quantum mechanics. The wavelength associated with a particle is the de Broglie wavelength where h is Planck's constant and p is the momentum of the particle (mass × velocity for slow-moving particles). For most macroscopic objects, this wavelength is so short that it is not meaningful to assign a wavelength to them. A sodium atom traveling at about 30,000 m/s would have a De Broglie wavelength of about 50 pico meters.",
                    "score": 0.8967384696006775
                },
                {
                    "id": 1680393,
                    "contents": "Diffraction\nIn the case of particles like electrons, neutrons, and atoms, the coherence length is related to the spatial extent of the wave function that describes the particle. Applications Diffraction before destruction A new way to image single biological particles has emerged over the last few years, utilising the bright X-rays generated by X-ray free electron lasers. These femtosecond-duration pulses will allow for the (potential) imaging of single biological macromolecules. Due to these short pulses, radiation damage can be outrun, and diffraction patterns of single biological macromolecules will be able to be obtained. See also",
                    "score": 0.8947537541389465
                },
                {
                    "id": 200654,
                    "contents": "Electron diffraction\nCharacter of the resulting diffraction pattern depends on whether the beam is diffracted by one single crystal or by number of differently oriented crystallites for instance in a polycrystalline material. The single-crystalline diffractogram depicts a regular pattern of bright spots. This pattern can be seen as a two-dimensional projection of reciprocal crystal lattice. If there are more contributing crystallites, the diffraction image becomes a superposition of individual crystals' diffraction patterns. Ultimately, this superposition contains diffraction spots of all possible crystallographic plane systems in all possible orientations. For two reasons, these conditions result in a diffractogram of concentric rings: There are discrete spacings between various parallel crystallographic planes and therefore the beams satisfying the diffraction condition can only form diffraction spots in discrete distances from the transmitted beam.",
                    "score": 0.8938262462615967
                },
                {
                    "id": 8365992,
                    "contents": "Low-energy electron diffraction\nwhere (h, k, l) is a set of integers, and is a vector of the reciprocal lattice. Note that these vectors specify the Fourier components of charge density in the reciprocal (momentum) space, and that the incoming electrons scatter at these density modulations within the crystal lattice. The magnitudes of the wave vectors are unchanged, i.e. , because only elastic scattering is considered. Since the mean free path of low-energy electrons in a crystal is only a few angstroms, only the first few atomic layers contribute to the diffraction. This means that there are no diffraction conditions in the direction perpendicular to the sample surface. As a consequence, the reciprocal lattice of a surface is a 2D lattice with rods extending perpendicular from each lattice point. The rods can be pictured as regions where the reciprocal lattice points are infinitely dense. Therefore, in the case of diffraction from a surface the Laue condition reduces to the 2D form:",
                    "score": 0.8919034600257874
                },
                {
                    "id": 4822650,
                    "contents": "Gas electron diffraction\nThe most interesting contribution is the molecular scattering, because it contains information about the distance between all pairs of atoms in a molecule (bonded or non-bonded): with being the parameter of main interest: the atomic distance between two atoms, being the mean square amplitude of vibration between the two atoms, the anharmonicity constant (correcting the vibration description for deviations from a purely harmonic model), and is a phase factor, which becomes important if a pair of atoms with very different nuclear charge is involved. The first part is similar to the atomic scattering, but contains two scattering factors of the involved atoms. Summation is performed over all atom pairs. is negligible in most cases and not described here in more detail. is mostly determined by fitting and subtracting smooth functions to account for the background contribution.",
                    "score": 0.8908319473266602
                },
                {
                    "id": 8365996,
                    "contents": "Low-energy electron diffraction\npatterns can be inferred from the crystal structure of the bulk crystal, known from other more quantitative diffraction techniques, LEED is more interesting in the cases where the surface layers of a material reconstruct, or where surface adsorbates form their own superstructures.",
                    "score": 0.8906134366989136
                },
                {
                    "id": 1694092,
                    "contents": "Electron\nbe diffracted like light. The wave properties of electrons are easier to observe with experiments than those of other particles like neutrons and protons because electrons have a lower mass and hence a longer de Broglie wavelength for a given energy.",
                    "score": 0.890360951423645
                },
                {
                    "id": 4205493,
                    "contents": "Clinton Davisson\nElectron Diffraction and the Davisson–Germer Experiment Diffraction is a characteristic effect when a wave is incident upon an aperture or a grating, and is closely associated with the meaning of wave motion itself. In the 19th Century, diffraction was well established for light and for ripples on the surfaces of fluids. In 1927, while working for Bell Labs, Davisson and Lester Germer performed an experiment showing that electrons were diffracted at the surface of a crystal of nickel. This celebrated Davisson–Germer experiment confirmed the de Broglie hypothesis that particles of matter have a wave-like nature, which is a central tenet of quantum mechanics. In particular, their observation of diffraction allowed the first measurement of a wavelength for electrons. The measured wavelength agreed well with de Broglie's equation , where is Planck's constant and is the electron's momentum.",
                    "score": 0.8897618651390076
                },
                {
                    "id": 8057567,
                    "contents": "Electron scattering\nCoulomb's law states that:",
                    "score": 0.8897178173065186
                },
                {
                    "id": 6289112,
                    "contents": "Diffractometer\nA diffractometer is a measuring instrument for analyzing the structure of a material from the scattering pattern produced when a beam of radiation or particles (such as X-rays or neutrons) interacts with it. Principle Because it is relatively easy to use electrons or neutrons having wavelengths smaller than a nanometer, electrons and neutrons may be used to study crystal structure in a manner very similar to X-ray diffraction. Electrons do not penetrate as deeply into matter as X-rays, hence electron diffraction reveals structure near the surface; neutrons do penetrate easily and have an advantage that they possess an intrinsic magnetic moment that causes them to interact differently with atoms having different alignments of their magnetic moments.",
                    "score": 0.8885599374771118
                },
                {
                    "id": 200651,
                    "contents": "Electron diffraction\nThen the relativistic velocity is given by the equation Substitution of the De Broglie equation to the above expression of energy gives which leads to the final expression for the relativistic wavelength The wavelength of the electrons in a 10 kV SEM is then 12.2 × 10−12 m (12.2 pm) while in a 200 kV TEM the wavelength is 2.5 pm. In comparison, the wavelength of X-rays usually used in X-ray diffraction is in the order of 100 pm (Cu Kα: λ=154 pm). Diffraction on atomic lattice Wavelength of the electron beam used in a typical electron microscope is sufficiently small, that crystal lattice acts as a diffraction grating. Therefore a diffraction pattern can be formed with beams diffracted under certain angles and intensities. Diffraction angles",
                    "score": 0.8884152173995972
                },
                {
                    "id": 200646,
                    "contents": "Electron diffraction\nParadoxically, Thomson's discovery did not bring the cathode rays and diffraction much closer to each other, since the diffraction was a phenomenon specific to waves, not particles like electrons. The light diffraction was first described already in 17th century by Italian priest and physicist Francesco Maria Grimaldi.. But the light was suggested to be of a wave nature in 1803 when British scientist Thomas Young performed his experiment with two slits. The wave theory was further supported by studies and calculations of French physicist Augustin-Jean Fresnel 1816 and 1818 finally confirming theory of Christiaan Huygens.",
                    "score": 0.8878312706947327
                },
                {
                    "id": 18871497,
                    "contents": "Length measurement\nDiffraction measurements For small objects, different methods are used that also depend upon determining size in units of wavelengths. For instance, in the case of a crystal, atomic spacings can be determined using X-ray diffraction. The present best value for the lattice parameter of silicon, denoted a, is: a = 543.102 0504(89) × 10−12 m, corresponding to a resolution of ΔL/L ≈ Similar techniques can provide the dimensions of small structures repeated in large periodic arrays like a diffraction grating. Such measurements allow the calibration of electron microscopes, extending measurement capabilities. For non-relativistic electrons in an electron microscope, the de Broglie wavelength is:",
                    "score": 0.886925220489502
                },
                {
                    "id": 200650,
                    "contents": "Electron diffraction\nwhere is the electron rest mass, is the elementary charge and is the speed of light. Substituting the momentum and velocity to the de Broglie equation we receive Relativistic theory In an electron microscope, the accelerating potential is usually several thousand volts, causing the electron to travel at an appreciable fraction of the speed of light. Scanning electron microscopes typically operate at an accelerating voltage of 10,000 volts (10 kV) giving an electron velocity approximately 20% of the speed of light, while a typical TEM operates at 200 kV raising the electron velocity to 70% the speed of light. Therefore, relativistic effects need to be taken into account. The relativistic relation between energy and momentum is It follows then, that the ratio between the electron mass and its rest mass (or Lorentz factor) is Then the relativistic velocity is given by the equation Substitution of the De Broglie equation to the above expression of energy gives",
                    "score": 0.8866198062896729
                },
                {
                    "id": 27118365,
                    "contents": "Direct methods (electron microscopy)\nLet ) be a function that relates the intensity to the phase for the same beam, where contains normalization terms: Then, the distribution of values will be directly related to the values of . That is, when the product is large or small, will also be large and small. So, the observed intensities can be used to reasonably estimate the phases for diffracted beams. The observed intensity can be related to the structure factor more formally using the Blackman formula. Other cases to consider for intensity mapping are specific diffraction experiments, including powder diffraction and precession electron diffraction. Specifically, precession electron diffraction produces a quasi-kinematical diffraction pattern that can be used adequately in direct methods.",
                    "score": 0.8863874077796936
                },
                {
                    "id": 200663,
                    "contents": "Electron diffraction\ntherefore, whether a magnified image or diffractogram is acquired. Modern microscopes allow to switch between the imaging and diffraction mode by pressing a single button, which makes diffraction data easily available and accessible.",
                    "score": 0.8863239288330078
                },
                {
                    "id": 15616569,
                    "contents": "Timeline of United States discoveries\n1927 Electron diffraction Electron diffraction is a collective scattering phenomenon with electrons being scattered by atoms in a regular crystal array. This can be understood in analogy to the Huygens principle for the diffraction of light. The incoming plane electron wave interacts with the atoms, and secondary waves are generated which interfere with each other. In 1927, two Americans named Clinton Davisson and Lester Germer had proven de Broglie's theory by discovering electron diffraction. This confirmation of the wavelike nature of an electron was discovered independently of Englishman George Paget Thomson.",
                    "score": 0.8860552906990051
                },
                {
                    "id": 27118356,
                    "contents": "Direct methods (electron microscopy)\nComparison to X-Ray Direct Methods The majority of direct methods was developed for X-ray diffraction. However, electron diffraction has advantages in several applications. Electron diffraction is a powerful technique for analyzing and characterizing nano- and micron-sized particles, molecules, and proteins. While electron diffraction is often dynamical and more complex to understand compared to X-ray diffraction, which is usually kinematical, there are specific cases (detailed later) that have sufficient conditions for applying direct methods for structure determination. Theory Unitary Sayre Equation",
                    "score": 0.8848081231117249
                },
                {
                    "id": 27118363,
                    "contents": "Direct methods (electron microscopy)\nStatistical Kinematical Diffraction Even though most cases of electron diffraction are dynamical, it is still possible to achieve scattering that is statistically kinematical in nature. This is what enables the analysis of amorphous and biological materials, where dynamical scattering from random phases add up to be nearly kinematical. Furthermore, as explained earlier, it is not critical to retrieve phase information completely accurately. Errors in the phase information are tolerable. Recalling the Cochran distribution and considering a logarithm of that distribution:",
                    "score": 0.8844743371009827
                },
                {
                    "id": 8366002,
                    "contents": "Low-energy electron diffraction\nThe R-factor is then given by: where and is the imaginary part of the electron self-energy. In general, is considered as a good agreement, is considered mediocre and is considered a bad agreement. Figure 9 shows examples of the comparison between experimental I–V spectra and theoretical calculations. Dynamical LEED calculations The term dynamical stems from the studies of X-ray diffraction and describes the situation where the response of the crystal to an incident wave is included self-consistently and multiple scattering can occur. The aim of any dynamical LEED theory is to calculate the intensities of diffraction of an electron beam impinging on a surface as accurately as possible.",
                    "score": 0.8844722509384155
                },
                {
                    "id": 8366001,
                    "contents": "Low-energy electron diffraction\nA more quantitative analysis of LEED experimental data can be achieved by analysis of so-called I–V curves, which are measurements of the intensity versus incident electron energy. The I–V curves can be recorded by using a camera connected to computer controlled data handling or by direct measurement with a movable Faraday cup. The experimental curves are then compared to computer calculations based on the assumption of a particular model system. The model is changed in an iterative process until a satisfactory agreement between experimental and theoretical curves is achieved. A quantitative measure for this agreement is the so-called reliability- or R-factor. A commonly used reliability factor is the one proposed by Pendry. It is expressed in terms of the logarithmic derivative of the intensity: The R-factor is then given by:",
                    "score": 0.8844188451766968
                },
                {
                    "id": 8365977,
                    "contents": "Low-energy electron diffraction\nHistorical perspective An electron-diffraction experiment similar to modern LEED was the first to observe the wavelike properties of electrons, but LEED was established as an ubiquitous tool in surface science only with the advances in vacuum generation and electron detection techniques.",
                    "score": 0.8843648433685303
                },
                {
                    "id": 200655,
                    "contents": "Electron diffraction\nThere are all possible orientations of crystallographic planes and therefore the diffraction spots are formed around the transmitted beam in the whole 360-degree azimuthal range.",
                    "score": 0.883645236492157
                },
                {
                    "id": 784447,
                    "contents": "X-ray photoelectron spectroscopy\nwhere is the IMFP and is the axis perpendicular to the sample. In fact it is generally the case that the IMFP is only weakly material dependent, but rather strongly dependent on the photoelectron kinetic energy. Quantitatively we can relate to IMFP by where is the mean atomic diameter as calculated by the density so . The above formula was developed by Seah and Dench.",
                    "score": 0.8836116790771484
                },
                {
                    "id": 8365982,
                    "contents": "Low-energy electron diffraction\nIt soon became clear that the kinematic (single-scattering) theory, which had been successfully used to explain X-ray diffraction experiments, was inadequate for the quantitative interpretation of experimental data obtained from LEED. At this stage a detailed determination of surface structures, including adsorption sites, bond angles and bond lengths was not possible. A dynamical electron-diffraction theory, which took into account the possibility of multiple scattering, was established in the late 1960s. With this theory, it later became possible to reproduce experimental data with high precision. Experimental setup In order to keep the studied sample clean and free from unwanted adsorbates, LEED experiments are performed in an ultra-high vacuum environment (residual gas pressure <10−7 Pa). LEED optics The main components of a LEED instrument are:",
                    "score": 0.882552981376648
                },
                {
                    "id": 6724839,
                    "contents": "Powder diffraction\nPowder diffraction is a scientific technique using X-ray, neutron, or electron diffraction on powder or microcrystalline samples for structural characterization of materials. An instrument dedicated to performing such powder measurements is called a powder diffractometer. Powder diffraction stands in contrast to single crystal diffraction techniques, which work best with a single, well-ordered crystal. Explanation",
                    "score": 0.8821631669998169
                },
                {
                    "id": 7919693,
                    "contents": "Selected area diffraction\nSAD is similar to X-ray diffraction, but unique in that areas as small as several hundred nanometers in size can be examined, whereas X-ray diffraction typically samples areas several centimeters in size. See also Diffraction Transmission electron microscope Electron crystallography CrysTBox X-ray (Powder) diffraction Convergent beam electron diffraction References Materials science Condensed matter physics Diffraction Crystallography Electron microscopy",
                    "score": 0.8820500373840332
                },
                {
                    "id": 6114470,
                    "contents": "Davisson–Germer experiment\nAccording to the de Broglie relation, electrons with kinetic energy of have a wavelength of . The experimental outcome was via Bragg's law, which closely matched the predictions. As Davisson and Germer state in their 1928 follow-up paper to their Nobel prize winning paper, \"These results, including the failure of the data to satisfy the Bragg formula, are in accord with those previously obtained in our experiments on electron diffraction. The reflection data fail to satisfy the Bragg relation for the same reason that the electron diffraction beams fail to coincide with their Laue beam analogues.\" However, they add, \"The calculated wave-lengths are in excellent agreement with the theoretical values of h/mv as shown in the accompanying table.\" So although electron energy diffraction does not follow the Bragg law, it did confirm de Broglie's theory that particles behave like waves. However, the experiments did not follow the de Broglie calculations which led to attempts by Carl Eckart,",
                    "score": 0.881973147392273
                },
                {
                    "id": 3086296,
                    "contents": "Arthur Compton\nCompton's first book, X-Rays and Electrons, was published in 1926. In it he showed how to calculate the densities of diffracting materials from their X-ray diffraction patterns. He revised his book with the help of Samuel K. Allison to produce X-Rays in Theory and Experiment (1935). This work remained a standard reference for the next three decades.",
                    "score": 0.881352961063385
                },
                {
                    "id": 8365991,
                    "contents": "Low-energy electron diffraction\nThe interaction between the scatterers present in the surface and the incident electrons is most conveniently described in reciprocal space. In three dimensions the primitive reciprocal lattice vectors are related to the real space lattice {a, b, c} in the following way: For an incident electron with wave vector and scattered wave vector , the condition for constructive interference and hence diffraction of scattered electron waves is given by the Laue condition: where (h, k, l) is a set of integers, and",
                    "score": 0.8812361359596252
                },
                {
                    "id": 8365983,
                    "contents": "Low-energy electron diffraction\nAn electron gun from which monochromatic electrons are emitted by a cathode filament which is at a negative potential, typically 10–600 V, with respect to the sample. The electrons are accelerated and focused into a beam, typically about 0.1 to 0.5 mm wide, by a series of electrodes serving as electron lenses. Some of the electrons incident on the sample surface are backscattered elastically, and diffraction can be detected if sufficient order exists on the surface. This typically requires a region of single crystal surface as wide as the electron beam, although sometimes polycrystalline surfaces such as highly oriented pyrolytic graphite (HOPG) are sufficient.",
                    "score": 0.8811153769493103
                },
                {
                    "id": 1680389,
                    "contents": "Diffraction\nBecause the wavelength for even the smallest of macroscopic objects is extremely small, diffraction of matter waves is only visible for small particles, like electrons, neutrons, atoms and small molecules. The short wavelength of these matter waves makes them ideally suited to study the atomic crystal structure of solids and large molecules like proteins. Relatively larger molecules like buckyballs were also shown to diffract. Bragg diffraction Diffraction from a three-dimensional periodic structure such as atoms in a crystal is called Bragg diffraction. It is similar to what occurs when waves are scattered from a diffraction grating. Bragg diffraction is a consequence of interference between waves reflecting from different crystal planes. The condition of constructive interference is given by Bragg's law: where λ is the wavelength, d is the distance between crystal planes, θ is the angle of the diffracted wave. and m is an integer known as the order of the diffracted beam.",
                    "score": 0.8810359239578247
                },
                {
                    "id": 22611102,
                    "contents": "Precession electron diffraction\nBecause this process is highly automated, the quality of the recorded diffraction patterns is crucial to the software's ability to accurately compare and assign orientations to each pixel. Thus, the advantages of PED are well-suited for use with this scanning technique. By instead recording a PED pattern at each pixel, dynamical effects are reduced, and the patterns are more easily compared to simulated data, improving the accuracy of the automated phase/orientation assignment. Beyond diffraction Although the PED technique was initially developed for its improved diffraction applications, the advantageous properties of the technique have been found to enhance many other investigative techniques in the TEM. These include bright field and dark field imaging, electron tomography, and composition-probing techniques like energy-dispersive x-ray spectroscopy (EDS) and electron energy loss spectroscopy (EELS).",
                    "score": 0.880774974822998
                },
                {
                    "id": 1337590,
                    "contents": "X-ray crystallography\nX-rays range in wavelength from 10 to 0.01 nanometers; a typical wavelength used for crystallography is 1 Å (0.1 nm), which is on the scale of covalent chemical bonds and the radius of a single atom. Longer-wavelength photons (such as ultraviolet radiation) would not have sufficient resolution to determine the atomic positions. At the other extreme, shorter-wavelength photons such as gamma rays are difficult to produce in large numbers, difficult to focus, and interact too strongly with matter, producing particle-antiparticle pairs. Therefore, X-rays are the \"sweetspot\" for wavelength when determining atomic-resolution structures from the scattering of electromagnetic radiation.",
                    "score": 0.8804083466529846
                },
                {
                    "id": 20043626,
                    "contents": "Anomalous diffraction theory\nAnother limiting approximation for optically soft particles is Rayleigh scattering, which is valid for small size parameters. Notes and references Scattering, absorption and radiative transfer (optics)",
                    "score": 0.8791354298591614
                },
                {
                    "id": 6724874,
                    "contents": "Powder diffraction\nSee also Bragg diffraction Condensed matter physics Crystallographic database Crystallography Diffractometer Electron crystallography Electron diffraction Materials science Metallurgy Neutron diffraction Pair distribution function Solid state chemistry Texture (crystalline) Ultrafast x-ray X-ray crystallography X-ray scattering techniques References Further reading External links International Centre for Diffraction Data Powder Diffraction on the Web The Area DIffraction Machine – software to analyze powder diffraction data Powder diffraction at ILL Diffraction Neutron-related techniques Synchrotron-related techniques Diffraction",
                    "score": 0.8790249824523926
                },
                {
                    "id": 8057560,
                    "contents": "Electron scattering\nElectrons may be scattered through a solid in several ways: Not at all: no electron scattering occurs at all and the beam passes straight through. Single scattering: when an electron is scattered just once. Plural scattering: when electron(s) scatter several times. Multiple scattering: when electron(s) scatter many times over. The likelihood of an electron scattering and the degree of the scattering is a probability function of the specimen thickness to the mean free path. History The principle of the electron was first theorised in the period of 1838-1851 by a natural philosopher by the name of Richard Laming who speculated the existence of sub-atomic, unit charged particles; he also pictured the atom as being an 'electrosphere' of concentric shells of electrical particles surrounding a material core.",
                    "score": 0.8789340853691101
                },
                {
                    "id": 1337641,
                    "contents": "X-ray crystallography\nDiffraction theory The main goal of X-ray crystallography is to determine the density of electrons f(r) throughout the crystal, where r represents the three-dimensional position vector within the crystal. To do this, X-ray scattering is used to collect data about its Fourier transform F(q), which is inverted mathematically to obtain the density defined in real space, using the formula where the integral is taken over all values of q. The three-dimensional real vector q represents a point in reciprocal space, that is, to a particular oscillation in the electron density as one moves in the direction in which q points. The length of q corresponds to divided by the wavelength of the oscillation. The corresponding formula for a Fourier transform will be used below where the integral is summed over all possible values of the position vector r within the crystal.",
                    "score": 0.8784332275390625
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_24",
        "question": "Electron diffraction makes use of electrons with wavelengths comparable to bond lengths. To what speed must an electron be accelerated for it to have a wavelength of $100 \\mathrm{pm}$ ? ",
        "golden_answers": [
            " 7.27"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 200640,
                    "contents": "Electron diffraction\nElectron diffraction is a phenomenon of electron beam bending around atomic structures. This behaviour typical for waves is applicable to electrons due to the wave–particle duality stating that electrons behave as both, particles and waves. Since the diffracted beams interfere, they generate diffraction patterns widely used for analysis of the objects which caused the diffraction. Therefore, electron diffraction can also refer to derived experimental techniques used for material characterization. This technique is similar to X-ray and neutron diffraction.",
                    "score": 0.9302946329116821
                },
                {
                    "id": 8365979,
                    "contents": "Low-energy electron diffraction\nDavisson and Germer published notes of their electron-diffraction experiment result in Nature and in Physical Review in 1927. One month after Davisson and Germer's work appeared, Thompson and Reid published their electron-diffraction work with higher kinetic energy (thousand times higher than the energy used by Davisson and Germer) in the same journal. Those experiments revealed the wave property of electrons and opened up an era of electron-diffraction study.",
                    "score": 0.9168652892112732
                },
                {
                    "id": 200641,
                    "contents": "Electron diffraction\nElectron diffraction is most frequently used in solid state physics and chemistry to study crystalline, quasi-crystalline and amorphous materials using electron microscopes. In these instruments, electrons are accelerated by an electrostatic potential in order to gain energy and shorten their wavelength. With the wavelength sufficiently short, the atomic structure acts as a diffraction grating generating diffraction patterns, which carry the infrormation about the crystal orientation, lattice parameters, crystal defects etc.",
                    "score": 0.9136889576911926
                },
                {
                    "id": 4822644,
                    "contents": "Gas electron diffraction\nDiffraction occurs because the wavelength of electrons accelerated by a potential of a few thousand volts is of the same order of magnitude as internuclear distances in molecules. The principle is the same as that of other electron diffraction methods such as LEED and RHEED, but the obtainable diffraction pattern is considerably weaker than those of LEED and RHEED because the density of the target is about one thousand times smaller. Since the orientation of the target molecules relative to the electron beams is random, the internuclear distance information obtained is one-dimensional. Thus only relatively simple molecules can be completely structurally characterized by electron diffraction in the gas phase. It is possible to combine information obtained from other sources, such as rotational spectra, NMR spectroscopy or high-quality quantum-mechanical calculations with electron diffraction data, if the latter are not sufficient to determine the molecule's structure completely.",
                    "score": 0.905031681060791
                },
                {
                    "id": 8057562,
                    "contents": "Electron scattering\nThe first electron diffraction experiment was conducted in 1927 by Clinton Davisson and Lester Germer using what would come to be a prototype for modern LEED system. The experiment was able to demonstrate the wave-like properties of electrons, thus confirming the de Broglie hypothesis that matter particles have a wave-like nature. However, after this the interest in LEED diminished in favour of High-energy electron diffraction until the early 1960s when an interest in LEED was revived; of notable mention during this period is H. E. Farnsworth who continued to develop LEED techniques.",
                    "score": 0.9049111604690552
                },
                {
                    "id": 200645,
                    "contents": "Electron diffraction\nThe electron beam was discovered in 1869 by German physicist Johann Hittorf. He noticed a shadow cast by the anode on the tube wall behind the anode. He correctly induced that there must be rays emitted from the cathode. Another German scientist Eugen Goldstein named them cathode rays (German kathodenstrahlen). In 1897, Joseph Thomson measured the mass of cathode rays proving they were made of particles. These particles, however, were 1800 times lighter than the lightest particle known by then - a hydrogen atom. Therefore, the first subatomic particle was discovered, originally called corpuscle and later named electron. Thomson also showed electrons were identical with particles given off by photoelectric and radioactive materials..",
                    "score": 0.9040079712867737
                },
                {
                    "id": 8365978,
                    "contents": "Low-energy electron diffraction\nDavisson and Germer's discovery of electron diffraction The theoretical possibility of the occurrence of electron diffraction first emerged in 1924, when Louis de Broglie introduced wave mechanics and proposed the wavelike nature of all particles. In his Nobel-laureated work de Broglie postulated that the wavelength of a particle with linear momentum p is given by h/p, where h is Planck's constant. The de Broglie hypothesis was confirmed experimentally at Bell Labs in 1927, when Clinton Davisson and Lester Germer fired low-energy electrons at a crystalline nickel target and observed that the angular dependence of the intensity of backscattered electrons showed diffraction patterns. These observations were consistent with the diffraction theory for X-rays developed by Bragg and Laue earlier. Before the acceptance of the de Broglie hypothesis, diffraction was believed to be an exclusive property of waves.",
                    "score": 0.9025998115539551
                },
                {
                    "id": 8365990,
                    "contents": "Low-energy electron diffraction\nHere d is the penetration depth, and denotes the inelastic mean free path, defined as the distance an electron can travel before its intensity has decreased by the factor 1/e. While the inelastic scattering processes and consequently the electronic mean free path depend on the energy, it is relatively independent of the material. The mean free path turns out to be minimal (5–10 Å) in the energy range of low-energy electrons (20–200 eV). This effective attenuation means that only a few atomic layers are sampled by the electron beam, and, as a consequence, the contribution of deeper atoms to the diffraction progressively decreases. Kinematic theory: single scattering Kinematic diffraction is defined as the situation where electrons impinging on a well-ordered crystal surface are elastically scattered only once by that surface. In the theory the electron beam is represented by a plane wave with a wavelength given by the de Broglie hypothesis:",
                    "score": 0.902153730392456
                },
                {
                    "id": 200647,
                    "contents": "Electron diffraction\nUnderstanding to the nature of electron beam has fundamentally changed in 1925, when French physicist Louis de Broglie published his hypothesis. He stated that all matter particles can behave as waves and therefore, among other important implications, can be diffracted. The de Broglie hypothesis was experimentally confirmed for electrons in two experiments performed independently by George Paget Thomson and Clinton Joseph Davisson. This sparked a rapid development of electron-based analytical techniques in 1930s from gas electron diffraction invented by Herman Mark to the first electron microscopes developed by Ernst Ruska. Theory Electron interaction with matter",
                    "score": 0.9013990163803101
                },
                {
                    "id": 200648,
                    "contents": "Electron diffraction\nTheory Electron interaction with matter In order to get diffracted, electrons needs to interact with matter. Due to their negative electric charge, their interactions differ form other radiations used in diffraction studies of materials such as X-rays and neutrons. Negative electrons are scattered due to Coulomb forces when they interact with positively charged atomic core. In comparison, X-rays are scattered after interactions with valence electrons, while neutrons are scattered by the atomic nuclei through the strong nuclear forces. Electron diffraction occurs as result of an elastic scattering, when the incident electrons do not lose their kinetic energy in their interactions with atoms. In some cases, however, even inelastically scattered electrons can be diffracted as result of a following elastic interaction.",
                    "score": 0.8991373181343079
                },
                {
                    "id": 8365976,
                    "contents": "Low-energy electron diffraction\nLow-energy electron diffraction (LEED) is a technique for the determination of the surface structure of single-crystalline materials by bombardment with a collimated beam of low-energy electrons (30–200 eV) and observation of diffracted electrons as spots on a fluorescent screen. LEED may be used in one of two ways: Qualitatively, where the diffraction pattern is recorded and analysis of the spot positions gives information on the symmetry of the surface structure. In the presence of an adsorbate the qualitative analysis may reveal information about the size and rotational alignment of the adsorbate unit cell with respect to the substrate unit cell. Quantitatively, where the intensities of diffracted beams are recorded as a function of incident electron beam energy to generate the so-called I–V curves. By comparison with theoretical curves, these may provide accurate information on atomic positions on the surface at hand.",
                    "score": 0.8980311751365662
                },
                {
                    "id": 200659,
                    "contents": "Electron diffraction\nwhere is the atomic distance between two atoms, is the mean square amplitude of vibration between the two atoms, is the anharmonicity constant and is a phase factor which is important for atomic pairs with very different nuclear charges. The summation is performed over all atom pairs. Atomic triplet intensity is negligible in most cases. Applications In transmission electron microscope Electron diffraction in a transmission electron microscope (TEM) is a versatile technique allowing to determine a wide range of crystallographic quantities. The versatility of TEM is originates from its ability to form the electron beam using complex electron optics. Good control of the beam geometry allows to perform various diffraction techniques enabling to measure the crystal lattice constants, study crystal defects or even to reconstruct an unknown crystal structure.",
                    "score": 0.8969534635543823
                },
                {
                    "id": 1680388,
                    "contents": "Diffraction\nParticle diffraction According to quantum theory every particle exhibits wave properties. In particular, massive particles can interfere with themselves and therefore diffract. Diffraction of electrons and neutrons stood as one of the powerful arguments in favor of quantum mechanics. The wavelength associated with a particle is the de Broglie wavelength where h is Planck's constant and p is the momentum of the particle (mass × velocity for slow-moving particles). For most macroscopic objects, this wavelength is so short that it is not meaningful to assign a wavelength to them. A sodium atom traveling at about 30,000 m/s would have a De Broglie wavelength of about 50 pico meters.",
                    "score": 0.8967382907867432
                },
                {
                    "id": 1680393,
                    "contents": "Diffraction\nIn the case of particles like electrons, neutrons, and atoms, the coherence length is related to the spatial extent of the wave function that describes the particle. Applications Diffraction before destruction A new way to image single biological particles has emerged over the last few years, utilising the bright X-rays generated by X-ray free electron lasers. These femtosecond-duration pulses will allow for the (potential) imaging of single biological macromolecules. Due to these short pulses, radiation damage can be outrun, and diffraction patterns of single biological macromolecules will be able to be obtained. See also",
                    "score": 0.8947537541389465
                },
                {
                    "id": 200654,
                    "contents": "Electron diffraction\nCharacter of the resulting diffraction pattern depends on whether the beam is diffracted by one single crystal or by number of differently oriented crystallites for instance in a polycrystalline material. The single-crystalline diffractogram depicts a regular pattern of bright spots. This pattern can be seen as a two-dimensional projection of reciprocal crystal lattice. If there are more contributing crystallites, the diffraction image becomes a superposition of individual crystals' diffraction patterns. Ultimately, this superposition contains diffraction spots of all possible crystallographic plane systems in all possible orientations. For two reasons, these conditions result in a diffractogram of concentric rings: There are discrete spacings between various parallel crystallographic planes and therefore the beams satisfying the diffraction condition can only form diffraction spots in discrete distances from the transmitted beam.",
                    "score": 0.8938262462615967
                },
                {
                    "id": 8365992,
                    "contents": "Low-energy electron diffraction\nwhere (h, k, l) is a set of integers, and is a vector of the reciprocal lattice. Note that these vectors specify the Fourier components of charge density in the reciprocal (momentum) space, and that the incoming electrons scatter at these density modulations within the crystal lattice. The magnitudes of the wave vectors are unchanged, i.e. , because only elastic scattering is considered. Since the mean free path of low-energy electrons in a crystal is only a few angstroms, only the first few atomic layers contribute to the diffraction. This means that there are no diffraction conditions in the direction perpendicular to the sample surface. As a consequence, the reciprocal lattice of a surface is a 2D lattice with rods extending perpendicular from each lattice point. The rods can be pictured as regions where the reciprocal lattice points are infinitely dense. Therefore, in the case of diffraction from a surface the Laue condition reduces to the 2D form:",
                    "score": 0.8919034600257874
                },
                {
                    "id": 4822650,
                    "contents": "Gas electron diffraction\nThe most interesting contribution is the molecular scattering, because it contains information about the distance between all pairs of atoms in a molecule (bonded or non-bonded): with being the parameter of main interest: the atomic distance between two atoms, being the mean square amplitude of vibration between the two atoms, the anharmonicity constant (correcting the vibration description for deviations from a purely harmonic model), and is a phase factor, which becomes important if a pair of atoms with very different nuclear charge is involved. The first part is similar to the atomic scattering, but contains two scattering factors of the involved atoms. Summation is performed over all atom pairs. is negligible in most cases and not described here in more detail. is mostly determined by fitting and subtracting smooth functions to account for the background contribution.",
                    "score": 0.8908321857452393
                },
                {
                    "id": 8365996,
                    "contents": "Low-energy electron diffraction\npatterns can be inferred from the crystal structure of the bulk crystal, known from other more quantitative diffraction techniques, LEED is more interesting in the cases where the surface layers of a material reconstruct, or where surface adsorbates form their own superstructures.",
                    "score": 0.8906134366989136
                },
                {
                    "id": 1694092,
                    "contents": "Electron\nbe diffracted like light. The wave properties of electrons are easier to observe with experiments than those of other particles like neutrons and protons because electrons have a lower mass and hence a longer de Broglie wavelength for a given energy.",
                    "score": 0.890360951423645
                },
                {
                    "id": 4205493,
                    "contents": "Clinton Davisson\nElectron Diffraction and the Davisson–Germer Experiment Diffraction is a characteristic effect when a wave is incident upon an aperture or a grating, and is closely associated with the meaning of wave motion itself. In the 19th Century, diffraction was well established for light and for ripples on the surfaces of fluids. In 1927, while working for Bell Labs, Davisson and Lester Germer performed an experiment showing that electrons were diffracted at the surface of a crystal of nickel. This celebrated Davisson–Germer experiment confirmed the de Broglie hypothesis that particles of matter have a wave-like nature, which is a central tenet of quantum mechanics. In particular, their observation of diffraction allowed the first measurement of a wavelength for electrons. The measured wavelength agreed well with de Broglie's equation , where is Planck's constant and is the electron's momentum.",
                    "score": 0.8897618651390076
                },
                {
                    "id": 8057567,
                    "contents": "Electron scattering\nCoulomb's law states that:",
                    "score": 0.8897178173065186
                },
                {
                    "id": 6289112,
                    "contents": "Diffractometer\nA diffractometer is a measuring instrument for analyzing the structure of a material from the scattering pattern produced when a beam of radiation or particles (such as X-rays or neutrons) interacts with it. Principle Because it is relatively easy to use electrons or neutrons having wavelengths smaller than a nanometer, electrons and neutrons may be used to study crystal structure in a manner very similar to X-ray diffraction. Electrons do not penetrate as deeply into matter as X-rays, hence electron diffraction reveals structure near the surface; neutrons do penetrate easily and have an advantage that they possess an intrinsic magnetic moment that causes them to interact differently with atoms having different alignments of their magnetic moments.",
                    "score": 0.8885599374771118
                },
                {
                    "id": 200651,
                    "contents": "Electron diffraction\nThen the relativistic velocity is given by the equation Substitution of the De Broglie equation to the above expression of energy gives which leads to the final expression for the relativistic wavelength The wavelength of the electrons in a 10 kV SEM is then 12.2 × 10−12 m (12.2 pm) while in a 200 kV TEM the wavelength is 2.5 pm. In comparison, the wavelength of X-rays usually used in X-ray diffraction is in the order of 100 pm (Cu Kα: λ=154 pm). Diffraction on atomic lattice Wavelength of the electron beam used in a typical electron microscope is sufficiently small, that crystal lattice acts as a diffraction grating. Therefore a diffraction pattern can be formed with beams diffracted under certain angles and intensities. Diffraction angles",
                    "score": 0.8884152173995972
                },
                {
                    "id": 200646,
                    "contents": "Electron diffraction\nParadoxically, Thomson's discovery did not bring the cathode rays and diffraction much closer to each other, since the diffraction was a phenomenon specific to waves, not particles like electrons. The light diffraction was first described already in 17th century by Italian priest and physicist Francesco Maria Grimaldi.. But the light was suggested to be of a wave nature in 1803 when British scientist Thomas Young performed his experiment with two slits. The wave theory was further supported by studies and calculations of French physicist Augustin-Jean Fresnel 1816 and 1818 finally confirming theory of Christiaan Huygens.",
                    "score": 0.8878312706947327
                },
                {
                    "id": 18871497,
                    "contents": "Length measurement\nDiffraction measurements For small objects, different methods are used that also depend upon determining size in units of wavelengths. For instance, in the case of a crystal, atomic spacings can be determined using X-ray diffraction. The present best value for the lattice parameter of silicon, denoted a, is: a = 543.102 0504(89) × 10−12 m, corresponding to a resolution of ΔL/L ≈ Similar techniques can provide the dimensions of small structures repeated in large periodic arrays like a diffraction grating. Such measurements allow the calibration of electron microscopes, extending measurement capabilities. For non-relativistic electrons in an electron microscope, the de Broglie wavelength is:",
                    "score": 0.886925220489502
                },
                {
                    "id": 200650,
                    "contents": "Electron diffraction\nwhere is the electron rest mass, is the elementary charge and is the speed of light. Substituting the momentum and velocity to the de Broglie equation we receive Relativistic theory In an electron microscope, the accelerating potential is usually several thousand volts, causing the electron to travel at an appreciable fraction of the speed of light. Scanning electron microscopes typically operate at an accelerating voltage of 10,000 volts (10 kV) giving an electron velocity approximately 20% of the speed of light, while a typical TEM operates at 200 kV raising the electron velocity to 70% the speed of light. Therefore, relativistic effects need to be taken into account. The relativistic relation between energy and momentum is It follows then, that the ratio between the electron mass and its rest mass (or Lorentz factor) is Then the relativistic velocity is given by the equation Substitution of the De Broglie equation to the above expression of energy gives",
                    "score": 0.8866198062896729
                },
                {
                    "id": 27118365,
                    "contents": "Direct methods (electron microscopy)\nLet ) be a function that relates the intensity to the phase for the same beam, where contains normalization terms: Then, the distribution of values will be directly related to the values of . That is, when the product is large or small, will also be large and small. So, the observed intensities can be used to reasonably estimate the phases for diffracted beams. The observed intensity can be related to the structure factor more formally using the Blackman formula. Other cases to consider for intensity mapping are specific diffraction experiments, including powder diffraction and precession electron diffraction. Specifically, precession electron diffraction produces a quasi-kinematical diffraction pattern that can be used adequately in direct methods.",
                    "score": 0.8863874077796936
                },
                {
                    "id": 200663,
                    "contents": "Electron diffraction\ntherefore, whether a magnified image or diffractogram is acquired. Modern microscopes allow to switch between the imaging and diffraction mode by pressing a single button, which makes diffraction data easily available and accessible.",
                    "score": 0.8863239288330078
                },
                {
                    "id": 15616569,
                    "contents": "Timeline of United States discoveries\n1927 Electron diffraction Electron diffraction is a collective scattering phenomenon with electrons being scattered by atoms in a regular crystal array. This can be understood in analogy to the Huygens principle for the diffraction of light. The incoming plane electron wave interacts with the atoms, and secondary waves are generated which interfere with each other. In 1927, two Americans named Clinton Davisson and Lester Germer had proven de Broglie's theory by discovering electron diffraction. This confirmation of the wavelike nature of an electron was discovered independently of Englishman George Paget Thomson.",
                    "score": 0.8860552906990051
                },
                {
                    "id": 27118356,
                    "contents": "Direct methods (electron microscopy)\nComparison to X-Ray Direct Methods The majority of direct methods was developed for X-ray diffraction. However, electron diffraction has advantages in several applications. Electron diffraction is a powerful technique for analyzing and characterizing nano- and micron-sized particles, molecules, and proteins. While electron diffraction is often dynamical and more complex to understand compared to X-ray diffraction, which is usually kinematical, there are specific cases (detailed later) that have sufficient conditions for applying direct methods for structure determination. Theory Unitary Sayre Equation",
                    "score": 0.8848081231117249
                },
                {
                    "id": 27118363,
                    "contents": "Direct methods (electron microscopy)\nStatistical Kinematical Diffraction Even though most cases of electron diffraction are dynamical, it is still possible to achieve scattering that is statistically kinematical in nature. This is what enables the analysis of amorphous and biological materials, where dynamical scattering from random phases add up to be nearly kinematical. Furthermore, as explained earlier, it is not critical to retrieve phase information completely accurately. Errors in the phase information are tolerable. Recalling the Cochran distribution and considering a logarithm of that distribution:",
                    "score": 0.8844743371009827
                },
                {
                    "id": 8366002,
                    "contents": "Low-energy electron diffraction\nThe R-factor is then given by: where and is the imaginary part of the electron self-energy. In general, is considered as a good agreement, is considered mediocre and is considered a bad agreement. Figure 9 shows examples of the comparison between experimental I–V spectra and theoretical calculations. Dynamical LEED calculations The term dynamical stems from the studies of X-ray diffraction and describes the situation where the response of the crystal to an incident wave is included self-consistently and multiple scattering can occur. The aim of any dynamical LEED theory is to calculate the intensities of diffraction of an electron beam impinging on a surface as accurately as possible.",
                    "score": 0.8844722509384155
                },
                {
                    "id": 8366001,
                    "contents": "Low-energy electron diffraction\nA more quantitative analysis of LEED experimental data can be achieved by analysis of so-called I–V curves, which are measurements of the intensity versus incident electron energy. The I–V curves can be recorded by using a camera connected to computer controlled data handling or by direct measurement with a movable Faraday cup. The experimental curves are then compared to computer calculations based on the assumption of a particular model system. The model is changed in an iterative process until a satisfactory agreement between experimental and theoretical curves is achieved. A quantitative measure for this agreement is the so-called reliability- or R-factor. A commonly used reliability factor is the one proposed by Pendry. It is expressed in terms of the logarithmic derivative of the intensity: The R-factor is then given by:",
                    "score": 0.8844188451766968
                },
                {
                    "id": 8365977,
                    "contents": "Low-energy electron diffraction\nHistorical perspective An electron-diffraction experiment similar to modern LEED was the first to observe the wavelike properties of electrons, but LEED was established as an ubiquitous tool in surface science only with the advances in vacuum generation and electron detection techniques.",
                    "score": 0.8843648433685303
                },
                {
                    "id": 200655,
                    "contents": "Electron diffraction\nThere are all possible orientations of crystallographic planes and therefore the diffraction spots are formed around the transmitted beam in the whole 360-degree azimuthal range.",
                    "score": 0.883645236492157
                },
                {
                    "id": 784447,
                    "contents": "X-ray photoelectron spectroscopy\nwhere is the IMFP and is the axis perpendicular to the sample. In fact it is generally the case that the IMFP is only weakly material dependent, but rather strongly dependent on the photoelectron kinetic energy. Quantitatively we can relate to IMFP by where is the mean atomic diameter as calculated by the density so . The above formula was developed by Seah and Dench.",
                    "score": 0.8836116790771484
                },
                {
                    "id": 8365982,
                    "contents": "Low-energy electron diffraction\nIt soon became clear that the kinematic (single-scattering) theory, which had been successfully used to explain X-ray diffraction experiments, was inadequate for the quantitative interpretation of experimental data obtained from LEED. At this stage a detailed determination of surface structures, including adsorption sites, bond angles and bond lengths was not possible. A dynamical electron-diffraction theory, which took into account the possibility of multiple scattering, was established in the late 1960s. With this theory, it later became possible to reproduce experimental data with high precision. Experimental setup In order to keep the studied sample clean and free from unwanted adsorbates, LEED experiments are performed in an ultra-high vacuum environment (residual gas pressure <10−7 Pa). LEED optics The main components of a LEED instrument are:",
                    "score": 0.882552981376648
                },
                {
                    "id": 6724839,
                    "contents": "Powder diffraction\nPowder diffraction is a scientific technique using X-ray, neutron, or electron diffraction on powder or microcrystalline samples for structural characterization of materials. An instrument dedicated to performing such powder measurements is called a powder diffractometer. Powder diffraction stands in contrast to single crystal diffraction techniques, which work best with a single, well-ordered crystal. Explanation",
                    "score": 0.8821631669998169
                },
                {
                    "id": 7919693,
                    "contents": "Selected area diffraction\nSAD is similar to X-ray diffraction, but unique in that areas as small as several hundred nanometers in size can be examined, whereas X-ray diffraction typically samples areas several centimeters in size. See also Diffraction Transmission electron microscope Electron crystallography CrysTBox X-ray (Powder) diffraction Convergent beam electron diffraction References Materials science Condensed matter physics Diffraction Crystallography Electron microscopy",
                    "score": 0.8820500373840332
                },
                {
                    "id": 6114470,
                    "contents": "Davisson–Germer experiment\nAccording to the de Broglie relation, electrons with kinetic energy of have a wavelength of . The experimental outcome was via Bragg's law, which closely matched the predictions. As Davisson and Germer state in their 1928 follow-up paper to their Nobel prize winning paper, \"These results, including the failure of the data to satisfy the Bragg formula, are in accord with those previously obtained in our experiments on electron diffraction. The reflection data fail to satisfy the Bragg relation for the same reason that the electron diffraction beams fail to coincide with their Laue beam analogues.\" However, they add, \"The calculated wave-lengths are in excellent agreement with the theoretical values of h/mv as shown in the accompanying table.\" So although electron energy diffraction does not follow the Bragg law, it did confirm de Broglie's theory that particles behave like waves. However, the experiments did not follow the de Broglie calculations which led to attempts by Carl Eckart,",
                    "score": 0.881973147392273
                },
                {
                    "id": 3086296,
                    "contents": "Arthur Compton\nCompton's first book, X-Rays and Electrons, was published in 1926. In it he showed how to calculate the densities of diffracting materials from their X-ray diffraction patterns. He revised his book with the help of Samuel K. Allison to produce X-Rays in Theory and Experiment (1935). This work remained a standard reference for the next three decades.",
                    "score": 0.881352961063385
                },
                {
                    "id": 8365991,
                    "contents": "Low-energy electron diffraction\nThe interaction between the scatterers present in the surface and the incident electrons is most conveniently described in reciprocal space. In three dimensions the primitive reciprocal lattice vectors are related to the real space lattice {a, b, c} in the following way: For an incident electron with wave vector and scattered wave vector , the condition for constructive interference and hence diffraction of scattered electron waves is given by the Laue condition: where (h, k, l) is a set of integers, and",
                    "score": 0.8812361359596252
                },
                {
                    "id": 8365983,
                    "contents": "Low-energy electron diffraction\nAn electron gun from which monochromatic electrons are emitted by a cathode filament which is at a negative potential, typically 10–600 V, with respect to the sample. The electrons are accelerated and focused into a beam, typically about 0.1 to 0.5 mm wide, by a series of electrodes serving as electron lenses. Some of the electrons incident on the sample surface are backscattered elastically, and diffraction can be detected if sufficient order exists on the surface. This typically requires a region of single crystal surface as wide as the electron beam, although sometimes polycrystalline surfaces such as highly oriented pyrolytic graphite (HOPG) are sufficient.",
                    "score": 0.8811153769493103
                },
                {
                    "id": 1680389,
                    "contents": "Diffraction\nBecause the wavelength for even the smallest of macroscopic objects is extremely small, diffraction of matter waves is only visible for small particles, like electrons, neutrons, atoms and small molecules. The short wavelength of these matter waves makes them ideally suited to study the atomic crystal structure of solids and large molecules like proteins. Relatively larger molecules like buckyballs were also shown to diffract. Bragg diffraction Diffraction from a three-dimensional periodic structure such as atoms in a crystal is called Bragg diffraction. It is similar to what occurs when waves are scattered from a diffraction grating. Bragg diffraction is a consequence of interference between waves reflecting from different crystal planes. The condition of constructive interference is given by Bragg's law: where λ is the wavelength, d is the distance between crystal planes, θ is the angle of the diffracted wave. and m is an integer known as the order of the diffracted beam.",
                    "score": 0.8810360431671143
                },
                {
                    "id": 22611102,
                    "contents": "Precession electron diffraction\nBecause this process is highly automated, the quality of the recorded diffraction patterns is crucial to the software's ability to accurately compare and assign orientations to each pixel. Thus, the advantages of PED are well-suited for use with this scanning technique. By instead recording a PED pattern at each pixel, dynamical effects are reduced, and the patterns are more easily compared to simulated data, improving the accuracy of the automated phase/orientation assignment. Beyond diffraction Although the PED technique was initially developed for its improved diffraction applications, the advantageous properties of the technique have been found to enhance many other investigative techniques in the TEM. These include bright field and dark field imaging, electron tomography, and composition-probing techniques like energy-dispersive x-ray spectroscopy (EDS) and electron energy loss spectroscopy (EELS).",
                    "score": 0.880774974822998
                },
                {
                    "id": 1337590,
                    "contents": "X-ray crystallography\nX-rays range in wavelength from 10 to 0.01 nanometers; a typical wavelength used for crystallography is 1 Å (0.1 nm), which is on the scale of covalent chemical bonds and the radius of a single atom. Longer-wavelength photons (such as ultraviolet radiation) would not have sufficient resolution to determine the atomic positions. At the other extreme, shorter-wavelength photons such as gamma rays are difficult to produce in large numbers, difficult to focus, and interact too strongly with matter, producing particle-antiparticle pairs. Therefore, X-rays are the \"sweetspot\" for wavelength when determining atomic-resolution structures from the scattering of electromagnetic radiation.",
                    "score": 0.8804083466529846
                },
                {
                    "id": 20043626,
                    "contents": "Anomalous diffraction theory\nAnother limiting approximation for optically soft particles is Rayleigh scattering, which is valid for small size parameters. Notes and references Scattering, absorption and radiative transfer (optics)",
                    "score": 0.8791354298591614
                },
                {
                    "id": 6724874,
                    "contents": "Powder diffraction\nSee also Bragg diffraction Condensed matter physics Crystallographic database Crystallography Diffractometer Electron crystallography Electron diffraction Materials science Metallurgy Neutron diffraction Pair distribution function Solid state chemistry Texture (crystalline) Ultrafast x-ray X-ray crystallography X-ray scattering techniques References Further reading External links International Centre for Diffraction Data Powder Diffraction on the Web The Area DIffraction Machine – software to analyze powder diffraction data Powder diffraction at ILL Diffraction Neutron-related techniques Synchrotron-related techniques Diffraction",
                    "score": 0.8790249824523926
                },
                {
                    "id": 8057560,
                    "contents": "Electron scattering\nElectrons may be scattered through a solid in several ways: Not at all: no electron scattering occurs at all and the beam passes straight through. Single scattering: when an electron is scattered just once. Plural scattering: when electron(s) scatter several times. Multiple scattering: when electron(s) scatter many times over. The likelihood of an electron scattering and the degree of the scattering is a probability function of the specimen thickness to the mean free path. History The principle of the electron was first theorised in the period of 1838-1851 by a natural philosopher by the name of Richard Laming who speculated the existence of sub-atomic, unit charged particles; he also pictured the atom as being an 'electrosphere' of concentric shells of electrical particles surrounding a material core.",
                    "score": 0.8789340853691101
                },
                {
                    "id": 1337641,
                    "contents": "X-ray crystallography\nDiffraction theory The main goal of X-ray crystallography is to determine the density of electrons f(r) throughout the crystal, where r represents the three-dimensional position vector within the crystal. To do this, X-ray scattering is used to collect data about its Fourier transform F(q), which is inverted mathematically to obtain the density defined in real space, using the formula where the integral is taken over all values of q. The three-dimensional real vector q represents a point in reciprocal space, that is, to a particular oscillation in the electron density as one moves in the direction in which q points. The length of q corresponds to divided by the wavelength of the oscillation. The corresponding formula for a Fourier transform will be used below where the integral is summed over all possible values of the position vector r within the crystal.",
                    "score": 0.8784332275390625
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_25",
        "question": "Nelson, et al. (Science 238, 1670 (1987)) examined several weakly bound gas-phase complexes of ammonia in search of examples in which the $\\mathrm{H}$ atoms in $\\mathrm{NH}_3$ formed hydrogen bonds, but found none. For example, they found that the complex of $\\mathrm{NH}_3$ and $\\mathrm{CO}_2$ has the carbon atom nearest the nitrogen (299 pm away): the $\\mathrm{CO}_2$ molecule is at right angles to the $\\mathrm{C}-\\mathrm{N}$ 'bond', and the $\\mathrm{H}$ atoms of $\\mathrm{NH}_3$ are pointing away from the $\\mathrm{CO}_2$. The magnitude of the permanent dipole moment of this complex is reported as $1.77 \\mathrm{D}$. If the $\\mathrm{N}$ and $\\mathrm{C}$ atoms are the centres of the negative and positive charge distributions, respectively, what is the magnitude of those partial charges (as multiples of $e$ )?",
        "golden_answers": [
            " 0.123"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1567759,
                    "contents": "Ammonia\nThe ammonia molecule has a trigonal pyramidal shape as predicted by the valence shell electron pair repulsion theory (VSEPR theory) with an experimentally determined bond angle of 106.7°. The central nitrogen atom has five outer electrons with an additional electron from each hydrogen atom. This gives a total of eight electrons, or four electron pairs that are arranged tetrahedrally. Three of these electron pairs are used as bond pairs, which leaves one lone pair of electrons. The lone pair repels more strongly than bond pairs, therefore the bond angle is not 109.5°, as expected for a regular tetrahedral arrangement, but 106.8°. This shape gives the molecule a dipole moment and makes it polar. The molecule's polarity, and especially, its ability to form hydrogen bonds, makes ammonia highly miscible with water. The lone pair makes ammonia a base, a proton acceptor. Ammonia is moderately basic; a 1.0 M aqueous solution has a pH of 11.6, and if a strong acid is added to such a solution",
                    "score": 0.8713100552558899
                },
                {
                    "id": 1567760,
                    "contents": "Ammonia\nmiscible with water. The lone pair makes ammonia a base, a proton acceptor. Ammonia is moderately basic; a 1.0 M aqueous solution has a pH of 11.6, and if a strong acid is added to such a solution until the solution is neutral (pH = 7), 99.4% of the ammonia molecules are protonated. Temperature and salinity also affect the proportion of NH4+. The latter has the shape of a regular tetrahedron and is isoelectronic with methane.",
                    "score": 0.850470781326294
                },
                {
                    "id": 2340726,
                    "contents": "Hydride\nIn chemistry, a hydride is formally the anion of hydrogen, H−. The term is applied loosely. At one extreme, all compounds containing covalently bound H atoms are called hydrides: water (H2O) is a hydride of oxygen, ammonia is a hydride of nitrogen, etc. For inorganic chemists, hydrides refer to compounds and ions in which hydrogen is covalently attached to a less electronegative element. In such cases, the H centre has nucleophilic character, which contrasts with the protic character of acids. The hydride anion is very rarely observed. Almost all of the elements form binary compounds with hydrogen, the exceptions being He, Ne, Ar, Kr, Pm, Os, Ir, Rn, Fr, and Ra. Exotic molecules such as positronium hydride have also been made.",
                    "score": 0.8503045439720154
                },
                {
                    "id": 4130875,
                    "contents": "Brønsted–Lowry acid–base theory\nAn analogous reaction occurs in liquid ammonia NH3 + NH3 <=> NH4+ + NH2^{-} Thus, the ammonium ion, , plays the same role in liquid ammonia as does the hydronium ion in water and the amide ion, , is analogous to the hydroxide ion. Ammonium salts behave as acids, and amides behave as bases. Some non-aqueous solvents can behave as bases, that is, proton acceptors, in relation to Brønsted–Lowry acids. HA + S <=> A- + SH+ where S stands for a solvent molecule. The most important such solvents are dimethylsulfoxide, DMSO, and acetonitrile, CH3CN, as these solvents have been widely used to measure the acid dissociation constants of organic molecules. Because DMSO is a stronger proton acceptor than H2O the acid becomes a stronger acid in this solvent than in water. Indeed, many molecules behave as acids in non-aqueous solution that do not do so in aqueous solution. An extreme case occurs with carbon acids, where a proton is extracted from a C-H bond.",
                    "score": 0.8482748866081238
                },
                {
                    "id": 1555264,
                    "contents": "Acid\nBrønsted–Lowry theory can be used to describe reactions of molecular compounds in nonaqueous solution or the gas phase. Hydrogen chloride (HCl) and ammonia combine under several different conditions to form ammonium chloride, NH4Cl. In aqueous solution HCl behaves as hydrochloric acid and exists as hydronium and chloride ions. The following reactions illustrate the limitations of Arrhenius's definition: H3O + Cl + NH3 → Cl + NH(aq) + H2O HCl(benzene) + NH3(benzene) → NH4Cl(s) HCl(g) + NH3(g) → NH4Cl(s) As with the acetic acid reactions, both definitions work for the first example, where water is the solvent and hydronium ion is formed by the HCl solute. The next two reactions do not involve the formation of ions but are still proton-transfer reactions. In the second reaction hydrogen chloride and ammonia (dissolved in benzene) react to form solid ammonium chloride in a benzene solvent and in the third gaseous HCl and NH3 combine to form the solid. Lewis acids",
                    "score": 0.8476046323776245
                },
                {
                    "id": 28257486,
                    "contents": "Larry Curtiss\nCurtiss is a fellow of the American Association for the Advancement of Science. Early life and education Curtiss received his bachelor’s degree in chemistry from the University of Wisconsin-Madison in 1969. He then attended Carnegie-Mellon University, where he completed his master's in physical chemistry in 1971, and his Ph.D. in physical chemistry in 1973. While a graduate student, he worked under the supervision of pioneering chemist Sir John Anthony Pople, who won the Nobel Prize in chemistry for his work on computational methods in quantum chemistry. Curtiss’s thesis focused on quantum chemical studies of hydrogen bonded complexes. After graduating in 1973, he became a research fellow at Battelle Memorial Institute in Columbus, Ohio until 1976.",
                    "score": 0.8468979001045227
                },
                {
                    "id": 3099036,
                    "contents": "Noble gas compound\nNoble gas compounds are chemical compounds that include an element from the noble gases, group 18 of the periodic table. Although the noble gases are generally unreactive elements, many such compounds have been observed, particularly involving the element xenon. From the standpoint of chemistry, the noble gases may be divided into two groups: the relatively reactive krypton (ionisation energy 14.0 eV), xenon (12.1 eV), and radon (10.7 eV) on one side, and the very unreactive argon (15.8 eV), neon (21.6 eV), and helium (24.6 eV) on the other. Consistent with this classification, Kr, Xe, and Rn form compounds that can be isolated in bulk at or near standard temperature and pressure (at least in principle for the highly radioactive radon), whereas He, Ne, Ar have been observed to form true chemical bonds using spectroscopic techniques, but only when frozen into a noble gas matrix at temperatures of 40 K or lower, in supersonic jets of noble gas, or under extremely high pressures with",
                    "score": 0.8453360795974731
                },
                {
                    "id": 705202,
                    "contents": "Oganesson\nCalculations on the diatomic molecule showed a bonding interaction roughly equivalent to that calculated for , and a dissociation energy of 6 kJ/mol, roughly 4 times of that of . Most strikingly, it was calculated to have a bond length shorter than in by 0.16 Å, which would be indicative of a significant bonding interaction. On the other hand, the compound OgH+ exhibits a dissociation energy (in other words proton affinity of oganesson) that is smaller than that of RnH+.",
                    "score": 0.8449295163154602
                },
                {
                    "id": 1128595,
                    "contents": "Nitrogen\nNitrogen bonds to almost all the elements in the periodic table except the first three noble gases, helium, neon, and argon, and some of the very short-lived elements after bismuth, creating an immense variety of binary compounds with varying properties and applications. Many binary compounds are known: with the exception of the nitrogen hydrides, oxides, and fluorides, these are typically called nitrides. Many stoichiometric phases are usually present for most elements (e.g. MnN, Mn6N5, Mn3N2, Mn2N, Mn4N, and MnxN for 9.2 < x < 25.3). They may be classified as \"salt-like\" (mostly ionic), covalent, \"diamond-like\", and metallic (or interstitial), although this classification has limitations generally stemming from the continuity of bonding types instead of the discrete and separate types that it implies. They are normally prepared by directly reacting a metal with nitrogen or ammonia (sometimes after heating), or by thermal decomposition of metal amides: 3 Ca + N2 → Ca3N2",
                    "score": 0.8441978693008423
                },
                {
                    "id": 11954791,
                    "contents": "Determination of equilibrium constants\nThe diagram at the right shows the result of a refinement of the stability constants of Ni(Gly)+, Ni(Gly)2 and (where GlyH = glycine). The observed values are shown a blue diamonds and the species concentrations, as a percentage of the total nickel, are superimposed. The residuals are shown in the lower box. The residuals are not distributed as randomly as would be expected. This is due to the variation of liquid junction potentials and other effects at the glass/liquid interfaces. Those effects are very slow compared to the rate at which equilibrium is established. Physical constraints Some physical constraints are usually incorporated in the calculations. For example, all the concentrations of free reactants and species must have positive values and association constants must have positive values. With spectrophotometric data the calculated molar absorptivity (or emissivity) values should all be positive. Most computer programs do not impose this constraint on the calculations.",
                    "score": 0.8440774083137512
                },
                {
                    "id": 1555749,
                    "contents": "Alkali metal\nhydrogen species, being the foundation of acid-base chemistry. As an example of hydrogen's unorthodox properties stemming from its unusual electron configuration and small size, the hydrogen ion is very small (radius around 150 fm compared to the 50–220 pm size of most other atoms and ions) and so is nonexistent in condensed systems other than in association with other atoms or molecules. Indeed, transferring of protons between chemicals is the basis of acid-base chemistry. Also unique is hydrogen's ability to form hydrogen bonds, which are an effect of charge-transfer, electrostatic, and electron correlative contributing phenomena. While analogous lithium bonds are also known, they are mostly electrostatic. Nevertheless, hydrogen can take on the same structural role as the alkali metals in some molecular crystals, and has a close relationship with the lightest alkali metals (especially lithium).",
                    "score": 0.8415836095809937
                },
                {
                    "id": 26351018,
                    "contents": "William J. Evans (chemist)\nFurther exploration of dinitrogen reduction led to the synthesis of the first crystallographically characterizable molecular complexes containing Pr2+, Gd2+, Tb2+, Ho2+, Y2+, Er2+, and Lu2+ ions. These new lanthanide ions unexpectedly had 4fn5d1 electron configurations, and not the conventional 4fn+1 configuration generated by reduction of 4fn Ln3+ ions of Eu, Yb, Sm, Tm Dy, and Nd. The first molecular complexes of U2+ and Th2+ were also discovered in the Evans lab. In the Th2+ case, the complex contained the first example of any ion with a 6d2 electron configuration. This is the configuration expected for superheavy metal ions like Rf2+ and Db3+.",
                    "score": 0.8414028286933899
                },
                {
                    "id": 1567771,
                    "contents": "Ammonia\nHgCl2 + 2 NH3 → HgCl(NH2) + NH4Cl Ammonia forms 1:1 adducts with a variety of Lewis acids such as I2, phenol, and Al(CH3)3. Ammonia is a hard base (HSAB theory) and its E & C parameters are EB = 2.31 and C B = 2.04. Its relative donor strength toward a series of acids, versus other Lewis bases, can be illustrated by C-B plots. Detection and determination Ammonia in solution",
                    "score": 0.841314435005188
                },
                {
                    "id": 1759803,
                    "contents": "Hydrogen bond\nN−H···:N (13 kJ/mol or 3.1 kcal/mol), illustrated by ammonia-ammonia N−H···:O (8 kJ/mol or 1.9 kcal/mol), illustrated water-amide ···: (18 kJ/mol or 4.3 kcal/mol) The strength of intermolecular hydrogen bonds is most often evaluated by measurements of equilibria between molecules containing donor and/or acceptor units, most often in solution. The strength of intramolecular hydrogen bonds can be studied with equilibria between conformers with and without hydrogen bonds. The most important method for the identification of hydrogen bonds also in complicated molecules is crystallography, sometimes also NMR-spectroscopy. Structural details, in particular distances between donor and acceptor which are smaller than the sum of the van der Waals radii can be taken as indication of the hydrogen bond strength.",
                    "score": 0.8412021398544312
                },
                {
                    "id": 1128024,
                    "contents": "Noble gas\nThe discovery of the noble gases aided in the development of a general understanding of atomic structure. In 1895, French chemist Henri Moissan attempted to form a reaction between fluorine, the most electronegative element, and argon, one of the noble gases, but failed. Scientists were unable to prepare compounds of argon until the end of the 20th century, but these attempts helped to develop new theories of atomic structure. Learning from these experiments, Danish physicist Niels Bohr proposed in 1913 that the electrons in atoms are arranged in shells surrounding the nucleus, and that for all noble gases except helium the outermost shell always contains eight electrons. In 1916, Gilbert N. Lewis formulated the octet rule, which concluded an octet of electrons in the outer shell was the most stable arrangement for any atom; this arrangement caused them to be unreactive with other elements since they did not require any more electrons to complete their outer shell.",
                    "score": 0.8408994674682617
                },
                {
                    "id": 14309070,
                    "contents": "Solid hydrogen\nMonte Carlo methods together with a first-principles treatment of anharmonic vibrational effects have then been used to obtain the relative Gibbs free energies of these structures and hence to obtain a theoretical pressure-temperature phase diagram that is in reasonable quantitative agreement with experiment. On this basis, Phase II is believed to be a molecular structure of P21/c symmetry; Phase III is (or is similar to) a structure of C2/c symmetry consisting of flat layers of molecules in a distorted hexagonal arrangement; and Phase IV is (or is similar to) a structure of Pc symmetry, consisting of alternate layers of strongly bonded molecules and weakly bonded graphene-like sheets.",
                    "score": 0.8404812216758728
                },
                {
                    "id": 21013271,
                    "contents": "Binary compounds of hydrogen\nNon-classical covalent hydrides A molecular hydride may be able to bind to hydrogen molecules acting as a ligand. The complexes are termed non-classical covalent hydrides. These complexes contain more hydrogen than the classical covalent hydrides, but are only stable at very low temperatures. They may be isolated in inert gas matrix, or as a cryogenic gas. Others have only been predicted using computational chemistry. Hydrogen solutions Hydrogen has a highly variable solubility in the elements. When the continuous phase of the solution is a metal, it is called a metallic hydride or interstitial hydride, on account of the position of the hydrogen within the crystal structure of the metal. In solution, hydrogen can occur in either the atomic or molecular form. For some elements, when hydrogen content exceeds its solubility, the excess precipitates out as a stoichiometric compound. The table below shows the solubility of hydrogen in each element as a molar ratio at and 100 kPa.",
                    "score": 0.840279221534729
                },
                {
                    "id": 18094709,
                    "contents": "Hydrogen ion cluster\nClampitt and Gowland found clusters with an odd number of hydrogen atoms and later showed that was relatively stable. formed the core of this cluster with six molecules surrounding it. Hiroka studied the stability of the odd numbered clusters in gas up to . Bae determined that was especially stable amongst the odd numbered clusters. Kirchner discovered even numbered atomic clusters in gas at lower concentrations than the odd numbered atom clusters. was twenty times less abundant than . , and were detected at lesser amounts than . Kurosaki and Takayanagi showed that is much more stable than other even clusters and showed antiprismatic symmetry of order 4 ( molecular symmetry). This turnstile structured molecule was computationally found to be more energetically stable than a ring of five hydrogen atoms around a proton. Negative hydrogen clusters have not been found to exist. is theoretically unstable, but in theory is bound at 0.003 eV.",
                    "score": 0.8401434421539307
                },
                {
                    "id": 1555744,
                    "contents": "Alkali metal\nPseudo-alkali metals Many other substances are similar to the alkali metals in their tendency to form monopositive cations. Analogously to the pseudohalogens, they have sometimes been called \"pseudo-alkali metals\". These substances include some elements and many more polyatomic ions; the polyatomic ions are especially similar to the alkali metals in their large size and weak polarising power. Hydrogen The element hydrogen, with one electron per neutral atom, is usually placed at the top of Group 1 of the periodic table for convenience, but hydrogen is not normally considered to be an alkali metal; when it is considered to be an alkali metal, it is because of its atomic properties and not its chemical properties. Under typical conditions, pure hydrogen exists as a diatomic gas consisting of two atoms per molecule (H2); however, the alkali metals form diatomic molecules (such as dilithium, Li2) only at high temperatures, when they are in the gaseous state.",
                    "score": 0.8399956226348877
                },
                {
                    "id": 10106698,
                    "contents": "Atomism\n2nd. That ammonia is a binary compound of hydrogen and azote nitrogen, and the relative weights of the two atoms are as 1:5, nearly... Dalton concluded that the fixed proportions of elements by weight suggested that the atoms of one element combined with only a limited number of atoms of the other elements to form the substances that he listed.",
                    "score": 0.8392598628997803
                },
                {
                    "id": 636066,
                    "contents": "Dudley R. Herschbach\nIn 1963, Herschbach returned to Harvard University as a professor of chemistry. There he continued his work on molecular-beam reactive dynamics, working with graduate students Sanford Safron and Walter Miller on the reactions of alkali atoms with alkali halides. In 1967, Yuan T. Lee joined the lab as a postdoctoral student, and Herschbach, Lee, and graduate students Doug MacDonald and Pierre LeBreton began to construct a \"supermachine\" for studying collisions such as Cl + Br2 and hydrogen and halogen reactions.",
                    "score": 0.8392027616500854
                },
                {
                    "id": 1128601,
                    "contents": "Nitrogen\nof nitrogen compared to oxygen and the presence of only one lone pair in NH3 rather than two in H2O. It is a weak base in aqueous solution (pKb 4.74); its conjugate acid is ammonium, . It can also act as an extremely weak acid, losing a proton to produce the amide anion, . It thus undergoes self-dissociation, similar to water, to produce ammonium and amide. Ammonia burns in air or oxygen, though not readily, to produce nitrogen gas; it burns in fluorine with a greenish-yellow flame to give nitrogen trifluoride. Reactions with the other nonmetals are very complex and tend to lead to a mixture of products. Ammonia reacts on heating with metals to give nitrides.",
                    "score": 0.8388198614120483
                },
                {
                    "id": 1555748,
                    "contents": "Alkali metal\nThe 1s1 electron configuration of hydrogen, while analogous to that of the alkali metals (ns1), is unique because there is no 1p subshell. Hence it can lose an electron to form the hydron H+, or gain one to form the hydride ion H−. In the former case it resembles superficially the alkali metals; in the latter case, the halogens, but the differences due to the lack of a 1p subshell are important enough that neither group fits the properties of hydrogen well. Group 14 is also a good fit in terms of thermodynamic properties such as ionisation energy and electron affinity, but hydrogen cannot be tetravalent. Thus none of the three placements are entirely satisfactory, although group 1 is the most common placement (if one is chosen) because the hydron is by far the most important of all monatomic hydrogen species, being the foundation of acid-base chemistry. As an example of hydrogen's unorthodox properties stemming from its unusual electron configuration and small size, the hydrogen ion",
                    "score": 0.838721752166748
                },
                {
                    "id": 752984,
                    "contents": "Electron configuration\nNoble gas configuration is the electron configuration of noble gases. The basis of all chemical reactions is the tendency of chemical elements to acquire stability. Main-group atoms generally obey the octet rule, while transition metals generally obey the 18-electron rule. The noble gases (He, Ne, Ar, Kr, Xe, Rn) are less reactive than other elements because they already have a noble gas configuration. Oganesson is predicted to be more reactive due to relativistic effects for heavy atoms. {|class=wikitable ! Period ! Element ! colspan=\"7\"| Configuration |- | 1 || He || 1s2|| || || || || || |- | 2 || Ne || 1s2||2s2 2p6|| || || || || |- | 3 || Ar || 1s2||2s2 2p6||3s2 3p6|| || || || |- | 4 || Kr || 1s2||2s2 2p6||3s2 3p6||4s2 3d10 4p6|| || || |- | 5 || Xe || 1s2||2s2 2p6||3s2 3p6||4s2 3d10 4p6||5s2 4d10 5p6|| || |- | 6 || Rn || 1s2||2s2 2p6||3s2 3p6||4s2 3d10 4p6||5s2 4d10 5p6||6s2 4f14 5d10 6p6|| |-",
                    "score": 0.8387010097503662
                },
                {
                    "id": 11242072,
                    "contents": "Timeline of chemistry\n1937Pyotr Kapitsa, John Allen and Don Misener produce supercooled helium-4, the first zero-viscosity superfluid, a substance that displays quantum mechanical properties on a macroscopic scale. 1938Otto Hahn discovers the process of nuclear fission in uranium and thorium. 1939Linus Pauling publishes The Nature of the Chemical Bond, a compilation of a decades worth of work on chemical bonding. It is one of the most important modern chemical texts. It explains hybridization theory, covalent bonding and ionic bonding as explained through electronegativity, and resonance as a means to explain, among other things, the structure of benzene. 1940Edwin McMillan and Philip H. Abelson identify neptunium, the lightest and first synthesized transuranium element, found in the products of uranium fission. McMillan would found a lab at Berkeley that would be involved in the discovery of many new elements and isotopes.",
                    "score": 0.8384777903556824
                },
                {
                    "id": 3099037,
                    "contents": "Noble gas compound\nchemical bonds using spectroscopic techniques, but only when frozen into a noble gas matrix at temperatures of 40 K or lower, in supersonic jets of noble gas, or under extremely high pressures with metals.",
                    "score": 0.837976336479187
                },
                {
                    "id": 1128031,
                    "contents": "Noble gas\nThe noble gases are nearly ideal gases under standard conditions, but their deviations from the ideal gas law provided important clues for the study of intermolecular interactions. The Lennard-Jones potential, often used to model intermolecular interactions, was deduced in 1924 by John Lennard-Jones from experimental data on argon before the development of quantum mechanics provided the tools for understanding intermolecular forces from first principles. The theoretical analysis of these interactions became tractable because the noble gases are monatomic and the atoms spherical, which means that the interaction between the atoms is independent of direction, or isotropic. Chemical properties",
                    "score": 0.8378788232803345
                },
                {
                    "id": 1753306,
                    "contents": "Hydrogen\nHydrogen is nonmetallic, except at extremely high pressures, and readily forms a single covalent bond with most nonmetallic elements, forming compounds such as water and nearly all organic compounds. Hydrogen plays a particularly important role in acid–base reactions because these reactions usually involve the exchange of protons between soluble molecules. In ionic compounds, hydrogen can take the form of a negative charge (i.e., anion) where it is known as a hydride, or as a positively charged (i.e., cation) species denoted by the symbol H+. The H+ cation is simply a proton (symbol p) but its behavior in aqueous solutions and in ionic compounds involves screening of its electric charge by nearby polar molecules or anions. Because hydrogen is the only neutral atom for which the Schrödinger equation can be solved analytically, the study of its energetics and chemical bonding has played a key role in the development of quantum mechanics.",
                    "score": 0.8377091884613037
                },
                {
                    "id": 1555746,
                    "contents": "Alkali metal\nThe first ionisation energy of hydrogen (1312.0 kJ/mol) is much higher than that of the alkali metals. As only one additional electron is required to fill in the outermost shell of the hydrogen atom, hydrogen often behaves like a halogen, forming the negative hydride ion, and is very occasionally considered to be a halogen on that basis. (The alkali metals can also form negative ions, known as alkalides, but these are little more than laboratory curiosities, being unstable.) An argument against this placement is that formation of hydride from hydrogen is endothermic, unlike the exothermic formation of halides from halogens. The radius of the H− anion also does not fit the trend of increasing size going down the halogens: indeed, H− is very diffuse because its single proton cannot easily control both electrons. It was expected for some time that liquid hydrogen would show metallic properties; while this has been shown to not be the case, under extremely high pressures, such as those",
                    "score": 0.8376410007476807
                },
                {
                    "id": 11777115,
                    "contents": "Hydron (chemistry)\nThe unsolvated hydron (a completely free or \"naked\" hydrogen atomic nucleus) does not exist in the condensed (liquid or solid) phase. Although superacids are sometimes said to owe their extraordinary hydron-donating power to the presence of \"free hydrons\", such a statement is highly misleading: even for a source of \"free hydrons\" like , one of the superacidic cations present in the superacid fluoroantimonic acid (HF:SbF5), detachment of a free still comes at an enormous energetic penalty on the order of several hundred kcal/mol. This effectively rules out the possibility of the free hydron being present in solution, even as a fleeting intermediate. For this reason, in liquid strong acids, hydrons are believed to diffuse by sequential transfer from one molecule to the next along a network of hydrogen bonds through what is known as the Grotthuss mechanism.",
                    "score": 0.8374079465866089
                },
                {
                    "id": 1128588,
                    "contents": "Nitrogen\nAt atmospheric pressure, molecular nitrogen condenses (liquefies) at 77 K (−195.79 °C) and freezes at 63 K (−210.01 °C) into the beta hexagonal close-packed crystal allotropic form. Below 35.4 K (−237.6 °C) nitrogen assumes the cubic crystal allotropic form (called the alpha phase). Liquid nitrogen, a colourless fluid resembling water in appearance, but with 80.8% of the density (the density of liquid nitrogen at its boiling point is 0.808 g/mL), is a common cryogen. Solid nitrogen has many crystalline modifications. It forms a significant dynamic surface coverage on Pluto and outer moons of the Solar System such as Triton. Even at the low temperatures of solid nitrogen it is fairly volatile and can sublime to form an atmosphere, or condense back into nitrogen frost. It is very weak and flows in the form of glaciers and on Triton geysers of nitrogen gas come from the polar ice cap region. Dinitrogen complexes",
                    "score": 0.8370761871337891
                },
                {
                    "id": 1336531,
                    "contents": "William Lipscomb\nLipscomb's group did not propose or discover the three-center two-electron bond, nor did they develop formulas that give the proposed mechanism. In 1943, Longuet-Higgins, while still an undergraduate at Oxford, was the first to explain the structure and bonding of the boron hydrides. The paper reporting the work, written with his tutor R. P. Bell, also reviews the history of the subject beginning with the work of Dilthey. Shortly after, in 1947 and 1948, experimental spectroscopic work was performed by Price",
                    "score": 0.8368040919303894
                },
                {
                    "id": 7982427,
                    "contents": "Fluoroantimonic acid\nThe gas-phase acidity (GPA) of individual species present in the mixture have been calculated using density functional theory methods. (Solution-phase pKas of these species can, in principle, be estimated by taking into account solvation energies, but do not appear to be reported in the literature as of 2019.) For example, the ion-pair [H2F]+· was estimated to have a GPA of 254 kcal/mol. For comparison, the commonly encountered superacid triflic acid, TfOH, is a substantially weaker acid by this measure, with a GPA of 299 kcal/mol. However, certain carborane superacids have GPAs lower than that of [H2F]+·. For example, H(CHB11Cl11) has an experimentally determined GPA of 241 kcal/mol.",
                    "score": 0.8359600305557251
                },
                {
                    "id": 3739592,
                    "contents": "HNC\nHNC may refer to: Hydrogen isocyanide, a molecule with the formula HNC that is important to the field of astrochemistry Heptanitrocubane, an experimental high explosive Higher National Certificate, a higher education qualification in the United Kingdom High Negotiations Committee, a Syrian political-military opposition bloc headquartered in Riyadh Classical-map Hyper-Netted-Chain equation, a method in many-body theoretical physics for interacting uniform electron liquids in two and three dimensions Hypernetted-chain equation, a closure relation to solve the Ornstein-Zernike equation commonly applied in statistical mechanics and fluid theory Hopkins-Nanjing Center, a joint educational venture between Nanjing University and Johns Hopkins University located in Nanjing, China Habits & Contradictions, album by Schoolboy Q Huddersfield Narrow Canal, Northern England",
                    "score": 0.8352563977241516
                },
                {
                    "id": 16655858,
                    "contents": "Properties of water\nA single water molecule can participate in a maximum of four hydrogen bonds because it can accept two bonds using the lone pairs on oxygen and donate two hydrogen atoms. Other molecules like hydrogen fluoride, ammonia, and methanol can also form hydrogen bonds. However, they do not show anomalous thermodynamic, kinetic or structural properties like those observed in water because none of them can form four hydrogen bonds: either they cannot donate or accept hydrogen atoms, or there are steric effects in bulky residues. In water, intermolecular tetrahedral structures form due to the four hydrogen bonds, thereby forming an open structure and a three-dimensional bonding network, resulting in the anomalous decrease in density when cooled below 4 °C. This repeated, constantly reorganizing unit defines a three-dimensional network extending throughout the liquid. This view is based upon neutron scattering studies and computer simulations, and it makes sense in the light of the unambiguously",
                    "score": 0.8343674540519714
                },
                {
                    "id": 6710530,
                    "contents": "Walter Heitler\nIn Zurich, with Fritz London, Heitler applied the new quantum mechanics to deal with the saturable, nondynamic forces of attraction and repulsion, i.e., exchange forces, of the hydrogen molecule. Their valence bond treatment of this problem, was a landmark in that it brought chemistry under quantum mechanics. Furthermore, their work greatly influenced chemistry through Linus Pauling, who had just received his doctorate and on a Guggenheim Fellowship visited Heitler and London in Zurich. Pauling spent much of his career studying the nature of the chemical bond. The application of quantum mechanics to chemistry would be a prominent theme in Heitler's career.",
                    "score": 0.8342435956001282
                },
                {
                    "id": 1772942,
                    "contents": "Hydrogen atom\nwhich, for the bound states, results in where denotes a Gegenbauer polynomial and is in units of . The solutions to the Schrödinger equation for hydrogen are analytical, giving a simple expression for the hydrogen energy levels and thus the frequencies of the hydrogen spectral lines and fully reproduced the Bohr model and went beyond it. It also yields two other quantum numbers and the shape of the electron's wave function (\"orbital\") for the various possible quantum-mechanical states, thus explaining the anisotropic character of atomic bonds. The Schrödinger equation also applies to more complicated atoms and molecules. When there is more than one electron or nucleus the solution is not analytical and either computer calculations are necessary or simplifying assumptions must be made.",
                    "score": 0.8340193033218384
                },
                {
                    "id": 1128599,
                    "contents": "Nitrogen\nThe largest category of nitrides are the interstitial nitrides of formulae MN, M2N, and M4N (although variable composition is perfectly possible), where the small nitrogen atoms are positioned in the gaps in a metallic cubic or hexagonal close-packed lattice. They are opaque, very hard, and chemically inert, melting only at very high temperatures (generally over 2500 °C). They have a metallic lustre and conduct electricity as do metals. They hydrolyse only very slowly to give ammonia or nitrogen. The nitride anion (N3−) is the strongest π donor known amongst ligands (the second-strongest is O2−). Nitrido complexes are generally made by thermal decomposition of azides or by deprotonating ammonia, and they usually involve a terminal {≡N}3− group. The linear azide anion (), being isoelectronic with nitrous oxide, carbon dioxide, and cyanate, forms many coordination complexes. Further catenation is rare, although (isoelectronic with carbonate and nitrate) is known. Hydrides",
                    "score": 0.8339923024177551
                },
                {
                    "id": 11242067,
                    "contents": "Timeline of chemistry\n1909S. P. L. Sørensen invents the pH concept and develops methods for measuring acidity. 1911Antonius van den Broek proposes the idea that the elements on the periodic table are more properly organized by positive nuclear charge rather than atomic weight. 1911The first Solvay Conference is held in Brussels, bringing together most of the most prominent scientists of the day. Conferences in physics and chemistry continue to be held periodically to this day. 1911Ernest Rutherford, Hans Geiger, and Ernest Marsden perform the gold foil experiment, which proves the nuclear model of the atom, with a small, dense, positive nucleus surrounded by a diffuse electron cloud. 1912William Henry Bragg and William Lawrence Bragg propose Bragg's law and establish the field of X-ray crystallography, an important tool for elucidating the crystal structure of substances. 1912Peter Debye develops the concept of molecular dipole to describe asymmetric charge distribution in some molecules.",
                    "score": 0.8337456583976746
                },
                {
                    "id": 4966230,
                    "contents": "VSEPR theory\nThe ammonia molecule (NH3) has three pairs of electrons involved in bonding, but there is a lone pair of electrons on the nitrogen atom. It is not bonded with another atom; however, it influences the overall shape through repulsions. As in methane above, there are four regions of electron density. Therefore, the overall orientation of the regions of electron density is tetrahedral. On the other hand, there are only three outer atoms. This is referred to as an AX3E type molecule because the lone pair is represented by an E. By definition, the molecular shape or geometry describes the geometric arrangement of the atomic nuclei only, which is trigonal-pyramidal for NH3.",
                    "score": 0.8336636424064636
                },
                {
                    "id": 6660699,
                    "contents": "Ammonia (data page)\nThis page provides supplementary chemical data on ammonia. Structure and properties Thermodynamic properties Vapor–liquid equilibrium data Table data (above) obtained from CRC Handbook of Chemistry and Physics 44th ed. The (s) notation indicates equilibrium temperature of vapor over solid. Otherwise temperature is equilibrium of vapor over liquid. Vapor-pressure formula for ammonia: log10P = A – B / (T − C), where P is pressure in kPa, and T is temperature in kelvins; A = 6.67956, B = 1002.711, C = 25.215 for T = 190 K through 333 K. Heat capacity of liquid and vapor Spectral data Regulatory data Safety data sheet The handling of this chemical may incur notable safety precautions... It is highly recommend that you seek the Safety Data Sheet (SDS) for this chemical from a reliable source and follow its directions. SIRI Science Stuff (Ammonia Solution) References External links IR spectrum (from NIST) Chemical data pages Chemical data pages cleanup",
                    "score": 0.8332947492599487
                },
                {
                    "id": 22856492,
                    "contents": "Ethanium\nEarlier calculations had predicted that the energies of the two forms should be 4 to 12 kcal/mol lower than the dissociated state + , and they should be separated by a slightly positive energy barrier. Gas-phase infrared spectroscopy by Yeh and others (1989) has shown that both forms are stable. The bridged structure has the lowest energy, 4 to 8 kcal/mol lower than the classical one.",
                    "score": 0.8332017660140991
                },
                {
                    "id": 24462825,
                    "contents": "Hydration number\nDetermination of hydration number Hydration numbers can be determined using a variety of different experimental methods. These include Raman spectroscopy, neutron and X-ray scattering, luminescence, and NMR. Hydration numbers can change depending on whether the species is locked into a crystalline lattice form or free flowing in solution. The apparent hydration number of a species can vary depending on which experimental method was used. Large alkali metal cations in particular, very common throughout nature and in biological systems, remain unreliably characterized. Methane clathrates",
                    "score": 0.8328949213027954
                },
                {
                    "id": 10430088,
                    "contents": "Molecular solid\nVan der Waals forces Argon, is a noble gas that has a full octet, no charge, and is nonpolar. These characteristics make it unfavorable for Argon to partake in metallic, covalent, and ionic bonds as well as most intermolecular interactions. It can though partake in van der Waals and London dispersion forces. These weak self-interactions are isotropic and result in the long-range ordering of the atoms into face centered cubic packing when cooled below -189.3. Similarly iodine, a linear diatomic molecule has a net dipole of zero and can only partake in van der Waals interactions that are fairly isotropic. This results in the bipyramidal symmetry. Dipole-dipole and quadrupole interactions",
                    "score": 0.8324899673461914
                },
                {
                    "id": 1336534,
                    "contents": "William Lipscomb\nThe Eberhardt, Crawford, and Lipscomb paper discussed above also devised the \"styx number\" method to catalog certain kinds of boron-hydride bonding configurations. Wandering atoms was a puzzle solved by Lipscomb in one of his few papers with no co-authors. Compounds of boron and hydrogen tend to form closed cage structures. Sometimes the atoms at the vertices of these cages move substantial distances with respect to each other. The diamond-square-diamond mechanism (diagram at left) was suggested by Lipscomb to explain this rearrangement of vertices. Following along in the diagram at left for example in the faces shaded in blue, a pair of triangular faces has a left-right diamond shape. First, the bond common to these adjacent triangles breaks, forming a square, and then the square collapses back to an up-down diamond shape by bonding the atoms that were not bonded before. Other researchers have discovered more about these rearrangements.",
                    "score": 0.8323897123336792
                },
                {
                    "id": 3941836,
                    "contents": "John Polanyi\nPolanyi's PhD studies at Manchester University focused on measuring the strengths of chemical bonds using thermal dissociation, building on Warhurst's graduate studies using a sodium flame apparatus to determine the likelihood that a collision between a sodium atom and another molecule would lead to a chemical reaction. For the majority of his career, Polanyi's research has focused on chemical dynamics, attempting to determine the mechanics of a chemical reaction, and the properties of chemical species in the transition state. While at the National Research Council (NRC), Polanyi evaluated transition state theory for its predictive powers, coming to the conclusion that the theory was flawed, largely due to a lack of knowledge about the forces at play in the transition state. Near the end of his stay at NRC, Polanyi worked in Gerhard Herzberg's lab, using spectroscopy to examine vibrational and rotational excitation in iodine molecules. During Polanyi's time at Princeton University, he",
                    "score": 0.8321115970611572
                },
                {
                    "id": 5606494,
                    "contents": "History of chemistry\nFor cases where no sharing was involved, Lewis in 1923 developed the electron pair theory of acids and base: Lewis redefined an acid as any atom or molecule with an incomplete octet that was thus capable of accepting electrons from another atom; bases were, of course, electron donors. His theory is known as the concept of Lewis acids and bases. In 1923, G. N. Lewis and Merle Randall published Thermodynamics and the Free Energy of Chemical Substances, first modern treatise on chemical thermodynamics. The 1920s saw a rapid adoption and application of Lewis's model of the electron-pair bond in the fields of organic and coordination chemistry. In organic chemistry, this was primarily due to the efforts of the British chemists Arthur Lapworth, Robert Robinson, Thomas Lowry, and Christopher Ingold; while in coordination chemistry, Lewis's bonding model was promoted through the efforts of the American chemist Maurice Huggins and the British chemist Nevil Sidgwick. Quantum mechanics",
                    "score": 0.8320741653442383
                },
                {
                    "id": 3099049,
                    "contents": "Noble gas compound\nCoordination compounds Coordination compounds such as Ar·BF3 have been postulated to exist at low temperatures, but have never been confirmed. Also, compounds such as WHe2 and HgHe2 were reported to have been formed by electron bombardment, but recent research has shown that these are probably the result of He being adsorbed on the surface of the metal; therefore, these compounds cannot truly be considered chemical compounds. Hydrates Hydrates are formed by compressing noble gases in water, where it is believed that the water molecule, a strong dipole, induces a weak dipole in the noble gas atoms, resulting in dipole-dipole interaction. Heavier atoms are more influenced than smaller ones, hence Xe•5.75 H2O was reported to have been the most stable hydrate; it has a melting point of 24 °C. The deuterated version of this hydrate has also been produced. Fullerene adducts",
                    "score": 0.8320696949958801
                },
                {
                    "id": 25524251,
                    "contents": "Pnictogen hydride\nAmmonia is produced industrially on the largest scale among all compounds. Like water, hydrogen bonding results in a high melting and boiling point compared to the other pnictogen hydrides, although 26% is lost on melting, another 7% as the liquid is heated to boiling, and the remaining 67% upon boiling. Other effects of hydrogen bonding are a high dielectric constant as well as low values of density, viscosity, and electrical conductivity. Like water, it is an excellent and often-used ionising solvent. Over twenty other hydrides of nitrogen are known, the most important being hydrazine (N2H4) and hydrogen azide (HN3). Hydrazine has physical properties that are remarkably similar to those of water: its melting and boiling points are 2.0 °C and 113.5 °C, the density of the solid at −5 °C is 1.146 g/cm3, while that of the liquid at 25 °C is 1.00 g/cm3. The azanes are a series which include ammonia, hydrazine and triazane.",
                    "score": 0.8317779898643494
                },
                {
                    "id": 1861877,
                    "contents": "Molecule\nWhen trying to define rigorously whether an arrangement of atoms is sufficiently stable to be considered a molecule, IUPAC suggests that it \"must correspond to a depression on the potential energy surface that is deep enough to confine at least one vibrational state\". This definition does not depend on the nature of the interaction between the atoms, but only on the strength of the interaction. In fact, it includes weakly bound species that would not traditionally be considered molecules, such as the helium dimer, He2, which has one vibrational bound state and is so loosely bound that it is only likely to be observed at very low temperatures.",
                    "score": 0.8316099643707275
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_26",
        "question": "The NOF molecule is an asymmetric rotor with rotational constants $3.1752 \\mathrm{~cm}^{-1}, 0.3951 \\mathrm{~cm}^{-1}$, and $0.3505 \\mathrm{~cm}^{-1}$. Calculate the rotational partition function of the molecule at $25^{\\circ} \\mathrm{C}$.",
        "golden_answers": [
            " 7.97"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 4700219,
                    "contents": "Rigid rotor\nis -fold degenerate: the functions with fixed and have the same energy. Introducing the rotational constant B, we write, In the units of reciprocal length the rotational constant is, with c the speed of light. If cgs units are used for h, c, and I, is expressed in wave numbers, cm−1, a unit that is often used for rotational-vibrational spectroscopy. The rotational constant depends on the distance . Often one writes where is the equilibrium value of (the value for which the interaction energy of the atoms in the rotor has a minimum). A typical rotational spectrum consists of a series of peaks that correspond to transitions between levels with different values of the angular momentum quantum number (). Consequently, rotational peaks appear at energies corresponding to an integer multiple of .",
                    "score": 0.9084345102310181
                },
                {
                    "id": 4039815,
                    "contents": "Molecular physics\nIn addition to the electronic excitation states which are known from atoms, molecules exhibit rotational and vibrational modes whose energy levels are quantized. The smallest energy differences exist between different rotational states: pure rotational spectra are in the far infrared region (about 30 - 150 μm wavelength) of the electromagnetic spectrum. Vibrational spectra are in the near infrared (about 1 - 5 μm) and spectra resulting from electronic transitions are mostly in the visible and ultraviolet regions. From measuring rotational and vibrational spectra properties of molecules like the distance between the nuclei can be specifically calculated. One important aspect of molecular physics is that the essential atomic orbital theory in the field of atomic physics expands to the molecular orbital theory. See also Born–Oppenheimer approximation Electrostatic deflection (molecular physics/nanotechnology) Molecular energy state Molecular modeling Rigid rotor Spectroscopy",
                    "score": 0.8947110176086426
                },
                {
                    "id": 4700224,
                    "contents": "Rigid rotor\nwhere is the fundamental vibrational frequency of the bond (in cm−1). This frequency is related to the reduced mass and the force constant (bond strength) of the molecule according to The non-rigid rotor is an acceptably accurate model for diatomic molecules but is still somewhat imperfect. This is because, although the model does account for bond stretching due to rotation, it ignores any bond stretching due to vibrational energy in the bond (anharmonicity in the potential).",
                    "score": 0.8945801258087158
                },
                {
                    "id": 18471745,
                    "contents": "Rotational partition function\nNonlinear molecules A rigid, nonlinear molecule has rotational energy levels determined by three rotational constants, conventionally written and , which can often be determined by rotational spectroscopy. In terms of these constants, the rotational partition function can be written in the high temperature limit as with again known as the rotational symmetry number which in general equals the number ways a molecule can be rotated to overlap itself in an indistinguishable way, i.e. that at most interchanges identical atoms. Like in the case of the diatomic treated explicitly above, this factor corrects for the fact that only a fraction of the nuclear spin functions can be used for any given molecular level to construct wavefunctions that overall obey the required exchange symmetries. The expression for works for asymmetric, symmetric and spherical top rotors. References",
                    "score": 0.8931940793991089
                },
                {
                    "id": 4700222,
                    "contents": "Rigid rotor\nHere is the z component of the permanent dipole moment. The moment is the vibronically averaged component of the dipole operator. Only the component of the permanent dipole along the axis of a heteronuclear molecule is non-vanishing. By the use of the orthogonality of the spherical harmonics it is possible to determine which values of , , , and will result in nonzero values for the dipole transition moment integral. This constraint results in the observed selection rules for the rigid rotor:",
                    "score": 0.8894227147102356
                },
                {
                    "id": 3433070,
                    "contents": "Rotational spectroscopy\nThe term in DJK has the effect of removing degeneracy present in the rigid rotor approximation, with different K values. Asymmetric top The quantum number J refers to the total angular momentum, as before. Since there are three independent moments of inertia, there are two other independent quantum numbers to consider, but the term values for an asymmetric rotor cannot be derived in closed form. They are obtained by individual matrix diagonalization for each J value. Formulae are available for molecules whose shape approximates to that of a symmetric top. The water molecule is an important example of an asymmetric top. It has an intense pure rotation spectrum in the far infrared region, below about 200 cm−1. For this reason far infrared spectrometers have to be freed of atmospheric water vapour either by purging with a dry gas or by evacuation. The spectrum has been analyzed in detail.",
                    "score": 0.8871443867683411
                },
                {
                    "id": 4700223,
                    "contents": "Rigid rotor\nNon-rigid linear rotor The rigid rotor is commonly used to describe the rotational energy of diatomic molecules but it is not a completely accurate description of such molecules. This is because molecular bonds (and therefore the interatomic distance ) are not completely fixed; the bond between the atoms stretches out as the molecule rotates faster (higher values of the rotational quantum number ). This effect can be accounted for by introducing a correction factor known as the centrifugal distortion constant (bars on top of various quantities indicate that these quantities are expressed in cm−1): where is the fundamental vibrational frequency of the bond (in cm−1). This frequency is related to the reduced mass and the force constant (bond strength) of the molecule according to",
                    "score": 0.8861029148101807
                },
                {
                    "id": 2819617,
                    "contents": "Rotational–vibrational spectroscopy\nFor symmetric rotors a quantum number J is associated with the total angular momentum of the molecule. For a given value of J, there is a 2J+1- fold degeneracy with the quantum number, M taking the values +J ...0 ... -J. The third quantum number, K is associated with rotation about the principal rotation axis of the molecule. As with linear molecules, transitions are classified as parallel, or perpendicular,, in this case according to the direction of the dipole moment change with respect to the principal rotation axis. A third category involves certain overtones and combination bands which share the properties of both parallel and perpendicular transitions. The selection rules are If K ≠ 0, then ΔJ = 0, ±1 and ΔK = 0 If K = 0, then ΔJ = ±1 and ΔK = 0 ΔJ = 0, ±1 and ΔK = ±1 The fact that the selection rules are different is the justification for the classification and it means that the spectra have a different appearance which can often be immediately recognized.",
                    "score": 0.8850449919700623
                },
                {
                    "id": 19036026,
                    "contents": "Hund's cases\nIn rotational-vibrational and electronic spectroscopy of diatomic molecules, Hund's coupling cases are idealized descriptions of rotational states in which specific terms in the molecular Hamiltonian and involving couplings between angular momenta are assumed to dominate over all other terms. There are five cases, proposed by Friedrich Hund in 1926-27 and traditionally denoted by the letters (a) through (e). Most diatomic molecules are somewhere between the idealized cases (a) and (b). Angular momenta To describe the Hund's coupling cases, we use the following angular momenta (where boldface letters indicate vector quantities): , the electronic orbital angular momentum , the electronic spin angular momentum , the total electronic angular momentum , the rotational angular momentum of the nuclei , the total angular momentum of the system (exclusive of nuclear spin) , the total angular momentum exclusive of electron (and nuclear) spin",
                    "score": 0.8842454552650452
                },
                {
                    "id": 3433041,
                    "contents": "Rotational spectroscopy\nFor rotational spectroscopy, molecules are classified according to symmetry into spherical top, linear and symmetric top; analytical expressions can be derived for the rotational energy terms of these molecules. Analytical expressions can be derived for the fourth category, asymmetric top, for rotational levels up to J=3, but higher energy levels need to be determined using numerical methods. The rotational energies are derived theoretically by considering the molecules to be rigid rotors and then applying extra terms to account for centrifugal distortion, fine structure, hyperfine structure and Coriolis coupling. Fitting the spectra to the theoretical expressions gives numerical values of the angular moments of inertia from which very precise values of molecular bond lengths and angles can be derived in favorable cases. In the presence of an electrostatic field there is Stark splitting which allows molecular electric dipole moments to be determined.",
                    "score": 0.8827155828475952
                },
                {
                    "id": 3433049,
                    "contents": "Rotational spectroscopy\nClassification of molecular rotors In quantum mechanics the free rotation of a molecule is quantized, so that the rotational energy and the angular momentum can take only certain fixed values, which are related simply to the moment of inertia, , of the molecule. For any molecule, there are three moments of inertia: , and about three mutually orthogonal axes A, B, and C with the origin at the center of mass of the system. The general convention, used in this article, is to define the axes such that , with axis corresponding to the smallest moment of inertia. Some authors, however, define the axis as the molecular rotation axis of highest order. The particular pattern of energy levels (and, hence, of transitions in the rotational spectrum) for a molecule is determined by its symmetry. A convenient way to look at the molecules is to divide them into four different classes, based on the symmetry of their structure. These are Selection rules",
                    "score": 0.8812730312347412
                },
                {
                    "id": 1863142,
                    "contents": "Molecular orbital\nMost present-day methods in computational chemistry begin by calculating the MOs of the system. A molecular orbital describes the behavior of one electron in the electric field generated by the nuclei and some average distribution of the other electrons. In the case of two electrons occupying the same orbital, the Pauli principle demands that they have opposite spin. Necessarily this is an approximation, and highly accurate descriptions of the molecular electronic wave function do not have orbitals (see configuration interaction).",
                    "score": 0.8807018399238586
                },
                {
                    "id": 18471744,
                    "contents": "Rotational partition function\nto correct for the missing nuclear spin states by dividing the rotational partition function by a factor with known as the rotational symmetry number which is 2 for linear molecules with a center of symmetry and 1 for linear molecules without.",
                    "score": 0.8804579973220825
                },
                {
                    "id": 4700218,
                    "contents": "Rigid rotor\nwhere is reduced Planck constant and is the Laplacian. The Laplacian is given above in terms of spherical polar coordinates. The energy operator written in terms of these coordinates is: This operator appears also in the Schrödinger equation of the hydrogen atom after the radial part is separated off. The eigenvalue equation becomes The symbol represents a set of functions known as the spherical harmonics. Note that the energy does not depend on . The energy is -fold degenerate: the functions with fixed and have the same energy. Introducing the rotational constant B, we write, In the units of reciprocal length the rotational constant is,",
                    "score": 0.8800249099731445
                },
                {
                    "id": 1582126,
                    "contents": "Aage Bohr\nOnly after doing his Nobel Prize-winning research did Bohr receive his doctorate from the University of Copenhagen, in 1954, writing his thesis on \"Rotational States of Atomic Nuclei\". Bohr became a professor at the University of Copenhagen in 1956, and, following his father's death in 1962, succeeded him as director of the Niels Bohr Institute, a position he held until 1970. He remained active there until he retired in 1992. He was also a member of the board of the Nordic Institute for Theoretical Physics (Nordita) from its inception in 1957, and was its director from 1975 to 1981. In addition to the Nobel Prize, he won the Dannie Heineman Prize for Mathematical Physics in 1960, the Atoms for Peace Award in 1969, H.C. Ørsted Medal in 1970, Rutherford Medal and Prize in 1972, John Price Wetherill Medal in 1974, and the Ole Rømer medal in 1976. Bohr and Mottelson continued to work together, publishing a two-volume monograph, Nuclear Structure. The first volume, Single-Particle Motion,",
                    "score": 0.8791404366493225
                },
                {
                    "id": 3433069,
                    "contents": "Rotational spectroscopy\nSymmetric top For symmetric rotors a quantum number J is associated with the total angular momentum of the molecule. For a given value of J, there is a 2J+1- fold degeneracy with the quantum number, M taking the values +J ...0 ... -J. The third quantum number, K is associated with rotation about the principal rotation axis of the molecule. In the absence of an external electrical field, the rotational energy of a symmetric top is a function of only J and K and, in the rigid rotor approximation, the energy of each rotational state is given by where and for a prolate symmetric top molecule or for an oblate molecule. This gives the transition wavenumbers as which is the same as in the case of a linear molecule. With a first order correction for centrifugal distortion the transition wavenumbers become The term in DJK has the effect of removing degeneracy present in the rigid rotor approximation, with different K values. Asymmetric top",
                    "score": 0.8791263699531555
                },
                {
                    "id": 1863138,
                    "contents": "Molecular orbital\nIn chemistry, a molecular orbital is a mathematical function describing the location and wave-like behavior of an electron in a molecule. This function can be used to calculate chemical and physical properties such as the probability of finding an electron in any specific region. The terms atomic orbital and molecular orbital were introduced by Robert S. Mulliken in 1932 to mean one-electron orbital wave functions. At an elementary level, they are used to describe the region of space in which a function has a significant amplitude.",
                    "score": 0.8780317306518555
                },
                {
                    "id": 11150137,
                    "contents": "Molecular orbital diagram\nMolecular orbital diagrams are diagrams of molecular orbital (MO) energy levels, shown as short horizontal lines in the center, flanked by constituent atomic orbital (AO) energy levels for comparison, with the energy levels increasing from the bottom to the top. Lines, often dashed diagonal lines, connect MO levels with their constituent AO levels. Degenerate energy levels are commonly shown side by side. Appropriate AO and MO levels are filled with electrons by the Pauli Exclusion Principle, symbolized by small vertical arrows whose directions indicate the electron spins. The AO or MO shapes themselves are often not shown on these diagrams. For a diatomic molecule, an MO diagram effectively shows the energetics of the bond between the two atoms, whose AO unbonded energies are shown on the sides. For simple polyatomic molecules with a \"central atom\" such as methane () or carbon dioxide (), a MO diagram may show one of the identical bonds to the central atom. For other",
                    "score": 0.8773614168167114
                },
                {
                    "id": 3433048,
                    "contents": "Rotational spectroscopy\nwhere v is a vibrational quantum number and α is a vibration-rotation interaction constant which can be calculated if the B values for two different vibrational states can be found. For other molecules, if the spectra can be resolved and individual transitions assigned both bond lengths and bond angles can be deduced. When this is not possible, as with most asymmetric tops, all that can be done is to fit the spectra to three moments of inertia calculated from an assumed molecular structure. By varying the molecular structure the fit can be improved, giving a qualitative estimate of the structure. Isotopic substitution is invaluable when using this approach to the determination of molecular structure. Classification of molecular rotors",
                    "score": 0.8773162364959717
                },
                {
                    "id": 2922166,
                    "contents": "Molecular orbital theory\nRobert S. Mulliken, who actively participated in the advent of molecular orbital theory, considers each molecule to be a self-sufficient unit. He asserts in his article: ...Attempts to regard a molecule as consisting of specific atomic or ionic units held together by discrete numbers of bonding electrons or electron-pairs are considered as more or less meaningless, except as an approximation in special cases, or as a method of calculation […]. A molecule is here regarded as a set of nuclei, around each of which is grouped an electron configuration closely similar to that of a free atom in an external field, except that the outer parts of the electron configurations surrounding each nucleus usually belong, in part, jointly to two or more nuclei....An example is the MO description of benzene, , which is an aromatic hexagonal ring of six carbon atoms and three double bonds. In this molecule, 24 of the 30 total valence bonding electrons—24 coming from carbon atoms and 6 coming from",
                    "score": 0.8768302798271179
                },
                {
                    "id": 4700225,
                    "contents": "Rigid rotor\nArbitrarily shaped rigid rotor An arbitrarily shaped rigid rotor is a rigid body of arbitrary shape with its center of mass fixed (or in uniform rectilinear motion) in field-free space R3, so that its energy consists only of rotational kinetic energy (and possibly constant translational energy that can be ignored). A rigid body can be (partially) characterized by the three eigenvalues of its moment of inertia tensor, which are real nonnegative values known as principal moments of inertia. In microwave spectroscopy—the spectroscopy based on rotational transitions—one usually classifies molecules (seen as rigid rotors) as follows: spherical rotors symmetric rotors oblate symmetric rotors prolate symmetric rotors asymmetric rotors This classification depends on the relative magnitudes of the principal moments of inertia.",
                    "score": 0.8766005039215088
                },
                {
                    "id": 3433061,
                    "contents": "Rotational spectroscopy\nLinear molecules The rigid rotor is a good starting point from which to construct a model of a rotating molecule. It is assumed that component atoms are point masses connected by rigid bonds. A linear molecule lies on a single axis and each atom moves on the surface of a sphere around the centre of mass. The two degrees of rotational freedom correspond to the spherical coordinates θ and φ which describe the direction of the molecular axis, and the quantum state is determined by two quantum numbers J and M. J defines the magnitude of the rotational angular momentum, and M its component about an axis fixed in space, such as an external electric or magnetic field. In the absence of external fields, the energy depends only on J. Under the rigid rotor model, the rotational energy levels, F(J), of the molecule can be expressed as,",
                    "score": 0.8761425018310547
                },
                {
                    "id": 16681008,
                    "contents": "Timeline of quantum mechanics\n1930 – Dirac hypothesizes the existence of the positron. 1930 – Dirac's textbook The Principles of Quantum Mechanics is published, becoming a standard reference book that is still used today. 1930 – Erich Hückel introduces the Hückel molecular orbital method, which expands on orbital theory to determine the energies of orbitals of pi electrons in conjugated hydrocarbon systems. 1930 – Fritz London explains van der Waals forces as due to the interacting fluctuating dipole moments between molecules 1930 – Pauli suggests in a famous letter that, in addition to electrons and protons, atoms also contain an extremely light neutral particle which he calls the \"neutron.\" He suggests that this \"neutron\" is also emitted during beta decay and has simply not yet been observed. Later it is determined that this particle is actually the almost massless neutrino. 1931 – John Lennard-Jones proposes the Lennard-Jones interatomic potential",
                    "score": 0.8761072754859924
                },
                {
                    "id": 4700221,
                    "contents": "Rigid rotor\nTypically, rotational transitions can only be observed when the angular momentum quantum number changes by 1 (). This selection rule arises from a first-order perturbation theory approximation of the time-dependent Schrödinger equation. According to this treatment, rotational transitions can only be observed when one or more components of the dipole operator have a non-vanishing transition moment. If z is the direction of the electric field component of the incoming electromagnetic wave, the transition moment is, A transition occurs if this integral is non-zero. By separating the rotational part of the molecular wavefunction from the vibronic part, one can show that this means that the molecule must have a permanent dipole moment. After integration over the vibronic coordinates the following rotational part of the transition moment remains,",
                    "score": 0.8758140206336975
                },
                {
                    "id": 19036028,
                    "contents": "Hund's cases\nThe last two rows are degenerate because they have the same good quantum numbers. In practice there are also many molecular states which are intermediate between the above limiting cases. Case (a) The most common case is case (a) in which is electrostatically coupled to the internuclear axis, and is coupled to by spin-orbit coupling. Then both and have well-defined axial components, and respectively. The spin component is not related to states, which are states with orbital angular component equal to zero. defines a vector of magnitude pointing along the internuclear axis. Combined with the rotational angular momentum of the nuclei , we have . In this case, the precession of and around the nuclear axis is assumed to be much faster than the nutation of and around .",
                    "score": 0.8752008080482483
                },
                {
                    "id": 18471738,
                    "contents": "Rotational partition function\nThe rotational partition function relates the rotational degrees of freedom to the rotational part of the energy. Definition The total canonical partition function of a system of identical, indistinguishable, noninteracting atoms or molecules can be divided into the atomic or molecular partition functions : with : , where is the degeneracy of the jth quantum level of an individual particle, is the Boltzmann constant, and is the absolute temperature of system. For molecules, under the assumption that total energy levels can be partitioned into its contributions from different degrees of freedom (weakly coupled degrees of freedom) and the number of degenerate states are given as products of the single contributions where \"trans\", \"ns\", \"rot\", \"vib\" and \"e\" denotes translational, nuclear spin, rotational and vibrational contributions as well as electron excitation, the molecular partition functions can be written as a product itself Linear molecules",
                    "score": 0.8749679327011108
                },
                {
                    "id": 2819594,
                    "contents": "Rotational–vibrational spectroscopy\nThe appearance of rotational fine structure is determined by the symmetry of the molecular rotors which are classified, in the same way as for pure rotational spectroscopy, into linear molecules, spherical-, symmetric- and asymmetric- rotor classes. The quantum mechanical treatment of rotational fine structure is the same as for pure rotation. The strength of an absorption line is related to the number of molecules with the initial values of the vibrational quantum number ν and the rotational quantum number , and depends on temperature. Since there are actually states with rotational quantum number , the population with value increases with initially, and then decays at higher . This gives the characteristic shape of the P and R branches.",
                    "score": 0.8748818635940552
                },
                {
                    "id": 16681003,
                    "contents": "Timeline of quantum mechanics\n1927 – Walter Heitler uses Schrödinger's wave equation to show how two hydrogen atom wavefunctions join together, with plus, minus, and exchange terms, to form a covalent bond. 1927 – Robert Mulliken works, in coordination with Hund, to develop a molecular orbital theory where electrons are assigned to states that extend over an entire molecule and, in 1932, introduces many new molecular orbital terminologies, such as σ bond, π bond, and δ bond. 1927 – Eugene Wigner relates degeneracies of quantum states to irreducible representations of symmetry groups.",
                    "score": 0.8739075660705566
                },
                {
                    "id": 18471740,
                    "contents": "Rotational partition function\nFor each value of J, we have rotational degeneracy, = (2J+1), so the rotational partition function is therefore For all but the lightest molecules or the very lowest temperatures we have . This suggests we can approximate the sum by replacing the sum over J by an integral of J treated as a continuous variable. This approximation is known as the high temperature limit. It is also called the classical approximation as this is the result for the canonical partition function for a classical rigid rod. Using the Euler–Maclaurin formula an improved estimate can be found . For the CO molecule at , the (unit less) contribution to turns out to be in the range of . The mean thermal rotational energy per molecule can now be computed by taking the derivative of with respect to temperature . In the high temperature limit approximation, the mean thermal rotational energy of a linear rigid rotor is . Quantum symmetry effects",
                    "score": 0.8723946809768677
                },
                {
                    "id": 10526932,
                    "contents": "Eckart conditions\nThe Eckart conditions, named after Carl Eckart, simplify the nuclear motion (rovibrational) Hamiltonian that arises in the second step of the Born–Oppenheimer approximation. They make it possible to approximately separate rotation from vibration. Although the rotational and vibrational motions of the nuclei in a molecule cannot be fully separated, the Eckart conditions minimize the coupling close to a reference (usually equilibrium) configuration. The Eckart condition are explained by Louck and Galbraith and in Section 10.2 of the textbook by Bunker and Jensen, where a numerical example is given. Definition of Eckart conditions The Eckart conditions can only be formulated for a semi-rigid molecule, which is a molecule with a potential energy surface V(R1, R2,..RN) that has a well-defined minimum for RA0 (). These equilibrium coordinates of the nuclei—with masses MA—are expressed with respect to a fixed orthonormal principal axes frame and hence satisfy the relations",
                    "score": 0.8722653388977051
                },
                {
                    "id": 9657791,
                    "contents": "November 1966\nNovember 3, 1966 (Thursday) The Nobel Committee announced in Stockholm that Professor Robert Mulliken of the United States would receive the Nobel Prize in Chemistry for \"his fundamental work concerning chemical bonds and the electronic structure of molecules by the molecular orbital method\", and Professor Alfred Kastler of France would get the Nobel Prize in Physics for \"the discovery and development of optical methods for studying Hertzian resonances in atoms\".",
                    "score": 0.8712911605834961
                },
                {
                    "id": 1668675,
                    "contents": "Diatomic molecule\nwhere is the mass of the molecule and is its velocity. Rotational energies Classically, the kinetic energy of rotation is where is the angular momentum is the moment of inertia of the molecule For microscopic, atomic-level systems like a molecule, angular momentum can only have specific discrete values given by where is a non-negative integer and is the reduced Planck constant. Also, for a diatomic molecule the moment of inertia is where is the reduced mass of the molecule and is the average distance between the centers of the two atoms in the molecule. So, substituting the angular momentum and moment of inertia into Erot, the rotational energy levels of a diatomic molecule are given by: Vibrational energies Another type of motion of a diatomic molecule is for each atom to oscillate—or vibrate—along the line connecting the two atoms. The vibrational energy is approximately that of a quantum harmonic oscillator:",
                    "score": 0.8712278604507446
                },
                {
                    "id": 3433045,
                    "contents": "Rotational spectroscopy\nOverview A molecule in the gas phase is free to rotate relative to a set of mutually orthogonal axes of fixed orientation in space, centered on the center of mass of the molecule. Free rotation is not possible for molecules in liquid or solid phases due to the presence of intermolecular forces. Rotation about each unique axis is associated with a set of quantized energy levels dependent on the moment of inertia about that axis and a quantum number. Thus, for linear molecules the energy levels are described by a single moment of inertia and a single quantum number, , which defines the magnitude of the rotational angular momentum.",
                    "score": 0.8703184723854065
                },
                {
                    "id": 4700214,
                    "contents": "Rigid rotor\nThe rigid rotor is a mechanical model of rotating systems. An arbitrary rigid rotor is a 3-dimensional rigid object, such as a top. To orient such an object in space requires three angles, known as Euler angles. A special rigid rotor is the linear rotor requiring only two angles to describe, for example of a diatomic molecule. More general molecules are 3-dimensional, such as water (asymmetric rotor), ammonia (symmetric rotor), or methane (spherical rotor).",
                    "score": 0.8703161478042603
                },
                {
                    "id": 4700237,
                    "contents": "Rigid rotor\nThe action of the on the Wigner D-matrix is simple. In particular so that the Schrödinger equation for the spherical rotor () is solved with the degenerate energy equal to . The symmetric top (= symmetric rotor) is characterized by . It is a prolate (cigar shaped) top if . In the latter case we write the Hamiltonian as and use that Hence The eigenvalue is -fold degenerate, for all eigenfunctions with have the same eigenvalue. The energies with |k| > 0 are -fold degenerate. This exact solution of the Schrödinger equation of the symmetric top was first found in 1927. The asymmetric top problem () is not exactly soluble. In molecular quantum mechanics, the solution of the rigid-rotor Schroedinger equation is discussed in Section 11.2 on pages 240-253 of an inexpensive textbook.",
                    "score": 0.8700647354125977
                },
                {
                    "id": 18471739,
                    "contents": "Rotational partition function\ncan be written as a product itself Linear molecules Rotational energies are quantized. For a diatomic molecule like CO or HCl or a linear polyatomic molecule like OCS in its ground vibrational state, the allowed rotational energies in the rigid rotor approximation are J is the quantum number for total rotational angular momentum and takes all integer values starting at zero,i.e. is the rotational constant, and is the moment of inertia. Here we are using B in energy units. If it is expressed in frequency units, replace B by hB in all the expression that follow, where h is Planck's constant. If B is given in units of , then replace B by hcB where c is the speed of light in vacuum. For each value of J, we have rotational degeneracy, = (2J+1), so the rotational partition function is therefore",
                    "score": 0.8691987991333008
                },
                {
                    "id": 636073,
                    "contents": "Dudley R. Herschbach\nHerschbach, D. R. & V. W. Laurie. \"Anharmonic Potential Constants and Their Dependence Upon Bond Length\", University of California, Lawrence Radiation Laboratory, Berkeley, United States Department of Energy (through predecessor agency the Atomic Energy Commission) (January 1961). Herschbach, D. R. \"Reactive Collisions in Crossed Molecular Beams\", University of California, Lawrence Radiation Laboratory, Berkeley, United States Department of Energy (through predecessor agency the Atomic Energy Commission) (February 1962). Laurie, V. W. & D. R. Herschbach. \"The Determination of Molecular Structure from Rotational Spectra\", Stanford University, University of California, Lawrence Radiation Laboratory, Berkeley, United States Department of Energy (through predecessor agency the Atomic Energy Commission) (July 1962).",
                    "score": 0.869111955165863
                },
                {
                    "id": 632877,
                    "contents": "Bohr radius\nThe CODATA value of the Bohr radius (in SI units) is History In the Bohr model for atomic structure, put forward by Niels Bohr in 1913, electrons orbit a central nucleus under electrostatic attraction. The original derivation posited that electrons have orbital angular momentum in integer multiples of the reduced Planck constant, which successfully matched the observation of discrete energy levels in emission spectra, along with predicting a fixed radius for each of these levels. In the simplest atom, hydrogen, a single electron orbits the nucleus, and its smallest possible orbit, with the lowest energy, has an orbital radius almost equal to the Bohr radius. (It is not exactly the Bohr radius due to the reduced mass effect. They differ by about 0.05%.)",
                    "score": 0.8688430786132812
                },
                {
                    "id": 3437005,
                    "contents": "Quantum number\nIn chemistry and spectroscopy, is called s orbital, , p orbital, , d orbital, and , f orbital. The value of ranges from 0 to , so the first p orbital () appears in the second electron shell (), the first d orbital () appears in the third shell (), and so on: A quantum number beginning in = 3, = 0, describes an electron in the s orbital of the third electron shell of an atom. In chemistry, this quantum number is very important, since it specifies the shape of an atomic orbital and strongly influences chemical bonds and bond angles. The azimuthal quantum number can also denote the number of angular nodes present in an orbital. For example, for p orbitals, and thus the amount of angular nodes in a p orbital is 1. Shape of orbital is also given by azimuthal quantum number. Magnetic quantum number The magnetic quantum number describes the specific orbital (or \"cloud\") within that subshell, and yields the projection of the orbital angular momentum along a specified axis:",
                    "score": 0.8687839508056641
                },
                {
                    "id": 986651,
                    "contents": "Atomic, molecular, and optical physics\ndifferent rotational states, therefore pure rotational spectra are in the far infrared region (about 30 - 150 µm wavelength) of the electromagnetic spectrum. Vibrational spectra are in the near infrared (about 1 - 5 µm) and spectra resulting from electronic transitions are mostly in the visible and ultraviolet regions. From measuring rotational and vibrational spectra properties of molecules like the distance between the nuclei can be calculated.",
                    "score": 0.8687707185745239
                },
                {
                    "id": 4258552,
                    "contents": "Molecular geometry\nAs stated above, rotation hardly influences the molecular geometry. But, as a quantum mechanical motion, it is thermally excited at relatively (as compared to vibration) low temperatures. From a classical point of view it can be stated that at higher temperatures more molecules will rotate faster,",
                    "score": 0.8687326312065125
                },
                {
                    "id": 1334779,
                    "contents": "Wolfgang Pauli\nPauli proposed in 1924 a new quantum degree of freedom (or quantum number) with two possible values, to resolve inconsistencies between observed molecular spectra and the developing theory of quantum mechanics. He formulated the Pauli exclusion principle, perhaps his most important work, which stated that no two electrons could exist in the same quantum state, identified by four quantum numbers including his new two-valued degree of freedom. The idea of spin originated with Ralph Kronig. A year later, George Uhlenbeck and Samuel Goudsmit identified Pauli's new degree of freedom as electron spin, in which Pauli for a very long time wrongly refused to believe. In 1926, shortly after Heisenberg published the matrix theory of modern quantum mechanics, Pauli used it to derive the observed spectrum of the hydrogen atom. This result was important in securing credibility for Heisenberg's theory.",
                    "score": 0.8680938482284546
                },
                {
                    "id": 18600271,
                    "contents": "Quantum rotor model\nThe quantum rotor model is a mathematical model for a quantum system. It can be visualized as an array of rotating electrons which behave as rigid rotors that interact through short-range dipole-dipole magnetic forces originating from their magnetic dipole moments (neglecting Coulomb forces). The model differs from similar spin-models such as the Ising model and the Heisenberg model in that it includes a term analogous to kinetic energy. Although elementary quantum rotors do not exist in nature, the model can describe effective degrees of freedom for a system of sufficiently small number of closely coupled electrons in low-energy states. Suppose the n-dimensional position (orientation) vector of the model at a given site is . Then, we can define rotor momentum by the commutation relation of components However, it is found convenient to use rotor angular momentum operators defined (in 3 dimensions) by components",
                    "score": 0.8668324947357178
                },
                {
                    "id": 9025036,
                    "contents": "Stationary state\nComparison to \"orbital\" in chemistry An orbital is a stationary state (or approximation thereof) of a one-electron atom or molecule; more specifically, an atomic orbital for an electron in an atom, or a molecular orbital for an electron in a molecule.",
                    "score": 0.8667933940887451
                },
                {
                    "id": 1565321,
                    "contents": "Atomic orbital\nIn chemistry, Schrödinger, Pauling, Mulliken and others noted that the consequence of Heisenberg's relation was that the electron, as a wave packet, could not be considered to have an exact location in its orbital. Max Born suggested that the electron's position needed to be described by a probability distribution which was connected with finding the electron at some point in the wave-function which described its associated wave packet. The new quantum mechanics did not give exact results, but only the probabilities for the occurrence of a variety of possible such results. Heisenberg held that the path of a moving particle has no meaning if we cannot observe it, as we cannot with electrons in an atom. In the quantum picture of Heisenberg, Schrödinger and others, the Bohr atom number n for each orbital became known as an n-sphere in a three-dimensional atom and was pictured as the most probable energy of the probability cloud of the electron's wave packet which surrounded the atom.",
                    "score": 0.8666210174560547
                },
                {
                    "id": 1863143,
                    "contents": "Molecular orbital\nMolecular orbitals are, in general, delocalized throughout the entire molecule. Moreover, if the molecule has symmetry elements, its nondegenerate molecular orbitals are either symmetric or antisymmetric with respect to any of these symmetries. In other words, application of a symmetry operation S (e.g., a reflection, rotation, or inversion) to molecular orbital ψ results in the molecular orbital being unchanged or reversing its mathematical sign: Sψ = ±ψ. In planar molecules, for example, molecular orbitals are either symmetric (sigma) or antisymmetric (pi) with respect to reflection in the molecular plane. If molecules with degenerate orbital energies are also considered, a more general statement that molecular orbitals form bases for the irreducible representations of the molecule's symmetry group holds. The symmetry properties of molecular orbitals means that delocalization is an inherent feature of molecular orbital theory and makes it fundamentally different from (and",
                    "score": 0.8659822940826416
                },
                {
                    "id": 17941502,
                    "contents": "Alan Carrington\nCarrington's earlier contributions to chemical physics were in the fields of electron spin resonance (esr) spectroscopy, and magnetic resonance in general. During this period Carrington authored the classic monograph on Magnetic Resonance with Andrew McLachlan, 'Introduction to Magnetic Resonance with Applications to Chemistry and Chemical Physics'. Carrington's later work was concerned with examining the structure of molecular ions in energy regions close to their dissociation limits. This work on the spectroscopy of simple molecular ions provided accurate measurements with which theoretical calculations could usefully be compared. In particular, his work on the simplest diatomic and triatomic molecules gave rise to measurements that have not yet been matched by theoretical calculations. Much of this work is reviewed in the classic monograph authored with John M Brown, \"Rotational Spectroscopy of Diatomic Molecules\". Awards and honours",
                    "score": 0.865791916847229
                },
                {
                    "id": 16139173,
                    "contents": "Walsh diagram\nIn his publications, Walsh showed through multiple examples that the geometry adopted by a molecule in its ground state primarily depends on the number of its valence electrons. He himself acknowledged that this general concept was not novel, but explained that the new data available to him allowed the previous generalizations to be expanded upon and honed. He also noted that Mulliken had previously attempted to construct a correlation diagram for the possible orbitals of a polyatomic molecule in two different nuclear configurations, and had even tried to use this diagram to explain shapes and spectra of molecules in their ground and excited states. However, Mulliken was unable to explain the reasons for the rises and falls of certain curves with increases in angle, thus Walsh claimed \"his diagram was either empirical or based upon unpublished computations.\"",
                    "score": 0.8656179904937744
                },
                {
                    "id": 1495712,
                    "contents": "Friedrich Hund\nIn fact, Robert S. Mulliken, who was awarded the 1966 Nobel Prize in chemistry for molecular orbital theory, always proclaimed the great influence Hund's work had on his own and that he would have gladly shared the Nobel prize with Hund. In recognition of the importance of Hund's contributions, MO theory is often referred to as the Hund-Mulliken MO theory. Hund's rule of maximum multiplicity is another eponym and, in 1926, Hund discovered the so-called tunnel effect or quantum tunnelling. The Hund's cases, which are particular regimes in diatomic molecular angular momentum coupling, and Hund's rules, which govern atomic electron configurations, are important in spectroscopy and quantum chemistry. In chemistry, the first rule, Hund's rule of maximum multiplicity, is especially important and is often referred to as simply Hund's Rule.",
                    "score": 0.8655598759651184
                },
                {
                    "id": 3433064,
                    "contents": "Rotational spectroscopy\nThe maximum relative intensity occurs at The diagram at the right shows an intensity pattern roughly corresponding to the spectrum above it. Centrifugal distortion When a molecule rotates, the centrifugal force pulls the atoms apart. As a result, the moment of inertia of the molecule increases, thus decreasing the value of , when it is calculated using the expression for the rigid rotor. To account for this a centrifugal distortion correction term is added to the rotational energy levels of the diatomic molecule. where is the centrifugal distortion constant. Therefore, the line positions for the rotational mode change to In consequence, the spacing between lines is not constant, as in the rigid rotor approximation, but decreases with increasing rotational quantum number. An assumption underlying these expressions is that the molecular vibration follows simple harmonic motion. In the harmonic approximation the centrifugal constant can be derived as",
                    "score": 0.864625096321106
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_27",
        "question": "Suppose that $2.5 \\mathrm{mmol} \\mathrm{N}_2$ (g) occupies $42 \\mathrm{~cm}^3$ at $300 \\mathrm{~K}$ and expands isothermally to $600 \\mathrm{~cm}^3$. Calculate $\\Delta G$ for the process.",
        "golden_answers": [
            " -17"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 11242054,
                    "contents": "Timeline of chemistry\n1662Robert Boyle proposes Boyle's law, an experimentally based description of the behavior of gases, specifically the relationship between pressure and volume. 1735Swedish chemist Georg Brandt analyzes a dark blue pigment found in copper ore. Brandt demonstrated that the pigment contained a new element, later named cobalt. 1754Joseph Black isolates carbon dioxide, which he called \"fixed air\". 1757Louis Claude Cadet de Gassicourt, while investigating arsenic compounds, creates Cadet's fuming liquid, later discovered to be cacodyl oxide, considered to be the first synthetic organometallic compound. 1758Joseph Black formulates the concept of latent heat to explain the thermochemistry of phase changes. 1766Henry Cavendish discovers hydrogen as a colorless, odourless gas that burns and can form an explosive mixture with air. 1773–1774 Carl Wilhelm Scheele and Joseph Priestley independently isolate oxygen, called by Priestley \"dephlogisticated air\" and Scheele \"fire air\".",
                    "score": 0.869651734828949
                },
                {
                    "id": 330383,
                    "contents": "Nernst heat theorem\nIn the limit of T = 0 the equation reduces to just ΔG = ΔH, as illustrated in the figure shown here, which is supported by experimental data. However, it is known from thermodynamics that the slope of the ΔG curve is -ΔS. Since the slope shown here reaches the horizontal limit of 0 as T → 0 then the implication is that ΔS → 0, which is the Nernst heat theorem. The significance of the Nernst heat theorem is that it was later used by Max Planck to give the third law of thermodynamics, which is that the entropy of all pure, perfectly crystalline homogeneous materials in complete internal equilibrium is 0 at absolute zero. See also Theodore William Richards Entropy References and notes Further reading - See especially pages 421 – 424 External links Nernst heat theorem Thermochemistry Walther Nernst de:Nernst-Theorem",
                    "score": 0.8657553195953369
                },
                {
                    "id": 13082414,
                    "contents": "Wendell Mitchell Latimer\nHe received his Ph.D from the University of California, Berkeley for the work with George Ernest Gibson. He earned many awards and honors for his scientific work. Awards and honors Latimer received many awards and honor during his lifetime including membership in the National Academy of Sciences, and chairmanship of its Section of Chemistry from 1947 to 1950; the Distinguished Service Award from his alma mater, the University of Kansas, in 1948; the President's Certificate of Merit, in 1948; Faculty Research Lecture in 1953, an honor that the Academic Senate of the University of California annually bestows upon one of its members; the William H. Nichols Medal from the New York Section of the American Chemical Society, in 1955 with a citation for his \"Pioneer Studies on the Thermodynamics of Electrolytes, especially the Entropies of Ions in Aqueous Solutions.\" Discovery of tritium",
                    "score": 0.8629069328308105
                },
                {
                    "id": 2661326,
                    "contents": "Isobaric process\n, where cV, m is molar heat capacity at a constant volume. Substituting the last two equations into the first equation produces: where cP is molar heat capacity at a constant pressure. Specific heat capacity To find the molar specific heat capacity of the gas involved, the following equations apply for any general gas that is calorically perfect. The property γ is either called the adiabatic index or the heat capacity ratio. Some published sources might use k instead of γ. Molar isochoric specific heat: . Molar isobaric specific heat: . The values for γ are γ = for diatomic gases like air and its major components, and γ = for monatomic gases like the noble gases. The formulas for specific heats would reduce in these special cases: Monatomic: and Diatomic: and",
                    "score": 0.8626772165298462
                },
                {
                    "id": 1477630,
                    "contents": "List of experiments\nBenjamin Thompson, Count Rumford demonstrates that the heat developed by the friction of boring cannon is nearly inexhaustible. This result was presented in opposition to caloric theory (1798). Humphry Davy uses electrolysis to isolate elemental potassium, sodium, calcium, strontium, barium, magnesium, and chlorine (1807–1810). Joseph Louis Gay-Lussac studies reactions among gases and determines that their volumes combine chemically in simple integer ratios (1809). Robert Brown studies very small particles in water under the microscope and observes Brownian motion which was later named in his honor (1827). Friedrich Wöhler synthesizes the organic compound urea using inorganic reactants, disproving the application of vitalism to chemical processes (1828). Thomas Graham measures the rates of effusion for different gases and establishes Graham's law of effusion and diffusion (1833).",
                    "score": 0.8620926141738892
                },
                {
                    "id": 823365,
                    "contents": "Walther Nernst\nIn 1905, he proposed his \"New Heat Theorem\", later known as the Third law of thermodynamics. He showed that as the temperature approached absolute zero, the entropy approaches zero while the free energy remains above zero. This is the work for which he is best remembered, as it enabled chemists to determine free energies (and therefore equilibrium points) of chemical reactions from heat measurements. Theodore Richards claimed that Nernst had stolen his idea, but Nernst is almost universally credited with the discovery. Nernst became friendly with Kaiser Wilhelm, whom he persuaded to found the Kaiser Wilhelm Gesellschaft for the Advancement of the Sciences with an initial capital of eleven million marks. Nernst's laboratory discovered that at low temperatures specific heats fell markedly and would probably disappear at absolute zero. This fall was predicted for liquids and solids in a 1909 paper of Albert Einstein's on the quantum mechanics of specific heats at cryogenic",
                    "score": 0.8616818189620972
                },
                {
                    "id": 11242064,
                    "contents": "Timeline of chemistry\n1883Svante Arrhenius develops ion theory to explain conductivity in electrolytes. 1884Jacobus Henricus van 't Hoff publishes Études de Dynamique chimique, a seminal study on chemical kinetics. 1884Hermann Emil Fischer proposes structure of purine, a key structure in many biomolecules, which he later synthesized in 1898. Also begins work on the chemistry of glucose and related sugars. 1884Henry Louis Le Chatelier develops Le Chatelier's principle, which explains the response of dynamic chemical equilibria to external stresses. 1885Eugen Goldstein names the cathode ray, later discovered to be composed of electrons, and the canal ray, later discovered to be positive hydrogen ions that had been stripped of their electrons in a cathode ray tube. These would later be named protons. 1893Alfred Werner discovers the octahedral structure of cobalt complexes, thus establishing the field of coordination chemistry.",
                    "score": 0.8613146543502808
                },
                {
                    "id": 14216023,
                    "contents": "George Samuel Newth\nBibliography G. S. Newth, Elementary Inorganic Chemistry, Longmans, Green, and Co. (first published 1898). G. S. Newth, Smaller Chemical Analysis, Longmans, Green, and Co. (first published 1906) G. S. Newth, A Manual of Chemical Analysis: Qualitative and Quantitative, Longmans, Green, and Co. (1899) G. S. Newth, A Text-book of Inorganic Chemistry, Longmans, Green, and Co. (first published 1894) G. S. Newth, Chemical Lecture Experiments: Non-metallic Elements, Longmans, Green, and Co. (1922; first published in 1892) G. S. Newth: \"An apparatus for showing experiments with ozone\", Journal of the Chemical Society, Transactions 69, 1298–1299, Royal Society of Chemistry, 1896. G. S. Newth: \"Notes on partially miscible aqueous inorganic liquids\", J. Chem. Soc., Trans., 1900, 77, 775 - 778. G. S. Newth: \"A New Laboratory Process for Preparing Hydrobromic Acid\", Scientific American Supplement, No. 841, February 13, 1892.",
                    "score": 0.8574520349502563
                },
                {
                    "id": 27263691,
                    "contents": "Douglas McKie\nHe retired in 1964 and died in London on 28 August 1967. Publications The Discovery of Specific and Latent Heat (1935) Thomas Cochrane’s Notes from Dr Black’s Lectures on Chemistry 1767/8 (1936) Antoine Lavoisier: The Father of Modern Chemistry (1936) Newton and Chemistry (1943) Antoine Lavoisier: Scientist, Economist and Social Reformer (1953) In 1936 he was co-founder of the journal Annals of Science and he served as its Editor until his death. The French awarded him Chevalier of the Légion d'honneur in 1957 for his work on Lavoisier. References 1896 births 1967 deaths Alumni of the University of London Academics of the University of London British science writers 20th-century British historians British chemists Fellows of the Royal Society of Edinburgh People from Tredegar Historians of science",
                    "score": 0.8565708994865417
                },
                {
                    "id": 19541047,
                    "contents": "Grant M. Wilson\nThe Wilson equation was published by Grant M. Wilson as \"Vapor-Liquid Equilibrium. XI. A New Expression for the Excess Free Energy of Mixing\" in the Journal of the American Chemical Society 86:127-130, 1964. Wilson and his wife, Reta Raphiel were married in the Logan Temple on September 18, 1950. Together in 2002, they served as missionaries for The Church of Jesus Christ of Latter-day Saints in Bangalore, India for two years. Wilson died on September 10, 2012 in Orem, Utah. Wilson's hobby was hiking in the mountains. His favorite climb was Mt. Timpanogos. References",
                    "score": 0.8565182685852051
                },
                {
                    "id": 333025,
                    "contents": "Thermodynamic activity\nSee also Fugacity, the equivalent of activity for partial pressure Chemical equilibrium Electrochemical potential Excess chemical potential Partial molar property Thermodynamic equilibrium Thermal expansion Virial expansion Water activity Non-random two-liquid model (NRTL model) – phase equilibrium calculations UNIQUAC model – phase equilibrium calculations References External links Equivalences among different forms of activity coefficients and chemical potentials Calculate activity coefficients of common inorganic electrolytes and their mixtures AIOMFAC online-model: calculator for activity coefficients of inorganic ions, water, and organic compounds in aqueous solutions and multicomponent mixtures with organic compounds. Dimensionless numbers of chemistry Physical chemistry Thermodynamic properties",
                    "score": 0.8563263416290283
                },
                {
                    "id": 2751075,
                    "contents": "1625 in science\nThe year 1625 in science and technology involved some significant events. Chemistry First description of hydrogen by Johann Baptista van Helmont. First to use the word \"gas\". Johann Rudolf Glauber discovers sodium sulfate (sal mirabilis or \"Glauber's salt\", used as a laxative) in Austrian spring water. Births June 8 – Giovanni Cassini, Italian astronomer (died 1712) March 25 – John Collins, English mathematician (died 1683) August 13 – Rasmus Bartholin, Danish scientist (died 1698) December 16 – Erhard Weigel, German mathematician and scientific populariser (died 1699) December 20 – David Gregory, Scottish physician and inventor (died 1720) Samuel Morland, English inventor (died 1695)",
                    "score": 0.856243371963501
                },
                {
                    "id": 1379353,
                    "contents": "Le Chatelier's principle\nN2(g) + 3 H2(g) ⇌ 2 NH3(g) ΔH = −92 kJ mol−1 Because this reaction is exothermic, it produces heat: N2(g) + 3 H2(g) ⇌ 2 NH3(g) + heat If the temperature were increased, the heat content of the system would increase, so the system would consume some of that heat by shifting the equilibrium to the left, thereby producing less ammonia. More ammonia would be produced if the reaction were run at a lower temperature, but a lower temperature also lowers the rate of the process, so, in practice (the Haber process) the temperature is set at a compromise value that allows ammonia to be made at a reasonable rate with an equilibrium concentration that is not too unfavorable. In exothermic reactions, an increase in temperature decreases the equilibrium constant, K, whereas in endothermic reactions, an increase in temperature increases K.",
                    "score": 0.8555387258529663
                },
                {
                    "id": 2815917,
                    "contents": "Superseded theories in science\nChemistry Caloric theory – the theory that a self-repelling fluid called \"caloric\" was the substance of heat. Rendered obsolete by the mechanical theory of heat. Classical elements – All matter was once thought composed of various combinations of classical elements (most famously air, earth, fire, and water). Antoine Lavoisier finally refuted this in his 1789 publication, Elements of Chemistry, which contained the first modern list of chemical elements. Electrochemical dualism - the theory that all molecules are salts composed of basic and acidic oxides Phlogiston theory – The theory that combustible goods contain a substance called \"phlogiston\" that entered air during combustion. Replaced by Lavoisier's work on oxidation Point 2 of Dalton's Atomic Theory was rendered obsolete by discovery of isotopes, and point 3 by discovery of subatomic particles and nuclear reactions.",
                    "score": 0.8555310368537903
                },
                {
                    "id": 6077103,
                    "contents": "Kilocalorie per mole\nEven though it is not an SI unit, the kilocalorie per mole is still widely used in chemistry for thermodynamical quantities such as thermodynamic free energy, heat of vaporization, heat of fusion and ionization energy, due to the ease with which it can be calculated based on the units of measure typically employed in quantifying a chemical reaction, especially in aqueous solution. Typically but not exclusively, kcal/mol are used in the United States, whereas kJ/mol are preferred elsewhere. References Energy (physics) Thermodynamics Heat transfer",
                    "score": 0.8553255796432495
                },
                {
                    "id": 12463859,
                    "contents": "Thomas Dale Stewart\nThomas Dale Stewart (August 14, 1890 – February 6, 1958) was an American chemist. He was born at Sumner, Washington, and received his Ph.D. degree in chemistry from University of California at Berkeley in 1916. After one year of research at University of Chicago under Julius Stieglitz, he returned to Berkeley as an instructor in the chemistry department, and became a professor there in 1935. His early research was about the mechanism of electron conduction in metals. The collaborative work with Richard C. Tolman led to the discovery of Stewart–Tolman effect. Later he worked on acid-base equilibria of organic nitrogen compounds, as well as reaction kinetics. References Thomas Dale Stewart, University of California: In Memoriam, 1959, accessed 06-21-2007. 20th-century American physicists 1890 births 1958 deaths People from Sumner, Washington University of California, Berkeley alumni UC Berkeley College of Chemistry faculty",
                    "score": 0.8552179336547852
                },
                {
                    "id": 2698950,
                    "contents": "1782 in science\nThe year 1782 in science and technology included many events, some of which are listed here. Aviation December 14 – The Montgolfier brothers first test fly a hot air balloon; it floats nearly . Biology Jesuit abbot Juan Ignacio Molina publishes Saggio sulla Storia Naturale del Chili in Spain, the first account of the natural history of his native Chile, describing many species to science for the first time (e.g., Araucaria araucana). Chemistry Telluride minerals are first discovered in a gold mine in Kleinschlatten, Transylvania (modern-day Zlatna, Romania) by Austrian mineralogist Franz-Joseph Müller von Reichenstein. Winter 1782–83 – Antoine Lavoisier and Pierre-Simon Laplace begin to use the world’s first ice calorimeter to determine the heat evolved in various chemical changes (calculations based on Joseph Black's prior discovery of latent heat), marking the foundation of thermochemistry. Medicine September – Nottingham General Hospital opens to patients in England.",
                    "score": 0.8546204566955566
                },
                {
                    "id": 3297009,
                    "contents": "Thermochemical equation\nWhere to Find Values of ΔH Values of ΔH have been experimentally determined and are available in table form. Most general chemistry textbooks have appendixes including common ΔH values. There are several online tables available. For more extensive information there is software offered with Active Thermochemical Tables (ATcT), available online. See also Chemistry Thermochemistry Chemical Reaction Enthalpy References Atkins, Peter and Loretta Jones. 2005. Chemical Principles, the Quest for Insight (3rd edition). W. H. Freeman and Co., New York, NY. External links General chemistry information index: http://chemistry.about.com/library/blazlist4.htm Further step by step help on Hess’s Law: http://members.aol.com/profchm/hess.html Thermochemistry",
                    "score": 0.8538879752159119
                },
                {
                    "id": 21584515,
                    "contents": "David A. Shirley\nDavid Arthur Shirley (March 30, 1934 – March 29, 2021) was an American chemist, best known as the fourth director of the Lawrence Berkeley National Laboratory from 1980 to 1989, and for spearheading the funding and creation of the Advanced Light Source. Biography David Arthur Shirley was born in North Conway, New Hampshire, on March 30, 1934. He earned a Bachelor of Science degree in chemistry from the University of Maine in 1955, and then entered the University of California, Berkeley, where he completed his PhD, writing his 1959 doctoral thesis on \"The heat capacities and entropies of iodine and lithium chloride from 15 to 325 degrees Kelvin\", under the supervision of William Giauque. Shirley married Virginia Schultz in 1956, and they had five children together, David, Diane, Michael, Eric and Gail Shirley. Shirley has a total of eleven grandchildren, Brian, Arthur, Kevin, Colleen, Sarah, Lauren, Catalina, Wendell, Wilbur, Darian and Madelyn.",
                    "score": 0.8537510633468628
                },
                {
                    "id": 11242071,
                    "contents": "Timeline of chemistry\n1932James Chadwick discovers the neutron. 1932–1934Linus Pauling and Robert Mulliken quantify electronegativity, devising the scales that now bear their names. 1935Wallace Carothers leads a team of chemists at DuPont who invent nylon, one of the most commercially successful synthetic polymers in history. 1937Carlo Perrier and Emilio Segrè perform the first confirmed synthesis of technetium-97, the first artificially produced element, filling a gap in the periodic table. Though disputed, the element may have been synthesized as early as 1925 by Walter Noddack and others. 1937Eugene Houdry develops a method of industrial scale catalytic cracking of petroleum, leading to the development of the first modern oil refinery. 1937Pyotr Kapitsa, John Allen and Don Misener produce supercooled helium-4, the first zero-viscosity superfluid, a substance that displays quantum mechanical properties on a macroscopic scale.",
                    "score": 0.853274405002594
                },
                {
                    "id": 2132707,
                    "contents": "Georg Ernst Stahl\nand that once a metal is heated, the phlogiston leaves only the calx within the substance. He was able to make the theory applicable to chemistry as it was one of the first unifying theories in the discipline. Phlogiston provided an explanation of various chemical phenomena and encouraged the chemists of the time to rationally work with the theory to explore more of the subject. This theory was later replaced by Antoine-Laurent Lavoisier’s theory of oxidation and caloric theory. He also propounded a view of fermentation, which in some respects resembles that supported by Justus von Liebig a century and half later. Although his theory was replaced, Stahl's theory of phlogiston is seen to be the transition between alchemy and chemistry.",
                    "score": 0.8530633449554443
                },
                {
                    "id": 823376,
                    "contents": "Walther Nernst\nPublications Walther Nernst, \"Reasoning of theoretical chemistry: Nine papers (1889–1921)\" (Ger., Begründung der Theoretischen Chemie : Neun Abhandlungen, 1889–1921). Frankfurt am Main : Verlag Harri Deutsch, c. 2003. Walther Nernst, \"The theoretical and experimental bases of the New Heat Theorem\" (Ger., Die theoretischen und experimentellen Grundlagen des neuen Wärmesatzes). Halle [Ger.] W. Knapp, 1918 [tr. 1926]. [ed., this is a list of thermodynamical papers from the physico-chemical institute of the University of Berlin (1906–1916); Translation available by Guy Barr Walther Nernst, \"Theoretical chemistry from the standpoint of Avogadro's law and thermodynamics\" (Ger., Theoretische Chemie vom Standpunkte der Avogadroschen Regel und der Thermodynamik). Stuttgart, F. Enke, 1893 [5th edition, 1923].",
                    "score": 0.8530188798904419
                },
                {
                    "id": 18316637,
                    "contents": "Thermochemical cycle\n(2) Hence, for an ambient temperature T° of 298K (kelvin) and a pressure of 1 atm (atmosphere (unit)) (ΔG° and ΔS° are respectively equal to 237 kJ/mol and 163 J/mol/K, relative to the initial amount of water), more than 80% of the required energy ΔH must be provided as work in order for water-splitting to proceed.",
                    "score": 0.8523935079574585
                },
                {
                    "id": 12545120,
                    "contents": "J. R. Partington\nPartington joined the army in 1914 as World War I began in Eastern Europe. He was first assigned to work with Eric Rideal on the purification of water for troops on the Somme. Later the two chemists turned to the question of the oxidation of nitrogen to form nitric acid and investigated the Haber-Bosch process that the Germans were pursuing. Thus, he was transferred to a group led by Frederick G. Donnan, which worked on the production of nitric acid for munitions. Captain Partington was appointed a Member of the Most Excellent Order of the British Empire (MBE) in the Military Division for this latter work. Outside his war work for the government, Partington managed to continue with thermodynamics, joining the Faraday Society in 1915. In 1919 he presented a major review of the literature on the dilution law to the Faraday Society, to whose Council he was elected that same year.",
                    "score": 0.8518199324607849
                },
                {
                    "id": 13082069,
                    "contents": "George E. Kimball\nDuring the summer of 1935, Kimball returned to Princeton, to work with Henry Eyring. After a year when Kimball taught physics at Hunter College, he became assistant professor at the Chemistry Department of Columbia University. One of his students during his early time at Columbia was Isaac Asimov, who remembered getting a zero from him in physical chemistry. During the years 1936–1941, Kimball published nine papers on reaction rates and electrochemical surface effects. He also developed and taught courses in quantum chemistry, and supervised graduate student research. In 1941 he was elected a Fellow of the American Physical Society. The book Quantum Chemistry written by Kimball, Henry Eyring and John Walter, was begun around 1934 and published in 1944. Although periodically occupied with other tasks from 1942, he became a full professor of chemistry at Columbia in 1947 and remained there until 1956.",
                    "score": 0.8517336249351501
                },
                {
                    "id": 18582345,
                    "contents": "Equilibrium chemistry\nBy convention po is usually taken to be 1 bar. Fugacity can be expressed as the product of partial pressure, p, and a fugacity coefficient, Φ: Fugacity coefficients are dimensionless and can be obtained experimentally at specific temperature and pressure, from measurements of deviations from ideal gas behaviour. Equilibrium constants are defined in terms of fugacity. If the gases are at sufficiently low pressure that they behave as ideal gases, the equilibrium constant can be defined as a quotient of partial pressures.",
                    "score": 0.8516490459442139
                },
                {
                    "id": 2085926,
                    "contents": "Stanley Miller\nStanley Lloyd Miller (March 7, 1930 – May 20, 2007) was an American chemist who made landmark experiments in the origin of life by demonstrating that a wide range of vital organic compounds can be synthesized by fairly simple chemical processes from inorganic substances. In 1952 he carried out the Miller–Urey experiment, which showed that complex organic molecules could be synthesised from inorganic precursors. The experiment was widely reported, and provided support for the idea that the chemical evolution of the early Earth had led to the natural synthesis of chemical building blocks of life from inanimate inorganic molecules. He has been described as the \"father of prebiotic chemistry\". Life and career",
                    "score": 0.8515888452529907
                },
                {
                    "id": 1903880,
                    "contents": "Reaction rate\nIn practice, the matter can be complicated because the partial molar volumes and the activation volume can themselves be a function of pressure. Reactions can increase or decrease their rates with pressure, depending on the value of ΔV‡. As an example of the possible magnitude of the pressure effect, some organic reactions were shown to double the reaction rate when the pressure was increased from atmospheric (0.1 MPa) to 50 MPa (which gives ΔV‡ = −0.025 L/mol). See also Rate of solution Dilution (equation) Diffusion-controlled reaction Steady state approximation Collision theory and transition state are chemical theories that attempt to predict and explain reaction rates. Isothermal microcalorimetry Notes",
                    "score": 0.8510938286781311
                },
                {
                    "id": 2244521,
                    "contents": "1912 in science\nChemistry Peter Debye derives the T-cubed law for the low temperature heat capacity of a nonmetallic solid. Casimir Funk introduces the concept of vitamins. Fritz Klatte, a German chemist working for Griesheim-Elektron, discovers polyvinyl acetate and applies for a patent for preparing the monomer, vinyl acetate, by addition of acetic acid to acetylene using a mercuric chloride catalyst although it is not successfully commercialized at this time. Wilbur Scoville devises the Scoville scale for measuring the heat of peppers. December 24 – Merck files patent applications for synthesis of the entactogenic drug MDMA, developed by Anton Köllisch. Geology January – Alfred Wegener proposes a fully formulated theory of continental drift and gave the supercontinent Pangaea its name. June 6 – The Novarupta volcano on the Alaska Peninsula comes into being through a VEI 6 eruption, the largest this century.",
                    "score": 0.8496526479721069
                },
                {
                    "id": 1707360,
                    "contents": "Enthalpy\nSee also Standard enthalpy change of formation (data table) Calorimetry Calorimeter Departure function Hess's law Isenthalpic process Laws of thermodynamics Stagnation enthalpy Thermodynamic databases for pure substances Notes References Bibliography External links Enthalpy – Eric Weisstein's World of Physics Enthalpy – Georgia State University Enthalpy example calculations – Texas A&M University Chemistry Department State functions Energy (physics) Physical quantities",
                    "score": 0.8495071530342102
                },
                {
                    "id": 1654422,
                    "contents": "Outline of chemistry\nHistory of chemical kinetics – history of the study of rates of chemical processes. History of chemical thermodynamics – history of the study of the interrelation of heat and work with chemical reactions or with physical changes of state within the confines of the laws of thermodynamics. History of electrochemistry – history of the branch of chemistry that studies chemical reactions which take place in a solution at the interface of an electron conductor (a metal or a semiconductor) and an ionic conductor (the electrolyte), and which involve electron transfer between the electrode and the electrolyte or species in solution. History of Femtochemistry – history of the Femtochemistry is the science that studies chemical reactions on extremely short timescales, approximately 10−15 seconds (one femtosecond, hence the name).",
                    "score": 0.8493179082870483
                },
                {
                    "id": 17938826,
                    "contents": "Standard Gibbs free energy of formation\nThe standard Gibbs free energy of formation (Gf°) of a compound is the change of Gibbs free energy that accompanies the formation of 1 mole of a substance in its standard state from its constituent elements in their standard states (the most stable form of the element at 1 bar of pressure and the specified temperature, usually 298.15 K or 25 °C). The table below lists the standard Gibbs function of formation for several elements and chemical compounds and is taken from Lange's Handbook of Chemistry. Note that all values are in kJ/mol. Far more extensive tables can be found in the CRC Handbook of Chemistry and Physics and the NIST JANAF tables. The NIST Chemistry WebBook (see link below) is an online resource that contains standard enthalpy of formation for various compounds along with the standard absolute entropy for these compounds from which the standard Gibbs free energy of formation can be calculated. See also Thermochemistry Calorimetry References",
                    "score": 0.8492954969406128
                },
                {
                    "id": 15615350,
                    "contents": "Karl James Jalkanen\nHe is currently the Editor-in-Chief (EiC) for Current Physical Chemistry. He has also been guest editor for three special issues of Theoretical Chemistry Accounts, the P.J. Stephens Honorary Issue, volume 119, numbers 1-3, the January 2008 issue, with Dr. Gerard M. Jensen, Gilead Sciences, Inc., the Suhai Festschrift Honorary Issue, volume 125, numbers 3-6, the March 2010 issue, and the Akira Imamura Hononary Issue, volume 130, numbers 4-6, the December 2011 issue. He was guest editor with Dr. Gerard M. Jensen, Gilead Sciences, Inc. for the two issue Quantum Nanobiology and Biophysical Chemistry series in Current Physical Chemistry (CPC) that appeared as the January and April in 2013 in volume 3, issues 1 and 2",
                    "score": 0.8492883443832397
                },
                {
                    "id": 2722500,
                    "contents": "1834 in science\nPhysics Émile Clapeyron presents a formulation of the second law of thermodynamics. Michael Faraday publishes \"On Electrical Decomposition\" in the Philosophical Transactions of the Royal Society, in which he coins the words electrode, anode, cathode, anion, cation, electrolyte and electrolyze. Heinrich Lenz discovers Lenz's law. Jean-Charles-Athanase Peltier discovers the Peltier effect. Technology June 21 – Cyrus McCormick receives his first patent for a mechanical reaper, in the United States. December 23 – English architect Joseph Hansom patents the Hansom cab. Joseph Chaley’s Grand Pont Suspendu in Fribourg is the first suspension bridge with cables assembled in mid-air. Jacob Perkins creates a cooling machine that uses ice, an early refrigerator. Awards Copley Medal: Giovanni Plana",
                    "score": 0.8491783738136292
                },
                {
                    "id": 16914778,
                    "contents": "Arnold Eucken\nContributions Eucken made important contributions within physical and technical chemistry. He concentrated on specific heat at very low temperatures, the structure of liquids and electrolytic solutions, the molecular physics (rotation, oscillation), on deuterium and heavy water, on homogeneous and heterogeneous gas kinetics, catalysis, chemical engineering and chemical technology. Death Eucken killed himself in Seebruck on 16 June 1950. See also Eucken's law Spin isomers of hydrogen References 1884 births 1950 deaths Scientists from Jena People from Saxe-Weimar-Eisenach 20th-century German chemists 20th-century German physicists University of Göttingen faculty Suicides in Germany 1950 suicides",
                    "score": 0.8488514423370361
                },
                {
                    "id": 8939174,
                    "contents": "S-50 (Manhattan Project)\nLiquid thermal diffusion The liquid thermal diffusion process was based on the discovery by Carl Ludwig in 1856 and later Charles Soret in 1879, that when a temperature gradient is maintained in an originally homogeneous salt solution, after a time, a concentration gradient will also exist in the solution. This is known as the Soret effect. David Enskog in 1911 and Sydney Chapman in 1916 independently developed the Chapman–Enskog theory, which explained that when a mixture of two gases passes through a temperature gradient, the heavier gas tends to concentrate at the cold end and the lighter gas at the warm end. This was experimentally confirmed by Chapman and F. W. Dootson in 1916.",
                    "score": 0.8480499982833862
                },
                {
                    "id": 1749734,
                    "contents": "Gilbert N. Lewis\nHarvard, Manila, and MIT After his stay in Nernst's lab, Lewis returned to Harvard in 1901 as an instructor for three more years. He was appointed instructor in thermodynamics and electrochemistry. In 1904 Lewis was granted a leave of absence and became Superintendent of Weights and Measures for the Bureau of Science in Manila, Philippines. The next year he returned to Cambridge, Massachusetts when the Massachusetts Institute of Technology (MIT) appointed him to a faculty position, in which he had a chance to join a group of outstanding physical chemists under the direction of Arthur Amos Noyes. He became an assistant professor in 1907, associate professor in 1908, and full professor in 1911.",
                    "score": 0.8478386402130127
                },
                {
                    "id": 823358,
                    "contents": "Walther Nernst\nWalther Hermann Nernst (; 25 June 1864 – 18 November 1941) was a German chemist known for his work in thermodynamics, physical chemistry, electrochemistry, and solid state physics. His formulation of the Nernst heat theorem helped pave the way for the third law of thermodynamics, for which he won the 1920 Nobel Prize in Chemistry. He is also known for developing the Nernst equation in 1887. Life and career Early years Nernst was born in Briesen in West Prussia (now Wąbrzeźno, Poland) to Gustav Nernst (1827–1888) and Ottilie Nerger (1833–1876). His father was a country judge. Nernst had three older sisters and one younger brother. His third sister died of cholera. Nernst went to elementary school at Graudenz. He studied physics and mathematics at the universities of Zürich, Berlin, Graz and Würzburg, where he received his doctorate 1887. In 1889, he finished his habilitation at University of Leipzig.",
                    "score": 0.8475837707519531
                },
                {
                    "id": 10303350,
                    "contents": "Carl Wagner\nSee also Electrochemical engineering Diffusion Solid-state ionics Lifshitz–Slyozov–Wagner theory References External links Chemistry Tree: Carl W. Wagner Details 1901 births 1977 deaths Scientists from Leipzig German physical chemists MIT School of Engineering faculty Foreign associates of the National Academy of Sciences Technische Universität Darmstadt faculty Fellows of the Minerals, Metals & Materials Society",
                    "score": 0.8473303318023682
                },
                {
                    "id": 18316639,
                    "contents": "Thermochemical cycle\n(3) As ΔS° is positive, a temperature increase leads to a reduction of the required work. This is the basis of high-temperature electrolysis. This can also be intuitively explained graphically. Chemical species can have various excitation levels depending on the absolute temperature T, which is a measure of the thermal agitation. The latter causes shocks between atoms or molecules inside the closed system such that energy spreading among the excitation levels increases with time, and stop (equilibrium) only when most of the species have similar excitation levels (a molecule in a highly excited level will quickly return to a lower energy state by collisions) (Entropy (statistical thermodynamics)).",
                    "score": 0.8473270535469055
                },
                {
                    "id": 1302084,
                    "contents": "Urea\nAgNCO + NH4Cl → (NH2)2CO + AgCl This was the first time an organic compound was artificially synthesized from inorganic starting materials, without the involvement of living organisms. The results of this experiment implicitly discredited vitalism — the theory that the chemicals of living organisms are fundamentally different from those of inanimate matter. This insight was important for the development of organic chemistry. His discovery prompted Wöhler to write triumphantly to Berzelius: \"I must tell you that I can make urea without the use of kidneys, either man or dog. Ammonium cyanate is urea.\" In fact, this was incorrect. These are two different chemicals with the same overall chemical formula N2H4CO, which are in chemical equilibrium heavily favoring urea under standard conditions. Regardless, with his discovery, Wöhler secured a place among the pioneers of organic chemistry.",
                    "score": 0.8472078442573547
                },
                {
                    "id": 1106416,
                    "contents": "Timeline of thermodynamics\n1884 – Boltzmann derives the Stefan–Boltzmann blackbody radiant flux law from thermodynamic considerations 1888 – Henri-Louis Le Chatelier states his principle that the response of a chemical system perturbed from equilibrium will be to counteract the perturbation 1889 – Walther Nernst relates the voltage of electrochemical cells to their chemical thermodynamics via the Nernst equation 1889 – Svante Arrhenius introduces the idea of activation energy for chemical reactions, giving the Arrhenius equation 1893 – Wilhelm Wien discovers the displacement law for a blackbody's maximum specific intensity",
                    "score": 0.8471303582191467
                },
                {
                    "id": 18994509,
                    "contents": "Thermodynamik chemischer Vorgänge\nIn the history of thermodynamics, Thermodynamik chemischer Vorgänge (Chemical thermodynamic process) is an 1882 paper written by German physicist Hermann von Helmholtz. It is one of the founding papers in thermodynamics, along with Josiah Willard Gibbs's 1876 paper \"On the Equilibrium of Heterogeneous Substances\" by American physicist Josiah Willard Gibbs. Together they form the foundation of chemical thermodynamics as well as a large part of physical chemistry. References Thermodynamics Historical physics publications Physics papers",
                    "score": 0.8470289707183838
                },
                {
                    "id": 5597107,
                    "contents": "Molar heat capacity\nIn chemistry, heat amounts are still often measured in calories. Confusingly, two units with that name, denoted \"cal\" or \"Cal\", have been commonly used to measure amounts of heat: the \"small calorie\" (or \"gram-calorie\", \"cal\") is 4.184 J, exactly. The \"grand calorie\" (also \"kilocalorie\", \"kilogram-calorie\", or \"food calorie\"; \"kcal\" or \"Cal\") is 1000 small calories, that is, 4184 J, exactly. When heat is measured in these units, the unit of specific heat is usually 1 cal/(°C⋅mol) (\"small calorie\") = 4.184 J⋅K−1⋅mol−1 1 kcal/(°C⋅mol) (\"large calorie\") = 4184 J⋅K−1⋅mol−1. The molar heat capacity of a substance has the same dimension as the heat capacity of an object; namely, L2⋅M⋅T−2⋅Θ−1, or M(L/T)2/Θ. (Indeed, it is the heat capacity of the object that consists of an Avogadro number of molecules of the substance.) Therefore, the SI unit J⋅K−1⋅mol−1 is equivalent to kilogram metre squared per second squared per kelvin (kg⋅m2⋅K−1⋅s−2). Physical basis of molar heat capacity",
                    "score": 0.8469467163085938
                },
                {
                    "id": 13566223,
                    "contents": "Enthalpy–entropy compensation\nIn this form, β has the dimension of temperature and is referred to as the isokinetic (or isoequilibrium) temperature. Alternately, the isokinetic (or isoequilibrium) temperature may be reached by observing that, if a linear relationship is found, then the difference between the ΔH‡'s for any closely related reactants will be related to the difference between ΔS‡'s for the same reactants: δΔH‡ = βδΔS‡ Using the Gibbs free-energy equation, δΔG‡ = (1 − T/β)δΔS‡ In both forms, it is apparent that the difference in Gibbs free-energies of activations (δΔG‡) will be zero when the temperature is at the isokinetic (or isoequilibrium) temperature and hence identical for all members of the reaction set at that temperature.",
                    "score": 0.8466992378234863
                },
                {
                    "id": 1749748,
                    "contents": "Gilbert N. Lewis\nBased on work by J. Willard Gibbs, it was known that chemical reactions proceeded to an equilibrium determined by the free energy of the substances taking part. Lewis spent 25 years determining free energies of various substances. In 1923 he and Merle Randall published the results of this study, which helped formalize modern chemical thermodynamics. Heavy water Lewis was the first to produce a pure sample of deuterium oxide (heavy water) in 1933 and the first to study survival and growth of life forms in heavy water. By accelerating deuterons (deuterium nuclei) in Ernest O. Lawrence's cyclotron, he was able to study many of the properties of atomic nuclei. During the 1930s, he was mentor to Glenn T. Seaborg, who was retained for post-doctoral work as Lewis' personal research assistant. Seaborg went on to win the 1951 Nobel Prize in Chemistry and have the element seaborgium named in his honor while he was still alive.",
                    "score": 0.8465117812156677
                },
                {
                    "id": 28285685,
                    "contents": "Eulim\nExample $ irb irb(main):001:0> require 'eulim' irb(main):002:0> Eulim::Chemistry::Reaction.new(equation: 'KMnO4 + HCl >> KCl + MnCl2 + H2O + Cl2').balanced_eqn => \"2KMnO4 + 16HCl >> 2KCl + 2MnCl2 + 8H2O + 5Cl2\" irb(main):003:0> Eulim::Chemistry::Compound.new(\"CaCO3\") => #<Eulim::Chemistry::Compound:0x00000002a65340 @formula=\"CaCO3\", @constituents={\"Ca\"=>{:element=>#<Eulim::Chemistry::Element:0x00000002c805a8 @name=\"Calcium\", @symbol=\"Ca\", @atomic_number=20, @atomic_mass=#<Unitwise::Measurement value=40.078 unit=u>>, :atom_count=>1}, \"C\"=>{:element=>#<Eulim::Chemistry::Element:0x00000002c8f6e8 @name=\"Carbon\", @symbol=\"C\", @atomic_number=6, @atomic_mass=#<Unitwise::Measurement value=12.0107 unit=u>>, :atom_count=>1}, \"O\"=>{:element=>#<Eulim::Chemistry::Element:0x00000002c8dc30 @name=\"Oxygen\", @symbol=\"O\", @atomic_number=8, @atomic_mass=#<Unitwise::Measurement value=15.9996 unit=u>>, :atom_count=>3}}, @molecular_mass=#<Unitwise::Measurement value=100.0875 unit=u>>",
                    "score": 0.846366822719574
                },
                {
                    "id": 1568571,
                    "contents": "Absolute zero\nThermodynamics near absolute zero At temperatures near , nearly all molecular motion ceases and ΔS = 0 for any adiabatic process, where S is the entropy. In such a circumstance, pure substances can (ideally) form perfect crystals with no structural imperfections as T → 0. Max Planck's strong form of the third law of thermodynamics states the entropy of a perfect crystal vanishes at absolute zero. The original Nernst heat theorem makes the weaker and less controversial claim that the entropy change for any isothermal process approaches zero as T → 0: The implication is that the entropy of a perfect crystal approaches a constant value. An adiabat is a state with constant entropy, typically represented on a graph as a curve in a manner similar to isotherms and isobars.",
                    "score": 0.8463611602783203
                },
                {
                    "id": 27599250,
                    "contents": "Andreas von Antropoff\nWork Publications Experimentelle Untersuchung über die Löslichkeit der Edelgase in Flüssigkeiten, 1919 Experimentelle Einführung in die Chemie, (1929) Atlas der anorganischen und physikalischen Chemie (in cooperation with M. v. Stackelberg) Wandtafeln des periodischen Systems der Elemente, 1926 numerous publications about Inorganic chemistry, general chemistry, electrochemistry and physics Andreas von Antropoff's periodic table He first published his periodic table in the article \"Eine neue Form des periodischen Systems der Elemente\" in the Zeitschrift für angewandte Chemie in 1926. The periodic table is regularly numbered from 1 - Hydrogen to 118 - Oganesson, with \"each number representing the number of protons stored within an atom's nucleus in a satisfying balance\" compared to most other contemporary tables. In addition he placed the theoretical \"Element zero\", which had \"been a matter of conjecture for nearly a century\" atop his periodic table and called it Neutronium.",
                    "score": 0.8463308811187744
                },
                {
                    "id": 5606496,
                    "contents": "History of chemistry\nIn 1925, Austrian-born physicist Wolfgang Pauli developed the Pauli exclusion principle, which states that no two electrons around a single nucleus in an atom can occupy the same quantum state simultaneously, as described by four quantum numbers. Pauli made major contributions to quantum mechanics and quantum field theory - he was awarded the 1945 Nobel Prize for Physics for his discovery of the Pauli exclusion principle - as well as solid-state physics, and he successfully hypothesized the existence of the neutrino. In addition to his original work, he wrote masterful syntheses of several areas of physical theory that are considered classics of scientific literature.",
                    "score": 0.8461951613426208
                }
            ],
            "metric_score": {
                "retrieval_recall": 1,
                "retrieval_precision": 0.4
            }
        }
    },
    {
        "id": "test_28",
        "question": "Calculate the standard potential of the $\\mathrm{Ce}^{4+} / \\mathrm{Ce}$ couple from the values for the $\\mathrm{Ce}^{3+} / \\mathrm{Ce}$ and $\\mathrm{Ce}^{4+} / \\mathrm{Ce}^{3+}$ couples.\r\n",
        "golden_answers": [
            " -1.46"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 11048539,
                    "contents": "Quantum potential\nHiley has emphasized that the quantum potential, for Bohm, was \"a key element in gaining insights into what could underlie the quantum formalism. Bohm was convinced by his deeper analysis of this aspect of the approach that the theory could not be mechanical. Rather, it is organic in the sense of Whitehead. Namely, that it was the whole that determined the properties of the individual particles and their relationship, not the other way round.\"See also: Basil Hiley#Quantum potential and active information Peter R. Holland, in his comprehensive textbook, also refers to it as quantum potential energy. The quantum potential is also referred to in association with Bohm's name as Bohm potential, quantum Bohm potential or Bohm quantum potential.",
                    "score": 0.8762425780296326
                },
                {
                    "id": 10893172,
                    "contents": "Coleman–Weinberg potential\nLiterature See also Quartic interaction References Quantum field theory Quantum mechanical potentials",
                    "score": 0.8714947700500488
                },
                {
                    "id": 101824,
                    "contents": "Lennard-Jones potential\n'Lennard-Jonesium', suggesting that it is viewed as a chemical element. The Lennard-Jones potential is usually the standard choice for the development of theories for matter (especially soft-matter) as well as for the development and testing of computational methods and algorithms. Upon adjusting the model parameters and to real substance properties, the Lennard-Jones potential can be used to describe simple substance (like noble gases) with good accuracy. Furthermore, the Lennard-Jones potential is often used as a building block in molecular models (a.k.a. force fields) for more complex substances.",
                    "score": 0.8663186430931091
                },
                {
                    "id": 24403987,
                    "contents": "Morse/Long-range potential\nthe c-state of Li2: where the MLR potential was successfully able to bridge a gap of more than 5000 cm−1 in experimental data. Two years later it was found that the MLR potential was able to successfully predict the energies in the middle of this gap, correctly within about 1 cm−1. The accuracy of these predictions was much better than the most sophisticated ab initio techniques at the time. the A-state of Li2: where Le Roy et al. constructed an MLR potential which determined the C3 value for atomic lithium to a higher-precision than any previously measured atomic oscillator strength, by an order of magnitude. This lithium oscillator strength is related to the radiative lifetime of atomic lithium and is used as a benchmark for atomic clocks and measurements of fundamental constants. the a-state of KLi: where the MLR was used to build an analytic global potential successfully despite there only being a small amount of levels observed near the top of the potential.",
                    "score": 0.864185094833374
                },
                {
                    "id": 11048536,
                    "contents": "Quantum potential\nThis has been called the superquantum potential by Bohm and his co-workers.<ref>Basil Hiley: The conceptual structure of the Bohm interpretation of quantum mechanics, Kalervo Vihtori Laurikainen et al (ed.): Symposium on the Foundations of Modern Physics 1994: 70 years of matter waves, Editions Frontières, , p. 99–117, p. 144</ref> Basil Hiley showed that the energy–momentum-relations in the Bohm model can be obtained directly from the energy–momentum tensor of quantum field theory and that the quantum potential is an energy term that is required for local energy–momentum conservation. He has also hinted that for particle with energies equal to or higher than the pair creation threshold, Bohm's model constitutes a many-particle theory that describes also pair creation and annihilation processes.",
                    "score": 0.863873302936554
                },
                {
                    "id": 27550450,
                    "contents": "Uehling potential\nIn quantum electrodynamics, the Uehling potential describes the interaction potential between two electric charges which, in addition to the classical Coulomb potential, contains an extra term responsible for the electric polarization of the vacuum. This potential was found by Edwin Albrecht Uehling in 1935.",
                    "score": 0.8631824254989624
                },
                {
                    "id": 14165264,
                    "contents": "Born–Landé equation\nEvaluating the minimum intensive potential energy and substituting the expression for B in terms of r0 yields the Born–Landé equation: Calculated lattice energies The Born–Landé equation gives an idea to the lattice energy of a system. {| class=\"wikitable\" border=\"1\" |- ! Compound ! Calculated ! Experimental |- !NaCl | −756 kJ/mol | −787 kJ/mol |- !LiF | −1007 kJ/mol | −1046 kJ/mol |- !CaCl2 | −2170 kJ/mol | −2255 kJ/mol |} Born exponent The Born exponent is typically between 5 and 12. Approximate experimental values are listed below: {| class=\"wikitable\" border=\"1\" |- !Ion configuration !He !Ne !Ar, Cu+ !Kr, Ag+ !Xe, Au+ |- !n | 5 | 7 | 9 | 10 | 12 |} See also Kapustinskii equation Born–Mayer equation References Solid-state chemistry Ions Max Born",
                    "score": 0.8626090288162231
                },
                {
                    "id": 14638953,
                    "contents": "Hartree equation\nIn 1927, a year after the publication of the Schrödinger equation, Hartree formulated what are now known as the Hartree equations for atoms, using the concept of self-consistency that Lindsay had introduced in his study of many electron systems in the context of Bohr theory. Hartree assumed that the nucleus together with the electrons formed a spherically symmetric field. The charge distribution of each electron was the solution of the Schrödinger equation for an electron in a potential , derived from the field. Self-consistency required that the final field, computed from the solutions, was self-consistent with the initial field, and he thus called his method the self-consistent field method.",
                    "score": 0.8625372648239136
                },
                {
                    "id": 5251261,
                    "contents": "Hubbard model\nThe model was originally proposed in 1963 to describe electrons in solids. Since then, it has been applied to the study of high-temperature superconductivity, quantum magnetism, and charge density waves. The Hubbard model introduces short-range interactions between electrons to the tight-binding model, which only includes kinetic energy (a \"hopping\" term) and interactions with the atoms of the lattice (an \"atomic\" potential). When the interaction between electrons is strong, the behavior of the Hubbard model can be qualitatively different from a tight-binding model. For example, the Hubbard model correctly predicts the existence of Mott insulators: materials that are insulating due to the strong repulsion between electrons, even though they satisfy the usual criteria for conductors, such as having an odd number of electrons per unit cell.",
                    "score": 0.8620402216911316
                },
                {
                    "id": 20303125,
                    "contents": "James Charles Phillips\nBiography Phillips was born in New Orleans and grew up in several Western states (Arizona, Colorado and New Mexico). After graduating from Albuquerque HS in 1950, he went to the University of Chicago, where he received M.S. in both mathematics and physics. He was the grader in Enrico Fermi’s last course (1955). He studied with Morrel H. Cohen, with a Ph.D. thesis on algebraic topology (1956). He joined the Theoretical Physics group at Bell Laboratories, newly formed and under the leadership of Conyers Herring (1956-1958). Following a suggestion by Herring, Phillips invented a simplified (PseudoPotential, PP) theory of the electronic structure of semiconductors, and produced the first electronic structures of Silicon and Germanium semiconductors in good agreement with known properties (1958).",
                    "score": 0.8616985082626343
                },
                {
                    "id": 25385637,
                    "contents": "Luttinger–Ward functional\nIn solid state physics, the Luttinger–Ward functional, proposed by Joaquin Mazdak Luttinger and John Clive Ward in 1960, is a scalar functional of the bare electron-electron interaction and the renormalized many-body Green's function. In terms of Feynman diagrams, the Luttinger–Ward functional is the sum of all closed, bold, two-particle irreducible diagrams, i.e., all diagrams without particles going in or out that do not fall apart if one removes two propagator lines. It is usually written as or , where is the Green's function and is the bare interaction. The Luttinger–Ward functional has no direct physical meaning, but it is useful in proving conservation laws.",
                    "score": 0.8613680005073547
                },
                {
                    "id": 11048508,
                    "contents": "Quantum potential\nThe Bohm quantum potential is closely linked with the results of other approaches, in particular relating to work by Erwin Madelung of 1927 and to work by Carl Friedrich von Weizsäcker of 1935. Building on the interpretation of the quantum theory introduced by Bohm in 1952, David Bohm and Basil Hiley in 1975 presented how the concept of a quantum potential leads to the notion of an \"unbroken wholeness of the entire universe\", proposing that the fundamental new quality introduced by quantum physics is nonlocality. Quantum potential as part of the Schrödinger equation The Schrödinger equation is re-written using the polar form for the wave function with real-valued functions and , where is the amplitude (absolute value) of the wave function , and its phase. This yields two equations: from the imaginary and real part of the Schrödinger equation follow the continuity equation and the quantum Hamilton–Jacobi equation respectively.",
                    "score": 0.8606112599372864
                },
                {
                    "id": 12714997,
                    "contents": "Charles Kittel\nAwards Oliver E. Buckley Condensed Matter Prize, 1957 Berkeley Distinguished Teacher Award, 1970 Oersted Medal, American Association of Physics Teachers, 1979 Works Introduction to Solid State Physics, 1st ed. 1953 - 8th ed. 2005, Quantum Theory of Solids, 1963, and (with C. Y. Fong) 1987, Thermal Physics, 2nd ed. 1980, , and (with H. Kroemer) 1980. Berkeley Physics Course. Mechanics. Vol. 1, with Walter Knight and Malvin A. Ruderman Reprinted five times by 1967; a reproduction was published in 2004 by Dover (). See also Antiferroelectricity Ferromagnetic resonance Single domain (magnetic) References External links Freeman Dyson on work at Berkeley with Charles Kittel Charles Kittel (Physics History Network)",
                    "score": 0.8597347736358643
                },
                {
                    "id": 14631073,
                    "contents": "Gordon Baym\nGordon Alan Baym (born July 1, 1935) is an American theoretical physicist. Biography Born in New York City, he graduated from the Brooklyn Technical High School, and received his undergraduate degree from Cornell University in 1956. He earned his Ph.D. from Harvard University in 1960, studying under Julian Schwinger. He joined the physics faculty of the University of Illinois at Urbana-Champaign in 1963, becoming a full professor in 1968. His areas of research include condensed-matter physics, nuclear physics and astrophysics, as well as the history of physics. In 1962 he and Leo Kadanoff collaborated on Quantum Statistical Mechanics: Green's Function Methods in Equilibrium and Nonequilibrium Problems. In 1969 he published Lectures on Quantum Mechanics, a widely used graduate textbook that, unconventionally, begins with photon polarization. In 1991 he and Chris Pethick published the monograph Landau Fermi-Liquid Theory: Concepts and Applications.",
                    "score": 0.8593422174453735
                },
                {
                    "id": 992999,
                    "contents": "Robert Andrews Millikan\nSee also Nobel Prize controversies Robert Millikan is widely believed to have been denied the 1920 prize for physics owing to Felix Ehrenhaft's claims to have measured charges smaller than Millikan's elementary charge. Ehrenhaft's claims were ultimately dismissed and Millikan was awarded the prize in 1923. Millikan's passage announcing emerging branch of physics under the designation of quantum theory, published in Popular Science January 1927. References Citations Sources Waller, John, \"Einstein's Luck: The Truth Behind Some of the Greatest Scientific Discoveries\". Oxford University Press, 2003. . Physics paper On the Elementary Electrical Charge and the Avogadro Constant (extract) Robert Andrews Millikan at www.aip.org/history, 2003",
                    "score": 0.8592117428779602
                },
                {
                    "id": 24891398,
                    "contents": "Double-well potential\nReferences Quantum mechanics Quantum mechanical potentials",
                    "score": 0.8592002987861633
                },
                {
                    "id": 1403693,
                    "contents": "Quintessence (physics)\ndepending on the ratio of its kinetic and potential energy. Those working with this postulate believe that quintessence became repulsive about ten billion years ago, about 3.5 billion years after the Big Bang.",
                    "score": 0.8590867519378662
                },
                {
                    "id": 16681002,
                    "contents": "Timeline of quantum mechanics\n1927 – Born and J. Robert Oppenheimer introduce the Born–Oppenheimer approximation, which allows the quick approximation of the energy and wavefunctions of smaller molecules. 1927 – Walter Heitler and Fritz London introduce the concepts of valence bond theory and apply it to the hydrogen molecule. 1927 – Thomas and Fermi develop the Thomas–Fermi model for a Gas in a box. 1927 – Chandrasekhara Venkata Raman studies optical photon scattering by electrons. 1927 – Dirac states his relativistic electron quantum wave equation, the Dirac equation. 1927 – Charles Galton Darwin and Walter Gordon solve the Dirac equation for a Coulomb potential. 1927 – Charles Drummond Ellis (along with James Chadwick and colleagues) finally establish clearly that the beta decay spectrum is in fact continuous and not discrete, posing a problem that will later be solved by theorizing (and later discovering) the existence of the neutrino.",
                    "score": 0.8589063882827759
                },
                {
                    "id": 1866322,
                    "contents": "Maxwell's equations\nSee below for a detailed description of the differences between the microscopic equations, dealing with total charge and current including material contributions, useful in air/vacuum; and the macroscopic equations, dealing with free charge and current, practical to use within materials. Bound charge and current",
                    "score": 0.8587325811386108
                },
                {
                    "id": 1402323,
                    "contents": "Robert S. Mulliken\nUp to this point, the primary way to calculate the electronic structure of molecules was based on a calculation by Walter Heitler and Fritz London on the hydrogen molecule (H2) in 1927. With the conception of hybridized atomic orbitals by John C. Slater and Linus Pauling, which rationalized observed molecular geometries, the method was based on the premise that the bonds in any molecule could be described in a manner similar to the bond in H2, namely, as overlapping atomic orbitals centered on the atoms involved. Since it corresponded to chemists' ideas of localized bonds between pairs of atoms, this method (called the Valence-Bond (VB) or Heitler-London-Slater-Pauling (HLSP) method), was very popular. In attempting to calculate the properties of excited states (molecules that have been excited by an energy source), the VB method does not always work well. With its description of the electron wave functions in molecules as delocalized molecular orbitals that possess the same symmetry",
                    "score": 0.8584975004196167
                },
                {
                    "id": 28771667,
                    "contents": "Linnett double-quartet theory\nLinnett continued to expand on his theory through a number of publications until his death in 1975. In these writings, Linnett recognised the continued importance of the Lewis model of bonding and the importance of satisfying the octet rule. However, he also argued that this view overemphasises the importance of electron pairing in the formation of chemical bonds. Hence, his theory sought to introduce spin into the conventional model of bonding and hence rectify some of the problems associated with Lewis’ theory. While LDQ theory is a relatively simple extension of Lewis’ bonding theory, the additional freedom of the electrons to separate into two sets, differentiated by their spins, has bestowed upon the theory exquisite agreement with the results of many experiments.",
                    "score": 0.8584564924240112
                },
                {
                    "id": 16680998,
                    "contents": "Timeline of quantum mechanics\n1923 – Pierre Auger discovers the Auger effect, where filling the inner-shell vacancy of an atom is accompanied by the emission of an electron from the same atom. 1923 – Louis de Broglie extends wave–particle duality to particles, postulating that electrons in motion are associated with waves. He predicts that the wavelengths are given by Planck's constant h divided by the momentum of the mv = p of the electron: λ = h / mv = h / p. 1923 – Gilbert N. Lewis creates the theory of Lewis acids and bases based on the properties of electrons in molecules, defining an acid as accepting an electron lone pair from a base. 1924 – Satyendra Nath Bose explains Planck's law using a new statistical law that governs bosons, and Einstein generalizes it to predict Bose–Einstein condensate. The theory becomes known as Bose–Einstein statistics.",
                    "score": 0.8583898544311523
                },
                {
                    "id": 7844098,
                    "contents": "Grüneisen parameter\nSome formulations for the Grüneisen parameter include: where is volume, and are the principal (i.e. per-mass) heat capacities at constant pressure and volume, is energy, is entropy, is the volume thermal expansion coefficient, and are the adiabatic and isothermal bulk moduli, is the speed of sound in the medium, and is density. The Grüneisen parameter is dimensionless. Grüneisen constant for perfect crystals with pair interactions The expression for the Grüneisen constant of a perfect crystal with pair interactions in -dimensional space has the form: where is the interatomic potential, is the equilibrium distance, is the space dimensionality. Relations between the Grüneisen constant and parameters of Lennard-Jones, Morse, and Mie potentials are presented in the table below.",
                    "score": 0.8583887815475464
                },
                {
                    "id": 15644722,
                    "contents": "Leonard I. Schiff\nRecognition Schiff became a Fellow of the American Physical Society in 1939. He was elected to membership in the National Academy of Sciences in 1957. In 1966, he received the Oersted Medal of the American Association of Physics Teachers. Also, he received the Dinkelspiel Award for Excellence in Teaching at Stanford University. Schiff Hall, an undergraduate dormitory at Stanford, is named for him. References External links http://books.nap.edu/openbook.php?record_id=577&page=300 National Academies Press Biography - Leonard Schiff http://www.oac.cdlib.org/view?docId=tf609nb1db;developer=local;query=;style=oac4 Guide to the Leonard I. Schiff Papers, 1948–1971 http://www.stanford.edu/dept/physics/history/# Quantum Mechanics and Leonard Schiff",
                    "score": 0.8582353591918945
                },
                {
                    "id": 1620482,
                    "contents": "Bohr model\nThe Bohr model is a relatively primitive model of the hydrogen atom, compared to the valence shell atom model. As a theory, it can be derived as a first-order approximation of the hydrogen atom using the broader and much more accurate quantum mechanics and thus may be considered to be an obsolete scientific theory. However, because of its simplicity, and its correct results for selected systems (see below for application), the Bohr model is still commonly taught to introduce students to quantum mechanics or energy level diagrams before moving on to the more accurate, but more complex, valence shell atom. A related quantum model was originally proposed by Arthur Erich Haas in 1910 but was rejected until the 1911 Solvay Congress where it was thoroughly discussed. The quantum theory of the period between Planck's discovery of the quantum (1900) and the advent of a mature quantum mechanics (1925) is often referred to as the old quantum theory. Origin",
                    "score": 0.858148455619812
                },
                {
                    "id": 54830,
                    "contents": "Chemical potential\nIn atomic physics, the chemical potential of the electrons in an atom is sometimes said to be the negative of the atom's electronegativity. Likewise, the process of chemical potential equalization is sometimes referred to as the process of electronegativity equalization. This connection comes from the Mulliken electronegativity scale. By inserting the energetic definitions of the ionization potential and electron affinity into the Mulliken electronegativity, it is seen that the Mulliken chemical potential is a finite difference approximation of the electronic energy with respect to the number of electrons., i.e.,",
                    "score": 0.8581427335739136
                },
                {
                    "id": 24433324,
                    "contents": "Lieb–Oxford inequality\nIn quantum chemistry and physics, the Lieb–Oxford inequality provides a lower bound for the indirect part of the Coulomb energy of a quantum mechanical system. It is named after Elliott H. Lieb and Stephen Oxford. The inequality is of importance for density functional theory and plays a role in the proof of stability of matter. Introduction In classical physics, one can calculate the Coulomb energy of a configuration of charged particles in the following way. First, calculate the charge density , where is a function of the coordinates . Second, calculate the Coulomb energy by integrating: In other words, for each pair of points and , this expression calculates the energy related to the fact that the charge at is attracted to or repelled from the charge at . The factor of corrects for double-counting the pairs of points.",
                    "score": 0.8578900694847107
                },
                {
                    "id": 1446131,
                    "contents": "Dirac sea\nwhich means that if one replaces N by 1−N for negative energy states, there is a constant shift in quantities like the energy and the charge density, quantities that count the total number of particles. The infinite constant gives the Dirac sea an infinite energy and charge density. The vacuum charge density should be zero, since the vacuum is Lorentz invariant, but this is artificial to arrange in Dirac's picture. The way it is done is by passing to the modern interpretation. Dirac's idea is more directly applicable to solid state physics, where the valence band in a solid can be regarded as a \"sea\" of electrons. Holes in this sea indeed occur, and are extremely important for understanding the effects of semiconductors, though they are never referred to as \"positrons\". Unlike in particle physics, there is an underlying positive charge—the charge of the ionic lattice—that cancels out the electric charge of the sea.",
                    "score": 0.8578200340270996
                },
                {
                    "id": 19908272,
                    "contents": "Resonating valence bond theory\nIn condensed matter physics, the resonating valence bond theory (RVB) is a theoretical model that attempts to describe high temperature superconductivity, and in particular the superconductivity in cuprate compounds. It was first proposed by an American physicist P. W. Anderson and Indian theoretical physicist Ganapathy Baskaran in 1987. The theory states that in copper oxide lattices, electrons from neighboring copper atoms interact to form a valence bond, which locks them in place. However, with doping, these electrons can act as mobile Cooper pairs and are able to superconduct. Anderson observed in his 1987 paper that the origins of superconductivity in doped cuprates was in the Mott insulator nature of crystalline copper oxide. RVB builds on the Hubbard and t-J models used in the study of strongly correlated materials.",
                    "score": 0.8576462268829346
                },
                {
                    "id": 1129313,
                    "contents": "Niels Bohr\nwhere me is the electron's mass, e is its charge, h is Planck's constant and Z is the atom's atomic number (1 for hydrogen). The model's first hurdle was the Pickering series, lines which did not fit Balmer's formula. When challenged on this by Alfred Fowler, Bohr replied that they were caused by ionised helium, helium atoms with only one electron. The Bohr model was found to work for such ions. Many older physicists, like Thomson, Rayleigh and Hendrik Lorentz, did not like the trilogy, but the younger generation, including Rutherford, David Hilbert, Albert Einstein, Enrico Fermi, Max Born and Arnold Sommerfeld saw it as a breakthrough. The trilogy's acceptance was entirely due to its ability to explain phenomena which stymied other models, and to predict results that were subsequently verified by experiments. Today, the Bohr model of the atom has been superseded, but is still the best known model of the atom, as it often appears in high school physics and chemistry texts.",
                    "score": 0.8575003147125244
                },
                {
                    "id": 4443134,
                    "contents": "Free electron model\nThe free electron model solved many of the inconsistencies related to the Drude model and gave insight into several other properties of metals. The free electron model considers that metals are composed of a quantum electron gas where ions play almost no role. The model can be very predictive when applied to alkali and noble metals. Ideas and assumptions",
                    "score": 0.8568400144577026
                },
                {
                    "id": 13952852,
                    "contents": "John Hubbard (physicist)\nJohn Hubbard (27 October 1931 – 27 November 1980) was a British physicist, best known for the Hubbard model for interacting electrons, the Hubbard–Stratonovich transformation, and the Hubbard approximations. He graduated from Imperial College London, receiving a B.Sc. (1955) and a Ph.D. degree (1958). He was the Head of the Solid State Theory Group at the Atomic Energy Research Establishment in Harwell (England), and worked at the IBM Research Laboratory in San Jose, California (1976–1980). References External links Biography by A. L. Kuzemsky, 2006. John Hubbard 1931–1980 by David Thouless, 18 June 2013 1931 births 1980 deaths Alumni of Imperial College London IBM employees British physicists",
                    "score": 0.8566872477531433
                },
                {
                    "id": 11048538,
                    "contents": "Quantum potential\nHiley refers to the quantum potential as internal energy and as \"a new quality of energy only playing a role in quantum processes\". He explains that the quantum potential is a further energy term aside the well-known kinetic energy and the (classical) potential energy and that it is a nonlocal energy term that arises necessarily in view of the requirement of energy conservation; he added that much of the physics community's resistance against the notion of the quantum potential may have been due to scientists' expectations that energy should be local.",
                    "score": 0.8565775156021118
                },
                {
                    "id": 3167739,
                    "contents": "Brilliant Light Power\nin Dombey's paper, further work by Antonio Di Castro has shown that states below the ground state, as described in Mills' work, are incompatible with the Schrödinger, Klein–Gordon and Dirac equations, key equations in the study of quantum systems.",
                    "score": 0.8563851118087769
                },
                {
                    "id": 27487641,
                    "contents": "20th century in science\nQuantum chemistry Some view the birth of quantum chemistry in the discovery of the Schrödinger equation and its application to the hydrogen atom in 1926. However, the 1927 article of Walter Heitler and Fritz London is often recognised as the first milestone in the history of quantum chemistry. This is the first application of quantum mechanics to the diatomic hydrogen molecule, and thus to the phenomenon of the chemical bond. In the following years much progress was accomplished by Edward Teller, Robert S. Mulliken, Max Born, J. Robert Oppenheimer, Linus Pauling, Erich Hückel, Douglas Hartree, Vladimir Aleksandrovich Fock, to cite a few. Still, skepticism remained as to the general power of quantum mechanics applied to complex chemical systems. The situation around 1930 is described by Paul Dirac:",
                    "score": 0.8563494086265564
                },
                {
                    "id": 597672,
                    "contents": "Fermi energy\nThe term \"Fermi energy\" is often used to refer to a different yet closely related concept, the Fermi level (also called electrochemical potential). There are a few key differences between the Fermi level and Fermi energy, at least as they are used in this article: The Fermi energy is only defined at absolute zero, while the Fermi level is defined for any temperature. The Fermi energy is an energy difference (usually corresponding to a kinetic energy), whereas the Fermi level is a total energy level including kinetic energy and potential energy. The Fermi energy can only be defined for non-interacting fermions (where the potential energy or band edge is a static, well defined quantity), whereas the Fermi level remains well defined even in complex interacting systems, at thermodynamic equilibrium.",
                    "score": 0.8561167120933533
                },
                {
                    "id": 22831386,
                    "contents": "Index of physics articles (M)\nManhattan Project Mani Lal Bhaumik Manifest covariance Manipulation of atoms by optical field Manne Siegbahn Manning formula Mannque Rho Mantle convection Manuel António Gomes Manuel Mateus Ventura Manuel Sandoval Vallarta Many-body problem Many-body theory Many-worlds interpretation Marangoni effect Marangoni number Marc-Auguste Pictet Marc A. Kastner Marc Henneaux Marcel Audiffren Marcel Brillouin Marcel Grossmann Marcel J. E. Golay Marcel Schein Marcela Carena Marcello Pirani Marcelo Damy Marcelo Gleiser Marchenko equation Marcia McNutt Marcia Neugebauer Marcos Moshinsky Marcus Birkenkrahe Marcus O'Day Marek Gazdzicki Marek Huberath Margaret Eliza Maltby Margaret Geller Margaret Hamilton (scientist) Margaret MacVicar Margaret Murnane Margaret Wertheim Margherita Hack Marginal stability Margolus–Levitin theorem Marguerite Perey Maria Ardinghelli Maria Goeppert-Mayer Maria Spiropulu Marian Danysz Marian Smoluchowski Mariano Gago Marie Alfred Cornu Marie Curie Marietta Blau",
                    "score": 0.8558953404426575
                },
                {
                    "id": 1194925,
                    "contents": "Quantum chemistry\nSome view the birth of quantum chemistry as starting with the discovery of the Schrödinger equation and its application to the hydrogen atom in 1926. However, the 1927 article of Walter Heitler (1904–1981) and Fritz London, is often recognized as the first milestone in the history of quantum chemistry. This is the first application of quantum mechanics to the diatomic hydrogen molecule, and thus to the phenomenon of the chemical bond. In the following years much progress was accomplished by Robert S. Mulliken, Max Born, J. Robert Oppenheimer, Linus Pauling, Erich Hückel, Douglas Hartree, Vladimir Fock, to cite a few. The history of quantum chemistry also goes through the 1838 discovery of cathode rays by Michael Faraday, the 1859 statement of the black-body radiation problem by Gustav Kirchhoff, the 1877 suggestion by Ludwig Boltzmann that the energy states of a physical system could be discrete, and the 1900 quantum hypothesis by Max Planck that any energy radiating atomic system can",
                    "score": 0.8558456897735596
                },
                {
                    "id": 701050,
                    "contents": "Max Born\nIn 1928, Einstein nominated Heisenberg, Born, and Jordan for the Nobel Prize in Physics, but Heisenberg alone won the 1932 Prize \"for the creation of quantum mechanics, the application of which has led to the discovery of the allotropic forms of hydrogen\", while Schrödinger and Dirac shared the 1933 Prize \"for the discovery of new productive forms of atomic theory\". On 25 November 1933, Born received a letter from Heisenberg in which he said he had been delayed in writing due to a \"bad conscience\" that he alone had received the Prize \"for work done in Göttingen in collaboration—you, Jordan and I.\" Heisenberg went on to say that Born and Jordan's contribution to quantum mechanics cannot be changed by \"a wrong decision from the outside.\" In 1954, Heisenberg wrote an article honouring Planck for his insight in 1900, in which he credited Born and Jordan for the final mathematical formulation of matrix mechanics and Heisenberg went on to stress how great their contributions were to",
                    "score": 0.8556223511695862
                },
                {
                    "id": 11048506,
                    "contents": "Quantum potential\nThe quantum potential or quantum potentiality is a central concept of the de Broglie–Bohm formulation of quantum mechanics, introduced by David Bohm in 1952. Initially presented under the name quantum-mechanical potential, subsequently quantum potential, it was later elaborated upon by Bohm and Basil Hiley in its interpretation as an information potential which acts on a quantum particle. It is also referred to as quantum potential energy, Bohm potential, quantum Bohm potential or Bohm quantum potential.",
                    "score": 0.8555790781974792
                },
                {
                    "id": 4558489,
                    "contents": "Aufbau principle\nThe aufbau principle, from the German Aufbauprinzip (building-up principle), also called the aufbau rule, states that in the ground state of an atom or ion, electrons fill subshells of the lowest available energy, then they fill subshells of higher energy. For example, the 1s subshell is filled before the 2s subshell is occupied. In this way, the electrons of an atom or ion form the most stable electron configuration possible. An example is the configuration for the phosphorus atom, meaning that the 1s subshell has 2 electrons, and so on. Electron behavior is elaborated by other principles of atomic physics, such as Hund's rule and the Pauli exclusion principle. Hund's rule asserts that if multiple orbitals of the same energy are available, electrons will occupy different orbitals singly before any are occupied doubly. If double occupation does occur, the Pauli exclusion principle requires that electrons that occupy the same orbital must have different spins (+ and −).",
                    "score": 0.8555411100387573
                },
                {
                    "id": 15122627,
                    "contents": "Mattis–Bardeen theory\nReferences Further reading Michael Tinkham, Introduction to Superconductivity. Second edition. Shu-Ang-Zhou, Electrodynamics of Solids and Microwave Superconductivity''. Superconductivity",
                    "score": 0.8552411198616028
                },
                {
                    "id": 3852308,
                    "contents": "Quantum electrochemistry\nThe scientific school of Quantum electrochemistry began to form in the 1960s under Revaz Dogonadze. Generally speaking, the field comprises the notions arising in electrodynamics, quantum mechanics, and electrochemistry; and so is studied by a very large array of different professional researchers. The fields they reside in include, chemical, electrical and mechanical engineering, chemistry and physics. More specifically, quantum electrochemistry is the application of quantum mechanical tools such as density functional theory to the study of electrochemical processes, including electron transfer at electrodes. It also includes models such as Marcus theory.",
                    "score": 0.8552101850509644
                },
                {
                    "id": 8243009,
                    "contents": "Hans Hellmann\nAfter the Nazi rise to power, Hellmann was dismissed on 24 December 1933 as ‘undesirable’ because of his Jewish wife. He immigrated to the Soviet Union, taking up a position at the Karpov institute in Moscow working among other things on pseudopotentials. However, he was later denounced during the Great Purge, imprisoned on 10 May 1938 and executed in Butovo on 29 May. His son, Hans Hellmann, Jr., was only allowed to leave the former Soviet Union in 1991. In science, his name is primarily associated with the Hellmann–Feynman theorem, as well as with one of the first-ever textbooks on quantum chemistry (‘Kvantovaya Khimiya’, 1937; translated into German as ‘Einfuehrung in die Quantenchemie’, Vienna, 1937). He pioneered several approaches now commonplace in quantum chemistry, notably the use of pseudopotentials. Notes References Translation of Siegen university site Complete list of publications of Hans Hellmann (Freie Universität Berlin)",
                    "score": 0.85471111536026
                },
                {
                    "id": 7211737,
                    "contents": "John Clive Ward\nStandard Model Ward left the British hydrogen bomb programme and took a job with an electronics company in California. Later in 1956, Elliott Montroll offered him a visiting professorship at the University of Maryland. Noting a recent paper by Keith Brueckner and Murray Gell-Mann on the ground state energy of an electron gas, Ward gave a lecture in which he proposed a different approach. Montroll recognised that this was Debye–Hückel theory. Over the next few weeks, Ward later recalled, \"We had managed not only to produce a definitive extension of a previously purely classical theory, but also to establish the rules for diagrammatic treatment of problems in quantum statistical mechanics, rules that are now the bread and butter of modern calculations.\"",
                    "score": 0.8545899987220764
                },
                {
                    "id": 21593473,
                    "contents": "List of things named after Charles-Augustin de Coulomb\nA list of things named for French physicist Charles-Augustin de Coulomb (1736–1806). For additional uses of the term, see coulomb (disambiguation) coulomb (symbol C), the SI unit of electric charge Coulomb's law Coulomb constant Coulomb barrier Coulomb blockade Coulomb collision Coulomb damping Coulomb excitation Coulomb explosion Coulomb friction Coulomb gap Coulomb gauge Coulomb Hamiltonian Coulomb logarithm Coulomb operator Coulomb phase Coulomb potential Coulomb scattering (Rutherford scattering) Coulomb scattering state Coulomb stress transfer Coulomb wave function A coulomb wave function is a solution to the coulomb wave equation Coulomb, a lunar crater Coulomb-Sarton Basin, lunar basin named after the craters Coulomb and Sarton Coulometry Interatomic Coulombic decay Mohr–Coulomb theory Screened Coulomb Potentials Implicit Solvent Model Statcoulomb (Symbol statC) See also Coulomb (disambiguation) Coulombs (disambiguation) Coulomb",
                    "score": 0.8545820713043213
                },
                {
                    "id": 13007900,
                    "contents": "Cedar Paul\nThe new theories of matter and the atom by Alfred Berthoud. London: G. Allen & Unwin; New York: Macmillan, [1924]. Translated from the French. Labour's alternative: the United States of Europe or Europe limited by Edo Fimmen. London, Labour Pub. Co., 1924. Translated from the German. Love in children and its aberrations; a book for parents and teachers by Oskar Pfister. New York: Dodd, Mead and Company, 1924. Translated from the German. The remaking of Russia by Kurt Wiedenfeld. London: Labour Pub. Co., 1924. Translated from the German. Sigmund Freud, his personality, his teaching, & his school by Fritz Wittels. London: G. Allen & Unwin, [1924]. Translated from the German. Passion and pain by Stefan Zweig. London, Chapman and Hall, 1924. Translated from the German.",
                    "score": 0.8545730113983154
                },
                {
                    "id": 101836,
                    "contents": "Lennard-Jones potential\neventually also consists of other potential types, e.g. partial charges). Molecular models (often referred to as 'force fields') for practically all molecular and ionic particles can be constructed using this scheme for example for alkanes.",
                    "score": 0.8544368147850037
                },
                {
                    "id": 7073762,
                    "contents": "John Gribbin\nQuantum physics (1984) In Search of Schrödinger's Cat: Quantum Physics and Reality, Bantam Books, (reprinted in 2012 by Random House ) (1996) Schrödinger's Kittens and the Search for Reality, Back Bay Books, (1998) Q Is for Quantum: An Encyclopedia of Particle Physics, Free Press, (2002) Quantum Physics (Essential Science), Dorling Kindersley, (2007) La physique quantique, Pearson Education, (2019) Six Impossible Things: The 'Quanta of Solace' and the Mysteries of the Subatomic World, Icon Books,",
                    "score": 0.8544061779975891
                },
                {
                    "id": 11719108,
                    "contents": "History of quantum mechanics\nThe field of quantum chemistry was pioneered by physicists Walter Heitler and Fritz London, who published a study of the covalent bond of the hydrogen molecule in 1927. Quantum chemistry was subsequently developed by a large number of workers, including the American theoretical chemist Linus Pauling at Caltech, and John C. Slater into various theories such as Molecular Orbital Theory or Valence Theory. Quantum field theory Beginning in 1927, researchers attempted to apply quantum mechanics to fields instead of single particles, resulting in quantum field theories. Early workers in this area include P.A.M. Dirac, W. Pauli, V. Weisskopf, and P. Jordan. This area of research culminated in the formulation of quantum electrodynamics by R.P. Feynman, F. Dyson, J. Schwinger, and S. Tomonaga during the 1940s. Quantum electrodynamics describes a quantum theory of electrons, positrons, and the electromagnetic field, and served as a model for subsequent quantum field theories.",
                    "score": 0.8541456460952759
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_29",
        "question": "An effusion cell has a circular hole of diameter $1.50 \\mathrm{~mm}$. If the molar mass of the solid in the cell is $300 \\mathrm{~g} \\mathrm{~mol}^{-1}$ and its vapour pressure is $0.735 \\mathrm{~Pa}$ at $500 \\mathrm{~K}$, by how much will the mass of the solid decrease in a period of $1.00 \\mathrm{~h}$ ?",
        "golden_answers": [
            " 16"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 111483,
                    "contents": "Effusion\nwhere and represent the molar masses of the gases. This equation is known as Graham's law of effusion. The effusion rate for a gas depends directly on the average velocity of its particles. Thus, the faster the gas particles are moving, the more likely they are to pass through the effusion orifice. Knudsen effusion cell The Knudsen effusion cell is used to measure the vapor pressures of a solid with very low vapor pressure. Such a solid forms a vapor at low pressure by sublimation. The vapor slowly effuses through a pinhole, and the loss of mass is proportional to the vapor pressure and can be used to determine this pressure. The heat of sublimation can also be determined by measuring the vapor pressure as a function of temperature, using the Clausius–Clapeyron relation. References Physical chemistry Gases",
                    "score": 0.9020986557006836
                },
                {
                    "id": 111479,
                    "contents": "Effusion\nIn physics and chemistry, effusion is the process in which a gas escapes from a container through a hole of diameter considerably smaller than the mean free path of the molecules. Such a hole is often described as a pinhole and the escape of the gas is due to the pressure difference between the container and the exterior. Under these conditions, essentially all molecules which arrive at the hole continue and pass through the hole, since collisions between molecules in the region of the hole are negligible. Conversely, when the diameter is larger than the mean free path of the gas, flow obeys the Sampson flow law. In medical terminology, an effusion refers to accumulation of fluid in an anatomic space, usually without loculation. Specific examples include subdural, mastoid, pericardial and pleural effusions. Etymology The word effusion derives from the Latin word, effundo, which means \"shed, pour forth, pour out, utter, lavish, waste.\"",
                    "score": 0.8724371194839478
                },
                {
                    "id": 111482,
                    "contents": "Effusion\nor where is the volumetric flow rate of the gas, is the average pressure on either side of the orifice, and is the hole diameter. Effect of molecular weight At constant pressure and temperature, the root-mean-square speed and therefore the effusion rate are inversely proportional to the square root of the molecular weight. Gases with a lower molecular weight effuse more rapidly than gases with a higher molecular weight, so that the number of lighter molecules passing through the hole per unit time is greater. Graham's law Scottish chemist Thomas Graham (1805–1869) found experimentally that the rate of effusion of a gas is inversely proportional to the square root of the mass of its particles. In other words, the ratio of the rates of effusion of two gases at the same temperature and pressure is given by the inverse ratio of the square roots of the masses of the gas particles.",
                    "score": 0.8679158687591553
                },
                {
                    "id": 111480,
                    "contents": "Effusion\nEtymology The word effusion derives from the Latin word, effundo, which means \"shed, pour forth, pour out, utter, lavish, waste.\" Effusion into vacuum Effusion from an equilibrated container into outside vacuum can be calculated based on kinetic theory. If a small area on the container is punched to become a small hole, the effusive flow rate will be where is the molar mass, is the Avogadro constant, and is the gas constant. The average velocity of effused particles is Combined with the effusive flow rate, the recoil/thrust force on the system itself is An example is the recoil force on a balloon with a small hole flying in vacuum. Measures of flow rate According to the kinetic theory of gases, the kinetic energy for a gas at a temperature is",
                    "score": 0.8423225283622742
                },
                {
                    "id": 880887,
                    "contents": "Graham's law\nGraham's law of effusion (also called Graham's law of diffusion) was formulated by Scottish physical chemist Thomas Graham in 1848. Graham found experimentally that the rate of effusion of a gas is inversely proportional to the square root of the molar mass of its particles. This formula can be written as: , where: Rate1 is the rate of effusion for the first gas. (volume or number of moles per unit time). Rate2 is the rate of effusion for the second gas. M1 is the molar mass of gas 1 M2 is the molar mass of gas 2.",
                    "score": 0.8334712982177734
                },
                {
                    "id": 1477631,
                    "contents": "List of experiments\nThomas Graham measures the rates of effusion for different gases and establishes Graham's law of effusion and diffusion (1833). Julius Robert von Mayer and James Prescott Joule measure the heat generated by mechanical work. This establishes the principle of conservation of energy and the kinetic theory of heat (1842–1843). Louis Pasteur separates a racemic mixture of two enantiomers by sorting individual crystals, and demonstrates their impact on the polarization of light (1849). Anders Jonas Ångström observes the presence of hydrogen and other elements in the spectrum of the sun (1862). François-Marie Raoult demonstrates that the decrease in the vapor pressure and freezing point of liquids caused by the addition of solutes is proportional to the number of solute molecules present. This establishes the concept of colligative properties (1878). Svante Arrhenius studies the conductivity of salt solutions and determines that salts dissociate into ions in water (1884).",
                    "score": 0.8193051815032959
                },
                {
                    "id": 892657,
                    "contents": "Vapor pressure\nVery low vapor pressures of solids can be measured using the Knudsen effusion cell method. In a medical context, vapor pressure is sometimes expressed in other units, specifically millimeters of mercury (mmHg). This is important for volatile anesthetics, most of which are liquids at body temperature, but with a relatively high vapor pressure. Estimating vapor pressures with Antoine equation The Antoine equation is a pragmatic mathematical expression of the relation between the vapor pressure and the temperature of pure liquid or solid substances. It is obtained by curve-fitting and is adapted to the fact that vapor pressure is usually increasing and concave as a function of temperature. The basic form of the equation is: and it can be transformed into this temperature-explicit form: where: is the absolute vapor pressure of a substance is the temperature of the substance , and are substance-specific coefficients (i.e., constants or parameters) is typically either or",
                    "score": 0.8173542022705078
                },
                {
                    "id": 8325137,
                    "contents": "MAUD Committee\nThis is based on Graham's law, which states that the rate of effusion of a gas through a porous barrier is inversely proportional to the square root of the gas's molecular mass. In a container with a porous barrier containing a mixture of two gases, the lighter molecules will pass out of the container more rapidly than the heavier molecules. The gas leaving the container is slightly enriched in the lighter molecules, while the residual gas is slightly depleted. Simon's team conducted experiments with copper gauze as the barrier. Because uranium hexafluoride, the only known gas containing uranium, was both scarce and difficult to handle, a mixture of carbon dioxide and water vapour was used to test it.",
                    "score": 0.8115379810333252
                },
                {
                    "id": 4431768,
                    "contents": "Gaseous diffusion\nTechnology Scientific basis Gaseous diffusion is based on Graham's law, which states that the rate of effusion of a gas is inversely proportional to the square root of its molecular mass. For example, in a box with a semi-permeable membrane containing a mixture of two gases, the lighter molecules will pass out of the container more rapidly than the heavier molecules. The gas leaving the container is somewhat enriched in the lighter molecules, while the residual gas is somewhat depleted. A single container wherein the enrichment process takes place through gaseous diffusion is called a diffuser.",
                    "score": 0.8077517747879028
                },
                {
                    "id": 2795339,
                    "contents": "Extracellular fluid\nFunction The extracellular fluid provides the medium for the exchange of substances between the ECF and the cells, and this can take place through dissolving, mixing and transporting in the fluid medium. Substances in the ECF include dissolved gases, nutrients, and electrolytes, all needed to maintain life. The ECF also contains materials secreted from cells in soluble form, but which quickly coalesces into fibres (e.g. collagen, reticular, and elastic fibres) or precipitates out into a solid or semisolid form (e.g. proteoglycans which form the bulk of cartilage, and the components of bone). These and many other substances occur, especially in association with various proteoglycans to form the extracellular matrix or the \"filler\" substance between the cells throughout the body. These substances occur in the extracellular space, and are therefore all bathed or soaked in ECF, without being part of the ECF.",
                    "score": 0.8061219453811646
                },
                {
                    "id": 2240412,
                    "contents": "Electro-osmosis\nElectro-osmotic flow is actuated in a FlowFET to electronically control fluid flow through a junction. It is projected that micro fluidic devices utilizing electroosmotic flow will have applications in medical research. Once controlling this flow is better understood and implemented, the ability to separate fluids on the atomic level will be a vital component for drug dischargers. Mixing fluids at the micro scale is currently troublesome. It is believed that electrically controlling fluids will be the method in which small fluids are mixed. A controversial use of electro-osmotic systems is the control rising damp in the walls of buildings. While there is little evidence to suggest that these systems can be useful in moving salts in walls, such systems are claimed to be especially effective in structures with very thick walls. However some claim that there is no scientific base for those systems, and cite several examples for their failure.",
                    "score": 0.8059597015380859
                },
                {
                    "id": 2795355,
                    "contents": "Extracellular fluid\nExtracellular fluid may be mechanically guided in this circulation by the vesicles between other structures. Collectively this forms the interstitium, which may be considered a newly identified biological structure in the body. However, there is some debate over whether the interstitium is an organ. Electrolytic constituents Main cations: Sodium (Na+) 136–146 mM Potassium (K+) 3.8–5.0 mM Calcium (Ca2+) 1.0–1.4 mM Main anions: Chloride (Cl−) 103–112 mM Bicarbonate (HCO3−) 22–28 mM Phosphate (HPO42−) 0.8-1.4 mM See also Effective circulating volume (ECV) Fluid compartments References External links Britannica.com Biology-online.org Body fluids Cell biology",
                    "score": 0.802453339099884
                },
                {
                    "id": 2275054,
                    "contents": "Pleural effusion\nA pleural effusion is accumulation of excessive fluid in the pleural space, the potential space that surrounds each lung. Under normal conditions, pleural fluid is secreted by the parietal pleural capillaries at a rate of 0.01 millilitre per kilogram weight per hour, and is cleared by lymphatic absorption leaving behind only 5–15 millilitres of fluid, which helps to maintain a functional vacuum between the parietal and visceral pleurae. Excess fluid within the pleural space can impair inspiration by upsetting the functional vacuum and hydrostatically increasing the resistance against lung expansion, resulting in a fully or partially collapsed lung.",
                    "score": 0.80005943775177
                },
                {
                    "id": 11530225,
                    "contents": "Knudsen cell\nIn crystal growth, a Knudsen cell is an effusion evaporator source for relatively low partial pressure elementary sources (e.g. Ga, Al, Hg, As). Because it is easy to control the temperature of the evaporating material in Knudsen cells, they are commonly used in molecular-beam epitaxy. Development The Knudsen effusion cell was developed by Martin Knudsen (1871-1949). A typical Knudsen cell contains a crucible (made of pyrolytic boron nitride, quartz, tungsten or graphite), heating filaments (often made of metal tantalum), water cooling system, heat shields, and an orifice shutter.",
                    "score": 0.7998443841934204
                },
                {
                    "id": 6214,
                    "contents": "Fluid bearing\nthat he had been working on the concept for many years. As stated by Sydney Walker, a long-time employee of Michell's, the granting of Kingsbury's patent was \"a blow which Michell found hard to accept\".",
                    "score": 0.7995946407318115
                },
                {
                    "id": 6630757,
                    "contents": "Acentric factor\nThe definition of gives essentially zero for the noble gases argon, krypton, and xenon. is very close to zero for other spherical molecules. Values of correspond to vapor pressures above the critical pressure, and are non-physical. By definition, a van der Waals fluid has a critical compressibility of 3/8 and an acentric factor of about −0.302024, indicating a small ultra-spherical molecule. A Redlich-Kwong fluid has a critical compressibility of 1/3 and an acentric factor of about 0.058280, close to nitrogen; without the temperature dependence of its attractive term, its acentric factor would be only -0.293572. Values of some common gases See also Equation of state Reduced pressure Reduced temperature References Gas laws",
                    "score": 0.7991406917572021
                },
                {
                    "id": 14362711,
                    "contents": "Glossary of fuel cell terms\nElectrode An electrode is an electrical conductor used to make contact with a nonmetallic part of a circuit (e.g. a semiconductor, an electrolyte or a vacuum). Electro-galvanic fuel cell Electro-galvanic fuel cell (EGFC)an electrical device used to measure the concentration of oxygen gas in scuba diving and medical equipment. Electroosmotic flow Electroosmotic flow (or Electro-osmotic flow, often abbreviated EOF) is the motion of liquid induced by an applied potential across a capillary tube or microchannel. Electroosmotic flow is an essential component in chemical separation techniques, notably capillary electrophoresis. Electroosmotic pump An electroosmotic pump (EOP), or EO pump, is used for removing liquid flooding water from channels and gas diffusion layers and direct hydration of the proton exchange membrane in the membrane electrode assembly (MEA) of the proton exchange membrane fuel cell",
                    "score": 0.7963907122612
                },
                {
                    "id": 2275071,
                    "contents": "Pleural effusion\nTransudative pleural effusions are defined as effusions that are caused by systemic factors that alter the pleural equilibrium, or Starling forces. The components of the Starling forces – hydrostatic pressure, permeability, and oncotic pressure (effective pressure due to the composition of the pleural fluid and blood) – are altered in many diseases, e.g., left ventricular failure, kidney failure, liver failure, and cirrhosis. Exudative pleural effusions, by contrast, are caused by alterations in local factors that influence the formation and absorption of pleural fluid (e.g., bacterial pneumonia, cancer, pulmonary embolism, and viral infection). An accurate diagnosis of the cause of the effusion, transudate versus exudate, relies on a comparison of the chemistries in the pleural fluid to those in the blood, using Light's criteria. According to Light's criteria (Light, et al. 1972), a pleural effusion is likely exudative if at least one of the following exists:",
                    "score": 0.7959182262420654
                },
                {
                    "id": 5108144,
                    "contents": "Electrorheological fluid\nforming chains aligned with an electric field in an analogous way to how magnetorheological fluid (MR) fluids work. An ER fluid has been constructed with the solid phase made from a conductor coated in an insulator. This ER fluid clearly cannot work by the water bridge model. However, although demonstrating that some ER fluids work by the electrostatic effect, it does not prove that all ER fluids do so. The advantage of having an ER fluid which operates on the electrostatic effect is the elimination of leakage current, i.e. potentially there is no direct current. Of course, since ER devices behave electrically as capacitors, and the main advantage of the ER effect is the speed of response, an alternating current is to be expected.",
                    "score": 0.795650839805603
                },
                {
                    "id": 5074034,
                    "contents": "K-25\nGaseous diffusion is based on Graham's law, which states that the rate of effusion of a gas through a porous barrier is inversely proportional to the square root of the gas's molecular mass. In a container with a porous barrier containing a mixture of two gases, the lighter molecules will pass out of the container more rapidly than the heavier molecules. The gas leaving the container is slightly enriched in the lighter molecules, while the residual gas is slightly depleted. A container wherein the enrichment process takes place through gaseous diffusion is called a diffuser.",
                    "score": 0.7955746650695801
                },
                {
                    "id": 13039721,
                    "contents": "Effusion (disambiguation)\nEffusion is the process of gases passing through a small hole. Effusion may also refer to: Medicine The seeping of fluid into a body cavity, the fluid itself, or an abnormal collection of fluid in a body cavity or space: Ascites Pericardial effusion Pleural effusion Joint effusion Subdural Effusion Mastoid Effusion Knee effusion Sometimes called \"hydrops\" Geology Effusive eruption, an effusion of lava from a volcano",
                    "score": 0.7954080104827881
                },
                {
                    "id": 5108150,
                    "contents": "Electrorheological fluid\nProblems and advantages A major problem is that ER fluids are suspensions, hence in time they tend to settle out, so advanced ER fluids tackle this problem by means such as matching the densities of the solid and liquid components, or by using nanoparticles, which brings ER fluids into line with the development of magnetorheological fluids. Another problem is that the breakdown voltage of air is ~ 3 kV/mm, which is near the electric field needed for ER devices to operate. An advantage is that an ER device can control considerably more mechanical power than the electrical power used to control the effect, i.e. it can act as a power amplifier. But the main advantage is the speed of response. There are few other effects able to control such large amounts of mechanical or hydraulic power so rapidly.",
                    "score": 0.7951892614364624
                },
                {
                    "id": 2795338,
                    "contents": "Extracellular fluid\nThe ionic composition of the interstitial fluid and blood plasma vary due to the Gibbs–Donnan effect. This causes a slight difference in the concentration of cations and anions between the two fluid compartments. Transcellular fluid Transcellular fluid is formed from the transport activities of cells, and is the smallest component of extracellular fluid. These fluids are contained within epithelial lined spaces. Examples of this fluid are cerebrospinal fluid, aqueous humor in the eye, serous fluid in the serous membranes lining body cavities, perilymph and endolymph in the inner ear, and joint fluid. Due to the varying locations of transcellular fluid, the composition changes dramatically. Some of the electrolytes present in the transcellular fluid are sodium ions, chloride ions, and bicarbonate ions. Function",
                    "score": 0.7948705554008484
                },
                {
                    "id": 880888,
                    "contents": "Graham's law\nM1 is the molar mass of gas 1 M2 is the molar mass of gas 2. Graham's law states that the rate of diffusion or of effusion of a gas is inversely proportional to the square root of its molecular weight. Thus, if the molecular weight of one gas is four times that of another, it would diffuse through a porous plug or escape through a small pinhole in a vessel at half the rate of the other (heavier gases diffuse more slowly). A complete theoretical explanation of Graham's law was provided years later by the kinetic theory of gases. Graham's law provides a basis for separating isotopes by diffusion—a method that came to play a crucial role in the development of the atomic bomb. Graham's law is most accurate for molecular effusion which involves the movement of one gas at a time through a hole. It is only approximate for diffusion of one gas in another or in air, as these processes involve the movement of more than one gas.",
                    "score": 0.7939816117286682
                },
                {
                    "id": 4393994,
                    "contents": "Joule–Thomson effect\nIn thermodynamics, the Joule–Thomson effect (also known as the Joule–Kelvin effect or Kelvin–Joule effect) describes the temperature change of a real gas or liquid (as differentiated from an ideal gas) when it is forced through a valve or porous plug while keeping it insulated so that no heat is exchanged with the environment. This procedure is called a throttling process or Joule–Thomson process. At room temperature, all gases except hydrogen, helium, and neon cool upon expansion by the Joule–Thomson process when being throttled through an orifice; these three gases experience the same effect but only at lower temperatures. Most liquids such as hydraulic oils will be warmed by the Joule–Thomson throttling process.",
                    "score": 0.7938993573188782
                },
                {
                    "id": 8063624,
                    "contents": "Pericardial effusion\nPathophysiology How much fluid is stored in the pericardial sac at one particular time is based on the balance between production and reabsorption. Studies have shown that much of the fluid that accumulates in the pericardial sac is from plasma filtration of the epicardial capillaries and a small amount from the myocardium, while the fluid that is drained is mostly via the parietal lymphatic capillaries. Pericardial effusion usually results from a disturbed equilibrium between these two processes or from a structural abnormality that allows excess fluid to enter the pericardial cavity. Because of the limited amount of anatomic space in the pericardial cavity and the limited elasticity of the pericardium, fluid accumulation beyond the normal amount leads to an increased intrapericardial pressure which can negatively affect heart function.",
                    "score": 0.7926278710365295
                },
                {
                    "id": 5108145,
                    "contents": "Electrorheological fluid\nThe particles are electrically active. They can be ferroelectric or, as mentioned above, made from a conducting material coated with an insulator, or electro-osmotically active particles. In the case of ferroelectric or conducting material, the particles would have a high dielectric constant. There may be some confusion here as to the dielectric constant of a conductor, but \"if a material with a high dielectric constant is placed in an electric field, the magnitude of that field will be measurably reduced within the volume of the dielectric\" (see main page: Dielectric constant), and since the electric field is zero in an ideal conductor, then in this context the dielectric constant of a conductor is infinite.",
                    "score": 0.7917330265045166
                },
                {
                    "id": 5108140,
                    "contents": "Electrorheological fluid\nElectrorheological (ER) fluids are suspensions of extremely fine non-conducting but electrically active particles (up to 50 micrometres diameter) in an electrically insulating fluid. The apparent viscosity of these fluids changes reversibly by an order of up to 100,000 in response to an electric field. For example, a typical ER fluid can go from the consistency of a liquid to that of a gel, and back, with response times on the order of milliseconds. The effect is sometimes called the Winslow effect after its discoverer, the American inventor Willis Winslow, who obtained a US patent on the effect in 1947 and wrote an article published in 1949.",
                    "score": 0.7907856702804565
                },
                {
                    "id": 1753399,
                    "contents": "Helium\nIn the fountain effect, a chamber is constructed which is connected to a reservoir of helium II by a sintered disc through which superfluid helium leaks easily but through which non-superfluid helium cannot pass. If the interior of the container is heated, the superfluid helium changes to non-superfluid helium. In order to maintain the equilibrium fraction of superfluid helium, superfluid helium leaks through and increases the pressure, causing liquid to fountain out of the container.",
                    "score": 0.7906630635261536
                },
                {
                    "id": 28274011,
                    "contents": "Sampson flow\nHere, is the molecular flux in atoms/m2·sec, is the average of the pressures on either side of the orifice, is the Boltzmann constant, ( J/K), and is the absolute temperature in K. Sampson flow is the macroscopic analog of effusion flow, which describes stochastic diffusion of molecules through an orifice much smaller than the mean-free-path of the gas molecules. For pore diameters on the order of the mean-free-path of the fluid, flow will occur with contributions from the molecular regime as well as the viscous regime, obeying the dusty gas model according to the following equation: Here, is the total volumetric flowrate and is the volumetric flowrate according to the law of effusion. As it turns out, for many gasses, we notice equal contributions from molecular and viscous regimes when the pore size is significantly larger than the mean-free-path of the fluid, for nitrogen this occurs at a pore diameter of 393 nm, 6.0× larger than the mean-free-path. References",
                    "score": 0.7904486060142517
                },
                {
                    "id": 892656,
                    "contents": "Vapor pressure\nExperimental measurement of vapor pressure is a simple procedure for common pressures between 1 and 200 kPa. Most accurate results are obtained near the boiling point of substances and large errors result for measurements smaller than . Procedures often consist of purifying the test substance, isolating it in a container, evacuating any foreign gas, then measuring the equilibrium pressure of the gaseous phase of the substance in the container at different temperatures. Better accuracy is achieved when care is taken to ensure that the entire substance and its vapor are at the prescribed temperature. This is often done, as with the use of an isoteniscope, by submerging the containment area in a liquid bath. Very low vapor pressures of solids can be measured using the Knudsen effusion cell method.",
                    "score": 0.7902089953422546
                },
                {
                    "id": 13620217,
                    "contents": "Electroosmotic pump\nAn electroosmotic pump (EOP), or EO pump, is used for generating flow or pressure by use of an electric field. One application of this is removing liquid flooding water from channels and gas diffusion layers and direct hydration of the proton exchange membrane in the membrane electrode assembly (MEA) of the proton exchange membrane fuel cells. Principle Electroosmotic pumps are fabricated from silica nanospheres or hydrophilic porous glass, the pumping mechanism is generated by an external electric field applied on an electric double layer (EDL), generates high pressures (e.g., more than 340 atm (34 MPa) at 12 kV applied potentials) and high flow rates (e.g., 40 ml/min at 100 V in a pumping structure less than 1 cm³ in volume). EO pumps are compact, have no moving parts, and scale favorably with fuel cell design. The EO pump might drop the parasitic load of water management in fuel cells from 20% to 0.5% of the fuel cell power. Types",
                    "score": 0.7891818284988403
                },
                {
                    "id": 14362755,
                    "contents": "Glossary of fuel cell terms\nPressure sensor A pressure sensor measures the pressure, typically of gases or liquids. Pressure swing adsorption Pressure Swing Adsorption (PSA) is a technology used to separate some gas species from a mixture of gases under pressure according to the species' molecular characteristics and affinity for an adsorbent material. Pressure vessel A pressure vessel is a closed container designed to hold gases or liquids at a pressure different from the ambient pressure. Propane Propane is a three-carbon alkane, normally a gas, but compressible to a liquid that is transportable. See also LPG. Proton The proton is a subatomic particle with an electric charge of one positive fundamental unit Proton exchange membrane Proton exchange membrane (PEM) is a semipermeable membrane generally made from ionomers and designed to conduct protons while being impermeable to gases such as oxygen or hydrogen.",
                    "score": 0.7889778017997742
                },
                {
                    "id": 3817482,
                    "contents": "Bottled gas\nNote: cryogenic gases are typically equipped with some type of 'bleed' device to prevent overpressure from rupturing the bottle and to allow evaporative cooling to continue. Expansion and volume The general rule is that one unit volume of liquid will expand to approximately 800 unit volumes of gas at Standard temperature and pressure with some variation due to intermolecular force and molecule size compared to an ideal gas. Normal high pressure gas cylinders will hold gas at pressures from . An ideal gas pressurised to 200 bar in a cylinder would contain 200 times as much as the volume of the cylinder at atmospheric pressure, but real gases will contain less than that by a few percent. At higher pressures, the shortfall is greater.",
                    "score": 0.7886427640914917
                },
                {
                    "id": 111481,
                    "contents": "Effusion\nAn example is the recoil force on a balloon with a small hole flying in vacuum. Measures of flow rate According to the kinetic theory of gases, the kinetic energy for a gas at a temperature is where is the mass of one molecule, is the root-mean-square speed of the molecules, and is the Boltzmann constant. The average molecular speed can be calculated from the Maxwell speed distribution as (or, equivalently, ). The rate at which a gas of molar mass effuses (typically expressed as the number of molecules passing through the hole per second) is then Here is the gas pressure difference across the barrier, is the area of the hole, is the Avogadro constant, is the gas constant and is the absolute temperature. Assuming the pressure difference between the two sides of the barrier is much smaller than , the average absolute pressure in the system (i.e. ), it is possible to express effusion flow as a volumetric flow rate as follows: or",
                    "score": 0.7883778810501099
                },
                {
                    "id": 11455485,
                    "contents": "Heat capacity rate\nIf the hot fluid had a much larger heat capacity rate, then when hot and cold fluids went through a heat exchanger, the hot fluid would have a very small change in temperature while the cold fluid would heat up a significant amount. If the cool fluid has a much lower heat capacity rate, that is desirable. If they were equal, they would both change more or less temperature equally, assuming equal mass-flow per unit time through a heat exchanger. In practice, a cooling fluid which has both a higher specific heat capacity and a lower heat capacity rate is desirable, accounting for the pervasiveness of water cooling solutions in technology—the polar nature of the water molecule creates some distinct sub-atomic behaviors favorable in practice. where C = heat capacity rate of the fluid of interest, dm/dt = mass flow rate of the fluid of interest and cp = specific heat of the fluid of interest. See also",
                    "score": 0.7880042791366577
                },
                {
                    "id": 6714889,
                    "contents": "Logarithmic mean temperature difference\nThis holds both for cocurrent flow, where the streams enter from the same end, and for countercurrent flow, where they enter from different ends. In a cross-flow, in which one system, usually the heat sink, has the same nominal temperature at all points on the heat transfer surface, a similar relation between exchanged heat and LMTD holds, but with a correction factor. A correction factor is also required for other more complex geometries, such as a shell and tube exchanger with baffles. Derivation Assume heat transfer is occurring in a heat exchanger along an axis z, from generic coordinate A to B, between two fluids, identified as 1 and 2, whose temperatures along z are T1(z) and T2(z). The local exchanged heat flux at z is proportional to the temperature difference: where D is the distance between the two fluids. The heat that leaves the fluids causes a temperature gradient according to Fourier's law:",
                    "score": 0.7876876592636108
                },
                {
                    "id": 445105,
                    "contents": "Lithium-ion battery\nThese capsules began as an aqueous dispersion of GO and Si particles and are then nebulized into a mist of droplets that pass through a tube furnace. As they pass through the liquid evaporates, the GO sheets are pulled into a crumpled ball by capillary forces and encapsulate Si particles with them. There is a galvanostatic charge/discharge profile of 0.05 \\scriptstyle mA/cm^2 to 1 \\scriptstyle mA/cm^2 for current densities 0.2 to 4 A/g, delivering 1200 mAh/g at 0.2 A/g. Electrolyte Electrolyte alternatives have also played a significant role, for example the lithium polymer battery. Polymer electrolytes are promising for minimizing the dendrite formation of lithium. Polymers are supposed to prevent short circuits and maintain conductivity. The ions in the electrolyte diffuse because there are small changes in the electrolyte concentration. Linear diffusion is only considered here. The change in concentration c, as a function of time t and distance x, is",
                    "score": 0.7875208854675293
                },
                {
                    "id": 17780810,
                    "contents": "Gas\nThrough these experiments, Boyle noted that the pressure exerted by a gas held at a constant temperature varies inversely with the volume of the gas. For example, if the volume is halved, the pressure is doubled; and if the volume is doubled, the pressure is halved. Given the inverse relationship between pressure and volume, the product of pressure (P) and volume (V) is a constant (k) for a given mass of confined gas as long as the temperature is constant. Stated as a formula, thus is: Because the before and after volumes and pressures of the fixed amount of gas, where the before and after temperatures are the same both equal the constant k, they can be related by the equation: Charles's law",
                    "score": 0.7870863080024719
                },
                {
                    "id": 2795332,
                    "contents": "Extracellular fluid\nIn cell biology, extracellular fluid (ECF) denotes all body fluid outside the cells of any multicellular organism. Total body water in healthy adults is about 60% (range 45 to 75%) of total body weight; women and the obese typically have a lower percentage than lean men. Extracellular fluid makes up about one-third of body fluid, the remaining two-thirds is intracellular fluid within cells. The main component of the extracellular fluid is the interstitial fluid that surrounds cells.",
                    "score": 0.7864631414413452
                },
                {
                    "id": 14362702,
                    "contents": "Glossary of fuel cell terms\nCondensate Condensate, the liquid phase produced by the condensation of steam or any other gas Condensation Condensation is the change of the physical state of aggregation (or simply state) of matter from gaseous phase into liquid phase. Condenser In systems involving heat transfer, a condenser is a heat exchanger which condenses a substance from its gaseous to its liquid state. Contamination Contamination is the introduction of material that \"does not belong there\". Coulomb The coulomb (symbol: C) is the SI unit of electric charge. Countercurrent exchange Countercurrent exchange is a mechanism used to transfer some property of a fluid from one flowing current of fluid to another across a semipermeable membrane, conductive material, or free surface (e.g. a liquid–gas absorption or extraction).",
                    "score": 0.7863789200782776
                },
                {
                    "id": 983571,
                    "contents": "Electrolyte\nElectrically, such a solution is neutral. If an electric potential is applied to such a solution, the cations of the solution are drawn to the electrode that has an abundance of electrons, while the anions are drawn to the electrode that has a deficit of electrons. The movement of anions and cations in opposite directions within the solution amounts to a current. Some gases, such as hydrogen chloride (HCl), under conditions of high temperature or low pressure can also function as electrolytes. Electrolyte solutions can also result from the dissolution of some biological (e.g., DNA, polypeptides) and synthetic polymers (e.g., polystyrene sulfonate), termed \"polyelectrolytes\", which contain charged functional groups. A substance that dissociates into ions in solution acquires the capacity to conduct electricity. Sodium, potassium, chloride, calcium, magnesium, and phosphate are examples of electrolytes.",
                    "score": 0.7854320406913757
                },
                {
                    "id": 1477630,
                    "contents": "List of experiments\nBenjamin Thompson, Count Rumford demonstrates that the heat developed by the friction of boring cannon is nearly inexhaustible. This result was presented in opposition to caloric theory (1798). Humphry Davy uses electrolysis to isolate elemental potassium, sodium, calcium, strontium, barium, magnesium, and chlorine (1807–1810). Joseph Louis Gay-Lussac studies reactions among gases and determines that their volumes combine chemically in simple integer ratios (1809). Robert Brown studies very small particles in water under the microscope and observes Brownian motion which was later named in his honor (1827). Friedrich Wöhler synthesizes the organic compound urea using inorganic reactants, disproving the application of vitalism to chemical processes (1828). Thomas Graham measures the rates of effusion for different gases and establishes Graham's law of effusion and diffusion (1833).",
                    "score": 0.7850087881088257
                },
                {
                    "id": 14055452,
                    "contents": "Volume contraction\n5. The volume of lost fluid from each compartment: where: VI/ECF b = Intra/Extra-cellular fluid volume before fluid loss VI/ECF a = Intra/Extra-cellular fluid volume after fluid loss See also Contraction alkalosis, the increase in blood pH that occurs as a result of fluid losses References Physiology",
                    "score": 0.7850087285041809
                },
                {
                    "id": 14055449,
                    "contents": "Volume contraction\nICF volume contraction Volume contraction of intracellular fluid may occur after substantial fluid loss, since it is much larger than ECF volume, or loss of potassium (K+) see section below. ICF volume contraction may cause disturbances in various organs throughout the body. Dependence on lost solutes Na+ loss approximately correlates with fluid loss from ECF, since Na+ has a much higher concentration in ECF than ICF. In contrast, K+ has a much higher concentration in ICF than ECF, and therefore its loss rather correlates with fluid loss from ICF, since K+ loss from ECF causes the K+ in ICF to diffuse out of the cells, dragging water with it by osmosis. Estimation When the body loses fluids, the amount lost from ICF and ECF, respectively, can be estimated by measuring volume and amount of substance of sodium (Na+) and potassium (K+) in the lost fluid, as well as estimating the body composition of the person.",
                    "score": 0.7843917608261108
                },
                {
                    "id": 3063286,
                    "contents": "Working fluid\nWorking fluids other than air or water are necessarily recirculated in a loop. Some hydraulic and passive heat-transfer systems are open to the water supply and/or atmosphere, sometimes through breather filters. Heat engines, heat pumps, and systems using volatile liquids or special gases are usually sealed behind relief valves. Properties and states The working fluid's properties are essential for the full description of thermodynamic systems. Although working fluids have many physical properties which can be defined, the thermodynamic properties which are often required in engineering design and analysis are few. Pressure, temperature, enthalpy, entropy, specific volume, and internal energy are the most common. If at least two thermodynamic properties are known, the state of the working fluid can be defined. This is usually done on a property diagram which is simply a plot of one property versus another.",
                    "score": 0.7836897373199463
                },
                {
                    "id": 982377,
                    "contents": "Thomas Graham (chemist)\nPublications On the Law of Diffusion of Gases (1833) Scientific works Thomas Graham is known for his studies on the behaviour of gases, which resulted in his formulation of two relationships, both since becoming known as \"Graham's Laws,\" the first regarding gas diffusion, and the second regarding gas effusion. In the former case, Graham deduced that when measured repeatedly under the same conditions of pressure and temperature, the rate of diffusive mixing of a gas is inversely proportional to the square root of its density, and given the relationship between density and molar mass, also inversely proportional to the square root of its molar mass. In the same way, in the latter case, regarding effusion of a gas through a pin hole in to a vacuum, Graham deduced that the rate of effusion of a gas is inversely proportional to the square root of its molar mass. These two are sometimes referred to as a combined law (describing both phenomena).",
                    "score": 0.7828649878501892
                },
                {
                    "id": 7313692,
                    "contents": "Hydropneumatic device\nVariations a. Having a separator membrane into the interior of which the liquid is communicated. Used for corrosive liquids, so that the chamber metal can be of low cost. b. Having a metal bellows separator membrane for use at low and higher temperatures than are compatible with an elastomeric or plastomeric membrane. c. Having a float separator to reduce the rate of gas absorption at the liquid interface, typically used in vessel chambers larger than 500 gallons. Hydropneumatic pump controllers Purpose a. Means of control for multiple fixed delivery volume, low cost low complexity pumps; to provide variable flow as required by small (say +or - 10 psi) pressure increase or decrease of a system. b. Means of control for pump unloading / recirculation against no pressure, without electric pressure switches.",
                    "score": 0.7827776670455933
                },
                {
                    "id": 2795336,
                    "contents": "Extracellular fluid\nInterstitial fluid The interstitial fluid is essentially comparable to plasma. The interstitial fluid and plasma make up about 97% of the ECF, and a small percentage of this is lymph. Interstitial fluid is the body fluid between blood vessels and cells, containing nutrients from capillaries by diffusion and holding waste products discharged out by cells due to metabolism. 11 litres of the ECF is interstitial fluid and the remaining three litres is plasma. Plasma and interstitial fluid are very similar because water, ions, and small solutes are continuously exchanged between them across the walls of capillaries, through pores and capillary clefts.",
                    "score": 0.7827218770980835
                },
                {
                    "id": 3063283,
                    "contents": "Working fluid\nFor fluid power, a working fluid is a gas or liquid that primarily transfers force, motion, or mechanical energy. In hydraulics, water or hydraulic fluid transfers force between hydraulic components such as hydraulic pumps, hydraulic cylinders, and hydraulic motors that are assembled into hydraulic machinery, hydraulic drive systems, etc. In pneumatics, the working fluid is air or another gas which transfers force between pneumatic components such as compressors, vacuum pumps, pneumatic cylinders, and pneumatic motors. In pneumatic systems, the working gas also stores energy because it is compressible. (Gases also heat up as they are compressed and cool as they expand; this incidental heat pump is rarely exploited.) (Some gases also condense into liquids as they are compressed and boil as pressure is reduced.)",
                    "score": 0.7825020551681519
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_30",
        "question": "The speed of a certain proton is $6.1 \\times 10^6 \\mathrm{~m} \\mathrm{~s}^{-1}$. If the uncertainty in its momentum is to be reduced to 0.0100 per cent, what uncertainty in its location must be tolerated?",
        "golden_answers": [
            " 52"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 4041639,
                    "contents": "Oh-My-God particle\nAssuming it was a proton, this particle traveled at of the speed of light, its Lorentz factor was and its rapidity was . At this speed, if a photon were travelling with the particle, it would take over 215,000 years for the photon to gain a 1 cm lead as seen from the Earth's reference frame. Due to special relativity, the relativistic time dilation experienced by a proton traveling at this speed would be extreme. If the proton originated from a distance of 1.5 billion light years, it would take approximately 1.71 days from the reference frame of the proton to travel that distance.",
                    "score": 0.8829256892204285
                },
                {
                    "id": 1164041,
                    "contents": "Proton\nIf no errors were found in the measurements or calculations, it would have been necessary to re-examine the world's most precise and best-tested fundamental theory: quantum electrodynamics. The proton radius was a puzzle as of 2017. A resolution came in 2019, when two different studies, using different techniques involving the Lamb shift of the electron in hydrogen, and electron–proton scattering, found the radius of the proton to be 0.833 fm, with an uncertainty of ±0.010 fm, and 0.831 fm. The radius of the proton is linked to the form factor and momentum-transfer cross section. The atomic form factor G modifies the cross section corresponding to point-like proton. The atomic form factor is related to the wave function density of the target: The form factor can be split in electric and magnetic form factors. These can be further written as linear combinations of Dirac and Pauli form factors.",
                    "score": 0.8784003257751465
                },
                {
                    "id": 358879,
                    "contents": "Lenz's law\ndo not, such as a proton and an electron, the interaction is different. An electron generating a magnetic field would generate an EMF that causes a proton to accelerate in the same direction as the electron. At first, this might seem to violate the law of conservation of momentum, but such an interaction is seen to conserve momentum if the momentum of electromagnetic fields is taken into account.",
                    "score": 0.8781905770301819
                },
                {
                    "id": 1019486,
                    "contents": "Dimensionless quantity\nβ (or μ) ≈ 1836, the proton-to-electron mass ratio. This ratio is the rest mass of the proton divided by that of the electron. An analogous ratio can be defined for any elementary particle; αs ≈ 1, a constant characterizing the strong nuclear force coupling strength; The ratio of the mass of any given elementary particle to the Planck mass, .",
                    "score": 0.8751853704452515
                },
                {
                    "id": 2939968,
                    "contents": "1932 in science\nPhysics April 14 – John Cockcroft and Ernest Walton focus a proton beam on lithium and split its nucleus. May 10 – James Chadwick discovers the neutron. Werner Heisenberg explains its symmetries by introducing the concept of isospin. August 2 – The positron is observed by Carl Anderson. The Kennedy–Thorndike experiment shows that measured time as well as length are affected by motion, in accordance with the theory of special relativity. John von Neumann rigorously establishes a mathematical framework for quantum mechanics in Mathematische Grundlagen der Quantenmechanik. Zero-length springs are invented, revolutionizing seismometers and gravimeters. Awards Nobel Prizes Physics – Werner Karl Heisenberg Chemistry – Irving Langmuir Medicine – Sir Charles Sherrington, Edgar Adrian",
                    "score": 0.8734965324401855
                },
                {
                    "id": 7748028,
                    "contents": "Introduction to quantum mechanics\nHeisenberg gave, as an illustration, the measurement of the position and momentum of an electron using a photon of light. In measuring the electron's position, the higher the frequency of the photon, the more accurate is the measurement of the position of the impact of the photon with the electron, but the greater is the disturbance of the electron. This is because from the impact with the photon, the electron absorbs a random amount of energy, rendering the measurement obtained of its momentum increasingly uncertain (momentum is velocity multiplied by mass), for one is necessarily measuring its post-impact disturbed momentum from the collision products and not its original momentum (momentum which should be simultaneously measured with position). With a photon of lower frequency, the disturbance (and hence uncertainty) in the momentum is less, but so is the accuracy of the measurement of the position of the impact.",
                    "score": 0.8730233907699585
                },
                {
                    "id": 1723065,
                    "contents": "Elementary particle\nThe number of protons in the observable universe is called the Eddington number. In terms of number of particles, some estimates imply that nearly all the matter, excluding dark matter, occurs in neutrinos, which constitute the majority of the roughly elementary particles of matter that exist in the visible universe. Other estimates imply that roughly elementary particles exist in the visible universe (not including dark matter), mostly photons and other massless force carriers. Standard Model",
                    "score": 0.8725000619888306
                },
                {
                    "id": 17038121,
                    "contents": "Proton-to-electron mass ratio\nIn physics, the proton-to-electron mass ratio, μ or β, is simply the rest mass of the proton (a baryon found in atoms) divided by that of the electron (a lepton found in atoms). Because this is a ratio of like-dimensioned physical quantities, it is a dimensionless quantity, a function of the dimensionless physical constants, and has numerical value independent of the system of units, namely: μ = The number enclosed in parentheses is the measurement uncertainty on the last two digits. The value of μ is known to about 0.1 parts per billion. It was also noticed that μ ≈",
                    "score": 0.8721746206283569
                },
                {
                    "id": 1164020,
                    "contents": "Proton\nThe word proton is Greek for \"first\", and this name was given to the hydrogen nucleus by Ernest Rutherford in 1920. In previous years, Rutherford had discovered that the hydrogen nucleus (known to be the lightest nucleus) could be extracted from the nuclei of nitrogen by atomic collisions. Protons were therefore a candidate to be a fundamental or elementary particle, and hence a building block of nitrogen and all other heavier atomic nuclei.",
                    "score": 0.8705489039421082
                },
                {
                    "id": 18767722,
                    "contents": "Planck units\nIt is equal to where the two digits enclosed by parentheses are the estimated standard error associated with the reported numerical value, or about times the diameter of a proton. Planck time The Planck time is the time required for light to travel a distance of 1 Planck length in a vacuum, which is a time interval of approximately . All scientific experiments and human experiences occur over time scales that are many orders of magnitude longer than the Planck time, making any events happening at the Planck scale undetectable with current scientific technology. , the smallest time interval uncertainty in direct measurements was on the order of 247 zeptoseconds ().",
                    "score": 0.8690286874771118
                },
                {
                    "id": 15004370,
                    "contents": "Particle accelerators in popular culture\nThe Feynman Lectures on Physics The Feynman Lectures on Physics is a 1964 physics textbook by Richard Feynman, Robert B. Leighton and Matthew Sands, based upon the lectures given by Feynman to undergraduate students at the California Institute of Technology (Caltech) in 1961–63. It includes lectures on mathematics, electromagnetism, Newtonian physics, quantum physics, and even the relation of physics to other sciences. Six readily accessible chapters were later compiled into a book entitled Six Easy Pieces: Essentials of Physics Explained by Its Most Brilliant Teacher, and six more in Six Not So Easy Pieces: Einstein's Relativity, Symmetry and Space-Time. The first volume focuses on mechanics, radiation, and heat. The second volume is mainly on electromagnetism and matter. The third volume, on quantum mechanics, shows, for example, how the double-slit experiment contains the essential features of quantum mechanics.",
                    "score": 0.8686699867248535
                },
                {
                    "id": 16681019,
                    "contents": "Timeline of quantum mechanics\n1946 – Theodor V. Ionescu and Vasile Mihu report the construction of the first hydrogen maser by stimulated emission of radiation in molecular hydrogen. 1947 – Willis Lamb and Robert Retherford measure a small difference in energy between the energy levels 2S1/2 and 2P1/2 of the hydrogen atom, known as the Lamb shift. 1947 – George Rochester and Clifford Charles Butler publishes two cloud chamber photographs of cosmic ray-induced events, one showing what appears to be a neutral particle decaying into two charged pions, and one that appears to be a charged particle decaying into a charged pion and something neutral. The estimated mass of the new particles is very rough, about half a proton's mass. More examples of these \"V-particles\" were slow in coming, and they are soon given the name kaons.",
                    "score": 0.8684272766113281
                },
                {
                    "id": 1164039,
                    "contents": "Proton\nThe internationally accepted value of a proton's charge radius is (see orders of magnitude for comparison to other sizes). This value is based on measurements involving a proton and an electron (namely, electron scattering measurements and complex calculation involving scattering cross section based on Rosenbluth equation for momentum-transfer cross section), and studies of the atomic energy levels of hydrogen and deuterium.",
                    "score": 0.8657967448234558
                },
                {
                    "id": 19869111,
                    "contents": "Tests of relativistic energy and momentum\nAlso measurements of the charge-to-mass ratio and thus momentum of protons have been conducted. Grove and Fox (1953) measured 385-MeV protons moving at ∼0.7c. Determination of the angular frequencies and of the magnetic field provided the charge-to-mass ratio. This, together with measuring the magnetic center, allowed to confirm the relativistic expression for the charge-to-mass ratio with a precision of ∼0.0006. However, Zrelov et al. (1958) criticized the scant information given by Grove and Fox, emphasizing the difficulty of such measurements due to the complex motion of the protons. Therefore, they conducted a more extensive measurement, in which protons of 660 MeV with mean velocity of 0.8112c were employed. The proton's momentum was measured using a Litz wire, and the velocity was determined by evaluation of Cherenkov radiation. They confirmed relativity with an upper limit for deviations of ∼0.0041. Bertozzi experiment",
                    "score": 0.8643775582313538
                },
                {
                    "id": 2730788,
                    "contents": "Eddington number\nIn astrophysics, the Eddington number, , is the number of protons in the observable universe. Eddington originally calculated it as about ; current estimates make it approximately . The term is named for British astrophysicist Arthur Eddington, who in 1940 was the first to propose a value of and to explain why this number might be important for physical cosmology and the foundations of physics. History Eddington argued that the value of the fine-structure constant, α, could be obtained by pure deduction. He related α to the Eddington number, which was his estimate of the number of protons in the universe. This led him in 1929 to conjecture that α was exactly 1/136. He devised a \"proof\" that NEdd = 136 × 2256, or about 1.57×1079. Other physicists did not adopt this conjecture and did not accept his argument.",
                    "score": 0.8643178939819336
                },
                {
                    "id": 2521455,
                    "contents": "Macroscopic scale\nHigh energy physics compared to low energy physics Particle physics, dealing with the smallest physical systems, is also known as high energy physics. Physics of larger length scales, including the macroscopic scale, is also known as low energy physics. Intuitively, it might seem incorrect to associate \"high energy\" with the physics of very small, low mass-energy systems, like subatomic particles. By comparison, one gram of hydrogen, a macroscopic system, has ~ times the mass-energy of a single proton, a central object of study in high energy physics. Even an entire beam of protons circulated in the Large Hadron Collider, a high energy physics experiment, contains ~ protons, each with of energy, for a total beam energy of ~ or ~ 336.4 MJ, which is still ~ times lower than the mass-energy of a single gram of hydrogen. Yet, the macroscopic realm is \"low energy physics\", while that of quantum particles is \"high energy physics\".",
                    "score": 0.8636094927787781
                },
                {
                    "id": 1560662,
                    "contents": "Atom\nProtons have a positive charge and a mass 1,836 times that of the electron, at . The number of protons in an atom is called its atomic number. Ernest Rutherford (1919) observed that nitrogen under alpha-particle bombardment ejects what appeared to be hydrogen nuclei. By 1920 he had accepted that the hydrogen nucleus is a distinct particle within the atom and named it proton. Neutrons have no electrical charge and have a free mass of 1,839 times the mass of the electron, or . Neutrons are the heaviest of the three constituent particles, but their mass can be reduced by the nuclear binding energy. Neutrons and protons (collectively known as nucleons) have comparable dimensions—on the order of —although the 'surface' of these particles is not sharply defined. The neutron was discovered in 1932 by the English physicist James Chadwick.",
                    "score": 0.8635106086730957
                },
                {
                    "id": 24604486,
                    "contents": "Lawrence H. Johnston\nJohnston never regretted the part he had played in the bombings. Years later, Johnston recalled: After the war After the war, Johnston returned to graduate school at Berkeley. Under Alvarez's supervision, he wrote his PhD thesis at the Lawrence Berkeley Laboratory on the \"Development of the Alvarez-type proton linear accelerator\". After he graduated in 1950, he became an associate professor at the University of Minnesota. There, he built a 68 MeV proton linear accelerator, which he used to perform proton-proton scattering experiments. In 1964, he joined the Physics Laboratory of The Aerospace Corporation, where he learned techniques for investigating far infrared radiation.",
                    "score": 0.8634089231491089
                },
                {
                    "id": 2521458,
                    "contents": "Macroscopic scale\nFinally, when reaching the quantum particle level, the high energy domain is revealed. The proton has a mass-energy of ~ ; some other massive quantum particles, both elementary and hadronic, have yet higher mass-energies. Quantum particles with lower mass-energies are also part of high energy physics; they also have a mass-energy that is far higher than that at the macroscopic scale (such as electrons), or are equally involved in reactions at the particle level (such as neutrinos). Relativistic effects, as in particle accelerators and cosmic rays, can further increase the accelerated particles' energy by many orders of magnitude, as well as the total energy of the particles emanating from their collision and annihilation. See also High energy physics Microscopic scale Quantum realm References Concepts in physics Orders of magnitude",
                    "score": 0.8623791933059692
                },
                {
                    "id": 1135364,
                    "contents": "Neutrino\nThe first measurements of neutrino speed were made in the early 1980s using pulsed pion beams (produced by pulsed proton beams hitting a target). The pions decayed producing neutrinos, and the neutrino interactions observed within a time window in a detector at a distance were consistent with the speed of light. This measurement was repeated in 2007 using the MINOS detectors, which found the speed of neutrinos to be, at the 99% confidence level, in the range between and . The central value of is higher than the speed of light but, with uncertainty taken into account, is also consistent with a velocity of exactly or slightly less. This measurement set an upper bound on the mass of the muon neutrino at with 99% confidence. After the detectors for the project were upgraded in 2012, MINOS refined their initial result and found agreement with the speed of light, with the difference in the arrival time of neutrinos and light of −0.0006% (±0.0012%).",
                    "score": 0.8620010614395142
                },
                {
                    "id": 456200,
                    "contents": "Orders of magnitude (length)\n1 attometre To help compare different orders of magnitude, this section lists lengths between 10−18 m and 10−17 m (1 am and 10 am). 1 am – sensitivity of the LIGO detector for gravitational waves 1 am – upper limit for the size of quarks and electrons 10 attometres To help compare different orders of magnitude, this section lists lengths between 10−17 m and 10−16 m (10 am and 100 am). 10 am – range of the weak force 100 attometres To help compare different orders of magnitude, this section lists lengths between 10−16 m and 10−15 m (100 am and 1 fm). 100 am – all lengths shorter than this distance are not confirmed in terms of size 850 am – approximate proton radius",
                    "score": 0.8619234561920166
                },
                {
                    "id": 986659,
                    "contents": "Atomic, molecular, and optical physics\n. where E0 is the magnitude of the electric field amplitude, and E is the magnitude of the electric field at position x. From this basic, Planck's law was derived. In 1911, Ernest Rutherford concluded, based on alpha particle scattering, that an atom has a central pointlike proton. He also thought that an electron would be still attracted to the proton by Coulomb's law, which he had verified still held at small scales. As a result, he believed that electrons revolved around the proton. Niels Bohr, in 1913, combined the Rutherford model of the atom with the quantisation ideas of Planck. Only specific and well-defined orbits of the electron could exist, which also do not radiate light. In jumping orbit the electron would emit or absorb light corresponding to the difference in energy of the orbits. His prediction of the energy levels was then consistent with observation.",
                    "score": 0.8617340922355652
                },
                {
                    "id": 19063774,
                    "contents": "Measurements of neutrino speed\nTo exclude possible statistical errors, CERN produced bunched proton beams between October and November 2011. The proton extractions were split into short bunches of 3 ns at intervals of 524 ns, so that every neutrino event could be directly connected to a proton bunch. The measurement of twenty neutrino events again gave an early arrival of about 62 ns, in agreement with the previous result. They updated their analysis and increased the significance up to 6,2σ.",
                    "score": 0.8614318370819092
                },
                {
                    "id": 19063770,
                    "contents": "Measurements of neutrino speed\nSince the protons are transferred in bunches of one nanosecond duration at an interval of 18.73 ns, the speed of muons and neutrinos could be determined. A speed difference would lead to an elongation of the neutrino bunches and to a displacement of the whole neutrino time spectrum. At first, the speeds of muons and neutrinos were compared. Later, also antineutrinos were observed. The upper limit for deviations from light speed was: . This was in agreement with the speed of light within the measurement accuracy (95% confidence level), and also no energy dependence of neutrino speeds could be found at this accuracy. Supernova 1987A The most precise agreement with the speed of light () was determined in 1987 by the observation of electron antineutrinos of energies between 7.5 and 35 MeV originated at the Supernova 1987A at a distance of 157000 ± 16000 light years. The upper limit for deviations from light speed was: ,",
                    "score": 0.8613452911376953
                },
                {
                    "id": 1590090,
                    "contents": "Angular momentum\nQuantization In quantum mechanics, angular momentum is quantized – that is, it cannot vary continuously, but only in \"quantum leaps\" between certain allowed values. For any system, the following restrictions on measurement results apply, where is the reduced Planck constant and is any Euclidean vector such as x, y, or z: (There are additional restrictions as well, see angular momentum operator for details.) The reduced Planck constant is tiny by everyday standards, about 10−34 J s, and therefore this quantization does not noticeably affect the angular momentum of macroscopic objects. However, it is very important in the microscopic world. For example, the structure of electron shells and subshells in chemistry is significantly affected by the quantization of angular momentum. Quantization of angular momentum was first postulated by Niels Bohr in his Bohr model of the atom and was later predicted by Erwin Schrödinger in his Schrödinger equation.",
                    "score": 0.8609558939933777
                },
                {
                    "id": 19869109,
                    "contents": "Tests of relativistic energy and momentum\nElectrons traveling between 0.25–0.75c indicated an increase of momentum in agreement with the relativistic predictions, and were considered as clear confirmations of special relativity. However, it was later pointed out that although the experiments were in agreement with relativity, the precision wasn't sufficient to rule out competing models of the electron, such as the one of Max Abraham. Already in 1915, however, Arnold Sommerfeld was able to derive the Fine structure of hydrogen-like spectra by using the relativistic expressions for momentum and energy (in the context of the Bohr–Sommerfeld theory). Subsequently, Karl Glitscher simply replaced the relativistic expression's by Abraham's, demonstrating that Abraham's theory is in conflict with experimental data and is therefore refuted, while relativity is in agreement with the data. Precision measurements",
                    "score": 0.860776424407959
                },
                {
                    "id": 1872176,
                    "contents": "Muon\nThe experimental technique that is expected to provide the most precise determination of the root-mean-square charge radius of the proton is the measurement of the frequency of photons (precise \"color\" of light) emitted or absorbed by atomic transitions in muonic hydrogen. This form of hydrogen atom is composed of a negatively charged muon bound to a proton. The muon is particularly well suited for this purpose because its much larger mass results in a much more compact bound state and hence a larger probability for it to be found inside the proton in muonic hydrogen compared to the electron in atomic hydrogen. The Lamb shift in muonic hydrogen was measured by driving the muon from a 2s state up to an excited 2p state using a laser. The frequency of the photons required to induce two such (slightly different) transitions were reported in 2014 to be 50 and 55 THz which, according to present theories of quantum electrodynamics (QED), yield an appropriately averaged value of for the",
                    "score": 0.8605269193649292
                },
                {
                    "id": 1762780,
                    "contents": "History of physics\n\"uncertainty principle\" (indicating the impossibility of precisely and simultaneously measuring position and momentum) and the \"Copenhagen interpretation\" of quantum mechanics (named after Bohr's home city) continued to deny the possibility of fundamental causality, though opponents such as Einstein would metaphorically assert that \"God does not play dice with the universe\". The new quantum mechanics became an indispensable tool in the investigation and explanation of phenomena at the atomic level. Also in the 1920s, the Indian scientist Satyendra Nath Bose's work on photons and quantum mechanics provided the foundation for Bose–Einstein statistics, the theory of the Bose–Einstein condensate.",
                    "score": 0.8601828813552856
                },
                {
                    "id": 1194756,
                    "contents": "Quantum mechanics\nand likewise for the momentum: The uncertainty principle states that Either standard deviation can in principle be made arbitrarily small, but not both simultaneously. This inequality generalizes to arbitrary pairs of self-adjoint operators and . The commutator of these two operators is and this provides the lower bound on the product of standard deviations:",
                    "score": 0.8600066900253296
                },
                {
                    "id": 28117438,
                    "contents": "Proton radius puzzle\nRelativistic reference frame issues Other investigators have suggested that the analysis used for the electron-based proton charge radius may not properly consider the rest frames of the different components of the experiments, in the light of special relativity. Polarization factors in muonic hydrogen which are not material in ordinary hydrogen have also been proposed as a possible solution. Yet another paper in April 2019 suggested that scale relativity may provide an answer based on the relativistic sizes of protons and muons. 2019 measurements In September 2019, Bezginov et al. reported the remeasurement of the proton's charge radius for electronic hydrogen and found a result consistent with Pohl's value for muonic hydrogen. In November W. Xiong et al. reported a similar result using extremely low momentum transfer electron scattering.",
                    "score": 0.859813928604126
                },
                {
                    "id": 1164021,
                    "contents": "Proton\nAlthough protons were originally considered elementary particles, in the modern Standard Model of particle physics, protons are now known to be composite particles, containing three valence quarks, and together with neutrons are now classified as hadrons. Protons are composed of two up quarks of charge +e and one down quark of charge −e. The rest masses of quarks contribute only about 1% of a proton's mass. The remainder of a proton's mass is due to quantum chromodynamics binding energy, which includes the kinetic energy of the quarks and the energy of the gluon fields that bind the quarks together. Because protons are not fundamental particles, they possess a measurable size; the root mean square charge radius of a proton is about 0.84–0.87 fm (or to ). In 2019, two different studies, using different techniques, found the radius of the proton to be 0.833 fm, with an uncertainty of ±0.010 fm.",
                    "score": 0.8594595193862915
                },
                {
                    "id": 15708225,
                    "contents": "Planck constant\nUncertainty principle The Planck constant also occurs in statements of Werner Heisenberg's uncertainty principle. Given numerous particles prepared in the same state, the uncertainty in their position, , and the uncertainty in their momentum, , obey where the uncertainty is given as the standard deviation of the measured value from its expected value. There are several other such pairs of physically measurable conjugate variables which obey a similar rule. One example is time vs. energy. The inverse relationship between the uncertainty of the two conjugate variables forces a tradeoff in quantum experiments, as measuring one quantity more precisely results in the other quantity becoming imprecise. In addition to some assumptions underlying the interpretation of certain values in the quantum mechanical formulation, one of the fundamental cornerstones to the entire theory lies in the commutator relationship between the position operator and the momentum operator :",
                    "score": 0.8591383099555969
                },
                {
                    "id": 16681010,
                    "contents": "Timeline of quantum mechanics\n1931 – Ernst Ruska creates the first electron microscope. 1931 – Ernest Lawrence creates the first cyclotron and founds the Radiation Laboratory, later the Lawrence Berkeley National Laboratory; in 1939 he awarded the Nobel Prize in Physics for his work on the cyclotron. 1932 – Irène Joliot-Curie and Frédéric Joliot show that if the unknown radiation generated by alpha particles falls on paraffin or any other hydrogen-containing compound, it ejects protons of very high energy. This is not in itself inconsistent with the proposed gamma ray nature of the new radiation, but detailed quantitative analysis of the data become increasingly difficult to reconcile with such a hypothesis. 1932 – James Chadwick performs a series of experiments showing that the gamma ray hypothesis for the unknown radiation produced by alpha particles is untenable, and that the new particles must be the neutrons hypothesized by Fermi.",
                    "score": 0.859048068523407
                },
                {
                    "id": 6237105,
                    "contents": "Philosophy of physics\nPhysicist Roland Omnés noted that it is impossible to experimentally differentiate between Everett's view, which says that as the wave-function decoheres into distinct worlds, each of which exists equally, and the more traditional view that says that a decoherent wave-function leaves only one unique real result. Hence, the dispute between the two views represents a great \"chasm.\" \"Every characteristic of reality has reappeared in its reconstruction by our theoretical model; every feature except one: the uniqueness of facts.\" Uncertainty principle The uncertainty principle is a mathematical relation asserting an upper limit to the accuracy of the simultaneous measurement of any pair of conjugate variables, e.g. position and momentum. In the formalism of operator notation, this limit is the evaluation of the commutator of the variables' corresponding operators.",
                    "score": 0.8589726090431213
                },
                {
                    "id": 674171,
                    "contents": "Greisen–Zatsepin–Kuzmin limit\nThe Greisen–Zatsepin–Kuzmin limit (GZK limit) is a theoretical upper limit on the energy of cosmic ray protons traveling from other galaxies through the intergalactic medium to our galaxy. The limit is (50 EeV), or about 8 joules (the energy of a proton travelling at ≈ % the speed of light). The limit is set by the slowing effect of interactions of the protons with the microwave background radiation over long distances (≈ 160 million light-years). The limit is at the same order of magnitude as the upper limit for energy at which cosmic rays have experimentally been detected, although indeed some detections appear to have exceeded the limit, as noted below. For example, one extreme-energy cosmic ray, the Oh-My-God Particle, which has been found to possess a record-breaking (50 joules) of energy (about the same as the kinetic energy of a 95 km/h baseball).",
                    "score": 0.8588898777961731
                },
                {
                    "id": 552405,
                    "contents": "Wavenumber\nHere p is the momentum of the particle, m is the mass of the particle, E is the kinetic energy of the particle, and ħ is the reduced Planck constant. Wavenumber is also used to define the group velocity. In spectroscopy In spectroscopy, \"wavenumber\" refers to a frequency which has been divided by the speed of light in vacuum usually in centimeters per second (cm.s−1): : The historical reason for using this spectroscopic wavenumber rather than frequency is that it is a convenient unit when studying atomic spectra by counting fringes per cm with an interferometer : the spectroscopic wavenumber is the reciprocal of the wavelength of light in vacuum:",
                    "score": 0.858857274055481
                },
                {
                    "id": 19378718,
                    "contents": "Faster-than-light neutrino anomaly\na 0.2-in-a-million chance of the result being a false positive, assuming the error were entirely due to random effects (significance of six sigma). This measure included estimates for both errors in measuring and errors from the statistical procedure used. It was, however, a measure of precision, not accuracy, which could be influenced by elements such as incorrect computations or wrong readouts of instruments. For particle physics experiments involving collision data, the standard for a discovery announcement is a five-sigma error limit, looser than the observed six-sigma limit.",
                    "score": 0.8588196039199829
                },
                {
                    "id": 8557319,
                    "contents": "Angular momentum operator\nThe Robertson–Schrödinger relation gives the following uncertainty principle: where is the standard deviation in the measured values of X and denotes the expectation value of X. This inequality is also true if x, y, z are rearranged, or if L is replaced by J or S. Therefore, two orthogonal components of angular momentum (for example Lx and Ly) are complementary and cannot be simultaneously known or measured, except in special cases such as . It is, however, possible to simultaneously measure or specify L2 and any one component of L; for example, L2 and Lz. This is often useful, and the values are characterized by the azimuthal quantum number (l) and the magnetic quantum number (m). In this case the quantum state of the system is a simultaneous eigenstate of the operators L2 and Lz, but not of Lx or Ly. The eigenvalues are related to l and m, as shown in the table below. Quantization",
                    "score": 0.8588168025016785
                },
                {
                    "id": 24468008,
                    "contents": "NA63 experiment\nAn electron entering an electric field is accelerated, and therefore must lose part of its energy in the form of a photon via the Bremsstrahlung effect - the process by which a charged particle emits electromagnetic radiation when being decelerated upon passing an atom, for instance in a solid material. By exploiting the relativistic phenomena of time dilatation and length contraction, the NA63 experiment has shown that this process of photon emission is not instantaneous, but rather, takes time. Because the process takes time, the photon production can be influenced experimentally. For non-relativistic particles this time is so short that investigations are very difficult, if not excluded. But for the relativistic particles used by NA63, their time is ‘slowed’ by a factor of about half a million due to the relativistic effect of time dilatation, making investigations possible.",
                    "score": 0.8582134246826172
                },
                {
                    "id": 4750223,
                    "contents": "Variable speed of light\nPaul Davies and collaborators have suggested that it is in principle possible to disentangle which of the dimensionful constants (the elementary charge, Planck's constant, and the speed of light) of which the fine-structure constant is composed is responsible for the variation. However, this has been disputed by others and is not generally accepted. Several fundamental constants From the properties of vacuum and fundamental constants, it is possible to build a velocity that is of the same order of magnitude as the speed of light in vacuum. Let us note the critical density of the universe (it is assumed that the value of the Hubble constant is approximately ), the temperature of the cosmic microwave background, the Boltzmann constant, the vacuum permittivity and the elementary charge. Thus,",
                    "score": 0.8580155372619629
                },
                {
                    "id": 1693515,
                    "contents": "Electromagnetic radiation\nAt the quantum level, electromagnetic radiation is produced when the wavepacket of a charged particle oscillates or otherwise accelerates. Charged particles in a stationary state do not move, but a superposition of such states may result in a transition state that has an electric dipole moment that oscillates in time. This oscillating dipole moment is responsible for the phenomenon of radiative transition between quantum states of a charged particle. Such states occur (for example) in atoms when photons are radiated as the atom shifts from one stationary state to another. As a wave, light is characterized by a velocity (the speed of light), wavelength, and frequency. As particles, light is a stream of photons. Each has an energy related to the frequency of the wave given by Planck's relation E = hf, where E is the energy of the photon, h is Planck's constant, 6.626 × 10−34 J·s, and f is the frequency of the wave.",
                    "score": 0.8577849864959717
                },
                {
                    "id": 8557335,
                    "contents": "Angular momentum operator\nNotes References Further reading Quantum Mechanics Demystified, D. McMahon, Mc Graw Hill (USA), 2006, Quantum mechanics, E. Zaarur, Y. Peleg, R. Pnini, Schaum's Easy Outlines Crash Course, Mc Graw Hill (USA), 2006, Quantum Physics of Atoms, Molecules, Solids, Nuclei, and Particles (2nd Edition), R. Eisberg, R. Resnick, John Wiley & Sons, 1985, Quantum Mechanics, E. Abers, Pearson Ed., Addison Wesley, Prentice Hall Inc, 2004, Physics of Atoms and Molecules, B.H. Bransden, C.J.Joachain, Longman, 1983, Angular Momentum. Understanding Spatial Aspects in Chemistry and Physics, R. N. Zare, Wiley-Interscience, 1991, Rotational symmetry Quantum mechanics",
                    "score": 0.8575173616409302
                },
                {
                    "id": 1872178,
                    "contents": "Muon\nThe internationally accepted value of the proton's charge radius is based on a suitable average of results from older measurements of effects caused by the nonzero size of the proton on scattering of electrons by nuclei and the light spectrum (photon energies) from excited atomic hydrogen. The official value updated in 2014 is (see orders of magnitude for comparison to other sizes). The expected precision of this result is inferior to that from muonic hydrogen by about a factor of fifteen, yet they disagree by about 5.6 times the nominal uncertainty in the difference (a discrepancy called 5.6 in scientific notation). A conference of the world experts on this topic led to the decision to exclude the muon result from influencing the official 2014 value, in order to avoid hiding the mysterious discrepancy.",
                    "score": 0.8572105765342712
                },
                {
                    "id": 1164034,
                    "contents": "Proton\nQuarks and the mass of a proton In quantum chromodynamics, the modern theory of the nuclear force, most of the mass of protons and neutrons is explained by special relativity. The mass of a proton is about 80–100 times greater than the sum of the rest masses of its three valence quarks, while the gluons have zero rest mass. The extra energy of the quarks and gluons in a proton, as compared to the rest energy of the quarks alone in the QCD vacuum, accounts for almost 99% of the proton's mass. The rest mass of a proton is, thus, the invariant mass of the system of moving quarks and gluons that make up the particle, and, in such systems, even the energy of massless particles is still measured as part of the rest mass of the system.",
                    "score": 0.8571997880935669
                },
                {
                    "id": 1402001,
                    "contents": "J. Robert Oppenheimer\nHe worked closely with Nobel Prize-winning experimental physicist Ernest O. Lawrence and his cyclotron pioneers, helping them understand the data their machines were producing at the Lawrence Berkeley National Laboratory. In 1936, Berkeley promoted him to full professor at a salary of $3,300 a year (). In return he was asked to curtail his teaching at Caltech, so a compromise was reached whereby Berkeley released him for six weeks each year, enough to teach one term at Caltech. Scientific work Oppenheimer did important research in theoretical astronomy (especially as related to general relativity and nuclear theory), nuclear physics, spectroscopy, and quantum field theory, including its extension into quantum electrodynamics. The formal mathematics of relativistic quantum mechanics also attracted his attention, although he doubted its validity. His work predicted many later finds, which include the neutron, meson and neutron star.",
                    "score": 0.8571262955665588
                },
                {
                    "id": 8739812,
                    "contents": "Robert Karplus\nAfter completing his education Karplus worked at the Institute for Advanced Study in Princeton, where he became interested in the developing, but yet untested, theory of quantum electrodynamics (QED). The magnetic moment of the electron had been determined very precisely by means of a variety of experiments, but the best theoretical calculations of this quantity, based on quantum mechanics, were seriously at variance with the experimental results. There was great interest among physicists in knowing whether or not a calculation based on QED would agree with the experimental results, but because of the ambiguities and complexity of QED, no one had so far been able to do such a calculation. Karplus, in collaboration with Norman Kroll, used QED to calculate the value of the magnetic moment of the electron. This was an extremely difficult calculation, requiring more than a year of intense effort from both men; the agreement between their result and the experimental measurements was the",
                    "score": 0.856915295124054
                },
                {
                    "id": 9515886,
                    "contents": "Constant of motion\nDerivation Say there is some observable quantity Q which depends on position, momentum and time, And also, that there is a wave function which obeys Schrödinger's equation Taking the time derivative of the expectation value of Q requires use of the product rule, and results in {| | | |- | | |- | | |- | | |- | | |} So finally, {|cellpadding=\"2\" style=\"border:2px solid #ccccff\" | |} Comment For an arbitrary state of a Quantum Mechanical system, if H and Q commute, i.e. if and Q is not explicitly dependent on time, then But if is an eigenfunction of Hamiltonian, then even if it is still the case that provided Q is independent on time. Derivation {| | | |- | | |} Since {| | |} then {| | | |- | | |} This is the reason why Eigenstates of the Hamiltonian are also called stationary states. Relevance for quantum chaos",
                    "score": 0.8568843603134155
                },
                {
                    "id": 16681027,
                    "contents": "Timeline of quantum mechanics\n1961 – Clauss Jönsson performs Young's double-slit experiment (1909) for the first time with particles other than photons by using electrons and with similar results, confirming that massive particles also behaved according to the wave–particle duality that is a fundamental principle of quantum field theory. 1961 – Anatole Abragam publishes the fundamental textbook on the quantum theory of Nuclear Magnetic Resonance entitled The Principles of Nuclear Magnetism; 1961 – Sheldon Glashow extends the electroweak interaction models developed by Julian Schwinger by including a short range neutral current, the Z_o. The resulting symmetry structure that Glashow proposes, SU(2) X U(1), forms the basis of the accepted theory of the electroweak interactions. 1962 – Leon M. Lederman, Melvin Schwartz and Jack Steinberger show that more than one type of neutrino exists by detecting interactions of the muon neutrino (already hypothesised with the name \"neutretto\")",
                    "score": 0.8568524122238159
                },
                {
                    "id": 3048299,
                    "contents": "Planck length\nThe Planck length is about 10−20 times the diameter of a proton. It can be defined as the reduced Compton wavelength of a black hole for which this equals its Schwarzschild radius. The Planck length can be found also without knowledge of the Newtonian gravitational constant using a Newton force spring. History In 1899, Max Planck suggested that there existed some fundamental natural units for length, mass, time and energy. He derived these using dimensional analysis, using only the Newton gravitational constant, the speed of light and the Planck constant (though it was not yet called this). The modern convention is to use the reduced Planck constant in place of the Planck constant in the definition of the resulting units. The derived natural units became known as the \"Planck length\", the \"Planck mass\", the \"Planck time\" and the \"Planck energy\".",
                    "score": 0.8567897081375122
                },
                {
                    "id": 8585209,
                    "contents": "Richard Dalitz\nQuantum mechanics Dalitz was an old and close friend of John Clive Ward, the creator of the Ward Identities. Their friendship began around 1948 when Dalitz independently derived Ward's results for the polarisation entanglement of two photons propagating in opposite directions. Dalitz was the lead author of a succinct, and yet revealing, account of Ward's physics. While commenting on the physics surrounding the derivation of the probability amplitude by Ward, Dalitz and Duarte wrote: \"Ward and Pryce calculated, using quantum mechanics, the distribution of the azimuth angle between the planes of polarization of... two gamma rays from positron-electron annihilation... the two photons are entangled and according to local realism, their polarization planes should become independent... a typical EPR situation. Already in 1948, observations... agreed with quantum mechanics, not with local realism.\" Quarks",
                    "score": 0.8567069172859192
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_31",
        "question": "It is possible to produce very high magnetic fields over small volumes by special techniques. What would be the resonance frequency of an electron spin in an organic radical in a field of $1.0 \\mathrm{kT}$ ?",
        "golden_answers": [
            " 2.8"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1016009,
                    "contents": "Magnet\nIn all units, it is convenient to employ two types of magnetic field, B and H, as well as the magnetization M, defined as the magnetic moment per unit volume.",
                    "score": 0.8982402086257935
                },
                {
                    "id": 1865800,
                    "contents": "Magnetism\nFerromagnetism only occurs in a few substances; common ones are iron, nickel, cobalt, their alloys, and some alloys of rare-earth metals. Magnetic domains The magnetic moments of atoms in a ferromagnetic material cause them to behave something like tiny permanent magnets. They stick together and align themselves into small regions of more or less uniform alignment called magnetic domains or Weiss domains. Magnetic domains can be observed with a magnetic force microscope to reveal magnetic domain boundaries that resemble white lines in the sketch. There are many scientific experiments that can physically show magnetic fields. When a domain contains too many molecules, it becomes unstable and divides into two domains aligned in opposite directions, so that they stick together more stably, as shown at the right.",
                    "score": 0.8969573974609375
                },
                {
                    "id": 1367493,
                    "contents": "Magnetic field\nMost materials respond to an applied -field by producing their own magnetization and therefore their own -fields. Typically, the response is weak and exists only when the magnetic field is applied. The term magnetism describes how materials respond on the microscopic level to an applied magnetic field and is used to categorize the magnetic phase of a material. Materials are divided into groups based upon their magnetic behavior: Diamagnetic materials produce a magnetization that opposes the magnetic field. Paramagnetic materials produce a magnetization in the same direction as the applied magnetic field. Ferromagnetic materials and the closely related ferrimagnetic materials and antiferromagnetic materials can have a magnetization independent of an applied B-field with a complex relationship between the two fields.",
                    "score": 0.8966768980026245
                },
                {
                    "id": 358183,
                    "contents": "Magnetic susceptibility\nThe magnetizability of materials comes from the atomic-level magnetic properties of the particles of which they are made. Usually, this is dominated by the magnetic moments of electrons. Electrons are present in all materials, but without any external magnetic field, the magnetic moments of the electrons are usually either paired up or random so that the overall magnetism is zero (the exception to this usual case is ferromagnetism). The fundamental reasons why the magnetic moments of the electrons line up or do not are very complex and cannot be explained by classical physics. However, a useful simplification is to measure the magnetic susceptibility of a material and apply the macroscopic form of Maxwell's equations. This allows classical physics to make useful predictions while avoiding the underlying quantum mechanical details. Definition",
                    "score": 0.8900137543678284
                },
                {
                    "id": 1675311,
                    "contents": "Diamagnetism\nSee also Antiferromagnetism Magnetochemistry Moses effect References External links Diamagnetic Levitation (YouTube) Diamagnetism of water (YouTube, in Japanese) Electric and magnetic fields in matter Magnetic levitation Magnetism",
                    "score": 0.889055073261261
                },
                {
                    "id": 12860892,
                    "contents": "Earth's field NMR\nAn important feature of EFNMR compared with high-field NMR is that some aspects of molecular structure can be observed more clearly at low fields and low frequencies, whereas other features observable at high fields may not be observable at low fields. This is because: Electron-mediated heteronuclear J-couplings (spin-spin couplings) are field independent, producing clusters of two or more frequencies separated by several Hz, which are more easily observed in a fundamental resonance of about 2 kHz. \"Indeed it appears that enhanced resolution is possible due to the long spin relaxation times and high field homogeneity which prevail in EFNMR.\" Chemical shifts of several parts per million (ppm) are clearly separated in high field NMR spectra, but have separations of only a few milliherz at proton EFNMR frequencies, and so are undetectable in an experiment that takes place on a timescale of tenths of a second.",
                    "score": 0.887406051158905
                },
                {
                    "id": 19465013,
                    "contents": "Zeeman energy\nZeeman energy, or the external field energy, is the potential energy of a magnetised body in an external magnetic field. It is named after the Dutch physicist Pieter Zeeman, primarily known by the Zeeman effect. In SI units, it is given by where HExt is the external field, M the local magnetisation, and the integral is done over the volume of the body. This is the statistical average (over a unit volume macroscopic sample) of a corresponding microscopic Hamiltonial (energy) for each individual magnetic moment m, which is however experiencing a local induction B: References F. Barozzi, F. Gasparini, Fondamenti di Elettrotecnica: Elettromagnetismo, UTET Torino, 1989 Hubert, A. and Schäfer, R. Magnetic domains: the analysis of magnetic microstructures, Springer-Verlag, 1998 Magnetism Physical phenomena",
                    "score": 0.8868130445480347
                },
                {
                    "id": 14050641,
                    "contents": "Magnetic structure\nMore recently, table-top techniques are being developed which allow magnetic structures to be studied without recourse to neutron or synchrotron sources. Magnetic structure of the chemical elements Only three elements are ferromagnetic at room temperature and pressure: iron, cobalt, and nickel. This is because their Curie temperature, Tc, is higher than room temperature (Tc > 298K). Gadolinium has a spontaneous magnetization just below room temperature (293 K) and is sometimes counted as the fourth ferromagnetic element. There has been some suggestion that Gadolinium has helimagnetic ordering, but others defend the longstanding view that Gadolinium is a conventional ferromagnet.",
                    "score": 0.8866579532623291
                },
                {
                    "id": 1628657,
                    "contents": "Condensed matter physics\nExternal magnetic fields In experimental condensed matter physics, external magnetic fields act as thermodynamic variables that control the state, phase transitions and properties of material systems. Nuclear magnetic resonance (NMR) is a method by which external magnetic fields are used to find resonance modes of individual electrons, thus giving information about the atomic, molecular, and bond structure of their neighborhood. NMR experiments can be made in magnetic fields with strengths up to 60 Tesla. Higher magnetic fields can improve the quality of NMR measurement data. Quantum oscillations is another experimental method where high magnetic fields are used to study material properties such as the geometry of the Fermi surface. High magnetic fields will be useful in experimentally testing of the various theoretical predictions such as the quantized magnetoelectric effect, image magnetic monopole, and the half-integer quantum Hall effect.",
                    "score": 0.8855977058410645
                },
                {
                    "id": 15708239,
                    "contents": "Planck constant\nMagnetic resonance The gyromagnetic ratio γ is the constant of proportionality between the frequency ν of nuclear magnetic resonance (or electron paramagnetic resonance for electrons) and the applied magnetic field . It is difficult to measure gyromagnetic ratios precisely because of the difficulties in precisely measuring B, but the value for protons in water at is known to better than one part per million. The protons are said to be \"shielded\" from the applied magnetic field by the electrons in the water molecule, the same effect that gives rise to chemical shift in NMR spectroscopy, and this is indicated by a prime on the symbol for the gyromagnetic ratio, γ′p. The gyromagnetic ratio is related to the shielded proton magnetic moment μ′p, the spin number I ( for protons) and the reduced Planck constant.",
                    "score": 0.885384202003479
                },
                {
                    "id": 358185,
                    "contents": "Magnetic susceptibility\nis therefore a dimensionless quantity. Using SI units, the magnetic induction is related to by the relationship where is the vacuum permeability (see table of physical constants), and is the relative permeability of the material. Thus the volume magnetic susceptibility and the magnetic permeability are related by the following formula: Sometimes an auxiliary quantity called intensity of magnetization (also referred to as magnetic polarisation ) and with unit teslas, is defined as This allows an alternative description of all magnetization phenomena in terms of the quantities and , as opposed to the commonly used and . Molar susceptibility and massic susceptibility There are two other measures of susceptibility, the molar magnetic susceptibility () with unit m3/mol, and the massic magnetic susceptibility () with unit m3/kg that are defined below, where is the density with unit kg/m3 and is molar mass with unit kg/mol:",
                    "score": 0.8853797316551208
                },
                {
                    "id": 1865796,
                    "contents": "Magnetism\nSometimes, either spontaneously, or owing to an applied external magnetic field—each of the electron magnetic moments will be, on average, lined up. A suitable material can then produce a strong net magnetic field. The magnetic behavior of a material depends on its structure, particularly its electron configuration, for the reasons mentioned above, and also on the temperature. At high temperatures, random thermal motion makes it more difficult for the electrons to maintain alignment. Types of magnetism Diamagnetism",
                    "score": 0.8852171897888184
                },
                {
                    "id": 358187,
                    "contents": "Magnetic susceptibility\nIn physics it is common to see CGS massic susceptibility with unit cm3/g or emu/g⋅Oe−1, and the CGS molar susceptibility with unit cm3/mol or emu/mol⋅Oe−1. Paramagnetism and diamagnetism If is positive, a material can be paramagnetic. In this case, the magnetic field in the material is strengthened by the induced magnetization. Alternatively, if is negative, the material is diamagnetic. In this case, the magnetic field in the material is weakened by the induced magnetization. Generally, nonmagnetic materials are said to be para- or diamagnetic because they do not possess permanent magnetization without external magnetic field. Ferromagnetic, ferrimagnetic, or antiferromagnetic materials possess permanent magnetization even without external magnetic field and do not have a well defined zero-field susceptibility.",
                    "score": 0.8845824599266052
                },
                {
                    "id": 1675301,
                    "contents": "Diamagnetism\nMaterials Diamagnetism is a property of all materials, and always makes a weak contribution to the material's response to a magnetic field. However, other forms of magnetism (such as ferromagnetism or paramagnetism) are so much stronger that, when multiple different forms of magnetism are present in a material, the diamagnetic contribution is usually negligible. Substances where the diamagnetic behaviour is the strongest effect are termed diamagnetic materials, or diamagnets. Diamagnetic materials are those that some people generally think of as non-magnetic, and include water, wood, most organic compounds such as petroleum and some plastics, and many metals including copper, particularly the heavy ones with many core electrons, such as mercury, gold and bismuth. The magnetic susceptibility values of various molecular fragments are called Pascal's constants.",
                    "score": 0.8845477104187012
                },
                {
                    "id": 1865824,
                    "contents": "Magnetism\nThe explanation of the phenomena is thus essentially based on all subtleties of quantum mechanics, whereas the electrodynamics covers mainly the phenomenology. See also Coercivity Gravitomagnetism Magnetic hysteresis Magnetar Magnetic bearing Magnetic circuit Magnetic cooling Magnetic field viewing film Magnetic stirrer Magnetic structure Magnetism and temperature Micromagnetism Neodymium magnet Plastic magnet Rare-earth magnet Spin wave Spontaneous magnetization Vibrating-sample magnetometer References Further reading Bibliography The Exploratorium Science Snacks – Subject:Physics/Electricity & Magnetism A collection of magnetic structures – MAGNDATA",
                    "score": 0.8842664957046509
                },
                {
                    "id": 9086562,
                    "contents": "Micromagnetics\nThe anisotropy energy favors magnetic configurations where the magnetization is everywhere aligned along an easy axis. Zeeman energy The Zeeman energy is the interaction energy between the magnetization and any externally applied field. It's written as: where Ha is the applied field and µ0 is the vacuum permeability. The Zeeman energy favors alignment of the magnetization parallel to the applied field. Energy of the demagnetizing field The demagnetizing field is the magnetic field created by the magnetic sample upon itself. The associated energy is: where Hd is the demagnetizing field. This field depends on the magnetic configuration itself, and it can be found by solving: where −∇·M is sometimes called magnetic charge density. The solution of these equations (c.f. magnetostatics) is: where r is the vector going from the current integration point to the point where Hd is being calculated.",
                    "score": 0.8840680122375488
                },
                {
                    "id": 1865787,
                    "contents": "Magnetism\nThe magnetic state (or magnetic phase) of a material depends on temperature, pressure, and the applied magnetic field. A material may exhibit more than one form of magnetism as these variables change. The strength of a magnetic field almost always decreases with distance, though the exact mathematical relationship between strength and distance varies. Different configurations of magnetic moments and electric currents can result in complicated magnetic fields. Only magnetic dipoles have been observed, although some theories predict the existence of magnetic monopoles. History",
                    "score": 0.8837289214134216
                },
                {
                    "id": 15076613,
                    "contents": "Weiss magneton\nThe Weiss magneton was an experimentally derived unit of magnetic moment equal to joules per tesla, which is about 20% of the Bohr magneton. It was suggested in 1911 by Pierre Weiss. Origin The idea of elementary magnets originated from the Swiss physicist Walther Ritz, who tried to explain atomic spectra. In 1907 he suggested that atoms might contain chains of magnetized and neutral rods, which were the cause of magnetic properties of materials. Just like elementary charges, this was supposed to give rise to discrete values of the total magnetic moment per atom. In 1909, Weiss performed measurements of the saturation magnetization at the temperature of liquid hydrogen in the laboratory of Heike Kamerlingh Onnes in Leiden. In 1911, Weiss announced that the molar moments of nickel and iron had the ratio of 3:11, from which he derived the value of a magneton.",
                    "score": 0.8834612369537354
                },
                {
                    "id": 16459837,
                    "contents": "Nuclear magnetic resonance\nNMR phenomena are also utilized in low-field NMR, NMR spectroscopy and MRI in the Earth's magnetic field (referred to as Earth's field NMR), and in several types of magnetometers. History Nuclear magnetic resonance was first described and measured in molecular beams by Isidor Rabi in 1938, by extending the Stern–Gerlach experiment, and in 1944, Rabi was awarded the Nobel Prize in Physics for this work. In 1946, Felix Bloch and Edward Mills Purcell expanded the technique for use on liquids and solids, for which they shared the Nobel Prize in Physics in 1952. Yevgeny Zavoisky likely observed nuclear magnetic resonance in 1941, well before Felix Bloch and Edward Mills Purcell, but dismissed the results as not reproducible. Russell H. Varian filed the \"Method and means for correlating nuclear properties of atoms and magnetic fields\", on July 24, 1951. Varian Associates developed the first NMR unit called NMR HR-30 in 1952.",
                    "score": 0.8833057284355164
                },
                {
                    "id": 20080980,
                    "contents": "Magnonics\nThe constant is the Gilbert phenomenological damping parameter and depends on the solid, and is the electron gyromagnetic ratio. Here Research in magnetism, like the rest of modern science, is conducted with a symbiosis of theoretical and experimental approaches. Both approaches go hand-in-hand, experiments test the predictions of theory and theory provides explanations and predictions of new experiments. The theoretical side focuses on numerical modelling and simulations, so called micromagnetic modelling. Programs such as OOMMF or NMAG are micromagnetic solvers that numerically solve the LLG equation with appropriate boundary conditions. Prior to the start of the simulation, magnetic parameters of the sample and the initial groundstate magnetisation and bias field details are stated.",
                    "score": 0.8824788331985474
                },
                {
                    "id": 24540080,
                    "contents": "Magnetic resonance (quantum mechanics)\nFrom this expression many interesting points can be exploited, such Varying uniform magnetic field so that in produces a Lorentz curve (see Cauchy–Lorentz distribution), detecting the peak of that curve, the abscissa of it gives , so now (angular frequency of rotation of = , so from the known value of and , the gyromagnetic ratio of the dipole can be measured; by this method we can measure Nuclear spin where all electronic spins are balanced. Correct measurement of nuclear magnetic moment helps to understand the character of nuclear force. If is known, by varying , the value of can be obtained. This measurement technique is precise enough for use in sensitive magnetometers. Using this technique, the value of magnetic field acting at a particular lattice site by its environment inside a crystal can be obtained.",
                    "score": 0.8820123672485352
                },
                {
                    "id": 1865795,
                    "contents": "Magnetism\nOrdinarily, the enormous number of electrons in a material are arranged such that their magnetic moments (both orbital and intrinsic) cancel out. This is due, to some extent, to electrons combining into pairs with opposite intrinsic magnetic moments as a result of the Pauli exclusion principle (see electron configuration), and combining into filled subshells with zero net orbital motion. In both cases, the electrons preferentially adopt arrangements in which the magnetic moment of each electron is canceled by the opposite moment of another electron. Moreover, even when the electron configuration is such that there are unpaired electrons and/or non-filled subshells, it is often the case that the various electrons in the solid will contribute magnetic moments that point in different, random directions so that the material will not be magnetic.",
                    "score": 0.8817296624183655
                },
                {
                    "id": 1367502,
                    "contents": "Magnetic field\nThe Maxwell term is critically important in the creation and propagation of electromagnetic waves. Maxwell's correction to Ampère's Law together with Faraday's law of induction describes how mutually changing electric and magnetic fields interact to sustain each other and thus to form electromagnetic waves, such as light: a changing electric field generates a changing magnetic field, which generates a changing electric field again. These, though, are usually described using the differential form of this equation given below. where is the complete microscopic current density. As discussed above, materials respond to an applied electric field and an applied magnetic field by producing their own internal \"bound\" charge and current distributions that contribute to and but are difficult to calculate. To circumvent this problem, and fields are used to re-factor Maxwell's equations in terms of the free current density :",
                    "score": 0.8816655874252319
                },
                {
                    "id": 4687677,
                    "contents": "Polarizability\nMagnetic polarizability likewise refers to the tendency for a magnetic dipole moment to appear in proportion to an external magnetic field. Electric and magnetic polarizabilities determine the dynamical response of a bound system (such as a molecule or crystal) to external fields, and provide insight into a molecule's internal structure. \"Polarizability\" should not be confused with the intrinsic magnetic or electric dipole moment of an atom, molecule, or bulk substance; these do not depend on the presence of an external field. Electric polarizability Definition Electric polarizability is the relative tendency of a charge distribution, like the electron cloud of an atom or molecule, to be distorted from its normal shape by an external electric field. The polarizability in isotropic media is defined as the ratio of the induced dipole moment of an atom to the electric field that produces this dipole moment.",
                    "score": 0.8814319372177124
                },
                {
                    "id": 16459831,
                    "contents": "Nuclear magnetic resonance\nNuclear magnetic resonance (NMR) is a physical phenomenon in which nuclei in a strong constant magnetic field are perturbed by a weak oscillating magnetic field (in the near field) and respond by producing an electromagnetic signal with a frequency characteristic of the magnetic field at the nucleus. This process occurs near resonance, when the oscillation frequency matches the intrinsic frequency of the nuclei, which depends on the strength of the static magnetic field, the chemical environment, and the magnetic properties of the isotope involved; in practical applications with static magnetic fields up to ca. 20 tesla, the frequency is similar to VHF and UHF television broadcasts (60–1000 MHz). NMR results from specific magnetic properties of certain atomic nuclei. Nuclear magnetic resonance spectroscopy is widely used to determine the structure of organic molecules in solution and study molecular physics and crystals as well as non-crystalline materials. NMR is also routinely used",
                    "score": 0.8812829256057739
                },
                {
                    "id": 1053632,
                    "contents": "Permittivity\nIn electromagnetism, the absolute permittivity, often simply called permittivity and denoted by the Greek letter ε (epsilon), is a measure of the electric polarizability of a dielectric. A material with high permittivity polarizes more in response to an applied electric field than a material with low permittivity, thereby storing more energy in the material. In electrostatics, the permittivity plays an important role in determining the capacitance of a capacitor. In the simplest case, the electric displacement field D resulting from an applied electric field E is More generally, the permittivity is a thermodynamic function of state. It can depend on the frequency, magnitude, and direction of the applied field. The SI unit for permittivity is farad per meter (F/m). The permittivity is often represented by the relative permittivity εr which is the ratio of the absolute permittivity ε and the vacuum permittivity ε0 .",
                    "score": 0.8808468580245972
                },
                {
                    "id": 418748,
                    "contents": "Isidor Isaac Rabi\nMeasuring the magnetic resonance of crystals first involved growing the crystals, a simple procedure often done by elementary school students. The crystals then had to be prepared by skillfully cutting them into sections with facets that had an orientation different from the internal structure of the crystal, and the response to a magnetic field had to be painstakingly measured. While his crystals were growing, Rabi read James Clerk Maxwell's 1873 A Treatise on Electricity and Magnetism, which inspired an easier method. He lowered a crystal on a glass fiber attached to a torsion balance into a solution whose magnetic susceptibility could be varied between two magnetic poles. When it matched that of the crystal, the magnet could be turned on and off without disturbing the crystal. The new method not only required much less work, it also produced a more accurate result. Rabi sent his thesis, entitled On the Principal Magnetic Susceptibilities of Crystals, to Physical Review on July 16,",
                    "score": 0.880519449710846
                },
                {
                    "id": 14136530,
                    "contents": "Orders of magnitude (magnetic field)\nThis page lists examples of magnetic induction B in teslas and gauss produced by various sources, grouped by orders of magnitude. Note: Traditionally, magnetizing field H, is measured in amperes per meter. Magnetic induction B (also known as magnetic flux density) has the SI unit tesla [T or Wb/m2]. One tesla is equal to 104 gauss. Magnetic field drops off as the cube of the distance from a dipole source. Examples These examples attempt to make the measuring point clear, usually the surface of the item mentioned. References Magnetic Field Magnetism",
                    "score": 0.8802909851074219
                },
                {
                    "id": 1865799,
                    "contents": "Magnetism\nFerromagnetism A ferromagnet, like a paramagnetic substance, has unpaired electrons. However, in addition to the electrons' intrinsic magnetic moment's tendency to be parallel to an applied field, there is also in these materials a tendency for these magnetic moments to orient parallel to each other to maintain a lowered-energy state. Thus, even in the absence of an applied field, the magnetic moments of the electrons in the material spontaneously line up parallel to one another. Every ferromagnetic substance has its own individual temperature, called the Curie temperature, or Curie point, above which it loses its ferromagnetic properties. This is because the thermal tendency to disorder overwhelms the energy-lowering due to ferromagnetic order. Ferromagnetism only occurs in a few substances; common ones are iron, nickel, cobalt, their alloys, and some alloys of rare-earth metals. Magnetic domains",
                    "score": 0.8802547454833984
                },
                {
                    "id": 8273040,
                    "contents": "Lorentz–Heaviside units\nOther basic laws Dielectric and magnetic materials Below are the expressions for the macroscopic fields , , and in a material medium. It is assumed here for simplicity that the medium is homogeneous, linear, isotropic, and nondispersive, so that the susceptibilities are constants. Note that The quantities , and are dimensionless, and they have the same numeric value. By contrast, the electric susceptibility is dimensionless in all the systems, but has different numeric values for the same material: The same statements apply for the corresponding magnetic quantities. Advantages and disadvantages of Heaviside-Lorentz units Advantages",
                    "score": 0.8800972700119019
                },
                {
                    "id": 13366179,
                    "contents": "Zero field NMR\nZero- to ultralow-field (ZULF) NMR is the acquisition of nuclear magnetic resonance (NMR) spectra of chemicals with magnetically active nuclei (spins 1/2 and greater) in an environment carefully screened from magnetic fields (including from the Earth's field). ZULF NMR experiments typically involve the use of passive or active shielding to attenuate Earth’s magnetic field. This is in contrast to the majority of NMR experiments which are performed in high magnetic fields provided by superconducting magnets. In ZULF experiments the dominant interactions are nuclear spin-spin couplings, and the coupling between spins and the external magnetic field is a perturbation to this. There are a number of advantages to operating in this regime: magnetic-susceptibility-induced line broadening is attenuated which reduces inhomogeneous broadening of the spectral lines for samples in heterogeneous environments. Another advantage is that the low frequency signals readily pass through conductive",
                    "score": 0.8795459270477295
                },
                {
                    "id": 4843892,
                    "contents": "Gaussian units\nNext, here are the expressions for the various fields in a magnetic medium. Again, it is assumed that the medium is homogeneous, linear, isotropic, and nondispersive, so that the permeability is a simple constant. where B and H are the magnetic fields M is magnetization is magnetic permeability is the permeability of vacuum (used in the SI system, but meaningless in Gaussian units); is the magnetic susceptibility The quantities and are both dimensionless, and they have the same numeric value. By contrast, the magnetic susceptibility and are both unitless, but has different numeric values in the two systems for the same material: Vector and scalar potentials The electric and magnetic fields can be written in terms of a vector potential A and a scalar potential φ: Electrical circuit",
                    "score": 0.8795226812362671
                },
                {
                    "id": 3347656,
                    "contents": "Electric field gradient\nIn atomic, molecular, and solid-state physics, the electric field gradient (EFG) measures the rate of change of the electric field at an atomic nucleus generated by the electronic charge distribution and the other nuclei. The EFG couples with the nuclear electric quadrupole moment of quadrupolar nuclei (those with spin quantum number greater than one-half) to generate an effect which can be measured using several spectroscopic methods, such as nuclear magnetic resonance (NMR), microwave spectroscopy, electron paramagnetic resonance (EPR, ESR), nuclear quadrupole resonance (NQR), Mössbauer spectroscopy or perturbed angular correlation (PAC). The EFG is non-zero only if the charges surrounding the nucleus violate cubic symmetry and therefore generate an inhomogeneous electric field at the position of the nucleus.",
                    "score": 0.8792670965194702
                },
                {
                    "id": 16459836,
                    "contents": "Nuclear magnetic resonance\nThe two magnetic fields are usually chosen to be perpendicular to each other as this maximizes the NMR signal strength. The frequencies of the time-signal response by the total magnetization (M) of the nuclear spins are analyzed in NMR spectroscopy and magnetic resonance imaging. Both use applied magnetic fields (B0) of great strength, often produced by large currents in superconducting coils, in order to achieve dispersion of response frequencies and of very high homogeneity and stability in order to deliver spectral resolution, the details of which are described by chemical shifts, the Zeeman effect, and Knight shifts (in metals). The information provided by NMR can also be increased using hyperpolarization, and/or using two-dimensional, three-dimensional and higher-dimensional techniques. NMR phenomena are also utilized in low-field NMR, NMR spectroscopy and MRI in the Earth's magnetic field (referred to as Earth's field NMR), and in several types of magnetometers. History",
                    "score": 0.8789200186729431
                },
                {
                    "id": 1866324,
                    "contents": "Maxwell's equations\nSomewhat similarly, in all materials the constituent atoms exhibit magnetic moments that are intrinsically linked to the angular momentum of the components of the atoms, most notably their electrons. The connection to angular momentum suggests the picture of an assembly of microscopic current loops. Outside the material, an assembly of such microscopic current loops is not different from a macroscopic current circulating around the material's surface, despite the fact that no individual charge is traveling a large distance. These bound currents can be described using the magnetization .",
                    "score": 0.8786674737930298
                },
                {
                    "id": 6730330,
                    "contents": "Magnetization\nDefinition The magnetization field or M-field can be defined according to the following equation: Where is the elementary magnetic moment and is the volume element; in other words, the M-field is the distribution of magnetic moments in the region or manifold concerned. This is better illustrated through the following relation: where m is an ordinary magnetic moment and the triple integral denotes integration over a volume. This makes the M-field completely analogous to the electric polarisation field, or P-field, used to determine the electric dipole moment p generated by a similar region or manifold with such a polarization: Where is the elementary electric dipole moment. Those definitions of P and M as a \"moments per unit volume\" are widely adopted, though in some cases they can lead to ambiguities and paradoxes. The M-field is measured in amperes per meter (A/m) in SI units.",
                    "score": 0.8782542943954468
                },
                {
                    "id": 18239864,
                    "contents": "Magnetochemistry\nMain group elements and organic compounds Very few compounds of main group elements are paramagnetic. Notable examples include: oxygen, O2; nitric oxide, NO; nitrogen dioxide, NO2 and chlorine dioxide, ClO2. In organic chemistry, compounds with an unpaired electron are said to be free radicals. Free radicals, with some exceptions, are short-lived because one free radical will react rapidly with another, so their magnetic properties are difficult to study. However, if the radicals are well separated from each other in a dilute solution in a solid matrix, at low temperature, they can be studied by electron paramagnetic resonance (EPR). Such radicals are generated by irradiation. Extensive EPR studies have revealed much about electron delocalization in free radicals. The simulated spectrum of the CH3• radical shows hyperfine splitting due to the interaction of the electron with the 3 equivalent hydrogen nuclei, each of which has a spin of 1/2.",
                    "score": 0.8775963187217712
                },
                {
                    "id": 358186,
                    "contents": "Magnetic susceptibility\nIn CGS units The definitions above are according to the International System of Quantities (ISQ) upon which the SI is based. However, many tables of magnetic susceptibility give the values of the corresponding quantities of the CGS system (more specifically CGS-EMU, short for electromagnetic units, or Gaussian-CGS; both are the same in this context). The quantities characterizing the permeability of free space for each system have different defining equations: The respective CGS susceptibilities are multiplied by 4 to give the corresponding ISQ quantities (often referred to as SI quantities) with the same units: For example, the CGS volume magnetic susceptibility of water at 20 °C is , which is using the SI convention, both quantities being dimensionless. Whereas for most electromagnetic quantities, which system of quantities it belongs to can be disambiguated by incompatibility of their units, this is not true for the susceptibility quantities.",
                    "score": 0.8772215843200684
                },
                {
                    "id": 18239840,
                    "contents": "Magnetochemistry\nMagnetic susceptibility The primary measurement in magnetochemistry is magnetic susceptibility. This measures the strength of interaction on placing the substance in a magnetic field. The volume magnetic susceptibility, represented by the symbol is defined by the relationship where, is the magnetization of the material (the magnetic dipole moment per unit volume), measured in amperes per meter (SI units), and is the magnetic field strength, also measured in amperes per meter. Susceptibility is a dimensionless quantity. For chemical applications the molar magnetic susceptibility (χmol) is the preferred quantity. It is measured in m3·mol−1 (SI) or cm3·mol−1 (CGS) and is defined as where ρ is the density in kg·m−3 (SI) or g·cm−3 (CGS) and M is molar mass in kg·mol−1 (SI) or g·mol−1 (CGS). A variety of methods are available for the measurement of magnetic susceptibility.",
                    "score": 0.8769948482513428
                },
                {
                    "id": 5125961,
                    "contents": "Curie constant\nIn magnetism, the Curie constant is a material-dependent property that relates a material's magnetic susceptibility to its temperature through Curie's law. The Curie constant when expressed in SI units, is given in kelvins (K), by , where is the number of magnetic atoms (or molecules) per unit volume, is the Landé g-factor, is the Bohr magneton, is the angular momentum quantum number and is Boltzmann's constant. For a two-level system with magnetic moment , the formula reduces to , while the corresponding expressions in Gaussian units are , . The constant is used in Curie's law, which states that for a fixed value of an applied magnetic field , the magnetization of a material is (approximately) inversely proportional to temperature. . This equation was first derived by Pierre Curie. Because of the relationship between magnetic susceptibility , magnetization and applied magnetic field is almost linear at low fields, then ,",
                    "score": 0.8762437105178833
                },
                {
                    "id": 5892372,
                    "contents": "Nuclear magnetic moment\nThe nuclear magnetic moment varies from isotope to isotope of an element. For a nucleus of which the numbers of protons and of neutrons are both even in its ground state (i.e. lowest energy state), the nuclear spin and magnetic moment are both always zero. In cases with odd numbers of either or both protons and neutrons, the nucleus often has nonzero spin and magnetic moment. The nuclear magnetic moment is not sum of nucleon magnetic moments, this property being assigned to the tensorial character of the nuclear force, such as in the case of the most simple nucleus where both proton and neutron appear, namely deuterium nucleus, deuteron. Measurement methods The methods for measuring nuclear magnetic moments can be divided into two broad groups in regard to the interaction with internal or external applied fields. Generally the methods based on external fields are more accurate.",
                    "score": 0.8760514855384827
                },
                {
                    "id": 9183027,
                    "contents": "Spin magnetic moment\nSee also Nuclear magneton Pauli exclusion principle Nuclear magnetic resonance Multipole expansion Relativistic quantum mechanics Magnetic spin vortex disc Footnotes References Selected books Hans Kopfermann Kernmomente and ''Nuclear Momenta (Akademische Verl., 1940, 1956, and Academic Press, 1958) Selected papers External links An Introduction to the Electronic Structure of Atoms and Molecules by Dr. Richard F.W. Bader (McMaster University) Magnetism Rotational symmetry Spintronics",
                    "score": 0.875893771648407
                },
                {
                    "id": 3061211,
                    "contents": "Permeability (electromagnetism)\nIn electromagnetism, permeability is the measure of magnetization that a material obtains in response to an applied magnetic field. Permeability is typically represented by the (italicized) Greek letter μ. The term was coined in September 1885 by Oliver Heaviside. The reciprocal of permeability is magnetic reluctivity. In SI units, permeability is measured in henries per meter (H/m), or equivalently in newtons per ampere squared (N/A2). The permeability constant μ0, also known as the magnetic constant or the permeability of free space, is the proportionality between magnetic induction and magnetizing force when forming a magnetic field in a classical vacuum. A closely related property of materials is magnetic susceptibility, which is a dimensionless proportionality factor that indicates the degree of magnetization of a material in response to an applied magnetic field.",
                    "score": 0.8750075101852417
                },
                {
                    "id": 3061217,
                    "contents": "Permeability (electromagnetism)\nThe magnetic moment induced by the applied field is linear in the field strength and rather weak. It typically requires a sensitive analytical balance to detect the effect. Unlike ferromagnets, paramagnets do not retain any magnetization in the absence of an externally applied magnetic field, because thermal motion causes the spins to become randomly oriented without it. Thus the total magnetization will drop to zero when the applied field is removed. Even in the presence of the field, there is only a small induced magnetization because only a small fraction of the spins will be oriented by the field. This fraction is proportional to the field strength and this explains the linear dependency. The attraction experienced by ferromagnets is non-linear and much stronger so that it is easily observed, for instance, in magnets on one's refrigerator.",
                    "score": 0.8749187588691711
                },
                {
                    "id": 16459877,
                    "contents": "Nuclear magnetic resonance\nAs noted above, the sensitivity of nuclear magnetic resonance signals is also dependent on the presence of a magnetically susceptible nuclide and, therefore, either on the natural abundance of such nuclides or on the ability of the experimentalist to artificially enrich the molecules, under study, with such nuclides. The most abundant naturally occurring isotopes of hydrogen and phosphorus (for example) are both magnetically susceptible and readily useful for nuclear magnetic resonance spectroscopy. In contrast, carbon and nitrogen have useful isotopes but which occur only in very low natural abundance.",
                    "score": 0.8747912645339966
                },
                {
                    "id": 18219499,
                    "contents": "Curie's law\nFor many paramagnetic materials, the magnetization of the material is directly proportional to an applied magnetic field, for sufficiently high temperatures and small fields. However, if the material is heated, this proportionality is reduced. For a fixed value of the field, the magnetic susceptibility is inversely proportional to temperature, that is where is the (volume) magnetic susceptibility, is the magnitude of the resulting magnetization (A/m), is the magnitude of the applied magnetic field (A/m), is absolute temperature (K), is a material-specific Curie constant (K).",
                    "score": 0.874789834022522
                },
                {
                    "id": 22831383,
                    "contents": "Index of physics articles (M)\nMagnetic domain Magnetic effective resistance Magnetic energy Magnetic evaporative cooling Magnetic field Magnetic field intensity Magnetic field viewing film Magnetic flow meter Magnetic flux Magnetic flux quantum Magnetic force microscope Magnetic form factor Magnetic helicity Magnetic hyperthermia Magnetic impedance Magnetic impurity Magnetic inductance Magnetic inductive coil Magnetic ionic liquid Magnetic isotope effect Magnetic lattice (accelerator) Magnetic lens Magnetic levitation Magnetic mirror Magnetic mirror point Magnetic moment Magnetic monopole Magnetic nanoparticles Magnetic particle imaging Magnetic photon Magnetic pole strength Magnetic pressure Magnetic properties Magnetic property Magnetic quantum number Magnetic reactance Magnetic reconnection Magnetic refrigeration Magnetic reluctance Magnetic resonance force microscopy Magnetic resonance imaging Magnetic sail Magnetic scalar potential Magnetic semiconductor Magnetic separation Magnetic structure",
                    "score": 0.8747023344039917
                },
                {
                    "id": 3461479,
                    "contents": "Magnetic moment\nThe magnetic moment is the magnetic strength and orientation of a magnet or other object that produces a magnetic field. Examples of objects that have magnetic moments include: loops of electric current (such as electromagnets), permanent magnets, elementary particles (such as electrons), various molecules, and many astronomical objects (such as many planets, some moons, stars, etc). More precisely, the term magnetic moment normally refers to a system's magnetic dipole moment, the component of the magnetic moment that can be represented by an equivalent magnetic dipole: a magnetic north and south pole separated by a very small distance. The magnetic dipole component is sufficient for small enough magnets or for large enough distances. Higher-order terms (such as the magnetic quadrupole moment) may be needed in addition to the dipole moment for extended objects.",
                    "score": 0.8745941519737244
                },
                {
                    "id": 358188,
                    "contents": "Magnetic susceptibility\nExperimental measurement Volume magnetic susceptibility is measured by the force change felt upon a substance when a magnetic field gradient is applied. Early measurements are made using the Gouy balance where a sample is hung between the poles of an electromagnet. The change in weight when the electromagnet is turned on is proportional to the susceptibility. Today, high-end measurement systems use a superconductive magnet. An alternative is to measure the force change on a strong compact magnet upon insertion of the sample. This system, widely used today, is called the Evans balance. For liquid samples, the susceptibility can be measured from the dependence of the NMR frequency of the sample on its shape or orientation. Another method using NMR techniques measures the magnetic field distortion around a sample immersed in water inside an MR scanner. This method is highly accurate for diamagnetic materials with susceptibilities similar to water.",
                    "score": 0.8743956685066223
                },
                {
                    "id": 26575074,
                    "contents": "Field effect (chemistry)\nReferences Chemical properties Chemistry Electrostatics Electromagnetism Matter Molecular physics Molecules Physical chemistry",
                    "score": 0.8743839859962463
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_32",
        "question": "A particle of mass $1.0 \\mathrm{~g}$ is released near the surface of the Earth, where the acceleration of free fall is $g=8.91 \\mathrm{~m} \\mathrm{~s}^{-2}$. What will be its kinetic energy after  $1.0 \\mathrm{~s}$. Ignore air resistance?",
        "golden_answers": [
            "48"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1853025,
                    "contents": "Mass\nSometime prior to 1638, Galileo turned his attention to the phenomenon of objects in free fall, attempting to characterize these motions. Galileo was not the first to investigate Earth's gravitational field, nor was he the first to accurately describe its fundamental characteristics. However, Galileo's reliance on scientific experimentation to establish physical principles would have a profound effect on future generations of scientists. It is unclear if these were just hypothetical experiments used to illustrate a concept, or if they were real experiments performed by Galileo, but the results obtained from these experiments were both realistic and compelling. A biography by Galileo's pupil Vincenzo Viviani stated that Galileo had dropped balls of the same material, but different masses, from the Leaning Tower of Pisa to demonstrate that their time of descent was independent of their mass. In support of this conclusion, Galileo had advanced the following theoretical argument: He",
                    "score": 0.8942195177078247
                },
                {
                    "id": 1853006,
                    "contents": "Mass\nActive gravitational mass is a measure of the strength of an object's gravitational flux (gravitational flux is equal to the surface integral of gravitational field over an enclosing surface). Gravitational field can be measured by allowing a small \"test object\" to fall freely and measuring its free-fall acceleration. For example, an object in free-fall near the Moon is subject to a smaller gravitational field, and hence accelerates more slowly, than the same object would if it were in free-fall near the Earth. The gravitational field near the Moon is weaker because the Moon has less active gravitational mass.",
                    "score": 0.8893599510192871
                },
                {
                    "id": 1853010,
                    "contents": "Mass\nThe force known as \"weight\" is proportional to mass and acceleration in all situations where the mass is accelerated away from free fall. For example, when a body is at rest in a gravitational field (rather than in free fall), it must be accelerated by a force from a scale or the surface of a planetary body such as the Earth or the Moon. This force keeps the object from going into free fall. Weight is the opposing force in such circumstances and is thus determined by the acceleration of free fall. On the surface of the Earth, for example, an object with a mass of 50 kilograms weighs 491 newtons, which means that 491 newtons is being applied to keep the object from going into free fall. By contrast, on the surface of the Moon, the same object still has a mass of 50 kilograms but weighs only 81.5 newtons, because only 81.5 newtons is required to keep this object from going into a free fall on the moon. Restated in mathematical terms, on the surface of the Earth, the weight W of an",
                    "score": 0.8807584643363953
                },
                {
                    "id": 1853015,
                    "contents": "Mass\nGiven this force, the acceleration of the object can be determined by Newton's second law: Putting these together, the gravitational acceleration is given by: This says that the ratio of gravitational to inertial mass of any object is equal to some constant K if and only if all objects fall at the same rate in a given gravitational field. This phenomenon is referred to as the \"universality of free-fall\". In addition, the constant K can be taken as 1 by defining our units appropriately.",
                    "score": 0.8803164958953857
                },
                {
                    "id": 1853029,
                    "contents": "Mass\nGalileo found that for an object in free fall, the distance that the object has fallen is always proportional to the square of the elapsed time: Galileo had shown that objects in free fall under the influence of the Earth's gravitational field have a constant acceleration, and Galileo's contemporary, Johannes Kepler, had shown that the planets follow elliptical paths under the influence of the Sun's gravitational mass. However, Galileo's free fall motions and Kepler's planetary motions remained distinct during Galileo's lifetime. Newtonian mass",
                    "score": 0.8801447749137878
                },
                {
                    "id": 6089837,
                    "contents": "Free-fall time\n, where the volume of a sphere is: Let us assume that the only force acting is gravity. Then, as first demonstrated by Newton, and can easily be demonstrated using the divergence theorem, the acceleration of gravity at any given distance from the center of the sphere depends only upon the total mass contained within . The consequence of this result is that if one imagined breaking the sphere up into a series of concentric shells, each shell would collapse only subsequent to the shells interior to it, and no shells cross during collapse. As a result, the free-fall time of a massless particle at can be expressed solely in terms of the total mass interior to it. In terms of the average density interior to , the free-fall time is where the latter is in SI units. This result is exactly the same as from the previous section when :.",
                    "score": 0.8793274164199829
                },
                {
                    "id": 7108931,
                    "contents": "Gravitational acceleration\nIn physics, gravitational acceleration is the acceleration of an object in free fall within a vacuum (and thus without experiencing drag). This is the steady gain in speed caused exclusively by the force of gravitational attraction. All bodies accelerate in vacuum at the same rate, regardless of the masses or compositions of the bodies; the measurement and analysis of these rates is known as gravimetry. At a fixed point on the surface, the magnitude of gravity of Earth results from combined effect of gravitation and the centrifugal force (from the Earth's rotation). At different points on Earth's surface, the free fall acceleration ranges from to depending on altitude, latitude, and longitude. A conventional standard value is defined exactly as 9.80665 m/s2 (approximately 32.17405 ft/s2). Locations of significant variation from this value are known as gravity anomalies. This does not take into account other effects, such as buoyancy or drag. Relation to the Universal Law",
                    "score": 0.8789715766906738
                },
                {
                    "id": 20867983,
                    "contents": "Galileo Galilei\nGalileo proposed that a falling body would fall with a uniform acceleration, as long as the resistance of the medium through which it was falling remained negligible, or in the limiting case of its falling through a vacuum. He also derived the correct kinematical law for the distance travelled during a uniform acceleration starting from rest—namely, that it is proportional to the square of the elapsed time (d∝t2). Prior to Galileo, Nicole Oresme, in the 14th century, had derived the times-squared law for uniformly accelerated change, and Domingo de Soto had suggested in the 16th century that bodies falling through a homogeneous medium would be uniformly accelerated. Soto, however, did not anticipate many of the qualifications and refinements contained in Galileo's theory of falling bodies. He did not, for instance, recognise, as Galileo did, that a body would fall with a strictly uniform acceleration only in a vacuum, and that it would otherwise eventually reach a uniform terminal",
                    "score": 0.877967119216919
                },
                {
                    "id": 858989,
                    "contents": "Free fall\nNear the surface of the Earth, an object in free fall in a vacuum will accelerate at approximately 9.8 m/s2, independent of its mass. With air resistance acting on an object that has been dropped, the object will eventually reach a terminal velocity, which is around 53 m/s (190 km/h or 118 mph) for a human skydiver. The terminal velocity depends on many factors including mass, drag coefficient, and relative surface area and will only be achieved if the fall is from sufficient altitude. A typical skydiver in a spread-eagle position will reach terminal velocity after about 12 seconds, during which time they will have fallen around 450 m (1,500 ft).",
                    "score": 0.8779174089431763
                },
                {
                    "id": 7438014,
                    "contents": "Niccolò Cabeo\nHe is noted for his contributions to physics experiments and observations. He observed the experiments of Giovanni Battista Baliani regarding falling objects, and he wrote about these experiments noting that two different objects fall in the same amount of time regardless of the medium. He also performed experiments with pendulums and observed that an electrically charged body can attract non-electrified objects. He also noted that two charged objects repelled each other.",
                    "score": 0.877039909362793
                },
                {
                    "id": 1106244,
                    "contents": "Timeline of classical mechanics\n1500-1528 - Al-Birjandi develops the theory of \"circular inertia\" to explain Earth's rotation 16th century - Francesco Beato and Luca Ghini experimentally contradict Aristotelian view on free fall. 16th century - Domingo de Soto suggests that bodies falling through a homogeneous medium are uniformly accelerated. Soto, however, did not anticipate many of the qualifications and refinements contained in Galileo's theory of falling bodies. He did not, for instance, recognise, as Galileo did, that a body would fall with a strictly uniform acceleration only in a vacuum, and that it would otherwise eventually reach a uniform terminal velocity 1581 - Galileo Galilei notices the timekeeping property of the pendulum 1589 - Galileo Galilei uses balls rolling on inclined planes to show that different weights fall with the same acceleration",
                    "score": 0.8761262893676758
                },
                {
                    "id": 6089831,
                    "contents": "Free-fall time\nThe free-fall time is the characteristic time that would take a body to collapse under its own gravitational attraction, if no other forces existed to oppose the collapse. As such, it plays a fundamental role in setting the timescale for a wide variety of astrophysical processes—from star formation to helioseismology to supernovae—in which gravity plays a dominant role. Derivation",
                    "score": 0.874656617641449
                },
                {
                    "id": 858991,
                    "contents": "Free fall\nwhere is the initial velocity (m/s). is the vertical velocity with respect to time (m/s). is the initial altitude (m). is the altitude with respect to time (m). is time elapsed (s). is the acceleration due to gravity (9.81 m/s2 near the surface of the earth). If the initial velocity is zero, then the distance fallen from the initial position will grow as the square of the elapsed time. Moreover, because the odd numbers sum to the perfect squares, the distance fallen in successive time intervals grows as the odd numbers. This description of the behavior of falling bodies was given by Galileo. Uniform gravitational field with air resistance This case, which applies to skydivers, parachutists or any body of mass, , and cross-sectional area, , with Reynolds number well above the critical Reynolds number, so that the air resistance is proportional to the square of the fall velocity, , has an equation of motion",
                    "score": 0.8746493458747864
                },
                {
                    "id": 10363953,
                    "contents": "Proper acceleration\nin such a fall or generally any such ballistic path (also called inertial motion), including objects in orbit, experience no proper acceleration (neglecting small tidal accelerations for inertial paths in gravitational fields). This state is also known as \"zero gravity\" (\"zero-g\") or \"free-fall,\" and it produces a sensation of weightlessness.",
                    "score": 0.8736449480056763
                },
                {
                    "id": 858993,
                    "contents": "Free fall\nwhere the terminal speed is given by The object's speed versus time can be integrated over time to find the vertical position as a function of time: Using the figure of 56 m/s for the terminal velocity of a human, one finds that after 10 seconds he will have fallen 348 metres and attained 94% of terminal velocity, and after 12 seconds he will have fallen 455 metres and will have attained 97% of terminal velocity. However, when the air density cannot be assumed to be constant, such as for objects falling from high altitude, the equation of motion becomes much more difficult to solve analytically and a numerical simulation of the motion is usually necessary. The figure shows the forces acting on meteoroids falling through the Earth's upper atmosphere. HALO jumps, including Joe Kittinger's and Felix Baumgartner's record jumps, also belong in this category.",
                    "score": 0.871982753276825
                },
                {
                    "id": 858982,
                    "contents": "Free fall\nIn Newtonian physics, free fall is any motion of a body where gravity is the only force acting upon it. In the context of general relativity, where gravitation is reduced to a space-time curvature, a body in free fall has no force acting on it. An object in the technical sense of the term \"free fall\" may not necessarily be falling down in the usual sense of the term. An object moving upwards might not normally be considered to be falling, but if it is subject to only the force of gravity, it is said to be in free fall. The Moon is thus in free fall around the Earth, though its orbital speed keeps it in very far orbit from the Earth's surface.",
                    "score": 0.8718842267990112
                },
                {
                    "id": 858992,
                    "contents": "Free fall\nwhere is the air density and is the drag coefficient, assumed to be constant although in general it will depend on the Reynolds number. Assuming an object falling from rest and no change in air density with altitude, the solution is: where the terminal speed is given by The object's speed versus time can be integrated over time to find the vertical position as a function of time:",
                    "score": 0.8696058392524719
                },
                {
                    "id": 25700085,
                    "contents": "Gladys Mackenzie\nAlpha particles Gladys Mackenzie was a scholar at the University of Bristol from 1929 to 1930 before becoming a Research Fellow. From the beginning of her time at the University of Bristol in 1929 to her resignation in 1947, Mackenzie conducted her most note-worthy research. She started by researching methods of measuring the ranges of alpha particles. She tested ranges of alpha particles at varying initial velocities as they travelled through gases such as air, oxygen, nitrogen, argon and hydrogen and observed the stopping power of these gases as the particles travelled through them. She discovered a relationship between the range of the alpha particles and its initial velocity and proved that the theory of Gaunt for the stopping power of hydrogen atoms is also applicable for molecular hydrogen. This research was published in 1930.",
                    "score": 0.869472324848175
                },
                {
                    "id": 1716780,
                    "contents": "Force\nGravitational What we now call gravity was not identified as a universal force until the work of Isaac Newton. Before Newton, the tendency for objects to fall towards the Earth was not understood to be related to the motions of celestial objects. Galileo was instrumental in describing the characteristics of falling objects by determining that the acceleration of every object in free-fall was constant and independent of the mass of the object. Today, this acceleration due to gravity towards the surface of the Earth is usually designated as and has a magnitude of about 9.81 meters per second squared (this measurement is taken from sea level and may vary depending on location), and points toward the center of the Earth. This observation means that the force of gravity on an object at the Earth's surface is directly proportional to the object's mass. Thus an object that has a mass of will experience a force:",
                    "score": 0.8690323829650879
                },
                {
                    "id": 1853011,
                    "contents": "Mass\nonly 81.5 newtons, because only 81.5 newtons is required to keep this object from going into a free fall on the moon. Restated in mathematical terms, on the surface of the Earth, the weight W of an object is related to its mass m by , where is the acceleration due to Earth's gravitational field, (expressed as the acceleration experienced by a free-falling object).",
                    "score": 0.8683313131332397
                },
                {
                    "id": 2528817,
                    "contents": "Implosion (mechanical process)\nImplosion is a process in which objects are destroyed by collapsing (or being squeezed in) on themselves. The opposite of explosion (which expands the volume), implosion reduces the volume occupied and concentrates matter and energy. True implosion usually involves a difference between internal (lower) and external (higher) pressure, or inward and outward forces, that is so large that the structure collapses inward into itself, or into the space it occupied if it is not a completely solid object. Examples of implosion include a submarine being crushed from the outside by the hydrostatic pressure of the surrounding water, and the collapse of a massive star under its own gravitational pressure.",
                    "score": 0.8680757284164429
                },
                {
                    "id": 858983,
                    "contents": "Free fall\nIn a roughly uniform gravitational field, in the absence of any other forces, gravitation acts on each part of the body roughly equally. When there is no normal force exerted between a body (e.g. an astronaut in orbit) and its surrounding objects, it will result in the sensation of weightlessness, a condition that also occurs when the gravitational field is weak (such as when far away from any source of gravity). The term \"free fall\" is often used more loosely than in the strict sense defined above. Thus, falling through an atmosphere without a deployed parachute, or lifting device, is also often referred to as free fall. The aerodynamic drag forces in such situations prevent them from producing full weightlessness, and thus a skydiver's \"free fall\" after reaching terminal velocity produces the sensation of the body's weight being supported on a cushion of air.",
                    "score": 0.867899477481842
                },
                {
                    "id": 164187,
                    "contents": "Two New Sciences\nThe law of falling bodies While Aristotle had observed that heavier objects fall more quickly than lighter ones, in Two New Sciences Galileo postulated that this was due not to inherently stronger forces acting on the heavier objects, but to the countervailing forces of air resistance and friction. To compensate, he conducted experiments using a shallowly inclined ramp, smoothed so as to eliminate as much friction as possible, on which he rolled down balls of different weights. In this manner, he was able to provide empirical evidence that matter accelerates vertically downward at a constant rate, regardless of mass, due to the effects of gravity.",
                    "score": 0.8669809103012085
                },
                {
                    "id": 799813,
                    "contents": "Marin Mersenne\nHe also performed extensive experiments to determine the acceleration of falling objects by comparing them with the swing of pendulums, reported in his Cogitata Physico-Mathematica in 1644. He was the first to measure the length of the seconds pendulum, that is a pendulum whose swing takes one second, and the first to observe that a pendulum's swings are not isochronous as Galileo thought, but that large swings take longer than small swings.",
                    "score": 0.8666086792945862
                },
                {
                    "id": 8734830,
                    "contents": "History of gravitational theory\nBy 1544, according to Benedetto Varchi, the experiments of at least two Italians had dispelled the Aristotelian claim that objects fall proportionately to their weight. In 1551, Domingo de Soto suggested that objects in free fall accelerate uniformly. This idea was subsequently explored in more detail by Galileo Galilei, who derived his kinematics from the 14th-century Merton College and Jean Buridan, and possibly De Soto as well. Galileo successfully applied mathematics to the acceleration of falling objects, correctly hypothesizing in a 1604 letter to Paolo Sarpi that the distance of a falling object is proportional to the square of the time elapsed. Galileo suggested in his Two New Sciences (1638) that the slight variance of speed of falling objects of different mass was due to air resistance, and that objects would fall completely uniformly in a vacuum.",
                    "score": 0.8664847612380981
                },
                {
                    "id": 8228200,
                    "contents": "Giambattista Benedetti\nScience of motion In his works Resolutio omnium Euclidis problematum (1553) and Demonstratio proportionum motuum localium (1554), Benedetti proposed a new doctrine of the speed of bodies in free fall. The accepted Aristotelian doctrine at that time was that the speed of a freely falling body is directly proportional to the total weight of the body and inversely proportional to the density of the medium. Benedetti's view was that the speed depends on just the difference between the specific gravity of the body and that of the medium. As opposed to the Aristotelian theory, his theory predicts that two objects of the same material but of different weights would fall at the same speed, and also that objects of different materials in a vacuum would fall at different though finite speeds.",
                    "score": 0.8658424615859985
                },
                {
                    "id": 1861950,
                    "contents": "Mechanics\nOften cited as father to modern science, Galileo brought together the ideas of other great thinkers of his time and began to calculate motion in terms of distance travelled from some starting position and the time that it took. He showed that the speed of falling objects increases steadily during the time of their fall. This acceleration is the same for heavy objects as for light ones, provided air friction (air resistance) is discounted. The English mathematician and physicist Isaac Newton improved this analysis by defining force and mass and relating these to acceleration. For objects traveling at speeds close to the speed of light, Newton's laws were superseded by Albert Einstein's theory of relativity. [A sentence illustrating the computational complication of Einstein's theory of relativity.] For atomic and subatomic particles, Newton's laws were superseded by quantum theory. For everyday phenomena, however, Newton's three laws of motion remain the cornerstone of dynamics, which",
                    "score": 0.865615963935852
                },
                {
                    "id": 8735156,
                    "contents": "Equations for a falling body\nThe equations ignore air resistance, which has a dramatic effect on objects falling an appreciable distance in air, causing them to quickly approach a terminal velocity. The effect of air resistance varies enormously depending on the size and geometry of the falling object—for example, the equations are hopelessly wrong for a feather, which has a low mass but offers a large resistance to the air. (In the absence of an atmosphere all objects fall at the same rate, as astronaut David Scott demonstrated by dropping a hammer and a feather on the surface of the Moon.) The equations also ignore the rotation of the Earth, failing to describe the Coriolis effect for example. Nevertheless, they are usually accurate enough for dense and compact objects falling over heights not exceeding the tallest man-made structures. Overview",
                    "score": 0.8656051158905029
                },
                {
                    "id": 1853017,
                    "contents": "Mass\nThe universality of free-fall only applies to systems in which gravity is the only acting force. All other forces, especially friction and air resistance, must be absent or at least negligible. For example, if a hammer and a feather are dropped from the same height through the air on Earth, the feather will take much longer to reach the ground; the feather is not really in free-fall because the force of air resistance upwards against the feather is comparable to the downward force of gravity. On the other hand, if the experiment is performed in a vacuum, in which there is no air resistance, the hammer and the feather should hit the ground at exactly the same time (assuming the acceleration of both objects towards each other, and of the ground towards both objects, for its own part, is negligible). This can easily be done in a high school laboratory by dropping the objects in transparent tubes that have the air removed with a vacuum pump. It is even more dramatic when done in an",
                    "score": 0.8655330538749695
                },
                {
                    "id": 11681920,
                    "contents": "Earth mass\nMass loss is due to atmospheric escape of gases. About 95,000 tons of hydrogen per year () and 1,600 tons of helium per year are lost through atmospheric escape. The main factor in mass gain is in-falling material, cosmic dust, meteors, etc. are the most significant contributors to Earth's increase in mass. The sum of material is estimated to be annually, although this can vary significantly; to take an extreme example, the Chicxulub impactor, with a midpoint mass estimate of , added 900 million times that annual dustfall amount to the Earth's mass in a single event. Additional changes in mass are due to the mass–energy equivalence principle, although these changes are relatively negligible. Mass loss due to the combination of nuclear fission and natural radioactive decay is estimated to amount to 16 tons per year.",
                    "score": 0.8639060258865356
                },
                {
                    "id": 1861938,
                    "contents": "Mechanics\nInfluenced by earlier writers such as Ibn Sina and al-Baghdaadi, the 14th-century French priest Jean Buridan developed the theory of impetus, which later developed into the modern theories of inertia, velocity, acceleration and momentum. This work and others was developed in 14th-century England by the Oxford Calculators such as Thomas Bradwardine, who studied and formulated various laws regarding falling bodies. The concept that the main properties of a body are uniformly accelerated motion (as of falling bodies) was worked out by the 14th-century Oxford Calculators. Early modern age Two central figures in the early modern age are Galileo Galilei and Isaac Newton. Galileo's final statement of his mechanics, particularly of falling bodies, is his Two New Sciences (1638). Newton's 1687 Philosophiæ Naturalis Principia Mathematica provided a detailed mathematical account of mechanics, using the newly developed mathematics of calculus and providing the basis of Newtonian mechanics.",
                    "score": 0.8621100783348083
                },
                {
                    "id": 17886948,
                    "contents": "Specific force\nSpecific force is defined as the non-gravitational force per unit mass. Specific force (also called g-force and mass-specific force) is measured in meters/second² (m·s−2) which is the units for acceleration. Thus, specific force is not actually a force, but a type of acceleration. However, the (mass-)specific force is not a coordinate-acceleration, but rather a proper acceleration, which is the acceleration relative to free-fall. Forces, specific forces, and proper accelerations are the same in all reference frames, but coordinate accelerations are frame-dependent. For free bodies, the specific force is the cause of, and a measure of, the body's proper acceleration.",
                    "score": 0.8618937730789185
                },
                {
                    "id": 1762696,
                    "contents": "History of physics\nHibat Allah Abu'l-Barakat al-Baghdaadi (c. 1080-1165) adopted and modified Ibn Sina's theory on projectile motion. In his Kitab al-Mu'tabar, Abu'l-Barakat stated that the mover imparts a violent inclination (mayl qasri) on the moved and that this diminishes as the moving object distances itself from the mover. He also proposed an explanation of the acceleration of falling bodies by the accumulation of successive increments of power with successive increments of velocity. According to Shlomo Pines, al-Baghdaadi's theory of motion was \"the oldest negation of Aristotle's fundamental dynamic law [namely, that a constant force produces a uniform motion], [and is thus an] anticipation in a vague fashion of the fundamental law of classical mechanics [namely, that a force applied continuously produces acceleration].\" Jean Buridan and Albert of Saxony later referred to Abu'l-Barakat in explaining that the acceleration of a falling body is a result of its increasing impetus.",
                    "score": 0.8616724610328674
                },
                {
                    "id": 22064958,
                    "contents": "Impact survival\nRecent experiments have found organisms that can survive both the acceleration and jerk involved in reaching escape velocity. A major impact event was simulated using an air cannon to propel both ice and agar projectiles covered with chosen microorganisms to extreme speeds and then crashing the projectiles into a solid surface. Two species of bacteria were tested - R. erythropolis and B. subtilis - and while survival rates were low, at 100 GPa of peak pressure there was still a survival rate of 3.9x10−5 in the B. subtilis. These findings have been replicated with other bacteria as well - D. radiodurans as well as when shot into liquid water - with similar low, but not zero, survival rates. Also, experimental methods have been varied, and survival rates have also been found when bacteria are subjected to acceleration at an extended time, through the use of a centrifuge as well as when shot into liquid water. While very small, these finite results show that some lifeforms could",
                    "score": 0.8616040945053101
                },
                {
                    "id": 8420665,
                    "contents": "Gravitational metric system\nMass The hyl, metric slug (mug), or TME (), is the mass that accelerates at 1 m/s2 under a force of 1 kgf. The hyl has also been used as the unit of mass in a metre–gram-force–second (mgfs) system. 1 TME = 1 kp / 1 m/s2 = 1 kp⋅s2/m = 1 hyl = 1 kp⋅s2/m = or 1 hyl (alternate definition – mgfs) = 1 p⋅s2/m = Pressure The gravitational unit of pressure is the technical atmosphere (at). It is the gravitational force of one kilogram, i.e. 1 kgf, exerted on an area of one square centimetre. 1 at = 1 kp/cm2 = 10 000 × gn kg/m2 = 98 066.5 kg/(m⋅s2) = 98.066 5 kPa Energy There is no dedicated name for the unit of energy, \"metre\" is simply appended to \"kilopond\", but usually the symbol of the kilopond-metre is written without the middle dot. 1 kpm = 1 kp⋅m = gn kg⋅m = 9.806 65 kg⋅m2/s2 = 9.806 65 J",
                    "score": 0.8615871667861938
                },
                {
                    "id": 6180587,
                    "contents": "Drag (physics)\nWhere is the wind speed and is the object speed (both relative to ground). Velocity of a falling object The velocity as a function of time for an object falling through a non-dense medium, and released at zero relative-velocity v = 0 at time t = 0, is roughly given by a function involving a hyperbolic tangent (tanh): The hyperbolic tangent has a limit value of one, for large time t. In other words, velocity asymptotically approaches a maximum value called the terminal velocity vt: For an object falling and released at relative-velocity v = vi at time t = 0, with vi < vt, is also defined in terms of the hyperbolic tangent function: For vi > vt, the velocity function is defined in terms of the hyperbolic cotangent function: The hyperbolic cotangent has also a limit value of one, for large time t. Velocity asymptotically tends to the terminal velocity vt, strictly from above vt. For vi = vt, the velocity is constant:",
                    "score": 0.861514151096344
                },
                {
                    "id": 8924308,
                    "contents": "Specific kinetic energy\nSpecific kinetic energy is kinetic energy of an object per unit of mass. It is defined as . Where is the specific kinetic energy and is velocity. It has units of J/kg, which is equivalent to m2/s2. Energy (physics)",
                    "score": 0.8614006638526917
                },
                {
                    "id": 1396328,
                    "contents": "Gravity\nIn the mid-16th century, various Europeans experimentally disproved the Aristotelian notion that heavier objects fall at a faster rate. The mid-16th century Italian physicist Giambattista Benedetti published papers claiming that, due to specific gravity, objects of the same material but different weights would fall at the same speed. With the 1586 Delft tower experiment the Flemish physicist Simon Stevin demonstrated that, when dropped from a tower, two cannonballs of differing sizes and weights would in fact reach the ground at the same time. In the late 16th century, Galileo Galilei demonstrated the premise (perhaps as a thought experiment) that two balls of different weights dropped from a tower would fall at the same rate. Combining this knowledge with careful measurements of balls rolling down inclines, Galileo firmly established that gravitational acceleration is the same for all objects. Galileo postulated that air resistance is the reason that objects with a low density and",
                    "score": 0.8612025380134583
                },
                {
                    "id": 8734828,
                    "contents": "History of gravitational theory\nEuropean Renaissance In the 14th century, both the French philosopher Jean Buridan and the Merton College of Oxford rejected the Aristotelian concept of gravity. They attributed the motion of objects to an impetus (akin to momentum), which varies according to velocity and mass; Buridan was influenced in this by Ibn Sina's Book of Healing. Buridan and the philosopher Albert of Saxony (c. 1320–1390) adopted Abu'l-Barakat's theory that the acceleration of a falling body is a result of its increasing impetus. Influenced by Buridan, Albert developed a law of proportion regarding the relationship between the speed of an object in free fall and the time elapsed. He also theorized that mountains and valleys are caused by erosion—displacing the Earth's centre of gravity. Also in that century, the Merton College developed the mean speed theorem, which was proved by Nicole Oresme (c. 1323–1382) and would be influential in later gravitational equations.",
                    "score": 0.8607928156852722
                },
                {
                    "id": 3384862,
                    "contents": "Micro-g environment\nCompare the gravitational potential at some of these locations. Free fall What remains is a micro-g environment moving in free fall, i.e. there are no forces other than gravity acting on the people or objects in this environment. To prevent air drag making the free fall less perfect, objects and people can free-fall in a capsule that itself, while not necessarily in free fall, is accelerated as in free fall. This can be done by applying a force to compensate for air drag. Alternatively free fall can be carried out in space, or in a vacuum tower or shaft. Two cases can be distinguished: Temporary micro-g, where after some time the Earth's surface is or would be reached, and indefinite micro-g.",
                    "score": 0.8597980737686157
                },
                {
                    "id": 13270280,
                    "contents": "Clinostat\nAn alternative to the clinostat for simulating microgravity is the free fall machine (FFM). Small samples (such as cell suspensions) are allowed to free fall under gravity for about a metre, with the period of free fall lasting just under a second. They are then pushed back to the top of the apparatus by a briefly applied large force (c. 20 g for 20 ms - the \"bounce\"), and allowed to fall again, and so on. The principle of the machine is that most of the time is spent in zero g free fall. The periods spent under high g are assumed to be too short to be detected by the physiological mechanism of the biological samples, which consequently only perceive the time spent in free fall.",
                    "score": 0.8596199154853821
                },
                {
                    "id": 28402335,
                    "contents": "Pauthenier equation\nThe Pauthenier equation states that the maximum charge accumulated by a particle modelled by a small sphere passing through an electric field is given by: where is the permittivity of free space, is the radius of the sphere, is the electric field strength, and is a material dependent constant. For conductors, . For dielectrics: where is the relative permittivity. Low charges on nanoparticles and microparticles are stable over more than 103 second time scales. References Physics theorems",
                    "score": 0.8592915534973145
                },
                {
                    "id": 1106243,
                    "contents": "Timeline of classical mechanics\n1100-1138 - Avempace develops the concept of a fatigue, which according to Shlomo Pines is precursor to Leibnizian idea of force 1100-1165 - Hibat Allah Abu'l-Barakat al-Baghdaadi discovers that force is proportional to acceleration rather than speed, a fundamental law in classical mechanics 1340-1358 - Jean Buridan develops the theory of impetus 14th century - Oxford Calculators and French collaborators prove the mean speed theorem 14th century - Nicole Oresme derives the times-squared law for uniformly accelerated change. Oresme, however, regarded this discovery as a purely intellectual exercise having no relevance to the description of any natural phenomena, and consequently failed to recognise any connection with the motion of accelerating bodies 1500-1528 - Al-Birjandi develops the theory of \"circular inertia\" to explain Earth's rotation 16th century - Francesco Beato and Luca Ghini experimentally contradict Aristotelian view on free fall.",
                    "score": 0.8588880300521851
                },
                {
                    "id": 12437300,
                    "contents": "Aristotelian physics\nIn a relatively dense medium such as water, a heavier body falls faster than a lighter one. This led Aristotle to speculate that the rate of falling is proportional to the weight and inversely proportional to the density of the medium. From his experience with objects falling in water, he concluded that water is approximately ten times denser than air. By weighing a volume of compressed air, Galileo showed that this overestimates the density of air by a factor of forty. From his experiments with inclined planes, he concluded that if friction is neglected, all bodies fall at the same rate (which is also not true, since not only friction but also density of the medium relative to density of the bodies has to be negligible. Aristotle correctly noticed that medium density is a factor but focused on body weight instead of density. Galileo neglected medium density which led him to correct conclusion for vacuum).",
                    "score": 0.8586872816085815
                },
                {
                    "id": 1386942,
                    "contents": "Escape velocity\nThe work needed to move the body over a small distance dr against this force is therefore given by The total work needed to move the body from the surface r0 of the gravitating body to infinity is then In order to do this work to reach infinity, the body's minimal kinetic energy at departure must match this work, so the escape velocity v0 satisfies which results in See also Black hole – an object with an escape velocity greater than the speed of light Characteristic energy (C3) Delta-v budget – speed needed to perform manoeuvres. Gravitational slingshot – a technique for changing trajectory Gravity well List of artificial objects in heliocentric orbit List of artificial objects leaving the Solar System Newton's cannonball Oberth effect – burning propellant deep in a gravity field gives higher change in kinetic energy Two-body problem Notes References External links Escape velocity calculator Web-based numerical escape velocity calculator",
                    "score": 0.8584499955177307
                },
                {
                    "id": 1553372,
                    "contents": "Aristotle\nAristotle's writings on motion remained influential until the Early Modern period. John Philoponus (in the Middle Ages) and Galileo are said to have shown by experiment that Aristotle's claim that a heavier object falls faster than a lighter object is incorrect. A contrary opinion is given by Carlo Rovelli, who argues that Aristotle's physics of motion is correct within its domain of validity, that of objects in the Earth's gravitational field immersed in a fluid such as air. In this system, heavy bodies in steady fall indeed travel faster than light ones (whether friction is ignored, or not), and they do fall more slowly in a denser medium.",
                    "score": 0.8575712442398071
                },
                {
                    "id": 5842318,
                    "contents": "Carl Størmer\nFrom 1903, when Størmer first observed Kristian Birkeland's experimental attempts to explain the aurora borealis, he was fascinated by aurorae and related phenomena. His first work on the subject attempted to model mathematically the paths taken by charged particles perturbed by the influence of a magnetized sphere, and Størmer eventually published over 48 papers on the motion of charged particles. By modeling the problem using differential equations and polar coordinates, Størmer was able to show that the radius of curvature of any particle's path is proportional to the square of its distance from the sphere's center. To solve the resulting differential equations numerically, he used Verlet integration, which is therefore also known as Störmer's method. Ernst Brüche and Willard Harrison Bennett verified experimentally Størmer's predicted particle motions; Bennett called his experimental apparatus \"Störmertron\" in honor of Størmer. Størmer's calculations showed that small variations",
                    "score": 0.8574527502059937
                },
                {
                    "id": 19731199,
                    "contents": "Speed skydiving\nwhere is the mass of the falling object is the acceleration due to gravity (9.8 m/s2) is the drag coefficient (~0.7 for head down position, ~1 for belly-to-earth position) is the density of the fluid through which the object is falling (1.23 kg/m3 for air at sea level, and ~0.99 kg/m3 at the middle of the measurement zone (2200m)) is the projected area of the object, or area cross-section (~0.18 m2 for head down position, ~0.7 for belly-to-earth position) So, for a human in belly-to-earth position ( m2, kg, ) this gives 50.6 m/s, about the terminal velocity of the typical skydiver of 55 m/s.",
                    "score": 0.8573578596115112
                },
                {
                    "id": 164178,
                    "contents": "Two New Sciences\n[274] Air resistance shows itself in two ways: by affecting less dense bodies more and by offering greater resistance to faster bodies. A lead ball will fall slightly faster than an oak ball, but the difference with a stone ball is negligible. However the speed does not go on increasing indefinitely but reaches a maximum. Though at small speeds the effect of air resistance is small, it is greater when considering, say, a ball fired from a cannon. [292] The effect of a projectile hitting a target is reduced if the target is free to move. The velocity of a moving body can overcome that of a larger body if its speed is proportionately greater than the resistance. [310] A cord or chain stretched out is never level but also approximates to a parabola. (But see also catenary.) Additional day: The force of percussion [323] What is the weight of water falling from a bucket hanging on a balance arm onto another bucket suspended to the same arm?",
                    "score": 0.8572108745574951
                },
                {
                    "id": 1162791,
                    "contents": "Particle physics\nSubatomic particles Modern particle physics research is focused on subatomic particles, including atomic constituents, such as electrons, protons, and neutrons (protons and neutrons are composite particles called baryons, made of quarks), that are produced by radioactive and scattering processes; such particles are photons, neutrinos, and muons, as well as a wide range of exotic particles. Dynamics of particles are also governed by quantum mechanics; they exhibit wave–particle duality, displaying particle-like behaviour under certain experimental conditions and wave-like behaviour in others. In more technical terms, they are described by quantum state vectors in a Hilbert space, which is also treated in quantum field theory. Following the convention of particle physicists, the term elementary particles is applied to those particles that are, according to current understanding, presumed to be indivisible and not composed of other particles.",
                    "score": 0.8571071624755859
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_33",
        "question": "A particle of mass $1.0 \\mathrm{~g}$ is released near the surface of the Earth, where the acceleration of free fall is $g=8.91 \\mathrm{~m} \\mathrm{~s}^{-2}$. What will be its kinetic energy after  $1.0 \\mathrm{~s}$. Ignore air resistance?",
        "golden_answers": [
            "48"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1853025,
                    "contents": "Mass\nSometime prior to 1638, Galileo turned his attention to the phenomenon of objects in free fall, attempting to characterize these motions. Galileo was not the first to investigate Earth's gravitational field, nor was he the first to accurately describe its fundamental characteristics. However, Galileo's reliance on scientific experimentation to establish physical principles would have a profound effect on future generations of scientists. It is unclear if these were just hypothetical experiments used to illustrate a concept, or if they were real experiments performed by Galileo, but the results obtained from these experiments were both realistic and compelling. A biography by Galileo's pupil Vincenzo Viviani stated that Galileo had dropped balls of the same material, but different masses, from the Leaning Tower of Pisa to demonstrate that their time of descent was independent of their mass. In support of this conclusion, Galileo had advanced the following theoretical argument: He",
                    "score": 0.8942195177078247
                },
                {
                    "id": 1853006,
                    "contents": "Mass\nActive gravitational mass is a measure of the strength of an object's gravitational flux (gravitational flux is equal to the surface integral of gravitational field over an enclosing surface). Gravitational field can be measured by allowing a small \"test object\" to fall freely and measuring its free-fall acceleration. For example, an object in free-fall near the Moon is subject to a smaller gravitational field, and hence accelerates more slowly, than the same object would if it were in free-fall near the Earth. The gravitational field near the Moon is weaker because the Moon has less active gravitational mass.",
                    "score": 0.8893599510192871
                },
                {
                    "id": 1853010,
                    "contents": "Mass\nThe force known as \"weight\" is proportional to mass and acceleration in all situations where the mass is accelerated away from free fall. For example, when a body is at rest in a gravitational field (rather than in free fall), it must be accelerated by a force from a scale or the surface of a planetary body such as the Earth or the Moon. This force keeps the object from going into free fall. Weight is the opposing force in such circumstances and is thus determined by the acceleration of free fall. On the surface of the Earth, for example, an object with a mass of 50 kilograms weighs 491 newtons, which means that 491 newtons is being applied to keep the object from going into free fall. By contrast, on the surface of the Moon, the same object still has a mass of 50 kilograms but weighs only 81.5 newtons, because only 81.5 newtons is required to keep this object from going into a free fall on the moon. Restated in mathematical terms, on the surface of the Earth, the weight W of an",
                    "score": 0.8807584643363953
                },
                {
                    "id": 1853015,
                    "contents": "Mass\nGiven this force, the acceleration of the object can be determined by Newton's second law: Putting these together, the gravitational acceleration is given by: This says that the ratio of gravitational to inertial mass of any object is equal to some constant K if and only if all objects fall at the same rate in a given gravitational field. This phenomenon is referred to as the \"universality of free-fall\". In addition, the constant K can be taken as 1 by defining our units appropriately.",
                    "score": 0.8803164958953857
                },
                {
                    "id": 1853029,
                    "contents": "Mass\nGalileo found that for an object in free fall, the distance that the object has fallen is always proportional to the square of the elapsed time: Galileo had shown that objects in free fall under the influence of the Earth's gravitational field have a constant acceleration, and Galileo's contemporary, Johannes Kepler, had shown that the planets follow elliptical paths under the influence of the Sun's gravitational mass. However, Galileo's free fall motions and Kepler's planetary motions remained distinct during Galileo's lifetime. Newtonian mass",
                    "score": 0.8801447749137878
                },
                {
                    "id": 6089837,
                    "contents": "Free-fall time\n, where the volume of a sphere is: Let us assume that the only force acting is gravity. Then, as first demonstrated by Newton, and can easily be demonstrated using the divergence theorem, the acceleration of gravity at any given distance from the center of the sphere depends only upon the total mass contained within . The consequence of this result is that if one imagined breaking the sphere up into a series of concentric shells, each shell would collapse only subsequent to the shells interior to it, and no shells cross during collapse. As a result, the free-fall time of a massless particle at can be expressed solely in terms of the total mass interior to it. In terms of the average density interior to , the free-fall time is where the latter is in SI units. This result is exactly the same as from the previous section when :.",
                    "score": 0.8793274164199829
                },
                {
                    "id": 7108931,
                    "contents": "Gravitational acceleration\nIn physics, gravitational acceleration is the acceleration of an object in free fall within a vacuum (and thus without experiencing drag). This is the steady gain in speed caused exclusively by the force of gravitational attraction. All bodies accelerate in vacuum at the same rate, regardless of the masses or compositions of the bodies; the measurement and analysis of these rates is known as gravimetry. At a fixed point on the surface, the magnitude of gravity of Earth results from combined effect of gravitation and the centrifugal force (from the Earth's rotation). At different points on Earth's surface, the free fall acceleration ranges from to depending on altitude, latitude, and longitude. A conventional standard value is defined exactly as 9.80665 m/s2 (approximately 32.17405 ft/s2). Locations of significant variation from this value are known as gravity anomalies. This does not take into account other effects, such as buoyancy or drag. Relation to the Universal Law",
                    "score": 0.8789715766906738
                },
                {
                    "id": 20867983,
                    "contents": "Galileo Galilei\nGalileo proposed that a falling body would fall with a uniform acceleration, as long as the resistance of the medium through which it was falling remained negligible, or in the limiting case of its falling through a vacuum. He also derived the correct kinematical law for the distance travelled during a uniform acceleration starting from rest—namely, that it is proportional to the square of the elapsed time (d∝t2). Prior to Galileo, Nicole Oresme, in the 14th century, had derived the times-squared law for uniformly accelerated change, and Domingo de Soto had suggested in the 16th century that bodies falling through a homogeneous medium would be uniformly accelerated. Soto, however, did not anticipate many of the qualifications and refinements contained in Galileo's theory of falling bodies. He did not, for instance, recognise, as Galileo did, that a body would fall with a strictly uniform acceleration only in a vacuum, and that it would otherwise eventually reach a uniform terminal",
                    "score": 0.877967119216919
                },
                {
                    "id": 858989,
                    "contents": "Free fall\nNear the surface of the Earth, an object in free fall in a vacuum will accelerate at approximately 9.8 m/s2, independent of its mass. With air resistance acting on an object that has been dropped, the object will eventually reach a terminal velocity, which is around 53 m/s (190 km/h or 118 mph) for a human skydiver. The terminal velocity depends on many factors including mass, drag coefficient, and relative surface area and will only be achieved if the fall is from sufficient altitude. A typical skydiver in a spread-eagle position will reach terminal velocity after about 12 seconds, during which time they will have fallen around 450 m (1,500 ft).",
                    "score": 0.8779174089431763
                },
                {
                    "id": 7438014,
                    "contents": "Niccolò Cabeo\nHe is noted for his contributions to physics experiments and observations. He observed the experiments of Giovanni Battista Baliani regarding falling objects, and he wrote about these experiments noting that two different objects fall in the same amount of time regardless of the medium. He also performed experiments with pendulums and observed that an electrically charged body can attract non-electrified objects. He also noted that two charged objects repelled each other.",
                    "score": 0.877039909362793
                },
                {
                    "id": 1106244,
                    "contents": "Timeline of classical mechanics\n1500-1528 - Al-Birjandi develops the theory of \"circular inertia\" to explain Earth's rotation 16th century - Francesco Beato and Luca Ghini experimentally contradict Aristotelian view on free fall. 16th century - Domingo de Soto suggests that bodies falling through a homogeneous medium are uniformly accelerated. Soto, however, did not anticipate many of the qualifications and refinements contained in Galileo's theory of falling bodies. He did not, for instance, recognise, as Galileo did, that a body would fall with a strictly uniform acceleration only in a vacuum, and that it would otherwise eventually reach a uniform terminal velocity 1581 - Galileo Galilei notices the timekeeping property of the pendulum 1589 - Galileo Galilei uses balls rolling on inclined planes to show that different weights fall with the same acceleration",
                    "score": 0.8761262893676758
                },
                {
                    "id": 6089831,
                    "contents": "Free-fall time\nThe free-fall time is the characteristic time that would take a body to collapse under its own gravitational attraction, if no other forces existed to oppose the collapse. As such, it plays a fundamental role in setting the timescale for a wide variety of astrophysical processes—from star formation to helioseismology to supernovae—in which gravity plays a dominant role. Derivation",
                    "score": 0.874656617641449
                },
                {
                    "id": 858991,
                    "contents": "Free fall\nwhere is the initial velocity (m/s). is the vertical velocity with respect to time (m/s). is the initial altitude (m). is the altitude with respect to time (m). is time elapsed (s). is the acceleration due to gravity (9.81 m/s2 near the surface of the earth). If the initial velocity is zero, then the distance fallen from the initial position will grow as the square of the elapsed time. Moreover, because the odd numbers sum to the perfect squares, the distance fallen in successive time intervals grows as the odd numbers. This description of the behavior of falling bodies was given by Galileo. Uniform gravitational field with air resistance This case, which applies to skydivers, parachutists or any body of mass, , and cross-sectional area, , with Reynolds number well above the critical Reynolds number, so that the air resistance is proportional to the square of the fall velocity, , has an equation of motion",
                    "score": 0.8746493458747864
                },
                {
                    "id": 10363953,
                    "contents": "Proper acceleration\nin such a fall or generally any such ballistic path (also called inertial motion), including objects in orbit, experience no proper acceleration (neglecting small tidal accelerations for inertial paths in gravitational fields). This state is also known as \"zero gravity\" (\"zero-g\") or \"free-fall,\" and it produces a sensation of weightlessness.",
                    "score": 0.8736449480056763
                },
                {
                    "id": 858993,
                    "contents": "Free fall\nwhere the terminal speed is given by The object's speed versus time can be integrated over time to find the vertical position as a function of time: Using the figure of 56 m/s for the terminal velocity of a human, one finds that after 10 seconds he will have fallen 348 metres and attained 94% of terminal velocity, and after 12 seconds he will have fallen 455 metres and will have attained 97% of terminal velocity. However, when the air density cannot be assumed to be constant, such as for objects falling from high altitude, the equation of motion becomes much more difficult to solve analytically and a numerical simulation of the motion is usually necessary. The figure shows the forces acting on meteoroids falling through the Earth's upper atmosphere. HALO jumps, including Joe Kittinger's and Felix Baumgartner's record jumps, also belong in this category.",
                    "score": 0.871982753276825
                },
                {
                    "id": 858982,
                    "contents": "Free fall\nIn Newtonian physics, free fall is any motion of a body where gravity is the only force acting upon it. In the context of general relativity, where gravitation is reduced to a space-time curvature, a body in free fall has no force acting on it. An object in the technical sense of the term \"free fall\" may not necessarily be falling down in the usual sense of the term. An object moving upwards might not normally be considered to be falling, but if it is subject to only the force of gravity, it is said to be in free fall. The Moon is thus in free fall around the Earth, though its orbital speed keeps it in very far orbit from the Earth's surface.",
                    "score": 0.8718842267990112
                },
                {
                    "id": 858992,
                    "contents": "Free fall\nwhere is the air density and is the drag coefficient, assumed to be constant although in general it will depend on the Reynolds number. Assuming an object falling from rest and no change in air density with altitude, the solution is: where the terminal speed is given by The object's speed versus time can be integrated over time to find the vertical position as a function of time:",
                    "score": 0.8696058392524719
                },
                {
                    "id": 25700085,
                    "contents": "Gladys Mackenzie\nAlpha particles Gladys Mackenzie was a scholar at the University of Bristol from 1929 to 1930 before becoming a Research Fellow. From the beginning of her time at the University of Bristol in 1929 to her resignation in 1947, Mackenzie conducted her most note-worthy research. She started by researching methods of measuring the ranges of alpha particles. She tested ranges of alpha particles at varying initial velocities as they travelled through gases such as air, oxygen, nitrogen, argon and hydrogen and observed the stopping power of these gases as the particles travelled through them. She discovered a relationship between the range of the alpha particles and its initial velocity and proved that the theory of Gaunt for the stopping power of hydrogen atoms is also applicable for molecular hydrogen. This research was published in 1930.",
                    "score": 0.869472324848175
                },
                {
                    "id": 1716780,
                    "contents": "Force\nGravitational What we now call gravity was not identified as a universal force until the work of Isaac Newton. Before Newton, the tendency for objects to fall towards the Earth was not understood to be related to the motions of celestial objects. Galileo was instrumental in describing the characteristics of falling objects by determining that the acceleration of every object in free-fall was constant and independent of the mass of the object. Today, this acceleration due to gravity towards the surface of the Earth is usually designated as and has a magnitude of about 9.81 meters per second squared (this measurement is taken from sea level and may vary depending on location), and points toward the center of the Earth. This observation means that the force of gravity on an object at the Earth's surface is directly proportional to the object's mass. Thus an object that has a mass of will experience a force:",
                    "score": 0.8690323829650879
                },
                {
                    "id": 1853011,
                    "contents": "Mass\nonly 81.5 newtons, because only 81.5 newtons is required to keep this object from going into a free fall on the moon. Restated in mathematical terms, on the surface of the Earth, the weight W of an object is related to its mass m by , where is the acceleration due to Earth's gravitational field, (expressed as the acceleration experienced by a free-falling object).",
                    "score": 0.8683313131332397
                },
                {
                    "id": 2528817,
                    "contents": "Implosion (mechanical process)\nImplosion is a process in which objects are destroyed by collapsing (or being squeezed in) on themselves. The opposite of explosion (which expands the volume), implosion reduces the volume occupied and concentrates matter and energy. True implosion usually involves a difference between internal (lower) and external (higher) pressure, or inward and outward forces, that is so large that the structure collapses inward into itself, or into the space it occupied if it is not a completely solid object. Examples of implosion include a submarine being crushed from the outside by the hydrostatic pressure of the surrounding water, and the collapse of a massive star under its own gravitational pressure.",
                    "score": 0.8680757284164429
                },
                {
                    "id": 858983,
                    "contents": "Free fall\nIn a roughly uniform gravitational field, in the absence of any other forces, gravitation acts on each part of the body roughly equally. When there is no normal force exerted between a body (e.g. an astronaut in orbit) and its surrounding objects, it will result in the sensation of weightlessness, a condition that also occurs when the gravitational field is weak (such as when far away from any source of gravity). The term \"free fall\" is often used more loosely than in the strict sense defined above. Thus, falling through an atmosphere without a deployed parachute, or lifting device, is also often referred to as free fall. The aerodynamic drag forces in such situations prevent them from producing full weightlessness, and thus a skydiver's \"free fall\" after reaching terminal velocity produces the sensation of the body's weight being supported on a cushion of air.",
                    "score": 0.867899477481842
                },
                {
                    "id": 164187,
                    "contents": "Two New Sciences\nThe law of falling bodies While Aristotle had observed that heavier objects fall more quickly than lighter ones, in Two New Sciences Galileo postulated that this was due not to inherently stronger forces acting on the heavier objects, but to the countervailing forces of air resistance and friction. To compensate, he conducted experiments using a shallowly inclined ramp, smoothed so as to eliminate as much friction as possible, on which he rolled down balls of different weights. In this manner, he was able to provide empirical evidence that matter accelerates vertically downward at a constant rate, regardless of mass, due to the effects of gravity.",
                    "score": 0.8669809103012085
                },
                {
                    "id": 799813,
                    "contents": "Marin Mersenne\nHe also performed extensive experiments to determine the acceleration of falling objects by comparing them with the swing of pendulums, reported in his Cogitata Physico-Mathematica in 1644. He was the first to measure the length of the seconds pendulum, that is a pendulum whose swing takes one second, and the first to observe that a pendulum's swings are not isochronous as Galileo thought, but that large swings take longer than small swings.",
                    "score": 0.8666086792945862
                },
                {
                    "id": 8734830,
                    "contents": "History of gravitational theory\nBy 1544, according to Benedetto Varchi, the experiments of at least two Italians had dispelled the Aristotelian claim that objects fall proportionately to their weight. In 1551, Domingo de Soto suggested that objects in free fall accelerate uniformly. This idea was subsequently explored in more detail by Galileo Galilei, who derived his kinematics from the 14th-century Merton College and Jean Buridan, and possibly De Soto as well. Galileo successfully applied mathematics to the acceleration of falling objects, correctly hypothesizing in a 1604 letter to Paolo Sarpi that the distance of a falling object is proportional to the square of the time elapsed. Galileo suggested in his Two New Sciences (1638) that the slight variance of speed of falling objects of different mass was due to air resistance, and that objects would fall completely uniformly in a vacuum.",
                    "score": 0.8664847612380981
                },
                {
                    "id": 8228200,
                    "contents": "Giambattista Benedetti\nScience of motion In his works Resolutio omnium Euclidis problematum (1553) and Demonstratio proportionum motuum localium (1554), Benedetti proposed a new doctrine of the speed of bodies in free fall. The accepted Aristotelian doctrine at that time was that the speed of a freely falling body is directly proportional to the total weight of the body and inversely proportional to the density of the medium. Benedetti's view was that the speed depends on just the difference between the specific gravity of the body and that of the medium. As opposed to the Aristotelian theory, his theory predicts that two objects of the same material but of different weights would fall at the same speed, and also that objects of different materials in a vacuum would fall at different though finite speeds.",
                    "score": 0.8658424615859985
                },
                {
                    "id": 1861950,
                    "contents": "Mechanics\nOften cited as father to modern science, Galileo brought together the ideas of other great thinkers of his time and began to calculate motion in terms of distance travelled from some starting position and the time that it took. He showed that the speed of falling objects increases steadily during the time of their fall. This acceleration is the same for heavy objects as for light ones, provided air friction (air resistance) is discounted. The English mathematician and physicist Isaac Newton improved this analysis by defining force and mass and relating these to acceleration. For objects traveling at speeds close to the speed of light, Newton's laws were superseded by Albert Einstein's theory of relativity. [A sentence illustrating the computational complication of Einstein's theory of relativity.] For atomic and subatomic particles, Newton's laws were superseded by quantum theory. For everyday phenomena, however, Newton's three laws of motion remain the cornerstone of dynamics, which",
                    "score": 0.865615963935852
                },
                {
                    "id": 8735156,
                    "contents": "Equations for a falling body\nThe equations ignore air resistance, which has a dramatic effect on objects falling an appreciable distance in air, causing them to quickly approach a terminal velocity. The effect of air resistance varies enormously depending on the size and geometry of the falling object—for example, the equations are hopelessly wrong for a feather, which has a low mass but offers a large resistance to the air. (In the absence of an atmosphere all objects fall at the same rate, as astronaut David Scott demonstrated by dropping a hammer and a feather on the surface of the Moon.) The equations also ignore the rotation of the Earth, failing to describe the Coriolis effect for example. Nevertheless, they are usually accurate enough for dense and compact objects falling over heights not exceeding the tallest man-made structures. Overview",
                    "score": 0.8656051158905029
                },
                {
                    "id": 1853017,
                    "contents": "Mass\nThe universality of free-fall only applies to systems in which gravity is the only acting force. All other forces, especially friction and air resistance, must be absent or at least negligible. For example, if a hammer and a feather are dropped from the same height through the air on Earth, the feather will take much longer to reach the ground; the feather is not really in free-fall because the force of air resistance upwards against the feather is comparable to the downward force of gravity. On the other hand, if the experiment is performed in a vacuum, in which there is no air resistance, the hammer and the feather should hit the ground at exactly the same time (assuming the acceleration of both objects towards each other, and of the ground towards both objects, for its own part, is negligible). This can easily be done in a high school laboratory by dropping the objects in transparent tubes that have the air removed with a vacuum pump. It is even more dramatic when done in an",
                    "score": 0.8655330538749695
                },
                {
                    "id": 11681920,
                    "contents": "Earth mass\nMass loss is due to atmospheric escape of gases. About 95,000 tons of hydrogen per year () and 1,600 tons of helium per year are lost through atmospheric escape. The main factor in mass gain is in-falling material, cosmic dust, meteors, etc. are the most significant contributors to Earth's increase in mass. The sum of material is estimated to be annually, although this can vary significantly; to take an extreme example, the Chicxulub impactor, with a midpoint mass estimate of , added 900 million times that annual dustfall amount to the Earth's mass in a single event. Additional changes in mass are due to the mass–energy equivalence principle, although these changes are relatively negligible. Mass loss due to the combination of nuclear fission and natural radioactive decay is estimated to amount to 16 tons per year.",
                    "score": 0.8639060258865356
                },
                {
                    "id": 1861938,
                    "contents": "Mechanics\nInfluenced by earlier writers such as Ibn Sina and al-Baghdaadi, the 14th-century French priest Jean Buridan developed the theory of impetus, which later developed into the modern theories of inertia, velocity, acceleration and momentum. This work and others was developed in 14th-century England by the Oxford Calculators such as Thomas Bradwardine, who studied and formulated various laws regarding falling bodies. The concept that the main properties of a body are uniformly accelerated motion (as of falling bodies) was worked out by the 14th-century Oxford Calculators. Early modern age Two central figures in the early modern age are Galileo Galilei and Isaac Newton. Galileo's final statement of his mechanics, particularly of falling bodies, is his Two New Sciences (1638). Newton's 1687 Philosophiæ Naturalis Principia Mathematica provided a detailed mathematical account of mechanics, using the newly developed mathematics of calculus and providing the basis of Newtonian mechanics.",
                    "score": 0.8621100783348083
                },
                {
                    "id": 17886948,
                    "contents": "Specific force\nSpecific force is defined as the non-gravitational force per unit mass. Specific force (also called g-force and mass-specific force) is measured in meters/second² (m·s−2) which is the units for acceleration. Thus, specific force is not actually a force, but a type of acceleration. However, the (mass-)specific force is not a coordinate-acceleration, but rather a proper acceleration, which is the acceleration relative to free-fall. Forces, specific forces, and proper accelerations are the same in all reference frames, but coordinate accelerations are frame-dependent. For free bodies, the specific force is the cause of, and a measure of, the body's proper acceleration.",
                    "score": 0.8618937730789185
                },
                {
                    "id": 1762696,
                    "contents": "History of physics\nHibat Allah Abu'l-Barakat al-Baghdaadi (c. 1080-1165) adopted and modified Ibn Sina's theory on projectile motion. In his Kitab al-Mu'tabar, Abu'l-Barakat stated that the mover imparts a violent inclination (mayl qasri) on the moved and that this diminishes as the moving object distances itself from the mover. He also proposed an explanation of the acceleration of falling bodies by the accumulation of successive increments of power with successive increments of velocity. According to Shlomo Pines, al-Baghdaadi's theory of motion was \"the oldest negation of Aristotle's fundamental dynamic law [namely, that a constant force produces a uniform motion], [and is thus an] anticipation in a vague fashion of the fundamental law of classical mechanics [namely, that a force applied continuously produces acceleration].\" Jean Buridan and Albert of Saxony later referred to Abu'l-Barakat in explaining that the acceleration of a falling body is a result of its increasing impetus.",
                    "score": 0.8616724610328674
                },
                {
                    "id": 22064958,
                    "contents": "Impact survival\nRecent experiments have found organisms that can survive both the acceleration and jerk involved in reaching escape velocity. A major impact event was simulated using an air cannon to propel both ice and agar projectiles covered with chosen microorganisms to extreme speeds and then crashing the projectiles into a solid surface. Two species of bacteria were tested - R. erythropolis and B. subtilis - and while survival rates were low, at 100 GPa of peak pressure there was still a survival rate of 3.9x10−5 in the B. subtilis. These findings have been replicated with other bacteria as well - D. radiodurans as well as when shot into liquid water - with similar low, but not zero, survival rates. Also, experimental methods have been varied, and survival rates have also been found when bacteria are subjected to acceleration at an extended time, through the use of a centrifuge as well as when shot into liquid water. While very small, these finite results show that some lifeforms could",
                    "score": 0.8616040945053101
                },
                {
                    "id": 8420665,
                    "contents": "Gravitational metric system\nMass The hyl, metric slug (mug), or TME (), is the mass that accelerates at 1 m/s2 under a force of 1 kgf. The hyl has also been used as the unit of mass in a metre–gram-force–second (mgfs) system. 1 TME = 1 kp / 1 m/s2 = 1 kp⋅s2/m = 1 hyl = 1 kp⋅s2/m = or 1 hyl (alternate definition – mgfs) = 1 p⋅s2/m = Pressure The gravitational unit of pressure is the technical atmosphere (at). It is the gravitational force of one kilogram, i.e. 1 kgf, exerted on an area of one square centimetre. 1 at = 1 kp/cm2 = 10 000 × gn kg/m2 = 98 066.5 kg/(m⋅s2) = 98.066 5 kPa Energy There is no dedicated name for the unit of energy, \"metre\" is simply appended to \"kilopond\", but usually the symbol of the kilopond-metre is written without the middle dot. 1 kpm = 1 kp⋅m = gn kg⋅m = 9.806 65 kg⋅m2/s2 = 9.806 65 J",
                    "score": 0.8615871667861938
                },
                {
                    "id": 6180587,
                    "contents": "Drag (physics)\nWhere is the wind speed and is the object speed (both relative to ground). Velocity of a falling object The velocity as a function of time for an object falling through a non-dense medium, and released at zero relative-velocity v = 0 at time t = 0, is roughly given by a function involving a hyperbolic tangent (tanh): The hyperbolic tangent has a limit value of one, for large time t. In other words, velocity asymptotically approaches a maximum value called the terminal velocity vt: For an object falling and released at relative-velocity v = vi at time t = 0, with vi < vt, is also defined in terms of the hyperbolic tangent function: For vi > vt, the velocity function is defined in terms of the hyperbolic cotangent function: The hyperbolic cotangent has also a limit value of one, for large time t. Velocity asymptotically tends to the terminal velocity vt, strictly from above vt. For vi = vt, the velocity is constant:",
                    "score": 0.861514151096344
                },
                {
                    "id": 8924308,
                    "contents": "Specific kinetic energy\nSpecific kinetic energy is kinetic energy of an object per unit of mass. It is defined as . Where is the specific kinetic energy and is velocity. It has units of J/kg, which is equivalent to m2/s2. Energy (physics)",
                    "score": 0.8614006638526917
                },
                {
                    "id": 1396328,
                    "contents": "Gravity\nIn the mid-16th century, various Europeans experimentally disproved the Aristotelian notion that heavier objects fall at a faster rate. The mid-16th century Italian physicist Giambattista Benedetti published papers claiming that, due to specific gravity, objects of the same material but different weights would fall at the same speed. With the 1586 Delft tower experiment the Flemish physicist Simon Stevin demonstrated that, when dropped from a tower, two cannonballs of differing sizes and weights would in fact reach the ground at the same time. In the late 16th century, Galileo Galilei demonstrated the premise (perhaps as a thought experiment) that two balls of different weights dropped from a tower would fall at the same rate. Combining this knowledge with careful measurements of balls rolling down inclines, Galileo firmly established that gravitational acceleration is the same for all objects. Galileo postulated that air resistance is the reason that objects with a low density and",
                    "score": 0.8612025380134583
                },
                {
                    "id": 8734828,
                    "contents": "History of gravitational theory\nEuropean Renaissance In the 14th century, both the French philosopher Jean Buridan and the Merton College of Oxford rejected the Aristotelian concept of gravity. They attributed the motion of objects to an impetus (akin to momentum), which varies according to velocity and mass; Buridan was influenced in this by Ibn Sina's Book of Healing. Buridan and the philosopher Albert of Saxony (c. 1320–1390) adopted Abu'l-Barakat's theory that the acceleration of a falling body is a result of its increasing impetus. Influenced by Buridan, Albert developed a law of proportion regarding the relationship between the speed of an object in free fall and the time elapsed. He also theorized that mountains and valleys are caused by erosion—displacing the Earth's centre of gravity. Also in that century, the Merton College developed the mean speed theorem, which was proved by Nicole Oresme (c. 1323–1382) and would be influential in later gravitational equations.",
                    "score": 0.8607928156852722
                },
                {
                    "id": 3384862,
                    "contents": "Micro-g environment\nCompare the gravitational potential at some of these locations. Free fall What remains is a micro-g environment moving in free fall, i.e. there are no forces other than gravity acting on the people or objects in this environment. To prevent air drag making the free fall less perfect, objects and people can free-fall in a capsule that itself, while not necessarily in free fall, is accelerated as in free fall. This can be done by applying a force to compensate for air drag. Alternatively free fall can be carried out in space, or in a vacuum tower or shaft. Two cases can be distinguished: Temporary micro-g, where after some time the Earth's surface is or would be reached, and indefinite micro-g.",
                    "score": 0.8597980737686157
                },
                {
                    "id": 13270280,
                    "contents": "Clinostat\nAn alternative to the clinostat for simulating microgravity is the free fall machine (FFM). Small samples (such as cell suspensions) are allowed to free fall under gravity for about a metre, with the period of free fall lasting just under a second. They are then pushed back to the top of the apparatus by a briefly applied large force (c. 20 g for 20 ms - the \"bounce\"), and allowed to fall again, and so on. The principle of the machine is that most of the time is spent in zero g free fall. The periods spent under high g are assumed to be too short to be detected by the physiological mechanism of the biological samples, which consequently only perceive the time spent in free fall.",
                    "score": 0.8596199154853821
                },
                {
                    "id": 28402335,
                    "contents": "Pauthenier equation\nThe Pauthenier equation states that the maximum charge accumulated by a particle modelled by a small sphere passing through an electric field is given by: where is the permittivity of free space, is the radius of the sphere, is the electric field strength, and is a material dependent constant. For conductors, . For dielectrics: where is the relative permittivity. Low charges on nanoparticles and microparticles are stable over more than 103 second time scales. References Physics theorems",
                    "score": 0.8592915534973145
                },
                {
                    "id": 1106243,
                    "contents": "Timeline of classical mechanics\n1100-1138 - Avempace develops the concept of a fatigue, which according to Shlomo Pines is precursor to Leibnizian idea of force 1100-1165 - Hibat Allah Abu'l-Barakat al-Baghdaadi discovers that force is proportional to acceleration rather than speed, a fundamental law in classical mechanics 1340-1358 - Jean Buridan develops the theory of impetus 14th century - Oxford Calculators and French collaborators prove the mean speed theorem 14th century - Nicole Oresme derives the times-squared law for uniformly accelerated change. Oresme, however, regarded this discovery as a purely intellectual exercise having no relevance to the description of any natural phenomena, and consequently failed to recognise any connection with the motion of accelerating bodies 1500-1528 - Al-Birjandi develops the theory of \"circular inertia\" to explain Earth's rotation 16th century - Francesco Beato and Luca Ghini experimentally contradict Aristotelian view on free fall.",
                    "score": 0.8588880300521851
                },
                {
                    "id": 12437300,
                    "contents": "Aristotelian physics\nIn a relatively dense medium such as water, a heavier body falls faster than a lighter one. This led Aristotle to speculate that the rate of falling is proportional to the weight and inversely proportional to the density of the medium. From his experience with objects falling in water, he concluded that water is approximately ten times denser than air. By weighing a volume of compressed air, Galileo showed that this overestimates the density of air by a factor of forty. From his experiments with inclined planes, he concluded that if friction is neglected, all bodies fall at the same rate (which is also not true, since not only friction but also density of the medium relative to density of the bodies has to be negligible. Aristotle correctly noticed that medium density is a factor but focused on body weight instead of density. Galileo neglected medium density which led him to correct conclusion for vacuum).",
                    "score": 0.8586872816085815
                },
                {
                    "id": 1386942,
                    "contents": "Escape velocity\nThe work needed to move the body over a small distance dr against this force is therefore given by The total work needed to move the body from the surface r0 of the gravitating body to infinity is then In order to do this work to reach infinity, the body's minimal kinetic energy at departure must match this work, so the escape velocity v0 satisfies which results in See also Black hole – an object with an escape velocity greater than the speed of light Characteristic energy (C3) Delta-v budget – speed needed to perform manoeuvres. Gravitational slingshot – a technique for changing trajectory Gravity well List of artificial objects in heliocentric orbit List of artificial objects leaving the Solar System Newton's cannonball Oberth effect – burning propellant deep in a gravity field gives higher change in kinetic energy Two-body problem Notes References External links Escape velocity calculator Web-based numerical escape velocity calculator",
                    "score": 0.8584499955177307
                },
                {
                    "id": 1553372,
                    "contents": "Aristotle\nAristotle's writings on motion remained influential until the Early Modern period. John Philoponus (in the Middle Ages) and Galileo are said to have shown by experiment that Aristotle's claim that a heavier object falls faster than a lighter object is incorrect. A contrary opinion is given by Carlo Rovelli, who argues that Aristotle's physics of motion is correct within its domain of validity, that of objects in the Earth's gravitational field immersed in a fluid such as air. In this system, heavy bodies in steady fall indeed travel faster than light ones (whether friction is ignored, or not), and they do fall more slowly in a denser medium.",
                    "score": 0.8575712442398071
                },
                {
                    "id": 5842318,
                    "contents": "Carl Størmer\nFrom 1903, when Størmer first observed Kristian Birkeland's experimental attempts to explain the aurora borealis, he was fascinated by aurorae and related phenomena. His first work on the subject attempted to model mathematically the paths taken by charged particles perturbed by the influence of a magnetized sphere, and Størmer eventually published over 48 papers on the motion of charged particles. By modeling the problem using differential equations and polar coordinates, Størmer was able to show that the radius of curvature of any particle's path is proportional to the square of its distance from the sphere's center. To solve the resulting differential equations numerically, he used Verlet integration, which is therefore also known as Störmer's method. Ernst Brüche and Willard Harrison Bennett verified experimentally Størmer's predicted particle motions; Bennett called his experimental apparatus \"Störmertron\" in honor of Størmer. Størmer's calculations showed that small variations",
                    "score": 0.8574527502059937
                },
                {
                    "id": 19731199,
                    "contents": "Speed skydiving\nwhere is the mass of the falling object is the acceleration due to gravity (9.8 m/s2) is the drag coefficient (~0.7 for head down position, ~1 for belly-to-earth position) is the density of the fluid through which the object is falling (1.23 kg/m3 for air at sea level, and ~0.99 kg/m3 at the middle of the measurement zone (2200m)) is the projected area of the object, or area cross-section (~0.18 m2 for head down position, ~0.7 for belly-to-earth position) So, for a human in belly-to-earth position ( m2, kg, ) this gives 50.6 m/s, about the terminal velocity of the typical skydiver of 55 m/s.",
                    "score": 0.8573578596115112
                },
                {
                    "id": 164178,
                    "contents": "Two New Sciences\n[274] Air resistance shows itself in two ways: by affecting less dense bodies more and by offering greater resistance to faster bodies. A lead ball will fall slightly faster than an oak ball, but the difference with a stone ball is negligible. However the speed does not go on increasing indefinitely but reaches a maximum. Though at small speeds the effect of air resistance is small, it is greater when considering, say, a ball fired from a cannon. [292] The effect of a projectile hitting a target is reduced if the target is free to move. The velocity of a moving body can overcome that of a larger body if its speed is proportionately greater than the resistance. [310] A cord or chain stretched out is never level but also approximates to a parabola. (But see also catenary.) Additional day: The force of percussion [323] What is the weight of water falling from a bucket hanging on a balance arm onto another bucket suspended to the same arm?",
                    "score": 0.8572108745574951
                },
                {
                    "id": 1162791,
                    "contents": "Particle physics\nSubatomic particles Modern particle physics research is focused on subatomic particles, including atomic constituents, such as electrons, protons, and neutrons (protons and neutrons are composite particles called baryons, made of quarks), that are produced by radioactive and scattering processes; such particles are photons, neutrinos, and muons, as well as a wide range of exotic particles. Dynamics of particles are also governed by quantum mechanics; they exhibit wave–particle duality, displaying particle-like behaviour under certain experimental conditions and wave-like behaviour in others. In more technical terms, they are described by quantum state vectors in a Hilbert space, which is also treated in quantum field theory. Following the convention of particle physicists, the term elementary particles is applied to those particles that are, according to current understanding, presumed to be indivisible and not composed of other particles.",
                    "score": 0.8571071624755859
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_34",
        "question": "The flux of visible photons reaching Earth from the North Star is about $4 \\times 10^3 \\mathrm{~mm}^{-2} \\mathrm{~s}^{-1}$. Of these photons, 30 per cent are absorbed or scattered by the atmosphere and 25 per cent of the surviving photons are scattered by the surface of the cornea of the eye. A further 9 per cent are absorbed inside the cornea. The area of the pupil at night is about $40 \\mathrm{~mm}^2$ and the response time of the eye is about $0.1 \\mathrm{~s}$. Of the photons passing through the pupil, about 43 per cent are absorbed in the ocular medium. How many photons from the North Star are focused onto the retina in $0.1 \\mathrm{~s}$ ?",
        "golden_answers": [
            " 4.4"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1219811,
                    "contents": "Sun\nThe photosphere is tens to hundreds of kilometers thick, and is slightly less opaque than air on Earth. Because the upper part of the photosphere is cooler than the lower part, an image of the Sun appears brighter in the center than on the edge or limb of the solar disk, in a phenomenon known as limb darkening. The spectrum of sunlight has approximately the spectrum of a black-body radiating at , interspersed with atomic absorption lines from the tenuous layers above the photosphere. The photosphere has a particle density of ~1023 m−3 (about 0.37% of the particle number per volume of Earth's atmosphere at sea level). The photosphere is not fully ionized—the extent of ionization is about 3%, leaving almost all of the hydrogen in atomic form.",
                    "score": 0.8986332416534424
                },
                {
                    "id": 1241672,
                    "contents": "Sunlight\nThe total amount of energy received at ground level from the Sun at the zenith depends on the distance to the Sun and thus on the time of year. It is about 3.3% higher than average in January and 3.3% lower in July (see below). If the extraterrestrial solar radiation is 1367 watts per square meter (the value when the Earth–Sun distance is 1 astronomical unit), then the direct sunlight at Earth's surface when the Sun is at the zenith is about 1050 W/m2, but the total amount (direct and indirect from the atmosphere) hitting the ground is around 1120 W/m2. In terms of energy, sunlight at Earth's surface is around 52 to 55 percent infrared (above 700 nm), 42 to 43 percent visible (400 to 700 nm), and 3 to 5 percent ultraviolet (below 400 nm). At the top of the atmosphere, sunlight is about 30% more intense, having about 8% ultraviolet (UV), with most of the extra UV consisting of biologically damaging short-wave ultraviolet.",
                    "score": 0.896918773651123
                },
                {
                    "id": 1219789,
                    "contents": "Sun\nThe Sun is by far the brightest object in the Earth's sky, with an apparent magnitude of −26.74. This is about 13 billion times brighter than the next brightest star, Sirius, which has an apparent magnitude of −1.46. is defined as the mean distance of the Sun's center to Earth's center, though the distance varies as Earth moves from perihelion in January to aphelion in July. The distances can vary between 147,098,074 km (perihelion) and 152,097,701 km (aphelion), and extreme values can range from 147,083,346 km to 152,112,126 km. At its average distance, light travels from the Sun's horizon to Earth's horizon in about 8 minutes and 19 seconds, while light from the closest points of the Sun and Earth takes about two seconds less. The energy of this sunlight supports almost all life on Earth by photosynthesis, and drives Earth's climate and weather.",
                    "score": 0.895753026008606
                },
                {
                    "id": 17168278,
                    "contents": "Earthlight (astronomy)\nEarthlight has a calculated maximum apparent magnitude of −17.7 as viewed from the Moon. Earthshine has a calculated maximum apparent magnitude of −3.69 as viewed from Earth. This phenomenon is most visible from Earth at night (or astronomical twilight) a few days before or after the day of new moon, when the lunar phase is a thin crescent. On these nights, the entire lunar disk is both directly and indirectly sunlit, and is thus unevenly bright enough to see. Earthshine is most clearly seen after dusk during the waxing crescent (in the western sky) and before dawn during the waning crescent (in the eastern sky). The term earthlight would also be suitable for an observer on the Moon seeing Earth during the lunar night, or for an astronaut inside a spacecraft looking out the window. Arthur C. Clarke uses it in this sense in his 1955 novel Earthlight. Radio frequency transmissions are also reflected by the moon; for example, see Earth–Moon–Earth communication.",
                    "score": 0.8936547040939331
                },
                {
                    "id": 5905930,
                    "contents": "Solar irradiance\nIrradiance on Earth's surface Average annual solar radiation arriving at the top of the Earth's atmosphere is roughly 1361W/m2. The Sun's rays are attenuated as they pass through the atmosphere, leaving maximum normal surface irradiance at approximately 1000W/m2 at sea level on a clear day. When 1361 W/m2 is arriving above the atmosphere (when the sun is at the zenith in a cloudless sky), direct sun is about 1050 W/m2, and global radiation on a horizontal surface at ground level is about 1120 W/m2. The latter figure includes radiation scattered or reemitted by the atmosphere and surroundings. The actual figure varies with the Sun's angle and atmospheric circumstances. Ignoring clouds, the daily average insolation for the Earth is approximately .",
                    "score": 0.893541157245636
                },
                {
                    "id": 6150763,
                    "contents": "Rupert Wildt\nIn 1939 he demonstrated that the major source of optical opacity in the Sun's atmosphere is the H− ion, and thus the main source of visible light for the Sun and stars. From 1965 until 1968 he was president of the Association of Universities for Research in Astronomy. In the period 1966-1968 he also held the post of the chairman of the department of astronomy at Yale, and from 1973 until his death he was professor emeritus. He died in Orleans, Massachusetts. Awards and honors Awarded the Eddington Medal in 1966 Asteroid 1953 Rupertwildt is named after him The crater Wildt on the Moon is named after him References 1905 births 1976 deaths 20th-century German astronomers 20th-century American astronomers Planetary scientists",
                    "score": 0.8933385014533997
                },
                {
                    "id": 1241681,
                    "contents": "Sunlight\nThe amount of radiation intercepted by a planetary body varies inversely with the square of the distance between the star and the planet. Earth's orbit and obliquity change with time (over thousands of years), sometimes forming a nearly perfect circle, and at other times stretching out to an orbital eccentricity of 5% (currently 1.67%). As the orbital eccentricity changes, the average distance from the Sun (the semimajor axis does not significantly vary, and so the total insolation over a year remains almost constant due to Kepler's second law, where is the \"areal velocity\" invariant. That is, the integration over the orbital period (also invariant) is a constant. If we assume the solar radiation power as a constant over time and the solar irradiation given by the inverse-square law, we obtain also the average insolation as a constant.",
                    "score": 0.8927996754646301
                },
                {
                    "id": 9349895,
                    "contents": "Sky brightness\nAfter the sun has also set for these altitudes at the end of nautical twilight, the intensity of light emanating from earlier mentioned lines decreases, until the oxygen-green remains as the dominant source. When astronomical darkness has set in, the green 557.7 nm oxygen line is dominant, and atmospheric scattering of starlight occurs. Differential refraction causes different parts of the spectrum to dominate, producing a golden hour and a blue hour. Relative contributions The following table gives the relative and absolute contributions to night sky brightness at zenith on a perfectly dark night at middle latitudes without moonlight and in the absence of any light pollution. (The S10 unit is defined as the surface brightness of a star whose V-magnitude is 10 and whose light is smeared over one square degree, or 27.78 mag arcsec−2.)",
                    "score": 0.8927199840545654
                },
                {
                    "id": 9349891,
                    "contents": "Sky brightness\nIn daytime, sodium and red oxygen emissions are dominant and roughly 1,000 times as bright as nighttime emissions because in daytime, the upper atmosphere is fully exposed to solar UV radiation. The effect is however not noticeable to the human eye, since the glare of directly scattered sunlight outshines and obscures it. Indirect scattering of sunlight Indirectly scattered sunlight comes from two directions. From the atmosphere itself, and from outer space. In the first case, the sun has just set but still illuminates the upper atmosphere directly. Because the amount of scattered sunlight is proportional to the number of scatterers (i.e. air molecules) in the line of sight, the intensity of this light decreases rapidly as the sun drops further below the horizon and illuminates less of the atmosphere.",
                    "score": 0.8916863203048706
                },
                {
                    "id": 453450,
                    "contents": "Atmosphere of Earth\nThe average mass of the atmosphere is about 5 quadrillion (5) tonnes or 1/1,200,000 the mass of Earth. According to the American National Center for Atmospheric Research, \"The total mean mass of the atmosphere is 5.1480 kg with an annual range due to water vapor of 1.2 or 1.5 kg, depending on whether surface pressure or water vapor data are used; somewhat smaller than the previous estimate. The mean mass of water vapor is estimated as 1.27 kg and the dry air mass as 5.1352 ±0.0003 kg.\" Optical properties Solar radiation (or sunlight) is the energy Earth receives from the Sun. Earth also emits radiation back into space, but at longer wavelengths that humans cannot see. Part of the incoming and emitted radiation is absorbed or reflected by the atmosphere. In May 2017, glints of light, seen as twinkling from an orbiting satellite a million miles away, were found to be reflected light from ice crystals in the atmosphere. Scattering",
                    "score": 0.8913353085517883
                },
                {
                    "id": 1219793,
                    "contents": "Sun\nThe Sun emits light across the visible spectrum, so its color is white, with a CIE color-space index near (0.3, 0.3), when viewed from space or when the Sun is high in the sky. The Solar radiance per wavelength peaks in the green portion of the spectrum when viewed from space. When the Sun is low in the sky, atmospheric scattering renders the Sun yellow, red, orange, or magenta. Despite its typical whiteness, most people mentally picture the Sun as yellow; the reasons for this are the subject of debate. The Sun is a G2V star, with G2 indicating its surface temperature of approximately 5,778 K (5,505 °C, 9,941 °F), and V that it, like most stars, is a main-sequence star. The average luminance of the Sun is about 1.88 giga candela per square metre, but as viewed through Earth's atmosphere, this is lowered to about 1.44 Gcd/m2. However, the luminance is not constant across the disk of the Sun, due to limb darkening. Composition",
                    "score": 0.8911992311477661
                },
                {
                    "id": 1241684,
                    "contents": "Sunlight\nSolar irradiance Solar constant The solar constant is a measure of flux density, is the amount of incoming solar electromagnetic radiation per unit area that would be incident on a plane perpendicular to the rays, at a distance of one astronomical unit (AU) (roughly the mean distance from the Sun to Earth). The \"solar constant\" includes all types of solar radiation, not just the visible light. Its average value was thought to be approximately 1366 W/m2, varying slightly with solar activity, but recent recalibrations of the relevant satellite observations indicate a value closer to 1361 W/m2 is more realistic. Total solar irradiance (TSI) and spectral solar irradiance (SSI) upon Earth",
                    "score": 0.889867901802063
                },
                {
                    "id": 1649672,
                    "contents": "Clyde Tombaugh\nTombaugh observed these rectangles of light for about 3 seconds and his wife saw them for about seconds. He never supported the interpretation as a spaceship that has often been attributed to him. He considered other possibilities, with a temperature inversion as the most likely cause.From my own studies of the solar system I cannot entertain any serious possibility for intelligent life on other planets, not even for Mars... The logistics of visitations from planets revolving around the nearer stars is staggering. In consideration of the hundreds of millions of years in the geologic time scale when such visits may have possibly occurred, the odds of a single visit in a given century or millennium are overwhelmingly against such an event.A much more likely source of explanation is some natural optical phenomenon in our own atmosphere. In my 1949 sightings the faintness of the object, together with the manner of fading in intensity as it traveled away from the zenith towards the",
                    "score": 0.8895890116691589
                },
                {
                    "id": 1241674,
                    "contents": "Sunlight\nComposition and power The spectrum of the Sun's solar radiation is close to that of a black body with a temperature of about 5,800 K. The Sun emits EM radiation across most of the electromagnetic spectrum. Although the Sun produces gamma rays as a result of the nuclear-fusion process, internal absorption and thermalization convert these super-high-energy photons to lower-energy photons before they reach the Sun's surface and are emitted out into space. As a result, the Sun does not emit gamma rays from this process, but it does emit gamma rays from solar flares. The Sun also emits X-rays, ultraviolet, visible light, infrared, and even radio waves; the only direct signature of the nuclear process is the emission of neutrinos.",
                    "score": 0.8884270191192627
                },
                {
                    "id": 1219792,
                    "contents": "Sun\nSunlight The solar constant is the amount of power that the Sun deposits per unit area that is directly exposed to sunlight. The solar constant is equal to approximately (watts per square meter) at a distance of one astronomical unit (AU) from the Sun (that is, on or near Earth). Sunlight on the surface of Earth is attenuated by Earth's atmosphere, so that less power arrives at the surface (closer to ) in clear conditions when the Sun is near the zenith. Sunlight at the top of Earth's atmosphere is composed (by total energy) of about 50% infrared light, 40% visible light, and 10% ultraviolet light. The atmosphere in particular filters out over 70% of solar ultraviolet, especially at the shorter wavelengths. Solar ultraviolet radiation ionizes Earth's dayside upper atmosphere, creating the electrically conducting ionosphere.",
                    "score": 0.8883981108665466
                },
                {
                    "id": 2225050,
                    "contents": "Solar constant\nThe actual direct solar irradiance at the top of the atmosphere fluctuates by about 6.9% during a year (from 1.412 kW/m2 in early January to 1.321 kW/m2 in early July) due to the Earth's varying distance from the Sun, and typically by much less than 0.1% from day to day. Thus, for the whole Earth (which has a cross section of 127,400,000 km2), the power is 1.730×1017 W (or 173,000 terawatts), plus or minus 3.5% (half the approximately 6.9% annual range). The solar constant does not remain constant over long periods of time (see Solar variation), but over a year the solar constant varies much less than the solar irradiance measured at the top of the atmosphere. This is because the solar constant is evaluated at a fixed distance of 1 Astronomical Unit (au) while the solar irradiance will be affected by the eccentricity of the Earth's orbit. Its distance to the Sun varies annually between 147.1·106 km at perihelion and 152.1·106 km at aphelion. In addition, several long term (tens to",
                    "score": 0.888272225856781
                },
                {
                    "id": 1238338,
                    "contents": "Solar energy\nPotential The Earth receives 174 petawatts (PW) of incoming solar radiation (insolation) at the upper atmosphere. Approximately 30% is reflected back to space while the rest is absorbed by clouds, oceans and land masses. The spectrum of solar light at the Earth's surface is mostly spread across the visible and near-infrared ranges with a small part in the near-ultraviolet. Most of the world's population live in areas with insolation levels of 150–300 watts/m2, or 3.5–7.0 kWh/m2 per day.",
                    "score": 0.8882414102554321
                },
                {
                    "id": 4940563,
                    "contents": "Airglow\n(where h is Planck's constant; hν is the energy of a single photon of frequency ν). At V band, the emission from airglow is per square arc-second at a high-altitude observatory on a moonless night; in excellent seeing conditions, the image of a star will be about 0.7 arc-second across with an area of 0.4 square arc-second, and so the emission from airglow over the area of the image corresponds to about . This gives the number of photons from airglow, Na: The signal-to-noise for an ideal ground-based observation with a telescope of area A (ignoring losses and detector noise), arising from Poisson statistics, is only: If we assume a 10 m diameter ideal ground-based telescope and an unresolved star: every second, over a patch the size of the seeing-enlarged image of the star, 35 photons arrive from the star and 3500 from air-glow. So, over an hour, roughly arrive from the air-glow, and approximately arrive from the source; so the S/N ratio is about:",
                    "score": 0.8875793218612671
                },
                {
                    "id": 5905931,
                    "contents": "Solar irradiance\nThe average annual solar radiation arriving at the top of the Earth's atmosphere (1361W/m2) represents the power per unit area of solar irradiance across the spherical surface surrounding the sun with a radius equal to the distance to the Earth (1AU). This means that the approximately circular disc of the Earth, as viewed from the sun, receives a roughly stable 1361W/m2 at all times. The area of this circular disc is , in which is the radius of the Earth. Because the Earth is approximately spherical, it has total area , meaning that the solar radiation arriving at the top of the atmosphere, averaged over the entire surface of the Earth, is simply divided by four to get 340W/m2. In other words, averaged over the year and the day, the Earth's atmosphere receives 340W/m2 from the sun. This figure is important in radiative forcing.",
                    "score": 0.8874284029006958
                },
                {
                    "id": 1693535,
                    "contents": "Electromagnetic radiation\nAtmosphere and magnetosphere Most UV and X-rays are blocked by absorption first from molecular nitrogen, and then (for wavelengths in the upper UV) from the electronic excitation of dioxygen and finally ozone at the mid-range of UV. Only 30% of the Sun's ultraviolet light reaches the ground, and almost all of this is well transmitted. Visible light is well transmitted in air, as it is not energetic enough to excite nitrogen, oxygen, or ozone, but too energetic to excite molecular vibrational frequencies of water vapor. Absorption bands in the infrared are due to modes of vibrational excitation in water vapor. However, at energies too low to excite water vapor, the atmosphere becomes transparent again, allowing free transmission of most microwave and radio waves.",
                    "score": 0.8870368003845215
                },
                {
                    "id": 1221240,
                    "contents": "Star\nThe Sun has an apparent magnitude of −26.7, but its absolute magnitude is only +4.83. Sirius, the brightest star in the night sky as seen from Earth, is approximately 23 times more luminous than the Sun, while Canopus, the second brightest star in the night sky with an absolute magnitude of −5.53, is approximately 14,000 times more luminous than the Sun. Despite Canopus being vastly more luminous than Sirius, the latter star appears the brighter of the two. This is because Sirius is merely 8.6 light-years from the Earth, while Canopus is much farther away at a distance of 310 light-years.",
                    "score": 0.8865371346473694
                },
                {
                    "id": 1219818,
                    "contents": "Sun\nPhotons and neutrinos High-energy gamma ray photons initially released with fusion reactions in the core are almost immediately absorbed by the solar plasma of the radiative zone, usually after traveling only a few millimeters. Re-emission happens in a random direction and usually at slightly lower energy. With this sequence of emissions and absorptions, it takes a long time for radiation to reach the Sun's surface. Estimates of the photon travel time range between 10,000 and 170,000 years. In contrast, it takes only 2.3 seconds for the neutrinos, which account for about 2% of the total energy production of the Sun, to reach the surface. Because energy transport in the Sun is a process that involves photons in thermodynamic equilibrium with matter, the time scale of energy transport in the Sun is longer, on the order of 30,000,000 years. This is the time it would take the Sun to return to a stable state if the rate of energy generation in its core were suddenly changed.",
                    "score": 0.8863729238510132
                },
                {
                    "id": 4277020,
                    "contents": "Pale Blue Dot\nEarth's reflectance spectrum from the far-ultraviolet to the near-infrared is unlike that of any other observed planet and is partially due to the presence of life on Earth. Rayleigh scattering, which causes Earth's blueness, is enhanced in an atmosphere that does not substantially absorb visible light, unlike, for example, the orange-brown color of Titan, where organic haze particles absorb strongly at blue visible wavelengths. Earth's plentiful atmospheric oxygen, which is produced by photosynthetic life forms, causes the atmosphere to be transparent to visible light, which allows for substantial Rayleigh scattering and hence stronger reflectance of blue light. Distance According to NASA's Jet Propulsion Laboratory's HORIZONS tool, the distances between Voyager 1 and the Earth on February 14 and May 15, 1990, were as follows: Reflections In his 1994 book, Pale Blue Dot, Carl Sagan comments on what he sees as the greater significance of the photograph, writing: Anniversaries",
                    "score": 0.8859195709228516
                },
                {
                    "id": 23890654,
                    "contents": "Franklin E. Roach\nRoach's and Gordon's volume was entitled The Light of the Night Sky and dealt with the subject of the composition of the lighted sky itself in the topical subject area \"the light of the night sky\" (LONS). It gave scientific presentations with a fundamental overview of the atmospheric processes and interstellar physics involved, especially on Earth's nightside. The preface was prepared in August 1973 and Roach was still writing later chapters in September. Topics discussed included the dark adaptation of the eye, star counts and the distribution of starlight over the sky, the polarization of the \"Zodiacal Light\", and the study of \"The Gegenschein\".",
                    "score": 0.8858819007873535
                },
                {
                    "id": 3517387,
                    "contents": "Johann Karl Friedrich Zöllner\nIn 1867 he made the first measurement of the Sun's apparent magnitude, using a particular \"telescope / photometer\" he designed. The instrument was able to superimpose two images, one from a small telescope and the second from a reference lamp. During daytime he dimmed the image of the Sun (using polarizers and diaphragms) and compared it to the lamp. During nighttime, the lamp was dimmed and compared to bright stars. He estimated the visual magnitude of the Sun to be -26.66, an extraordinary result for the time. Today's accepted value is -26.74. This measure is very difficult, since the flux difference between the Sun and Capella (one of the bright stars he used) is roughly 50 billion times. This work was pivotal for astrophysics - leading to the discovery that star's brightness varies wildly among different stars, and also that the Sun is brighter than the vast majority of nearby stars. The lunar crater Zöllner is named in his honor. Spiritualism",
                    "score": 0.8855315446853638
                },
                {
                    "id": 17168277,
                    "contents": "Earthlight (astronomy)\nEarthlight is the diffuse reflection of sunlight reflected from Earth's surface and clouds. Earthshine (an example of planetshine), also known as the Moon's ashen glow, is the dim illumination of the otherwise unilluminated portion of the Moon by this indirect sunlight. Earthlight on the Moon during the waxing crescent is called \"the old Moon in the new Moon's arms\", while that during the waning crescent is called \"the new Moon in the old Moon's arms\". Earthlight has a calculated maximum apparent magnitude of −17.7 as viewed from the Moon. Earthshine has a calculated maximum apparent magnitude of −3.69 as viewed from Earth.",
                    "score": 0.8851729035377502
                },
                {
                    "id": 626083,
                    "contents": "Ultraviolet astronomy\nThe ultraviolet universe looks quite different from the familiar stars and galaxies seen in visible light. Most stars are actually relatively cool objects emitting much of their electromagnetic radiation in the visible or near-infrared part of the spectrum. Ultraviolet radiation is the signature of hotter objects, typically in the early and late stages of their evolution. In the Earth's sky seen in ultraviolet light, most stars would fade in prominence. Some very young massive stars and some very old stars and galaxies, growing hotter and producing higher-energy radiation near their birth or death, would be visible. Clouds of gas and dust would block the vision in many directions along the Milky Way. Space-based solar observatories such as SDO and SOHO use ultraviolet telescopes (called AIA and EIT, respectively) to view activity on the Sun and its corona. Weather satellites such as the GOES-R series also carry telescopes for observing the Sun in ultraviolet.",
                    "score": 0.8847565054893494
                },
                {
                    "id": 6432581,
                    "contents": "Solar balloon\nOver the course of a year the average solar radiation arriving at the top of the Earth's atmosphere is roughly 1,366 watts per square meter (see solar constant). The radiant power is distributed across the entire electromagnetic spectrum, although most of the power is in the visible light portion of the spectrum. The Sun's rays are attenuated as they pass through the atmosphere, thus reducing the insolation at the Earth's surface to approximately 1,000 watts per square meter for a surface perpendicular to the Sun's rays at sea level on a clear day. A black body absorbs all the radiation that hits it. Real world objects are gray objects, with their absorption being equal to their emissivity. Black plastic might have an emissivity of around 0.95, meaning 95 percent of all radiation that hits it will be absorbed, and the remaining 5 percent reflected. Estimating energy received",
                    "score": 0.8844715356826782
                },
                {
                    "id": 24460794,
                    "contents": "Solar phenomena\nFor a sunspot to be visible to the human eye it must be about 50,000 km in diameter, covering or 700 millionths of the visible area. Over recent cycles, approximately 100 sunspots or compact sunspot groups are visible from Earth. Sunspots expand and contract as they move about and can travel at a few hundred meters per second when they first appear. Wind The solar wind is a stream of plasma released from the Sun's upper atmosphere. It consists of mostly electrons and protons with energies usually between 1.5 and 10 keV. The stream of particles varies in density, temperature and speed over time and over solar longitude. These particles can escape the Sun's gravity because of their high energy.",
                    "score": 0.8844097852706909
                },
                {
                    "id": 1238339,
                    "contents": "Solar energy\nSolar radiation is absorbed by the Earth's land surface, oceans – which cover about 71% of the globe – and atmosphere. Warm air containing evaporated water from the oceans rises, causing atmospheric circulation or convection. When the air reaches a high altitude, where the temperature is low, water vapor condenses into clouds, which rain onto the Earth's surface, completing the water cycle. The latent heat of water condensation amplifies convection, producing atmospheric phenomena such as wind, cyclones and anticyclones. Sunlight absorbed by the oceans and land masses keeps the surface at an average temperature of 14 °C. By photosynthesis, green plants convert solar energy into chemically stored energy, which produces food, wood and the biomass from which fossil fuels are derived.",
                    "score": 0.8843024373054504
                },
                {
                    "id": 1238340,
                    "contents": "Solar energy\nThe total solar energy absorbed by Earth's atmosphere, oceans and land masses is approximately 3,850,000 exajoules (EJ) per year. In 2002, this was more energy in one hour than the world used in one year. Photosynthesis captures approximately 3,000 EJ per year in biomass. The amount of solar energy reaching the surface of the planet is so vast that in one year it is about twice as much as will ever be obtained from all of the Earth's non-renewable resources of coal, oil, natural gas, and mined uranium combined,",
                    "score": 0.8838005661964417
                },
                {
                    "id": 1689226,
                    "contents": "Earth\nEarth receives 1361 W/m2 of solar irradiance. The amount of solar energy that reaches the Earth's surface decreases with increasing latitude. At higher latitudes, the sunlight reaches the surface at lower angles, and it must pass through thicker columns of the atmosphere. As a result, the mean annual air temperature at sea level decreases by about per degree of latitude from the equator. Earth's surface can be subdivided into specific latitudinal belts of approximately homogeneous climate. Ranging from the equator to the polar regions, these are the tropical (or equatorial), subtropical, temperate and polar climates.",
                    "score": 0.8835030198097229
                },
                {
                    "id": 1219812,
                    "contents": "Sun\nDuring early studies of the optical spectrum of the photosphere, some absorption lines were found that did not correspond to any chemical elements then known on Earth. In 1868, Norman Lockyer hypothesized that these absorption lines were caused by a new element that he dubbed helium, after the Greek Sun god Helios. Twenty-five years later, helium was isolated on Earth. Atmosphere During a total solar eclipse, when the disk of the Sun is covered by that of the Moon, parts of the Sun's surrounding atmosphere can be seen. It is composed of four distinct parts: the chromosphere, the transition region, the corona and the heliosphere. The coolest layer of the Sun is a temperature minimum region extending to about above the photosphere, and has a temperature of about . This part of the Sun is cool enough to allow the existence of simple molecules such as carbon monoxide and water, which can be detected via their absorption spectra.",
                    "score": 0.8832922577857971
                },
                {
                    "id": 4262153,
                    "contents": "Night sky\noften the only \"star\" visible near sunrise or sunset, depending on its location in its orbit. Because of its brightness, Venus can sometimes be seen after sunrise. Mercury, Mars, Jupiter and Saturn are also visible to the naked eye in the night sky.",
                    "score": 0.8820406794548035
                },
                {
                    "id": 19108811,
                    "contents": "Starlight\nStarlight is the light emitted by stars. It typically refers to visible electromagnetic radiation from stars other than the Sun, observable from Earth at night, although a component of starlight is observable from Earth during daytime. Sunlight is the term used for the Sun's starlight observed during daytime. During nighttime, albedo describes solar reflections from other Solar System objects, including moonlight, planetshine, and zodiacal light.",
                    "score": 0.8812111020088196
                },
                {
                    "id": 19108816,
                    "contents": "Starlight\nThe explanation is that the interstellar medium is optically thin. Starlight traveling through a kiloparsec column undergoes about a magnitude of extinction, so that the optical depth ~ 1. An optical depth of 1 corresponds to a mean free path, which is the distance, on average that a photon travels before scattering from a dust grain. So on average, a starlight photon is scattered from a single interstellar grain; multiple scattering (which produces circular polarization) is much less likely. Observationally, the linear polarization fraction p ~ 0.015 from a single scattering; circular polarization from multiple scattering goes as , so we expect a circularly polarized fraction of . Light from early-type stars has very little intrinsic polarization. Kemp et al. measured the optical polarization of the Sun at sensitivity of ; they found upper limits of for both (fraction of linear polarization) and (fraction of circular polarization).",
                    "score": 0.8810147047042847
                },
                {
                    "id": 1254138,
                    "contents": "Speed of light\nReceiving light and other signals from distant astronomical sources can even take much longer. For example, it has taken 13 billion (13) years for light to travel to Earth from the faraway galaxies viewed in the Hubble Ultra Deep Field images. Those photographs, taken today, capture images of the galaxies as they appeared 13 billion years ago, when the universe was less than a billion years old. The fact that more distant objects appear to be younger, due to the finite speed of light, allows astronomers to infer the evolution of stars, of galaxies, and of the universe itself.",
                    "score": 0.8808815479278564
                },
                {
                    "id": 1219800,
                    "contents": "Sun\nBecause the Sun is a gaseous object, it does not have a clearly defined surface; its visible parts are usually divided into a \"photosphere\" and \"atmosphere\": Photosphere – the deepest part of the Sun which we can directly observe with visible light. Atmosphere – a gaseous \"halo\" surrounding the Sun, comprising the chromosphere, solar transition region, corona and heliosphere. These can be seen when the main part of the Sun is hidden, for example, during a solar eclipse.",
                    "score": 0.880510687828064
                },
                {
                    "id": 2225052,
                    "contents": "Solar constant\nThe Earth receives a total amount of radiation determined by its cross section (π·RE2), but as it rotates this energy is distributed across the entire surface area (4·π·RE2). Hence the average incoming solar radiation, taking into account the angle at which the rays strike and that at any one moment half the planet does not receive any solar radiation, is one-fourth the solar constant (approximately 340 W/m2). The amount reaching the Earth's surface (as insolation) is further reduced by atmospheric attenuation, which varies. At any given moment, the amount of solar radiation received at a location on the Earth's surface depends on the state of the atmosphere, the location's latitude, and the time of day. Apparent magnitude",
                    "score": 0.8803766369819641
                },
                {
                    "id": 9349896,
                    "contents": "Sky brightness\n(The S10 unit is defined as the surface brightness of a star whose V-magnitude is 10 and whose light is smeared over one square degree, or 27.78 mag arcsec−2.) The total sky brightness in zenith is therefore ~220 S10 or 21.9 mag/arcsec² in the V-band. Note that the contributions from Airglow and Zodiacal light vary with the time of year, the solar cycle, and the observer's latitude roughly as follows: where S is the solar 10.7 cm flux in MJy, and various sinusoidally between 0.8 and 2.0 with the 11-year solar cycle, yielding an upper contribution of ~270 S10 at solar maximum.",
                    "score": 0.8797574043273926
                },
                {
                    "id": 3534954,
                    "contents": "Extraterrestrial sky\nLuminosity and angular diameter of the Sun The Sun's apparent magnitude changes according to the inverse square law, therefore, the difference in magnitude as a result of greater or lesser distances from different celestial bodies can be predicted by the following formula: Where \"distance\" can be in km, au, or any other appropriate unit. To illustrate, since Pluto is 40 au away from the Sun on average, it follows that the parent star would appear to be times as bright as it is on Earth. Though a terrestrial observer would find a dramatic decrease in available sunlight in these environments, the Sun would still be bright enough to cast shadows even as far as the hypothetical Planet Nine, possibly located 1,200 AU away, and by analogy would still outshine the full Moon as seen from Earth. The change in angular diameter of the Sun with distance is illustrated in the diagram below:",
                    "score": 0.8791401386260986
                },
                {
                    "id": 1219810,
                    "contents": "Sun\nThe visible surface of the Sun, the photosphere, is the layer below which the Sun becomes opaque to visible light. Photons produced in this layer escape the Sun through the transparent solar atmosphere above it and become solar radiation, sunlight. The change in opacity is due to the decreasing amount of H− ions, which absorb visible light easily. Conversely, the visible light we see is produced as electrons react with hydrogen atoms to produce H− ions.",
                    "score": 0.8791079521179199
                },
                {
                    "id": 11514,
                    "contents": "Solar luminosity\nThe solar luminosity, , is a unit of radiant flux (power emitted in the form of photons) conventionally used by astronomers to measure the luminosity of stars, galaxies and other celestial objects in terms of the output of the Sun. One nominal solar luminosity is defined by the International Astronomical Union to be . This does not include the solar neutrino luminosity, which would add , or , i.e. a total of (the mean energy of the solar photons is 26 MeV and that of the solar neutrinos 0.59 MeV, i.e. 2.27%; the Sun emits photons and as many neutrinos each second, of which per m2 reach the Earth each second). The Sun is a weakly variable star, and its actual luminosity therefore fluctuates. The major fluctuation is the eleven-year solar cycle (sunspot cycle) that causes a quasi-periodic variation of about ±0.1%. Other variations over the last 200–300 years are thought to be much smaller than this.",
                    "score": 0.8787809610366821
                },
                {
                    "id": 24460782,
                    "contents": "Solar phenomena\nThe Sun is a G-type main-sequence star (G2V) based on spectral class and it is informally designated as a yellow dwarf because its visible radiation is most intense in the yellow-green portion of the spectrum. It is actually white, but from the Earth's surface it appears yellow because of atmospheric scattering of blue light. In the spectral class label, G2 indicates its surface temperature, of approximately 5778 K () and V indicates that the Sun, like most stars, is a main-sequence star, and thus generates its energy via fusing hydrogen into helium. In its core, the Sun fuses about 620 million metric tons of hydrogen each second.",
                    "score": 0.8785485029220581
                },
                {
                    "id": 19588613,
                    "contents": "(55638) 2002 VE95\nIn the visible light, has a featureless reflectance spectrum. It is very red in color (RR), with a color index of 1.080 and 0.71, in the B–V and V−R passband filters, respectively. The near-infrared spectrum of is flat with two distinct absorption bands of water ice at 1.5 and 2.0 μm. There is the third feature near 2.3 μm of unclear origin. The spectral behavior of this object is similar to 5145 Pholus, a centaur. Observations with the Very Large Telescope revealed that has a heterogeneous surface—the amount of different ices and non-ice components depends on the observed area. Among the probable surface materials are water ice (4–19%), methanol ice (10–12%) and various tholins, photochemically altered organic compounds, also found on Triton and Titan. The redder areas are generally associated with the presence of methanol ice. The surface of appears to be primordial in origin. References External links List of Transneptunian Objects, Minor Planet Center",
                    "score": 0.8780511617660522
                },
                {
                    "id": 24460783,
                    "contents": "Solar phenomena\nThe Earth's mean distance from the Sun is approximately , though the distance varies as the Earth moves from perihelion in January to aphelion in July. At this average distance, light travels from the Sun to Earth in about 8 minutes, 19 seconds. The energy of this sunlight supports almost all life on Earth by photosynthesis, and drives Earth's climate and weather. As recently as the 19th century scientists had little knowledge of the Sun's physical composition and source of energy. This understanding is still developing; a number of present-day anomalies in the Sun's behavior remain unexplained. Solar cycle Many solar phenomena change periodically over an average interval of about 11 years. This solar cycle affects solar irradiation and influences space weather, terrestrial weather and climate.",
                    "score": 0.877937376499176
                },
                {
                    "id": 16791199,
                    "contents": "Superflare\nand had an energy of 1036 ergs. White-light flares on the Sun change the brightness by about 0.01%, and the strongest flares have a visible-light energy of about 1032 ergs. (All energies quoted are in the optical bandpass and so are lower limits since some energy is emitted at other wavelengths.) Most events were much less energetic than this: flare amplitudes below 0.1% of the stellar value and energies of 2 × 1033 ergs were detectable with the 30 minute integration. The flares had a rapid rise followed by an exponential decay on a time scale of 1–3 hours. The most powerful events corresponded to energies ten thousand greater than the largest flares observed on the Sun. Some stars flared very frequently: one star showed 57 events in 500 days, a rate of one every nine days. For the statistics of flares, the number of flares decreased with energy E roughly as E−2, a similar behaviour to solar flares. The duration of the flare increased with its energy, again in accordance with the",
                    "score": 0.8777359127998352
                },
                {
                    "id": 1241688,
                    "contents": "Sunlight\nSee diffuse sky radiation for more details. Spectral composition of sunlight at Earth's surface The Sun may be said to illuminate, which is a measure of the light within a specific sensitivity range. Many animals (including humans) have a sensitivity range of approximately 400–700 nm, and given optimal conditions the absorption and scattering by Earth's atmosphere produces illumination that approximates an equal-energy illuminant for most of this range. The useful range for color vision in humans, for example, is approximately 450–650 nm. Aside from effects that arise at sunset and sunrise, the spectral composition changes primarily in respect to how directly sunlight is able to illuminate. When illumination is indirect, Rayleigh scattering in the upper atmosphere will lead blue wavelengths to dominate. Water vapour in the lower atmosphere produces further scattering and ozone, dust and water particles will also absorb particular wavelengths. Life on Earth",
                    "score": 0.8776370286941528
                },
                {
                    "id": 1328574,
                    "contents": "White dwarf\nThe visible radiation emitted by white dwarfs varies over a wide color range, from the blue-white color of an O-type main sequence star to the red of an M-type red dwarf. White dwarf effective surface temperatures extend from over 150,000 K to barely under 4,000 K. In accordance with the Stefan–Boltzmann law, luminosity increases with increasing surface temperature; this surface temperature range corresponds to a luminosity from over 100 times the Sun's to under that of the Sun's. Hot white dwarfs, with surface temperatures in excess of 30,000 K, have been observed to be sources of soft (i.e., lower-energy) X-rays. This enables the composition and structure of their atmospheres to be studied by soft X-ray and extreme ultraviolet observations. White dwarfs also radiate neutrinos through the Urca process.",
                    "score": 0.8775027990341187
                },
                {
                    "id": 16273888,
                    "contents": "Kosmos 262\nKosmos 262 was the first satellite to study VUV (Vacuum Ultraviolet light). The satellite was also first to study soft X-Ray radiation from the stars, the Sun and the Earth's upper atmosphere. The craft used three 16-channel photometers. The results were made public on October 1969. Kosmos 262 was the only DS-U2-GF satellite to be launched. It was operated in an orbit with a perigee of , an apogee of , 48.4 degrees of inclination, and an orbital period of 94.6 minutes. It completed operations on 3 May 1969, before decaying from orbit and reentering the atmosphere on 18 July. See also 1968 in spaceflight References Spacecraft launched in 1968 Kosmos satellites Dnepropetrovsk Sputnik program",
                    "score": 0.8773037791252136
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_35",
        "question": "When ultraviolet radiation of wavelength $58.4 \\mathrm{~nm}$ from a helium lamp is directed on to a sample of krypton, electrons are ejected with a speed of $1.59 \\times 10^6 \\mathrm{~m} \\mathrm{~s}^{-1}$. Calculate the ionization energy of krypton.\r\n",
        "golden_answers": [
            " 14"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 11293408,
                    "contents": "Krypton\nKrypton (from 'the hidden one') is a chemical element with the symbol Kr and atomic number 36. It is a colorless, odorless, tasteless noble gas that occurs in trace amounts in the atmosphere and is often used with other rare gases in fluorescent lamps. With rare exceptions, krypton is chemically inert. Krypton, like the other noble gases, is used in lighting and photography. Krypton light has many spectral lines, and krypton plasma is useful in bright, high-powered gas lasers (krypton ion and excimer lasers), each of which resonates and amplifies a single spectral line. Krypton fluoride also makes a useful laser medium. From 1960 to 1983, the official definition of meter was based on the wavelength of one spectral line of krypton-86, because of the high power and relative ease of operation of krypton discharge tubes. History",
                    "score": 0.899142861366272
                },
                {
                    "id": 11293410,
                    "contents": "Krypton\nIn 1960, the International Bureau of Weights and Measures defined the meter as 1,650,763.73 wavelengths of light emitted in the vacuum corresponding to the transition between the levels 2p10 and 5d5 of krypton-86 isotope . This agreement replaced the 1889 international prototype meter, which was a metal bar located in Sèvres. This also obsoleted the 1927 definition of the ångström based on the red cadmium spectral line, replacing it with 1 Å = 10−10 m. The krypton-86 definition lasted until the October 1983 conference, which redefined the meter as the distance that light travels in vacuum during 1/299,792,458 s. Characteristics Krypton is characterized by several sharp emission lines (spectral signatures) the strongest being green and yellow. Krypton is one of the products of uranium fission. Solid krypton is white and has a face-centered cubic crystal structure, which is a common property of all noble gases (except helium, which has a hexagonal close-packed crystal structure).",
                    "score": 0.8802070617675781
                },
                {
                    "id": 1115862,
                    "contents": "Ionization energy\nWhen ultraviolet light is used, the wavelength is swept down the ultraviolet range. At a certain wavelength (λ) and frequency of light (ν=c/λ, where c is the speed of light), the light quanta, whose energy is proportional to the frequency, will have energy high enough to dislodge the least bound electrons. These electrons will be attracted to the positive electrode, and the positive ions remaining after the photoionization will get attracted to the negatively charged electrode. These electrons and ions will establish a current through the tube. The ionization energy will be the energy of photons hνi (h is the Planck constant) that caused a steep rise in the current: Ei=hνi.",
                    "score": 0.8767609596252441
                },
                {
                    "id": 11293417,
                    "contents": "Krypton\nKrypton's white discharge is sometimes used as an artistic effect in gas discharge \"neon\" tubes. Krypton produces much higher light power than neon in the red spectral line region, and for this reason, red lasers for high-power laser light-shows are often krypton lasers with mirrors that select the red spectral line for laser amplification and emission, rather than the more familiar helium-neon variety, which could not achieve the same multi-watt outputs. The krypton fluoride laser is important in nuclear fusion energy research in confinement experiments. The laser has high beam uniformity, short wavelength, and the spot size can be varied to track an imploding pellet.",
                    "score": 0.8735641241073608
                },
                {
                    "id": 7421970,
                    "contents": "Extreme ultraviolet\nPoint of absorption: EUV photon energy = 92 eV, = Electron binding energy + photoelectron initial kinetic energy Within 3 mean free paths of photoelectron (1–2 nm): Reduction of photoelectron kinetic energy = ionization potential + secondary electron kinetic energy; Within 3 mean free paths of secondary electron (~30 nm): Reduction of secondary electron kinetic energy = ionization potential + tertiary electron kinetic energy mNth generation electron slows down aside from ionization by heating (phonon generation) Final generation electron kinetic energy ~ 0 eV => dissociative electron attachment + heat, where the ionization potential is typically 7–9 eV for organic materials and 4–5 eV for metals. The photoelectron subsequently causes the emission of secondary electrons through the process of impact ionization. Sometimes, an Auger transition is also possible, resulting in the emission of two electrons with the absorption of a single photon.",
                    "score": 0.8714646697044373
                },
                {
                    "id": 2544287,
                    "contents": "Flashtube\nKrypton and other gases All gases produce spectral lines which are specific to the gas, superimposed on a background of continuum radiation. With all gases, low current-densities produce mostly spectral lines, with the highest output being concentrated in the near-IR between 650 and 1000 nm. Krypton's strongest peaks are around 760 and 810 nm. Argon has many strong peaks at 670, 710, 760, 820, 860, and 920 nm. Neon has peaks around 650, 700, 850, and 880 nm. As current densities become higher, the output of continuum radiation will increase more than the spectral-line radiation at a rate 20% greater, and output center will shift toward the visual spectrum. At greybody current-densities there is only a slight difference in the spectrum emitted by various gases. At very high current-densities, all gases will begin to operate as blackbody radiators, with spectral outputs resembling a blue giant star, centered in the UV.",
                    "score": 0.8701253533363342
                },
                {
                    "id": 451647,
                    "contents": "Ionizing radiation\nThe lowest ionization energy of any element is 3.89 eV, for caesium. However, US Federal Communications Commission material defines ionizing radiation as that with a photon energy greater than 10 eV (equivalent to a far ultraviolet wavelength of 124 nanometers). Roughly, this corresponds to both the first ionization energy of oxygen, and the ionization energy of hydrogen, both about 14 eV. In some Environmental Protection Agency references, the ionization of a typical water molecule at an energy of 33 eV is referenced as the appropriate biological threshold for ionizing radiation: this value represents the so-called W-value, the colloquial name for the ICRU's mean energy expended in a gas per ion pair formed, which combines ionization energy plus the energy lost to other processes such as excitation. At 38 nanometers wavelength for electromagnetic radiation, 33 eV is close to the energy at the conventional 10 nm wavelength transition between extreme ultraviolet and X-ray radiation,",
                    "score": 0.864072322845459
                },
                {
                    "id": 7421971,
                    "contents": "Extreme ultraviolet\nStrictly speaking, photoelectrons, Auger electrons and secondary electrons are all accompanied by positively charged holes (ions which can be neutralized by pulling electrons from nearby molecules) in order to preserve charge neutrality. An electron-hole pair is often referred to as an exciton. For highly energetic electrons, the electron-hole separation can be quite large and the binding energy is correspondingly low, but at lower energy, the electron and hole can be closer to each other. The exciton itself diffuses quite a large distance (>10 nm). As the name implies, an exciton is an excited state; only when it disappears as the electron and hole recombine, can stable chemical reaction products form.",
                    "score": 0.8599438667297363
                },
                {
                    "id": 11293422,
                    "contents": "Krypton\nFurther reading William P. Kirk \"Krypton 85: a Review of the Literature and an Analysis of Radiation Hazards\", Environmental Protection Agency, Office of Research and Monitoring, Washington (1972) External links Krypton at The Periodic Table of Videos (University of Nottingham) Krypton Fluoride Lasers, Plasma Physics Division Naval Research Laboratory Chemical elements Noble gases",
                    "score": 0.8585628271102905
                },
                {
                    "id": 11293416,
                    "contents": "Krypton\nApplications Krypton's multiple emission lines make ionized krypton gas discharges appear whitish, which in turn makes krypton-based bulbs useful in photography as a white light source. Krypton is used in some photographic flashes for high speed photography. Krypton gas is also combined with mercury to make luminous signs that glow with a bright greenish-blue light. Krypton is mixed with argon in energy efficient fluorescent lamps, reducing the power consumption, but also reducing the light output and raising the cost. Krypton costs about 100 times as much as argon. Krypton (along with xenon) is also used to fill incandescent lamps to reduce filament evaporation and allow higher operating temperatures. A brighter light results with more blue color than conventional incandescent lamps.",
                    "score": 0.8578394055366516
                },
                {
                    "id": 7421965,
                    "contents": "Extreme ultraviolet\nExtreme ultraviolet radiation (EUV or XUV) or high-energy ultraviolet radiation is electromagnetic radiation in the part of the electromagnetic spectrum spanning wavelengths from 124 nm down to 10 nm, and therefore (by the Planck–Einstein equation) having photons with energies from 10 eV up to 124 eV. EUV is naturally generated by the solar corona and artificially by plasma, high harmonic generation sources and synchrotron light sources. Since UVC extends to 100 nm, there is some overlap in the terms. The main uses of extreme ultraviolet radiation are photoelectron spectroscopy, solar imaging, and lithography. In air, EUV is the most highly absorbed component of the electromagnetic spectrum, requiring high vacuum for transmission.",
                    "score": 0.8576017618179321
                },
                {
                    "id": 18326096,
                    "contents": "Photon energy\nThe photon energy at 1 μm wavelength, the wavelength of near infrared radiation, is approximately 1.2398 eV. In chemistry, quantum physics and optical engineering See where E is photon energy (joules), h is the Planck constant - 6.62607015 × 10−34 (m2kgs−1) The Greek letter ν (nu) is the photon's frequency. Examples An FM radio station transmitting at 100 MHz emits photons with an energy of about 4.1357 × 10−7 eV. This minuscule amount of energy is approximately 8 × 10−13 times the electron's mass (via mass-energy equivalence). Very-high-energy gamma rays have photon energies of 100 GeV to over 1 PeV (1011 to 1015 electronvolts) or 16 nanojoules to 160 microjoules. This corresponds to frequencies of 2.42 × 1025 to 2.42 × 1029 Hz.",
                    "score": 0.8552838563919067
                },
                {
                    "id": 1169159,
                    "contents": "Photoelectric effect\nMany substances besides metals discharge negative electricity under the action of ultraviolet light. G. C. Schmidt and O. Knoblauch compiled a list of these substances. In 1899, J. J. Thomson investigated ultraviolet light in Crookes tubes. Thomson deduced that the ejected particles, which he called corpuscles, were of the same nature as cathode rays. These particles later became known as the electrons. Thomson enclosed a metal plate (a cathode) in a vacuum tube, and exposed it to high-frequency radiation. It was thought that the oscillating electromagnetic fields caused the atoms' field to resonate and, after reaching a certain amplitude, caused subatomic corpuscles to be emitted, and current to be detected. The amount of this current varied with the intensity and color of the radiation. Larger radiation intensity or frequency would produce more current.",
                    "score": 0.8550342321395874
                },
                {
                    "id": 7576604,
                    "contents": "Ralph Kronig\ntheory. In the Kronig equation, energy positions Wn correspond to the zone boundaries, i. e. not the absorption maxima or minima, but the first rise in each fine structure maximum. abg are the Miller indices, a is the lattice constant and q is the angle between the electron direction and the reciprocal lattice direction. When averaged over all directions with a non-polarized x-ray beam and a polycrystalline absorber, cos2q = 1. However, with a single crystal absorber and polarized x-rays the absorption features should be larger for specific crystal planes. This was another experimental variable that might verify the theory and many attempted to test it. Thus began the long record of publications in which Kronig structure was interpreted in terms of the simple Kronig theory. Until the 1970s fully 2% of the papers published in Phys. Rev. were devoted to x-ray absorption spectroscopy and most invoked Kronig's theory.",
                    "score": 0.854017972946167
                },
                {
                    "id": 1206478,
                    "contents": "Radiation\nX-rays are also totally absorbed by the thickness of the earth's atmosphere, resulting in the prevention of the X-ray output of the sun, smaller in quantity than that of UV but nonetheless powerful, from reaching the surface. Gamma radiation Gamma (γ) radiation consists of photons with a wavelength less than 3x10−11 meters (greater than 1019 Hz and 41.4 keV). Gamma radiation emission is a nuclear process that occurs to rid an unstable nucleus of excess energy after most nuclear reactions. Both alpha and beta particles have an electric charge and mass, and thus are quite likely to interact with other atoms in their path. Gamma radiation, however, is composed of photons, which have neither mass nor electric charge and, as a result, penetrates much further through matter than either alpha or beta radiation.",
                    "score": 0.8534829020500183
                },
                {
                    "id": 1696337,
                    "contents": "Electronvolt\nA photon with a wavelength of (green light) would have an energy of approximately . Similarly, would correspond to an infrared photon of wavelength or frequency . Scattering experiments In a low-energy nuclear scattering experiment, it is conventional to refer to the nuclear recoil energy in units of eVr, keVr, etc. This distinguishes the nuclear recoil energy from the \"electron equivalent\" recoil energy (eVee, keVee, etc.) measured by scintillation light. For example, the yield of a phototube is measured in phe/keVee (photoelectrons per keV electron-equivalent energy). The relationship between eV, eVr, and eVee depends on the medium the scattering takes place in, and must be established empirically for each material. Energy comparisons Per mole One mole of particles given 1 eV of energy has approximately 96.5 kJ of energy – this corresponds to the Faraday constant (F ≈ ), where the energy in joules of n moles of particles each with energy E eV is equal to E·F·n.",
                    "score": 0.8534766435623169
                },
                {
                    "id": 1206493,
                    "contents": "Radiation\nThe occurrence of ionization depends on the energy of the individual particles or waves, and not on their number. An intense flood of particles or waves will not cause ionization if these particles or waves do not carry enough energy to be ionizing, unless they raise the temperature of a body to a point high enough to ionize small fractions of atoms or molecules by the process of thermal-ionization (this, however, requires relatively extreme radiation intensities). Ultraviolet light As noted above, the lower part of the spectrum of ultraviolet, called soft UV, from 3 eV to about 10 eV, is non-ionizing. However, the effects of non-ionizing ultraviolet on chemistry and the damage to biological systems exposed to it (including oxidation, mutation, and cancer) are such that even this part of ultraviolet is often compared with ionizing radiation. Visible light",
                    "score": 0.8526321053504944
                },
                {
                    "id": 17981715,
                    "contents": "Atmospheric-pressure laser ionization\nThe laser light sources used in APLI have power densities which allow multiphoton ionization via stable electronic states of the molecule or atom. The required power density has to be sufficiently high, so that in the lifetime of the first reached electronic state, which is in the range of a few nanoseconds, a second photon can be absorbed with a reasonable probability. Then a radical cation is formed: \\mathsf{M ->[{h\\nu\\ (5\\ \\ce{eV})}] M^\\ast ->[{h\\nu\\ (5\\ \\ce{eV})}] {M^{+.}}+ e^-} This process is called resonance enhanced multi photon ionization (REMPI). In the case of APLI both absorbed photons have the same wavelength, which is called \"1+1 REMPI\". Most of the organic molecules which are favorable for a photoionization method have ionization potentials smaller than approximately 10 eV. Thus APLI utilizes light with a photon energy of around 5 eV which corresponds to a wavelength of about 250 nm, which is in the ultraviolet (UV) part of the electromagnetic spectrum.",
                    "score": 0.8523358106613159
                },
                {
                    "id": 7421967,
                    "contents": "Extreme ultraviolet\nNeutral atoms or condensed matter cannot emit EUV radiation. Ionization must take place first. EUV light can only be emitted by electrons which are bound to multicharged positive ions; for example, to remove an electron from a +3 charged carbon ion (three electrons already removed) requires about 65 eV. Such electrons are more tightly bound than typical valence electrons. The existence of multicharged positive ions is only possible in a hot dense plasma. Alternatively, the free electrons and ions may be generated temporarily and instantaneously by the intense electric field of a very-high-harmonic laser beam. The electrons accelerate as they return to the parent ion, releasing higher energy photons at diminished intensities, which may be in the EUV range. If the released photons constitute ionizing radiation, they will also ionize the atoms of the harmonic-generating medium, depleting the sources of higher-harmonic generation. The freed electrons escape since the electric field of the",
                    "score": 0.8516875505447388
                },
                {
                    "id": 11985718,
                    "contents": "Lyman–Werner photons\nA Lyman-Werner photon is an ultraviolet photon with a photon energy in the range of 11.2 to 13.6 eV, corresponding to the energy range in which the Lyman and Werner absorption bands of molecular hydrogen (H2) are found. A photon in this energy range, with a frequency that coincides with that of one of the lines in the Lyman or Werner bands, can be absorbed by H2, placing the molecule in an excited electronic state. Radiative decay (that is, decay into photons) from this excited state occurs rapidly, with roughly 15% of these decays occurring into the vibrational continuum of the molecule, resulting in its dissociation. This two-step photodissociation process, known as the Solomon process, is one of the main mechanisms by which molecular hydrogen is destroyed in the interstellar medium.",
                    "score": 0.8508388996124268
                },
                {
                    "id": 10367808,
                    "contents": "Ultraviolet photoelectron spectroscopy\nUltraviolet photoelectron spectroscopy (UPS) refers to the measurement of kinetic energy spectra of photoelectrons emitted by molecules which have absorbed ultraviolet photons, in order to determine molecular orbital energies in the valence region. Basic theory If Albert Einstein's photoelectric law is applied to a free molecule, the kinetic energy () of an emitted photoelectron is given by , where h is Planck's constant, ν is the frequency of the ionizing light, and I is an ionization energy for the formation of a singly charged ion in either the ground state or an excited state. According to Koopmans' theorem, each such ionization energy may be identified with the energy of an occupied molecular orbital. The ground-state ion is formed by removal of an electron from the highest occupied molecular orbital, while excited ions are formed by removal of an electron from a lower occupied orbital.",
                    "score": 0.8503537178039551
                },
                {
                    "id": 10022996,
                    "contents": "Lyman continuum photons\nThe Lyman limit is at the wavelength of 91.2 nm (912 Å), corresponding to a frequency of 3.29 million GHz and a photon energy of 13.6 eV. LyC energies are mostly in the ultraviolet C portion of the electromagnetic spectrum (see Lyman series). Although X-rays and gamma-rays will also ionize a hydrogen atom, there are far fewer of them emitted from a star's photosphere—LyC are predominantly UV-C. The photon absorption process leading to the ionization of atomic hydrogen can occur in reverse: an electron and a proton can collide and form atomic hydrogen. If the two particles were traveling slowly (so that kinetic energy can be ignored), then the photon the atom emits upon its creation will theoretically be 13.6 eV (in reality, the energy will be less if the atom is formed in an excited state). At faster speeds, the excess (kinetic) energy is radiated (but momentum must be conserved) as photons of lower wavelength (higher energy). Therefore, photons with energies above 13.6 eV are emitted",
                    "score": 0.8494663238525391
                },
                {
                    "id": 11293415,
                    "contents": "Krypton\nThe reaction of with produces an unstable compound, , that contains a krypton-oxygen bond. A krypton-nitrogen bond is found in the cation [HC≡N–Kr–F], produced by the reaction of with [HC≡NH][AsF] below −50 °C. HKrCN and HKrC≡CH (krypton hydride-cyanide and hydrokryptoacetylene) were reported to be stable up to 40 K. Krypton hydride (Kr(H2)4) crystals can be grown at pressures above 5 GPa. They have a face-centered cubic structure where krypton octahedra are surrounded by randomly oriented hydrogen molecules. Natural occurrence Earth has retained all of the noble gases that were present at its formation except helium. Krypton's concentration in the atmosphere is about 1 ppm. It can be extracted from liquid air by fractional distillation. The amount of krypton in space is uncertain, because measurement is derived from meteoric activity and solar winds. The first measurements suggest an abundance of krypton in space. Applications",
                    "score": 0.8488867282867432
                },
                {
                    "id": 10108512,
                    "contents": "Robert Strutt, 4th Baron Rayleigh\nFollowing the death of his father in 1919, Strutt resigned his chair at Imperial College but continued to experiment at home in the private laboratory that his father had established in an old stable block. His earlier work on gaseous discharge and fluorescence, led to further work on the luminosity of the night sky. He was the first to differentiate between two types of light from the night sky, the aurora or \"northern lights\", and the airglow that prevents the sky ever being completely dark anywhere on earth. In 1929 he was the first to measure the intensity of the light from the night sky. This work led to his posthumous nickname \"the Airglow Rayleigh\". The importance of his unpublished data was such that the US Airforce Cambridge Research Laboratories acquired it in 1963, almost by accident, at the same time of many of his father's experimental notebooks. They are now housed in the McDermott Library of the US Air Force Academy, Colorado Springs, Colorado.",
                    "score": 0.8485578894615173
                },
                {
                    "id": 381768,
                    "contents": "Planck's law\nThe quantity is the spectral radiance as a function of temperature and frequency. It has units of W·m−2·sr−1·Hz−1 in the SI system. An infinitesimal amount of power is radiated in the direction described by the angle from the surface normal from infinitesimal surface area into infinitesimal solid angle in an infinitesimal frequency band of width centered on frequency . The total power radiated into any solid angle is the integral of over those three quantities, and is given by the Stefan–Boltzmann law. The spectral radiance of Planckian radiation from a black body has the same value for every direction and angle of polarization, and so the black body is said to be a Lambertian radiator.",
                    "score": 0.8483172655105591
                },
                {
                    "id": 1241672,
                    "contents": "Sunlight\nThe total amount of energy received at ground level from the Sun at the zenith depends on the distance to the Sun and thus on the time of year. It is about 3.3% higher than average in January and 3.3% lower in July (see below). If the extraterrestrial solar radiation is 1367 watts per square meter (the value when the Earth–Sun distance is 1 astronomical unit), then the direct sunlight at Earth's surface when the Sun is at the zenith is about 1050 W/m2, but the total amount (direct and indirect from the atmosphere) hitting the ground is around 1120 W/m2. In terms of energy, sunlight at Earth's surface is around 52 to 55 percent infrared (above 700 nm), 42 to 43 percent visible (400 to 700 nm), and 3 to 5 percent ultraviolet (below 400 nm). At the top of the atmosphere, sunlight is about 30% more intense, having about 8% ultraviolet (UV), with most of the extra UV consisting of biologically damaging short-wave ultraviolet.",
                    "score": 0.8483098745346069
                },
                {
                    "id": 5851780,
                    "contents": "Ion laser\nTypes Krypton laser A krypton laser is an ion laser using ions of the noble gas krypton as its gain medium. The laser pumping is done by an electrical discharge. Krypton lasers are widely used in scientific research, and in commercial uses, when the krypton is mixed with argon, it creates a \"white-light\" lasers, useful for laser light shows. Krypton lasers are also used in medicine (e.g. for coagulation of retina), for the manufacture of security holograms, and numerous other purposes. Krypton lasers can emit visible light close to several different wavelengths, commonly 406.7 nm, 413.1 nm, 415.4 nm, 468.0 nm, 476.2 nm, 482.5 nm, 520.8 nm, 530.9 nm, 568.2 nm, 647.1 nm, and 676.4 nm. Argon laser The argon-ion laser was invented in 1964 by William Bridges at the Hughes Aircraft Company and it is one of the family of ion lasers that use a noble gas as the active medium.",
                    "score": 0.8477401733398438
                },
                {
                    "id": 1337239,
                    "contents": "Xenon\nWhen xenon atoms are in the ground energy state, they repel each other and will not form a bond. When xenon atoms becomes energized, however, they can form an excimer (excited dimer) until the electrons return to the ground state. This entity is formed because the xenon atom tends to complete the outermost electronic shell by adding an electron from a neighboring xenon atom. The typical lifetime of a xenon excimer is 1–5 nanoseconds, and the decay releases photons with wavelengths of about 150 and 173 nm. Xenon can also form excimers with other elements, such as the halogens bromine, chlorine, and fluorine. Applications Although xenon is rare and relatively expensive to extract from the Earth's atmosphere, it has a number of applications. Illumination and optics",
                    "score": 0.8473641276359558
                },
                {
                    "id": 652366,
                    "contents": "Spectral line\nVisible light For each element, the following table shows the spectral lines which appear in the visible spectrum at about 400-700 nm. See also Absorption spectrum Atomic spectral line Bohr model Electron configuration Emission spectrum Fourier transform Fraunhofer line Table of emission spectra of gas discharge lamps Hydrogen line (21-cm line) Hydrogen spectral series Spectroscopy Splatalogue Notes References Further reading Spectroscopy Emission spectroscopy",
                    "score": 0.847358226776123
                },
                {
                    "id": 1693533,
                    "contents": "Electromagnetic radiation\nAt the higher end of the ultraviolet range, the energy of photons becomes large enough to impart enough energy to electrons to cause them to be liberated from the atom, in a process called photoionisation. The energy required for this is always larger than about 10 electron volt (eV) corresponding with wavelengths smaller than 124 nm (some sources suggest a more realistic cutoff of 33 eV, which is the energy required to ionize water). This high end of the ultraviolet spectrum with energies in the approximate ionization range, is sometimes called \"extreme UV.\" Ionizing UV is strongly filtered by the Earth's atmosphere. X-rays and gamma rays",
                    "score": 0.8473163843154907
                },
                {
                    "id": 7421968,
                    "contents": "Extreme ultraviolet\nionizing radiation, they will also ionize the atoms of the harmonic-generating medium, depleting the sources of higher-harmonic generation. The freed electrons escape since the electric field of the EUV light is not intense enough to drive the electrons to higher harmonics, while the parent ions are no longer as easily ionized as the originally neutral atoms. Hence, the processes of EUV generation and absorption (ionization) strongly compete against each other.",
                    "score": 0.8472709655761719
                },
                {
                    "id": 11177060,
                    "contents": "Heinrich Rubens\nThrough the improvements of instruments and invention of new techniques he could measure infrared radiation for larger and larger wavelengths. One of his goals was to better understand the reflexion of radiation by metals and crystals. It was known that this became stronger for wavelengths which were absorbed. This lead him to a new, powerful method by selective reflexion from several crystals to isolate a narrow range of infrared wavelengths from a broader spectrum of radiation. Using such Reststrahlen he could in 1898 detect wavelengths of sizes around 60 μm. Together with Ferdinand Kurlbaum he started the same year to measure the energy content of black-body radiation in the far infrared region using this technique. For a fixed value of the wavelength they found that the energy increased linearly with the temperature. This was in disagreement with the ruling Wien's radiation law, but consistent with an alternative law proposed by Lord Rayleigh.",
                    "score": 0.847122848033905
                },
                {
                    "id": 1169141,
                    "contents": "Photoelectric effect\nAs sunlight, due to atmosphere's absorption, does not provide much ultraviolet light, the light rich in ultraviolet rays used to be obtained by burning magnesium or from an arc lamp. At the present time, mercury-vapor lamps, noble-gas discharge UV lamps and radio-frequency plasma sources, ultraviolet lasers, and synchrotron insertion device light sources prevail. The classical setup to observe the photoelectric effect includes a light source, a set of filters to monochromatize the light, a vacuum tube transparent to ultraviolet light, an emitting electrode (E) exposed to the light, and a collector (C) whose voltage VC can be externally controlled.",
                    "score": 0.8470802903175354
                },
                {
                    "id": 1787244,
                    "contents": "Ionosphere\nUltraviolet (UV), X-ray and shorter wavelengths of solar radiation are ionizing, since photons at these frequencies contain sufficient energy to dislodge an electron from a neutral gas atom or molecule upon absorption. In this process the light electron obtains a high velocity so that the temperature of the created electronic gas is much higher (of the order of thousand K) than the one of ions and neutrals. The reverse process to ionization is recombination, in which a free electron is \"captured\" by a positive ion. Recombination occurs spontaneously, and causes the emission of a photon carrying away the energy produced upon recombination. As gas density increases at lower altitudes, the recombination process prevails, since the gas molecules and ions are closer together. The balance between these two processes determines the quantity of ionization present.",
                    "score": 0.8469336032867432
                },
                {
                    "id": 11985719,
                    "contents": "Lyman–Werner photons\nIn reference to the figure shown, Lyman-Werner photons are emitted as described below: A hydrogen molecule can absorb a far-ultraviolet photon (11.2eV<energy of the photon<13.6eV) and make a transition from the ground electronic state X to excited state B (Lyman) or C (Werner). Radiative decay occurs rapidly. 10-15% of the decays occur into the vibrational continuum. This means that the hydrogen molecule has dissociated. Photo-dissociation fragments carry away some of the photon energy as kinetic energy, heating the gas. Rest of the decays are either radiative decay (infrared emission) or collisional, which ultimately end up heating the gas. References Photons",
                    "score": 0.8463495969772339
                },
                {
                    "id": 1206506,
                    "contents": "Radiation\nIn 1801, the German physicist Johann Wilhelm Ritter made the discovery of ultraviolet by noting that the rays from a prism darkened silver chloride preparations more quickly than violet light. Ritter's experiments were an early precursor to what would become photography. Ritter noted that the UV rays were capable of causing chemical reactions. The first radio waves detected were not from a natural source, but were produced deliberately and artificially by the German scientist Heinrich Hertz in 1887, using electrical circuits calculated to produce oscillations in the radio frequency range, following formulas suggested by the equations of James Clerk Maxwell. Wilhelm Röntgen discovered and named X-rays. While experimenting with high voltages applied to an evacuated tube on 8 November 1895, he noticed a fluorescence on a nearby plate of coated glass. Within a month, he discovered the main properties of X-rays that we understand to this day.",
                    "score": 0.8462087512016296
                },
                {
                    "id": 7046754,
                    "contents": "Kramers–Kronig relations\nIn short, by measuring the number of high energy (e.g. 200 keV) electrons which lose a given amount of energy in traversing a very thin specimen (single scattering approximation), one can calculate the imaginary part of permittivity at that energy. Using this data with Kramers–Kronig analysis, one can calculate the real part of permittivity (as a function of energy) as well. This measurement is made with electrons, rather than with light, and can be done with very high spatial resolution. One might thereby, for example, look for ultraviolet (UV) absorption bands in a laboratory specimen of interstellar dust less than a 100 nm across, i.e. too small for UV spectroscopy. Although electron spectroscopy has poorer energy resolution than light spectroscopy, data on properties in visible, ultraviolet and soft x-ray spectral ranges may be recorded in the same experiment.",
                    "score": 0.8461185097694397
                },
                {
                    "id": 1693535,
                    "contents": "Electromagnetic radiation\nAtmosphere and magnetosphere Most UV and X-rays are blocked by absorption first from molecular nitrogen, and then (for wavelengths in the upper UV) from the electronic excitation of dioxygen and finally ozone at the mid-range of UV. Only 30% of the Sun's ultraviolet light reaches the ground, and almost all of this is well transmitted. Visible light is well transmitted in air, as it is not energetic enough to excite nitrogen, oxygen, or ozone, but too energetic to excite molecular vibrational frequencies of water vapor. Absorption bands in the infrared are due to modes of vibrational excitation in water vapor. However, at energies too low to excite water vapor, the atmosphere becomes transparent again, allowing free transmission of most microwave and radio waves.",
                    "score": 0.8460583686828613
                },
                {
                    "id": 3249446,
                    "contents": "Photoemission spectroscopy\nTypical PES (UPS) instruments use helium gas sources of UV light, with photon energy up to 52 eV (corresponding to wavelength 23.7 nm). The photoelectrons that actually escaped into the vacuum are collected, slightly retarded, energy resolved, and counted. This results in a spectrum of electron intensity as a function of the measured kinetic energy. Because binding energy values are more readily applied and understood, the kinetic energy values, which are source dependent, are converted into binding energy values, which are source independent. This is achieved by applying Einstein's relation . The term of this equation is the energy of the UV light quanta that are used for photoexcitation. Photoemission spectra are also measured using tunable synchrotron radiation sources.",
                    "score": 0.8456622362136841
                },
                {
                    "id": 2666394,
                    "contents": "H-alpha\nFor the Lyman series the naming convention is: n = 2 to n = 1 is called Lyman-alpha, n = 3 to n = 1 is called Lyman-beta, etc. H-alpha has a wavelength of 656.281 nm, is visible in the red part of the electromagnetic spectrum, and is the easiest way for astronomers to trace the ionized hydrogen content of gas clouds. Since it takes nearly as much energy to excite the hydrogen atom's electron from n = 1 to n = 3 (12.1 eV, via the Rydberg formula) as it does to ionize the hydrogen atom (13.6 eV), ionization is far more probable than excitation to the n = 3 level. After ionization, the electron and proton recombine to form a new hydrogen atom. In the new atom, the electron may begin in any energy level, and subsequently cascades to the ground state (n = 1), emitting photons with each transition. Approximately half the time, this cascade will include the n = 3 to n = 2 transition and the atom will emit H-alpha light. Therefore, the H-alpha line occurs where hydrogen is being ionized.",
                    "score": 0.8454955816268921
                },
                {
                    "id": 24392618,
                    "contents": "Hermann Ebert\nHis name is associated with the \"Ebert-Fastie spectrometer\", an optical device built by William George Fastie of Johns Hopkins University based on Ebert's design of a monochromator in 1889, and \"Ebert's apparatus\", an electrometer used to measure the concentration of atmospheric ions.",
                    "score": 0.845315158367157
                },
                {
                    "id": 11448471,
                    "contents": "Krypton difluoride\nIt is clear from these results that higher-energy ultraviolet light reduces the yield significantly. The ideal circumstances for the production KrF2 by a photochemical process appear to occur when krypton is a solid and fluorine is a liquid, which occur at 77 K. The biggest problem with this method is that it requires the handling of liquid F2 and the potential of it being released if it becomes overpressurized.",
                    "score": 0.8452783823013306
                },
                {
                    "id": 4593503,
                    "contents": "Frederick Sumner Brackett\nGeneral references Frederick Sumner Brackett, An Examination of the Infra-Red Spectrum of the Sun, lambda 8900 - lambda 9900, Astrophysical Journal, vol. 53, (1921) p. 121; Frederick Sumner Brackett, Visible and Infra-Red Radiation of Hydrogen; Ph.D. dissertation, Johns Hopkins University, 1922 Frederick Sumner Brackett, Visible and Infra-Red Radiation of Hydrogen; Astrophysical Journal, vol. 56, (1922) p. 154; Frederick Sumner Brackett, Graphic correlation of radiation and biological data, City of Washington, The Smithsonian Institution, 1932, 1 p. l., 7 p. diagrs. 24½ cm F. S. Brackett and Earl S. Johnston, The functions of radiation in the physiology of plants, City of Washington, Smithsonian Institution, 1932, 2 v. illus., plates, diagrs. 25 cm.",
                    "score": 0.844562292098999
                },
                {
                    "id": 1785724,
                    "contents": "Infrared\n1892: Willem Henri Julius published infrared spectra of 20 organic compounds measured with a bolometer in units of angular displacement. 1901: Max Planck published the blackbody equation and theorem. He solved the problem by quantizing the allowable energy transitions. 1905: Albert Einstein developed the theory of the photoelectric effect. 1905–1908: William Coblentz published infrared spectra in units of wavelength (micrometers) for several chemical compounds in Investigations of Infra-Red Spectra. 1917: Theodore Case developed the thallous sulfide detector; British scientist built the first infra-red search and track (IRST) device able to detect aircraft at a range of one mile (1.6 km). 1935: Lead salts – early missile guidance in World War II. 1938: Yeou Ta predicted that the pyroelectric effect could be used to detect infrared radiation. 1945: The Zielgerät 1229 \"Vampir\" infrared weapon system was introduced as the first portable infrared device for military applications.",
                    "score": 0.844506561756134
                },
                {
                    "id": 451644,
                    "contents": "Ionizing radiation\nPhoton radiation Even though photons are electrically neutral, they can ionize atoms indirectly through the photoelectric effect and the Compton effect. Either of those interactions will cause the ejection of an electron from an atom at relativistic speeds, turning that electron into a beta particle (secondary beta particle) that will ionize other atoms. Since most of the ionized atoms are due to the secondary beta particles, photons are indirectly ionizing radiation. Radiated photons are called gamma rays if they are produced by a nuclear reaction, subatomic particle decay, or radioactive decay within the nucleus. They are called x-rays if produced outside the nucleus. The generic term \"photon\" is used to describe both.",
                    "score": 0.8444421887397766
                },
                {
                    "id": 6886620,
                    "contents": "Isotopes of krypton\nAtmospheric concentration The atmospheric concentration of krypton-85 around the North Pole is about 30 percent higher than that at the Amundsen–Scott South Pole Station because nearly all of the world's nuclear reactors and all of its major nuclear reprocessing plants are located in the northern hemisphere, and also well-north of the equator. To be more specific, those nuclear reprocessing plants with significant capacities are located in the United States, the United Kingdom, the French Republic, the Russian Federation, Mainland China (PRC), Japan, India, and Pakistan. Krypton-86 Krypton-86 was formerly used to define the meter from 1960 until 1983, when the definition of the meter was based on the wavelength of the 606 nm (orange) spectral line of a krypton-86 atom. Others All other radioisotopes of krypton have half-lives of less than one day, except for krypton-79, a positron emitter with a half-life of about 35.0 hours. References Isotope masses from:",
                    "score": 0.8441728949546814
                },
                {
                    "id": 1785723,
                    "contents": "Infrared\n1830: Leopoldo Nobili made the first thermopile IR detector. 1840: John Herschel produces the first thermal image, called a thermogram. 1860: Gustav Kirchhoff formulated the blackbody theorem . 1873: Willoughby Smith discovered the photoconductivity of selenium. 1878: Samuel Pierpont Langley invents the first bolometer, a device which is able to measure small temperature fluctuations, and thus the power of far infrared sources. 1879: Stefan–Boltzmann law formulated empirically that the power radiated by a blackbody is proportional to T4. 1880s and 1890s: Lord Rayleigh and Wilhelm Wien solved part of the blackbody equation, but both solutions diverged in parts of the electromagnetic spectrum. This problem was called the \"ultraviolet catastrophe and infrared catastrophe\". 1892: Willem Henri Julius published infrared spectra of 20 organic compounds measured with a bolometer in units of angular displacement.",
                    "score": 0.8441318273544312
                },
                {
                    "id": 10022994,
                    "contents": "Lyman continuum photons\nLyman continuum photons (abbrev. LyC), shortened to Ly continuum photons or Lyc photons, are the photons emitted from stars at photon energies above the Lyman limit. Hydrogen is ionized by absorbing LyC. Working from Victor Schumann's discovery of ultraviolet light, from 1906 to 1914, Theodore Lyman observed that atomic hydrogen absorbs light only at specific frequencies (or wavelengths) and the Lyman series is thus named after him. All the wavelengths in the Lyman series are in the ultraviolet band. This quantized absorption behavior occurs only up to an energy limit, known as the ionization energy. In the case of neutral atomic hydrogen, the minimum ionization energy is equal to the Lyman limit, where the photon has enough energy to completely ionize the atom, resulting in a free proton and a free electron. Above this energy (below this wavelength), all wavelengths of light may be absorbed. This forms a continuum in the energy spectrum; the spectrum is continuous rather than composed",
                    "score": 0.844106912612915
                },
                {
                    "id": 24050460,
                    "contents": "Roy Henry Garstang\nDuring his career, he published over 50 papers, including calculations on neutral technetium and line strengths for ionized neon. He also calculated the energy levels and spectra of highly ionized species of iron, and spent time studying the effects of strong magnetic field on atomic spectra, ranging from the thousand gauss fields of sunspots to megagauss fields of white dwarfs. Late career Later in his career, Garstang began to work on light pollution. Between 1984 and 2007, he published 40 scientific papers concerning the phenomenon, and constructed a light pollution model which included an ozone layer, scattering of light by molecules and aerosols with improved variations with altitude, curvature of the earth, and a dust layer of dust either volcanic or desert origin. The models he created have since become standard in the field, and led to efforts to reduce light pollution in urban areas. References",
                    "score": 0.8439040184020996
                },
                {
                    "id": 10733352,
                    "contents": "Walther Kossel\nof photoelectrons. In 1919, Kossel and Sommerfeld explained the similarity of the atomic spectra of neutral atoms, of atomic number Z, and singly ionized atoms, of atomic number Z + 1, which became known as the Sommerfeld–Kossel displacement law. In 1920, Kossel explained another phenomenon of x-ray spectra. Under high resolution spectroscopy, the absorption edge has structure. He attributed this to absorption of radiation by electrons which are not ejected from matter as photoelectrons, but are “kicked up” to higher, unoccupied, bound electron energy levels. In early years, this was known as “Kossel structure.”",
                    "score": 0.8437193632125854
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_36",
        "question": " If $125 \\mathrm{~cm}^3$ of hydrogen gas effuses through a small hole in 135 seconds, how long will it take the same volume of oxygen gas to effuse under the same temperature and pressure?",
        "golden_answers": [
            " 537"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 3076973,
                    "contents": "John Frederic Daniell\nThe lunar crater Daniell is named after him. See also Timeline of hydrogen technologies References Bibliography 1790 births 1845 deaths English physicists English inventors English chemists Academics of King's College London Fellows of the Royal Society People of the Industrial Revolution Recipients of the Copley Medal Royal Medal winners Battery inventors People associated with electricity",
                    "score": 0.8797036409378052
                },
                {
                    "id": 17576271,
                    "contents": "Timeline of hydrogen technologies\n18th century 1755 – Joseph Black confirmed that different gases exist. / Latent heat 1766 – Henry Cavendish published in \"On Factitious Airs\" a description of \"dephlogisticated air\" by reacting zinc metal with hydrochloric acid and isolated a gas 7 to 11 times lighter than air. 1774 – Joseph Priestley isolated and categorized oxygen. 1780 – Felice Fontana discovers the water-gas shift reaction 1783 – Antoine Lavoisier gave hydrogen its name (Gk: hydro = water, genes = born of) 1783 – Jacques Charles made the first flight with his hydrogen balloon \"La Charlière\". 1783 – Antoine Lavoisier and Pierre Laplace measured the heat of combustion of hydrogen using an ice calorimeter. 1784 – Jean-Pierre Blanchard, attempted a dirigible hydrogen balloon, but it would not steer. 1784 – The invention of the Lavoisier Meusnier iron-steam process, generating hydrogen by passing water vapor over a bed of red-hot iron at 600 °C.",
                    "score": 0.87785404920578
                },
                {
                    "id": 4425785,
                    "contents": "Stanley Meyer's water fuel cell\nThe water fuel cell purportedly split water into its component elements, hydrogen and oxygen. The hydrogen gas was then burned to generate energy, a process that reconstituted the water molecules. According to Meyer, the device required less energy to perform electrolysis than the minimum energy requirement predicted or measured by conventional science. The mechanism of action was alleged to involve \"Brown's gas,\" a mixture of oxyhydrogen with a ratio of 2:1, the same composition as liquid water; which would then be mixed with ambient air (nitrogen, oxygen, carbon dioxide, carbon monoxide, methane, chlorofluorocarbons, free radicals/electrons, radiation, among others). The resultant hydrogen gas was then burned to generate energy, which reconstituted the water molecules in another unit separate from the unit in which water was separated. If the device worked as specified, it would violate both the first and second laws of thermodynamics, allowing operation as a perpetual motion",
                    "score": 0.8713257312774658
                },
                {
                    "id": 8172035,
                    "contents": "Hofmann voltameter\nA Hofmann voltameter is often used as a demonstration of stoichiometric principles, as the two-to-one ratio of the volumes of hydrogen and oxygen gas produced by the apparatus illustrates the chemical formula of water, H2O. However, this is only true if oxygen and hydrogen gases are assumed to be diatomic. If hydrogen gas were monatomic and oxygen diatomic, the gas volume ratio would be 4:1. The volumetric composition of water is the ratio by volume of hydrogen to oxygen present. This value is 2:1 experimentally; this value is determined using Hofmann's water voltameter. See also Timeline of hydrogen technologies References Electrolytic cells Hydrogen technologies Hydrogen production",
                    "score": 0.8710588216781616
                },
                {
                    "id": 17576275,
                    "contents": "Timeline of hydrogen technologies\n1849 – Eugène Bourdon – Bourdon gauge (manometer) 1863 – Etienne Lenoir made a test drive from Paris to Joinville-le-Pont with the 1-cylinder, 2-stroke Hippomobile. 1866 – August Wilhelm von Hofmann invents the Hofmann voltameter for the electrolysis of water. 1873 – Thaddeus S. C. Lowe – Water gas, the process used the water gas shift reaction. 1874 – Jules Verne – The Mysterious Island, \"water will one day be employed as fuel, that hydrogen and oxygen of which it is constituted will be used\" 1884 – Charles Renard and Arthur Constantin Krebs launch the airship La France. 1885 – Zygmunt Florenty Wróblewski published hydrogen's critical temperature as 33 K; critical pressure, 13.3 atmospheres; and boiling point, 23 K. 1889 – Ludwig Mond and Carl Langer coined the name fuel cell and tried to build one running on air and Mond gas. 1893 – Friedrich Wilhelm Ostwald experimentally determined the interconnected roles of the various components of the fuel cell. 1895 – Hydrolysis",
                    "score": 0.8699265718460083
                },
                {
                    "id": 17576270,
                    "contents": "Timeline of hydrogen technologies\nThis is a timeline of the history of hydrogen technology. Timeline 16th century c. 1520 – First recorded observation of hydrogen by Paracelsus through dissolution of metals (iron, zinc, and tin) in sulfuric acid. 17th century 1625 – First description of hydrogen by Johann Baptista van Helmont. First to use the word \"gas\". 1650 – Turquet de Mayerne obtained a gas or \"inflammable air\" by the action of dilute sulphuric acid on iron. 1662 – Boyle's law (gas law relating pressure and volume) 1670 – Robert Boyle produced hydrogen by reacting metals with acid. 1672 – \"New Experiments touching the Relation between Flame and Air\" by Robert Boyle. 1679 – Denis Papin – safety valve 1700 – Nicolas Lemery showed that the gas produced in the sulfuric acid/iron reaction was explosive in air",
                    "score": 0.8681507110595703
                },
                {
                    "id": 13703870,
                    "contents": "William E. Sawyer\nof gas for the same illumination. Sawyer was inspired to contrive many electrical devices that solved many problems of the day that baffled other engineers and ultimately patented seventy-five of his apparatuses.",
                    "score": 0.8681327104568481
                },
                {
                    "id": 1105013,
                    "contents": "Liquid hydrogen\nSee also Industrial gas Liquefaction of gases Hydrogen safety Compressed hydrogen Cryo-adsorption Expansion ratio Gasoline gallon equivalent Slush hydrogen Solid hydrogen Metallic hydrogen Hydrogen infrastructure Hydrogen-powered aircraft Liquid hydrogen tank car Liquid hydrogen tanktainer References Hydrogen physics Hydrogen technologies Hydrogen storage Liquid fuels Rocket fuels Coolants Cryogenics Hydrogen Industrial gases 1898 in science",
                    "score": 0.8674324154853821
                },
                {
                    "id": 5674337,
                    "contents": "Nascent hydrogen\nThe term \"nascent hydrogen\" continued to be invoked into the 20th Century. See Also Atomic hydrogen References Further reading Hydrogen Electrolysis Hydrogen Obsolete scientific theories",
                    "score": 0.8667959570884705
                },
                {
                    "id": 14379527,
                    "contents": "Hydrox (breathing gas)\nZetterström showed that hydrogen was perfectly usable to great depths. Following a fault in using the surface equipment, he died during a demonstration dive. The study of hydrogen was not resumed until several years later by the United States Navy and by the Compagnie maritime d'expertises (Comex), initially during their Hydra I and Hydra II experiments, in 1968 and 1969. Comex subsequently developed procedures allowing dives between 500 and 700 metres (1650 to 2300 feet) in depth, while breathing gas mixtures based on hydrogen, called hydrox (hydrogen-oxygen) or hydreliox (hydrogen-helium-oxygen). Memorial dives",
                    "score": 0.8650962114334106
                },
                {
                    "id": 1753327,
                    "contents": "Hydrogen\nHistory Discovery and use In 1671, Robert Boyle discovered and described the reaction between iron filings and dilute acids, which results in the production of hydrogen gas. In 1766, Henry Cavendish was the first to recognize hydrogen gas as a discrete substance, by naming the gas from a metal-acid reaction \"inflammable air\". He speculated that \"inflammable air\" was in fact identical to the hypothetical substance called \"phlogiston\" and further finding in 1781 that the gas produces water when burned. He is usually given credit for the discovery of hydrogen as an element. In 1783, Antoine Lavoisier gave the element the name hydrogen (from the Greek ὑδρο- hydro meaning \"water\" and -γενής genes meaning \"former\") when he and Laplace reproduced Cavendish's finding that water is produced when hydrogen is burned.",
                    "score": 0.8646221160888672
                },
                {
                    "id": 11242054,
                    "contents": "Timeline of chemistry\n1662Robert Boyle proposes Boyle's law, an experimentally based description of the behavior of gases, specifically the relationship between pressure and volume. 1735Swedish chemist Georg Brandt analyzes a dark blue pigment found in copper ore. Brandt demonstrated that the pigment contained a new element, later named cobalt. 1754Joseph Black isolates carbon dioxide, which he called \"fixed air\". 1757Louis Claude Cadet de Gassicourt, while investigating arsenic compounds, creates Cadet's fuming liquid, later discovered to be cacodyl oxide, considered to be the first synthetic organometallic compound. 1758Joseph Black formulates the concept of latent heat to explain the thermochemistry of phase changes. 1766Henry Cavendish discovers hydrogen as a colorless, odourless gas that burns and can form an explosive mixture with air. 1773–1774 Carl Wilhelm Scheele and Joseph Priestley independently isolate oxygen, called by Priestley \"dephlogisticated air\" and Scheele \"fire air\".",
                    "score": 0.8639541268348694
                },
                {
                    "id": 1128053,
                    "contents": "Noble gas\nSince the Hindenburg disaster in 1937, helium has replaced hydrogen as a lifting gas in blimps and balloons due to its lightness and incombustibility, despite an 8.6% decrease in buoyancy. In many applications, the noble gases are used to provide an inert atmosphere. Argon is used in the synthesis of air-sensitive compounds that are sensitive to nitrogen. Solid argon is also used for the study of very unstable compounds, such as reactive intermediates, by trapping them in an inert matrix at very low temperatures. Helium is used as the carrier medium in gas chromatography, as a filler gas for thermometers, and in devices for measuring radiation, such as the Geiger counter and the bubble chamber. Helium and argon are both commonly used to shield welding arcs and the surrounding base metal from the atmosphere during welding and cutting, as well as in other metallurgical processes and in the production of silicon for the semiconductor industry.",
                    "score": 0.8629534244537354
                },
                {
                    "id": 1644347,
                    "contents": "Chemical reaction\nAnother example is simple hydrogen gas combined with simple oxygen gas to produce a more complex substance, such as water. Decomposition A decomposition reaction is when a more complex substance breaks down into its more simple parts. It is thus the opposite of a synthesis reaction, and can be written as AB -> A + B One example of a decomposition reaction is the electrolysis of water to make oxygen and hydrogen gas: 2H2O -> 2H2 + O2 Single replacement In a single replacement reaction, a single uncombined element replaces another in a compound; in other words, one element trades places with another element in a compound These reactions come in the general form of: A + BC -> AC + B One example of a single displacement reaction is when magnesium replaces hydrogen in water to make magnesium hydroxide and hydrogen gas: Mg + 2H2O -> Mg(OH)2 + H2 (^)",
                    "score": 0.8625428676605225
                },
                {
                    "id": 1477630,
                    "contents": "List of experiments\nBenjamin Thompson, Count Rumford demonstrates that the heat developed by the friction of boring cannon is nearly inexhaustible. This result was presented in opposition to caloric theory (1798). Humphry Davy uses electrolysis to isolate elemental potassium, sodium, calcium, strontium, barium, magnesium, and chlorine (1807–1810). Joseph Louis Gay-Lussac studies reactions among gases and determines that their volumes combine chemically in simple integer ratios (1809). Robert Brown studies very small particles in water under the microscope and observes Brownian motion which was later named in his honor (1827). Friedrich Wöhler synthesizes the organic compound urea using inorganic reactants, disproving the application of vitalism to chemical processes (1828). Thomas Graham measures the rates of effusion for different gases and establishes Graham's law of effusion and diffusion (1833).",
                    "score": 0.8621835708618164
                },
                {
                    "id": 24054095,
                    "contents": "List of scientific demonstrations\nChemistry Ammonia fountain — introduces concepts like solubility and the gas laws at entry level. Barking dog reaction — demonstrates rapid exothermic chemical reaction Blue bottle (chemical reaction) — demonstrates reduction and oxidation reactions, and chemical colour change Chemical garden Diet Coke and Mentos eruption Elephant toothpaste Fizz keeper Flame test Magic sand Mercury beating heart — demonstrates electrochemical redox reaction. and an effect of a non-homogeneous electrical double layer Screaming jelly babies",
                    "score": 0.8597171306610107
                },
                {
                    "id": 2894933,
                    "contents": "Gay-Lussac's law\nThe ratio between the volumes of the reactant gases and the gaseous products can be expressed in simple whole numbers. For example, Gay-Lussac found that two volumes of hydrogen and one volume of oxygen would react to form two volumes of gaseous water. Based on Gay-Lussac's results, Amedeo Avogadro hypothesized that, at the same temperature and pressure, equal volumes of gas contain equal numbers of molecules (Avogadro's law). This hypothesis meant that the previously stated result 2 volumes of hydrogen + 1 volume of oxygen = 2 volume of gaseous water could also be expressed as 2 molecules of hydrogen + 1 molecule of oxygen = 2 molecule of water. It can also be expressed in another way of example, 100 mL of hydrogen combine with 50 mL of oxygen to give 100 mL of water vapour. Hydrogen(100 mL) + Oxygen(50 mL) = Water(100 mL) Thus, the volumes of hydrogen and oxygen which combine (i.e., 100mL and 50mL) bear a simple ratio of 2:1.",
                    "score": 0.8584577441215515
                },
                {
                    "id": 16471316,
                    "contents": "Triatomic hydrogen\nIn 1920 Wendt and Landauer named the substance \"Hyzone\" in analogy to ozone and its extra reactivity over normal hydrogen. Earlier Gottfried Wilhelm Osann believed he had discovered a form of hydrogen analogous to ozone which he called \"Ozonwasserstoff\". It was made by electrolysis of dilute sulfuric acid. In those days no one knew that ozone was triatomic so he did not announce triatomic hydrogen. This was later shown to be a mixture with sulfur dioxide, and not a new form of hydrogen.",
                    "score": 0.8584469556808472
                },
                {
                    "id": 1488620,
                    "contents": "Luis Walter Alvarez\nThis program built a liquid hydrogen bubble chamber almost 7 feet (2 meters) long, employed dozens of physicists and graduate students together with hundreds of engineers and technicians, took millions of photographs of particle interactions, developed computer systems to measure and analyze the interactions, and discovered families of new particles and resonance states. This work resulted in the Nobel Prize in Physics for Alvarez in 1968, \"For his decisive contributions to elementary particle physics, in particular the discovery of a large number of resonant states, made possible through his development of the technique of using hydrogen bubble chambers and data analysis.\" Scientific detective",
                    "score": 0.8575636148452759
                },
                {
                    "id": 17576272,
                    "contents": "Timeline of hydrogen technologies\n1784 – The invention of the Lavoisier Meusnier iron-steam process, generating hydrogen by passing water vapor over a bed of red-hot iron at 600 °C. 1785 – Jean-François Pilâtre de Rozier built the hybrid Rozière balloon. 1787 – Charles's law (gas law, relating volume and temperature) 1789 – Jan Rudolph Deiman and Adriaan Paets van Troostwijk using an electrostatic machine and a Leyden jar for the first electrolysis of water. 1800 – William Nicholson and Anthony Carlisle decomposed water into hydrogen and oxygen by electrolysis with a voltaic pile. 1800 – Johann Wilhelm Ritter duplicated the experiment with a rearranged set of electrodes to collect the two gases separately.",
                    "score": 0.8572782874107361
                },
                {
                    "id": 27375016,
                    "contents": "Hydrogen water\nHydrogen water is water with dissolved hydrogen gas (H2) similar to carbonated water in which the dissolved gas is carbon dioxide. It is tasteless since H2 is an odorless gas. There is limited scientific evidence that hydrogen water has any health benefits in humans, although its proponents make claims it provides such benefits as functioning as an antioxidant, reducing inflammation, reducing risk of metabolic syndrome, providing neuroprotection for various diseases, and reducing side effects associated with cancer radiation treatment. Composition Hydrogen water is made by dissolving gaseous molecular hydrogen into water under pressure, typically 7.0 mg per liter of water. Alternative means of hydrogen administration are by inhalation of a gas containing up to 4.6% hydrogen, by intravenous injection with a hydrogen-containing saline solution, or by topical application (to the skin).",
                    "score": 0.85719895362854
                },
                {
                    "id": 1753337,
                    "contents": "Hydrogen\nUnder ordinary conditions on Earth, elemental hydrogen exists as the diatomic gas, H2. Hydrogen gas is very rare in the Earth's atmosphere (1 ppm by volume) because of its light weight, which enables it to escape from the atmosphere more rapidly than heavier gases. However, hydrogen is the third most abundant element on the Earth's surface, mostly in the form of chemical compounds such as hydrocarbons and water.",
                    "score": 0.8568871021270752
                },
                {
                    "id": 2889319,
                    "contents": "Standard hydrogen electrode\nSHE vs NHE vs RHE During the early development of electrochemistry, researchers used the normal hydrogen electrode as their standard for zero potential. This was convenient because it could actually be constructed by \"[immersing] a platinum electrode into a solution of 1 N strong acid and [bubbling] hydrogen gas through the solution at about 1 atm pressure\". However, this electrode/solution interface was later changed. What replaced it was a theoretical electrode/solution interface, where the concentration of H+ was 1 M, but the H+ ions were assumed to have no interaction with other ions (a condition not physically attainable at those concentrations). To differentiate this new standard from the previous one it was given the name 'Standard Hydrogen Electrode'. Finally, there also exists the term RHE (Reversible Hydrogen Electrode), which is a practical hydrogen electrode whose potential depends on the pH of the solution. In summary,",
                    "score": 0.8565718531608582
                },
                {
                    "id": 1457075,
                    "contents": "Liquid oxygen\nHistory By 1845, Michael Faraday had managed to liquefy most gases then known to exist. Six gases, however, resisted every attempt at liquefaction and were known at the time as \"permanent gases\". They were oxygen, hydrogen, nitrogen, carbon monoxide, methane, and nitric oxide. In 1877, Louis Paul Cailletet in France and Raoul Pictet in Switzerland succeeded in producing the first droplets of liquid air. In 1883, Polish professors Zygmunt Wróblewski and Karol Olszewski produced the first measurable quantity of liquid oxygen. See also Oxygen storage Industrial gas Cryogenics Liquid hydrogen Liquid helium Liquid nitrogen List of Stoffs Natterer compressor Rocket fuel Solid oxygen Tetraoxygen References Rocket oxidizers Cryogenics Oxygen Industrial gases Liquids 1883 in science",
                    "score": 0.8558377623558044
                },
                {
                    "id": 14447322,
                    "contents": "Gas Gang\nCarbon Dioxide) attempted to poison them with fumes, while Carbon Dioxide (called \"CD\" by Carbon Monoxide) attempted to freeze them. The chase ended in one of the labs where Gold was attempting heat conduction on the others as a possible cure for their creator. As Helium expanded and cornered the Metal Men, Platinum got Gold to repeat the experiment, stretching and transforming himself into a large cage and trapping the Gas Gang. When he connected himself to the high-voltage conductors he melted the Gas Gang and converted them all to steam. That was when they discovered Doctor Magnus had been trapped in there with them, and as it turned out is what cured him and made him human again.",
                    "score": 0.8554985523223877
                },
                {
                    "id": 14362724,
                    "contents": "Glossary of fuel cell terms\nGas compressor A gas compressor is a mechanical device that increases the pressure of a gas by reducing its volume. Gas detector A gas detector is a device which detects the presence of various gases within an area, usually as part of a system to warn about gases which might be harmful to humans or animals. Gas diffusion Mixing of two gases caused by random molecular motions. Gases diffuse very quickly; liquids diffuse much more slowly, and solids diffuse at very slow (but often measurable) rates. Molecular collisions make diffusion slower in liquids and solids. Gas diffusion electrode Gas diffusion electrodes are electrodes with a conjunction of a solid, liquid and gaseous interface, and an electrical conducting catalyst supporting an electrochemical reaction between the liquid and the gaseous phase.",
                    "score": 0.8552796840667725
                },
                {
                    "id": 9316847,
                    "contents": "Water gas\nOr, alternatively, to prevent contamination with nitrogen, energy can be provided by using pure oxygen to burn carbon into carbon monoxide. (ΔH = -221 kJ/mol) In this case, 1 L of oxygen will create 5.3 L of pure water gas. History The water-gas shift reaction was discovered by Italian physicist Felice Fontana in 1780. Water gas was made in England from 1828 by blowing steam through white-hot coke. Hydrocarbonate (gas) Hydrocarbonate is an obsolete chemistry term for water gas composed of carbon monoxide and hydrogen generated by passing steam over molten coke. Hydrocarbonate was classified as a factitious air and explored for therapeutic properties by eighteenth century physicians including: Thomas Beddoes and James Watt. The term hydrocarbonate was coined by Thomas Beddoes in 1794. It should not be confused with the modern name \"hydrogen carbonate\" for bicarbonate ion.",
                    "score": 0.8551040887832642
                },
                {
                    "id": 4482499,
                    "contents": "Hydrogen fuel\nHydrogen is found in the first group and the first period in the periodic table, i.e. it is the lightest and first element of all. Since the weight of hydrogen is less than air, it rises in the atmosphere and is therefore rarely found in its pure form, H2. In a flame of pure hydrogen gas, burning in air, the hydrogen (H2) reacts with oxygen (O2) to form water (H2O) and releases energy. 2H2 (g) + O2 (g) → 2H2O (g) + energy If carried out in atmospheric air instead of pure oxygen, as is usually the case, hydrogen combustion may yield small amounts of nitrogen oxides, along with the water vapor. The energy released enables hydrogen to act as a fuel. In an electrochemical cell, that energy can be used with relatively high efficiency. If it is used simply for heat, the usual thermodynamics limits on the thermal efficiency apply.",
                    "score": 0.8550468683242798
                },
                {
                    "id": 4051545,
                    "contents": "RS-25\nconverting the liquid oxygen to gas. The gas is sent to a manifold and then routed to pressurize the liquid oxygen tank. Another path enters the HPOTP second-stage pre-burner pump to boost the liquid oxygen's pressure from 30 to 51 MPa (4,300 psia to 7,400 psia). It passes through the oxidizer pre-burner oxidizer valve into the oxidizer pre-burner and through the fuel pre-burner oxidizer valve into the fuel pre-burner. The HPOTP measures approximately . It is attached by flanges to the hot-gas manifold.",
                    "score": 0.8547417521476746
                },
                {
                    "id": 1753329,
                    "contents": "Hydrogen\n1) 2) 3) Many metals such as zirconium undergo a similar reaction with water leading to the production of hydrogen. Hydrogen was liquefied for the first time by James Dewar in 1898 by using regenerative cooling and his invention, the vacuum flask. He produced solid hydrogen the next year. Deuterium was discovered in December 1931 by Harold Urey, and tritium was prepared in 1934 by Ernest Rutherford, Mark Oliphant, and Paul Harteck. Heavy water, which consists of deuterium in the place of regular hydrogen, was discovered by Urey's group in 1932. François Isaac de Rivaz built the first de Rivaz engine, an internal combustion engine powered by a mixture of hydrogen and oxygen in 1806. Edward Daniel Clarke invented the hydrogen gas blowpipe in 1819. The Döbereiner's lamp and limelight were invented in 1823.",
                    "score": 0.8544314503669739
                },
                {
                    "id": 14675241,
                    "contents": "Hydride compressor\nSee also References Gas compressors Hydrogen technologies",
                    "score": 0.8541460633277893
                },
                {
                    "id": 1067646,
                    "contents": "James Dewar\nhe built a machine from which the liquefied gas could be drawn off through a valve for use as a cooling agent, before using the liquid oxygen in research work related to meteorites; about the same time, he also obtained oxygen in the solid state.",
                    "score": 0.8541458249092102
                },
                {
                    "id": 25570387,
                    "contents": "81 cm Saclay Bubble Chamber\nThe experiments carried out involved not only most of the CERN member states at the time but also USA, India, Israel, Spain, Czechoslovakia and Poland. Hydrogen liquid filling experiments were: P8, T5, T6, T9, T10, T12, T13, T17, T18, T19, T20, T21, T24, T25, T30, T31, T47, T55, T65, T67, T69, T70, T71, T72, T73, T74, T75, T78, T79, T83, T94, T98, T101, T102, T110, T123, T126, T127, T136, T138, T142, T146, T154, T156, T163, T170, T175, and T206; and using deuterium filling were:T12, T14, T21, T34, T42, T43, T45, T46, T48, T51, T52, T53, T58, T67, T71, T76, T81, T84, T85, T100, T103, T137, T147, T171, and T176.",
                    "score": 0.8540074825286865
                },
                {
                    "id": 892449,
                    "contents": "Joseph Priestley\nPriestley assembled his oxygen paper and several others into a second volume of Experiments and Observations on Air, published in 1776. He did not emphasise his discovery of \"dephlogisticated air\" (leaving it to Part III of the volume) but instead argued in the preface how important such discoveries were to rational religion. His paper narrated the discovery chronologically, relating the long delays between experiments and his initial puzzlements; thus, it is difficult to determine when exactly Priestley \"discovered\" oxygen. Such dating is significant as both Lavoisier and Swedish pharmacist Carl Wilhelm Scheele have strong claims to the discovery of oxygen as well, Scheele having been the first to isolate the gas (although he published after Priestley) and Lavoisier having been the first to describe it as purified \"air itself entire without alteration\" (that is, the first to explain oxygen without phlogiston theory).",
                    "score": 0.8539822697639465
                },
                {
                    "id": 2751075,
                    "contents": "1625 in science\nThe year 1625 in science and technology involved some significant events. Chemistry First description of hydrogen by Johann Baptista van Helmont. First to use the word \"gas\". Johann Rudolf Glauber discovers sodium sulfate (sal mirabilis or \"Glauber's salt\", used as a laxative) in Austrian spring water. Births June 8 – Giovanni Cassini, Italian astronomer (died 1712) March 25 – John Collins, English mathematician (died 1683) August 13 – Rasmus Bartholin, Danish scientist (died 1698) December 16 – Erhard Weigel, German mathematician and scientific populariser (died 1699) December 20 – David Gregory, Scottish physician and inventor (died 1720) Samuel Morland, English inventor (died 1695)",
                    "score": 0.8539490699768066
                },
                {
                    "id": 9316850,
                    "contents": "Water gas\nJames Watt suggested hydrocarbonate could act as \"an antidote to the oxygen in blood\" in 1794 and cautioned about the toxicity of an overdose prior to the discoveries of carbon monoxide (1800) and hemoglobin (1840). Despite Watt's observation, it is widely accepted that Claude Bernard had first described the mechanism for carbon monoxide poisoning by describing carbon monoxide's affinity for hemoglobin displacing oxygen to induce asphyxia circa 1857. Lowe's gas process In 1873, Thaddeus S. C. Lowe developed and patented the water gas process by which large amounts of hydrogen gas could be generated for residential and commercial use in heating and lighting. This gas provided a more efficient heating fuel than the common coal gas, or coke gas, which was used in municipal service. The process used the water-gas shift reaction:",
                    "score": 0.8539029359817505
                },
                {
                    "id": 5606397,
                    "contents": "History of chemistry\nIn 1754, Scottish chemist Joseph Black isolated carbon dioxide, which he called \"fixed air\". In 1757, Louis Claude Cadet de Gassicourt, while investigating arsenic compounds, creates Cadet's fuming liquid, later discovered to be cacodyl oxide, considered to be the first synthetic organometallic compound. In 1758, Joseph Black formulated the concept of latent heat to explain the thermochemistry of phase changes. In 1766, English chemist Henry Cavendish isolated hydrogen, which he called \"inflammable air\". Cavendish discovered hydrogen as a colorless, odourless gas that burns and can form an explosive mixture with air, and published a paper on the production of water by burning inflammable air (that is, hydrogen) in dephlogisticated air (now known to be oxygen), the latter a constituent of atmospheric air (phlogiston theory).",
                    "score": 0.8536867499351501
                },
                {
                    "id": 17576274,
                    "contents": "Timeline of hydrogen technologies\n1823 – Goldsworthy Gurney devised an oxy-hydrogen blowpipe. 1824 – Michael Faraday invented the rubber balloon. 1826 – Thomas Drummond built the Drummond Light. 1826 – Samuel Brown tested his internal combustion engine by using it to propel a vehicle up Shooter's Hill 1834 – Michael Faraday published Faraday's laws of electrolysis. 1834 – Benoît Paul Émile Clapeyron – Ideal gas law 1836 – John Frederic Daniell invented a primary cell in which hydrogen was eliminated in the generation of the electricity. 1839 – Christian Friedrich Schönbein published the principle of the fuel cell in the \"Philosophical Magazine\". 1839 – William Robert Grove developed the Grove cell. 1842 – William Robert Grove developed the first fuel cell (which he called the gas voltaic battery) 1849 – Eugène Bourdon – Bourdon gauge (manometer) 1863 – Etienne Lenoir made a test drive from Paris to Joinville-le-Pont with the 1-cylinder, 2-stroke Hippomobile.",
                    "score": 0.8534064888954163
                },
                {
                    "id": 14653365,
                    "contents": "Reversible hydrogen electrode\n{2H3O+} + {2e^-} <=> {H2} + {2H2O} or, more often commonly written simply with denoting : {2H+} + {2e^-} <=> {H2} with, the equilibrium potential depends on the hydrogen pressure and the activity as follows: Here, is the standard reduction potential (by convention equal to zero), is the universal gas constant, the absolute temperature, and is the Faraday constant. An overpotential occurs in the electrolysis of water. This means that the required cell voltage is higher than the equilibrium potential because of kinetic limitations. The potential increases with increasing current density at the electrodes. The measurement of equilibrium potentials is therefore possible without power. Principle The reversible hydrogen electrode is a fairly practical and reproducible electrode \"standard\". The term refers to a hydrogen electrode immersed in the electrolyte solution actually used.",
                    "score": 0.8533422946929932
                },
                {
                    "id": 1488619,
                    "contents": "Luis Walter Alvarez\nThe Glaser device was a small glass cylinder () filled with ether. By suddenly reducing the pressure in the device, the liquid could be placed into a temporary superheated state, which would boil along the disturbed track of a particle passing through. Glaser was able to maintain the superheated state for a few seconds before spontaneous boiling took place. The Alvarez team built chambers of 1.5 in, 2.5 in, 4 in, 10 in, and 15 in using liquid hydrogen, and constructed of metal with glass windows, so that the tracks could be photographed. The chamber could be cycled in synchronization with the accelerator beam, a picture could be taken, and the chamber recompressed in time for the next beam cycle.",
                    "score": 0.8531955480575562
                },
                {
                    "id": 17780811,
                    "contents": "Gas\nCharles's law In 1787, the French physicist and balloon pioneer, Jacques Charles, found that oxygen, nitrogen, hydrogen, carbon dioxide, and air expand to the same extent over the same 80 kelvin interval. He noted that, for an ideal gas at constant pressure, the volume is directly proportional to its temperature: Gay-Lussac's law In 1802, Joseph Louis Gay-Lussac published results of similar, though more extensive experiments. Gay-Lussac credited Charles' earlier work by naming the law in his honor. Gay-Lussac himself is credited with the law describing pressure, which he found in 1809. It states that the pressure exerted on a container's sides by an ideal gas is proportional to its temperature. Avogadro's law",
                    "score": 0.8529572486877441
                },
                {
                    "id": 10829468,
                    "contents": "Émile Amagat\nÉmile Hilaire Amagat (2 January 1841, Saint-Satur – 15 February 1915) was a French physicist. His doctoral thesis, published in 1872, expanded on the work of Thomas Andrews, and included plots of the isotherms of carbon dioxide at high pressures. Amagat published a paper in 1877 that contradicted the current understanding at the time, concluding that the coefficient of compressibility of fluids decreased with increasing pressure. He continued to publish data on isotherms for a number of different gases between 1879 and 1882, and invented the hydraulic manometer, which was able to withstand up to 3200 atmospheres, as opposed to 400 atmospheres using a glass apparatus. In 1880 he published his Law of Partial Volumes. Amagat was elected a member of the French Academy of Sciences on 9 June 1902. A unit of number density, amagat, was named after him. He was elected a foreign member of the Royal Society of London in 1897.",
                    "score": 0.8529331088066101
                },
                {
                    "id": 2156578,
                    "contents": "Henry Cavendish\nSee also Timeline of hydrogen technologies Notes and references Further reading Cavendish, Christa Jungnickel and Russell McCormmach, American Philosophical Society, 1996, , 414 pp. Cavendish: The Experimental Life, Christa Jungnickel and Russell McCormmach, Bucknell University Press, 1999, , 814 pp. Cavendish: The Experimental Life (Second revised edition 2016), Christa Jungnickel and Russell McCormmach, Max Planck Research Library for the History and Development of Knowledge, 2016, , 596 pp, (available online for free). External links – Alembic Club reprint number 3 1731 births 1810 deaths People from Nice English agnostics English chemists English physicists Discoverers of chemical elements Recipients of the Copley Medal Fellows of the Royal Society Alumni of Peterhouse, Cambridge Henry Cavendish 18th-century English people 19th-century English people 18th-century British chemists 19th-century British chemists People educated at Newcome's School",
                    "score": 0.8525462746620178
                },
                {
                    "id": 724263,
                    "contents": "Solaris (novel)\nliquid oxygen. This fails because her body is made of neutrinos, stabilized by some unknown force field, and has both incredible strength and the ability to quickly regenerate from all injuries. She subsequently convinces Snaut to destroy her with a device developed by Sartorius that disrupts the subatomic structure of the visitors.",
                    "score": 0.852347195148468
                },
                {
                    "id": 1148097,
                    "contents": "Oxygen\nOxygen was isolated by Michael Sendivogius before 1604, but it is commonly believed that the element was discovered independently by Carl Wilhelm Scheele, in Uppsala, in 1773 or earlier, and Joseph Priestley in Wiltshire, in 1774. Priority is often given for Priestley because his work was published first. Priestley, however, called oxygen \"dephlogisticated air\", and did not recognize it as a chemical element. The name oxygen was coined in 1777 by Antoine Lavoisier, who first recognized oxygen as a chemical element and correctly characterized the role it plays in combustion. Common uses of oxygen include production of steel, plastics and textiles, brazing, welding and cutting of steels and other metals, rocket propellant, oxygen therapy, and life support systems in aircraft, submarines, spaceflight and diving. History of study Early experiments",
                    "score": 0.8520504832267761
                },
                {
                    "id": 1775212,
                    "contents": "Humphry Davy\nSir Humphry Davy, 1st Baronet, (17 December 177829 May 1829) was an English chemist and inventor from Cornwall who invented the Davy lamp and a very early form of arc lamp. He is also remembered for isolating, by using electricity, a series of elements for the first time: potassium and sodium in 1807 and calcium, strontium, barium, magnesium and boron the following year, as well as for discovering the elemental nature of chlorine and iodine. Davy also studied the forces involved in these separations, inventing the new field of electrochemistry. Davy is also credited to have been the first to discover clathrate hydrates in his lab. In 1799 he experimented with nitrous oxide and was astonished at how it made him laugh, so he nicknamed it \"laughing gas\" and wrote about its potential anaesthetic properties in relieving pain during surgery.",
                    "score": 0.8515248894691467
                },
                {
                    "id": 9529360,
                    "contents": "Badoit\nDescription \"The carbonic acid gas therein is formed by combination and not by compression. This is a very clear water, a tangy flavor, fresh, very nice. In its most recent analysis made by Mr. O. Henry, giving it nearly 3 grams of carbon dioxide per liter, many earthen and alkaline bi-carbonates and proportion of nitrate of magnesia whose presence seems to explain this amazing fact that the residents of Saint-Galmier have never counted a calculous person among them.\" One source in 1856 says that the spring was capable of producing 7000 bottles a day. A 2004 analysis by the French Society for Radiation Protection confirms the spring water emits 70 becquerels per liter of radiation before treatment, containing 58 mg/m3 of uranium, 350 Bq/m3 of radium-226 and 713 Bq/m3 of radium-228. After treatment, it contains 5.45 mg/m3 of uranium, 28 Bq/m3 of radium 226 and 44 Bq/m3 of radium 228. References External links Bottled water brands Groupe Danone brands French brands",
                    "score": 0.8510080575942993
                },
                {
                    "id": 17576285,
                    "contents": "Timeline of hydrogen technologies\n21st century",
                    "score": 0.8506673574447632
                },
                {
                    "id": 2889320,
                    "contents": "Standard hydrogen electrode\nIn summary, NHE (Normal Hydrogen Electrode): potential of a platinum electrode in 1 M acid solution SHE (Standard Hydrogen Electrode): potential of a platinum electrode in a theoretical ideal solution (the current standard for zero potential for all temperatures) RHE (Reversible Hydrogen Electrode): a practical hydrogen electrode whose potential depends on the pH of the solution",
                    "score": 0.8503378629684448
                },
                {
                    "id": 454319,
                    "contents": "Perfect gas\nPerfect gas nomenclature The terms perfect gas and ideal gas are sometimes used interchangeably, depending on the particular field of physics and engineering. Sometimes, other distinctions are made, such as between thermally perfect gas and calorically perfect gas, or between imperfect, semi-perfect, and perfect gases, and as well as the characteristics of ideal gases. Two of the common sets of nomenclatures are summarized in the following table. Thermally and calorically perfect gas Along with the definition of a perfect gas, there are also two more simplifications that can be made although various textbooks either omit or combine the following simplifications into a general \"perfect gas\" definition.",
                    "score": 0.8502467274665833
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_37",
        "question": "The vibrational wavenumber of $\\mathrm{Br}_2$ is $323.2 \\mathrm{~cm}^{-1}$. Evaluate the vibrational partition function explicitly (without approximation) and plot its value as a function of temperature. At what temperature is the value within 5 per cent of the value calculated from the approximate formula?",
        "golden_answers": [
            " 4500"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 8657438,
                    "contents": "Vibrational partition function\nThe vibrational partition function traditionally refers to the component of the canonical partition function resulting from the vibrational degrees of freedom of a system. The vibrational partition function is only well-defined in model systems where the vibrational motion is relatively uncoupled with the system's other degrees of freedom. Definition For a system (such as a molecule or solid) with uncoupled vibrational modes the vibrational partition function is defined by where is the absolute temperature of the system, is the Boltzmann constant, and is the energy of j'th mode when it has vibrational quantum number . For an isolated molecule of n atoms, the number of vibrational modes (i.e. values of j) is 3n − 5 for linear molecules and 3n − 6 for non-linear ones. In crystals, the vibrational normal modes are commonly known as phonons. Approximations",
                    "score": 0.9269078373908997
                },
                {
                    "id": 8657440,
                    "contents": "Vibrational partition function\nwhere is total vibrational zero point energy of the system. Often the wavenumber, with units of cm−1 is given instead of the angular frequency of a vibrational mode and also often misnamed frequency. One can convert to angular frequency by using where c'' is the speed of light in vacuum. In terms of the vibrational wavenumbers we can write the partition function as References See also Partition function (mathematics) Partition functions",
                    "score": 0.9134320020675659
                },
                {
                    "id": 19260536,
                    "contents": "Vibrational temperature\nThe vibrational temperature is commonly used in thermodynamics, to simplify certain equations. It has units of temperature and is defined as where is Boltzmann's constant, is the speed of light, and (Greek letter nu) is the characteristic frequency of the oscillator. The vibrational temperature is used commonly when finding the vibrational partition function. References Statistical thermodynamics University Arizona See also Rotational temperature Rotational spectroscopy Vibrational spectroscopy Infrared spectroscopy Spectroscopy Atomic physics Molecular physics",
                    "score": 0.9062075018882751
                },
                {
                    "id": 8657439,
                    "contents": "Vibrational partition function\nApproximations Quantum harmonic oscillator The most common approximation to the vibrational partition function uses a model in which the vibrational eigenmodes or normal modes of the system are considered to be a set of uncoupled quantum harmonic oscillators. It is a first order approximation to the partition function which allows one to calculate the contribution of the vibrational degrees of freedom of molecules towards its thermodynamic variables. A quantum harmonic oscillator has an energy spectrum characterized by: where j runs over vibrational modes and is the vibrational quantum number in the j 'th mode, is Planck's constant, h, divided by and is the angular frequency of the j'''th mode. Using this approximation we can derive a closed form expression for the vibrational partition function. where is total vibrational zero point energy of the system.",
                    "score": 0.9019033312797546
                },
                {
                    "id": 19042079,
                    "contents": "Overtone band\nIn vibrational spectroscopy, an overtone band is the spectral band that occurs in a vibrational spectrum of a molecule when the molecule makes a transition from the ground state (v=0) to the second excited state (v=2), where v is the vibrational quantum number (a non-negative integer) obtained from solving the Schrödinger equation for the molecule.",
                    "score": 0.901634693145752
                },
                {
                    "id": 4258551,
                    "contents": "Molecular geometry\nTo get a feeling for the probability that the vibration of molecule may be thermally excited, we inspect the Boltzmann factor , where ΔE is the excitation energy of the vibrational mode, k the Boltzmann constant and T the absolute temperature. At 298 K (25 °C), typical values for the Boltzmann factor β are: β = 0.089 for ΔE = 500 cm−1 β = 0.008 for ΔE = 1000 cm−1 β = 0.0007 for ΔE = 1500 cm−1. (The reciprocal centimeter is an energy unit that is commonly used in infrared spectroscopy; 1 cm−1 corresponds to ). When an excitation energy is 500 cm−1, then about 8.9 percent of the molecules are thermally excited at room temperature. To put this in perspective: the lowest excitation vibrational energy in water is the bending mode (about 1600 cm−1). Thus, at room temperature less than 0.07 percent of all the molecules of a given amount of water will vibrate faster than at absolute zero.",
                    "score": 0.900405764579773
                },
                {
                    "id": 23978881,
                    "contents": "Vibronic spectroscopy\nThe intensity of allowed vibronic transitions is governed by the Franck–Condon principle. Since electronic transitions are very fast compared with nuclear motions, vibrational levels are favored when they correspond to a minimal change in the nuclear coordinates, that is, when the transition is \"vertical\" on the energy level diagram. Each line has a finite linewidth, dependent on a variety of factors. Vibronic spectra of diatomic molecules in the gas phase have been analyzed in detail. Vibrational coarse structure can sometimes be observed in the spectra of molecules in liquid or solid phases and of molecules in solution. Related phenomena including photoelectron spectroscopy, resonance Raman spectroscopy, luminescence, and fluorescence are not discussed in this article, though they also involve vibronic transitions.",
                    "score": 0.8975328207015991
                },
                {
                    "id": 10291323,
                    "contents": "Molecular vibration\nIntensities In an infrared spectrum the intensity of an absorption band is proportional to the derivative of the molecular dipole moment with respect to the normal coordinate. Likewise, the intensity of Raman bands depends on the derivative of polarizability with respect to the normal coordinate. There is also a dependence on the fourth-power of the wavelength of the laser used. See also Coherent anti-Stokes Raman spectroscopy Eckart conditions Fermi resonance GF method Infrared spectroscopy of metal carbonyls Lennard–Jones potential Near infrared spectroscopy Nuclear resonance vibrational spectroscopy Resonance Raman spectroscopy Transition dipole moment References Further reading External links Free Molecular Vibration code developed by Zs. Szabó and R. Scipioni Molecular vibration and absorption small explanation of vibrational spectra and a table including force constants. Character tables for chemically important point groups Chemical physics Spectroscopy",
                    "score": 0.8965184688568115
                },
                {
                    "id": 23978879,
                    "contents": "Vibronic spectroscopy\nFor absorption spectra, the vibrational coarse structure for a given electronic transition forms a single progression, or series of transitions with a common level, here the lower level . There are no selection rules for vibrational quantum numbers, which are zero in the ground vibrational level of the initial electronic ground state, but can take any integer values in the final electronic excited state. The term values for a harmonic oscillator are given by where v is a vibrational quantum number, ωe is the harmonic wavenumber. In the next approximation the term values are given by",
                    "score": 0.8949545621871948
                },
                {
                    "id": 14762074,
                    "contents": "Edgar Bright Wilson\nIn 1955 Bright published a book Molecular Vibrations along with co-authors J.C Decius and P.C. Cross which discussed infrared and raman spectra of polyatomic molecules. In 1955 Bright studied the internal rotation of single bonds in molecules using microwave spectroscopy. In 1965 Bright studied the energy transfer in rotationally molecular inelastic collisions. In 1970, Bright began to study hydrogen bonding and the structure of hydrogen bonds using low resolution microwave spectroscopy. In 1979, Bright retired and was named an emeritus professor. The E. Bright Wilson Award in Spectroscopy was established in 1994 by the American Chemical Society. Personal life Wilson was born in Gallatin, Tennessee to mother Alma Lackey and father E. B. Wilson, a lawyer. His family soon moved to Yonkers, New York.",
                    "score": 0.8941070437431335
                },
                {
                    "id": 23978882,
                    "contents": "Vibronic spectroscopy\nDiatomic molecules The vibronic spectra of diatomic molecules in the gas phase also show rotational fine structure. Each line in a vibrational progression will show P- and R- branches. For some electronic transitions there will also be a Q-branch. The transition energies, expressed in wavenumbers, of the lines for a particular vibronic transition are given, in the rigid rotor approximation, that is, ignoring centrifugal distortion, by",
                    "score": 0.8932454586029053
                },
                {
                    "id": 23978877,
                    "contents": "Vibronic spectroscopy\nEach electronic transition may show vibrational coarse structure, and for molecules in the gas phase, rotational fine structure. This is true even when the molecule has a zero dipole moment and therefore has no vibration-rotation infrared spectrum or pure rotational microwave spectrum.",
                    "score": 0.8921854496002197
                },
                {
                    "id": 2819610,
                    "contents": "Rotational–vibrational spectroscopy\nThe spectra of these molecules are classified according to the direction of the dipole moment change vector. When the vibration induces a dipole moment change pointing along the molecular axis the term parallel is applied, with the symbol . When the vibration induces a dipole moment pointing perpendicular to the molecular axis the term perpendicular is applied, with the symbol . In both cases the P- and R- branch wavenumbers follow the same trend as in diatomic molecules. The two classes differ in the selection rules that apply to ro-vibrational transitions. For parallel transitions the selection rule is the same as for diatomic molecules, namely, the transition corresponding to the Q-branch is forbidden. An example is the C-H stretching mode of hydrogen cyanide.",
                    "score": 0.8919385075569153
                },
                {
                    "id": 19042080,
                    "contents": "Overtone band\nGenerally, in order to study the vibrational spectra of molecules, chemical bond vibrations are assumed to be approximable as simple harmonic oscillators. Thus a quadratic potential is used in the Schrödinger equation to solve for the vibrational energy eigenstates and their eigenvalues.",
                    "score": 0.8919230699539185
                },
                {
                    "id": 23978886,
                    "contents": "Vibronic spectroscopy\nThe line of highest wavenumber in the R-branch is known as the band head. It occurs at the value of m which is equal to the integer part of x, or of (x+1). When a Q- branch is allowed for a particular electronic transition, the lines of the Q-branch correspond to the case ∆J=0, J′=J′′ and wavenumbers are given by The Q-branch then consists of a series of lines with increasing separation between adjacent lines as J increases. When B′<B′′ the Q-branch lies to lower wavenumbers relative to the vibrational line.",
                    "score": 0.8918340802192688
                },
                {
                    "id": 10291322,
                    "contents": "Molecular vibration\nSee quantum harmonic oscillator for graphs of the first 5 wave functions, which allow certain selection rules to be formulated. For example, for a harmonic oscillator transitions are allowed only when the quantum number n changes by one, but this does not apply to an anharmonic oscillator; the observation of overtones is only possible because vibrations are anharmonic. Another consequence of anharmonicity is that transitions such as between states n=2 and n=1 have slightly less energy than transitions between the ground state and first excited state. Such a transition gives rise to a hot band. To describe vibrational levels of an anharmonic oscillator, Dunham expansion is used.",
                    "score": 0.8904916048049927
                },
                {
                    "id": 5311726,
                    "contents": "Franck–Condon principle\nThe first integral after the plus sign is equal to zero because electronic wavefunctions of different states are orthogonal. Remaining is the product of three integrals. The first integral is the vibrational overlap integral, also called the Franck–Condon factor. The remaining two integrals contributing to the probability amplitude determine the electronic spatial and spin selection rules. The Franck–Condon principle is a statement on allowed vibrational transitions between two different electronic states; other quantum mechanical selection rules may lower the probability of a transition or prohibit it altogether. Rotational selection rules have been neglected in the above derivation. Rotational contributions can be observed in the spectra of gases but are strongly suppressed in liquids and solids.",
                    "score": 0.8903325796127319
                },
                {
                    "id": 23978887,
                    "contents": "Vibronic spectroscopy\nThe Q-branch then consists of a series of lines with increasing separation between adjacent lines as J increases. When B′<B′′ the Q-branch lies to lower wavenumbers relative to the vibrational line. Predissociation The phenomenon of predissociation occurs when an electronic transition results in dissociation of the molecule at an excitation energy less than the normal dissociation limit of the upper state. This can occur when the potential energy curve of the upper state crosses the curve for a repulsive state, so that the two states have equal energy at some internuclear distance. This allows the possibility of a radiationless transition to the repulsive state whose energy levels form a continuum, so that there is blurring of the particular vibrational band in the vibrational progression. Applications",
                    "score": 0.8896381855010986
                },
                {
                    "id": 21676810,
                    "contents": "Dunham expansion\nIn quantum chemistry, the Dunham expansion is an expression for the rotational-vibrational energy levels of a diatomic molecule: where and are the vibrational and rotational quantum numbers, and is the projection of along the internuclear axis in the body-fixed frame. The constant coefficients are called Dunham parameters with representing the electronic energy. The expression derives from a semiclassical treatment of a perturbational approach to deriving the energy levels. The Dunham parameters are typically calculated by a least-squares fitting procedure of energy levels with the quantum numbers. Relation to conventional band spectrum constants This table adapts the sign conventions from the book of Huber and Herzberg. See also Rotational-vibrational spectroscopy References Spectroscopy Molecular vibration",
                    "score": 0.888946533203125
                },
                {
                    "id": 23978876,
                    "contents": "Vibronic spectroscopy\nPrinciples Electronic transitions are typically observed in the visible and ultraviolet regions, in the wavelength range approximately 200–700 nm (50,000–14,000 cm−1), whereas fundamental vibrations are observed below about 4000 cm−1. When the electronic and vibrational energy changes are so different, vibronic coupling (mixing of electronic and vibrational wave functions) can be neglected and the energy of a vibronic level can be taken as the sum of the electronic and vibrational (and rotational) energies; that is, the Born–Oppenheimer approximation applies. The overall molecular energy depends not only on the electronic state but also on vibrational and rotational quantum numbers, denoted v and J respectively for diatomic molecules. It is conventional to add a double prime (v\", J\") for levels of the electronic ground state and a single prime (v', J') for electronically excited states.",
                    "score": 0.8882465958595276
                },
                {
                    "id": 2819607,
                    "contents": "Rotational–vibrational spectroscopy\nRaman spectra of diatomic molecules The selection rule is so that the spectrum has an O-branch (∆J = −2), a Q-branch (∆J = 0) and an S-branch (∆J=+2). In the approximation that B′′ = B′ = B the wavenumbers are given by since the S-branch starts at J=0 and the O-branch at J=2. So, to a first approximation, the separation between S(0) and O(2) is 12B and the separation between adjacent lines in both O- and S- branches is 4B. The most obvious effect of the fact that B′′ ≠ B′ is that the Q-branch has a series of closely spaced side lines on the low-frequency side due to transitions in which ΔJ=0 for J=1,2 etc. Useful difference formulae, neglecting centrifugal distortion are as follows. Molecular oxygen is a special case as the molecule is paramagnetic, with two unpaired electrons.",
                    "score": 0.8875045776367188
                },
                {
                    "id": 23978885,
                    "contents": "Vibronic spectroscopy\nSimilarly for the R-branch , and Thus, the wavenumbers of transitions in both P- and R- branches are given, to a first approximation, by the single formula Here positive m values refer to the R-branch (with m = +J ′ = J'' +1) and negative values refer to the P-branch (with m = -J ′′). The wavenumbers of the lines in the P-branch, on the low wavenumber side of the band origin at , increase with m. In the R-branch, for the usual case that B′ < B′′, as J increases the wavenumbers at first lie increasingly on the high wavenumber side of the band origin but then start to decrease, eventually lying on the low wavenumber side. The Fortrat diagram illustrates this effect. In the rigid rotor approximation the line wavenumbers lie on a parabola which has a maximum at The line of highest wavenumber in the R-branch is known as the band head. It occurs at the value of m which is equal to the integer part of x, or of (x+1).",
                    "score": 0.8869699239730835
                },
                {
                    "id": 2819601,
                    "contents": "Rotational–vibrational spectroscopy\nwhere mA and mB are the masses of the atoms A and B, and d represents the distance between the atoms. The term values of the ro-vibrational states are found (in the Born–Oppenheimer approximation) by combining the expressions for vibration and rotation. The first two terms in this expression correspond to a harmonic oscillator and a rigid rotor, the second pair of terms make a correction for anharmonicity and centrifugal distortion. A more general expression was given by Dunham. The selection rule for electric dipole allowed ro-vibrational transitions, in the case of a diamagnetic diatomic molecule is",
                    "score": 0.8864454030990601
                },
                {
                    "id": 2819590,
                    "contents": "Rotational–vibrational spectroscopy\nRotational–vibrational spectroscopy is a branch of molecular spectroscopy concerned with infrared and Raman spectra of molecules in the gas phase. Transitions involving changes in both vibrational and rotational states can be abbreviated as rovibrational (or ro-vibrational) transitions. When such transitions emit or absorb photons (electromagnetic radiation), the frequency is proportional to the difference in energy levels and can be detected by certain kinds of spectroscopy. Since changes in rotational energy levels are typically much smaller than changes in vibrational energy levels, changes in rotational state are said to give fine structure to the vibrational spectrum. For a given vibrational transition, the same theoretical treatment as for pure rotational spectroscopy gives the rotational quantum numbers, energy levels, and selection rules. In linear and spherical top molecules, rotational lines are found as simple progressions at both higher and lower frequencies relative to the",
                    "score": 0.8863794207572937
                },
                {
                    "id": 7113367,
                    "contents": "Anharmonicity\nAnharmonicity plays a role in lattice and molecular vibrations, in quantum oscillations, and in acoustics. The atoms in a molecule or a solid vibrate about their equilibrium positions. When these vibrations have small amplitudes they can be described by harmonic oscillators. However, when the vibrational amplitudes are large, for example at high temperatures, anharmonicity becomes important. An example of the effects of anharmonicity is the thermal expansion of solids, which is usually studied within the quasi-harmonic approximation. Studying vibrating anharmonic systems using quantum mechanics is a computationally demanding task because anharmonicity not only makes the potential experienced by each oscillator more complicated, but also introduces coupling between the oscillators. It is possible to use first-principles methods such as density-functional theory to map the anharmonic potential experienced by the atoms in both molecules and solids. Accurate anharmonic vibrational",
                    "score": 0.8862518668174744
                },
                {
                    "id": 23978883,
                    "contents": "Vibronic spectroscopy\nHere B are rotational constants and J are rotational quantum numbers. (For B also, a double prime indicates the ground state and a single prime an electronically excited state.) The values of the rotational constants may differ appreciably because the bond length in the electronic excited state may be quite different from the bond length in the ground state, because of the operation of the Franck-Condon principle. The rotational constant is inversely proportional to the square of the bond length. Usually B′ < B′′ as is true when an electron is promoted from a bonding orbital to an antibonding orbital, causing bond lengthening. But this is not always the case; if an electron is promoted from a non-bonding or antibonding orbital to a bonding orbital, there will be bond-shortening and B′ > B′′.",
                    "score": 0.8856580853462219
                },
                {
                    "id": 22214135,
                    "contents": "Vibrational bond\nA vibrational bond is a chemical bond that happens between two very large atoms, like bromine, and a very small atom, like hydrogen, at very high energy states. Vibrational bonds only exist for a few milliseconds. This bond is detectable through modern analytic chemistry and is significant because it affects the rate at which other reactions can occur. History Vibrational bonds were mathematically predicted almost thirty years before they were experimentally observed. The original theoretical calculations had been carried out by D.C. Clary and J.N.L Connor during the early 1980s. Together they hypothesized that with very large atoms and small atoms at high energy states, the elements would stabilize and create temporary bonds for very short periods of time. The vibrational bond would be weaker than any currently known bond, like the commonly known ionic or covalent bonds.",
                    "score": 0.8856368064880371
                },
                {
                    "id": 2819604,
                    "contents": "Rotational–vibrational spectroscopy\nwhere ν is a vibrational quantum number and α is a vibration-rotation interaction constant which can be calculated when the B values for two different vibrational states can be found. For carbon monoxide req = 113.0 pm. Nitric oxide, NO, is a special case as the molecule is paramagnetic, with one unpaired electron. Coupling of the electron spin angular momentum with the molecular vibration causes lambda-doubling with calculated harmonic frequencies of 1904.03 and 1903.68 cm−1. Rotational levels are also split.",
                    "score": 0.8839330077171326
                },
                {
                    "id": 552407,
                    "contents": "Wavenumber\nFor example, the spectroscopic wavenumbers of the emission spectrum of atomic hydrogen are given by the Rydberg formula: where R is the Rydberg constant, and ni and nf are the principal quantum numbers of the initial and final levels respectively (ni is greater than nf for emission). A spectroscopic wavenumber can be converted into energy per photon E by Planck's relation: It can also be converted into wavelength of light: where n is the refractive index of the medium. Note that the wavelength of light changes as it passes through different media, however, the spectroscopic wavenumber (i.e., frequency) remains constant. Conventionally, inverse centimeter (cm−1) units are used for , so often that such spatial frequencies are stated by some authors \"in wavenumbers\", incorrectly transferring the name of the quantity to the CGS unit cm−1 itself. See also Spatial frequency Refractive index Zonal wavenumber References Wave mechanics Physical quantities Units of frequency",
                    "score": 0.8838238716125488
                },
                {
                    "id": 9382991,
                    "contents": "Kasha's rule\nThe rule can be explained by the Franck–Condon factors for vibronic transitions. For a given pair of energy levels that differ in both vibrational and electronic quantum number, the Franck–Condon factor expresses the degree of overlap between their vibrational wavefunctions. The greater the overlap, the quicker the molecule can undergo transition from the higher to the lower level. Overlap between pairs is greatest when the two vibrational levels are close in energy; this tends to be the case when the vibrationless levels of the electronic states coupled by the transition (where the vibrational quantum number v is zero) are close. In most molecules, the vibrationless levels of the excited states all lie close together, so molecules in upper states quickly reach the lowest excited state, S1, before they have time to fluoresce. However, the energy gap between S1 and S0 is greater, so here fluorescence occurs, since it is now kinetically competitive with internal conversion (IC).",
                    "score": 0.8836974501609802
                },
                {
                    "id": 2819603,
                    "contents": "Rotational–vibrational spectroscopy\nwhere positive m values refer to the R-branch and negative values refer to the P-branch. The term ω0 gives the position of the (missing) Q-branch, the term implies an progression of equally spaced lines in the P- and R- branches, but the third term, shows that the separation between adjacent lines changes with changing rotational quantum number. When is greater than , as is usually the case, as J increases the separation between lines decreases in the R-branch and increases in the P-branch. Analysis of data from the infrared spectrum of carbon monoxide, gives value of of 1.915 cm−1 and of 1.898 cm−1. The bond lengths are easily obtained from these constants as r0 = 113.3 pm, r1 = 113.6 pm. These bond lengths are slightly different from the equilibrium bond length. This is because there is zero-point energy in the vibrational ground state, whereas the equilibrium bond length is at the minimum in the potential energy curve. The relation between the rotational constants is given by",
                    "score": 0.8836038112640381
                },
                {
                    "id": 18471746,
                    "contents": "Rotational partition function\nReferences See also Translational partition function Vibrational partition function Partition function (mathematics) Equations of physics Partition functions",
                    "score": 0.8834006786346436
                },
                {
                    "id": 2819619,
                    "contents": "Rotational–vibrational spectroscopy\nin which m = J+1 for the R-branch and -J for the P-branch. The three centrifugal distortion constants , and are needed to fit the term values of each level. The wavenumbers of the sub-structure corresponding to each band are given by represents the Q-branch of the sub-structure, whose position is given by . Parallel bands The C-Cl stretching vibration of methyl chloride, CH3Cl, gives a parallel band since the dipole moment change is aligned with the 3-fold rotation axis. The line spectrum shows the sub-structure of this band rather clearly; in reality, very high resolution spectroscopy would be needed to resolve the fine structure fully. Allen and Cross show parts of the spectrum of CH3D and give a detailed description of the numerical analysis of the experimental data.",
                    "score": 0.8831227421760559
                },
                {
                    "id": 19207720,
                    "contents": "Elmer Imes\nH.M. Randall and E.S. Imes, \"The Fine Structure of the Near Infra-Red Absorption Bands of HCI, HBr, and HF\"], Phys. Rev. 15, pp. 152-155, Feb. 1920; in Science Abstracts, Institution of Electrical Engineers., 1920, pp.342-343</ref> This work demonstrated for the first time that Quantum Theory could be applied to the rotational energy states of molecules, as well as the vibration and electronic levels. Imes' work provided an early verification of Quantum Theory.",
                    "score": 0.8828123807907104
                },
                {
                    "id": 10291321,
                    "contents": "Molecular vibration\nQuantum mechanics In the harmonic approximation the potential energy is a quadratic function of the normal coordinates. Solving the Schrödinger wave equation, the energy states for each normal coordinate are given by , where n is a quantum number that can take values of 0, 1, 2 ... In molecular spectroscopy where several types of molecular energy are studied and several quantum numbers are used, this vibrational quantum number is often designated as v. The difference in energy when n (or v) changes by 1 is therefore equal to , the product of the Planck constant and the vibration frequency derived using classical mechanics. For a transition from level n to level n+1 due to absorption of a photon, the frequency of the photon is equal to the classical vibration frequency (in the harmonic oscillator approximation).",
                    "score": 0.8827411532402039
                },
                {
                    "id": 2819593,
                    "contents": "Rotational–vibrational spectroscopy\nIn the simplest cases the part of the infrared spectrum involving vibrational transitions with the same rotational quantum number (ΔJ = 0) in ground and excited states is called the Q-branch. On the high frequency side of the Q-branch the energy of rotational transitions is added to the energy of the vibrational transition. This is known as the R-branch of the spectrum for ΔJ = +1. The P-branch for ΔJ = −1 lies on the low wavenumber side of the Q branch. The appearance of the R-branch is very similar to the appearance of the pure rotation spectrum (but shifted to much higher wavenumbers), and the P-branch appears as a nearly mirror image of the R-branch. The Q branch is sometimes missing because of transitions with no change in J being forbidden.",
                    "score": 0.8826231956481934
                },
                {
                    "id": 14762069,
                    "contents": "Edgar Bright Wilson\nWilson made major contributions to the field of molecular spectroscopy. He developed the first rigorous quantum mechanical Hamiltonian in internal coordinates for a polyatomic molecule. He developed the theory of how rotational spectra are influenced by centrifugal distortion during rotation. He pioneered the use of group theory for the analysis and simplification normal mode analysis, particularly for high symmetry molecules, such as benzene. In 1955, Wilson published Molecular Vibrations along with J.C. Decius Paul C. Cross. Following the Second World War, Wilson was a pioneer in the application of microwave spectroscopy to the determination of molecular structure. Wilson wrote an influential introductory text Introduction to Scientific Research that provided an introduction of all the steps of scientific research, from defining a problem through the archival of data after publication.",
                    "score": 0.8819925785064697
                },
                {
                    "id": 2819618,
                    "contents": "Rotational–vibrational spectroscopy\nThe fact that the selection rules are different is the justification for the classification and it means that the spectra have a different appearance which can often be immediately recognized. An expression for the calculated wavenumbers of the P- and R- branches may be given as",
                    "score": 0.8819668889045715
                },
                {
                    "id": 1791950,
                    "contents": "Infrared spectroscopy\nA molecule can vibrate in many ways, and each way is called a vibrational mode. For molecules with N number of atoms, linear molecules have 3N – 5 degrees of vibrational modes, whereas nonlinear molecules have 3N – 6 degrees of vibrational modes (also called vibrational degrees of freedom). As an example H2O, a non-linear molecule, will have 3 × 3 – 6 = 3 degrees of vibrational freedom, or modes. Simple diatomic molecules have only one bond and only one vibrational band. If the molecule is symmetrical, e.g. N2, the band is not observed in the IR spectrum, but only in the Raman spectrum. Asymmetrical diatomic molecules, e.g. CO, absorb in the IR spectrum. More complex molecules have many bonds, and their vibrational spectra are correspondingly more complex, i.e. big molecules have many peaks in their IR spectra.",
                    "score": 0.8810937404632568
                },
                {
                    "id": 29893161,
                    "contents": "Mary Jane Shultz\nShe studied at the University of Wisconsin-Madison, where she did research on physical chemistry and spectroscopy, receiving a Bachelor of Science with Honors in Chemistry in 1970. She was a graduate student at the Massachusetts Institute of Technology in Robert Silbey's laboratory investigating vibronic coupling in molecules and solids. Her PhD thesis established analytical models of the Jahn-Teller Effect between a strongly-coupled triply degenerate electronic state and a triply degenerate vibrational state strong coupling system. Career From 1977-78, she worked as a research associate and lecturer at Boston College. Then, she did research at Harvard University under Dr. Nicolaas Bloembergen as a post-doctoral scholar and later as a visiting faculty member on vibrational energy flow. During her time there, she was also a Radcliffe Fellow.",
                    "score": 0.8801756501197815
                },
                {
                    "id": 10291307,
                    "contents": "Molecular vibration\nThe vibrational states of a molecule can be probed in a variety of ways. The most direct way is through infrared spectroscopy, as vibrational transitions typically require an amount of energy that corresponds to the infrared region of the spectrum. Raman spectroscopy, which typically uses visible light, can also be used to measure vibration frequencies directly. The two techniques are complementary and comparison between the two can provide useful structural information such as in the case of the rule of mutual exclusion for centrosymmetric molecules. Vibrational excitation can occur in conjunction with electronic excitation in the ultraviolet-visible region. The combined excitation is known as a vibronic transition, giving vibrational fine structure to electronic transitions, particularly for molecules in the gas state. Simultaneous excitation of a vibration and rotations gives rise to vibration-rotation spectra. Number of vibrational modes",
                    "score": 0.8798065185546875
                },
                {
                    "id": 2819600,
                    "contents": "Rotational–vibrational spectroscopy\nLinear molecules Heteronuclear diatomic molecules Diatomic molecules with the general formula AB have one normal mode of vibration involving stretching of the A-B bond. The vibrational term values , for an anharmonic oscillator are given, to a first approximation, by where v is a vibrational quantum number, ωe is the harmonic wavenumber and χe is an anharmonicity constant. When the molecule is in the gas phase, it can rotate about an axis, perpendicular to the molecular axis, passing through the centre of mass of the molecule. The rotational energy is also quantized, with term values to a first approximation given by where J is a rotational quantum number and D is a centrifugal distortion constant. The rotational constant, Bv depends on the moment of inertia of the molecule, Iv, which varies with the vibrational quantum number, v",
                    "score": 0.8797047138214111
                },
                {
                    "id": 5522218,
                    "contents": "Selection rule\nVibrational spectra In vibrational spectroscopy, transitions are observed between different vibrational states. In a fundamental vibration, the molecule is excited from its ground state (v = 0) to the first excited state (v = 1). The symmetry of the ground-state wave function is the same as that of the molecule. It is, therefore, a basis for the totally symmetric representation in the point group of the molecule. It follows that, for a vibrational transition to be allowed, the symmetry of the excited state wave function must be the same as the symmetry of the transition moment operator. In infrared spectroscopy, the transition moment operator transforms as either x and/or y and/or z. The excited state wave function must also transform as at least one of these vectors. In Raman spectroscopy, the operator transforms as one of the second-order terms in the right-most column of the character table, below.",
                    "score": 0.8795040249824524
                },
                {
                    "id": 2819624,
                    "contents": "Rotational–vibrational spectroscopy\nThe water molecule is an important example of this class of molecule, particularly because of the presence of water vapor in the atmosphere. The low-resolution spectrum shown in green illustrates the complexity of the spectrum. At wavelengths greater than 10 μm (or wavenumbers less than 1000 cm−1) the absorption is due to pure rotation. The band around 6.3 μm (1590 cm−1) is due to the HOH bending vibration; the considerable breadth of this band is due to the presence of extensive rotational fine structure. High-resolution spectra of this band are shown in Allen and Cross, p 221. The symmetric and asymmetric stretching vibrations are close to each other, so the rotational fine structures of these bands overlap. The bands at shorter wavelength are overtones and combination bands, all of which show rotational fine structure. Medium resolution spectra of the bands around 1600 cm−1 and 3700 cm−1 are shown in Banwell and McCash, p91.",
                    "score": 0.8794038891792297
                },
                {
                    "id": 12411057,
                    "contents": "Hot band\nIn molecular vibrational spectroscopy, a hot band is a band centred on a hot transition, which is a transition between two excited vibrational states, i.e. neither is the overall ground state. In infrared or Raman spectroscopy, hot bands refer to those transitions for a particular vibrational mode which arise from a state containing thermal population of another vibrational mode. For example, for a molecule with 3 normal modes, , and , the transition ← , would be a hot band, since the initial state has one quantum of excitation in the mode. Hot bands are distinct from combination bands, which involve simultaneous excitation of multiple normal modes with a single photon, and overtones, which are transitions that involve changing the vibrational quantum number for a normal mode by more than 1.",
                    "score": 0.8792797327041626
                },
                {
                    "id": 1057638,
                    "contents": "Partition function\nPartition function may refer to: Rotational partition function Vibrational partition function Partition function (number theory) Partition function (mathematics), which generalizes its use in statistical mechanics and quantum field theory: Partition function (statistical mechanics) Partition function (quantum field theory)",
                    "score": 0.8790616989135742
                },
                {
                    "id": 23978884,
                    "contents": "Vibronic spectroscopy\nThe treatment of rotational fine structure of vibronic transitions is similar to the treatment of rotation-vibration transitions and differs principally in the fact that the ground and excited states correspond to two different electronic states as well as to two different vibrational levels. For the P-branch , so that Similarly for the R-branch , and Thus, the wavenumbers of transitions in both P- and R- branches are given, to a first approximation, by the single formula",
                    "score": 0.878760814666748
                },
                {
                    "id": 12411058,
                    "contents": "Hot band\nVibrational hot bands In the harmonic approximation, the normal modes of a molecule are not coupled, and all vibrational quantum levels are equally spaced, so hot bands would not be distinguishable from so-called \"fundamental\" transitions arising from the overall vibrational ground state. However, vibrations of real molecules always have some anharmonicity, which causes coupling between different vibrational modes that in turn shifts the observed frequencies of hot bands in vibrational spectra. Because anharmonicity decreases the spacing between adjacent vibrational levels, hot bands exhibit red shifts (appear at lower frequencies than the corresponding fundamental transitions). The magnitude of the observed shift is correlated to the degree of anharmonicity in the corresponding normal modes.",
                    "score": 0.8784205317497253
                },
                {
                    "id": 2819598,
                    "contents": "Rotational–vibrational spectroscopy\nwavenumbers corresponds to the energy difference between the (J + 1) and (J − 1) levels of the lower vibrational state and is denoted by since it is the difference between levels differing by two units of J. If centrifugal distortion is included, it is given by",
                    "score": 0.8782595992088318
                },
                {
                    "id": 986650,
                    "contents": "Atomic, molecular, and optical physics\nBoth subfields are primarily concerned with electronic structure and the dynamical processes by which these arrangements change. Generally this work involves using quantum mechanics. For molecular physics, this approach is known as quantum chemistry. One important aspect of molecular physics is that the essential atomic orbital theory in the field of atomic physics expands to the molecular orbital theory. Molecular physics is concerned with atomic processes in molecules, but it is additionally concerned with effects due to the molecular structure. Additionally to the electronic excitation states which are known from atoms, molecules are able to rotate and to vibrate. These rotations and vibrations are quantized; there are discrete energy levels. The smallest energy differences exist between different rotational states, therefore pure rotational spectra are in the far infrared region (about 30 - 150 µm wavelength) of the electromagnetic spectrum. Vibrational spectra are in the near",
                    "score": 0.8781211376190186
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_38",
        "question": "A thermodynamic study of $\\mathrm{DyCl}_3$ (E.H.P. Cordfunke, et al., J. Chem. Thermodynamics 28, 1387 (1996)) determined its standard enthalpy of formation from the following information\r\n(1) $\\mathrm{DyCl}_3(\\mathrm{~s}) \\rightarrow \\mathrm{DyCl}_3(\\mathrm{aq}$, in $4.0 \\mathrm{M} \\mathrm{HCl}) \\quad \\Delta_{\\mathrm{r}} H^{\\ominus}=-180.06 \\mathrm{~kJ} \\mathrm{~mol}^{-1}$\r\n(2) $\\mathrm{Dy}(\\mathrm{s})+3 \\mathrm{HCl}(\\mathrm{aq}, 4.0 \\mathrm{~m}) \\rightarrow \\mathrm{DyCl}_3(\\mathrm{aq}$, in $4.0 \\mathrm{M} \\mathrm{HCl}(\\mathrm{aq}))+\\frac{3}{2} \\mathrm{H}_2(\\mathrm{~g})$ $\\Delta_{\\mathrm{r}} H^{\\ominus}=-699.43 \\mathrm{~kJ} \\mathrm{~mol}^{-1}$\r\n(3) $\\frac{1}{2} \\mathrm{H}_2(\\mathrm{~g})+\\frac{1}{2} \\mathrm{Cl}_2(\\mathrm{~g}) \\rightarrow \\mathrm{HCl}(\\mathrm{aq}, 4.0 \\mathrm{M}) \\quad \\Delta_{\\mathrm{r}} H^{\\ominus}=-158.31 \\mathrm{~kJ} \\mathrm{~mol}^{-1}$\r\nDetermine $\\Delta_{\\mathrm{f}} H^{\\ominus}\\left(\\mathrm{DyCl}_3, \\mathrm{~s}\\right)$ from these data.",
        "golden_answers": [
            " -994.3"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 10535945,
                    "contents": "Table of thermodynamic equations\nReferences Atkins, Peter and de Paula, Julio Physical Chemistry, 7th edition, W.H. Freeman and Company, 2002 . Chapters 1–10, Part 1: \"Equilibrium\". Landsberg, Peter T. Thermodynamics and Statistical Mechanics. New York: Dover Publications, Inc., 1990. (reprinted from Oxford University Press, 1978). Lewis, G.N., and Randall, M., \"Thermodynamics\", 2nd Edition, McGraw-Hill Book Company, New York, 1961. Reichl, L.E., A Modern Course in Statistical Physics, 2nd edition, New York: John Wiley & Sons, 1998. Schroeder, Daniel V. Thermal Physics. San Francisco: Addison Wesley Longman, 2000 . Silbey, Robert J., et al. Physical Chemistry, 4th ed. New Jersey: Wiley, 2004. Callen, Herbert B. (1985). Thermodynamics and an Introduction to Themostatistics, 2nd edition, New York: John Wiley & Sons. External links Thermodynamic equation calculator Thermodynamic equations",
                    "score": 0.9014863967895508
                },
                {
                    "id": 17938826,
                    "contents": "Standard Gibbs free energy of formation\nThe standard Gibbs free energy of formation (Gf°) of a compound is the change of Gibbs free energy that accompanies the formation of 1 mole of a substance in its standard state from its constituent elements in their standard states (the most stable form of the element at 1 bar of pressure and the specified temperature, usually 298.15 K or 25 °C). The table below lists the standard Gibbs function of formation for several elements and chemical compounds and is taken from Lange's Handbook of Chemistry. Note that all values are in kJ/mol. Far more extensive tables can be found in the CRC Handbook of Chemistry and Physics and the NIST JANAF tables. The NIST Chemistry WebBook (see link below) is an online resource that contains standard enthalpy of formation for various compounds along with the standard absolute entropy for these compounds from which the standard Gibbs free energy of formation can be calculated. See also Thermochemistry Calorimetry References",
                    "score": 0.8977311849594116
                },
                {
                    "id": 9896541,
                    "contents": "Merle Randall\nEducation Randall completed his Ph.D. at the Massachusetts Institute of Technology in 1912 with a dissertation on “Studies in Free Energy”. Related Based on work by J. Willard Gibbs, it was known that chemical reactions proceeded to an equilibrium determined by the free energy of the substances taking part. Using this theory, Gilbert Lewis spent 25 years determining free energies of various substances. In 1923, he and Randall published the results of this study and formalizing chemical thermodynamics. According to the Belgian thermodynamicist Ilya Prigogine, their influential 1923 textbook led to the replacement of the term “affinity” by the term “free energy” in much of the English-speaking world. See also Ionic strength References Further reading Thermodynamicists American physical chemists 1888 births 1950 deaths",
                    "score": 0.8942858576774597
                },
                {
                    "id": 1638814,
                    "contents": "Chemical thermodynamics\nDuring the early 20th century, two major publications successfully applied the principles developed by Gibbs to chemical processes and thus established the foundation of the science of chemical thermodynamics. The first was the 1923 textbook Thermodynamics and the Free Energy of Chemical Substances by Gilbert N. Lewis and Merle Randall. This book was responsible for supplanting the chemical affinity with the term free energy in the English-speaking world. The second was the 1933 book Modern Thermodynamics by the methods of Willard Gibbs written by E. A. Guggenheim. In this manner, Lewis, Randall, and Guggenheim are considered as the founders of modern chemical thermodynamics because of the major contribution of these two books in unifying the application of thermodynamics to chemistry.",
                    "score": 0.8938469886779785
                },
                {
                    "id": 1749743,
                    "contents": "Gilbert N. Lewis\nLewis’ early papers also reveal an unusually advanced awareness of J. W. Gibbs's and P. Duhem's ideas of free energy and thermodynamic potential. These ideas were well known to physicists and mathematicians, but not to most practical chemists, who regarded them as abstruse and inapplicable to chemical systems. Most chemists relied on the familiar thermodynamics of heat (enthalpy) of Berthelot, Ostwald, and Van’t Hoff, and the calorimetric school. Heat of reaction is not, of course, a measure of the tendency of chemical changes to occur, and Lewis realized that only free energy and entropy could provide an exact chemical thermodynamics. He derived free energy from fugacity; he tried, without success, to obtain an exact expression for the entropy function, which in 1901 had not been defined at low temperatures. Richards too tried and failed, and not until Nernst succeeded in 1907 was it possible to calculate entropies unambiguously. Although Lewis’ fugacity-based system did not last,",
                    "score": 0.8915927410125732
                },
                {
                    "id": 5606461,
                    "contents": "History of chemistry\nAmerican mathematical physicist J. Willard Gibbs's work on the applications of thermodynamics was instrumental in transforming physical chemistry into a rigorous deductive science. During the years from 1876 to 1878, Gibbs worked on the principles of thermodynamics, applying them to the complex processes involved in chemical reactions. He discovered the concept of chemical potential, or the \"fuel\" that makes chemical reactions work. In 1876 he published his most famous contribution, \"On the Equilibrium of Heterogeneous Substances\", a compilation of his work on thermodynamics and physical chemistry which laid out the concept of free energy to explain the physical basis of chemical equilibria. In these essays were the beginnings of Gibbs’ theories of phases of matter: he considered each state of matter a phase, and each substance a component. Gibbs took all of the variables involved in a chemical reaction - temperature, pressure, energy, volume, and entropy - and included them in one",
                    "score": 0.8908144235610962
                },
                {
                    "id": 11242070,
                    "contents": "Timeline of chemistry\n1926Erwin Schrödinger proposes the Schrödinger equation, which provides a mathematical basis for the wave model of atomic structure. 1927Werner Heisenberg develops the uncertainty principle which, among other things, explains the mechanics of electron motion around the nucleus. 1927Fritz London and Walter Heitler apply quantum mechanics to explain covalent bonding in the hydrogen molecule, which marked the birth of quantum chemistry. 1929 Linus Pauling publishes Pauling's rules, which are key principles for the use of X-ray crystallography to deduce molecular structure. 1931Erich Hückel proposes Hückel's rule, which explains when a planar ring molecule will have aromatic properties. 1931Harold Urey discovers deuterium by fractionally distilling liquid hydrogen. 1932James Chadwick discovers the neutron. 1932–1934Linus Pauling and Robert Mulliken quantify electronegativity, devising the scales that now bear their names.",
                    "score": 0.8903200626373291
                },
                {
                    "id": 16135572,
                    "contents": "Swain–Lupton equation\nIn physical organic chemistry, the Swain–Lupton equation is a linear free energy relationship (LFER) that is used in the study of reaction mechanisms and in the development of quantitative structure activity relationships for organic compounds. It was developed by C. Gardner Swain and Elmer C. Lupton Jr. in 1968 as a refinement of the Hammett equation to include both field effects and resonance effects. Background In organic chemistry, the Hammett plot provides a means to assess substituent effects on a reaction equilibrium or rate using the Hammett equation (1): Hammett developed this equation from equilibrium constants from the dissociation of benzoic acid and derivatives (Fig. 1):",
                    "score": 0.89003586769104
                },
                {
                    "id": 3480034,
                    "contents": "Kenneth Pitzer\nKenneth Sanborn Pitzer (January 6, 1914 – December 26, 1997) was an American physical and theoretical chemist, educator, and university president. He was described as \"one of the most influential physical chemists of his era\" whose work \"spanned almost all of the important fields of physical chemistry: thermodynamics, statistical mechanics, molecular structure, quantum mechanics, spectroscopy, chemical bonding, relativistic chemical effects, properties of concentrated aqueous salt solutions, kinetics, and conformational analysis.\" Biography He received his B.S. in 1935 from the California Institute of Technology and his Ph.D. from the University of California, Berkeley in 1937. Upon graduation, he was appointed to the faculty of UC Berkeley's Chemistry Department and was eventually elevated to professor. From 1951 to 1960, he served as dean of the College of Chemistry.",
                    "score": 0.8883101344108582
                },
                {
                    "id": 5606496,
                    "contents": "History of chemistry\nIn 1925, Austrian-born physicist Wolfgang Pauli developed the Pauli exclusion principle, which states that no two electrons around a single nucleus in an atom can occupy the same quantum state simultaneously, as described by four quantum numbers. Pauli made major contributions to quantum mechanics and quantum field theory - he was awarded the 1945 Nobel Prize for Physics for his discovery of the Pauli exclusion principle - as well as solid-state physics, and he successfully hypothesized the existence of the neutrino. In addition to his original work, he wrote masterful syntheses of several areas of physical theory that are considered classics of scientific literature.",
                    "score": 0.8872712850570679
                },
                {
                    "id": 1377646,
                    "contents": "Josiah Willard Gibbs\nGibbs's monograph rigorously and ingeniously applied his thermodynamic techniques to the interpretation of physico-chemical phenomena, explaining and relating what had previously been a mass of isolated facts and observations. The work has been described as \"the Principia of thermodynamics\" and as a work of \"practically unlimited scope\". It solidly laid the foundation for physical Chemistry. Wilhelm Ostwald, who translated Gibbs's monograph into German, referred to Gibbs as the \"founder of chemical energetics\". According to modern commentators, Gibbs continued to work without pay until 1880, when the new Johns Hopkins University in Baltimore, Maryland offered him a position paying $3,000 per year. In response, Yale offered him an annual salary of $2,000, which he was content to accept. Career, 1880–1903",
                    "score": 0.8872581124305725
                },
                {
                    "id": 10795771,
                    "contents": "Thermodynamic databases for pure substances\nExternal links NIST WebBook A gateway to the data collection of the National Institute of Standards and Technology. NASA Glenn ThermoBuild A web interface to generate tabulated thermodynamic data. Burcat's Thermodynamic Database Database for more than 3,000 chemical species. DIPPR The Design Institute for Physical Properties DIPPR 801 Critically evaluated thermophysical property database useful for chemical process design and equilibrium calculations. MTDATA software and databases for calculation of thermodynamic properties and phase equilibria Free Steam Tables Online calculator based on IAPWS-IF97 FACT-Web programs Various on-line tools for obtaining thermodynamic data and making equilibrium calculations. Mol-Instincts A chemical database based on Quantum Mechanics and QSPR, providing thermodynamic properties for millions of compounds. Thermodynamics databases",
                    "score": 0.8869096040725708
                },
                {
                    "id": 10795763,
                    "contents": "Thermodynamic databases for pure substances\nAll thermodynamic data is a non-linear function of temperature (and pressure), but there is no universal equation format for expressing the various functions. Here we describe a commonly used polynomial equation to express the temperature dependence of the heat content. A common six-term equation for the isobaric heat content is: Regardless of the equation format, the heat of formation of a compound at any temperature is ΔH°form at 298.15 K, plus the sum of the heat content parameters of the products minus the sum of the heat content parameters of the reactants. The Cp equation is obtained by taking the derivative of the heat content equation. The entropy equation is obtained by integrating the Cp/T equation: F' is a constant of integration obtained by inserting S° at any temperature T. The Gibbs energy of formation of a compound is obtained from the defining equation ΔG°form = ΔH°form – T(ΔS°form), and is expressed as",
                    "score": 0.8860548138618469
                },
                {
                    "id": 6704743,
                    "contents": "History of thermodynamics\nGeological thermodynamics – c. 1970s Biological evolution thermodynamics – 1978 Geochemical thermodynamics – c. 1980s Atmospheric thermodynamics – c. 1980s Natural systems thermodynamics – 1990s Supramolecular thermodynamics – 1990s Earthquake thermodynamics – 2000 Drug-receptor thermodynamics – 2001 Pharmaceutical systems thermodynamics – 2002",
                    "score": 0.8859158754348755
                },
                {
                    "id": 1749728,
                    "contents": "Gilbert N. Lewis\nG. N. Lewis was born in 1875 in Weymouth, Massachusetts. After receiving his PhD in chemistry from Harvard University and studying abroad in Germany and the Philippines, Lewis moved to California in 1912 to teach chemistry at the University of California, Berkeley, where he became the Dean of the College of Chemistry and spent the rest of his life. As a professor, he incorporated thermodynamic principles into the chemistry curriculum and reformed chemical thermodynamics in a mathematically rigorous manner accessible to ordinary chemists. He began measuring the free energy values related to several chemical processes, both organic and inorganic. In 1916, he also proposed his theory of bonding and added information about electrons in the periodic table of the chemical elements. In 1933, he started his research on isotope separation. Lewis worked with hydrogen and managed to purify a sample of heavy water. He then came up with his theory of acids and bases, and did work in photochemistry",
                    "score": 0.8855811357498169
                },
                {
                    "id": 11140584,
                    "contents": "Frank L. Lambert\nThe 2005 2nd Edition of \"Chemistry: The Molecular Science\" by Moore et al., on p. xiv states \"Revised Chapters 14 and 18 to more clearly present entropy as dispersal of energy (See Lambert F. L. J. Chem. Educ. 1999,76, 1385; 2002, 79, 187).\" The 2006 4th edition of \"Chemistry: The Molecular Nature of Matter and Change\" by Silberberg on p. xviii states \"Chapter 20 has been completely rewritten to reflect a new approach to the coverage of entropy. The vague notion of \"disorder\" (with analogies to macroscopic systems) has been replaced with the idea that entropy is related to the dispersal of a system’s energy and the freedom of motion of its particles.\" Silberberg thanks \"Frank Lambert of Occidental College for insightful advice and comments on the coverage of entropy\". In his \"Chemistry: A Molecular Approach\", Tro states on p. xxi \"Thanks also to Frank Lambert for helping us all to think more clearly about entropy and his review of the entropy sections of this book.\" His ideas were",
                    "score": 0.8851951956748962
                },
                {
                    "id": 24531139,
                    "contents": "DMol3\nfrom first principles. DMol3 can either use gas phase boundary conditions or 3D periodic boundary conditions for solids or simulations of lower-dimensional periodicity. It has also pioneered the use of the conductor-like screening model COSMO Solvation Model for quantum simulations of solvated molecules and recently of wetted surfaces. DMol3 permits geometry optimisation and saddle point search with and without geometry constraints, as well as calculation of a variety of derived properties of the electronic configuration. DMol3 development started in the early eighties with B. Delley then associated with A.J.Freeman and D.E.Ellis at Northwestern University. In 1989 DMol3 appeared as DMol, the first commercial density functional package for industrial use by Biosym Technologies now Accelrys. Delley's 1990 publication was cited more than 3000 times. See also Quantum chemistry computer programs External links DMol3 datasheet developers page Materials Studio References",
                    "score": 0.8844031095504761
                },
                {
                    "id": 1002189,
                    "contents": "Standard enthalpy of formation\nKey concepts for doing enthalpy calculations When a reaction is reversed, the magnitude of ΔH stays the same, but the sign changes. When the balanced equation for a reaction is multiplied by an integer, the corresponding value of ΔH must be multiplied by that integer as well. The change in enthalpy for a reaction can be calculated from the enthalpies of formation of the reactants and the products Elements in their standard states make no contribution to the enthalpy calculations for the reaction, since the enthalpy of an element in its standard state is zero. Allotropes of an element other than the standard state generally have non-zero standard enthalpies of formation. Examples: standard enthalpies of formation at 25 °C Thermochemical properties of selected substances at 298.15 K and 1 atm Inorganic substances Aliphatic hydrocarbons Other organic compounds See also Calorimetry Enthalpy Heat of combustion Thermochemistry References",
                    "score": 0.8842819929122925
                },
                {
                    "id": 26410400,
                    "contents": "Pablo G. Debenedetti\nPresidential Young Investigator, National Science Foundation, 1987 Teacher-Scholar Award, Camille and Henry Dreyfus Foundation, 1989 Guggenheim Fellow, John Simon Guggenheim Memorial Foundation, 1991 Best Professional/Scholarly Book in Chemistry, Metastable Liquids, Association of American Publishers, 1997 Professional Progress Award, American Institute of Chemical Engineers, 1997 Elected to the National Academy of Engineering, 2000 John M. Prausnitz Award in Applied Chemical Thermodynamics, 2001 Joel Henry Hildebrand Award in the Theoretical and Experimental Chemistry of Liquids, American Chemical Society, 2008 Elected to the American Academy of Arts and Sciences, 2008 Distinguished Teacher Award, School of Engineering and Applied Science, Princeton University, 2008 President's Award for Distinguished Teaching, Princeton University, 2008 William H. Walker Award, American Institute of Chemical Engineers, 2008",
                    "score": 0.8842484354972839
                },
                {
                    "id": 1404488,
                    "contents": "Thermodynamic free energy\nThe Gibbs free energy is given by , where H is the enthalpy, T is the absolute temperature, and S is the entropy. , where U is the internal energy, p is the pressure, and V is the volume. G is the most useful for processes involving a system at constant pressure p and temperature T, because, in addition to subsuming any entropy change due merely to heat, a change in G also excludes the work needed to \"make space for additional molecules\" produced by various processes. Gibbs free energy change therefore equals work not associated with system expansion or compression, at constant temperature and pressure. (Hence its utility to solution-phase chemists, including biochemists.)",
                    "score": 0.88401198387146
                },
                {
                    "id": 2026571,
                    "contents": "Thermodynamic equilibrium\nLevine, I.N. (1983), Physical Chemistry, second edition, McGraw-Hill, New York, .",
                    "score": 0.8838221430778503
                },
                {
                    "id": 103988,
                    "contents": "Charles Coulson\nIn 1972, Coulson was appointed to the newly created chair of theoretical chemistry. Books and journals Coulson wrote several books. Valence, first published in 1952, and also reissued posthumously, was the most influential. Coulson also wrote popular works on atomic and molecular structure: Waves (1941) Electricity (1948) The Place of Science as a Cohesive Force in Modern Society (1951) Christianity in an Age of science (1953) Coulson was a founder member of the board of the journal Molecular Physics and its first editor.",
                    "score": 0.8838202357292175
                },
                {
                    "id": 1404508,
                    "contents": "Thermodynamic free energy\nBased on these and other ideas, Berthelot and Thomsen, as well as others, considered the heat given out in the formation of a compound as a measure of the affinity, or the work done by the chemical forces. This view, however, was not entirely correct. In 1847, the English physicist James Joule showed that he could raise the temperature of water by turning a paddle wheel in it, thus showing that heat and mechanical work were equivalent or proportional to each other, i.e., approximately, . This statement came to be known as the mechanical equivalent of heat and was a precursory form of the first law of thermodynamics.",
                    "score": 0.8838196396827698
                },
                {
                    "id": 9896540,
                    "contents": "Merle Randall\nMerle Randall (January 29, 1888 – March 17, 1950) was an American physical chemist famous for his work with Gilbert N. Lewis, over a period of 25 years, in measuring reaction heat of chemical compounds and determining their corresponding free energy. Together, their 1923 textbook \"Thermodynamics and the Free Energy of Chemical Substances\" became a classic work in the field of chemical thermodynamics. In 1932, Merle Randall authored two scientific papers with Mikkel Frandsen: “The Standard Electrode Potential of Iron and the Activity Coefficient of Ferrous Chloride,” and “Determination of the Free Energy of Ferrous Hydroxide from Measurements of Electromotive Force.” Education Randall completed his Ph.D. at the Massachusetts Institute of Technology in 1912 with a dissertation on “Studies in Free Energy”.",
                    "score": 0.8829116225242615
                },
                {
                    "id": 13665810,
                    "contents": "Walter Kauzmann\nHis first book, Quantum Chemistry, was published in 1957, followed by The Kinetic Theory of Gases (1966) and Thermodynamics and Statistics (1967). With David Eisenberg, a former postdoctoral fellow of Kauzmann, he wrote The Structure and Properties of Water (1969), a book reissued in 2005 by Oxford University Press as part of its Classic Texts in the Physical Sciences series. The first three are textbooks for undergraduate physical chemistry, which Kauzmann taught at Princeton for many years. Kauzmann's pedagogy is discussed in an article by Bruce Alberts. Kauzmann married Elizabeth Flagler Kauzmann, then a research assistant in the laboratory of Frank Johnson in the Princeton Biology Department, in April, 1951. Elizabeth died in 2004 after more than 50 years of marriage. They are survived by two sons, a daughter, and eight grandchildren. They summered on Cape Breton Island, and eventually donated of their property to the Nova Scotia Nature Trust. Awards and honors",
                    "score": 0.8825910091400146
                },
                {
                    "id": 1973063,
                    "contents": "Helmholtz free energy\n\"which has exactly the form of Helmholtz free energy\". See also Gibbs free energy and thermodynamic free energy for thermodynamics history overview and discussion of free energy Grand potential Enthalpy Statistical mechanics This page details the Helmholtz energy from the point of view of thermal and statistical physics. Bennett acceptance ratio for an efficient way to calculate free energy differences and comparison with other methods. References Further reading Atkins' Physical Chemistry, 7th edition, by Peter Atkins and Julio de Paula, Oxford University Press HyperPhysics Helmholtz Free Energy Helmholtz and Gibbs Free Energies Physical quantities Hermann von Helmholtz State functions Thermodynamic free energy",
                    "score": 0.882482647895813
                },
                {
                    "id": 1377645,
                    "contents": "Josiah Willard Gibbs\nGibbs then extended his thermodynamic analysis to multi-phase chemical systems (i.e., to systems composed of more than one form of matter) and considered a variety of concrete applications. He described that research in a monograph titled \"On the Equilibrium of Heterogeneous Substances\", published by the Connecticut Academy in two parts that appeared respectively in 1875 and 1878. That work, which covers about three hundred pages and contains exactly seven hundred numbered mathematical equations, begins with a quotation from Rudolf Clausius that expresses what would later be called the first and second laws of thermodynamics: \"The energy of the world is constant. The entropy of the world tends towards a maximum.\"",
                    "score": 0.882429838180542
                },
                {
                    "id": 1170404,
                    "contents": "Physical chemistry\nHistory The term \"physical chemistry\" was coined by Mikhail Lomonosov in 1752, when he presented a lecture course entitled \"A Course in True Physical Chemistry\" (Russian: «Курс истинной физической химии») before the students of Petersburg University. In the preamble to these lectures he gives the definition: \"Physical chemistry is the science that must explain under provisions of physical experiments the reason for what is happening in complex bodies through chemical operations\". Modern physical chemistry originated in the 1860s to 1880s with work on chemical thermodynamics, electrolytes in solutions, chemical kinetics and other subjects. One milestone was the publication in 1876 by Josiah Willard Gibbs of his paper, On the Equilibrium of Heterogeneous Substances. This paper introduced several of the cornerstones of physical chemistry, such as Gibbs energy, chemical potentials, and Gibbs' phase rule.",
                    "score": 0.8816177248954773
                },
                {
                    "id": 1002179,
                    "contents": "Standard enthalpy of formation\nThe standard enthalpy of formation or standard heat of formation of a compound is the change of enthalpy during the formation of 1 mole of the substance from its constituent elements, with all substances in their standard states. The standard pressure value p⦵ = 105 Pa (= 100 kPa = 1 bar) is recommended by IUPAC, although prior to 1982 the value 1.00 atm (101.325 kPa) was used. There is no standard temperature. Its symbol is ΔfH⦵. The superscript Plimsoll on this symbol indicates that the process has occurred under standard conditions at the specified temperature (usually 25 °C or 298.15 K). Standard states are as follows: For a gas: the hypothetical state it would have assuming it obeyed the ideal gas equation at a pressure of 1 bar For a gaseous or solid solute present in a diluted ideal solution: the hypothetical state of concentration of the solute of exactly one mole per liter (1 M) at a pressure of 1 bar extrapolated from infinite dilution",
                    "score": 0.881591796875
                },
                {
                    "id": 10795766,
                    "contents": "Thermodynamic databases for pure substances\nRow 1. Molar mass of species, density at 298.15 K, ΔH°form 298.15, S°298.15. and the upper temperature limit for the file. Row 2. Number of Cp equations required. Here, three because of three species phases. Row 3. Values of the five parameters for the first Cp equation; temperature limit for the equation. Row 4. Values of the five parameters for the second Cp equation; temperature limit for the equation. Row 5. Values of the five parameters for the third Cp equation; temperature limit for the equation. Row 6. Number of HT - H298 equations required. Row 7. Values of the six parameters for the first HT - H298 equation; temperature limit for the equation, and ΔH°trans for the first phase change. Row 8. Values of the six parameters for the second HT - H298 equation; temperature limit for the equation, and ΔH°trans for the second phase change.",
                    "score": 0.8815205693244934
                },
                {
                    "id": 1404514,
                    "contents": "Thermodynamic free energy\nUp until this point, the general view had been such that: “all chemical reactions drive the system to a state of equilibrium in which the affinities of the reactions vanish”. Over the next 60 years, the term affinity came to be replaced with the term free energy. According to chemistry historian Henry Leicester, the influential 1923 textbook Thermodynamics and the Free Energy of Chemical Reactions by Gilbert N. Lewis and Merle Randall led to the replacement of the term “affinity” by the term “free energy” in much of the English-speaking world. See also Energy Second law of thermodynamics Superconductivity Merle Randall References Energy (physics) State functions",
                    "score": 0.8813520073890686
                },
                {
                    "id": 1002180,
                    "contents": "Standard enthalpy of formation\nFor a pure substance or a solvent in a condensed state (a liquid or a solid): the standard state is the pure liquid or solid under a pressure of 1 bar For an element: the form in which the element is most stable under 1 bar of pressure. One exception is phosphorus, for which the most stable form at 1 bar is black phosphorus, but white phosphorus is chosen as the standard reference state for zero enthalpy of formation.",
                    "score": 0.8813483715057373
                },
                {
                    "id": 1624948,
                    "contents": "Chemistry\nEnergy and entropy considerations are invariably important in almost all chemical studies. Chemical substances are classified in terms of their structure, phase, as well as their chemical compositions. They can be analyzed using the tools of chemical analysis, e.g. spectroscopy and chromatography. Scientists engaged in chemical research are known as chemists. Most chemists specialize in one or more sub-disciplines. Several concepts are essential for the study of chemistry; some of them are: Matter In chemistry, matter is defined as anything that has rest mass and volume (it takes up space) and is made up of particles. The particles that make up matter have rest mass as well – not all particles have rest mass, such as the photon. Matter can be a pure chemical substance or a mixture of substances. Atom",
                    "score": 0.8811841607093811
                },
                {
                    "id": 10795769,
                    "contents": "Thermodynamic databases for pure substances\nMost computerized databases will create a table of thermodynamic values using the values from the datafile. For MgCl2(c,l,g) at 1 atm pressure: The table format is a common way to display thermodynamic data. The FREED table gives additional information in the top rows, such as the mass and amount composition and transition temperatures of the constituent elements. Transition temperatures for the constituent elements have dashes ------- in the first column in a blank row, such as at 922 K, the melting point of Mg. Transition temperatures for the substance have two blank rows with dashes, and a center row with the defined transition and the enthalpy change, such as the melting point of MgCl2 at 980 K. The datafile equations are at the bottom of the table, and the entire table is in an Excel worksheet. This is particularly useful when the data is intended for making specific calculations. See also",
                    "score": 0.881049633026123
                },
                {
                    "id": 5606463,
                    "contents": "History of chemistry\nWithin this paper was perhaps his most outstanding contribution, the introduction of the concept of free energy, now universally called Gibbs free energy in his honor. The Gibbs free energy relates the tendency of a physical or chemical system to simultaneously lower its energy and increase its disorder, or entropy, in a spontaneous natural process. Gibbs's approach allows a researcher to calculate the change in free energy in the process, such as in a chemical reaction, and how fast it will happen. Since virtually all chemical processes and many physical ones involve such changes, his work has significantly impacted both the theoretical and experiential aspects of these sciences. In 1877, Ludwig Boltzmann established statistical derivations of many important physical and chemical concepts, including entropy, and distributions of molecular velocities in the gas phase. Together with Boltzmann and James Clerk Maxwell, Gibbs created a new branch of theoretical physics called statistical",
                    "score": 0.881033182144165
                },
                {
                    "id": 7303299,
                    "contents": "The Journal of Physical Chemistry A\nThe Journal of Physical Chemistry A is a scientific journal which reports research on the chemistry of molecules - including their dynamics, spectroscopy, kinetics, structure, bonding, and quantum chemistry. It is published weekly by the American Chemical Society. Before 1997 the title was simply Journal of Physical Chemistry. Owing to the ever-growing amount of research in the area, in 1997 the journal was split into Journal of Physical Chemistry A (molecular theoretical and experimental physical chemistry) and The Journal of Physical Chemistry B (solid state, soft matter, liquids, etc.). Beginning in 2007, the latter underwent a further split, with The Journal of Physical Chemistry C now being dedicated to nanotechnology, molecular electronics, and related subjects. Editors-in-chief 1896–1932 Wilder Dwight Bancroft, Joseph E. Trevor 1933–1951 S. C. Lind 1952–1964 William A. Noyes 1965–1969 F. T. Wall 1970–1980 Bryce Crawford 1980–2004 Mostafa El-Sayed",
                    "score": 0.880507230758667
                },
                {
                    "id": 18691881,
                    "contents": "The Journal of Chemical Thermodynamics\nThe Journal of Chemical Thermodynamics is a monthly peer-reviewed scientific journal covering experimental thermodynamics and thermophysics including bio-thermodynamics, calorimetry, phase equilibria, equilibrium thermodynamic properties and transport properties. It is published by Elsevier. The editors-in-chief are W.E. Acree Jr., N. Kishore, B. F. Woodfield. Abstracting and indexing The journal is abstracted and indexed in Chemical Abstracts, Chemistry Citation Index, Current Contents/Physics, Chemical, & Earth Sciences, Engineered Materials Abstracts, Physics Abstracts, Reaction Citation Index, Science Citation Index, and Scopus. External links Monthly journals Elsevier academic journals Publications established in 1969 English-language journals Chemistry journals",
                    "score": 0.8805066347122192
                },
                {
                    "id": 13262040,
                    "contents": "List of scientific publications by Albert Einstein\n| Annalen der Physik (ser. 4), 8, 798–814, link || Intermolecular forces. Einstein's second paper on a universal molecular energy function, this time applied to electrolytic solutions. No data are available for comparison. Einstein characterizes these two papers as \"worthless\" in 1907. |- | Schilpp 3; CP 2, 3 || 1902 || Kinetische Theorie des Wärmegleichgewichtes und des zweiten Hauptsatzes der Thermodynamik | Annalen der Physik (ser. 4), 9, 417–433, link || Statistical mechanics. Study of the equipartition theorem and the definitions of temperature and entropy. |- | Schilpp 4; CP 2, 4 || 1903 || Eine Theorie der Grundlagen der Thermodynamik | Annalen der Physik (ser. 4), 11, 170–187, link || Statistical mechanics. The problem of irreversibility in thermodynamics. |- | Schilpp 5; CP 2, 5 || 1904 || Allgemeine molekulare Theorie der Wärme",
                    "score": 0.8803234100341797
                },
                {
                    "id": 1707360,
                    "contents": "Enthalpy\nSee also Standard enthalpy change of formation (data table) Calorimetry Calorimeter Departure function Hess's law Isenthalpic process Laws of thermodynamics Stagnation enthalpy Thermodynamic databases for pure substances Notes References Bibliography External links Enthalpy – Eric Weisstein's World of Physics Enthalpy – Georgia State University Enthalpy example calculations – Texas A&M University Chemistry Department State functions Energy (physics) Physical quantities",
                    "score": 0.8798516392707825
                },
                {
                    "id": 10535930,
                    "contents": "Table of thermodynamic equations\nThis article is a summary of common equations and quantities in thermodynamics (see thermodynamic equations for more elaboration). Definitions Many of the definitions below are also used in the thermodynamics of chemical reactions. General basic quantities {| class=\"wikitable\" |- ! scope=\"col\" width=\"200\" | Quantity (Common Name/s) ! scope=\"col\" width=\"125\" | (Common) Symbol/s ! scope=\"col\" width=\"125\" | SI Units ! scope=\"col\" width=\"100\" | Dimension |- !Number of molecules | N | dimensionless | dimensionless |- !Number of moles |n | mol | [N] |- !Temperature | T | K | [Θ] |- !Heat Energy | Q, q | J | [M][L]2[T]−2 |- !Latent Heat | QL | J | [M][L]2[T]−2 |- |} General derived quantities {| class=\"wikitable\" |-b",
                    "score": 0.8797961473464966
                },
                {
                    "id": 4024960,
                    "contents": "List of important publications in chemistry\nDescription: The defining reference for electrochemistry, coupling thousands of electroanalytical methods with the theory behind them. Importance: A reference publication. Theoretical chemistry, quantum chemistry and computational chemistry Valence and the structure of atoms and molecules Gilbert N. Lewis New York, The Chemical Catalog Company, Inc., 1923. Description: Discusses ionic and covalent bonding (polar and non-polar). Importance: The book that introduced the modern concept of the covalent bond as the sharing of electron pairs, and tried to reconcile the chemist's empirical view of the atom with the physicist's and spectroscopist's quantum mechanical view. It could be considered a precursor to Pauling's books. Introduction to Quantum Mechanics with Applications to Chemistry Linus Pauling, E. Bright Wilson New York, London, McGraw-Hill book company, 1935. Description: A classic and excellent introduction to quantum mechanics.",
                    "score": 0.879780650138855
                },
                {
                    "id": 1404506,
                    "contents": "Thermodynamic free energy\nIn the 19th century, the French chemist Marcellin Berthelot and the Danish chemist Julius Thomsen had attempted to quantify affinity using heats of reaction. In 1875, after quantifying the heats of reaction for a large number of compounds, Berthelot proposed the principle of maximum work, in which all chemical changes occurring without intervention of outside energy tend toward the production of bodies or of a system of bodies which liberate heat.",
                    "score": 0.8797426223754883
                },
                {
                    "id": 2204327,
                    "contents": "Standard enthalpy of reaction\nStandard states can be defined at any temperature and pressure, so both the standard temperature and pressure must always be specified. Most values of standard thermochemical data are tabulated at either (25°C, 1 bar) or (25°C, 1 atm).",
                    "score": 0.8796818256378174
                },
                {
                    "id": 1638835,
                    "contents": "Chemical thermodynamics\nSee also Thermodynamic databases for pure substances References Further reading Library of Congress Catalog No. 60-5597 Library of Congress Catalog No. 67-29540 Library of Congress Catalog No. 67-20003 External links Chemical Thermodynamics - University of North Carolina Chemical energetics (Introduction to thermodynamics and the First Law) Thermodynamics of chemical equilibrium (Entropy, Second Law and free energy) Physical chemistry Branches of thermodynamics Chemical engineering thermodynamics",
                    "score": 0.8795185685157776
                },
                {
                    "id": 27736629,
                    "contents": "C9H14N2O3\n{{DISPLAYTITLE:C9H14N2O3}} The molecular formula C9H14N2O3 (molar mass: 198.219 g/mol, exact mass: 198.1004 u) may refer to: Metharbital Probarbital Molecular formulas",
                    "score": 0.8793416619300842
                },
                {
                    "id": 11242069,
                    "contents": "Timeline of chemistry\n1916Gilbert N. Lewis publishes \"The Atom and the Molecule\", the foundation of valence bond theory. 1921Otto Stern and Walther Gerlach establish concept of quantum mechanical spin in subatomic particles. 1923Gilbert N. Lewis and Merle Randall publish Thermodynamics and the Free Energy of Chemical Substances, first modern treatise on chemical thermodynamics. 1923Gilbert N. Lewis develops the electron pair theory of acid/base reactions. 1924Louis de Broglie introduces the wave-model of atomic structure, based on the ideas of wave–particle duality. 1925Wolfgang Pauli develops the exclusion principle, which states that no two electrons around a single nucleus may have the same quantum state, as described by four quantum numbers. 1926Erwin Schrödinger proposes the Schrödinger equation, which provides a mathematical basis for the wave model of atomic structure.",
                    "score": 0.8792303204536438
                },
                {
                    "id": 1297220,
                    "contents": "Theoretical chemistry\nIn recent years, it has consisted primarily of quantum chemistry, i.e., the application of quantum mechanics to problems in chemistry. Other major components include molecular dynamics, statistical thermodynamics and theories of electrolyte solutions, reaction networks, polymerization, catalysis, molecular magnetism and spectroscopy. Modern theoretical chemistry may be roughly divided into the study of chemical structure and the study of chemical dynamics. The former includes studies of: electronic structure, potential energy surfaces, and force fields; vibrational-rotational motion; equilibrium properties of condensed-phase systems and macro-molecules. Chemical dynamics includes: bimolecular kinetics and the collision theory of reactions and energy transfer; unimolecular rate theory and metastable states; condensed-phase and macromolecular aspects of dynamics.",
                    "score": 0.8790594339370728
                },
                {
                    "id": 24617533,
                    "contents": "Annual Review of Physical Chemistry\nHistory The Annual Review of Physical Chemistry published its first volume in 1950. Its founding editor was University of California chemist Gerhard Krohn Rollefson. Some branches of physical chemistry were designated to be reviewed with each volume, while other branches would be reviewed less frequently. Upon Rollefson's death in 1955, he was succeeded by Henry Eyring. The editorial committee considered changing the name of the journal in the 1980s to the Annual Review of Physical Chemistry and Chemical Physics, though decided against it by 1988. In addition to publishing reviews about physical chemistry, many volumes contain a prefatory chapter with an informal review of a chemist or institution. As of 2020, it was published both in print and electronically.",
                    "score": 0.879039466381073
                },
                {
                    "id": 10795770,
                    "contents": "Thermodynamic databases for pure substances\nSee also Chemical thermodynamics Physical chemistry Materials science Laws of thermodynamics Thermochemistry Standard temperature and pressure Dortmund Data Bank CALPHAD (method) References Robie, Richard A., and Bruce S. Hemingway (1995). Thermodynamic Properties of Minerals . . . at Higher Temperatures, U. S. Geological Survey Bulletin 2131. Yaws, Carl L. (2007). Yaws Handbook of Thermodynamic Properties for Hydrocarbons & Chemicals, Gulf Publishing Company. . Gurvich, L.V., Veitz, I.V., et al. (1989) Thermodynamic Properties of Individual Substances. Fourth edition, Hemisphere Pub Co. NY, L., Vol.1 in 2 parts.",
                    "score": 0.8789545297622681
                },
                {
                    "id": 1170407,
                    "contents": "Physical chemistry\nFurther development in physical chemistry may be attributed to discoveries in nuclear chemistry, especially in isotope separation (before and during World War II), more recent discoveries in astrochemistry, as well as the development of calculation algorithms in the field of \"additive physicochemical properties\" (practically all physicochemical properties, such as boiling point, critical point, surface tension, vapor pressure, etc.—more than 20 in all—can be precisely calculated from chemical structure alone, even if the chemical molecule remains unsynthesized), and herein lies the practical importance of contemporary physical chemistry. See Group contribution method, Lydersen method, Joback method, Benson group increment theory, quantitative structure–activity relationship Journals",
                    "score": 0.8788291811943054
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_39",
        "question": "Calculate $\\Delta_{\\mathrm{r}} G^{\\ominus}(375 \\mathrm{~K})$ for the reaction $2 \\mathrm{CO}(\\mathrm{g})+\\mathrm{O}_2(\\mathrm{~g}) \\rightarrow 2 \\mathrm{CO}_2(\\mathrm{~g})$ from the values of $\\Delta_{\\mathrm{r}} G^{\\ominus}(298 \\mathrm{~K})$ : and $\\Delta_{\\mathrm{r}} H^{\\ominus}(298 \\mathrm{~K})$, and the GibbsHelmholtz equation.",
        "golden_answers": [
            "-501"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 27179636,
                    "contents": "Claire Vallance\nHonours and awards Fellow of the Royal Society of Chemistry, 2016 Books Tutorials in Molecular Reaction Dynamics. RSC Press, 2010. (Joint editor with Mark Brouard) Astrochemistry: from the Big Bang to the Present Day, World Scientific Press, 2017. An Introduction to Chemical Kinetics, Morgan-Claypool Publishing, 2017 An Introduction to the Gas Phase, Morgan-Claypool Publishing, 2018 References External links Living people Year of birth missing (living people) Fellows of Hertford College, Oxford Physical chemists New Zealand women chemists New Zealand pianists New Zealand women pianists New Zealand chemists New Zealand violinists 21st-century pianists 21st-century women musicians 21st-century violinists",
                    "score": 0.8638482689857483
                },
                {
                    "id": 1002189,
                    "contents": "Standard enthalpy of formation\nKey concepts for doing enthalpy calculations When a reaction is reversed, the magnitude of ΔH stays the same, but the sign changes. When the balanced equation for a reaction is multiplied by an integer, the corresponding value of ΔH must be multiplied by that integer as well. The change in enthalpy for a reaction can be calculated from the enthalpies of formation of the reactants and the products Elements in their standard states make no contribution to the enthalpy calculations for the reaction, since the enthalpy of an element in its standard state is zero. Allotropes of an element other than the standard state generally have non-zero standard enthalpies of formation. Examples: standard enthalpies of formation at 25 °C Thermochemical properties of selected substances at 298.15 K and 1 atm Inorganic substances Aliphatic hydrocarbons Other organic compounds See also Calorimetry Enthalpy Heat of combustion Thermochemistry References",
                    "score": 0.8634142875671387
                },
                {
                    "id": 12463859,
                    "contents": "Thomas Dale Stewart\nThomas Dale Stewart (August 14, 1890 – February 6, 1958) was an American chemist. He was born at Sumner, Washington, and received his Ph.D. degree in chemistry from University of California at Berkeley in 1916. After one year of research at University of Chicago under Julius Stieglitz, he returned to Berkeley as an instructor in the chemistry department, and became a professor there in 1935. His early research was about the mechanism of electron conduction in metals. The collaborative work with Richard C. Tolman led to the discovery of Stewart–Tolman effect. Later he worked on acid-base equilibria of organic nitrogen compounds, as well as reaction kinetics. References Thomas Dale Stewart, University of California: In Memoriam, 1959, accessed 06-21-2007. 20th-century American physicists 1890 births 1958 deaths People from Sumner, Washington University of California, Berkeley alumni UC Berkeley College of Chemistry faculty",
                    "score": 0.8617252707481384
                },
                {
                    "id": 13120029,
                    "contents": "Max Bodenstein\napproximation neglects the variations in the concentrations of reaction intermediates by assuming that these will remain quasi-constant. These reactive intermediates can be radicals, carbenium ions, molecules in the excited state, etc.",
                    "score": 0.8600850105285645
                },
                {
                    "id": 17890042,
                    "contents": "Butler–Volmer equation\nThe figure above plots various Gibbs energy curves as a function of the reaction coordinate ξ. The reaction coordinate is roughly a measure of distance, with the body of the electrode being on the left, the bulk solution being on the right. The blue energy curve shows the increase in Gibbs energy for an oxidized molecule as it moves closer to the surface of the electrode when no potential is applied. The black energy curve shows the increase in Gibbs energy as a reduced molecule moves closer to the electrode. The two energy curves intersect at . Applying a potential E to the electrode will move the energy curve downward (to the red curve) by nFE and the intersection point will move to . and are the activation energies (energy barriers) to be overcome by the oxidized and reduced species respectively for a general E, while and are the activation energies for E=0. Assume that the rate constants are well approximated by an Arrhenius equation,",
                    "score": 0.8600582480430603
                },
                {
                    "id": 13072844,
                    "contents": "Energy profile (chemistry)\nWhile most reversible processes will have a reasonably small K of 103 or less, this is not a hard and fast rule, and a number of chemical processes require reversibility of even very favorable reactions. For instance, the reaction of an carboxylic acid with amines to form a salt takes place with K of 105–6, and at ordinary temperatures, this process is regarded as irreversible. Yet, with sufficient heating, the reverse reaction takes place to allow formation of the tetrahedral intermediate and, ultimately, amide and water. (For an extreme example requiring reversibility of a step with K > 1011, see demethylation.) A reaction can also be rendered irreversible if a subsequent, faster step takes place to consume the initial product(s), or a gas is evolved in an open system. Thus, there is no value of K that serves as a \"dividing line\" between reversible and irreversible processes. Instead, reversibility depends on timescale, temperature, the reaction conditions, and the overall",
                    "score": 0.8599886894226074
                },
                {
                    "id": 13082069,
                    "contents": "George E. Kimball\nDuring the summer of 1935, Kimball returned to Princeton, to work with Henry Eyring. After a year when Kimball taught physics at Hunter College, he became assistant professor at the Chemistry Department of Columbia University. One of his students during his early time at Columbia was Isaac Asimov, who remembered getting a zero from him in physical chemistry. During the years 1936–1941, Kimball published nine papers on reaction rates and electrochemical surface effects. He also developed and taught courses in quantum chemistry, and supervised graduate student research. In 1941 he was elected a Fellow of the American Physical Society. The book Quantum Chemistry written by Kimball, Henry Eyring and John Walter, was begun around 1934 and published in 1944. Although periodically occupied with other tasks from 1942, he became a full professor of chemistry at Columbia in 1947 and remained there until 1956.",
                    "score": 0.8596277236938477
                },
                {
                    "id": 4024960,
                    "contents": "List of important publications in chemistry\nDescription: The defining reference for electrochemistry, coupling thousands of electroanalytical methods with the theory behind them. Importance: A reference publication. Theoretical chemistry, quantum chemistry and computational chemistry Valence and the structure of atoms and molecules Gilbert N. Lewis New York, The Chemical Catalog Company, Inc., 1923. Description: Discusses ionic and covalent bonding (polar and non-polar). Importance: The book that introduced the modern concept of the covalent bond as the sharing of electron pairs, and tried to reconcile the chemist's empirical view of the atom with the physicist's and spectroscopist's quantum mechanical view. It could be considered a precursor to Pauling's books. Introduction to Quantum Mechanics with Applications to Chemistry Linus Pauling, E. Bright Wilson New York, London, McGraw-Hill book company, 1935. Description: A classic and excellent introduction to quantum mechanics.",
                    "score": 0.8591213226318359
                },
                {
                    "id": 11518169,
                    "contents": "Physical organic chemistry\nGeneral Peter Atkins & Julio de Paula, 2006, \"Physical chemistry,\" 8th Edn., New York, NY, USA:Macmillan, , see , accessed 21 June 2015. [E.g., see p. 422 for a group theoretical/symmetry description of atomic orbitals contributing to bonding in methane, CH4, and pp. 390f for estimation of π-electron binding energy for 1,3-butadiene by the Hückel method.] Thomas H. Lowry & Kathleen Schueller Richardson, 1987, Mechanism and Theory in Organic Chemistry, 3rd Edn., New York, NY, USA:Harper & Row, , see , accessed 20 June 2015. [The authoritative textbook on the subject, containing a number of appendices that provide technical details on molecular orbital theory, kinetic isotope effects, transition state theory, and radical chemistry.] Eric V. Anslyn & Dennis A. Dougherty, 2006, Modern Physical Organic Chemistry, Sausalito, Calif.: University Science Books, . [A modernized and streamlined treatment with an emphasis on applications and cross-disciplinary connections.]",
                    "score": 0.8582096099853516
                },
                {
                    "id": 1394453,
                    "contents": "Activation energy\nlinear dependence on T. For a one-step unimolecular process whose half-life at room temperature is about 2 hours, ΔG‡ is approximately 23 kcal/mol. This is also the roughly the magnitude of Ea for a reaction that proceeds over several hours at room temperature. Due to the relatively small magnitude of TΔS‡ and RT at ordinary temperatures for most reactions, in sloppy discourse, Ea, ΔG‡, and ΔH‡ are often conflated and all referred to as the \"activation energy\".",
                    "score": 0.8580899238586426
                },
                {
                    "id": 3941850,
                    "contents": "John Polanyi\nIn 1958, Polanyi married Anne Ferrar Davidson (1929–2013). He has two children – a daughter, Margaret, born in 1961 and a son, Michael, born in 1963. His daughter is a journalist, and his son is a political scientist who started his career as a physicist. Polanyi is currently married to portrait artist Brenda Bury. Outside his scientific and policy endeavours, Polanyi's interests include art, literature and poetry. He was an avid white water canoeist in his younger days, but has replaced that with walking and skiing. See also Chemical laser The Martians (scientists) References External links including the Nobel Lecture, 8 December 1986 Some Concepts in Reaction Dynamics",
                    "score": 0.8576570749282837
                },
                {
                    "id": 2204332,
                    "contents": "Standard enthalpy of reaction\n(work) If is only pressure–volume work, then at constant pressure Assuming that the change in state variables is due solely to a chemical reaction, we have As enthalpy or heat content is defined by , we have By convention, the enthalpy of each element in its standard state is assigned a value of zero. If pure preparations of compounds or ions are not possible, then special further conventions are defined. Regardless, if each reactant and product can be prepared in its respective standard state, then the contribution of each species is equal to its molar enthalpy of formation multiplied by its stoichiometric coefficient in the reaction, and the enthalpy of reaction at constant (standard) pressure and constant temperature (usually 298 K) may be written as As shown above, at constant pressure the heat of the reaction is exactly equal to the enthalpy change, , of the reacting system.",
                    "score": 0.8573074340820312
                },
                {
                    "id": 649065,
                    "contents": "Henry Eyring (chemist)\nA prolific writer, he authored more than 600 scientific articles, ten scientific books, and a few books on the subject of science and religion. He received the Wolf Prize in Chemistry in 1980 and the National Medal of Science in 1966 for developing the Absolute Rate Theory or Transition state theory of chemical reactions, one of the most important developments of 20th-century chemistry. Several other chemists later received the Nobel Prize for work based on it, and his failure to receive the Nobel was a matter of surprise to many. The Nobel Prize organization admitted that \"Strangely, Eyring never received a Nobel Prize\"; the Royal Swedish Academy of Sciences apparently did not understand Eyring's theory until it was too late to award him the Nobel. The academy awarded him the Berzelius Medal in 1977 as partial compensation. Sterling M. McMurrin believed Eyring should have received the Nobel Prize but was not awarded it because of his religion.",
                    "score": 0.857269823551178
                },
                {
                    "id": 9585822,
                    "contents": "Ronnie Bell\nOther publications include: Acid-Base Catalysis (1941) The Tunnel Effect in Chemistry (1980) References External links Kinetics in Solution 1907 births 1996 deaths People from Maidenhead English physical chemists Alumni of Balliol College, Oxford Fellows of Balliol College, Oxford Academics of the University of Stirling Fellows of the Royal Society Fellows of the Royal Society of Chemistry Fellows of the Royal Society of Edinburgh Foreign associates of the National Academy of Sciences",
                    "score": 0.856803297996521
                },
                {
                    "id": 1654422,
                    "contents": "Outline of chemistry\nHistory of chemical kinetics – history of the study of rates of chemical processes. History of chemical thermodynamics – history of the study of the interrelation of heat and work with chemical reactions or with physical changes of state within the confines of the laws of thermodynamics. History of electrochemistry – history of the branch of chemistry that studies chemical reactions which take place in a solution at the interface of an electron conductor (a metal or a semiconductor) and an ionic conductor (the electrolyte), and which involve electron transfer between the electrode and the electrolyte or species in solution. History of Femtochemistry – history of the Femtochemistry is the science that studies chemical reactions on extremely short timescales, approximately 10−15 seconds (one femtosecond, hence the name).",
                    "score": 0.8556580543518066
                },
                {
                    "id": 3933521,
                    "contents": "Ronald George Wreyford Norrish\nReferences External links including the Nobel Lecture, December 11, 1967 Some Fast Reactions in Gases Studied by Flash Photolysis and Kinetic Spectroscopy 1897 births 1978 deaths People from Cambridge People educated at The Perse School Alumni of Emmanuel College, Cambridge Fellows of Emmanuel College, Cambridge Nobel laureates in Chemistry British Nobel laureates English physical chemists World War I prisoners of war held by Germany Faraday Lecturers Fellows of the Royal Society English Nobel laureates British World War I prisoners of war",
                    "score": 0.8548439145088196
                },
                {
                    "id": 1644381,
                    "contents": "Chemical reaction\nSee also Chemical equation Chemical reaction Substrate Reagent Catalyst Product Chemical reaction model Chemist Chemistry Combustion Limiting reagent List of organic reactions Mass balance Microscopic reversibility Organic reaction Reaction progress kinetic analysis Reversible reaction References Bibliography Chemistry Change",
                    "score": 0.8547171950340271
                },
                {
                    "id": 1973046,
                    "contents": "Thermodynamic potential\nMost commonly one considers reactions at constant and , so the Gibbs free energy is the most useful potential in studies of chemical reactions. See also Coomber's relationship Notes References Further reading McGraw Hill Encyclopaedia of Physics (2nd Edition), C.B. Parker, 1994, Thermodynamics, From Concepts to Applications (2nd Edition), A. Shavit, C. Gutfinger, CRC Press (Taylor and Francis Group, USA), 2009, Chemical Thermodynamics, D.J.G. Ives, University Chemistry, Macdonald Technical and Scientific, 1971, Elements of Statistical Thermodynamics (2nd Edition), L.K. Nash, Principles of Chemistry, Addison-Wesley, 1974, Statistical Physics (2nd Edition), F. Mandl, Manchester Physics, John Wiley & Sons, 2008, External links Thermodynamic Potentials – Georgia State University Chemical Potential Energy: The 'Characteristic' vs the Concentration-Dependent Kind Thermodynamics Potentials Thermodynamic equations",
                    "score": 0.8545976877212524
                },
                {
                    "id": 17143161,
                    "contents": "Allen J. Bard\nBard has published more than 1000 peer-reviewed research papers, 88 book chapters and other publications, and has more than 30 patents. He has written three books: Chemical Equilibrium; Electrochemical Methods – Fundamentals and Applications, and Integrated Chemical Systems: A Chemical Approach to Nanotechnology. The title, Electrochemical Methods – Fundamentals and Applications, is the defining text on electrochemistry in English, and generally referred to as just \"Bard.\" He was the chief editor of the Journal of the American Chemical Society.",
                    "score": 0.8545711040496826
                },
                {
                    "id": 27743145,
                    "contents": "William H. Green\nGreen received an National Science Foundation fellowship to attend graduate school in physical chemistry at the University of California, Berkeley. At Berkeley, he did his PhD thesis under the supervision of C. Bradley Moore. For his thesis, he measured and analyzed the spectra of highly vibrationally excited molecules, and, with fellow student I-Chia Chen, he measured and interpreted the photofragment excitation spectra of ketene. The latter experiments were the first to very clearly demonstrate that the energy-resolved relative rates of formation of different product channels are quantized, as predicted by RRKM theory. This work attracted press attention, was the subject of an article in Annual Review of Physical Chemistry and is discussed in textbooks on unimolecular reaction rates. In 1996 Klippenstein and Allen used this data to validate Klippenstein's first-principles method of calculating rates for barrierless reactions.",
                    "score": 0.8541461825370789
                },
                {
                    "id": 9345630,
                    "contents": "The Journal of Chemical Physics\nThe Journal of Chemical Physics is a scientific journal published by the American Institute of Physics that carries research papers on chemical physics. Two volumes, each of 24 issues, are published annually. It was established in 1933 when Journal of Physical Chemistry editors refused to publish theoretical works. The editors have been: 2019-present: Tim Lian 2008–2018: Marsha I. Lester 2007–2008: Branka M. Ladanyi 1998–2007: Donald H. Levy 1983–1997: John C. Light 1960–1982: J. Willard Stout 1958–1959: Clyde A. Hutchison Jr. 1956–1957 (Acting): Joseph Edward Mayer 1953–1955: Clyde A. Hutchison Jr. 1942–1952: Joseph E. Mayer 1933–1941: Harold Urey",
                    "score": 0.8533146977424622
                },
                {
                    "id": 9271168,
                    "contents": "Richard Zare\n1974 – National Fresenius Award, Phi Lambda Upsilon 1976 – Member, National Academy of Sciences 1976 – Member, American Academy of Arts and Sciences 1979 – inaugural recipient of the Michael Polanyi Medal, Royal Society of Chemistry 1981 – Earle K. Plyler Prize 1983 – Spectroscopy Society of Pittsburgh Award 1983 – National Medal of Science 1985 – Irving Langmuir Award in Chemical Physics 1986 – Michelson-Morley Award 1986 – John Gamble Kirkwood Award, ACS New Haven Section, \"in recognition of his fundamental contributions in experimental and theoretical aspects of reaction dynamics.\" 1990 – Willard Gibbs Medal 1991 – Peter Debye Award 1991 – National Academy of Sciences Award in Chemical Sciences, \"For his pioneering laser-based techniques, deep insights, and seminal contributions, which have influenced every facet of chemical reaction dynamics.\" 1991 – Member, American Philosophical Society 1993 – Dannie Heineman Prize 1993 – The Harvey Prize",
                    "score": 0.8531342148780823
                },
                {
                    "id": 23127303,
                    "contents": "Vincenzo Aquilanti\nAcademies and memberships 1985–91 – Italian Chemical Society (President, Section Umbria, 1985–1991). 1995–98 – European Physical Society (deputy-chair, Atomic and Molecular Physics Division. 2005–10 – INTAS Council of Scientists, Bruxelles. Italian Physical Society. Italian Society of Logic and Philosophy of Science. Awards and honors In 2005 he was elected to the Accademia Nazionale delle Scienze detta dei XL and in 2009 to the Accademia Nazionale dei Lincei. In 2009 a special issue of the Journal of Physical Chemistry is dedicated to him by the American Chemical Society. He was awarded the 2014 R.B. Bernstein Medal in Stereodynamics. Publications ; Angew. Chem. 117, 2408–12 (2005). References External links Group of Theory and Experiments on Elementary Processes 1939 births Italian chemists University of Perugia faculty Sapienza University of Rome alumni Living people",
                    "score": 0.8526374101638794
                },
                {
                    "id": 15615350,
                    "contents": "Karl James Jalkanen\nHe is currently the Editor-in-Chief (EiC) for Current Physical Chemistry. He has also been guest editor for three special issues of Theoretical Chemistry Accounts, the P.J. Stephens Honorary Issue, volume 119, numbers 1-3, the January 2008 issue, with Dr. Gerard M. Jensen, Gilead Sciences, Inc., the Suhai Festschrift Honorary Issue, volume 125, numbers 3-6, the March 2010 issue, and the Akira Imamura Hononary Issue, volume 130, numbers 4-6, the December 2011 issue. He was guest editor with Dr. Gerard M. Jensen, Gilead Sciences, Inc. for the two issue Quantum Nanobiology and Biophysical Chemistry series in Current Physical Chemistry (CPC) that appeared as the January and April in 2013 in volume 3, issues 1 and 2",
                    "score": 0.8522437214851379
                },
                {
                    "id": 9271133,
                    "contents": "Frank Westheimer\nFrank Henry Westheimer (January 15, 1912 – April 14, 2007) was an American chemist. He taught at the University of Chicago from 1936 to 1954, and at Harvard University from 1953 to 1983, becoming the Morris Loeb Professor of Chemistry in 1960, and Professor Emeritus in 1983. The Westheimer medal was established in his honor in 2002. Westheimer did pioneering work in physical organic chemistry, applying techniques from physical to organic chemistry and integrating the two fields. He explored the mechanisms of chemical and enzymatic reactions, and made fundamental theoretical advances. Westheimer worked with John Gamble Kirkwood on the Bjerrum electrostatic analysis of carboxylic acids; with Joseph Edward Mayer on the calculation of molecular mechanics; explored the mechanisms of enzyme catalysis with Birgit Vennesland and determined the mechanisms of chromic acid oxidations and kinetic isotope effects.",
                    "score": 0.8522200584411621
                },
                {
                    "id": 13202357,
                    "contents": "Max Volmer\nPersonal Volmer married the physical chemist Lotte Pusch. Max and Lotte knew and socialized with the physicist Lise Meitner and the chemist Otto Hahn since the 1920s. Selected bibliography Articles O. Stern and M. Volmer Über die Abklingzeit der Fluoreszenz, Physik. Zeitschr. 20 183-188 (1919) as cited in Mehra and Rechenberg, Volume 1, Part 2, 2001, 849. T. Erdey-Grúz and M. Volmer Z. Phys. Chem. 150 (A) 203-213 (1930) Books Max Volmer, Kinetik der Phasenbildung (1939) Max Volmer, Zur Kinetik der Phasenbildung und der Elektrodenreaktionen. Acht Arbeiten. (Akademische Verlagsgesellschaft Geest & Portig K.-G., 1983) Max Volmer und L. Dunsch, Zur Kinetik der Phasenbildung und Elektrodenreaktion. Acht Arbeiten. (Deutsch Harri GmbH, 1983) See also Butler–Volmer equation Stern–Volmer equation and constant Notes",
                    "score": 0.8522127866744995
                },
                {
                    "id": 14216023,
                    "contents": "George Samuel Newth\nBibliography G. S. Newth, Elementary Inorganic Chemistry, Longmans, Green, and Co. (first published 1898). G. S. Newth, Smaller Chemical Analysis, Longmans, Green, and Co. (first published 1906) G. S. Newth, A Manual of Chemical Analysis: Qualitative and Quantitative, Longmans, Green, and Co. (1899) G. S. Newth, A Text-book of Inorganic Chemistry, Longmans, Green, and Co. (first published 1894) G. S. Newth, Chemical Lecture Experiments: Non-metallic Elements, Longmans, Green, and Co. (1922; first published in 1892) G. S. Newth: \"An apparatus for showing experiments with ozone\", Journal of the Chemical Society, Transactions 69, 1298–1299, Royal Society of Chemistry, 1896. G. S. Newth: \"Notes on partially miscible aqueous inorganic liquids\", J. Chem. Soc., Trans., 1900, 77, 775 - 778. G. S. Newth: \"A New Laboratory Process for Preparing Hydrobromic Acid\", Scientific American Supplement, No. 841, February 13, 1892.",
                    "score": 0.8521339297294617
                },
                {
                    "id": 10531865,
                    "contents": "Bema Hapothle\nIn chemistry, Bema Hapothle is an extended acronym for Bell–Marcus–Hammond–Polanyi–Thornton–Leffler, referring to the combined contribution of the theories of these chemists to the rationalization of changes in transition state structure to perturbations, such as change of reaction solvent. See also Hammond–Leffler postulate References Physical organic chemistry",
                    "score": 0.8518524169921875
                },
                {
                    "id": 20126688,
                    "contents": "Bates–Guggenheim Convention\nIn chemistry, the Bates–Guggenheim Convention refers to a conventional method based on the Debye–Hückel theory to determine pH standard values. References Physical chemistry",
                    "score": 0.8512682318687439
                },
                {
                    "id": 16135572,
                    "contents": "Swain–Lupton equation\nIn physical organic chemistry, the Swain–Lupton equation is a linear free energy relationship (LFER) that is used in the study of reaction mechanisms and in the development of quantitative structure activity relationships for organic compounds. It was developed by C. Gardner Swain and Elmer C. Lupton Jr. in 1968 as a refinement of the Hammett equation to include both field effects and resonance effects. Background In organic chemistry, the Hammett plot provides a means to assess substituent effects on a reaction equilibrium or rate using the Hammett equation (1): Hammett developed this equation from equilibrium constants from the dissociation of benzoic acid and derivatives (Fig. 1):",
                    "score": 0.8512131571769714
                },
                {
                    "id": 11242070,
                    "contents": "Timeline of chemistry\n1926Erwin Schrödinger proposes the Schrödinger equation, which provides a mathematical basis for the wave model of atomic structure. 1927Werner Heisenberg develops the uncertainty principle which, among other things, explains the mechanics of electron motion around the nucleus. 1927Fritz London and Walter Heitler apply quantum mechanics to explain covalent bonding in the hydrogen molecule, which marked the birth of quantum chemistry. 1929 Linus Pauling publishes Pauling's rules, which are key principles for the use of X-ray crystallography to deduce molecular structure. 1931Erich Hückel proposes Hückel's rule, which explains when a planar ring molecule will have aromatic properties. 1931Harold Urey discovers deuterium by fractionally distilling liquid hydrogen. 1932James Chadwick discovers the neutron. 1932–1934Linus Pauling and Robert Mulliken quantify electronegativity, devising the scales that now bear their names.",
                    "score": 0.8509174585342407
                },
                {
                    "id": 8789785,
                    "contents": "Briggs–Rauscher reaction\nReferences Name reactions Non-equilibrium thermodynamics Articles containing video clips Clock reactions",
                    "score": 0.8504686951637268
                },
                {
                    "id": 13072837,
                    "contents": "Energy profile (chemistry)\nDrawing a reaction coordinate diagram",
                    "score": 0.8503757119178772
                },
                {
                    "id": 11140584,
                    "contents": "Frank L. Lambert\nThe 2005 2nd Edition of \"Chemistry: The Molecular Science\" by Moore et al., on p. xiv states \"Revised Chapters 14 and 18 to more clearly present entropy as dispersal of energy (See Lambert F. L. J. Chem. Educ. 1999,76, 1385; 2002, 79, 187).\" The 2006 4th edition of \"Chemistry: The Molecular Nature of Matter and Change\" by Silberberg on p. xviii states \"Chapter 20 has been completely rewritten to reflect a new approach to the coverage of entropy. The vague notion of \"disorder\" (with analogies to macroscopic systems) has been replaced with the idea that entropy is related to the dispersal of a system’s energy and the freedom of motion of its particles.\" Silberberg thanks \"Frank Lambert of Occidental College for insightful advice and comments on the coverage of entropy\". In his \"Chemistry: A Molecular Approach\", Tro states on p. xxi \"Thanks also to Frank Lambert for helping us all to think more clearly about entropy and his review of the entropy sections of this book.\" His ideas were",
                    "score": 0.8503061532974243
                },
                {
                    "id": 19237203,
                    "contents": "Advances in Chemical Physics\nSince the first book in 1958 and until 2010, either Ilya Prigogine or Stuart A. Rice acted as series editor. Since 2011, the series editor is Aaron R. Dinner. External links References English-language journals Publications established in 1958 Wiley (publisher) academic journals Chemical physics journals Irregular journals",
                    "score": 0.8502732515335083
                },
                {
                    "id": 3550216,
                    "contents": "Reaction mechanism\nComputational chemistry methods can also be used to calculate potential energy surfaces for reactions and determine probable mechanisms. Molecularity Molecularity in chemistry is the number of colliding molecular entities that are involved in a single reaction step. A reaction step involving one molecular entity is called unimolecular. A reaction step involving two molecular entities is called bimolecular. A reaction step involving three molecular entities is called trimolecular or termolecular. In general, reaction steps involving more than three molecular entities do not occur, because is statistically improbable in terms of Maxwell distribution to find such transition state. See also Organic reactions by mechanism under Organic reaction Nucleophilic acyl substitution Neighbouring group participation Finkelstein reaction Lindemann mechanism Electrochemical reaction mechanism Nucleophilic abstraction References L.G.WADE,ORGANIC CHEMISTRY 7TH ED,2010",
                    "score": 0.850260317325592
                },
                {
                    "id": 21524490,
                    "contents": "Bell–Evans–Polanyi principle\nIn physical chemistry, the Evans–Polanyi principle (also referred to as the Bell–Evans–Polanyi principle, Brønsted–Evans–Polanyi principle, or Evans–Polanyi–Semenov principle) observes that the difference in activation energy between two reactions of the same family is proportional to the difference of their enthalpy of reaction. This relationship can be expressed as where is the activation energy of a reference reaction of the same class, is the enthalpy of reaction, characterizes the position of the transition state along the reaction coordinate (such that ). The Evans–Polanyi model is a linear energy relationship that serves as an efficient way to calculate activation energy of many reactions within a distinct family. The activation energy may be used to characterize the kinetic rate parameter of a given reaction through application of the Arrhenius equation.",
                    "score": 0.850148618221283
                },
                {
                    "id": 1336522,
                    "contents": "William Lipscomb\nThe source for this subsection, except as noted, is Lipscomb's autobiographical sketch. Education Lipscomb's high-school chemistry teacher, Frederick Jones, gave Lipscomb his college books on organic, analytical, and general chemistry, and asked only that Lipscomb take the examinations. During the class lectures, Lipscomb in the back of the classroom did research that he thought was original (but he later found was not): the preparation of hydrogen from sodium formate (or sodium oxalate) and sodium hydroxide. He took care to include gas analyses and to search for probable side reactions. Lipscomb later had a high-school physics course and took first prize in the state contest on that subject. He also became very interested in special relativity.",
                    "score": 0.8500211238861084
                },
                {
                    "id": 13566223,
                    "contents": "Enthalpy–entropy compensation\nIn this form, β has the dimension of temperature and is referred to as the isokinetic (or isoequilibrium) temperature. Alternately, the isokinetic (or isoequilibrium) temperature may be reached by observing that, if a linear relationship is found, then the difference between the ΔH‡'s for any closely related reactants will be related to the difference between ΔS‡'s for the same reactants: δΔH‡ = βδΔS‡ Using the Gibbs free-energy equation, δΔG‡ = (1 − T/β)δΔS‡ In both forms, it is apparent that the difference in Gibbs free-energies of activations (δΔG‡) will be zero when the temperature is at the isokinetic (or isoequilibrium) temperature and hence identical for all members of the reaction set at that temperature.",
                    "score": 0.8499756455421448
                },
                {
                    "id": 11519360,
                    "contents": "P. G. Ashmore\nBooks Principles of Chemical Equilibrium by P G Ashmore (Royal Institute of Chemistry, 1961) Catalysis and Inhibition of Chemical Reaction by P. G. Ashmore (Butterworths, 1963) Gas Kinetics and Energy Transfer: A Review of Chemical Literature by P. G. Ashmore and R. J. Donovan (Specialist Periodical Reports, 1978 Principles of Reaction Kinetics by P. G. Ashmore (Royal Society of Chemistry, 1973, revised editions 1979 and 1993) Editor From 1965 to 1972 he was joint editor of the periodical Combustion and Flame Family In 1943, Ashmore married Ann Elizabeth (Betty) Scott, and they had three sons and one daughter. References Combustion People at ucl.ac.uk Who's Who 2002 (A. & C. Black, 2002)",
                    "score": 0.8498467206954956
                },
                {
                    "id": 11502620,
                    "contents": "Willard Gibbs Award\nJack Halpern 1986 \"For major research contributions to chemistry which have advanced the understanding of chemical reactivity especially for systems that involve metal centers in the reaction steps. The central goal of his research has been to extend the knowledge of catalytic processes by providing a detailed description and fundamental understanding of the steps that make up a catalytic cycle and by devising new catalytic processes. He is the recognized leader in an important subfield of catalytic reaction in solution. His early major contributions were concerned with the reactions of dihydrogen in aqueous solution and its activation by metal ions. More recently, his interests have evolved toward understanding the reaction pathways and relative reactivities of organometallic complexes. His studies in this field are diverse and most of them are definitive. Several of his papers on the role that reactions of organometallic compounds play in catalysis are already regarded as",
                    "score": 0.8496120572090149
                },
                {
                    "id": 16914778,
                    "contents": "Arnold Eucken\nContributions Eucken made important contributions within physical and technical chemistry. He concentrated on specific heat at very low temperatures, the structure of liquids and electrolytic solutions, the molecular physics (rotation, oscillation), on deuterium and heavy water, on homogeneous and heterogeneous gas kinetics, catalysis, chemical engineering and chemical technology. Death Eucken killed himself in Seebruck on 16 June 1950. See also Eucken's law Spin isomers of hydrogen References 1884 births 1950 deaths Scientists from Jena People from Saxe-Weimar-Eisenach 20th-century German chemists 20th-century German physicists University of Göttingen faculty Suicides in Germany 1950 suicides",
                    "score": 0.8495331406593323
                },
                {
                    "id": 9362061,
                    "contents": "Hammett equation\nSee also Bell–Evans–Polanyi principle Craig plot Free-energy relationship pKa Quantitative structure–activity relationship References Further reading General Thomas H. Lowry & Kathleen Schueller Richardson, 1987, Mechanism and Theory in Organic Chemistry, 3rd Edn., New York, NY, US: Harper & Row, , see , accessed 20 June 2015. Francis A. Carey & Richard J. Sundberg, 2006, \"Title Advanced Organic Chemistry: Part A: Structure and Mechanisms,\" 4th Edn., New York, NY, US: Springer Science & Business Media, , see , accessed 19 June 2015. Michael B. Smith & Jerry March, 2007, \"March's Advanced Organic Chemistry: Reactions, Mechanisms, and Structure,\" 6th Ed., New York, NY, US: Wiley & Sons, , see , accessed 19 June 2015.",
                    "score": 0.8494777679443359
                },
                {
                    "id": 8789781,
                    "contents": "Briggs–Rauscher reaction\nChemical mechanism The detailed mechanism of this reaction is quite complex. Nevertheless, a good general explanation can be given. For best results, and to prevent side reactions that may interfere with the main reaction, the solutions are best prepared a short time before the reaction. If left undisturbed, or exposed to ultra-violet radiation the reactants can decompose or react with themselves, interfering with the process. The essential features of the system depend on two key processes (These processes each involve many reactions working together): A (\"non-radical process\"): The slow consumption of free iodine by the malonic acid substrate in the presence of iodate. This process involves the intermediate production of iodide ion. B (\"radical process\"): A fast auto-catalytic process involving manganese and free radical intermediates, which converts hydrogen peroxide and iodate to free iodine and oxygen. This process also can consume iodide up to a limiting rate.",
                    "score": 0.8494657874107361
                },
                {
                    "id": 2204339,
                    "contents": "Standard enthalpy of reaction\nFinally the reaction enthalpy may be estimated using bond energies for the bonds which are broken and formed in the reaction of interest. This method is only approximate, however, because a reported bond energy is only an average value for different molecules with bonds between the same elements. References Enthalpy Thermochemistry Thermodynamics pl:Standardowe molowe ciepło tworzenia",
                    "score": 0.8494332432746887
                },
                {
                    "id": 21524493,
                    "contents": "Bell–Evans–Polanyi principle\nPlugging equation into equation and rearranging gives the following: The constants in equation can be condensed into the common form of the Evans–Polanyi equation given above. See also Free-energy relationship Brønsted catalysis equation References Notes Enthalpy Thermochemistry",
                    "score": 0.849399745464325
                },
                {
                    "id": 16137944,
                    "contents": "Nobel Prize in Chemistry\nPrizes A Chemistry Nobel Prize laureate earns a gold medal, a diploma bearing a citation, and a sum of money. Nobel Prize medals The Nobel Prize medals, minted by Myntverket in Sweden and the Mint of Norway since 1902, are registered trademarks of the Nobel Foundation. Each medal feature an image of Alfred Nobel in left profile on the obverse (front side of the medal). The Nobel Prize medals for Physics, Chemistry, Physiology or Medicine, and Literature have identical obverses, showing the image of Alfred Nobel and the years of his birth and death (1833–1896). Nobel's portrait also appears on the obverse of the Nobel Peace Prize medal and the Medal for the Prize in Economics, but with a slightly different design. The image on the reverse of a medal varies according to the institution awarding the prize. The reverse sides of the Nobel Prize medals for Chemistry and Physics share the same design.",
                    "score": 0.849335789680481
                },
                {
                    "id": 14283052,
                    "contents": "Keith J. Laidler\nLaidler was a Fellow of the Royal Society of Canada, who described him \"as one of the twentieth-century pioneers in the remarkable progress made in chemical kinetics leading to the development of transition state theory which provides the modern kinetic theory. Laidler's work includes seminal contributions in several areas of the field: gas phase reactions; kinetic aspects of reactivity of electronically excited molecules and construction of potential energy surfaces for such processes; development of treatments for kinetics and mechanisms for surface reactions and solution reactions, introducing modern concepts of solvation through dielectric polarization effects in the treatment of ionic redox reactions and of reactions producing or consuming ions; gas phase free-radical reactions involving pyrolysis and other thermal decomposition processes; and … the kinetics of enzyme-catalyzed reactions.\"",
                    "score": 0.8492406606674194
                },
                {
                    "id": 970277,
                    "contents": "Arrhenius equation\nAlternatively, the equation may be expressed as where is the activation energy for the reaction (in the same units as kBT), is the Boltzmann constant. The only difference is the energy units of : the former form uses energy per mole, which is common in chemistry, while the latter form uses energy per molecule directly, which is common in physics. The different units are accounted for in using either the gas constant, , or the Boltzmann constant, , as the multiplier of temperature .",
                    "score": 0.8492143750190735
                },
                {
                    "id": 8963379,
                    "contents": "Curtin–Hammett principle\nThe rate of formation for compound C from A is given as , and that of D from B as , with the second approximate equality following from the assumption of rapid equilibration. Under this assumption, the ratio of the products is then . In other words, because equilibration is fast compared to product formation, throughout the reaction. As a result, also remains roughly constant throughout the reaction. In turn, integration with respect to time implies that likewise takes on an approximately constant value through the course of the reaction, namely . In terms of the ground state and transition state energies, the product ratio can therefore be written as: . Importantly, inspection of the energy diagram above allows us to write , giving us a simplified equation that captures the essence of the Curtin-Hammett principle:",
                    "score": 0.8490825891494751
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_40",
        "question": "The vapour pressure of benzene is $53.3 \\mathrm{kPa}$ at $60.6^{\\circ} \\mathrm{C}$, but it fell to $51.5 \\mathrm{kPa}$ when $19.0 \\mathrm{~g}$ of an non-volatile organic compound was dissolved in $500 \\mathrm{~g}$ of benzene. Calculate the molar mass of the compound.",
        "golden_answers": [
            " 85"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 16874518,
                    "contents": "Reid vapor pressure\nReid vapor pressure (RVP) is a common measure of the volatility of gasoline and other petroleum products. It is defined as the absolute vapor pressure exerted by the vapor of the liquid and any dissolved gases/moisture at 37.8 °C (100 °F) as determined by the test method ASTM-D-323, which was first developed in 1930 and has been revised several times (the latest version is ASTM D323-15a). The test method measures the vapor pressure of gasoline, volatile crude oil, jet fuels, naphtha, and other volatile petroleum products but is not applicable for liquefied petroleum gases. ASTM D323-15a requires that the sample be chilled to 0 to 1 degrees Celsius and then poured into the apparatus; for any material that solidifies at this temperature, this step cannot be performed. RVP is commonly reported in kilopascals (kPa) or pounds per square inch (psi) and represents volatization at atmospheric pressure because ASTM-D-323 measures the gauge pressure of the sample in a non-evacuated chamber.",
                    "score": 0.8659206628799438
                },
                {
                    "id": 16874520,
                    "contents": "Reid vapor pressure\nThe Reid vapor pressure (RVP) can differ substantially from the true vapor pressure (TVP) of a liquid mixture, since (1) RVP is the vapor pressure measured at 37.8 °C (100 °F) and the TVP is a function of the temperature; (2) RVP is defined as being measured at a vapor-to-liquid ratio of 4:1, whereas the TVP of mixtures can depend on the actual vapor-to-liquid ratio; (3) RVP will include the pressure associated with the presence of dissolved water and air in the sample (which is excluded by some but not all definitions of TVP); and (4) the RVP method is applied to a sample which has had the opportunity to volatize somewhat prior to measurement: i.e., the sample container is required to be only 70-80% full of liquid (so that whatever volatizes into the container headspace is lost prior to analysis); the sample then again volatizes into the headspace of the D323 test chamber before it is heated to 37.8 degrees Celsius. See also Crude oil assay Gasoline volatility Vapor pressure",
                    "score": 0.8648526072502136
                },
                {
                    "id": 16547291,
                    "contents": "Benzene\nBenzene (also called cyclohexatriene) is an organic chemical compound with the molecular formula C6H6. The benzene molecule is composed of six carbon atoms joined in a planar ring with one hydrogen atom attached to each. Because it contains only carbon and hydrogen atoms, benzene is classed as a hydrocarbon. Benzene is a natural constituent of crude oil and is one of the elementary petrochemicals. Due to the cyclic continuous pi bonds between the carbon atoms, benzene is classed as an aromatic hydrocarbon. It is sometimes abbreviated PhH. Benzene is a colorless and highly flammable liquid with a sweet smell, and is partially responsible for the aroma around petrol (gasoline) stations. It is used primarily as a precursor to the manufacture of chemicals with more complex structure, such as ethylbenzene and cumene, of which billions of kilograms are produced annually. Although a major industrial chemical, benzene finds limited use in consumer items because of its toxicity. History",
                    "score": 0.8596282005310059
                },
                {
                    "id": 15556893,
                    "contents": "True vapor pressure\nTrue vapor pressure (TVP) is a common measure of the volatility of petroleum distillate fuels. It is defined as the equilibrium partial pressure exerted by a volatile organic liquid as a function of temperature as determined by the test method ASTM D 2879. The true vapor pressure (TVP) at 100 °F differs slightly from the Reid vapor pressure (RVP) (per definition also at 100 °F), as it excludes dissolved fixed gases such as air. Conversions between the two can be found in AP 42, Fifth Edition, Volume I Chapter 7: Liquid Storage Tanks (p 7.1-54 and onwards) References External links ASTM D2879 - 97(2007) Standard Test Method for Vapor Pressure-Temperature Relationship and Initial Decomposition Temperature of Liquids by Isoteniscope USA's Environmental Protection Agency (EPA) publication AP-42, Compilation of Air Pollutant Emissions. Chapter 7 Chemical properties Physical chemistry Engineering thermodynamics Natural gas Oil refining Petroleum production",
                    "score": 0.859320342540741
                },
                {
                    "id": 892659,
                    "contents": "Vapor pressure\nA simpler form of the equation with only two coefficients is sometimes used: which can be transformed to: Sublimations and vaporizations of the same substance have separate sets of Antoine coefficients, as do components in mixtures. Each parameter set for a specific compound is only applicable over a specified temperature range. Generally, temperature ranges are chosen to maintain the equation's accuracy of a few up to 8–10 percent. For many volatile substances, several different sets of parameters are available and used for different temperature ranges. The Antoine equation has poor accuracy with any single parameter set when used from a compound's melting point to its critical temperature. Accuracy is also usually poor when vapor pressure is under 10 Torr because of the limitations of the apparatus used to establish the Antoine parameter values.",
                    "score": 0.8563923239707947
                },
                {
                    "id": 1879017,
                    "contents": "Henry's law\nThe Kuenen coefficient S According to Sazonov and Shaw, the Kuenen coefficient is defined as \"the volume of saturating gas V(g), reduced to T° = 273.15 K, p° = bar, which is dissolved by unit mass of pure solvent at the temperature of measurement and partial pressure 1 bar.\" If the gas is ideal, the relation to is , where is the density of the solvent, and = 273.15 K. The SI unit for is m3/kg. The Kuenen coefficient, which is named after Johannes Kuenen, has been used mainly in the older literature, and IUPAC considers it to be obsolete. Henry's law volatility constants KH The Henry volatility defined via concentration (K) A common way to define a Henry volatility is dividing the partial pressure by the aqueous-phase concentration: The SI unit for is Pa·m3/mol. The Henry volatility defined via aqueous-phase mixing ratio (K) Another Henry volatility is The SI unit for is Pa. However, atm is still frequently used. The dimensionless Henry volatility K",
                    "score": 0.8534435033798218
                },
                {
                    "id": 1704092,
                    "contents": "Ethanol\nChemistry Chemical formula Ethanol is a 2-carbon alcohol. Its molecular formula is CH3CH2OH. An alternative notation is CH3−CH2−OH, which indicates that the carbon of a methyl group (CH3−) is attached to the carbon of a methylene group (−CH2–), which is attached to the oxygen of a hydroxyl group (−OH). It is a constitutional isomer of dimethyl ether. Ethanol is sometimes abbreviated as EtOH, using the common organic chemistry notation of representing the ethyl group (C2H5−) with Et. Physical properties Ethanol is a volatile, colorless liquid that has a slight odor. It burns with a smokeless blue flame that is not always visible in normal light. The physical properties of ethanol stem primarily from the presence of its hydroxyl group and the shortness of its carbon chain. Ethanol's hydroxyl group is able to participate in hydrogen bonding, rendering it more viscous and less volatile than less polar organic compounds of similar molecular weight, such as propane.",
                    "score": 0.8521455526351929
                },
                {
                    "id": 6679382,
                    "contents": "Eilhard Mitscherlich\nIn 1833 Mitscherlich made a series of careful determinations of the vapor densities of a large number of volatile substances, confirming the law of Gay-Lussac. In 1833–34, Mitscherlich investigated the synthesis of diethyl ether from ethanol and sulfuric acid. Through his careful studies, he realized that the acid was not being consumed during the production of the ether, although the reaction would not proceed unless the acid was present. After reviewing Mitscherlich's findings, Swedish chemist Jöns Jacob Berzelius was led to coin the term \"catalysis\" for the acceleration or enablement of a chemical reaction by a substance that itself was not consumed in the reaction. He obtained selenic acid in 1827 and showed that its salts are isomorphous with the sulphates, while a few years later he proved that the same thing is true of the manganates and the sulfates, and of the permanganates and the perchlorates. He investigated the relation of benzene to benzoic acid and to other",
                    "score": 0.8518020510673523
                },
                {
                    "id": 11848113,
                    "contents": "Victor Meyer apparatus\nThe Victor Meyer apparatus is the standard laboratory method for determining the molecular weight of a volatile liquid. It was developed by Viktor Meyer, who spelled his name Victor in publications at the time of its development. In this method, a known mass of a volatile solid or liquid under examination is converted into its vapour form by heating in a Victor Meyer's tube. The vapour displaces its own volume of air. The volume of air displaced at experimental temperature and pressure is calculated. Then volume of air displaced at Standard Temperature and Pressure is calculated. Using this, mass of air displaced at 2.24x10−2m3 of vapour at STP is calculated. This value represents the molecular mass of the substance.",
                    "score": 0.8516396284103394
                },
                {
                    "id": 1879024,
                    "contents": "Henry's law\nBy measuring the change in vapor pressure (and hence chemical potential) of the solvent, the chemical potential of the solute can be deduced. The standard state for a dilute solution is also defined in terms of infinite-dilution behavior. Although the standard concentration c° is taken to be 1 mol/l by convention, the standard state is a hypothetical solution of 1 mol/l in which the solute has its limiting infinite-dilution properties. This has the effect that all non-ideal behavior is described by the activity coefficient: the activity coefficient at 1 mol/l is not necessarily unity (and is frequently quite different from unity). All the relations above can also be expressed in terms of molalities b rather than concentrations, e.g.: where for a volatile solute; b° = 1 mol/kg. The standard chemical potential μm°, the activity coefficient γm and the Henry's law constant KH,b all have different numerical values when molalities are used in place of concentrations.",
                    "score": 0.850344181060791
                },
                {
                    "id": 1067643,
                    "contents": "James Dewar\nIn 1867 Dewar described several chemical formulas for benzene. One of the formulae, which does not represent benzene correctly and was not advocated by Dewar, is sometimes still called Dewar benzene. In 1869 he was elected a Fellow of the Royal Society of Edinburgh, his proposer being his former mentor, Lyon Playfair. His scientific work covers a wide field – his earlier papers cover topics including organic chemistry, hydrogen and its physical constants, high-temperature research, the temperature of the Sun and of the electric spark, spectrophotometry, and the chemistry of the electric arc.",
                    "score": 0.8503294587135315
                },
                {
                    "id": 1726299,
                    "contents": "August Kekulé\nThe empirical formula for benzene had been long known, but its highly unsaturated structure was a challenge to determine. Archibald Scott Couper in 1858 and Joseph Loschmidt in 1861 suggested possible structures that contained multiple double bonds or multiple rings, but the study of aromatic compounds was in its earliest years, and too little evidence was then available to help chemists decide on any particular structure.",
                    "score": 0.8492803573608398
                },
                {
                    "id": 1606618,
                    "contents": "Boiling point\nAs can be seen from the above plot of the logarithm of the vapor pressure vs. the temperature for any given pure chemical compound, its normal boiling point can serve as an indication of that compound's overall volatility. A given pure compound has only one normal boiling point, if any, and a compound's normal boiling point and melting point can serve as characteristic physical properties for that compound, listed in reference books. The higher a compound's normal boiling point, the less volatile that compound is overall, and conversely, the lower a compound's normal boiling point, the more volatile that compound is overall. Some compounds decompose at higher temperatures before reaching their normal boiling point, or sometimes even their melting point. For a stable compound, the boiling point ranges from its triple point to its critical point, depending on the external pressure. Beyond its triple point, a compound's normal boiling point, if any, is higher than its melting point.",
                    "score": 0.8491660356521606
                },
                {
                    "id": 6927875,
                    "contents": "Prismane\nHistory In the mid 19th century, investigators proposed several possible structures for benzene which were consistent with its empirical formula, C6H6, which had been determined by combustion analysis. The first, which was proposed by Kekulé in 1865, later proved to be closest to the true structure of benzene. This structure inspired several others to propose structures that were consistent with benzene's empirical formula; for example, Ladenburg proposed prismane, Dewar proposed Dewar benzene, and Koerner and Claus proposed Claus' benzene. Some of these structures would be synthesized in the following years. Prismane, like the other proposed structures for benzene, is still often cited in the literature, because it is part of the historical struggle toward understanding the mesomeric structures and resonance of benzene. Some computational chemists still research the differences between the possible isomers of C6H6.",
                    "score": 0.8482350707054138
                },
                {
                    "id": 1400113,
                    "contents": "Raoult's law\nWhere two volatile liquids A and B are mixed with each other to form a solution, the vapor phase consists of both components of the solution. Once the components in the solution have reached equilibrium, the total vapor pressure of the solution can be determined by combining Raoult's law with Dalton's law of partial pressures to give If a non-volatile solute B (zero vapor pressure, does not evaporate) is dissolved into a solvent A to form an ideal solution, the vapor pressure of the solution will be lower than that of the solvent. In an ideal solution of a nonvolatile solute, the decrease in vapor pressure is directly proportional to the mole fraction of solute: Principles",
                    "score": 0.8479255437850952
                },
                {
                    "id": 16547295,
                    "contents": "Benzene\nThe new understanding of benzene, and hence of all aromatic compounds, proved to be so important for both pure and applied chemistry that in 1890 the German Chemical Society organized an elaborate appreciation in Kekulé's honor, celebrating the twenty-fifth anniversary of his first benzene paper. Here Kekulé spoke of the creation of the theory. He said that he had discovered the ring shape of the benzene molecule after having a reverie or day-dream of a snake seizing its own tail (this is a common symbol in many ancient cultures known as the Ouroboros or Endless knot). This vision, he said, came to him after years of studying the nature of carbon-carbon bonds. This was 7 years after he had solved the problem of how carbon atoms could bond to up to four other atoms at the same time. Curiously, a similar, humorous depiction of benzene had appeared in 1886 in a pamphlet entitled Berichte der Durstigen Chemischen Gesellschaft (Journal of the Thirsty Chemical Society), a parody of the",
                    "score": 0.8464555740356445
                },
                {
                    "id": 6889511,
                    "contents": "Volatility (chemistry)\nVapor pressure Vapor pressure is a measurement of how readily a condensed phase forms a vapor at a given temperature. A substance enclosed in a sealed vessel initially at vacuum (no air inside) will quickly fill any empty space with vapor. After the system reaches equilibrium and no more vapor is formed, this vapor pressure can be measured. Increasing the temperature increases the amount of vapor that is formed and thus the vapor pressure. In a mixture, each substance contributes to the overall vapor pressure of the mixture, with more volatile compounds making a larger contribution. Boiling point Boiling point is the temperature at which the vapor pressure of a liquid is equal to the surrounding pressure, causing the liquid to rapidly evaporate, or boil. It is closely related to vapor pressure, but is dependent on pressure. The normal boiling point is the boiling point at atmospheric pressure, but it can also be reported at higher and lower pressures. Contributing factors",
                    "score": 0.8459857106208801
                },
                {
                    "id": 16547322,
                    "contents": "Benzene\na gas chromatograph. The measurement of benzene in humans can be accomplished via urine, blood, and breath tests; however, all of these have their limitations because benzene is rapidly metabolized in the human body.",
                    "score": 0.8450619578361511
                },
                {
                    "id": 1879025,
                    "contents": "Henry's law\nThe standard chemical potential μm°, the activity coefficient γm and the Henry's law constant KH,b all have different numerical values when molalities are used in place of concentrations. Solvent mixtures Henry's law solubility constant for a gas 2 in a mixture M of two solvents 1 and 3 depends on the individual constants for each solvent, and according to: Where , are the molar ratios of each solvent in the mixture and a13 is the interaction parameter of the solvents from Wohl expansion of the excess chemical potential of the ternary mixtures. A similar relationship can be found for the volatility constant , by remembering that and that, both being positive real numbers, , thus: For a water-ethanol mixture, the interaction parameter a13 has values around for ethanol concentrations (volume/volume) between 5% and 25% . Miscellaneous In geochemistry",
                    "score": 0.8439563512802124
                },
                {
                    "id": 22744101,
                    "contents": "DePriester chart\nDePriester Charts provide an efficient method to find the vapor-liquid equilibrium ratios for different substances at different conditions of pressure and temperature. The original chart was put forth by C.L. DePriester in an article in Chemical Engineering Progress in 1953. These nomograms have two vertical coordinates, one for pressure, and another for temperature. \"K\" values, representing the tendency of a given chemical species to partition itself preferentially between liquid and vapor phases, are plotted in between. Many DePriester charts have been printed for simple hydrocarbons. Example For example, to find the K value of methane at 100 psia and 60 °F. On the left-hand vertical axis, locate and mark the point containing the pressure 100 psia. On the right-hand vertical axis, locate and mark the point containing the temperature 60°F. Connect the points with a straight line. Note where the line crosses the methane axis. Read this K-value off the chart (approximately 21.3).",
                    "score": 0.8426467180252075
                },
                {
                    "id": 11242054,
                    "contents": "Timeline of chemistry\n1662Robert Boyle proposes Boyle's law, an experimentally based description of the behavior of gases, specifically the relationship between pressure and volume. 1735Swedish chemist Georg Brandt analyzes a dark blue pigment found in copper ore. Brandt demonstrated that the pigment contained a new element, later named cobalt. 1754Joseph Black isolates carbon dioxide, which he called \"fixed air\". 1757Louis Claude Cadet de Gassicourt, while investigating arsenic compounds, creates Cadet's fuming liquid, later discovered to be cacodyl oxide, considered to be the first synthetic organometallic compound. 1758Joseph Black formulates the concept of latent heat to explain the thermochemistry of phase changes. 1766Henry Cavendish discovers hydrogen as a colorless, odourless gas that burns and can form an explosive mixture with air. 1773–1774 Carl Wilhelm Scheele and Joseph Priestley independently isolate oxygen, called by Priestley \"dephlogisticated air\" and Scheele \"fire air\".",
                    "score": 0.8425219655036926
                },
                {
                    "id": 892660,
                    "contents": "Vapor pressure\nThe Wagner equation gives \"one of the best\" fits to experimental data but is quite complex. It expresses reduced vapor pressure as a function of reduced temperature. Relation to boiling point of liquids As a general trend, vapor pressures of liquids at ambient temperatures increase with decreasing boiling points. This is illustrated in the vapor pressure chart (see right) that shows graphs of the vapor pressures versus temperatures for a variety of liquids. At the normal boiling point of a liquid, the vapor pressure is equal to the standard atmospheric pressure defined as 1 atmosphere, 760Torr, 101.325kPa, or 14.69595psi. For example, at any given temperature, methyl chloride has the highest vapor pressure of any of the liquids in the chart. It also has the lowest normal boiling point (−24.2 °C), which is where the vapor pressure curve of methyl chloride (the blue line) intersects the horizontal pressure line of one atmosphere (atm) of absolute vapor pressure.",
                    "score": 0.8421764373779297
                },
                {
                    "id": 1039016,
                    "contents": "Volumetric heat capacity\nFor most liquids, the volumetric heat capacity is narrower, for example octane at 1.64 MJ⋅K−1⋅m−3 or ethanol at 1.9. This reflects the modest loss of degrees of freedom for particles in liquids as compared with solids. However, water has a very high volumetric heat capacity, at 4.18 MJ⋅K−1⋅m−3, and ammonia is also fairly high: 3.3 MJ⋅K−1⋅m−3.",
                    "score": 0.8418349027633667
                },
                {
                    "id": 1606622,
                    "contents": "Boiling point\nMost volatile compounds (anywhere near ambient temperatures) go through an intermediate liquid phase while warming up from a solid phase to eventually transform to a vapor phase. By comparison to boiling, a sublimation is a physical transformation in which a solid turns directly into vapor, which happens in a few select cases such as with carbon dioxide at atmospheric pressure. For such compounds, a sublimation point is a temperature at which a solid turning directly into vapor has a vapor pressure equal to the external pressure.",
                    "score": 0.8413366675376892
                },
                {
                    "id": 15912396,
                    "contents": "Benzenehexol\nBenzenehexol, also called hexahydroxybenzene, is an organic compound with formula C6H6O6 or C6(OH)6. It is a six-fold phenol of benzene. The product is also called hexaphenol, but this name has been used also for other substances. Benzenehexol is a crystalline solid soluble in hot water, with a melting point above 310°. It can be prepared from inositol (cyclohexanehexol). Oxidation of benzenehexol yields tetrahydroxy-p-benzoquinone (THBQ), rhodizonic acid, and dodecahydroxycyclohexane. Conversely, benzenehexol can be obtained by reduction of sodium THBQ salt with SnCl2/HCl. Benzenehexol is a starting material for a class of discotic liquid crystals. Benzenehexol forms an adduct with 2,2'-bipyridine, with 1:2 molecular ratio.",
                    "score": 0.840732216835022
                },
                {
                    "id": 1002179,
                    "contents": "Standard enthalpy of formation\nThe standard enthalpy of formation or standard heat of formation of a compound is the change of enthalpy during the formation of 1 mole of the substance from its constituent elements, with all substances in their standard states. The standard pressure value p⦵ = 105 Pa (= 100 kPa = 1 bar) is recommended by IUPAC, although prior to 1982 the value 1.00 atm (101.325 kPa) was used. There is no standard temperature. Its symbol is ΔfH⦵. The superscript Plimsoll on this symbol indicates that the process has occurred under standard conditions at the specified temperature (usually 25 °C or 298.15 K). Standard states are as follows: For a gas: the hypothetical state it would have assuming it obeyed the ideal gas equation at a pressure of 1 bar For a gaseous or solid solute present in a diluted ideal solution: the hypothetical state of concentration of the solute of exactly one mole per liter (1 M) at a pressure of 1 bar extrapolated from infinite dilution",
                    "score": 0.8399880528450012
                },
                {
                    "id": 16547298,
                    "contents": "Benzene\nNomenclature The German chemist Wilhelm Körner suggested the prefixes ortho-, meta-, para- to distinguish di-substituted benzene derivatives in 1867; however, he did not use the prefixes to distinguish the relative positions of the substituents on a benzene ring. It was the German chemist Karl Gräbe who, in 1869, first used the prefixes ortho-, meta-, para- to denote specific relative locations of the substituents on a di-substituted aromatic ring (viz, naphthalene). In 1870, the German chemist Viktor Meyer first applied Gräbe's nomenclature to benzene. Early applications In the 19th and early 20th centuries, benzene was used as an after-shave lotion because of its pleasant smell. Prior to the 1920s, benzene was frequently used as an industrial solvent, especially for degreasing metal. As its toxicity became obvious, benzene was supplanted by other solvents, especially toluene (methylbenzene), which has similar physical properties but is not as carcinogenic.",
                    "score": 0.8395188450813293
                },
                {
                    "id": 3003947,
                    "contents": "Ideal solution\nThis definition depends on vapor pressure, which is a directly measurable property, at least for volatile components. The thermodynamic properties may then be obtained from the chemical potential μ (which is the partial molar Gibbs energy g) of each component. If the vapor is an ideal gas, The reference pressure may be taken as = 1 bar, or as the pressure of the mix, whichever is simpler. On substituting the value of from Raoult's law, This equation for the chemical potential can be used as an alternate definition for an ideal solution. However, the vapor above the solution may not actually behave as a mixture of ideal gases. Some authors therefore define an ideal solution as one for which each component obeys the fugacity analogue of Raoult's law . Here is the fugacity of component in solution and is the fugacity of as a pure substance. Since the fugacity is defined by the equation",
                    "score": 0.839444100856781
                },
                {
                    "id": 13108797,
                    "contents": "Ethyl phenyl ether\nEthyl phenyl ether or phenetole is an organic compound that is an ether. Ethyl phenyl ether has the same properties as some other ethers, such as volatility, explosive vapors, and the ability to form peroxides. It will dissolve in less polar solvents such as ethanol or ether, but not in polar solvents such as water. Preparation PhOH + NaOH —————> Ph–O–Na Ph–O–Na + Et2SO4 ——————> Ph–O–Et This reaction follows Sn2 path. See also Anisole Notes Additional references Organic Chemistry, Fessenden & Fessenden, 6th Edition, Ralph J. Fessenden et al. For Antoine constants: http://webbook.nist.gov/cgi/cbook.cgi?ID=C103731&Units=SI&Mask=4#ref-10 Phenol ethers Phenyl compounds",
                    "score": 0.8388780951499939
                },
                {
                    "id": 16874521,
                    "contents": "Reid vapor pressure\nSee also Crude oil assay Gasoline volatility Vapor pressure External links ASTM D323 - 06 Standard Test Method for Vapor Pressure of Petroleum Products (Reid Method) Reid Vapor Pressure Requirements for Ethanol Congressional Research Service USA's Environmental Protection Agency (EPA) publication AP-42, Compilation of Air Pollutant Emissions. Chapter 7 (RVP is a parameter in the estimation of petroleum tank evaporative losses) References Chemical properties Physical chemistry Engineering thermodynamics Natural gas Oil refining Petroleum production",
                    "score": 0.8381830453872681
                },
                {
                    "id": 1865939,
                    "contents": "Michael Faraday\nFaraday worked extensively in the field of chemistry, discovering chemical substances such as benzene (which he called bicarburet of hydrogen) and liquefying gases such as chlorine. The liquefying of gases helped to establish that gases are the vapours of liquids possessing a very low boiling point and gave a more solid basis to the concept of molecular aggregation. In 1820 Faraday reported the first synthesis of compounds made from carbon and chlorine, C2Cl6 and C2Cl4, and published his results the following year. Faraday also determined the composition of the chlorine clathrate hydrate, which had been discovered by Humphry Davy in 1810. Faraday is also responsible for discovering the laws of electrolysis, and for popularizing terminology such as anode, cathode, electrode, and ion, terms proposed in large part by William Whewell.",
                    "score": 0.8379906415939331
                },
                {
                    "id": 1704110,
                    "contents": "Ethanol\nAbsolute alcohol Absolute or anhydrous alcohol refers to ethanol with a low water content. There are various grades with maximum water contents ranging from 1% to a few parts per million (ppm). If azeotropic distillation is used to remove water, it will contain trace amounts of the material separation agent (e.g. benzene). Absolute alcohol is not intended for human consumption. Absolute ethanol is used as a solvent for laboratory and industrial applications, where water will react with other chemicals, and as fuel alcohol. Spectroscopic ethanol is an absolute ethanol with a low absorbance in ultraviolet and visible light, fit for use as a solvent in ultraviolet-visible spectroscopy. Pure ethanol is classed as 200 proof in the US, equivalent to 175 degrees proof in the UK system.",
                    "score": 0.8376193046569824
                },
                {
                    "id": 16547303,
                    "contents": "Benzene\nDerivatives of benzene occur sufficiently often as a component of organic molecules that the Unicode Consortium has allocated a symbol in the Miscellaneous Technical block with the code U+232C (⌬) to represent it with three double bonds, and U+23E3 (⏣) for a delocalized version. Benzene derivatives Many important chemical compounds are derived from benzene by replacing one or more of its hydrogen atoms with another functional group. Examples of simple benzene derivatives are phenol, toluene, and aniline, abbreviated PhOH, PhMe, and PhNH2, respectively. Linking benzene rings gives biphenyl, C6H5–C6H5. Further loss of hydrogen gives \"fused\" aromatic hydrocarbons, such as naphthalene, anthracene, phenanthrene, and pyrene. The limit of the fusion process is the hydrogen-free allotrope of carbon, graphite.",
                    "score": 0.8375164866447449
                },
                {
                    "id": 11242050,
                    "contents": "Timeline of chemistry\nc. 1220 Robert Grosseteste publishes several Aristotelian commentaries where he lays out an early framework for the scientific method. c 1250 The works of Taddeo Alderotti (1223–1296) describe a method for concentrating ethanol involving repeated fractional distillation through a water-cooled still, by which an ethanol purity of 90% could be obtained. c 1260 St Albertus Magnus discovers arsenic and silver nitrate. He also made one of the first references to sulfuric acid. c. 1267 Roger Bacon publishes Opus Maius, which among other things, proposes an early form of the scientific method, and contains results of his experiments with gunpowder.",
                    "score": 0.8373855352401733
                },
                {
                    "id": 3639477,
                    "contents": "Charles J. Pedersen\nDue to not being soluble in methanol, Pedersen then proceeded to treat the methanol with soluble sodium salts, to which the unknown substance became soluble, allowing him to conclude that the solubility was due to sodium ions instead of alkalinity. Since the behavior of this substance mirrored that of 2,3-benzo-1,4,7-trioxacyclononane, with twice the molecular-weight, the unknown molecule was then coined as dibenzo-18-crown-6, the first of the aromatic crown compounds discovered. Associations with other chemists",
                    "score": 0.836498498916626
                },
                {
                    "id": 18414042,
                    "contents": "Benzvalene\nBenzvalene is an organic compound and one of several isomers of benzene. It was first synthesized in 1971 by Thomas J. Katz et al. The 1971 synthesis consisted of treating cyclopentadiene with methyllithium in dimethyl ether and then with dichloromethane and methyllithium in diethyl ether at −45 °C. It can also be formed in low yield (along with fulvene and Dewar benzene) by irradiation of benzene at 237 to 254 nm. The hydrocarbon in solution was described as having an extremely foul odor. Due to the high steric strain present in benzvalene, the pure compound (~71 kcal/mol higher in energy than benzene) easily detonates, for example by scratching. The compound converts to benzene with a chemical half-life of approximately 10 days. This symmetry-forbidden transition is believed to take place through a diradical intermediate.",
                    "score": 0.8364580273628235
                },
                {
                    "id": 6465470,
                    "contents": "Carbon dioxide (data page)\nPhase diagram Liquid/vapor equilibrium thermodynamic data The table below gives thermodynamic data of liquid CO2 in equilibrium with its vapor at various temperatures. Heat content data, heat of vaporization, and entropy values are relative to the liquid state at 0 °C temperature and 3483 kPa pressure. To convert heat values to joules per mole values, multiply by 44.095 g/mol. To convert densities to moles per liter, multiply by 22.678 cm3 mol/(L·g). Data obtained from CRC Handbook of Chemistry and Physics, 44th ed. pages 2560–2561, except for critical temperature line (31.1 °C) and temperatures −30 °C and below, which are taken from Lange's Handbook of Chemistry, 10th ed. page 1463. Spectral data Notes References Carbon dioxide Chemical data pages Chemical data pages cleanup",
                    "score": 0.8360254168510437
                },
                {
                    "id": 11889480,
                    "contents": "Kopp's law\nKopp's law can refer to either of two relationships discovered by the German chemist Hermann Franz Moritz Kopp (1817–1892). Kopp found \"that the molecular heat capacity of a solid compound is the sum of the atomic heat capacities of the elements composing it; the elements having atomic heat capacities lower than those required by the Dulong–Petit law retain these lower values in their compounds.\" In studying organic compounds, Kopp found a regular relationship between boiling points and the number of CH2 groups present. Kopp–Neumann law The Kopp–Neumann law, named for Kopp and Franz Ernst Neumann, is a common approach for determining the specific heat C (in J·kg−1·K−1) of compounds using the following equation: , where N is the total number of compound constituents, and Ci and fi denote the specific heat and mass fraction of the i-th constituent. This law works surprisingly well at room-temperature conditions, but poorly at elevated temperatures. See also Rule of mixtures",
                    "score": 0.8358524441719055
                },
                {
                    "id": 7825193,
                    "contents": "Viktor Meyer\nViktor Meyer (8 September 18488 August 1897) was a German chemist and significant contributor to both organic and inorganic chemistry. He is best known for inventing an apparatus for determining vapour densities, the Viktor Meyer apparatus, and for discovering thiophene, a heterocyclic compound. He is sometimes referred to as Victor Meyer, a name used in some of his publications.",
                    "score": 0.8357040882110596
                },
                {
                    "id": 2450505,
                    "contents": "Charles's law\nDalton was the first to demonstrate that the law applied generally to all gases, and to the vapours of volatile liquids if the temperature was well above the boiling point. Gay-Lussac concurred. With measurements only at the two thermometric fixed points of water, Gay-Lussac was unable to show that the equation relating volume to temperature was a linear function. On mathematical grounds alone, Gay-Lussac's paper does not permit the assignment of any law stating the linear relation. Both Dalton's and Gay-Lussac's main conclusions can be expressed mathematically as:",
                    "score": 0.834624171257019
                },
                {
                    "id": 2708000,
                    "contents": "1825 in science\nChemistry Michael Faraday isolates benzene as Bicarburet of Hydrogen. Hans Christian Ørsted reduces aluminium chloride to produce metallic aluminium in an impure form. Friedrich Wöhler and Justus von Liebig perform the first confirmed discovery and explanation of isomers, earlier named by Berzelius. Working with cyanic acid and fulminic acid, they correctly deduce that isomerism is caused by differing arrangements of atoms within a molecular structure. Earth sciences July – Volcanic eruption of Mount Guntur in West Java. G. Poulett Scrope publishes Considerations on Volcanoes, the first systematic work on volcanology.",
                    "score": 0.8343931436538696
                },
                {
                    "id": 1316199,
                    "contents": "Vapor\nProperties Vapor refers to a gas phase at a temperature where the same substance can also exist in the liquid or solid state, below the critical temperature of the substance. (For example, water has a critical temperature of 374 °C (647 K), which is the highest temperature at which liquid water can exist.) If the vapor is in contact with a liquid or solid phase, the two phases will be in a state of equilibrium. The term gas refers to a compressible fluid phase. Fixed gases are gases for which no liquid or solid can form at the temperature of the gas, such as air at typical ambient temperatures. A liquid or solid does not have to boil to release a vapor. Vapor is responsible for the familiar processes of cloud formation and condensation. It is commonly employed to carry out the physical processes of distillation and headspace extraction from a liquid sample prior to gas chromatography.",
                    "score": 0.8341692686080933
                },
                {
                    "id": 1865668,
                    "contents": "Methanol\nMethanol, also known as methyl alcohol, amongst other names, is a chemical and the simplest alcohol, with the formula CH3OH (a methyl group linked to a hydroxyl group, often abbreviated MeOH). It is a light, volatile, colourless, flammable liquid with a distinctive alcoholic odour similar to that of ethanol (potable alcohol). A polar solvent, methanol acquired the name wood alcohol because it was once produced chiefly by the destructive distillation of wood. Today, methanol is mainly produced industrially by hydrogenation of carbon monoxide. Methanol consists of a methyl group linked to a polar hydroxyl group. With more than 20 million tons produced annually, it is used as a precursor to other commodity chemicals, including formaldehyde, acetic acid, methyl tert-butyl ether, methyl benzoate, anisole, peroxyacids, as well as a host of more specialised chemicals.",
                    "score": 0.8340014219284058
                },
                {
                    "id": 6720842,
                    "contents": "Hermann Franz Moritz Kopp\nAnother question to which he gave much attention was the connection of the boiling point of compounds, organic ones in particular, with their composition. In addition to these and other laborious researches, Kopp was a prolific writer. In 1843–1847 he published a comprehensive History of Chemistry, in four volumes, to which three supplements were added in 1869–1875. The Development of Chemistry in Recent Times appeared in 1871–1874, and in 1886 he published a work in two volumes on Alchemy in Ancient and Modern Times. Kopp, in studying heat capacities, found \"that the molecular heat capacity of a solid compound is the sum of the atomic heat capacities of the elements composing it; the elements having atomic heat capacities lower than those required by the law of Dulong and Petit retain these lower values in their compounds.\"",
                    "score": 0.8336633443832397
                },
                {
                    "id": 1383444,
                    "contents": "Enthalpy of vaporization\nThe enthalpy of vaporization (symbol ), also known as the (latent) heat of vaporization or heat of evaporation, is the amount of energy (enthalpy) that must be added to a liquid substance to transform a quantity of that substance into a gas. The enthalpy of vaporization is a function of the pressure at which that transformation takes place. The enthalpy of vaporization is often quoted for the normal boiling temperature of the substance. Although tabulated values are usually corrected to 298 K, that correction is often smaller than the uncertainty in the measured value.",
                    "score": 0.8336089849472046
                },
                {
                    "id": 5606453,
                    "contents": "History of chemistry\nIn 1865, August Kekulé, based partially on the work of Loschmidt and others, established the structure of benzene as a six carbon ring with alternating single and double bonds. Kekulé's novel proposal for benzene's cyclic structure was much contested but was never replaced by a superior theory. This theory provided the scientific basis for the dramatic expansion of the German chemical industry in the last third of the 19th century. Today, the large majority of known organic compounds are aromatic, and all of them contain at least one hexagonal benzene ring of the sort that Kekulé advocated. Kekulé is also famous for having clarified the nature of aromatic compounds, which are compounds based on the benzene molecule. In 1865, Adolf von Baeyer began work on indigo dye, a milestone in modern industrial organic chemistry which revolutionized the dye industry.",
                    "score": 0.833482563495636
                },
                {
                    "id": 14933565,
                    "contents": "Lee–Kesler method\nThe Lee–Kesler method allows the estimation of the saturated vapor pressure at a given temperature for all components for which the critical pressure Pc, the critical temperature Tc, and the acentric factor ω are known. Equations with (reduced pressure) and (reduced temperature). Typical errors The prediction error can be up to 10% for polar components and small pressures and the calculated pressure is typically too low. For pressures above 1 bar, that means, above the normal boiling point, the typical errors are below 2%. Example calculation For benzene with Tc = 562.12 K Pc = 4898 kPa Tb = 353.15 K ω = 0.2120 the following calculation for T=Tb results: Tr = 353.15 / 562.12 = 0.628247 f(0) = -3.167428 f(1) = -3.429560 Pr = exp( f(0) + ω f(1) ) = 0.020354 P = Pr * Pc = 99.69 kPa The correct result would be P = 101.325 kPa, the normal (atmospheric) pressure. The deviation is -1.63 kPa or -1.61 %.",
                    "score": 0.8333892822265625
                },
                {
                    "id": 7825196,
                    "contents": "Viktor Meyer\nAt the age of 23 on Baeyer's recommendation, Meyer was engaged by Fehling as his assistant at Stuttgart Polytechnic, but within a year he left to succeed Johannes Wislicenus at Zurich. There he remained for thirteen years, and it was during this period that he devised his well-known method for determining vapour densities, and carried out his experiments on the dissociation of the halogens. In 1882, on the death of Wilhelm Weith (1844–1881), professor of chemistry at Zurich University, he undertook to continue the lectures on benzene derivatives, and this led him to the discovery of thiophen. In 1885 he was chosen to succeed Hans Hübner (1837–1884) in the professorship of chemistry at Göttingen University, where stereo-chemical questions especially engaged his attention; and in 1889, on the resignation of his old master, Bunsen, he was appointed to the chair of chemistry in Heidelberg University. He died on 8 August 1897. Health and suicide",
                    "score": 0.833244800567627
                },
                {
                    "id": 17353901,
                    "contents": "Antoine equation\nUnits The coefficients of Antoine's equation are normally given in mmHg—even today where the SI is recommended and pascals are preferred. The usage of the pre-SI units has only historic reasons and originates directly from Antoine's original publication. It is however easy to convert the parameters to different pressure and temperature units. For switching from degrees Celsius to kelvin it is sufficient to subtract 273.15 from the C parameter. For switching from millimeters of mercury to pascals it is sufficient to add the common logarithm of the factor between both units to the A parameter: The parameters for °C and mmHg for ethanol A, 8.20417 B, 1642.89 C, 230.300 are converted for K and Pa to A, 10.32907 B, 1642.89 C, −42.85 The first example calculation with TB = 351.47 K becomes A similarly simple transformation can be used if the common logarithm should be exchanged by the natural logarithm. It is sufficient to multiply the A and B parameters by ln(10) = 2.302585.",
                    "score": 0.8329991698265076
                },
                {
                    "id": 11242062,
                    "contents": "Timeline of chemistry\n1864Cato Maximilian Guldberg and Peter Waage, building on Claude Louis Berthollet's ideas, proposed the law of mass action. 1865Johann Josef Loschmidt determines exact number of molecules in a mole, later named Avogadro's number. 1865Friedrich August Kekulé von Stradonitz, based partially on the work of Loschmidt and others, establishes structure of benzene as a six carbon ring with alternating single and double bonds. 1865Adolf von Baeyer begins work on indigo dye, a milestone in modern industrial organic chemistry which revolutionizes the dye industry. 1869Dmitri Mendeleev publishes the first modern periodic table, with the 66 known elements organized by atomic weights. The strength of his table was its ability to accurately predict the properties of as-yet unknown elements.",
                    "score": 0.8326762914657593
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_41",
        "question": "J.G. Dojahn, et al. (J. Phys. Chem. 100, 9649 (1996)) characterized the potential energy curves of the ground and electronic states of homonuclear diatomic halogen anions. The ground state of $\\mathrm{F}_2^{-}$is ${ }^2 \\sum_{\\mathrm{u}}^{+}$with a fundamental vibrational wavenumber of $450.0 \\mathrm{~cm}^{-1}$ and equilibrium internuclear distance of $190.0 \\mathrm{pm}$. The first two excited states are at 1.609 and $1.702 \\mathrm{eV}$ above the ground state. Compute the standard molar entropy of $\\mathrm{F}_2^{-}$at $298 \\mathrm{~K}$.",
        "golden_answers": [
            " 199.4"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 28703087,
                    "contents": "William H. Parker (physicist)\nParker earned a bachelor's degree from Allegheny College in 1963. He obtained MS and PhD degrees from the University of Pennsylvania. He then joined the faculty of the Department of Physics and Astronomy at UCI in 1967 and he has remained there for his entire career. He was a Sloan Research Fellow from 1968 to 1970. In collaboration with Donald N. Langenberg and Barry N. Taylor, Parker used the alternating current Josephson effect to precisely measure e/h, the ratio of the elementary charge (e) to Planck's constant (h). This ratio could then also be used to refine the value of other fundamental constants such as the fine-structure constant (α). The new measurement of α removed a discrepancy between the theoretical and experimental values of the hyperfine splitting in the ground state of atomic hydrogen, one of the major unsolved problems of quantum electrodynamics at time. For this research, Parker received the John Price Wetherill Medal from the Franklin Institute in 1975.",
                    "score": 0.8836348652839661
                },
                {
                    "id": 2616198,
                    "contents": "John C. Slater\nReturning in time to 1920, Slater had gone to Harvard to work for a Ph.D. with Percy Bridgman, who studied the behaviour of substances under very high pressures. Slater measured the compressibility of common salt and ten other alkali halides—compounds of lithium, sodium, potassium and rubidium, with fluorine, chlorine and bromine. He described the results as \"exactly in accord with Bohr's recent views of the relation between electron structure and the periodic table\". This brought Slater's observation concerning the mechanical properties of ionic crystals into line with the theory that Bohr had based on the spectroscopy of gaseous elements. He wrote the alkali halide paper in 1923, having \"by the summer of 1922\" been \"thoroughly indoctrinated ... with quantum theory\", in part by the courses of Edwin Kemble following a fascination with Bohr's work during his undergraduate days. In 1924, Slater went to Europe on a Harvard Sheldon Fellowship. After a brief stay at the University of",
                    "score": 0.873088002204895
                },
                {
                    "id": 1402323,
                    "contents": "Robert S. Mulliken\nUp to this point, the primary way to calculate the electronic structure of molecules was based on a calculation by Walter Heitler and Fritz London on the hydrogen molecule (H2) in 1927. With the conception of hybridized atomic orbitals by John C. Slater and Linus Pauling, which rationalized observed molecular geometries, the method was based on the premise that the bonds in any molecule could be described in a manner similar to the bond in H2, namely, as overlapping atomic orbitals centered on the atoms involved. Since it corresponded to chemists' ideas of localized bonds between pairs of atoms, this method (called the Valence-Bond (VB) or Heitler-London-Slater-Pauling (HLSP) method), was very popular. In attempting to calculate the properties of excited states (molecules that have been excited by an energy source), the VB method does not always work well. With its description of the electron wave functions in molecules as delocalized molecular orbitals that possess the same symmetry",
                    "score": 0.8730483055114746
                },
                {
                    "id": 12918912,
                    "contents": "Włodzimierz Kołos\nKołos is best known for his work on the theory of electron correlation in molecules. In 1958 he went the University of Chicago, at a time when powerful computers were first becoming available for scientific work. He developed a new computer program to solve the Schrödinger equation for the hydrogen molecule to unprecedented accuracy. In the early 1960s, Kołos and Wolniewicz published a number of pioneering papers on the potential energy curves of the hydrogen molecule, including several corrections to the Born–Oppenheimer approximation, including adiabatic, non-adiabatic, and relativistic terms. One result attracted particular attention: the calculated dissociation energy disagreed with the best experimental data then available, from Gerhard Herzberg’s group. A few years later Herzberg improved his experiment and obtained a new result that agreed with the theoretical prediction. This was the first time that quantum mechanical calculations on a molecule had proved more accurate than",
                    "score": 0.8727930784225464
                },
                {
                    "id": 29064169,
                    "contents": "Isaac B. Bersuker\nThere is quite a list of other theoretical chemistry, chemical physics, and quantum chemistry fields with a remarkable Bersuker's contribution. In a number of his seminal papers, Bersuker introduced and developed theoretical models of vibronic mechanisms in redox properties, electron-conformational effects, chemical reactivity, and catalysis. He is known for revealing the role of JTE and PJTE in the properties of mixed-valence compounds. In addition, he discovered the effect of coordination covalent bonding and the JTE in the \"plasticity effect\". Also, Bersuker worked out a quantum mechanics/molecular mechanics method of electronic structure calculations of large organometallic systems when there is charge transfer between the QM and MM parts. The name of Bersuker is associated with the semiempirical approach to relativistic electronic structure calculations and a method of estimating molecular-orbital parameters from Mossbauer spectra. In another series of publications, he created",
                    "score": 0.8720002174377441
                },
                {
                    "id": 25760219,
                    "contents": "Carol Jane Anger Rieke\nScientific publications by Rieke included \"A study of the spectrum of alpha2 Canum Venaticorum\" (Astrophysical Journal 1929), \"Wave-Length Standards in the Extreme Ultraviolet\" (Phys. Rev. 1936, with Kenneth R. More), \"Molecular electronic spectra, dispersion and polarization: The theoretical interpretation and computation of oscillator strengths and intensities\" (Reports on Progress in Physics 1940, with Mulliken), \"Hyperconjugation\" (Journal of the American Chemical Society 1941, with Mulliken and Weldon G. Brown), \"Bond Integrals and Spectra With an Analysis of Kynch and Penney's Paper on the Heat of Sublimation of Carbon\" (Rev. Mod. Phys. 1942, with Mulliken). Rieke served as an elected member of the Bremen Community High School District 228 Board of Education from 1957 to 1963, while her children were in school there. She was also involved in the League of Women Voters and the Girl Scouts in the Chicago suburbs, and active with the Harvard-Radcliffe Club of Chicago.",
                    "score": 0.8702684640884399
                },
                {
                    "id": 21584516,
                    "contents": "David A. Shirley\nShirley became a lecturer in chemistry at Berkeley in 1959, an assistant professor in 1960, an associate professor in 1964, and a full professor in 1967. The following year he became chairman of the Chemistry Department. He was a National Science Foundation fellow at Oxford University in 1966–67, and was awarded the United States Atomic Energy Commission's Ernest Orlando Lawrence Award in 1972. His early research was into low temperature physics, nuclear orientation, and hyperfine interactions, particularly the Mössbauer effect, and he was a pioneer of X-ray photoelectron spectroscopy.",
                    "score": 0.8702594041824341
                },
                {
                    "id": 75601,
                    "contents": "Dilithium\nIt has been observed that 1% (by mass) of lithium in the vapor phase is in the form of dilithium. Being the lightest stable neutral homonuclear diatomic molecule after H2, and the helium dimer, dilithium is an extremely important model system for studying fundamentals of physics, chemistry, and electronic structure theory. It is the most thoroughly characterized compound in terms of the accuracy and completeness of the empirical potential energy curves of its electronic states. Analytic empirical potential energy curves have been constructed for the X-state, a-state, A-state, c-state, B-state, 2d-state, l-state, E-state, and the F-state . The most reliable of these potential energy curves are of the Morse/Long-range variety (see entries in the table below).",
                    "score": 0.8692595958709717
                },
                {
                    "id": 2616202,
                    "contents": "John C. Slater\nIn his memoir, Morse wrote \"In addition to other notable papers ... on ... Hartree's self-consistent field, the quantum mechanical derivation of the Rydberg constant, and the best values of atomic shielding constants, he wrote a seminal paper on directing valency \" (what became known, later, as linear combination of atomic orbitals).",
                    "score": 0.8688737154006958
                },
                {
                    "id": 705202,
                    "contents": "Oganesson\nCalculations on the diatomic molecule showed a bonding interaction roughly equivalent to that calculated for , and a dissociation energy of 6 kJ/mol, roughly 4 times of that of . Most strikingly, it was calculated to have a bond length shorter than in by 0.16 Å, which would be indicative of a significant bonding interaction. On the other hand, the compound OgH+ exhibits a dissociation energy (in other words proton affinity of oganesson) that is smaller than that of RnH+.",
                    "score": 0.8682429194450378
                },
                {
                    "id": 9345633,
                    "contents": "The Journal of Chemical Physics\nH. J. C. Berendsen, J. P. M. Postma, W. F. Van Gunsteren et al, Molecular dynamics with coupling to an external bath, 81(8), 3684-3690 (1984), [15 826 citations] T. Darden, D. York, J. Pedersen, Particle mesh Ewald - An N log(N) method for Ewald sums in large Systems, 98(12), 10089-10092 (1993) [11 591 citations] P. J. Hay, W. R. Wadt, Ab initio effective core potentials for molecular calculations - Potentials for K to Au including the outermost core orbitals, 82(1), 299-310 (1985), [11 195 citations] R. F. Stewart, E. R. Davidson, W. T. Simpson, Coherent X-ray scattering for hydrogen atom in hydrogen molecule, 42(9), 3175 (1965) [10 346 citations] W. J. Hehre, R. Ditchfield, J. A. Pople, Self-consistent molecular-orbital methods. 12. Further extensions of Gaussian-type basis sets for use in molecular-orbital studies of organic molecules, 56(5), 2257 (1972) [10 279 citations]",
                    "score": 0.8661827445030212
                },
                {
                    "id": 8698640,
                    "contents": "Rydberg state\nMolecular Rydberg states Although the energy formula of Rydberg series is a result of hydrogen-like atom structure, Rydberg states are also present in molecules. Wave functions of high Rydberg states are very diffuse and span diameters that approach infinity. As a result, any isolated neutral molecule behaves like a hydrogen-like atom at the Rydberg limit. For molecules with multiple stable monovalent cations, multiple Rydberg series may exist. Because of the complexity of molecular spectra, low-lying Rydberg states of molecules are often mixed with valence states with similar energy and are thus not pure Rydberg states. See also Rydberg atom Rydberg matter Orbital state References Atomic Spectra and Atomic Structure, Gerhard Herzberg, Prentice-Hall, 1937. Atoms and Molecules, Martin Karplus and Richard N. Porter, Benjamin & Company, Inc., 1970.",
                    "score": 0.8661627769470215
                },
                {
                    "id": 19036033,
                    "contents": "Hund's cases\nThe selection rules for , and parity are valid as for cases (a) and (b), but there are no rules for and since these are not good quantum numbers for case (c). Case (d) In case (d), the rotational coupling between and is much stronger than the electrostatic coupling of to the internuclear axis. Thus we form by coupling and and the form by coupling and . The good quantum numbers in case (d) are , , , , and . Because is a good quantum number, the rotational energy is simply . Case (e) In case (e), we first form and then form by coupling and . This case is rare but has been observed. Rydberg states which converge to ionic states with spin–orbit coupling (such as 2Π) are best described as case (e). The good quantum numbers in case (e) are , , and . Because is once again a good quantum number, the rotational energy is . References Spectroscopy",
                    "score": 0.8661127090454102
                },
                {
                    "id": 4811444,
                    "contents": "Hypervalent molecule\nA software program for ab initio calculations, Gaussian 86, was used by Dieters and coworkers to compare tetracoordinated silicon and phosphorus to their pentacoordinate analogues. This ab initio approach is used as a supplement to determine why reactivity improves in nucleophilic reactions with pentacoordinated compounds. For silicon, the 6-31+G* basis set was used because of its pentacoordinated anionic character and for phosphorus, the 6-31G* basis set was used.",
                    "score": 0.8659103512763977
                },
                {
                    "id": 11126343,
                    "contents": "Marvin L. Cohen\nThe methods developed for the above studies are numerous. Some examples include the Empirical Pseudopotential Method, ab initio pseudopotentials, supercells for surfaces and localized configurations, a method for calculating the total energy of solids, the creation of an empirical formula used to obtain the bulk moduli of many semiconductors and insulators, and the development of a method for calculating electron-phonon interactions using Wannier functions. These approaches and others first developed for this research are now used worldwide. Selected journal articles Erratum: Erratum: Erratum: Selected books and book chapters M. L. Cohen, \"Superconductivity in low-carrier-density systems: Degenerate semiconductors,\" in Superconductivity, ed. R. D. Parks. New York: Marcel Dekker, Inc., 1969. p. 615.",
                    "score": 0.8659055233001709
                },
                {
                    "id": 8689256,
                    "contents": "Kendall Houk\nKendall Newcomb Houk is a Distinguished Research Professor in Organic Chemistry at the University of California, Los Angeles. His research group studies organic, organometallic, and biological reactions using the tools of computational chemistry. This work involves quantum mechanical calculations, often with density functional theory, and molecular dynamics, either quantum dynamics for small systems or force fields such as AMBER, for solution and protein simulations. Early life and education K. N. Houk was born in Nashville, Tennessee, in 1943. He received his A.B. (1964), M.S. (1966), and Ph.D. (1968) degrees at Harvard, working with R. A. Olofson as an undergraduate and R. B. Woodward as a graduate student in the area of experimental tests of orbital symmetry selection rules. In 1968, he joined the faculty at Louisiana State University, becoming Professor in 1976.",
                    "score": 0.8657011389732361
                },
                {
                    "id": 4178755,
                    "contents": "Nevil Sidgwick\nSidgwick became absorbed by the study of atomic structure and its importance in chemical bonding. He explained the bonding in coordination compounds (complexes), with a convincing account of the significance of the dative bond. Together with his students he demonstrated the existence and wide-ranging importance of the hydrogen bond. He was elected a Fellow of the Royal Society in 1922. In 1927, he proposed the inert pair effect which describes the stability of heavier p-block atoms in an oxidation state two less than the maximum. In 1940 his Bakerian lecture with Herbert Marcus Powell correlated molecular geometry with the number of valence electrons on a central atom. These ideas were later developed into the VSEPR theory by Gillespie and Nyholm.",
                    "score": 0.8653669953346252
                },
                {
                    "id": 11945098,
                    "contents": "Michelle Francl\nMichelle M. Francl is an American chemist. Francl is a professor of chemistry, and has taught physical chemistry, general chemistry and mathematical modeling at Bryn Mawr College since 1986. Francl is noted for developing new methodology in computational chemistry, including the 6-31G* basis set for Na to Ar and electrostatic potential charges. She received a Ph.D. from the University of California, Irvine in 1983 On a list of the 1000 most cited chemists, Francl is a member of the editorial board for the Journal of Molecular Graphics and Modelling, active in the American Chemical Society and the author of The Survival Guide for Physical Chemistry. In 1994, she was awarded the Christian R. and Mary F. Lindback Award by Bryn Mawr College for excellence in teaching. Francl's podcast, \"Introduction to Quantum Mechanics,\" broke into the iTunes Top 100 in October 2005. She also currently writes for Nature Chemistry.",
                    "score": 0.8650757670402527
                },
                {
                    "id": 17075854,
                    "contents": "Dihydrogen cation\nThe energies for the lowest discrete states are shown in the graph above. These can be obtained to within arbitrary accuracy using computer algebra from the generalized Lambert W function (see eq. (3) in that site and the reference of Scott, Aubert-Frécon, and Grotendorst) but were obtained initially by numerical means to within double precision by the most precise program available, namely ODKIL. The red solid lines are 2Σ states. The green dashed lines are 2Σ states. The blue dashed line is a 2Πu state and the pink dotted line is a 2Πg state. Note that although the generalized Lambert W function eigenvalue solutions supersede these asymptotic expansions, in practice, they are most useful near the bond length. These solutions are possible because the partial differential equation of the wave equation here separates into two coupled ordinary differential equations using prolate spheroidal coordinates.",
                    "score": 0.8644213080406189
                },
                {
                    "id": 8788304,
                    "contents": "Henry F. Schaefer III\nBiography Early life and education Schaefer was born in Grand Rapids, Michigan, and was educated in Syracuse, New York; Menlo Park, California; and East Grand Rapids, Michigan. He was awarded a B.S. degree in chemical physics by the Massachusetts Institute of Technology in 1966, where he had the opportunity to work with scientists including George Whitesides, John C. Slater, F. Albert Cotton, Richard C. Lord, and Walter R. Thorson. He then received a National Defense Education Act Fellowship which enabled him to earn a Ph.D. degree in chemical physics from Stanford University in 1969. At Stanford he worked with Frank E. Harris on ab initio electronic structure theory and quantum chemistry. For his Ph.D. thesis work, he examined the electronic structure of first-row atoms and the oxygen molecule. He published 12 articles in journals including Physical Review and Physical Review Letters prior to defending his dissertation.",
                    "score": 0.8641618490219116
                },
                {
                    "id": 1336535,
                    "contents": "William Lipscomb\nThe B10H16 structure (diagram at right) determined by Grimes, Wang, Lewin, and Lipscomb found a bond directly between two boron atoms without terminal hydrogens, a feature not previously seen in other boron hydrides. Lipscomb's group developed calculation methods, both empirical and from quantum mechanical theory. Calculations by these methods produced accurate Hartree–Fock self-consistent field (SCF) molecular orbitals and were used to study boranes and carboranes. The ethane barrier to rotation (diagram at left) was first calculated accurately by Pitzer and Lipscomb using the Hartree–Fock (SCF) method. Lipscomb's calculations continued to a detailed examination of partial bonding through \"... theoretical studies of multicentered chemical bonds including both delocalized and localized molecular orbitals.\" This included \"... proposed molecular orbital descriptions in which the bonding electrons are delocalized over the whole molecule.\"",
                    "score": 0.8639945387840271
                },
                {
                    "id": 636073,
                    "contents": "Dudley R. Herschbach\nHerschbach, D. R. & V. W. Laurie. \"Anharmonic Potential Constants and Their Dependence Upon Bond Length\", University of California, Lawrence Radiation Laboratory, Berkeley, United States Department of Energy (through predecessor agency the Atomic Energy Commission) (January 1961). Herschbach, D. R. \"Reactive Collisions in Crossed Molecular Beams\", University of California, Lawrence Radiation Laboratory, Berkeley, United States Department of Energy (through predecessor agency the Atomic Energy Commission) (February 1962). Laurie, V. W. & D. R. Herschbach. \"The Determination of Molecular Structure from Rotational Spectra\", Stanford University, University of California, Lawrence Radiation Laboratory, Berkeley, United States Department of Energy (through predecessor agency the Atomic Energy Commission) (July 1962).",
                    "score": 0.8625409603118896
                },
                {
                    "id": 1560652,
                    "contents": "Atom\nLater in the same year Henry Moseley provided additional experimental evidence in favor of Niels Bohr's theory. These results refined Ernest Rutherford's and Antonius van den Broek's model, which proposed that the atom contains in its nucleus a number of positive nuclear charges that is equal to its (atomic) number in the periodic table. Until these experiments, atomic number was not known to be a physical and experimental quantity. That it is equal to the atomic nuclear charge remains the accepted atomic model today.",
                    "score": 0.8621789216995239
                },
                {
                    "id": 14078250,
                    "contents": "Molecular Spectra and Molecular Structure IV. Constants of Diatomic Molecules\nMolecular Spectra and Molecular Structure IV. Constants of Diatomic Molecules, by K. P. Huber and Gerhard Herzberg (Van nostrand Reinhold company, New York, 1979, ), is a classic comprehensive multidisciplinary reference text contains a critical compilation of available data for all diatomic molecules and ions known at the time of publication - over 900 diatomic species in all - including electronic energies, vibrational and rotational constants, and observed transitions. Extensive footnotes discuss the reliability of these data and additional detailed informationon potential energy curves, spin-coupling constants, /\\-type doubling, perturbations between electronic states, hyperfine structure, rotational g factors, dipole moments, radiative lifetimes, oscillator strengths, dissociation energies and ionization potentials when available, and other aspects. Herzberg received the 1971 Nobel Prize in Chemistry; both authors are world-renowned highly respected scientists.",
                    "score": 0.8619997501373291
                },
                {
                    "id": 3941836,
                    "contents": "John Polanyi\nPolanyi's PhD studies at Manchester University focused on measuring the strengths of chemical bonds using thermal dissociation, building on Warhurst's graduate studies using a sodium flame apparatus to determine the likelihood that a collision between a sodium atom and another molecule would lead to a chemical reaction. For the majority of his career, Polanyi's research has focused on chemical dynamics, attempting to determine the mechanics of a chemical reaction, and the properties of chemical species in the transition state. While at the National Research Council (NRC), Polanyi evaluated transition state theory for its predictive powers, coming to the conclusion that the theory was flawed, largely due to a lack of knowledge about the forces at play in the transition state. Near the end of his stay at NRC, Polanyi worked in Gerhard Herzberg's lab, using spectroscopy to examine vibrational and rotational excitation in iodine molecules. During Polanyi's time at Princeton University, he",
                    "score": 0.8609792590141296
                },
                {
                    "id": 4966231,
                    "contents": "VSEPR theory\nSteric numbers of 7 or greater are possible, but are less common. The steric number of 7 occurs in iodine heptafluoride (IF7); the base geometry for a steric number of 7 is pentagonal bipyramidal. The most common geometry for a steric number of 8 is a square antiprismatic geometry. Examples of this include the octacyanomolybdate () and octafluorozirconate () anions. The nonahydridorhenate ion () in potassium nonahydridorhenate is a rare example of a compound with a steric number of 9, which has a tricapped trigonal prismatic geometry. Possible geometries for steric numbers of 10, 11, 12, or 14 are bicapped square antiprismatic (or bicapped dodecadeltahedral), octadecahedral, icosahedral, and bicapped hexagonal antiprismatic, respectively. No compounds with steric numbers this high involving monodentate ligands exist, and those involving multidentate ligands can often be analysed more simply as complexes with lower steric numbers when some multidentate ligands are treated as a unit.",
                    "score": 0.8605437278747559
                },
                {
                    "id": 21117003,
                    "contents": "Reed McNeil Izatt\nIzatt and his colleagues, James J. Christensen and John L. Oscarson constructed and used a variety of novel high precision calorimeters to study a number of host and guest chemical systems of both academic and commercial interest. Izatts thermodynamic results have been used in the development of macrocyclic and supramolecular chemistry, molecular recognition, heats of mixing, nucleic acid chemistry, metal cyanide chemistry,<ref>Izatt, R. et al Thermodynamics of metal cyanide co-ordination. Part VII. Log K, ΔHo, and ΔSo values for the interaction of CN− with Pd2+. ΔHo values for the interaction of Cl− and Br−with Pd2+. J. Chem Soc. (A) 1967 pp1304-1308.</ref> chemical separations, amino acid microspecies formation,Zhang, X. et al Thermodynamics of macroscopic and microscopic proton ionization from protonated 4-aminobenzoic acid in aqueous solution from 298.15 to 393.15 K. J. Phys. Chem. B 2000 vol 104 pp8598-8605. and high- temperature corrosion chemistry,Oscarson, J. et al A model",
                    "score": 0.8604861497879028
                },
                {
                    "id": 1216972,
                    "contents": "Roald Hoffmann\nScientific research Hoffmann's research and interests have been in the electronic structure of stable and unstable molecules, and in the study of transition states in reactions. He has investigated the structure and reactivity of both organic and inorganic molecules, and examined problems in organo-metallic and solid-state chemistry. Hoffman has developed semiempirical and nonempirical computational tools and methods such as the extended Hückel method which he proposed in 1963 for determining molecular orbitals.",
                    "score": 0.8599716424942017
                },
                {
                    "id": 2616203,
                    "contents": "John C. Slater\nIn further comments, John Van Vleck pays particular attention to (1) the 1925 study of the spectra of hydrogen and ionized helium, that J.V.V. considers one sentence short of proposing electron spin (which would have led to sharing a Nobel prize), and (2) what J.V.V. regards as Slater's greatest paper, that introduced the mathematical object now called the Slater determinant. \"These were some of the achievements (that led to his) election to the National Academy ... at ... thirty-one. He played a key role in lifting American theoretical physics to high international standing.\" Slater's doctoral students, during this time, included Nathan Rosen Ph.D. in 1932 for a theoretical study of the hydrogen molecule, and William Shockley Ph.D. 1936 for an energy band structure of sodium chloride, who later received a Nobel Prize for the discovery of the transistor.",
                    "score": 0.8597970008850098
                },
                {
                    "id": 11777115,
                    "contents": "Hydron (chemistry)\nThe unsolvated hydron (a completely free or \"naked\" hydrogen atomic nucleus) does not exist in the condensed (liquid or solid) phase. Although superacids are sometimes said to owe their extraordinary hydron-donating power to the presence of \"free hydrons\", such a statement is highly misleading: even for a source of \"free hydrons\" like , one of the superacidic cations present in the superacid fluoroantimonic acid (HF:SbF5), detachment of a free still comes at an enormous energetic penalty on the order of several hundred kcal/mol. This effectively rules out the possibility of the free hydron being present in solution, even as a fleeting intermediate. For this reason, in liquid strong acids, hydrons are believed to diffuse by sequential transfer from one molecule to the next along a network of hydrogen bonds through what is known as the Grotthuss mechanism.",
                    "score": 0.8594591021537781
                },
                {
                    "id": 1336531,
                    "contents": "William Lipscomb\nLipscomb's group did not propose or discover the three-center two-electron bond, nor did they develop formulas that give the proposed mechanism. In 1943, Longuet-Higgins, while still an undergraduate at Oxford, was the first to explain the structure and bonding of the boron hydrides. The paper reporting the work, written with his tutor R. P. Bell, also reviews the history of the subject beginning with the work of Dilthey. Shortly after, in 1947 and 1948, experimental spectroscopic work was performed by Price",
                    "score": 0.8594551086425781
                },
                {
                    "id": 4966225,
                    "contents": "VSEPR theory\nThe difference between lone pairs and bonding pairs may also be used to rationalize deviations from idealized geometries. For example, the H2O molecule has four electron pairs in its valence shell: two lone pairs and two bond pairs. The four electron pairs are spread so as to point roughly towards the apices of a tetrahedron. However, the bond angle between the two O–H bonds is only 104.5°, rather than the 109.5° of a regular tetrahedron, because the two lone pairs (whose density or probability envelopes lie closer to the oxygen nucleus) exert a greater mutual repulsion than the two bond pairs. A bond of higher bond order also exerts greater repulsion since the pi bond electrons contribute. For example in isobutylene, (H3C)2C=CH2, the H3C−C=C angle (124°) is larger than the H3C−C−CH3 angle (111.5°). However, in the carbonate ion, , all three C−O bonds are equivalent with angles of 120° due to resonance.",
                    "score": 0.8594297766685486
                },
                {
                    "id": 2434565,
                    "contents": "Periodic table (electron configurations)\nRn, 86, radon : 1s2 2s2 2p6 3s2 3p6 4s2 3d10 4p6 5s2 4d10 5p6 6s2 4f14 5d10 6p6 Og, 118, oganesson : 1s2 2s2 2p6 3s2 3p6 4s2 3d10 4p6 5s2 4d10 5p6 6s2 4f14 5d10 6p6 7s2 5f14 6d10 7p6 Note that these electron configurations are given for neutral atoms in the gas phase, which are not the same as the electron configurations for the same atoms in chemical environments. In many cases, multiple configurations are within a small range of energies and the small irregularities that arise in the d- and f-blocks are quite irrelevant chemically. The construction of the periodic table ignores these irregularities and is based on ideal electron configurations. Note the non-linear shell ordering, which comes about due to the different energies of smaller and larger shells.",
                    "score": 0.8592197895050049
                },
                {
                    "id": 11242067,
                    "contents": "Timeline of chemistry\n1909S. P. L. Sørensen invents the pH concept and develops methods for measuring acidity. 1911Antonius van den Broek proposes the idea that the elements on the periodic table are more properly organized by positive nuclear charge rather than atomic weight. 1911The first Solvay Conference is held in Brussels, bringing together most of the most prominent scientists of the day. Conferences in physics and chemistry continue to be held periodically to this day. 1911Ernest Rutherford, Hans Geiger, and Ernest Marsden perform the gold foil experiment, which proves the nuclear model of the atom, with a small, dense, positive nucleus surrounded by a diffuse electron cloud. 1912William Henry Bragg and William Lawrence Bragg propose Bragg's law and establish the field of X-ray crystallography, an important tool for elucidating the crystal structure of substances. 1912Peter Debye develops the concept of molecular dipole to describe asymmetric charge distribution in some molecules.",
                    "score": 0.8589596748352051
                },
                {
                    "id": 8358322,
                    "contents": "Ab initio quantum chemistry methods\nThe only difference is that the four-membered ring ground state is planar and not bent. The cis-mono-bridged and vinylidene-like isomers are present. Experimental work on these molecules is not easy, but matrix isolation spectroscopy of the products of the reaction of hydrogen atoms and silicon and aluminium surfaces has found the ground state ring structures and the cis-mono-bridged structures for Si2H2 and Al2H2. Theoretical predictions of the vibrational frequencies were crucial in understanding the experimental observations of the spectra of a mixture of compounds. This may appear to be an obscure area of chemistry, but the differences between carbon and silicon chemistry is always a lively question, as are the differences between group 13 and group 14 (mainly the B and C differences). The silicon and germanium compounds were the subject of a Journal of Chemical Education article.",
                    "score": 0.8587332963943481
                },
                {
                    "id": 6710530,
                    "contents": "Walter Heitler\nIn Zurich, with Fritz London, Heitler applied the new quantum mechanics to deal with the saturable, nondynamic forces of attraction and repulsion, i.e., exchange forces, of the hydrogen molecule. Their valence bond treatment of this problem, was a landmark in that it brought chemistry under quantum mechanics. Furthermore, their work greatly influenced chemistry through Linus Pauling, who had just received his doctorate and on a Guggenheim Fellowship visited Heitler and London in Zurich. Pauling spent much of his career studying the nature of the chemical bond. The application of quantum mechanics to chemistry would be a prominent theme in Heitler's career.",
                    "score": 0.85854172706604
                },
                {
                    "id": 29867190,
                    "contents": "Alexander Boldyrev\nSelected Publications “DVM-Xa Calculations on the Ionization Potentials of [MXk+1]- Complex Anions and the Electron Affinities of MXk+1 \"Superhalogens\"” G. L. Gutsev and A. I. Boldyrev, Chem. Phys., 56, 277, (1981). “DVM-Xa Calculations on the Electronic Structure of \"Superalkali\" Cations” G. L. Gutsev and A. I. Boldyrev, Chem. Phys. Lett., 92, 262 (1982). “Tetracoordinate Planar Carbon in the Al4C- Anion. A Combined Photoelectron Spectroscopy and Ab Initio Study.” X. Li, W. Chen, L. S. Wang, A. I. Boldyrev, and J. Simons, J. Am Chem. Soc., 121, 6033 (1999). “Observation of All-Metal Aromatic Molecules.” X. Li, A.E. Kuznetsov, H.-F. Zhang, A.I. Boldyrev, L. S. Wang, Science, 291, 859-861 (2001). “All-Metal Antiaromatic Molecule: Rectangular Al44- in the Li3Al4- Anion”, A.E. Kuznetsov, K.A. Birch, A.I. Boldyrev, X. Li, H.-J. Zhai, L. S. Wang, Science, 300, 622 (2003).",
                    "score": 0.8581527471542358
                },
                {
                    "id": 1402326,
                    "contents": "Robert S. Mulliken\nIn 1952 he began to apply quantum mechanics to the analysis of the reaction between Lewis acid and base molecules. (See Acid-base reaction theories.) He became Distinguished Professor of Physics and Chemistry in 1961 and continued in his studies of molecular structure and spectra, ranging from diatomic molecules to large complex aggregates. In 1981, Mulliken became a founding member of the World Cultural Council. In 1983, Mulliken received the Golden Plate Award of the American Academy of Achievement. He retired in 1985. His wife died in 1975. At the age of 90, Mulliken died of congestive heart failure at his daughter's home in Arlington, Virginia on October 31, 1986. His body was returned to Chicago for burial. See also Mulliken symbols Adiabatic electron transfer Bonding molecular orbital Delta bond Halogen bond Walsh diagram References External links",
                    "score": 0.8579474687576294
                },
                {
                    "id": 2616200,
                    "contents": "John C. Slater\nSlater joined the Harvard faculty on his return from Europe in 1925, then moved to MIT in 1930. His research papers covered many topics. A year by year selection, up to his switch to work relating to radar includes: 1924: the theoretical part of his Ph.D. work, the Bohr-Kramers-Slater (BKS) theory, 1925: widths of spectral lines; ideas that came very close to the electron spins principle, 1926 and 1927: explicit attention to electron spin, and to the Schrödinger equation; 1928: the Hartree self-consistent field, the Rydberg formula, 1929: the determinantal expression for an antisymmetric wave function, 1930: Slater type orbitals (STOs) and atomic shielding constants, 1931: linear combination of atomic orbitals, van der Waals forces (with Jack Kirkwood, as a Chemistry Research Associate). 1932 to 1935: atomic orbitals, metallic conduction, application of the Thomas–Fermi method to metals,",
                    "score": 0.8573974967002869
                },
                {
                    "id": 1640254,
                    "contents": "Chemical bond\nIn 1933, H. H. James and A. S. Coolidge carried out a calculation on the dihydrogen molecule that, unlike all previous calculation which used functions only of the distance of the electron from the atomic nucleus, used functions which also explicitly added the distance between the two electrons. With up to 13 adjustable parameters they obtained a result very close to the experimental result for the dissociation energy. Later extensions have used up to 54 parameters and gave excellent agreement with experiments. This calculation convinced the scientific community that quantum theory could give agreement with experiment. However this approach has none of the physical pictures of the valence bond and molecular orbital theories and is difficult to extend to larger molecules.",
                    "score": 0.8565764427185059
                },
                {
                    "id": 431662,
                    "contents": "Rydberg constant\nSince the Bohr model is not perfectly accurate, due to fine structure, hyperfine splitting, and other such effects, the Rydberg constant cannot be directly measured at very high accuracy from the atomic transition frequencies of hydrogen alone. Instead, the Rydberg constant is inferred from measurements of atomic transition frequencies in three different atoms (hydrogen, deuterium, and antiprotonic helium). Detailed theoretical calculations in the framework of quantum electrodynamics are used to account for the effects of finite nuclear mass, fine structure, hyperfine splitting, and so on. Finally, the value of is determined from the best fit of the measurements to the theory. Alternative expressions The Rydberg constant can also be expressed as in the following equations. and in energy units",
                    "score": 0.8565458059310913
                },
                {
                    "id": 25012637,
                    "contents": "Henryk Witek\nRepresentative publications Henryk A. Witek, Takahito Nakijima, Kimihiko Hirao, \"Relativistic and correlated all-electron calculations on the ground and excited states of AgH and AuH\", J. Chem. Phys. 113, 8015 (2000). Henryk A. Witek, Stephan Irle, Keiji Morokuma, \"Analytical second-order geometrical derivatives of energy for the self-consistent-charge density-functional tight-binding method\", J. Chem. Phys. 121, 5163 (2004). Su YT, Huang YH, Witek HA, Lee YP, \"Infrared absorption spectrum of the simplest Criegee intermediate CH2OO\", Science 340, 174 (2013).",
                    "score": 0.8565318584442139
                },
                {
                    "id": 996054,
                    "contents": "Hydronium\nA 2007 calculation of the enthalpies and free energies of the various hydrogen bonds around the hydronium cation in liquid protonated water at room temperature and a study of the proton hopping mechanism using molecular dynamics showed that the hydrogen-bonds around the hydronium ion (formed with the three water ligands in the first solvation shell of the hydronium) are quite strong compared to those of bulk water. A new model was proposed by Stoyanov based on infrared spectroscopy in which the proton exists as an ion. The positive charge is thus delocalized over 6 water molecules. Solid hydronium salts",
                    "score": 0.8564692139625549
                },
                {
                    "id": 13333115,
                    "contents": "Hydrogen-like atom\nNegative-energy solutions to Dirac's equation exist even in the absence of a Coulomb force exerted by a nucleus. Dirac hypothesized that we can consider almost all of these states to be already filled. If one of these negative-energy states is not filled, this manifests itself as though there is an electron which is repelled by a positively-charged nucleus. This prompted Dirac to hypothesize the existence of positively-charged electrons, and his prediction was confirmed with the discovery of the positron. Beyond Gordon's solution to the Dirac equation The Dirac equation with a simple Coulomb potential generated by a point-like non-magnetic nucleus was not the last word, and its predictions differ from experimental results as mentioned earlier. More accurate results include the Lamb shift (radiative corrections arising from quantum electrodynamics) and hyperfine structure. See also Rydberg atom Positronium Exotic atom Two-electron atom Hydrogen molecular ion Notes",
                    "score": 0.8562347888946533
                },
                {
                    "id": 16471308,
                    "contents": "Triatomic hydrogen\nThe molecule can only exist in an excited state. The different excited electronic states are represented by symbols for the outer electron nLΓ with n the principal quantum number, L is the electronic angular momentum, and Γ is the electronic symmetry selected from the D3h group. Extra bracketed symbols can be attached showing vibration in the core: {s,dl} with s representing symmetrical stretch, d degenerate mode, and l vibrational angular momentum. Yet another term can be inserted to indicate molecular rotation: (N,G) with N angular momentum apart from electrons as projected on the molecular axis, and G the Hougen's convenient quantum number determined by G=l+λ-K. This is often (1,0), as the rotational states are restricted by the constituent particles all being fermions. Examples of these states are: 2sA1' 3sA1' 2pA2\" 3dE' 3DE\" 3dA1' 3pE' 3pA2\". The 2p2A2\" state has a lifetime of 700 ns. If the molecule attempts to lose energy and go to the repulsive ground state, it spontaneously",
                    "score": 0.8560993671417236
                },
                {
                    "id": 12233812,
                    "contents": "Slater's rules\nprovides a reasonable approximation to a single-electron wave function. Slater defined n* by the rule that for n = 1, 2, 3, 4, 5, 6 respectively; n* = 1, 2, 3, 3.7, 4.0 and 4.2. This was an arbitrary adjustment to fit calculated atomic energies to experimental data. Such a form was inspired by the known wave function spectrum of hydrogen-like atoms which have the radial component where n is the (true) principal quantum number, l the azimuthal quantum number, and fnl(r) is an oscillatory polynomial with n - l - 1 nodes. Slater argued on the basis of previous calculations by Clarence Zener that the presence of radial nodes was not required to obtain a reasonable approximation. He also noted that in the asymptotic limit (far away from the nucleus), his approximate form coincides with the exact hydrogen-like wave function in the presence of a nuclear charge of Z-s and in the state with a principal quantum number n equal to his effective quantum number n*.",
                    "score": 0.8560434579849243
                },
                {
                    "id": 1753306,
                    "contents": "Hydrogen\nHydrogen is nonmetallic, except at extremely high pressures, and readily forms a single covalent bond with most nonmetallic elements, forming compounds such as water and nearly all organic compounds. Hydrogen plays a particularly important role in acid–base reactions because these reactions usually involve the exchange of protons between soluble molecules. In ionic compounds, hydrogen can take the form of a negative charge (i.e., anion) where it is known as a hydride, or as a positively charged (i.e., cation) species denoted by the symbol H+. The H+ cation is simply a proton (symbol p) but its behavior in aqueous solutions and in ionic compounds involves screening of its electric charge by nearby polar molecules or anions. Because hydrogen is the only neutral atom for which the Schrödinger equation can be solved analytically, the study of its energetics and chemical bonding has played a key role in the development of quantum mechanics.",
                    "score": 0.8559267520904541
                },
                {
                    "id": 29539478,
                    "contents": "John W. Birks\nSelected Publications Activation energies for the dissociation of diatomic molecules are less than the bond dissociation energies (1972) Effect of nuclear explosions on stratospheric nitric oxide and ozone (1973) Chemiluminescence of IF in the gas phase reaction of I2 with F2 Studies of reactions of importance in the stratosphere. I. Reaction of nitric oxide with ozone (1976) Studies of reactions of importance in the stratosphere. II. Reactions involving chlorine nitrate and chlorine dioxide (1980) Studies of reactions of importance in the stratosphere. III. Rate constant and products of the reaction between ClO and HO2 radicals at 298 K (1980) Studies of reactions of importance in the stratosphere. IV. Rate constant for the reaction Cl + HOCl → HCl + ClO over the temperature range 243-365 K (1981) The atmosphere after a nuclear war: Twilight at noon (1982)",
                    "score": 0.8557668328285217
                },
                {
                    "id": 4064318,
                    "contents": "Walter Kohn\nSelected publications W. Kohn, \"An essay on condensed matter physics in the twentieth century,\" Reviews of Modern Physics, Vol. 71, No. 2, pp. S59–S77, Centenary 1999. APS W. Kohn, \"Nobel Lecture: Electronic structure of matter — wave functions and density functionals,\" Reviews of Modern Physics, Vol. 71, No. 5, pp. 1253–1266 (1999). APS D. Jérome, T.M. Rice, and W. Kohn, \"Excitonic Insulator,\" Physical Review, Vol. 158, No. 2, pp. 462–475 (1967). APS P. Hohenberg, and W. Kohn, \"Inhomogeneous Electron Gas,\" Physical Review, Vol. 136, No. 3B, pp. B864–B871 (1964). APS W. Kohn, and L. J. Sham, \"Self-Consistent Equations Including Exchange and Correlation Effects,\" Physical Review, Vol. 140, No. 4A, pp. A1133–A1138 (1965). APS W. Kohn, and J. M. Luttinger, \"New Mechanism for Superconductivity,\" Physical Review Letters, Vol. 15, No. 12, pp. 524–526 (1965). APS W. Kohn, \"Theory of the Insulating State,\" Physical Review, Vol. 133, No. 1A, pp. A171–A181 (1964). APS",
                    "score": 0.8557298183441162
                },
                {
                    "id": 8788305,
                    "contents": "Henry F. Schaefer III\nCareer Schaefer became an assistant professor of chemistry at the University of California, Berkeley in 1969, with access to Berkeley's Control Data Corporation (CDC) 6600 mainframe computer. Through collaborations with other researchers, he also gained access to resources at the University Computing Company (UCC) in Palo Alto, which had a UNIVAC 1108. He worked at Berkeley from 1969 to 1987, with one exception. Schaefer spent 1979-1980 as the Wilfred T. Doherty Professor of Chemistry and inaugural Director of the Institute for Theoretical Chemistry at the University of Texas, Austin, before deciding to return to Berkeley. During his time at Berkeley, Schaefer published 375 papers and several books, including The Electronic Structure of Atoms and Molecules: A Survey of Rigorous Quantum Mechanical Results (1972) and Quantum Chemistry: The Development of Ab Initio Methods in Molecular Electronic Structure Theory (1984), a survey of research with commentary.",
                    "score": 0.8556777238845825
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_42",
        "question": "The duration of a $90^{\\circ}$ or $180^{\\circ}$ pulse depends on the strength of the $\\mathscr{B}_1$ field. If a $180^{\\circ}$ pulse requires $12.5 \\mu \\mathrm{s}$, what is the strength of the $\\mathscr{B}_1$ field? ",
        "golden_answers": [
            " 5.9"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 21994227,
                    "contents": "Tri-level sync\nWaveform The main pulse definition is as follows: a negative-going pulse of 300 mV lasting 40 sample clocks followed by a positive-going pulse of 300 mV lasting 40 sample clocks. The allowed rise/fall time for each of the transitions is 4 sample clocks. This is with a clock rate of 74.25 MHz. References Synchronization Film and video technology Broadcast engineering Television terminology",
                    "score": 0.8657182455062866
                },
                {
                    "id": 4887227,
                    "contents": "Ultrashort pulse\nThe 1999 Nobel Prize in Chemistry was awarded to Ahmed H. Zewail, for the use of ultrashort pulses to observe chemical reactions at the timescales on which they occur, opening up the field of femtochemistry. Definition There is no standard definition of ultrashort pulse. Usually the attribute 'ultrashort' applies to pulses with a duration of a few tens of femtoseconds, but in a larger sense any pulse which lasts less than a few picoseconds can be considered ultrashort. The distinction between \"Ultrashort\" and \"Ultrafast\" is necessary as the speed at which the pulse propagates is a function of the index of refraction of the medium through which it travels, whereas \"Ultrashort\" refers to the temporal width of the pulse wavepacket. A common example is a chirped Gaussian pulse, a wave whose field amplitude follows a Gaussian envelope and whose instantaneous phase has a frequency sweep.",
                    "score": 0.8632534742355347
                },
                {
                    "id": 1382633,
                    "contents": "Amplitude\nPulse amplitude In telecommunication, pulse amplitude is the magnitude of a pulse parameter, such as the voltage level, current level, field intensity, or power level. Pulse amplitude is measured with respect to a specified reference and therefore should be modified by qualifiers, such as average, instantaneous, peak, or root-mean-square. Pulse amplitude also applies to the amplitude of frequency- and phase-modulated waveform envelopes. Formal representation In this simple wave equation is the amplitude (or peak amplitude), is the oscillating variable, is angular frequency, is time, and are arbitrary constants representing time and displacement offsets respectively. Units The units of the amplitude depend on the type of wave, but are always in the same units as the oscillating variable. A more general representation of the wave equation is more complex, but the role of amplitude remains analogous to this simple case.",
                    "score": 0.8624064326286316
                },
                {
                    "id": 19718294,
                    "contents": "Pulse width\nThe pulse width is a measure of the elapsed time between the leading and trailing edges of a single pulse of energy. The measure is typically used with electrical signals and is widely used in the fields of radar and power supplies. There are two closely related measures. The pulse repetition interval measures the time between the leading edges of two pulses but is normally expressed as the pulse repetition frequency (PRF), the number of pulses in a given time, typically a second. The duty cycle expresses the pulse width as a fraction or percentage of one complete cycle.",
                    "score": 0.8620365262031555
                },
                {
                    "id": 21698235,
                    "contents": "Electromagnetic pulse\nGeneral characteristics An electromagnetic pulse is a short surge of electromagnetic energy. Its short duration means that it will be spread over a range of frequencies. Pulses are typically characterized by: The mode of energy transfer (radiated, electric, magnetic or conducted). The range or spectrum of frequencies present. Pulse waveform: shape, duration and amplitude. The last two of these, the frequency spectrum and the pulse waveform, are interrelated via the Fourier transform which describes how component waveforms may sum to the observed frequency spectrum. Types of energy EMP energy may be transferred in any of four forms: Electric field Magnetic field Electromagnetic radiation Electrical conduction According to Maxwell's equations, a pulse of electric energy will always be accompanied by a pulse of magnetic energy. In a typical pulse, either the electric or the magnetic form will dominate.",
                    "score": 0.8590662479400635
                },
                {
                    "id": 4887228,
                    "contents": "Ultrashort pulse\nA common example is a chirped Gaussian pulse, a wave whose field amplitude follows a Gaussian envelope and whose instantaneous phase has a frequency sweep. Background The real electric field corresponding to an ultrashort pulse is oscillating at an angular frequency ω0 corresponding to the central wavelength of the pulse. To facilitate calculations, a complex field E(t) is defined. Formally, it is defined as the analytic signal corresponding to the real field. The central angular frequency ω0 is usually explicitly written in the complex field, which may be separated as a temporal intensity function I(t) and a temporal phase function ψ(t): The expression of the complex electric field in the frequency domain is obtained from the Fourier transform of E(t): Because of the presence of the term, E(ω) is centered around ω0, and it is a common practice to refer to E(ω-ω0) by writing just E(ω), which we will do in the rest of this article.",
                    "score": 0.857922375202179
                },
                {
                    "id": 1364866,
                    "contents": "Microsecond\n1 microsecond (1 μs) – cycle time for frequency (1 MHz), the inverse unit. This corresponds to radio wavelength 300 m (AM medium wave band), as can be calculated by multiplying 1 μs by the speed of light (approximately ). 1 microsecond – the length of time of a high-speed, commercial strobe light flash (see air-gap flash). 1.8 microseconds – the amount of time subtracted from the Earth's day as a result of the 2011 Japanese earthquake. 2 microseconds – the lifetime of a muonium particle 2.68 microseconds – the amount of time subtracted from the Earth's day as a result of the 2004 Indian Ocean earthquake. 3.33564095 microseconds – the time taken by light to travel one kilometre in a vacuum 5.4 microseconds – the time taken by light to travel one mile in a vacuum (or radio waves point-to-point in a near vacuum) 8.01 microseconds – the time taken by light to travel one mile in typical single-mode fiber optic cable",
                    "score": 0.8578879833221436
                },
                {
                    "id": 265217,
                    "contents": "Index of electronics articles\nPSK31 – Pulse amplitude – Pulse duration – Pulse – Pulse-address multiple access – Pulse-code modulation – Pulsed inductive thruster – Pulse-width modulation – Push-to-talk operation – Push-to-type operation – Pyroelectricity",
                    "score": 0.8566249012947083
                },
                {
                    "id": 13095698,
                    "contents": "Pulsed radiofrequency\nPulsed radiofrequency is the technique whereby radio frequency (RF) oscillations are gated at a rate of pulses (cycles) per second (one cycle per second is known as a hertz (Hz)). Radio frequency energies occupy 1.0 x 104 Hz to 3.0 x 1011 Hz of the electromagnetic spectrum. Radio frequency electromagnetic energy is routinely produced by RF electrical circuits connected to a transducer, usually an antenna.",
                    "score": 0.8551616072654724
                },
                {
                    "id": 19718296,
                    "contents": "Pulse width\nIn modern switched-mode power supplies, the voltage of the output electrical power is controlled by rapidly switching a fixed-voltage source on and off and then smoothing the resulting stepped waveform. Increasing the pulse width increases the output voltage. This allows complex output waveforms to be constructed by rapidly changing the pulse width to produce the desired signal, a concept known as pulse-width modulation. References Signal processing Radar theory",
                    "score": 0.8541495203971863
                },
                {
                    "id": 5356632,
                    "contents": "Pulse wave\nApplications The harmonic spectrum of a pulse wave is determined by the duty cycle. Acoustically, the rectangular wave has been described variously as having a narrow/thin, nasal/buzzy/biting, clear, resonant, rich, round and bright sound. Pulse waves are used in many Steve Winwood songs, such as \"While You See a Chance\". In digital electronics, a digital signal is a pulse train (a pulse amplitude modulated signal), a sequence of fixed-width square wave electrical pulses or light pulses, each occupying one of two discrete levels of amplitude. These electronic pulse trains are typically generated by metal–oxide–semiconductor field-effect transistor (MOSFET) devices due to their rapid on–off electronic switching behavior, in contrast to BJT transistors which slowly generate signals more closely resembling sine waves. See also Gibbs phenomenon Pulse shaping Sinc function Sine wave References Waves",
                    "score": 0.8522586226463318
                },
                {
                    "id": 3621198,
                    "contents": "Bandwidth-limited pulse\nA bandwidth-limited pulse (also known as Fourier-transform-limited pulse, or more commonly, transform-limited pulse) is a pulse of a wave that has the minimum possible duration for a given spectral bandwidth. Bandwidth-limited pulses have a constant phase across all frequencies making up the pulse. Optical pulses of this type can be generated by mode-locked lasers. Any waveform can be disassembled into its spectral components by Fourier analysis or Fourier transformation. The length of a pulse thereby is determined by its complex spectral components, which include not just their relative intensities, but also the relative positions (spectral phase) of these spectral components. For different pulse shapes, the minimum duration-bandwidth product is different. The duration-bandwidth product is minimal for zero phase-modulation. For example, pulses have a minimum duration-bandwidth product of 0.315 while gaussian pulses have a minimum value of 0.441.",
                    "score": 0.8505364656448364
                },
                {
                    "id": 5356630,
                    "contents": "Pulse wave\nA pulse wave or pulse train is a kind of non-sinusoidal waveform that includes square waves (duty cycle of 50%) and similarly periodic but asymmetrical waves (duty cycles other than 50%). It is a term is used in synthesizer programming, and is a typical waveform available on many synthesizers. The exact shape of the wave is determined by the duty cycle or pulse width of the oscillator output. In many synthesizers, the duty cycle can be modulated (pulse-width modulation) for a more dynamic timbre. The pulse wave is also known as the rectangular wave, the periodic version of the rectangular function. The average level of a rectangular wave is also given by the duty cycle, therefore by varying the on and off periods and then averaging these said periods, it is possible to represent any value between the two limiting levels. This is the basis of pulse-width modulation.",
                    "score": 0.8486899137496948
                },
                {
                    "id": 567975,
                    "contents": "Ultra-wideband\nTheory A significant difference between conventional radio transmissions and UWB is that conventional systems transmit information by varying the power level, frequency, and/or phase of a sinusoidal wave. UWB transmissions transmit information by generating radio energy at specific time intervals and occupying a large bandwidth, thus enabling pulse-position or time modulation. The information can also be modulated on UWB signals (pulses) by encoding the polarity of the pulse, its amplitude and/or by using orthogonal pulses. UWB pulses can be sent sporadically at relatively low pulse rates to support time or position modulation, but can also be sent at rates up to the inverse of the UWB pulse bandwidth. Pulse-UWB systems have been demonstrated at channel pulse rates in excess of 1.3 billion pulses per second using a continuous stream of UWB pulses (Continuous Pulse UWB or C-UWB), while supporting forward error-correction encoded data rates in excess of 675 Mbit/s.",
                    "score": 0.8469161987304688
                },
                {
                    "id": 4876242,
                    "contents": "Pulse generator\nMicrowave pulsers Pulse generators capable of generating pulses with widths under approximately 100 picoseconds are often termed as \"microwave pulsers\" and typically generate these ultra-short pulses using Step recovery diode (SRD) or Nonlinear Transmission Line (NLTL) methods (for example ). Step Recovery Diode pulse generators are inexpensive but typically require several volts of input drive level and have a moderately high level of random jitter (usually undesirable variation in the time at which successive pulses occur).",
                    "score": 0.8465161919593811
                },
                {
                    "id": 21698236,
                    "contents": "Electromagnetic pulse\nAccording to Maxwell's equations, a pulse of electric energy will always be accompanied by a pulse of magnetic energy. In a typical pulse, either the electric or the magnetic form will dominate. In general, radiation only acts over long distances, with the magnetic and electric fields acting over short distances. There are a few exceptions, such as a solar magnetic flare. Frequency ranges A pulse of electromagnetic energy typically comprises many frequencies from very low to some upper limit depending on the source. The range defined as EMP, sometimes referred to as \"DC to daylight\", excludes the highest frequencies comprising the optical (infrared, visible, ultraviolet) and ionizing (X and gamma rays) ranges. Some types of EMP events can leave an optical trail, such as lightning and sparks, but these are side effects of the current flow through the air and are not part of the EMP itself.",
                    "score": 0.8461548089981079
                },
                {
                    "id": 904749,
                    "contents": "Pulse duration\nIn signal processing and telecommunication, pulse duration is the interval between the time, during the first transition, that the amplitude of the pulse reaches a specified fraction (level) of its final amplitude, and the time the pulse amplitude drops, on the last transition, to the same level. The interval between the 50% points of the final amplitude is usually used to determine or define pulse duration, and this is understood to be the case unless otherwise specified. Other fractions of the final amplitude, e.g., 90% or 1/e, may also be used, as may the root mean square (rms) value of the pulse amplitude. In radar, the pulse duration is the time the radar's transmitter is energized during each cycle. References Signal processing Telecommunication theory",
                    "score": 0.8459749817848206
                },
                {
                    "id": 3723162,
                    "contents": "Pulse repetition frequency\nDefinition Pulse repetition frequency (PRF) is the number of times a pulsed activity occurs every second. This is similar to cycle per second used to describe other types of waveforms. PRF is inversely proportional to time period which is the property of a pulsed wave. PRF is usually associated with pulse spacing, which is the distance that the pulse travels before the next pulse occurs. Physics PRF is crucial to perform measurements for certain physics phenomenon. For example, a tachometer may use a strobe light with an adjustable PRF to measure rotational velocity. The PRF for the strobe light is adjusted upward from a low value until the rotating object appears to stand still. The PRF of the tachometer would then match the speed of the rotating object. Other types of measurements involve distance using the delay time for reflected echo pulses from light, microwaves, and sound transmissions. Measurement",
                    "score": 0.8453330397605896
                },
                {
                    "id": 13846714,
                    "contents": "Pulse (physics)\nIn physics, a pulse is a generic term describing a single disturbance that moves through a transmission medium. This medium may be vacuum (in the case of electromagnetic radiation) or matter, and may be indefinitely large or finite. Pulse reflection Consider a pulse moving through a medium - perhaps through a rope or a slinky. When the pulse reaches the end of that medium, what happens to it depends on whether the medium is fixed in space or free to move at its end. For example, if the pulse is moving through a rope and the end of the rope is held firmly by a person, then it is said that the pulse is approaching a fixed end. On the other hand, if the end of the rope is fixed to a stick such that it is free to move up or down along the stick when the pulse reaches its end, then it is said that the pulse is approaching a free end. Free end",
                    "score": 0.8445781469345093
                },
                {
                    "id": 3354389,
                    "contents": "Slot time\nSince a pulse's runtime will never exceed slot time (the maximum theoretical time for a frame to travel a network), the network interface controller, or NIC waits a minimum of slot time before retransmitting after a collision happened, in order to allow any pulse that was initiated at the time that the waiting NIC was requested to send, to reach all other nodes. By allowing the pulse to reach the waiting NIC, a local collision occurs (i.e. while still sending) rather than a late collision occurring (after sending may or may not have ended). By having the collision occur at the NIC (local) and not on the wire (late) CSMA/CD implementation recover the situation by retransmitting later. Some times for Ethernet slot time include: See DIFS for information on 802.11x slot times. References Ethernet Computer network analysis",
                    "score": 0.843923807144165
                },
                {
                    "id": 1434477,
                    "contents": "Glitch\nminimum may be called a glitch. A related concept is the runt pulse, a pulse whose amplitude is smaller than the minimum level specified for correct operation, and a spike, a short pulse similar to a glitch but often caused by ringing or crosstalk.",
                    "score": 0.8436763286590576
                },
                {
                    "id": 4887229,
                    "contents": "Ultrashort pulse\nBecause of the presence of the term, E(ω) is centered around ω0, and it is a common practice to refer to E(ω-ω0) by writing just E(ω), which we will do in the rest of this article. Just as in the time domain, an intensity and a phase function can be defined in the frequency domain: The quantity is the power spectral density (or simply, the spectrum) of the pulse, and is the phase spectral density (or simply spectral phase). Example of spectral phase functions include the case where is a constant, in which case the pulse is called a bandwidth-limited pulse, or where is a quadratic function, in which case the pulse is called a chirped pulse because of the presence of an instantaneous frequency sweep. Such a chirp may be acquired as a pulse propagates through materials (like glass) and is due to their dispersion. It results in a temporal broadening of the pulse.",
                    "score": 0.8422718048095703
                },
                {
                    "id": 21698258,
                    "contents": "Electromagnetic pulse\nSee also References Citations Sources External links TRESTLE: Landmark of the Cold War, a short documentary film on the SUMMA Foundation website Electromagnetic compatibility Electromagnetic radiation Electronic warfare Energy weapons Nuclear weapons Pulsed power",
                    "score": 0.8421841859817505
                },
                {
                    "id": 4845520,
                    "contents": "Marx generator\nShort pulses The Marx generator is also used to generate short high-power pulses for Pockels cells, driving a TEA laser, ignition of the conventional explosive of a nuclear weapon, and radar pulses.",
                    "score": 0.8416678309440613
                },
                {
                    "id": 21972640,
                    "contents": "Stephen E. Harris\nHis more recent work has sought to address restraints imposed on the types of waveforms that can be produced by the single-cycle barrier Harris and colleagues succeeded in this endeavour in 2005 during a series of experiments aimed at obtaining full control of waveforms, noting \"we were able to vary the shape of the pulse to generate different prescribed waveforms.\" It is hoped that these results will lead to coherent control of chemical reactions, as a probe for ever-shorter physical processes, and for highly efficient generation of far infra-red and vacuum ultra-violet radiation. Harris was elected as a member into the National Academy of Engineering in 1977 for contributions in the field of coherent and non-linear optics. Education 1959 B.S., Electrical Engineering, Rensselaer Polytechnic Institute 1961 M.S., Electrical Engineering, Stanford University 1963 Ph.D., Electrical Engineering, Stanford University Awards",
                    "score": 0.8410046100616455
                },
                {
                    "id": 4876241,
                    "contents": "Pulse generator\nA new class of pulse generator offers both multiple input trigger connections and multiple output connections. Multiple input triggers allows experimenters to synchronize both trigger events and data acquisition events using the same timing controller. In general, generators for pulses with widths over a few microseconds employ digital counters for timing these pulses, while widths between approximately 1 nanosecond and several microseconds are typically generated by analog techniques such as RC (resistor-capacitor) networks or switched delay lines.",
                    "score": 0.8407776355743408
                },
                {
                    "id": 244543,
                    "contents": "Continuous wave\nTransition to CW It was realized that the ideal radio wave for radiotelegraphic communication would be a sine wave with zero damping, a continuous wave. An unbroken continuous sine wave theoretically has no bandwidth; all its energy is concentrated at a single frequency, so it doesn't interfere with transmissions on other frequencies. Continuous waves could not be produced with an electric spark, but were achieved with the vacuum tube electronic oscillator, invented around 1913 by Edwin Armstrong and Alexander Meissner. After World War I, transmitters capable of producing continuous wave, the Alexanderson alternator and vacuum tube oscillators, became widely available. Damped wave spark transmitters were replaced by continuous wave vacuum tube transmitters around 1920, and damped wave transmissions were finally outlawed in 1934. Key clicks",
                    "score": 0.8406902551651001
                },
                {
                    "id": 3723156,
                    "contents": "Pulse repetition frequency\nThe pulse repetition frequency (PRF) is the number of pulses of a repeating signal in a specific time unit, normally measured in pulses per second. The term is used within a number of technical disciplines, notably radar. In radar, a radio signal of a particular carrier frequency is turned on and off; the term \"frequency\" refers to the carrier, while the PRF refers to the number of switches. Both are measured in terms of cycle per second, or hertz. The PRF is normally much lower than the frequency. For instance, a typical World War II radar like the Type 7 GCI radar had a basic carrier frequency of 209 MHz (209 million cycles per second) and a PRF of 300 or 500 pulses per second. A related measure is the pulse width, the amount of time the transmitter is turned on during each pulse.",
                    "score": 0.8405083417892456
                },
                {
                    "id": 20728794,
                    "contents": "List of Nikola Tesla writings\nWorks About Tesla The Tesla Effects With High Frequency and High Potential Currents, Introduction.--The Scope of the Tesla Lectures. Tesla's Oscillator and Other Inventions, Century Illustrated Magazine, April 1895 Earth Electricity to Kill Monopoly, The World Sunday Magazine — March 8, 1896 Inventor Tesla's Plant Nearing Completion, Brooklyn Eagle, February 8, 1902 Nikola Tesla's New Wireless, The Electrical Engineer - London, December 24, 1909 Presentation of the Edison Medal to Nikola Tesla, May 8, 1917 Tesla's Views on Electricity and the War, The Electrical Experimenter, August 1917 Rain Can Be Controlled and Hydraulic Force Provided . . . , Syracuse Herald, ca. February 29, 1920 When Woman is Boss, Colliers, January 30, 1926 Nikola Tesla Tells of New Radio Theories, New York Herald Tribune, September 22, 1929 Tesla Cosmic Ray Motor May Transmit Power ‘Round Earth, Brooklyn Eagle, July 10, 1932 Tesla Invents Peace Ray, New York Sun, July 10, 1934",
                    "score": 0.8390935063362122
                },
                {
                    "id": 901742,
                    "contents": "Duty cycle\nThe duty cycle can also be notated as . Applications Electrical and electronics In electronics, duty cycle is the percentage of the ratio of pulse duration, or pulse width (PW) to the total period (T) of the waveform. It is generally used to represent time duration of a pulse when it is high (1). In digital electronics, signals are used in rectangular waveform which are represented by logic 1 and logic 0. Logic 1 stands for presence of an electric pulse and 0 for absence of an electric pulse. For example, a signal (10101010) has 50% duty cycle, because the pulse remains high for 1/2 of the period or low for 1/2 of the period. Similarly, for pulse (10001000) the duty cycle will be 25% because the pulse remains high only for 1/4 of the period and remains low for 3/4 of the period. Electrical motors typically use less than a 100% duty cycle. For example, if a motor runs for one out of 100 seconds, or 1/100 of the time, then, its duty cycle is 1/100, or 1 percent.",
                    "score": 0.8368707895278931
                },
                {
                    "id": 13499489,
                    "contents": "The Hercules Text\nOne day, some of the pulses suddenly fail to appear. This incident draws more attention to this particular pulsar, as the newly discovered gaps show a remarkable pattern. The first gap consists of one missing pulse, the second of two missing pulses and the third gap consists of four missing pulses. The following gaps also consist of numbers representing powers of 2 (2, 4, 8, 16, 32, 64, 128, ...). The transmission of these numbers goes on for a couple of days until the pulsar falls completely silent.",
                    "score": 0.8364101648330688
                },
                {
                    "id": 3723159,
                    "contents": "Pulse repetition frequency\nElectromagnetic (e.g. radio or light) waves are conceptually pure single frequency phenomena while pulses may be mathematically thought of as composed of a number of pure frequencies that sum and nullify in interactions that create a pulse train of the specific amplitudes, PRRs, base frequencies, phase characteristics, et cetera (See Fourier Analysis). The first term (PRF) is more common in device technical literature (Electrical Engineering and some sciences), and the latter (PRR) more commonly used in military-aerospace terminology (especially United States armed forces terminologies) and equipment specifications such as training and technical manuals for radar and sonar systems.",
                    "score": 0.8362972736358643
                },
                {
                    "id": 901743,
                    "contents": "Duty cycle\nPulse-width modulation (PWM) is used in a variety of electronic situations, such as power delivery and voltage regulation. In electronic music, music synthesizers vary the duty cycle of their audio-frequency oscillators to obtain a subtle effect on the tone colors. This technique is known as pulse-width modulation. In the printer / copier industry, the duty cycle specification refers to the rated throughput (that is, printed pages) of a device per month. In a welding power supply, the maximum duty cycle is defined as the percentage of time in a 10-minute period that it can be operated continuously before overheating. Biological systems The concept of duty cycles is also used to describe the activity of neurons and muscle fibers. In neural circuits for example, a duty cycle specifically refers to the proportion of a cycle period in which a neuron remains active.",
                    "score": 0.8362253904342651
                },
                {
                    "id": 835845,
                    "contents": "Picosecond\n1.0 picoseconds (1.0 ps) – cycle time for electromagnetic frequency 1 terahertz (THz) (1 x 1012 hertz), an inverse unit. This corresponds to a wavelength of 0.3 mm, as can be calculated by multiplying 1 ps by the speed of light (approximately 3 x 108 m/s) to determine the distance traveled. 1 THz is in the far infrared. 1 picosecond – time taken by light in a vacuum to travel approximately 0.30 mm 1 picosecond – half-life of a bottom quark ~1 picosecond – lifetime of a single (hydronium) ion in water at 20 °C picoseconds to nanoseconds – phenomena observable by dielectric spectroscopy 1.2 picoseconds – switching time of the world's fastest transistor (845 GHz, as of 2006) 1.7 picoseconds - rotational correlation time of water 3.3 picoseconds (approximately) – time taken for light to travel 1 millimeter 10 picoseconds after the Big Bang – electromagnetism separates from the other fundamental forces",
                    "score": 0.8361071348190308
                },
                {
                    "id": 12293889,
                    "contents": "C-UWB\nC-UWB is an acronym for continuous pulse ultra-wideband (UWB) technology. C-UWB derives its bandwidth by virtue of the short time duration of the individual pulses. Information can be imparted (modulated) on UWB signals (pulses) by encoding the polarity of the pulse, the amplitude of the pulse, or by using orthogonal pulse shape modulation. Polarity modulation is analogous to BPSK in conventional RF technology. In orthogonal wave shape modulation, two orthogonal UWB pulse shapes are employed. These are further polarity modulated in a fashion analogous to QPSK in conventional radio technology. Preferably, the modulating data bits are scrambled or \"whitened\" to randomize the occurrences of ones and zeros. The pulses are sent contiguously as a continuous stream, hence the bit rate can equal the pulse rate.",
                    "score": 0.8359807729721069
                },
                {
                    "id": 2047941,
                    "contents": "Tresor (club)\nTresor 1: X-101: X-101 (12\"/CD) Tresor 2: Dream Sequence feat. Blake Baxter – Dream Sequence (12\"/ CD) Tresor 3: Eddie Flashin' Fowlkes & 3MB – 3MB featuring Eddie Flashin' Fowlkes (2x12\"/CD) Tresor 4: X-102: Discovers The Rings Of Saturn (2x12\"/CD) Tresor 5: Ingator II – Skyscratch (Mano Mano) (12\"/CD) Tresor 6: 3 Phase Feat. Dr. Motte – Der Klang Der Familie (12\"/CD) Tresor 7: Blake Baxter & Eddie Flashin' Fowlkes – The Project (2x12\"/CD) Tresor 8: Eddie Flashin' Fowlkes & 3MB – The Birth Of Technosoul (2x12\"/CD) Tresor 9: 3MB – 3MB Feat. Magic Juan Atkins (2x12\"/CD) Tresor 10: X-103: Thera EP (12\") Tresor 11: Jeff Mills – Waveform transmission Vol. 1 (2x12\"/CD) Tresor 11: Jeff Mills – Waveform transmission Vol. 1 (Mispress) (2x12\") Tresor 12: X-103: Atlantis (2x12\"/CD) Tresor 13: Various – Detroit Techno Soul EP (12\") Tresor 14: Various – Detroit Techno Soul Compilation (CD) Tresor 15: Tomi D. – You Are An Angel / B Basic (12\")",
                    "score": 0.8357754349708557
                },
                {
                    "id": 10009285,
                    "contents": "Supercontinuum\nThis idea of very short pulses resulting in the broad continuum was studied a year later when Fork et al. reported using 80 fs pulses from a colliding mode-locked laser. The laser's wavelength was 627 nm and they used it to pump a jet of ethylene glycol. They collimated the resulting continuum and measured the pulse duration at different wavelengths, noting that the red part of the continuum was at the front of the pulse and the blue at the rear. They reported very small chirps across the continuum. These observations and others led them to state that self-phase modulation was the dominant effect by some margin. However they also noted that their calculations showed that the continuum remained much larger than self-phase modulation would allow, suggesting that four-wave mixing processes must also be present. They stated that it was much easier to produce a reliable, repeatable continuum using a femtosecond source. Over the ensuing years this source was developed further and used to",
                    "score": 0.8351756930351257
                },
                {
                    "id": 1519739,
                    "contents": "RWM\nUT1 = UTC + DUT1 × 0.1 s + dUT1 × 0.02 s DUT1 may vary between −8 and +8. The number of double pulses sent during seconds 1–8 of each minute encode positive values; if DUT1 = +5, then pulses 1 through 5 will be doubled. Doubling pulses 9–16 encodes negative values similarly. dUT1 varies from −4 to +4. Positive values are encoded by double pulses during seconds 21–24 of each minute. Negative values are encoded during seconds 31–34. The 10 Hz pulses are widened in a pattern similar to that of the Beta time signal: Most pulses are 20 ms, but ones sent on the second are 40 ms, and ones sent on the minute are 500 ms. See also Beta (time signal), a Russian navy time signal. TDF time signal References Time signal radio stations Shortwave radio stations Radio stations in Russia",
                    "score": 0.8351653814315796
                },
                {
                    "id": 6187338,
                    "contents": "Gérard Mourou\nMourou and Strickland found that stretching a laser out reduced its peak power, which could then be greatly amplified using normal instruments. It could then be compressed to create the short-lived, highly powerful lasers they were after. The technique, which was described in Strickland's first scientific publication, came to be known as chirped pulse amplification (CPA). They were probably unaware at the time that their tools would make it possible to study natural phenomena in unprecedented ways. CPA could also per definition be used to create a laser pulse that only lasts one attosecond, one-billionth of a billionth of a second. At those timescales, it became possible not only to study chemical reactions, but what happens inside individual atoms.",
                    "score": 0.8342199325561523
                },
                {
                    "id": 2120930,
                    "contents": "Reginald Fessenden\nFessenden's basic approach was disclosed in U.S. Patent 706,737, which he applied for on May 29, 1901, and was issued the next year. It called for the use of a high-speed alternator (referred to as \"an alternating-current dynamo\") that generated \"pure sine waves\" and produced \"a continuous train of radiant waves of substantially uniform strength\", or, in modern terminology, a continuous-wave (CW) transmitter. The idea of using continuous-wave radio signals was in direct conflict with the current orthodoxy that the abrupt \"whiplash\" effect produced by large electrical sparks was needed in order to create adequately strong signals. John Ambrose Fleming, a Marconi associate, was particularly dismissive in his book The Principles of Electric Wave Telegraphy, a detailed review of the state of the art as he saw it that was published in 1906. Reviewing Fessenden's patent, he wrote that \"The creation of an electric wave seems to involve a certain suddenness in the beginning of the",
                    "score": 0.8339449763298035
                },
                {
                    "id": 567974,
                    "contents": "Ultra-wideband\nUltra-wideband was formerly known as pulse radio, but the FCC and the International Telecommunication Union Radiocommunication Sector (ITU-R) currently define UWB as an antenna transmission for which emitted signal bandwidth exceeds the lesser of 500 MHz or 20% of the arithmetic center frequency. Thus, pulse-based systems—where each transmitted pulse occupies the UWB bandwidth (or an aggregate of at least 500 MHz of narrow-band carrier; for example, orthogonal frequency-division multiplexing (OFDM))—can access the UWB spectrum under the rules.",
                    "score": 0.8338462114334106
                },
                {
                    "id": 102313,
                    "contents": "Mode locking\nThe duration of each pulse of light is determined by the number of modes oscillating in phase (in a real laser, it is not necessarily true that all of the laser's modes are phase-locked). If there are N modes locked with a frequency separation Δν, the overall mode-locked bandwidth is NΔν, and the wider this bandwidth, the shorter the pulse duration from the laser. In practice, the actual pulse duration is determined by the shape of each pulse, which is in turn determined by the exact amplitude and phase relationship of each longitudinal mode. For example, for a laser producing pulses with a Gaussian temporal shape, the minimum possible pulse duration Δt is given by The value 0.441 is known as the \"time–bandwidth product\" of the pulse and varies depending on the pulse shape. For ultrashort pulse lasers, a hyperbolic-secant-squared (sech2) pulse shape is often assumed, giving a time–bandwidth product of 0.315.",
                    "score": 0.8337538242340088
                },
                {
                    "id": 2804485,
                    "contents": "555 timer IC\nModes The 555 IC has the following operating modes: Astable (free-running) mode – The 555 can operate as an electronic oscillator. Uses include LED and lamp flashers, pulse generation, logic clocks, tone generation, security alarms, pulse-position modulation, and so on. The 555 can be used as a simple ADC, converting an analog value to a pulse length (e.g., selecting a thermistor as timing resistor allows the use of the 555 in a temperature sensor with the period of the output pulse determined by the temperature). The use of a microprocessor-based circuit can then convert the pulse period to temperature, linearize it, and even provide calibration means. Monostable (one-shot) mode – In this mode, the 555 functions as a \"one-shot\" pulse generator. Applications include timers, missing pulse detection, bounce-free switches, touch switches, frequency dividers, capacitance measurement, pulse-width modulation (PWM), and so on.",
                    "score": 0.833672046661377
                },
                {
                    "id": 21698244,
                    "contents": "Electromagnetic pulse\nElectronic devices such as vacuum tubes or valves, transistors, and diodes can also switch on and off very quickly, causing similar issues. One-off pulses may be caused by solid-state switches and other devices used only occasionally. However, the many millions of transistors in a modern computer may switch repeatedly at frequencies above 1 GHz, causing interference that appears to be continuous. Nuclear electromagnetic pulse (NEMP) A nuclear electromagnetic pulse is the abrupt pulse of electromagnetic radiation resulting from a nuclear explosion. The resulting rapidly changing electric fields and magnetic fields may couple with electrical/electronic systems to produce damaging current and voltage surges. The intense gamma radiation emitted can also ionize the surrounding air, creating a secondary EMP as the atoms of air first lose their electrons and then regain them.",
                    "score": 0.8336092233657837
                },
                {
                    "id": 12155532,
                    "contents": "John R. Wiegand\nReferences United States Patent 3780313 First Wiegand Pulse Generator United States Patent 3892118 Where it all Started July 1, 1975 United States Patent 4247601 United States Patent 4263523 United States Patent 4484090 United States Patent 4309628 American physicists 1912 births 1986 deaths",
                    "score": 0.8332391977310181
                },
                {
                    "id": 9413704,
                    "contents": "Chronaxie\nIn addition, the chronaxie value, however determined, identifies the pulse duration for minimum energy. In addition, the charge delivered at chronaxie, however determined, is 2, twice the minimum charge. Therefore, if minimum charge delivery is sought to prolong the life of a battery in an implanted stimulator, a pulse duration of less than the measured chronaxie should be selected; a duration of one-tenth chronaxie provides a charge that is only 10% above the minimum charge.",
                    "score": 0.833065390586853
                },
                {
                    "id": 21698243,
                    "contents": "Electromagnetic pulse\nSwitching pulses The switching action of an electrical circuit creates a sharp change in the flow of electricity. This sharp change is a form of EMP. Simple electrical sources include inductive loads such as relays, solenoids, and brush contacts in electric motors. These typically send a pulse down any electrical connections present, as well as radiating a pulse of energy. The amplitude is usually small and the signal may be treated as \"noise\" or \"interference\". The switching off or \"opening\" of a circuit causes an abrupt change in the current flowing. This can in turn cause a large pulse in the electric field across the open contacts, causing arcing and damage. It is often necessary to incorporate design features to limit such effects.",
                    "score": 0.8327775001525879
                },
                {
                    "id": 6990961,
                    "contents": "Self-phase modulation\nAs the pulse propagates, the intensity at any one point in the medium rises and then falls as the pulse goes past. This will produce a time-varying refractive index: This variation in refractive index produces a shift in the instantaneous phase of the pulse: where and are the carrier frequency and (vacuum) wavelength of the pulse, and is the distance the pulse has propagated. The phase shift results in a frequency shift of the pulse. The instantaneous frequency ω(t) is given by: and from the equation for dn/dt above, this is: Plotting ω(t) shows the frequency shift of each part of the pulse. The leading edge shifts to lower frequencies (\"redder\" wavelengths), trailing edge to higher frequencies (\"bluer\") and the very peak of the pulse is not shifted. For the centre portion of the pulse (between t'' = ±τ/2), there is an approximately linear frequency shift (chirp) given by: where α is:",
                    "score": 0.8323568105697632
                },
                {
                    "id": 3421677,
                    "contents": "Pulse (signal processing)\nNyquist pulse A Nyquist pulse is one which meets the Nyquist ISI criterion and is important in data transmission. An example of a pulse which meets this condition is the sinc function. The sinc pulse is of some significance in signal-processing theory but cannot be produced by a real generator for reasons of causality. In 2013, Nyquist pulses were produced in an effort to reduce the size of pulses in optical fibers, which enables them to be packed 10x more closely together, yielding a corresponding 10x increase in bandwidth. The pulses were more than 99 percent perfect and were produced using a simple laser and modulator.",
                    "score": 0.8321384787559509
                },
                {
                    "id": 861702,
                    "contents": "Pulse-width modulation\nwhich, because of their on/off nature, can easily set the needed duty cycle. PWM has also been used in certain communication systems where its duty cycle has been used to convey information over a communications channel.",
                    "score": 0.8317046761512756
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_43",
        "question": "In 1976 it was mistakenly believed that the first of the 'superheavy' elements had been discovered in a sample of mica. Its atomic number  was believed to be 126. What is the most probable distance of the innermost electrons from the nucleus of an atom of this element? (In such elements, relativistic effects are very important, but ignore them here.)",
        "golden_answers": [
            " 0.42"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1160595,
                    "contents": "Periodic table\nSome scientists have argued that should these superheavy elements truly have different properties than their position on the periodic table suggests, the periodic table should be altered to place them with more chemically similar elements. On the other hand, others have argued that the periodic table should reflect atomic structure rather than chemical properties, and oppose such a change. Future extension beyond the seventh period",
                    "score": 0.8665930032730103
                },
                {
                    "id": 1127362,
                    "contents": "Mica\nProperties and structure The mica group includes 37 phyllosilicate minerals. All crystallize in the monoclinic system, with a tendency towards pseudohexagonal crystals, and are similar in structure but vary in chemical composition. Micas are translucent to opaque with a distinct vitreous or pearly luster, and different mica minerals display colors ranging from white to green or red to black. Deposits of mica tend to have a flaky or platy appearance. The crystal structure of mica is described as TOT-c, meaning that it is composed of parallel TOT layers weakly bonded to each other by cations (c). The TOT layers in turn consist of two tetrahedral sheets (T) strongly bonded to the two faces of a single octahedral sheet (O). It is the relatively weak ionic bonding between TOT layers that gives mica its perfect basal cleavage.",
                    "score": 0.8658149242401123
                },
                {
                    "id": 25265211,
                    "contents": "Russell J. Hemley\nHemley's research deals with the properties of matter under high pressure with applications in geophysics, geochemistry and planetology, as well as applications in solid-state physics, chemistry, and pressure effects on biomolecules and biological systems; the applications in physics include hydrogen under pressure in the megabar range, generation of novel superconductors, magnetic structures, glasses and superhard materials under high pressure; the applications in chemistry include new compounds under high pressure. Helmley's research has been experimental (e.g. high-pressure studies with spectroscopic methods and generating high pressures with laser-heated diamond anvil cell) and theoretical; he used theory to develop high-pressure experimental methods in conjunction with microscopic laser-optical and X-ray diffraction analysis in situ from synchrotron radiation sources. Hemley worked in the late 1980s with Ho-Kwang Mao, who became famous for his 1976 work with Peter M. Bell on",
                    "score": 0.8622914552688599
                },
                {
                    "id": 19234152,
                    "contents": "Krotite\nResearchers have found that the mineral, which has the same atomic arrangement as a man-made component of some types of concrete, forms under low pressure at a temperature of at least . These conditions of high temperature and low pressure are consistent with a hypothesis that the krotite grains found in the meteorite formed as high-temperature condensates from the solar nebula from which the Solar System formed, approximately 4.6 billion years ago. Thus, they are likely to be among the earliest minerals formed in the solar system.",
                    "score": 0.8608389496803284
                },
                {
                    "id": 1127361,
                    "contents": "Mica\nMicas ( ) are a group of minerals whose outstanding physical characteristic is that individual mica crystals can easily be split into extremely thin elastic plates. This characteristic is described as perfect basal cleavage. Mica is common in igneous and metamorphic rock and is occasionally found as small flakes in sedimentary rock. It is particularly prominent in many granites, pegmatites, and schists, and \"books\" (large individual crystals) of mica several feet across have been found in some pegmatites. Micas are used in products such as drywalls, paints, fillers, especially in parts for automobiles, roofing and shingles, as well as in electronics. The mineral is used in cosmetics to add \"shimmer\" or \"frost.\" Properties and structure",
                    "score": 0.8581981062889099
                },
                {
                    "id": 13113121,
                    "contents": "Carnegie Institution for Science\nThe Laboratory develops instruments and procedures for examining materials across a wide range of temperatures and pressures — everything from near absolute zero to hotter than the sun and from ambient pressure to millions of atmospheres. The Laboratory uses diamond-anvil cells coupled with first-principles theory as research tools. It also develops scientific instrumentation and high-pressure technology used at the national x-ray and neutron facilities that it manages. This work addresses major problems in mineralogy, materials science, chemistry, and condensed-matter physics.",
                    "score": 0.8549290895462036
                },
                {
                    "id": 2031785,
                    "contents": "Mendeleev's predicted elements\nThe lightest of the Group 0 gases, the first in the periodic table, was assigned a theoretical atomic mass between 5.3×10−11 and 9.6×10−7. The kinetic velocity of this gas was calculated by Mendeleev to be 2,500,000 meters per second. Nearly massless, these gases were assumed by Mendeleev to permeate all matter, rarely interacting chemically. The high mobility and very small mass of the trans-hydrogen gases would result in the situation that they could be rarefied, yet appear to be very dense.",
                    "score": 0.8543879985809326
                },
                {
                    "id": 13162220,
                    "contents": "Mars\nIt is thought that, during the Solar System's formation, Mars was created as the result of a stochastic process of run-away accretion of material from the protoplanetary disk that orbited the Sun. Mars has many distinctive chemical features caused by its position in the Solar System. Elements with comparatively low boiling points, such as chlorine, phosphorus, and sulfur, are much more common on Mars than Earth; these elements were probably pushed outward by the young Sun's energetic solar wind.",
                    "score": 0.8528437614440918
                },
                {
                    "id": 3591611,
                    "contents": "History of the periodic table\nThe discovery of tennessine in 2010 filled the last remaining gap in the seventh period. Any newly discovered elements will thus be placed in an eighth period. Despite the completion of the seventh period, experimental chemistry of some transactinides has been shown to be inconsistent with the periodic law. In the 1990s, Ken Czerwinski at University of California, Berkeley observed similarities between rutherfordium and plutonium and between dubnium and protactinium, rather than a clear continuation of periodicity in groups 4 and 5. More recent experiments on copernicium and flerovium have yielded inconsistent results, some of which suggest that these elements behave more like the noble gas radon rather than mercury and lead, their respective congeners. As such, the chemistry of many superheavy elements has yet to be well characterized, and it remains unclear whether the periodic law can still be used to extrapolate the properties of undiscovered elements. See also",
                    "score": 0.8525317907333374
                },
                {
                    "id": 3952451,
                    "contents": "List of important publications in physics\nCondensed matter physics deals with the physical properties of condensed phases of matter. These properties appear when atoms interact strongly and adhere to each other or are otherwise concentrated. Kamerlingh Onnes, H., \"Further experiments with liquid helium. C. On the change of electric resistance of pure metals at very low temperatures, etc. IV. The resistance of pure mercury at helium temperatures.\" Comm. Phys. Lab. Univ. Leiden; No. 120b, 1911. Kamerlingh Onnes, H., \"Further experiments with liquid helium. D. On the change of electric resistance of pure metals at very low temperatures, etc. V. The disappearance of the resistance of mercury.\" Comm. Phys. Lab. Univ. Leiden; No. 122b, 1911. Kamerlingh Onnes, H., \"Further experiments with liquid helium. G. On the electrical resistance of pure metals, etc. VI. On the sudden change in the rate at which the resistance of mercury disappears.\" Comm. Phys. Lab. Univ. Leiden; No. 124c, 1911. Series of articles about superconductivity.",
                    "score": 0.8517143726348877
                },
                {
                    "id": 26884657,
                    "contents": "Mikhail Eremets\nIn 2001, Eremets joined the Max Planck Institute for Chemistry in Mainz, Germany, as a staff member and leader of the research group \"High-pressure chemistry and physics\". Eremets is working on high temperature superconductivity in metallic hydrogen and hydrogen-rich compounds. Additionally he is interested in polymeric nitrogen, the synthesis of novel high energy density materials, the stability of diamonds, extending the present high static pressure limits over 500 GPa and the synthesis of molecules at pressure and temperature conditions occurring in the Earth mantle. The core facility of the Mikhail Eremets research is a special diamond anvil cell, which can generate extreme pressures between the two diamonds anvils. This has already led to records of static pressure of 440 GPa, which corresponds to 4.4 million atmospheres and exceeds the pressure inside the Earth (360 GPa). The device can be complemented by a laser heating system, a cryostat, magnets and X-ray sources.",
                    "score": 0.8514816761016846
                },
                {
                    "id": 1560713,
                    "contents": "Atom\nThe Earth contains approximately atoms. Although small numbers of independent atoms of noble gases exist, such as argon, neon, and helium, 99% of the atmosphere is bound in the form of molecules, including carbon dioxide and diatomic oxygen and nitrogen. At the surface of the Earth, an overwhelming majority of atoms combine to form various compounds, including water, salt, silicates and oxides. Atoms can also combine to create materials that do not consist of discrete molecules, including crystals and liquid or solid metals. This atomic matter forms networked arrangements that lack the particular type of small-scale interrupted order associated with molecular matter. Rare and theoretical forms Superheavy elements",
                    "score": 0.8513245582580566
                },
                {
                    "id": 762485,
                    "contents": "Extended periodic table\nA study in 1976 by a group of American researchers from several universities proposed that primordial superheavy elements, mainly livermorium, unbiquadium, unbihexium, and unbiseptium, could be a cause of unexplained radiation damage (particularly radiohalos) in minerals. This prompted many researchers to search for them in nature from 1976 to 1983. A group led by Tom Cahill, a professor at the University of California at Davis, claimed in 1976 that they had detected alpha particles and X-rays with the right energies to cause the damage observed, supporting the presence of these elements. In particular, the presence of long-lived (on the order of 109 years) unbiquadium and unbihexium nuclei, along with their decay products, at an abundance of 10−11 relative to their possible congeners uranium and plutonium, was conjectured. Others claimed that none had been detected, and questioned the proposed characteristics of primordial superheavy nuclei. In particular, they cited that any such",
                    "score": 0.8509226441383362
                },
                {
                    "id": 762493,
                    "contents": "Extended periodic table\n| 3 g/cm3 | 7 g/cm3 |- ! Melting point | | |-sigfig= ! Boiling point | | |} The first two elements of period 8 will be ununennium and unbinilium, elements 119 and 120. Their electron configurations should have the 8s orbital being filled. This orbital is relativistically stabilized and contracted; thus, elements 119 and 120 should be more like rubidium and strontium than their immediate neighbours above, francium and radium. Another effect of the relativistic contraction of the 8s orbital is that the atomic radii of these two elements should be about the same as those of francium and radium. They should behave like normal alkali and alkaline earth metals (albeit less reactive than their immediate vertical neighbours), normally forming +1 and +2 oxidation states respectively, but the relativistic destabilization of the 7p3/2 subshell and the relatively low ionization energies of the 7p3/2 electrons should make higher oxidation states like +3 and +4 (respectively) possible as well.",
                    "score": 0.8507118821144104
                },
                {
                    "id": 20474289,
                    "contents": "Yuri Oganessian\nDiscovery of superheavy chemical elements In the 1970s, Oganessian invented the \"cold fusion\" method (unrelated to the unproven energy-producing process cold fusion), a technique to produce transactinide elements (superheavy elements). It played a vital role in the discoveries of elements from 106 to 113. From the mid-1970s to the mid-1990s, the partnership of JINR, led by Oganessian, and the GSI Helmholtz Centre for Heavy Ion Research in Germany, led to the discovery of six chemical elements (107 to 112): bohrium, meitnerium, hassium, darmstadtium, roentgenium, and copernicium.",
                    "score": 0.8501743078231812
                },
                {
                    "id": 20137166,
                    "contents": "Properties of metals, metalloids and nonmetals\nJauncey GEM 1948, Modern physics: A second course in college physics, D. Von Nostrand, New York Jenkins GM & Kawamura K 1976, Polymeric carbons—carbon fibre, glass and char, Cambridge University Press, Cambridge Keenan CW, Kleinfelter DC & Wood JH 1980, General college chemistry, 6th ed., Harper & Row, San Francisco, Keogh DW 2005, 'Actinides: Inorganic & coordination chemistry', in RB King (ed.), Encyclopedia of inorganic chemistry, 2nd ed., vol. 1, John Wiley & Sons, New York, pp. 2–32, Klein CA & Cardinale GF 1992, 'Young's modulus and Poisson's ratio of CVD diamond', in A Feldman & S Holly, SPIE Proceedings, vol. 1759, Diamond Optics V, pp. 178‒192, Kneen WR, Rogers MJW & Simpson P 1972, Chemistry: Facts, patterns, and principles, Addison-Wesley, London Kovalev D, Timoshenko VY, Künzner N, Gross E & Koch F 2001, 'Strong Explosive Interaction of Hydrogenated Porous Silicon with Oxygen at Cryogenic Temperatures', Physical Review Letters, vol. 87, pp. 068301–1–06831-4,",
                    "score": 0.8499283790588379
                },
                {
                    "id": 5156203,
                    "contents": "Widmanstätten pattern\nThe formation of Ni-poor kamacite proceeds by diffusion of Ni in the solid alloy at temperatures between 700 and 450 °C, and can only take place during very slow cooling, about 100 to 10,000 °C/Myr, with total cooling times of 10 Myr or less. This explains why this structure cannot be reproduced in the laboratory. The crystalline patterns become visible when the meteorites are cut, polished, and acid-etched, because taenite is more resistant to the acid. The dimension of kamacite lamellae ranges from coarsest to finest (upon their size) as the nickel content increases. This classification is called structural classification. Use Since nickel-iron crystals grow to lengths of some centimeters only when the solid metal cools down at an exceptionally slow rate (over several million years), the presence of these patterns is strongly suggestive of extraterrestrial origin of the material, and can be used to indicate if a piece of iron may come from a meteorite. Preparation",
                    "score": 0.8497645854949951
                },
                {
                    "id": 1624189,
                    "contents": "Biotite\nBiotite is a common group of phyllosilicate minerals within the mica group, with the approximate chemical formula . It is primarily a solid-solution series between the iron-endmember annite, and the magnesium-endmember phlogopite; more aluminous end-members include siderophyllite and eastonite. Biotite was regarded as a mineral species by the International Mineralogical Association until 1998, when its status was changed to a mineral group. The term biotite is still used to describe unanalysed dark micas in the field. Biotite was named by J.F.L. Hausmann in 1847 in honor of the French physicist Jean-Baptiste Biot, who performed early research into the many optical properties of mica.",
                    "score": 0.8497111201286316
                },
                {
                    "id": 6629478,
                    "contents": "Superheavy element\nThe International Union of Pure and Applied Chemistry defines an element to exist if its lifetime is longer than 10−14 seconds, which is the time it takes for the nucleus to form an electron cloud. The known superheavy elements form part of the 6d and 7p series in the periodic table. Except for rutherfordium and dubnium, even the longest-lasting isotopes of superheavy elements have short half-lives of minutes or less. The element naming controversy involved elements 102–109. Some of these elements thus used systematic names for many years after their discovery had been confirmed. (Usually the systematic names are replaced with permanent names proposed by the discoverers relatively shortly after a discovery has been confirmed.) Introduction Synthesis of superheavy nuclei",
                    "score": 0.8489237427711487
                },
                {
                    "id": 5606471,
                    "contents": "History of chemistry\nThe following year, Ramsay liberated another inert gas from a mineral called cleveite; this proved to be helium, previously known only in the solar spectrum. In his book The Gases of the Atmosphere (1896), Ramsay showed that the positions of helium and argon in the periodic table of elements indicated that at least three more noble gases might exist. In 1898 Ramsay and the British chemist Morris W. Travers isolated these elements—called neon, krypton, and xenon—from air brought to a liquid state at low temperature and high pressure. Sir William Ramsay worked with Frederick Soddy to demonstrate, in 1903, that alpha particles (helium nuclei) were continually produced during the radioactive decay of a sample of radium. Ramsay was awarded the 1904 Nobel Prize for Chemistry in recognition of \"services in the discovery of the inert gaseous elements in air, and his determination of their place in the periodic system.\"",
                    "score": 0.8483700752258301
                },
                {
                    "id": 762459,
                    "contents": "Extended periodic table\nbeyond uranium were not seen in nature was because they were too unstable. The German physicist and engineer Richard Swinne published a review paper in 1926 containing predictions on the transuranic elements (he may have coined the term) in which he anticipated modern predictions of an island of stability: he had hypothesised since 1914 that half-lives should not decrease strictly with atomic number, but suggested instead that there might be some longer-lived elements at Z = 98–102 and Z = 108–110, and speculated that such elements might exist in the Earth's core, in iron meteorites, or in the ice caps of Greenland where they had been locked up from their supposed cosmic origin. By 1955, these elements were called superheavy elements.",
                    "score": 0.8481674790382385
                },
                {
                    "id": 22314276,
                    "contents": "EPS Europhysics Prize\n1994: Donald R. Huffman, Wolfgang Krätschmer, Harry Kroto, Richard Smalley - New molecular forms of carbon and their production in the solid state 1993: Boris L. Altshuler, Arkadii G. Aronov, David E. Khmelnitskii, Anatoly I. Larkin, Boris Spivak - Theoretical work on coherent phenomena in disordered conductors 1992: Gerhard Ertl, Harald Ibach, J. Peter Toennies - Pioneering studies of surface structures, dynamics and reactions through the development of novel experimental methods 1991: Klaus Bechgaard, Denis Jérome - Synthesis of a new class of organic metals and the discovery of their superconductivity and novel magnetic properties 1990: Roberto Car, Michele Parrinello - A novel and powerful method for the ab-initio calculation of molecular dynamics 1989: Frank Steglich, Hans-Rudolf Ott, Gilbert G. Lonzarich - Pioneering investigations of heavy-fermion metals 1988: J. Georg Bednorz, K. Alex Müller - Discovery of high-temperature superconductivity",
                    "score": 0.8475591540336609
                },
                {
                    "id": 5156212,
                    "contents": "Widmanstätten pattern\ncooling, except that the cooling occurred in the Earth's mantle and crust rather than in the vacuum and microgravity of space. Such patterns have also been seen in mulberry, a ternary uranium alloy, after aging at or below for periods of minutes to hours produces a monoclinic ɑ phase.",
                    "score": 0.8471828699111938
                },
                {
                    "id": 11943651,
                    "contents": "Stephen Blundell\nBlundell is also involved in teaching for the Honour School of Physics – including running two undergraduate lecture courses on thermal and statistical physics, and tutoring second-, third- and fourth-year undergraduates. He has also authored two textbooks, the first being Magnetism in Condensed Matter , which covers the quantum mechanical nature of magnetism. Most recently he has co-authored, with his wife and colleague, astrophysicist Katherine Blundell of St John's College, Oxford, a textbook entitled Concepts in Thermal Physics. It provides an introduction to the topics of thermal physics and statistical mechanics covered in a typical undergraduate course in physics. Additionally, he has authored the Very Short Introduction to Superconductivity, part of the Very Short Introductions series published by Oxford University Press. He has authored or co-authored over 300 articles ranging right across the world of solid-state physics.",
                    "score": 0.8469929695129395
                },
                {
                    "id": 1131440,
                    "contents": "Nickel\nNickel is a chemical element with the symbol Ni and atomic number 28. It is a silvery-white lustrous metal with a slight golden tinge. Nickel belongs to the transition metals and is hard and ductile. Pure nickel, powdered to maximize the reactive surface area, shows a significant chemical activity, but larger pieces are slow to react with air under standard conditions because an oxide layer forms on the surface and prevents further corrosion (passivation). Even so, pure native nickel is found in Earth's crust only in tiny amounts, usually in ultramafic rocks, and in the interiors of larger nickel–iron meteorites that were not exposed to oxygen when outside Earth's atmosphere. Meteoric nickel is found in combination with iron, a reflection of the origin of those elements as major end products of supernova nucleosynthesis. An iron–nickel mixture is thought to compose Earth's outer and inner cores.",
                    "score": 0.846078097820282
                },
                {
                    "id": 1228070,
                    "contents": "Silicon\nSilicon is a chemical element with the symbol Si and atomic number 14. It is a hard, brittle crystalline solid with a blue-grey metallic luster, and is a tetravalent metalloid and semiconductor. It is a member of group 14 in the periodic table: carbon is above it; and germanium, tin, lead, and flerovium are below it. It is relatively unreactive. Because of its high chemical affinity for oxygen, it was not until 1823 that Jöns Jakob Berzelius was first able to prepare it and characterize it in pure form. Its oxides form a family of anions known as silicates. Its melting and boiling points of 1414 °C and 3265 °C, respectively, are the second highest among all the metalloids and nonmetals, being surpassed only by boron. Silicon is the eighth most common element in the universe by mass, but very rarely occurs as the pure element in the Earth's crust. It is most widely distributed in space in cosmic dusts, planetoids, and planets as various forms of silicon dioxide (silica) or silicates.",
                    "score": 0.8437910676002502
                },
                {
                    "id": 9360324,
                    "contents": "Joseph I. Goldstein\nIn 1983, Goldstein became Vice President for Graduate Studies and Research at Lehigh. In 1990, Goldstein moved to UMass to become Dean of Engineering, a position he held until 2004. In 1999 he received the Henry Clifton Sorby Award of the International Metallographic Society. The asteroid 4989 Joegoldstein was named after Goldstein in 2000 by Schelte J. Bus, who had discovered the asteroid in 1981 at the Anglo-Australian Telescope. It was named in honor of Goldstein because of his outstanding contributions to the science of meteoritics. In 2005 he received the highest award of the Meteoritical Society, the Leonard Medal, for work on metal, phosphide, carbide, and sulphide in meteorites and lunar rocks; the formation of the Widmanstätten pattern and the determination of cooling rates in irons, stony-irons, and chondrites; the nature of plessite and martensite formation; and determinations of phase diagrams for the Fe-Ni, Fe-Ni-P, Fe-Ni-Co, Fe-Ni-C, and Fe-Ni-S systems [2].",
                    "score": 0.843559980392456
                },
                {
                    "id": 1677543,
                    "contents": "Dubnium\nPredicted properties According to the periodic law, dubnium should belong to group 5, with vanadium, niobium, and tantalum. Several studies have investigated the properties of element 105 and found that they generally agreed with the predictions of the periodic law. Significant deviations may nevertheless occur, due to relativistic effects, which dramatically change physical properties on both atomic and macroscopic scales. These properties have remained challenging to measure for several reasons: the difficulties of production of superheavy atoms, the low rates of production, which only allows for microscopic scales, requirements for a radiochemistry laboratory to test the atoms, short half-lives of those atoms, and the presence of many unwanted activities apart from those of synthesis of superheavy atoms. So far, studies have only been performed on single atoms. Atomic and physical",
                    "score": 0.843368411064148
                },
                {
                    "id": 1222777,
                    "contents": "Solar System\nDue to their higher boiling points, only metals and silicates could exist in solid form in the warm inner Solar System close to the Sun, and these would eventually form the rocky planets of Mercury, Venus, Earth, and Mars. Because metallic elements only comprised a very small fraction of the solar nebula, the terrestrial planets could not grow very large. The giant planets (Jupiter, Saturn, Uranus, and Neptune) formed further out, beyond the frost line, the point between the orbits of Mars and Jupiter where material is cool enough for volatile icy compounds to remain solid. The ices that formed these planets were more plentiful than the metals and silicates that formed the terrestrial inner planets, allowing them to grow massive enough to capture large atmospheres of hydrogen and helium, the lightest and most abundant elements. Leftover debris that never became planets congregated in regions such as the asteroid belt, Kuiper belt, and Oort cloud. The Nice model is an explanation for",
                    "score": 0.8430893421173096
                },
                {
                    "id": 1762875,
                    "contents": "Hassium\nPhysical and atomic The previous members of group8 have relatively high melting points: Fe, 1538°C; Ru, 2334°C; Os, 3033°C. Much like them, hassium is predicted to be a solid at room temperature although its melting point has not been precisely calculated. Hassium should crystallize in the hexagonal close-packed structure (c/a=1.59), similarly to its lighter congener osmium. Pure metallic hassium is calculated to have a bulk modulus (resistance to uniform compression) of 450GPa, comparable with that of diamond, 442GPa. Hassium is expected to be one of the densest of the 118 known elements, with a predicted density of 27–29 g/cm3 vs. the 22.59 g/cm3 measured for osmium.",
                    "score": 0.8429315090179443
                },
                {
                    "id": 17586200,
                    "contents": "John Loveday (physicist)\nDr. John Stephen Loveday is an experimental physicist working in high pressure research. He was educated at Coopers School in Chislehurst and at the University of Bristol, from where he took his PhD in Physics. He currently works as a Reader in the School of Physics and Astronomy at the University of Edinburgh, Scotland. Loveday is considered one of the pioneers of neutron diffraction at high pressure and was a founder member of the Paris–Edinburgh high-pressure neutron diffraction collaboration. His specialism is in techniques for high-pressure neutron scattering and examining the application of these techniques for investigating structures and transitions in planetary ices, hydrates, water and other simple molecular systems. He is the author of more than seventy papers and his work on the behaviour of clathrate hydrates at high pressure and their relevance to models of planetary bodies including Titan was published in Nature and has been highly cited.",
                    "score": 0.8427494764328003
                },
                {
                    "id": 1751665,
                    "contents": "Glenn T. Seaborg\nSeaborg published several books and journal articles during his tenure at the Atomic Energy Commission. He predicted the existence of elements beyond those on the periodic table, the transactinide series and the superactinide series of undiscovered synthetic elements. While most of these theoretical future elements have extremely short half-lives and thus no expected practical applications, he also hypothesized the existence of stable super-heavy isotopes of certain elements in an island of stability. Seaborg served as chairman of the Atomic Energy Commission until 1971. Return to California",
                    "score": 0.8426399827003479
                },
                {
                    "id": 10025626,
                    "contents": "Cryochemistry\nAt absolute zero most elements become a solid, but not all behave as predictably as this; for instance, helium becomes a highly unusual liquid. The chemistry between substances, however, does not disappear, even near absolute zero temperatures, since separated molecules/atom can always combine to lower their total energy. Almost every molecule or element will show different properties at different temperatures; if cold enough, some functions are lost entirely. Cryogenic chemistry can lead to very different results compared with standard chemistry, and new chemical routes to substances may be available at cryogenic temperatures, such as the formation of argon fluorohydride, which is only a stable compound at or below . Methods of cooling",
                    "score": 0.8424572944641113
                },
                {
                    "id": 6629489,
                    "contents": "Superheavy element\nHistory Early predictions The heaviest element known at the end of the 19th century was uranium, with an atomic mass of approximately 240 (now known to be 238) amu. Accordingly, it was placed in the last row of the periodic table; this fueled speculation about the possible existence of elements heavier than uranium and why A = 240 seemed to be the limit. Following the discovery of the noble gases, beginning with that of argon in 1895, the possibility of heavier members of the group was considered. Danish chemist Julius Thomsen proposed in 1895 the existence of a sixth noble gas with Z = 86, A = 212 and a seventh with Z = 118, A = 292, the last closing a 32-element period containing thorium and uranium. In 1913, Swedish physicist Johannes Rydberg extended Thomsen's extrapolation of the periodic table to include even heavier elements with atomic numbers up to 460, but he did not believe that these superheavy elements existed or occurred in nature.",
                    "score": 0.8423507213592529
                },
                {
                    "id": 4885165,
                    "contents": "Clemens Winkler\nTo place germanium into the periodic table, Mendeleev suggested that it might be ekacadmium, an element he had predicted earlier. In contrast, Lothar Meyer favored an identification of germanium with ekasilicon, a different predicted element. Winkler isolated more of the pure material, and eventually obtained enough to measure some of its physical and chemical properties. His results showed unequivocally that Meyer's interpretation was the correct one and that nearly all of the new element's properties matched Mendeleev predictions. The close match between what had been predicted for ekasilicon and what was found for germanium was clear evidence for the utility and power of the periodic table and the concept of periodicity. Other work",
                    "score": 0.8420720100402832
                },
                {
                    "id": 688674,
                    "contents": "Dmitri Mendeleev\nIn an attempt at a chemical conception of the aether, he put forward a hypothesis that there existed two inert chemical elements of lesser atomic weight than hydrogen. Of these two proposed elements, he thought the lighter to be an all-penetrating, all-pervasive gas, and the slightly heavier one to be a proposed element, coronium. Mendeleev devoted much study and made important contributions to the determination of the nature of such indefinite compounds as solutions. In another department of physical chemistry, he investigated the expansion of liquids with heat, and devised a formula similar to Gay-Lussac's law of the uniformity of the expansion of gases, while in 1861 he anticipated Thomas Andrews' conception of the critical temperature of gases by defining the absolute boiling-point of a substance as the temperature at which cohesion and heat of vaporization become equal to zero and the liquid changes to vapor, irrespective of the pressure and volume.",
                    "score": 0.8419451117515564
                },
                {
                    "id": 13628568,
                    "contents": "Allende meteorite\nThe discovery at California Institute of Technology in 1977 of new forms of the elements calcium, barium and neodymium in the meteorite was believed to show that those elements came from some source outside the early clouds of gas and dust that formed the Solar System. This supports the theory that shockwaves from a supernova - the explosion of an aging star - may have triggered the formation of, or contributed to the formation of the Solar System. As further evidence, the Caltech group said the meteorite contained Aluminum 26, a rare form of aluminum. This acts as a \"clock\" on the meteorite, dating the explosion of the supernova to within less than 2 million years before the Solar System was formed. Subsequent studies have found isotopic ratios of krypton, xenon, nitrogen and some other elements whose forms are also unknown in the Solar System. The conclusion, from many studies with similar findings, is that there were a lot of substances in the presolar disc that were introduced as",
                    "score": 0.8417385816574097
                },
                {
                    "id": 2562838,
                    "contents": "Abundance of the chemical elements\nThe abundance of chemical elements in the universe is dominated by the large amounts of hydrogen and helium which were produced in the Big Bang. Remaining elements, making up only about 2% of the universe, were largely produced by supernovae and certain red giant stars. Lithium, beryllium and boron despite of their low atomic number, are rare because although they are produced by nuclear fusion, they are then destroyed by other reactions in the stars. The elements from carbon to iron are relatively more abundant in the universe because of the ease of making them in supernova nucleosynthesis. Elements of higher atomic number than iron (element 26) become progressively rarer in the universe, because they increasingly absorb stellar energy in their production. Also, elements with even atomic numbers are generally more common than their neighbors in the periodic table, due to favorable energetics of formation.",
                    "score": 0.8415555357933044
                },
                {
                    "id": 29477598,
                    "contents": "Discovery of the nonmetals\nHelium: In 1868, Janssen and Lockyer independently observed a yellow line in the solar spectrum that did not match that of any other element. In 1895, in each case at around the same time, Ramsay, Cleve, and Langlet independently observed helium trapped in cleveite. Fluorine: André-Marie Ampère predicted an element analogous to chlorine obtainable from hydrofluoric acid, and between 1812 and 1886 many researchers tried to obtain it. Fluorine was eventually isolated in 1886 by Moissan. Germanium: In mid-1885, at a mine near Freiberg, Saxony, a new mineral was discovered and named argyrodite because of its silver content. The chemist Clemens Winkler analyzed this new mineral, which proved to be a combination of silver, sulfur, and a new element, germanium, which he was able to isolate in 1886. Argon: Lord Rayleigh and Ramsay discovered argon in 1894 by comparing the molecular weights of nitrogen prepared by liquefaction from air, and nitrogen prepared by chemical means. It was the first",
                    "score": 0.8412841558456421
                },
                {
                    "id": 1776764,
                    "contents": "Henry Moseley\nMoseley's experiments confirmed these predictions, by showing exactly what the missing atomic numbers were, 43 and 61. In addition, Moseley predicted the existence of two more undiscovered elements, those with the atomic numbers 72 and 75, and gave very strong evidence that there were no other gaps in the Periodic Table between the elements aluminium (atomic number 13) and gold (atomic number 79).",
                    "score": 0.840970516204834
                },
                {
                    "id": 6629493,
                    "contents": "Superheavy element\nCharacteristics Due to their short half-lives (for example, the most stable known isotope of seaborgium has a half-life of 14 minutes, and half-lives decrease gradually going to the right of the group) and the low yield of the nuclear reactions that produce them, new methods have had to be created to determine their gas-phase and solution chemistry based on very small samples of a few atoms each. Relativistic effects become very important in this region of the periodic table, causing the filled 7s orbitals, empty 7p orbitals, and filling 6d orbitals to all contract inwards toward the atomic nucleus. This causes a relativistic stabilization of the 7s electrons and makes the 7p orbitals accessible in low excitation states.",
                    "score": 0.8408658504486084
                },
                {
                    "id": 1164168,
                    "contents": "Promethium\nHistory Searches for element 61 In 1902, Czech chemist Bohuslav Brauner found out that the differences in properties between neodymium and samarium were the largest between any two consecutive lanthanides in the sequence then known; as a conclusion, he suggested there was an element with intermediate properties between them. This prediction was supported in 1914 by Henry Moseley who, having discovered that atomic number was an experimentally measurable property of elements, found that a few atomic numbers had no known corresponding elements: the gaps were 43, 61, 72, 75, 85, and 87. With the knowledge of a gap in the periodic table several groups started to search for the predicted element among other rare earths in the natural environment.",
                    "score": 0.8408418893814087
                },
                {
                    "id": 1170449,
                    "contents": "Outline of physical science\nHistory of chemistry – history of the physical science of atomic matter (matter that is composed of chemical elements), especially its chemical reactions, but also including its properties, structure, composition, behavior, and changes as they relate the chemical reactions History of analytical chemistry – history of the study of the separation, identification, and quantification of the chemical components of natural and artificial materials. History of astrochemistry – history of the study of the abundance and reactions of chemical elements and molecules in the universe, and their interaction with radiation. History of cosmochemistry – history of the study of the chemical composition of matter in the universe and the processes that led to those compositions",
                    "score": 0.8406789898872375
                },
                {
                    "id": 1228153,
                    "contents": "Silicon\nThe crystallisation of igneous rocks from magma depends on a number of factors; among them are the chemical composition of the magma, the cooling rate, and some properties of the individual minerals to be formed, such as lattice energy, melting point, and complexity of their crystal structure. As magma is cooled, olivine appears first, followed by pyroxene, amphibole, biotite mica, orthoclase feldspar, muscovite mica, quartz, zeolites, and finally, hydrothermal minerals. This sequence shows a trend toward increasingly complex silicate units with cooling, and the introduction of hydroxide and fluoride anions in addition to oxides. Many metals may substitute for silicon. After these igneous rocks undergo weathering, transport, and deposition, sedimentary rocks like clay, shale, and sandstone are formed. Metamorphism also may occur at high temperatures and pressures, creating an even vaster variety of minerals.",
                    "score": 0.8405911922454834
                },
                {
                    "id": 13008821,
                    "contents": "The Ice Limit\nthan double what was expected — it is also staggering scientific discovery: no known element has an atomic number anywhere near 177. McFarlane speculates that this element is part of the undiscovered elemental \"island of stability\", and further states that the meteorite could only have come from outside the solar system. During this time, McFarlane also becomes romantically involved with Amira.",
                    "score": 0.8405801057815552
                },
                {
                    "id": 17555408,
                    "contents": "Periodic table (crystal structure)\nFor elements that are solid at standard temperature and pressure the table gives the crystalline structure of the most thermodynamically stable form(s) in those conditions. In all other cases the structure given is for the element at its melting point. Data is presented only for the elements that have been produced in bulk (the first 99, except for astatine and francium). Predictions are given for astatine, francium, and elements 100–114 and 118. No predictions are available for elements 115–117. Table Unusual structures Usual crystal structures",
                    "score": 0.8402124047279358
                },
                {
                    "id": 1762835,
                    "contents": "Hassium\nHassium is a chemical element with the symbol Hs and the atomic number 108. Hassium is highly radioactive; its most stable known isotopes have half-lives of approximately ten seconds. One of its isotopes, 270Hs, has magic numbers of both protons and neutrons for deformed nuclei, which gives it greater stability against spontaneous fission. Hassium is a superheavy element; it has been produced in a laboratory only in very small quantities by fusing heavy nuclei with lighter ones. Natural occurrences of the element have been hypothesised but never found.",
                    "score": 0.840003252029419
                },
                {
                    "id": 22893742,
                    "contents": "Metals close to the border between metals and nonmetals\nDeming HG 1940, Fundamental Chemistry, John Wiley & Sons, New York Dillard CR & Goldberg DE 1971, Chemistry: Reactions, Structure, and Properties, Macmillan, New York Dirkse, TP (ed.) 1986, Copper, silver, gold and zinc, cadmium, mercury oxides and hydroxides, IUPAC solubility data series, vol. 23, Pergamon, Oxford, Divakar C, Mohan M & Singh AK 1984, 'The kinetics of pressure-induced fcc-bcc transformation in ytterbium', Journal of Applied Physics, vol. 56, no. 8, pp. 2337–40, Donohue J 1982, The structures of the elements, Robert E. Krieger, Malabar, Florida, Driess M & Nöth H 2004, Molecular clusters of the main group elements, Wiley-VCH, Weinheim Dunlap BD, Brodsky MB, Shenoy GK & Kalvius GM 1970, 'Hyperfine interactions and anisotropic lattice vibrations of 237Np in α-Np metal', Physical Review B, vol. 1, no. 1, pp. 44–49, Durrant PJ & Durrant B 1970, Introduction to advanced inorganic chemistry, 2nd ed., Longman",
                    "score": 0.8392863869667053
                },
                {
                    "id": 6629477,
                    "contents": "Superheavy element\nSuperheavy elements are radioactive and have only been obtained synthetically in laboratories. None of these elements have ever been collected in a macroscopic sample. Superheavy elements are all named after physicists and chemists or important locations involved in the synthesis of the elements. The International Union of Pure and Applied Chemistry defines an element to exist if its lifetime is longer than 10−14 seconds, which is the time it takes for the nucleus to form an electron cloud.",
                    "score": 0.8392083048820496
                },
                {
                    "id": 744680,
                    "contents": "Island of stability\nAs early as 1914, the possible existence of superheavy elements with atomic numbers well beyond that of uranium—then the heaviest known element—was suggested, when German physicist Richard Swinne proposed that superheavy elements around Z = 108 were a source of radiation in cosmic rays. Although he did not make any definitive observations, he hypothesized in 1931 that transuranium elements around Z = 100 or Z = 108 may be relatively long-lived and possibly exist in nature. In 1955, American physicist John Archibald Wheeler also proposed the existence of these elements; he is credited with the first usage of the term \"superheavy element\" in a 1958 paper published with Frederick Werner. This idea did not attract wide interest until a decade later, after improvements in the nuclear shell model. In this model, the atomic nucleus is built up in \"shells\", analogous to electron shells in atoms. Independently of each other, neutrons and protons have energy levels that are normally close",
                    "score": 0.8391357660293579
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_44",
        "question": "The ground level of $\\mathrm{Cl}$ is ${ }^2 \\mathrm{P}_{3 / 2}$ and a ${ }^2 \\mathrm{P}_{1 / 2}$ level lies $881 \\mathrm{~cm}^{-1}$ above it. Calculate the electronic contribution to the molar Gibbs energy of $\\mathrm{Cl}$ atoms at  $500 \\mathrm{~K}$.",
        "golden_answers": [
            " -6.42"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1402323,
                    "contents": "Robert S. Mulliken\nUp to this point, the primary way to calculate the electronic structure of molecules was based on a calculation by Walter Heitler and Fritz London on the hydrogen molecule (H2) in 1927. With the conception of hybridized atomic orbitals by John C. Slater and Linus Pauling, which rationalized observed molecular geometries, the method was based on the premise that the bonds in any molecule could be described in a manner similar to the bond in H2, namely, as overlapping atomic orbitals centered on the atoms involved. Since it corresponded to chemists' ideas of localized bonds between pairs of atoms, this method (called the Valence-Bond (VB) or Heitler-London-Slater-Pauling (HLSP) method), was very popular. In attempting to calculate the properties of excited states (molecules that have been excited by an energy source), the VB method does not always work well. With its description of the electron wave functions in molecules as delocalized molecular orbitals that possess the same symmetry",
                    "score": 0.8558138608932495
                },
                {
                    "id": 7768707,
                    "contents": "Effective atomic number\nEffective atomic numbers are useful not only in understanding why electrons further from the nucleus are so much more weakly bound than those closer to the nucleus, but also because they can tell us when to use simplified methods of calculating other properties and interactions. For instance, lithium, atomic number 3, has two electrons in the 1s shell and one in the 2s shell. Because the two 1s electrons screen the protons to give an effective atomic number for the 2s electron close to 1, we can treat this 2s valence electron with a hydrogenic model. Mathematically, the effective atomic number Zeff can be calculated using methods known as \"self-consistent field\" calculations, but in simplified situations is just taken as the atomic number minus the number of electrons between the nucleus and the electron being considered.",
                    "score": 0.8535774946212769
                },
                {
                    "id": 29172249,
                    "contents": "Charles Rugeley Bury\nIn 1921 Bury proposed a model of the atom which suggested that electrons were distributed symmetrically over the surface of concentric spheres which could hold 2, 8, 18, and 32 electrons. He proposed that an outer layer of electrons can contain a maximum of 8 electrons (s2p6 in modern notation), and that for inner layers there occurs a transition series of elements during the change from 8 to 18 (or 18 to 32) electrons. This was the first use of the word transition in the context of electron configurations. In July 1943, Bury moved to the Imperial Chemical Industries to worked with colleague M.P. Appleby and retired from there in 1952. His other works were on the chemistry of colour, freezing points, and on micelles. He married Margaret Adams in 1922 and they had a son and a daughter. References 1890 births 1968 deaths English chemists",
                    "score": 0.8534650802612305
                },
                {
                    "id": 2616215,
                    "contents": "John C. Slater\nRussell M. Pitzer ‡, molecular calculations (ethane), later Chairman of Chemistry Department, Ohio State U, over 100 papers. George W. Pratt, Jr. †‡later Professor of Electrical Engineering and CMSE, MIT, solid state electronics. F.W. Quelle, Jr. augmented plane waves, later laser optics. Melvin M. Saffren † Robert Schrieffer wrote Bachelor's thesis on multiplets in heavy atoms, later shared Nobel Prize for BCS theory of superconductivity. Edward Schultz Harold Schweinler Hermann Statz ‡, ferromagnetism, later director of research at Raytheon and recipient of 2004 IEEE Microwave Pioneer Award, Levente Szasz, atomic structure, became Professor of Physics at Fordham University, published two books, Brian T. Sutcliffe ‡, co-developer of POLYATOM, later Professor of Chemistry, University of York. Richard E. Watson ‡៛, electronic properties of metal atoms, later at Brookhaven, published over 200 papers. E.B. White †",
                    "score": 0.8520641326904297
                },
                {
                    "id": 2616202,
                    "contents": "John C. Slater\nIn his memoir, Morse wrote \"In addition to other notable papers ... on ... Hartree's self-consistent field, the quantum mechanical derivation of the Rydberg constant, and the best values of atomic shielding constants, he wrote a seminal paper on directing valency \" (what became known, later, as linear combination of atomic orbitals).",
                    "score": 0.8502241969108582
                },
                {
                    "id": 18171570,
                    "contents": "Michael P. Barnett\nMichael Peter Barnett (24 March 1929 – 13 March 2012) was a British theoretical chemist and computer scientist. He developed mathematical and computer techniques for quantum chemical problems, and some of the earliest software for several other kinds of computer application. After his early days in London, Essex and Lancashire, he went to King's College, London, in 1945, the Royal Radar Establishment in Malvern in 1953, IBM UK in 1955, the University of Wisconsin Department of Chemistry in 1957, and the MIT Solid State and Molecular Theory Group in 1958.",
                    "score": 0.8490426540374756
                },
                {
                    "id": 4332799,
                    "contents": "Computational physics\nComputational solid state physics, for example, uses density functional theory to calculate properties of solids, a method similar to that used by chemists to study molecules. Other quantities of interest in solid state physics, such as the electronic band structure, magnetic properties and charge densities can be calculated by this and several methods, including the Luttinger-Kohn/k.p method and ab-initio methods. See also Advanced Simulation Library CECAM - Centre européen de calcul atomique et moléculaire Division of Computational Physics (DCOMP) of the American Physical Society Important publications in computational physics Mathematical and theoretical physics Open Source Physics, computational physics libraries and pedagogical tools Timeline of computational physics Car–Parrinello molecular dynamics References",
                    "score": 0.8486096858978271
                },
                {
                    "id": 2616201,
                    "contents": "John C. Slater\n1932 to 1935: atomic orbitals, metallic conduction, application of the Thomas–Fermi method to metals, 1936: ferromagnetism, (with Erik Rudberg, later Chairman of the Nobel Prize committee for Physics) inelastic scattering, and (with his Ph.D. student William Shockley and close to his own Ph.D. topic), optical properties of alkali halides 1937 and 1938: augmented plane waves, superconductivity, ferromagnetism, electrodynamics, 1939 he published \"only\" a book: the definitive Introduction to Chemical Physics, 1940 the Grüneisen constant, and the Curie point, 1941 phase transition analogous to ferromagnetism in potassium dihydrogen phosphate.",
                    "score": 0.8474522829055786
                },
                {
                    "id": 1129313,
                    "contents": "Niels Bohr\nwhere me is the electron's mass, e is its charge, h is Planck's constant and Z is the atom's atomic number (1 for hydrogen). The model's first hurdle was the Pickering series, lines which did not fit Balmer's formula. When challenged on this by Alfred Fowler, Bohr replied that they were caused by ionised helium, helium atoms with only one electron. The Bohr model was found to work for such ions. Many older physicists, like Thomson, Rayleigh and Hendrik Lorentz, did not like the trilogy, but the younger generation, including Rutherford, David Hilbert, Albert Einstein, Enrico Fermi, Max Born and Arnold Sommerfeld saw it as a breakthrough. The trilogy's acceptance was entirely due to its ability to explain phenomena which stymied other models, and to predict results that were subsequently verified by experiments. Today, the Bohr model of the atom has been superseded, but is still the best known model of the atom, as it often appears in high school physics and chemistry texts.",
                    "score": 0.847237765789032
                },
                {
                    "id": 1560652,
                    "contents": "Atom\nLater in the same year Henry Moseley provided additional experimental evidence in favor of Niels Bohr's theory. These results refined Ernest Rutherford's and Antonius van den Broek's model, which proposed that the atom contains in its nucleus a number of positive nuclear charges that is equal to its (atomic) number in the periodic table. Until these experiments, atomic number was not known to be a physical and experimental quantity. That it is equal to the atomic nuclear charge remains the accepted atomic model today.",
                    "score": 0.8472203016281128
                },
                {
                    "id": 5639617,
                    "contents": "Term symbol\nTerm symbols for the ground states of most chemical elements are given in the collapsed table below. In the d-block and f-block, the term symbols are not always the same for elements in the same column of the periodic table, because open shells of several d or f electrons have several closely spaced terms whose energy ordering is often perturbed by the addition of an extra complete shell to form the next element in the column. For example, the table shows that the first pair of vertically adjacent atoms with different ground-state term symbols are V and Nb. The 6D ground state of Nb corresponds to an excited state of V 2112 cm−1 above the 4F ground state of V, which in turn corresponds to an excited state of Nb 1143 cm−1 above the Nb ground state. These energy differences are small compared to the 15158 cm−1 difference between the ground and first excited state of Ca, which is the last element before V with no d electrons.",
                    "score": 0.8462278246879578
                },
                {
                    "id": 1131686,
                    "contents": "Nobelium\nIt is expected that the relativistic stabilization of the 7s subshell greatly destabilizes nobelium dihydride, NoH2, and relativistic stabilisation of the 7p1/2 spinor over the 6d3/2 spinor mean that excited states in nobelium atoms have 7s and 7p contribution instead of the expected 6d contribution. The long No–H distances in the NoH2 molecule and the significant charge transfer lead to extreme ionicity with a dipole moment of 5.94 D for this molecule. In this molecule, nobelium is expected to exhibit main-group-like behavior, specifically acting like an alkaline earth metal with its ns2 valence shell configuration and core-like 5f orbitals. Nobelium's complexing ability with chloride ions is most similar to that of barium, which complexes rather weakly. Its complexing ability with citrate, oxalate, and acetate in an aqueous solution of 0.5 M ammonium nitrate is between that of calcium and strontium, although it is somewhat closer to that of strontium.",
                    "score": 0.8459435701370239
                },
                {
                    "id": 833923,
                    "contents": "Nihonium\nNihonium is the first member of the 7p series of elements and the heaviest group 13 element on the periodic table, below boron, aluminium, gallium, indium, and thallium. All the group 13 elements except boron are metals, and nihonium is expected to follow suit. Nihonium is predicted to show many differences from its lighter homologues. The major reason for this is the spin–orbit (SO) interaction, which is especially strong for the superheavy elements, because their electrons move much faster than in lighter atoms, at velocities close to the speed of light. In relation to nihonium atoms, it lowers the 7s and the 7p electron energy levels (stabilising those electrons), but two of the 7p electron energy levels are stabilised more than the other four. The stabilisation of the 7s electrons is called the inert pair effect, and the separation of the 7p subshell into the more and less stabilised parts is called subshell splitting. Computational chemists see the split as a change of the",
                    "score": 0.8458586931228638
                },
                {
                    "id": 20029792,
                    "contents": "Empty lattice approximation\nThe electron bands of common metal crystals Apart from a few exotic exceptions, metals crystallize in three kinds of crystal structures: the BCC and FCC cubic crystal structures and the hexagonal close-packed HCP crystal structure. References External links Brillouin Zone simple lattice diagrams by Thayer Watkins Brillouin Zone 3d lattice diagrams by Technion. DoITPoMS Teaching and Learning Package- \"Brillouin Zones\" Quantum models Electronic band structures",
                    "score": 0.8458534479141235
                },
                {
                    "id": 27321062,
                    "contents": "John Monteath Robertson\nThurso (now atomic energy). Ian Dawson (now electron microscopy), J. C. Speakman, George Sim, Tom Hamor and Andrew Porte (now nuclear magnetic resonance) are all back in Glasgow again, after adventures in other places, and are actively participating in our latest and most exciting work.\"In 1960, Robertson's group reported the structure of limonin, a complex organic molecule whose structure had eluded chemists since its discovery in 1841. With the structure, Robertson's group also demonstrated a clear path to apply novel computational techniques to solve the phase problem for complex organic molecules by using heavy-metal derivatives. This was a continuation of his previous work phasing organic molecules.",
                    "score": 0.844551682472229
                },
                {
                    "id": 2616209,
                    "contents": "John C. Slater\nSolid state work progressed more rapidly at first in the SSMTG, with contributions over the first few years by George Koster, John Wood, Arthur Freeman and Leonard Mattheis. Molecular and atomic calculations also flourished in the hands of Fernando J. Corbató, Lee Allen and Alvin Meckler. This initial work followed lines largely set by Slater. Michael Barnett came in 1958. He and John Wood were given faculty appointments. Robert Nesbet, Brian Sutcliffe, Malcolm Harrison and Levente Szasz brought in a variety of further approaches to molecular and atomic problems. Jens Dahl, Alfred Switendick, Jules Moskowitz, Donald Merrifield and Russell Pitzer did further work on molecules, and Fred Quelle on solids.",
                    "score": 0.8444426655769348
                },
                {
                    "id": 7136132,
                    "contents": "Tight binding\nIn solid-state physics, the tight-binding model (or TB model) is an approach to the calculation of electronic band structure using an approximate set of wave functions based upon superposition of wave functions for isolated atoms located at each atomic site. The method is closely related to the LCAO method (linear combination of atomic orbitals method) used in chemistry. Tight-binding models are applied to a wide variety of solids. The model gives good qualitative results in many cases and can be combined with other models that give better results where the tight-binding model fails. Though the tight-binding model is a one-electron model, the model also provides a basis for more advanced calculations like the calculation of surface states and application to various kinds of many-body problem and quasiparticle calculations.",
                    "score": 0.8442701697349548
                },
                {
                    "id": 1160583,
                    "contents": "Periodic table\nLike the group 1 metals, hydrogen has one electron in its outermost shell and typically loses its only electron in chemical reactions. It has some metal-like chemical properties, being able to displace some metals from their salts. But hydrogen forms a diatomic nonmetallic gas at standard conditions, unlike the alkali metals which are reactive solid metals. This and hydrogen's formation of hydrides, in which it gains an electron, brings it close to the properties of the halogens which do the same. Moreover, the lightest two halogens (fluorine and chlorine) are gaseous like hydrogen at standard conditions. Hydrogen thus has properties corresponding to both those of the alkali metals and the halogens, but matches neither group perfectly, and is thus difficult to place by its chemistry. Therefore, while the electronic placement of hydrogen in group 1 predominates, some rarer arrangements show either hydrogen in group 17, duplicate hydrogen in both groups 1 and 17, or float it separately",
                    "score": 0.8438230752944946
                },
                {
                    "id": 4064318,
                    "contents": "Walter Kohn\nSelected publications W. Kohn, \"An essay on condensed matter physics in the twentieth century,\" Reviews of Modern Physics, Vol. 71, No. 2, pp. S59–S77, Centenary 1999. APS W. Kohn, \"Nobel Lecture: Electronic structure of matter — wave functions and density functionals,\" Reviews of Modern Physics, Vol. 71, No. 5, pp. 1253–1266 (1999). APS D. Jérome, T.M. Rice, and W. Kohn, \"Excitonic Insulator,\" Physical Review, Vol. 158, No. 2, pp. 462–475 (1967). APS P. Hohenberg, and W. Kohn, \"Inhomogeneous Electron Gas,\" Physical Review, Vol. 136, No. 3B, pp. B864–B871 (1964). APS W. Kohn, and L. J. Sham, \"Self-Consistent Equations Including Exchange and Correlation Effects,\" Physical Review, Vol. 140, No. 4A, pp. A1133–A1138 (1965). APS W. Kohn, and J. M. Luttinger, \"New Mechanism for Superconductivity,\" Physical Review Letters, Vol. 15, No. 12, pp. 524–526 (1965). APS W. Kohn, \"Theory of the Insulating State,\" Physical Review, Vol. 133, No. 1A, pp. A171–A181 (1964). APS",
                    "score": 0.8438051342964172
                },
                {
                    "id": 2616206,
                    "contents": "John C. Slater\nThe Solid State and Molecular Theory Group Activities In the words of Robert Nesbet: \"Slater founded the SSMTG with the idea of bringing together a younger generation of students and PostDocs with a common interest in the electronic structure and properties of atoms, molecules and solids. This was in part to serve as a balance for electronic physics to survive the overwhelming growth of nuclear physics following the war\" . George Koster soon completed his Ph.D., joined the faculty, and became the senior member of the group. He wrote \"During the fifteen-year life of the group some sixty persons were members and thirty-four took doctoral degrees with theses connected with its work. In my report I have been unable to separate the work of Slater from that of the group as a whole. He was part of every aspect of the group's research efforts.\"",
                    "score": 0.8437398076057434
                },
                {
                    "id": 22968030,
                    "contents": "Lithium atom\nA lithium atom is an atom of the chemical element lithium. Stable lithium is composed of three electrons bound by the electromagnetic force to a nucleus containing three protons along with either three or four neutrons, depending on the isotope, held together by the strong force. Similarly to the case of the helium atom, a closed-form solution to the Schrödinger equation for the lithium atom has not been found. However, various approximations, such as the Hartree–Fock method, can be used to estimate the ground state energy and wavefunction of the atom. The quantum defect is a value that describes the deviation from hydrogenic energy levels. Further reading W. Zheng et al. / Appl. Math. Comput. 153 (2004) 685–695 \"Numerical solutions of the Schrödinger equation for the ground lithium by the finite element method\" Atoms Lithium",
                    "score": 0.8436002731323242
                },
                {
                    "id": 1620482,
                    "contents": "Bohr model\nThe Bohr model is a relatively primitive model of the hydrogen atom, compared to the valence shell atom model. As a theory, it can be derived as a first-order approximation of the hydrogen atom using the broader and much more accurate quantum mechanics and thus may be considered to be an obsolete scientific theory. However, because of its simplicity, and its correct results for selected systems (see below for application), the Bohr model is still commonly taught to introduce students to quantum mechanics or energy level diagrams before moving on to the more accurate, but more complex, valence shell atom. A related quantum model was originally proposed by Arthur Erich Haas in 1910 but was rejected until the 1911 Solvay Congress where it was thoroughly discussed. The quantum theory of the period between Planck's discovery of the quantum (1900) and the advent of a mature quantum mechanics (1925) is often referred to as the old quantum theory. Origin",
                    "score": 0.8434929251670837
                },
                {
                    "id": 26965779,
                    "contents": "Kate Kirby\nKate Page Kirby is an American physicist. From February 2015 to December 2020, Kirby was the chief executive officer of the American Physical Society (APS) and sits on the board of directors of the American Institute of Physics. Kate Kirby was elected a fellow of the American Physical Society (APS) in 1989 for her \"innovative application of methods of quantum chemistry to the quantitative elucidation of a diverse range of molecular phenomena.\" She was made a fellow of the American Association for the Advancement of Science (AAAS) in 1996 for her contributions to physics. Education Kirby graduated from Harvard University in Cambridge, Massachusetts with a Bachelor of Arts (B.A) in physics and chemistry in 1967. Later she received her MS degree in Chemistry and PhD degree in chemical physics from the University of Chicago in Illinois. The title of her 1972 doctoral thesis is \"Accurate AB initio calculations of energy and properties for ground and excited states of lithium hydride.\"",
                    "score": 0.8434180021286011
                },
                {
                    "id": 8356827,
                    "contents": "Computational chemical methods in solid-state physics\nComputational chemical methods in solid-state physics follow the same approach as they do for molecules, but with two differences. First, the translational symmetry of the solid has to be utilised, and second, it is possible to use completely delocalised basis functions such as plane waves as an alternative to the molecular atom-centered basis functions. The electronic structure of a crystal is in general described by a band structure, which defines the energies of electron orbitals for each point in the Brillouin zone. Ab initio and semi-empirical calculations yield orbital energies, therefore they can be applied to band structure calculations. Since it is time-consuming to calculate the energy for a molecule, it is even more time-consuming to calculate them for the entire list of points in the Brillouin zone.",
                    "score": 0.8431220650672913
                },
                {
                    "id": 6677939,
                    "contents": "Electron configurations of the elements (data page)\nReferences All sources concur with the data above except in the instances listed separately: NIST http://physics.nist.gov/PhysRefData/IonEnergy/ionEnergy.html ; retrieved July 2005, (elements 1–104) based on: Atomic Spectroscopy, by W.C. Martin and W.L. Wiese in Atomic, Molecular, & Optical Physics Handbook, ed. by G.W.F. Drake (AIP, Woodbury, NY, 1996) Chapter 10, pp. 135–153. This website is also cited in the CRC Handbook as source of Section 1, subsection Electron Configuration of Neutral Atoms in the Ground State. 91 Pa : [Rn] 5f2(3H4) 6d 7s2 92 U : [Rn] 5f3(4Io9/2) 6d 7s2 93 Np : [Rn] 5f4(5I4) 6d 7s2 103 Lr : [Rn] 5f14 7s2 7p1 question-marked 104 Rf : [Rn] 5f14 6d2 7s2 question-marked",
                    "score": 0.8431075811386108
                },
                {
                    "id": 12678738,
                    "contents": "Herbert S. Gutowsky\nGutowsky was the first to apply NMR to the field of chemistry. During his first year at the University of Illinois, he obtained funding and built his own NMR spectrometer. Gutowsky's early work included investigations into a number of areas of importance to the development and use of NMR: (1) Gutowsky used NMR to study structure and motion in solids, connecting experimental observations with theoretical models and leading to important breakthroughs in the understanding of molecular structure (2) Gutowsky determined the origin of chemical shifts. (3) Gutowsky discovered spin-spin coupling in molecular liquids and understood its implications for the study of molecular structure (4) Gutowsky used NMR to study mechanisms of chemical exchange and conformational change of molecules.",
                    "score": 0.8428283929824829
                },
                {
                    "id": 26694948,
                    "contents": "Electronic specific heat\nThe alkali metals are expected to have the best agreement with the free electron model since these metals only one s-electron outside a closed shell. However even sodium, which is considered to be the closest to a free electron metal, is determined to have a more than 25 per cent higher than expected from the theory.",
                    "score": 0.8424588441848755
                },
                {
                    "id": 16681015,
                    "contents": "Timeline of quantum mechanics\n1936 – Carl D. Anderson discovers muons while he is studying cosmic radiation. 1937 – Hermann Arthur Jahn and Edward Teller prove, using group theory, that non-linear degenerate molecules are unstable. The Jahn-Teller theorem essentially states that any non-linear molecule with a degenerate electronic ground state will undergo a geometrical distortion that removes that degeneracy, because the distortion lowers the overall energy of the complex. The latter process is called the Jahn-Teller effect; this effect was recently considered also in relation to the superconductivity mechanism in YBCO and other high temperature superconductors. The details of the Jahn-Teller effect are presented with several examples and EPR data in the basic textbook by Abragam and Bleaney (1970). 1938 – Charles Coulson makes the first accurate calculation of a molecular orbital wavefunction with the hydrogen molecule.",
                    "score": 0.8423633575439453
                },
                {
                    "id": 8357411,
                    "contents": "Semi-empirical quantum chemistry method\nMethods that are in the MOPAC, AMPAC, and/or SPARTAN computer programs originally from the group of Michael Dewar. These are MINDO, MNDO, AM1, PM3, RM1 , PM6 and SAM1. Here the objective is to use parameters to fit experimental heats of formation, dipole moments, ionization potentials, and geometries. Methods whose primary aim is to predict the geometries of coordination compounds, such as Sparkle/AM1, available for lanthanide complexes. Methods whose primary aim is to calculate excited states and hence predict electronic spectra. These include ZINDO and SINDO. The latter is the largest group of methods. See also List of quantum chemistry and solid-state physics software References",
                    "score": 0.8422384858131409
                },
                {
                    "id": 2616226,
                    "contents": "John C. Slater\nSlater's papers were bequeathed to the American Philosophical Society by his widow, Rose Mooney Slater, in 1980 and 1982. In August 2003, Alfred Switendick donated a collection of Quarterly Reports of the MIT Solid State and Molecular Theory Group (SSMTG), dating from 1951 to 1965. These are available in several major research libraries. Awards and Honors Irving Langmuir Award (1967) Golden Plate Award of the American Academy of Achievement (1969) National Medal of Science (1970) Books Slater, J. C. (1950). Microwave Electronics. New York: Van Nostrand. References External links Biographical Memoir by Philip M. Morse, includes a photo",
                    "score": 0.8421677350997925
                },
                {
                    "id": 1336536,
                    "contents": "William Lipscomb\n\"Lipscomb and his coworkers developed the idea of transferability of atomic properties, by which approximate theories for complex molecules are developed from more exact calculations for simpler but chemically related molecules,...\" Subsequent Nobel Prize winner Roald Hoffmann was a doctoral student in Lipscomb's laboratory. Under Lipscomb's direction the Extended Hückel method of molecular orbital calculation was developed by Lawrence Lohr and by Roald Hoffmann. This method was later extended by Hoffman. In Lipscomb's laboratory this method was reconciled with self-consistent field (SCF) theory by Newton and by Boer. Noted boron chemist M. Frederick Hawthorne conducted early and continuing research with Lipscomb. Much of this work is summarized in a book by Lipscomb, Boron Hydrides, one of Lipscomb's two books.",
                    "score": 0.8419739007949829
                },
                {
                    "id": 11945098,
                    "contents": "Michelle Francl\nMichelle M. Francl is an American chemist. Francl is a professor of chemistry, and has taught physical chemistry, general chemistry and mathematical modeling at Bryn Mawr College since 1986. Francl is noted for developing new methodology in computational chemistry, including the 6-31G* basis set for Na to Ar and electrostatic potential charges. She received a Ph.D. from the University of California, Irvine in 1983 On a list of the 1000 most cited chemists, Francl is a member of the editorial board for the Journal of Molecular Graphics and Modelling, active in the American Chemical Society and the author of The Survival Guide for Physical Chemistry. In 1994, she was awarded the Christian R. and Mary F. Lindback Award by Bryn Mawr College for excellence in teaching. Francl's podcast, \"Introduction to Quantum Mechanics,\" broke into the iTunes Top 100 in October 2005. She also currently writes for Nature Chemistry.",
                    "score": 0.8407880663871765
                },
                {
                    "id": 15490721,
                    "contents": "Spin states (d electrons)\nd8Octahedral high-spin: 2 unpaired electrons, paramagnetic, substitutionally labile. Includes Ni2+. Example: [Ni(NH3)6]2+. Tetrahedral high-spin: 2 unpaired electrons, paramagnetic, substitutionally labile. Includes Ni2+. Example: [NiCl4]2-. Square planar low-spin: no unpaired electrons, diamagnetic, substitutionally inert. Includes Ni2+. Example: [Ni(CN)4]2−. Ionic radii The spin state of the complex affects an atom's ionic radius. For a given d-electron count, high-spin complexes are larger. d4 Octahedral high spin: Cr2+, 64.5 pm. Octahedral low spin: Mn3+, 58 pm. d5 Octahedral high spin: Fe3+, the ionic radius is 64.5 pm. Octahedral low spin: Fe3+, the ionic radius is 55 pm. d6 Octahedral high spin: Fe2+, the ionic radius is 78 pm, Co3+ ionic radius 61 pm. Octahedral low spin: Includes Fe2+ ionic radius 62 pm, Co3+ ionic radius 54.5 pm, Ni4+ ionic radius 48 pm.",
                    "score": 0.8401555418968201
                },
                {
                    "id": 5606496,
                    "contents": "History of chemistry\nIn 1925, Austrian-born physicist Wolfgang Pauli developed the Pauli exclusion principle, which states that no two electrons around a single nucleus in an atom can occupy the same quantum state simultaneously, as described by four quantum numbers. Pauli made major contributions to quantum mechanics and quantum field theory - he was awarded the 1945 Nobel Prize for Physics for his discovery of the Pauli exclusion principle - as well as solid-state physics, and he successfully hypothesized the existence of the neutrino. In addition to his original work, he wrote masterful syntheses of several areas of physical theory that are considered classics of scientific literature.",
                    "score": 0.840113639831543
                },
                {
                    "id": 5015321,
                    "contents": "Crystal field theory\nThe most common type of complex is octahedral, in which six ligands form the vertices of an octahedron around the metal ion. In octahedral symmetry the d-orbitals split into two sets with an energy difference, Δoct (the crystal-field splitting parameter, also commonly denoted by 10Dq for ten times the \"differential of quanta\") where the dxy, dxz and dyz orbitals will be lower in energy than the dz2 and dx2-y2, which will have higher energy, because the former group is farther from the ligands than the latter and therefore experiences less repulsion. The three lower-energy orbitals are collectively referred to as t2g, and the two higher-energy orbitals as eg. These labels are based on the theory of molecular symmetry: they are the names of irreducible representations of the octahedral point group, Oh.(see the Oh character table) Typical orbital energy diagrams are given below in the section High-spin and low-spin.",
                    "score": 0.8400940895080566
                },
                {
                    "id": 2616200,
                    "contents": "John C. Slater\nSlater joined the Harvard faculty on his return from Europe in 1925, then moved to MIT in 1930. His research papers covered many topics. A year by year selection, up to his switch to work relating to radar includes: 1924: the theoretical part of his Ph.D. work, the Bohr-Kramers-Slater (BKS) theory, 1925: widths of spectral lines; ideas that came very close to the electron spins principle, 1926 and 1927: explicit attention to electron spin, and to the Schrödinger equation; 1928: the Hartree self-consistent field, the Rydberg formula, 1929: the determinantal expression for an antisymmetric wave function, 1930: Slater type orbitals (STOs) and atomic shielding constants, 1931: linear combination of atomic orbitals, van der Waals forces (with Jack Kirkwood, as a Chemistry Research Associate). 1932 to 1935: atomic orbitals, metallic conduction, application of the Thomas–Fermi method to metals,",
                    "score": 0.8400761485099792
                },
                {
                    "id": 29673759,
                    "contents": "Matthias Scheffler\nmodels for the calculation of excited states and electron correlations. The software package FHI-aims developed for this purpose by Scheffler, together with Volker Blum and many others, was specifically designed for large-scale calculations on high-performance computers. Matthias Scheffler has investigated many different classes of materials with high application relevance (e.g. compound semiconductors, metals, oxides, two-dimensional materials, organic materials, surfaces), as well as successfully developing a wide range of phenomena with direct practical relevance (e.g. crystal structure and growth, electronic material properties, metastability of impurities in semiconductors, electrical and thermal conductivity, heterogeneous catalysis).",
                    "score": 0.8399714827537537
                },
                {
                    "id": 705155,
                    "contents": "Livermorium\nIn the periodic table, livermorium is a member of group 16, the chalcogens. It appears below oxygen, sulfur, selenium, tellurium, and polonium. Every previous chalcogen has six electrons in its valence shell, forming a valence electron configuration of ns2np4. In livermorium's case, the trend should be continued and the valence electron configuration is predicted to be 7s27p4; therefore, livermorium will have some similarities to its lighter congeners. Differences are likely to arise; a large contributing effect is the spin–orbit (SO) interaction—the mutual interaction between the electrons' motion and spin. It is especially strong for the superheavy elements, because their electrons move much faster than in lighter atoms, at velocities comparable to the speed of light. In relation to livermorium atoms, it lowers the 7s and the 7p electron energy levels (stabilizing the corresponding electrons), but two of the 7p electron energy levels are stabilized more than the other four. The",
                    "score": 0.8399381637573242
                },
                {
                    "id": 1160524,
                    "contents": "Periodic table\nStarting the next row, for potassium and calcium the 4s orbital is the lowest in energy, and therefore they fill it. Potassium adds one electron to the 4s shell ([Ar] 4s1), and calcium then completes it ([Ar] 4s2). However, starting from scandium the 3d orbital becomes the next highest in energy. The 4s and 3d orbitals are of approximately the same energy and they compete for filling the electrons, and so the occupation is not quite consistently filling the 3d orbitals one at a time. The precise energy ordering of 3d and 4s changes along the row, and also changes depending on how many electrons are removed from the atom. For example, due to the repulsion between the 3d electrons and the 4s ones, at chromium the 4s energy level becomes slightly higher than 3d, and so it becomes more profitable to have a [Ar] 3d5 4s1 configuration than an [Ar] 3d4 4s2 one. A similar anomaly occurs at copper. These are violations of the Madelung rule. Such anomalies however do not have any chemical",
                    "score": 0.8399366736412048
                },
                {
                    "id": 21297764,
                    "contents": "Harry Suhl\nIn 1948, he joined the Bell Telephone Laboratories at Murray Hill, New Jersey. In 1960, he was appointed Professor of Physics at the University of California, San Diego (UCSD) and was promoted to Professor Emeritus in 1991. He was Chairman of the Physics Department of UCSD from 1965 to 1968 and again from 1972 to 1975, and was Director of the university's Institute for Pure and Applied Physical Sciences from 1980 to 1991. Suhl served on the board of editors for Physical Review ('55-'76) and Solid State Communications ('61-'90), and was coeditor of several standard treatises: Magnetism, a Treatise on Modern Theory and Materials (with G.T. Rado, Academic Press, New York, 5 volumes, '63-'72), Superconductivity in d- and f-Band Metals (with M.B. Maple, Academic Press, New York, 1980) and Many Body Phenomena at Surfaces (with D.C. Langreth, Academic Press, New York, 1984).",
                    "score": 0.8398479223251343
                },
                {
                    "id": 1628630,
                    "contents": "Condensed matter physics\nDrude's classical model was augmented by Wolfgang Pauli, Arnold Sommerfeld, Felix Bloch and other physicists. Pauli realized that the free electrons in metal must obey the Fermi–Dirac statistics. Using this idea, he developed the theory of paramagnetism in 1926. Shortly after, Sommerfeld incorporated the Fermi–Dirac statistics into the free electron model and made it better to explain the heat capacity. Two years later, Bloch used quantum mechanics to describe the motion of an electron in a periodic lattice. The mathematics of crystal structures developed by Auguste Bravais, Yevgraf Fyodorov and others was used to classify crystals by their symmetry group, and tables of crystal structures were the basis for the series International Tables of Crystallography, first published in 1935. Band structure calculations was first used in 1930 to predict the properties of new materials, and in 1947 John Bardeen, Walter Brattain and William Shockley developed the first semiconductor-based",
                    "score": 0.8398036956787109
                },
                {
                    "id": 2616212,
                    "contents": "John C. Slater\nImre Cszimadia ‡, molecular calculations (LiH), later Professor of Chemistry, U. Toronto, ab initio calculations, drug design. Jens Dahl ‡, molecular calculations, later Professor of Chemistry, Technical University of Denmark, wrote quantum chemistry text. Donald E. Ellis ৳†, molecular calculations, later Professor of Physics and Astronomy at Northwestern University, \"real\" materials. Arthur Freeman †‡, orthogonalized plane wave calculations, later Professor of Physics and Astronomy at Northwestern University Robert P. Futrelle ৳, programming methods, later Professor of Computer and Information Science at Northeastern University. Leon Gunther †‡ lattice vibrations in alkali halides, later Professor of Physics at Tufts University, focus on condensed matter theory in many areas, including superconductivity and seminal papers on nanoscopic physics & quantum tunneling of magnetization.",
                    "score": 0.8397629261016846
                },
                {
                    "id": 7910165,
                    "contents": "2-Norbornyl cation\nEach peak in an NMR spectrum corresponds to a set of a particular element's atoms that are in similar chemical environments. The NMR spectrum of the antimony chloropentafluoride salt of the 2-norbornyl cation is not helpful at room temperature because hydride shifts occur faster than the timescale of an NMR experiment; most of the hydrogens are thus seen as equivalent and are accounted for in the same absorption peak. By lowering the temperature of the NMR experiment to −60 °C, hydride shifts are \"frozen out\" and more structural information can be gleaned from the spectrum. Researchers found that at these low temperatures, the H NMR spectrum matched what would be expected for the non-classical structure of the ion.",
                    "score": 0.8396639227867126
                },
                {
                    "id": 28771684,
                    "contents": "Linnett double-quartet theory\nThere are seven valence electrons of one spin which occupy two tetrahedra that share a common vertex (purple spheres), and the remaining five valence electrons of the other spin occupy two tetrahedra which share a common face (green spheres). Linnett postulated that this electronic arrangement reduces the magnitude of the inter-electronic repulsions in comparison with the case where the two spin sets have six electrons each. This arrangement results in a bond order of 2 and an excess of one electron spin, giving rise to the molecule's paramagnetism: both observations are in agreement with molecular orbital theory treatments of the molecule. In effect, the LDQ structure is equivalent to the combination of a two-centre one-electron bond (purple spin set) and a two-centre three-electron bond (green spin set).",
                    "score": 0.8396450281143188
                },
                {
                    "id": 22203573,
                    "contents": "Henry D. Hubbard\nHenry D. Hubbard (1870-1943) was a member of the U.S. Bureau of Standards in the 1920s. He modernized Mendeleev's periodic table and in 1924 he produced a version of the Periodic Table of Elements (called the Periodic Chart of the Atoms) which was distributed to schools and universities. His version of the periodic table placed the main groups in columns with some later groups taking up two rows per period and the Group VIIIB transition metals displayed out to the right of the noble gases. The noble gases themselves were shown first in Column 1 (Valence 0) and repeated in Column 9 (Group VIII). The table is also notable for including the solo Neutron as an entry on its own, \"above\" Hydrogen, and given the symbol lower-case 'n'. Gallery The chart was notably present in the laboratory of Glenn T. Seaborg. References",
                    "score": 0.8393682241439819
                },
                {
                    "id": 2155631,
                    "contents": "Nonmetal\nSisler HH 1973, Electronic Structure, Properties, and the Periodic Law, Van Nostrand, New York Smart LE & Moore EA 2012 Solid State Chemistry: An Introduction, 4th ed., CRC Press, Boca Raton, Smith A & Dwyer C 1991, Key Chemistry: Investigating Chemistry in the Contemporary World: Book 1: Materials and Everyday Life, Melbourne University Press, Carlton, Victoria, Smits et al. 2020, Oganesson: A noble gas element that is neither noble nor a gas, Angewandte Chemie International Edition, vol. 59, pp. 23636–23640, Stein L 1969, \"Oxidized radon in halogen fluoride solutions\", Journal of the American Chemical Society, vol. 19, no. 19, Stein L 1983, \"The chemistry of radon\", Radiochimica Acta, vol. 32, Stellman JM (ed.) 1998, Encyclopaedia of Occupational Health and Safety, vol. 4, 4th ed., International Labour Office, Geneva, Steudel R 1977, Chemistry of the Non-metals: With an Introduction to atomic Structure and Chemical Bonding, Walter de Gruyter, Berlin,",
                    "score": 0.8392825722694397
                },
                {
                    "id": 1160521,
                    "contents": "Periodic table\nThe third element, lithium, has no more space in the first shell. Its third electron must thus enter the 2s subshell, giving a 1s2 2s1 configuration. The 2s electron is lithium's only valence electron, as the 1s orbital is now too close to the nucleus to participate chemically. The 2s subshell is completed by the next element beryllium (1s2 2s2). The following elements then proceed to fill up the p-orbitals. Boron (1s2 2s2 2p1) puts its new electron in a 2p orbital; carbon (1s2 2s2 2p2) fills a second 2p orbital; and with nitrogen (1s2 2s2 2p3) all three 2p orbitals become singly occupied. This is consistent with Hund's rule, which states that atoms will prefer to singly occupy each orbital of the same type before filling them with the second electron. Oxygen (1s2 2s2 2p4), fluorine (1s2 2s2 2p5), and neon (1s2 2s2 2p6) then complete the already singly filled 2p orbitals; the last of these fills the second shell completely.",
                    "score": 0.8392276763916016
                },
                {
                    "id": 26351014,
                    "contents": "William J. Evans (chemist)\nEvans is one of the few people to have received the American Chemical Society (ACS) Awards in both Inorganic Chemistry and Organometallic Chemistry. He has also received the Sir Edward Franklin Award and the Centenary Prize of the Royal Society of Chemistry, the Frank Spedding Award for Excellence in the Science and Technology of Rare Earths, the Terrae Rarae Award of the Tage der Seltenen Erden Society in Germany, the Richard C. Tolman Award of the Southern California Section of the ACS, a Special Creativity Extension Award from the National Science Foundation, the UCI Distinguished Faculty Award for Research, and the UCI Physical Sciences Outstanding Contributions to Undergraduate Education Award. He was also honored with UCI’s highest faculty award, the Lauds and Laurels Outstanding Faculty Achievement Award. Recently, he was name Director of the Eddleman Quantum Institute at UCI and has been active in promoting interdisciplinary quantum science. Research",
                    "score": 0.8391786217689514
                },
                {
                    "id": 752962,
                    "contents": "Electron configuration\n{{Blockquote| It should be forbidden for more than one electron with the same value of the main quantum number n to have the same value for the other three quantum numbers k [], j [m] and m [ms].}} The Schrödinger equation, published in 1926, gave three of the four quantum numbers as a direct consequence of its solution for the hydrogen atom: this solution yields the atomic orbitals that are shown today in textbooks of chemistry (and above). The examination of atomic spectra allowed the electron configurations of atoms to be determined experimentally, and led to an empirical rule (known as Madelung's rule (1936), see below) for the order in which atomic orbitals are filled with electrons.",
                    "score": 0.8391386270523071
                },
                {
                    "id": 1115894,
                    "contents": "Ionization energy\nThe graph to the right shows the binding energy for electrons in different shells in neutral atoms. The ionization energy is the lowest binding energy for a particular atom (although these are not all shown in the graph). Solid surfaces: work function Work function is the minimum amount of energy required to remove an electron from a solid surface, where the work function for a given surface is defined by the difference where is the charge of an electron, is the electrostatic potential in the vacuum nearby the surface, and is the Fermi level (electrochemical potential of electrons) inside the material. Note",
                    "score": 0.8391252756118774
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_45",
        "question": "Calculate the melting point of ice under a pressure of 50 bar. Assume that the density of ice under these conditions is approximately $0.92 \\mathrm{~g} \\mathrm{~cm}^{-3}$ and that of liquid water is $1.00 \\mathrm{~g} \\mathrm{~cm}^{-3}$.",
        "golden_answers": [
            " 272.8"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1327772,
                    "contents": "Water\nThe melting and boiling points depend on pressure. A good approximation for the rate of change of the melting temperature with pressure is given by the Clausius–Clapeyron relation: where and are the molar volumes of the liquid and solid phases, and is the molar latent heat of melting. In most substances, the volume increases when melting occurs, so the melting temperature increases with pressure. However, because ice is less dense than water, the melting temperature decreases. In glaciers, pressure melting can occur under sufficiently thick volumes of ice, resulting in subglacial lakes.",
                    "score": 0.9183506965637207
                },
                {
                    "id": 1280689,
                    "contents": "Triple point\nFor those high-pressure forms of ice which can exist in equilibrium with liquid, the diagram shows that melting points increase with pressure. At temperatures above 273 K (0 °C), increasing the pressure on water vapor results first in liquid water and then a high-pressure form of ice. In the range , ice I is formed first, followed by liquid water and then ice III or ice V, followed by other still denser high-pressure forms.",
                    "score": 0.9178205728530884
                },
                {
                    "id": 17146614,
                    "contents": "Pressure melting point\nThe pressure melting point is the temperature at which ice melts at a given pressure. The pressure melting point is nearly a constant 0 °C at pressures above the triple point at 611.7 Pa, where water can exist in only the solid or liquid phases, through atmospheric pressure (100 kPa) until about 10 MPa. With increasing pressure above 10 MPa, the pressure melting point decreases to a minimum of −21.9 °C at 209.9 MPa. Thereafter, the pressure melting point rises rapidly with pressure, passing back through 0 °C at 632.4 MPa.",
                    "score": 0.9154585599899292
                },
                {
                    "id": 1784885,
                    "contents": "Ice\nAn unusual property of water is that its solid form—ice frozen at atmospheric pressure—is approximately 8.3% less dense than its liquid form; this is equivalent to a volumetric expansion of 9%. The density of ice is 0.9167–0.9168 g/cm3 at 0 °C and standard atmospheric pressure (101,325 Pa), whereas water has a density of 0.9998–0.999863 g/cm3 at the same temperature and pressure. Liquid water is densest, essentially 1.00 g/cm3, at 4 °C and begins to lose its density as the water molecules begin to form the hexagonal crystals of ice as the freezing point is reached. This is due to hydrogen bonding dominating the intermolecular forces, which results in a packing of molecules less compact in the solid. Density of ice increases slightly with decreasing temperature and has a value of 0.9340 g/cm3 at −180 °C (93 K).",
                    "score": 0.907593309879303
                },
                {
                    "id": 1784890,
                    "contents": "Ice\nPhases Ice may be any one of the 19 known solid crystalline phases of water, or in an amorphous solid state at various densities. Most liquids under increased pressure freeze at higher temperatures because the pressure helps to hold the molecules together. However, the strong hydrogen bonds in water make it different: for some pressures higher than , water freezes at a temperature below 0 °C, as shown in the phase diagram below. The melting of ice under high pressures is thought to contribute to the movement of glaciers. Ice, water, and water vapour can coexist at the triple point, which is exactly 273.16 K (0.01 °C) at a pressure of 611.657 Pa. The kelvin was in fact defined as of the difference between this triple point and absolute zero, though this definition changed in May 2019. Unlike most other solids, ice is difficult to superheat. In an experiment, ice at −3 °C was superheated to about 17 °C for about 250 picoseconds.",
                    "score": 0.9015750288963318
                },
                {
                    "id": 6040001,
                    "contents": "Ice IX\nIce IX is a form of solid water stable at temperatures below 140 K and pressures between 200 and 400 MPa. It has a tetragonal crystal lattice and a density of 1.16 g/cm3, 26% higher than ordinary ice. It is formed by cooling ice III from 208 K to 165 K (rapidly—to avoid forming ice II). Its structure is identical to ice III other than being hydrogen-ordered. Ordinary water ice is known as ice Ih in the Bridgman nomenclature. Different types of ice, from ice II to ice XIX, have been created in the laboratory at different temperatures and pressures. See also Ice, for other crystalline forms of ice. References Bridgman, P. W. (1937) J. Chem. Phys. 5, 964. External links London South Bank University Report Water ice",
                    "score": 0.8967457413673401
                },
                {
                    "id": 16655835,
                    "contents": "Properties of water\nUnder increasing pressure, ice undergoes a number of transitions to other polymorphs with higher density than liquid water, such as ice II, ice III, high-density amorphous ice (HDA), and very-high-density amorphous ice (VHDA). The unusual density curve and lower density of ice than of water is essential for much of the life on earth—if water were most dense at the freezing point, then in winter the very cold water at the surface of lakes and other water bodies would sink, lakes could freeze from the bottom up, and all life in them would be killed. Furthermore, given that water is a good thermal insulator (due to its heat capacity), some frozen lakes might not completely thaw in summer. The layer of ice that floats on top insulates the water below. Water at about 4 °C (39 °F) also sinks to the bottom, thus keeping the temperature of the water at the bottom constant (see diagram). Density of saltwater and ice",
                    "score": 0.8960038423538208
                },
                {
                    "id": 4676621,
                    "contents": "Ice Ih\nThe latent heat of melting is , and its latent heat of sublimation is . The high latent heat of sublimation is principally indicative of the strength of the hydrogen bonds in the crystal lattice. The latent heat of melting is much smaller, partly because liquid water near 0 °C also contains a significant number of hydrogen bonds. The refractive index of ice Ih is 1.31. Crystal structure",
                    "score": 0.892231822013855
                },
                {
                    "id": 1784888,
                    "contents": "Ice\nWhen ice melts, it absorbs as much energy as it would take to heat an equivalent mass of water by 80 °C. During the melting process, the temperature remains constant at 0 °C. While melting, any energy added breaks the hydrogen bonds between ice (water) molecules. Energy becomes available to increase the thermal energy (temperature) only after enough hydrogen bonds are broken that the ice can be considered liquid water. The amount of energy consumed in breaking hydrogen bonds in the transition from ice to water is known as the heat of fusion.",
                    "score": 0.8878564238548279
                },
                {
                    "id": 1784882,
                    "contents": "Ice\nIce is water frozen into a solid state, typically forming at or below temperatures of 0 degrees Celsius or 32 degrees Fahrenheit. Depending on the presence of impurities such as particles of soil or bubbles of air, it can appear transparent or a more or less opaque bluish-white color. In the Solar System, ice is abundant and occurs naturally from as close to the Sun as Mercury to as far away as the Oort cloud objects. Beyond the Solar System, it occurs as interstellar ice. It is abundant on Earth's surfaceparticularly in the polar regions and above the snow lineand, as a common form of precipitation and deposition, plays a key role in Earth's water cycle and climate. It falls as snowflakes and hail or occurs as frost, icicles or ice spikes and aggregates from snow as glaciers and ice sheets.",
                    "score": 0.887452244758606
                },
                {
                    "id": 893932,
                    "contents": "Melting point\nHere T, ΔS and ΔH are respectively the temperature at the melting point, change of entropy of melting and the change of enthalpy of melting. The melting point is sensitive to extremely large changes in pressure, but generally this sensitivity is orders of magnitude less than that for the boiling point, because the solid-liquid transition represents only a small change in volume. If, as observed in most cases, a substance is more dense in the solid than in the liquid state, the melting point will increase with increases in pressure. Otherwise the reverse behavior occurs. Notably, this is the case of water, as illustrated graphically to the right, but also of Si, Ge, Ga, Bi. With extremely large changes in pressure, substantial changes to the melting point are observed. For example, the melting point of silicon at ambient pressure (0.1 MPa) is 1415 °C, but at pressures in excess of 10 GPa it decreases to 1000 °C.",
                    "score": 0.8869134783744812
                },
                {
                    "id": 16655843,
                    "contents": "Properties of water\nMelting point The melting point of ice is at standard pressure; however, pure liquid water can be supercooled well below that temperature without freezing if the liquid is not mechanically disturbed. It can remain in a fluid state down to its homogeneous nucleation point of about . The melting point of ordinary hexagonal ice falls slightly under moderately high pressures, by /atm or about /70 atm as the stabilization energy of hydrogen bonding is exceeded by intermolecular repulsion, but as ice transforms into its polymorphs (see crystalline states of ice) above , the melting point increases markedly with pressure, i.e., reaching at (triple point of Ice VII). Electrical properties",
                    "score": 0.8854459524154663
                },
                {
                    "id": 13667710,
                    "contents": "Ice VII\nIce VII is a cubic crystalline form of ice. It can be formed from liquid water above 3 GPa (30,000 atmospheres) by lowering its temperature to room temperature, or by decompressing heavy water (D2O) ice VI below 95 K. (Different types of ice, from ice II to ice XVIII, have been created in the laboratory at different temperatures and pressures. Ordinary water ice is known as ice Ih in the Bridgman nomenclature.) Ice VII is metastable over a wide range of temperatures and pressures and transforms into low-density amorphous ice (LDA) above . Ice VII has a triple point with liquid water and ice VI at 355 K and 2.216 GPa, with the melt line extending to at least and 10 GPa. Ice VII can be formed within nanoseconds by rapid compression via shock-waves. It can also be created by increasing the pressure on ice VI at ambient temperature.",
                    "score": 0.884796142578125
                },
                {
                    "id": 6161598,
                    "contents": "Water (data page)\nStandard conditions In the following table, material data are given for standard pressure of 0.1 MPa (equivalent to 1 bar). Up to 99.63 °C (the boiling point of water at 0.1 MPa), at this pressure water exists as a liquid. Above that, it exists as water vapor. Note that the boiling point of 100.0 °C is at a pressure of 0.101325 MPa (1 atm), which is the average atmospheric pressure. Triple point In the following table, material data are given with a pressure of 611.7 Pa (equivalent to 0.006117 bar). Up to a temperature of 0.01 °C, the triple point of water, water normally exists as ice, except for supercooled water, for which one data point is tabulated here. At the triple point, ice can exist together with both liquid water and vapor. At higher temperatures, the data are for water vapor only. Saturated vapor pressure",
                    "score": 0.8846191167831421
                },
                {
                    "id": 218458,
                    "contents": "Supercooling\nWater normally freezes at 273.15 K (0 °C or 32 °F), but it can be \"supercooled\" at standard pressure down to its crystal homogeneous nucleation at almost 224.8 K (−48.3 °C/−55 °F). The process of supercooling requires that water be pure and free of nucleation sites, which can be achieved by processes like reverse osmosis or chemical demineralization, but the cooling itself does not require any specialised technique. If water is cooled at a rate on the order of 106 K/s, the crystal nucleation can be avoided and water becomes a glass—that is, an amorphous (non-crystalline) solid. Its glass transition temperature is much colder and harder to determine, but studies estimate it at about 136 K (−137 °C/−215 °F). Glassy water can be heated up to approximately 150 K (−123 °C/−189.4 °F) without nucleation occurring. In the range of temperatures between 231 K (−42 °C/−43.6 °F) and 150 K (−123 °C/−189.4 °F), experiments find only crystal ice.",
                    "score": 0.8829920291900635
                },
                {
                    "id": 13685176,
                    "contents": "Ice VIII\nIce VIII is a tetragonal crystalline form of ice formed from ice VII by cooling it below 5 °C. It is more ordered than ice VII, since the hydrogen atoms assume fixed positions. Ordinary water ice is known as ice Ih, (in the Bridgman nomenclature). Different types of ice, from ice II to ice XVIII, have been created in the laboratory at different temperatures and pressures. See also Ice, for other crystalline forms of ice References Water ice",
                    "score": 0.8829919695854187
                },
                {
                    "id": 13684857,
                    "contents": "Ice V\nIce V, pronounced \"ice five\", is a monoclinic crystalline phase of water, formed by cooling water to 253 K at 500 MPa. It has a density of 1.24 g cm3 (at 350 MPa). Ice V has a complicated structure, including 4-membered, 5-membered, 6-membered, and 8-membered rings and a total of 28 molecules in the unit cell. Ganymede's interior probably includes a liquid water ocean with tens to hundreds of kilometers of ice V at its base. References Water ice",
                    "score": 0.8824295401573181
                },
                {
                    "id": 1280687,
                    "contents": "Triple point\nThe gas–liquid–solid triple point of water corresponds to the minimum pressure at which liquid water can exist. At pressures below the triple point (as in outer space), solid ice when heated at constant pressure is converted directly into water vapor in a process known as sublimation. Above the triple point, solid ice when heated at constant pressure first melts to form liquid water, and then evaporates or boils to form vapor at a higher temperature. For most substances the gas–liquid–solid triple point is also the minimum temperature at which the liquid can exist. For water, however, this is not true because the melting point of ordinary ice decreases as a function of pressure, as shown by the dashed green line in the phase diagram. At temperatures just below the triple point, compression at constant temperature transforms water vapor first to solid and then to liquid (water ice has lower density than liquid water, so increasing pressure leads to a liquefaction).",
                    "score": 0.8821313977241516
                },
                {
                    "id": 7509980,
                    "contents": "Amorphous ice\nAmorphous ice (non-crystalline or \"vitreous\" ice) is an amorphous solid form of water. Common ice is a crystalline material wherein the molecules are regularly arranged in a hexagonal lattice, whereas amorphous ice has a lack of long-range order in its molecular arrangement. Amorphous ice is produced either by rapid cooling of liquid water (so the molecules do not have enough time to form a crystal lattice), or by compressing ordinary ice at low temperatures. Although almost all water ice on Earth is the familiar crystalline ice Ih, amorphous ice dominates in the depths of interstellar medium, making this likely the most common structure for H2O in the universe at large. Just as there are many different crystalline forms of ice (currently more than seventeen are known), there are also different forms of amorphous ice, distinguished principally by their densities.",
                    "score": 0.8818538188934326
                },
                {
                    "id": 12488026,
                    "contents": "Ice III\nIce III is a form of solid matter which consists of tetragonal crystalline ice, formed by cooling water down to at . It is the least dense of the high-pressure water phases, with a density of (at 350 MPa). The proton-ordered form of is ice IX. Ordinary water ice is known as , (in the Bridgman nomenclature). Different types of ice, from ice II to ice XVIII, have been created in the laboratory at different temperatures and pressures. See also Ice, for other crystalline forms of ice References Water ice",
                    "score": 0.8810738325119019
                },
                {
                    "id": 6161594,
                    "contents": "Water (data page)\nFor T = 273 K to 333 K: A = 7.2326; B = 1750.286; C = 38.1. For T = 333 K to 423 K: A = 7.0917; B = 1668.21; C = 45.1. Data in the table above is given for water–steam equilibria at various temperatures over the entire temperature range at which liquid water can exist. Pressure of the equilibrium is given in the second column in kPa. The third column is the heat content of each gram of the liquid phase relative to water at 0 °C. The fourth column is the heat of vaporization of each gram of liquid that changes to vapor. The fifth column is the work PΔV done by each gram of liquid that changes to vapor. The sixth column is the density of the vapor. Melting point of ice at various pressures Data obtained from CRC Handbook of Chemistry and Physics 44th ed., p. 2390 Table of various forms of ice ‡Ice XI triple point is theoretical and has never been obtained Phase diagram Water with dissolved NaCl",
                    "score": 0.8791018724441528
                },
                {
                    "id": 13684885,
                    "contents": "Ice VI\nIce VI is a form of ice that exists at high pressure at the order of about 1 GPa (= 10 000 bar) and temperatures ranging from 130 up to 355 Kelvin (−143°C up to 82°C); see also the phase diagram of water. Its discovery and the discovery of other high pressure forms of water was published by P.W. Bridgman in January 1912. It is part of one of the inner layers of Titan. Properties Ice VI has a density of 1.31 g/cm3 and a tetragonal crystal system with the space group P42/nmc; its unit cell contains 10 water molecules and has the dimensions a=6.27 Å and c=5.79 Å. The triple point of ice VI with ice VII and liquid water is at about 82°C and 2.22 GPa and its triple point with ice V and liquid water is at 0.16°C and 0.6324 GPa = 6324 bar. See also Ice phases (overview) External links Physik des Eises (PDF in German, iktp.tu-dresden.de) Ice phases (www.idc-online.com) References Water ice",
                    "score": 0.8788999319076538
                },
                {
                    "id": 1784892,
                    "contents": "Ice\nAs well as crystalline forms, solid water can exist in amorphous states as amorphous ice (ASW) of varying densities. Water in the interstellar medium is dominated by amorphous ice, making it likely the most common form of water in the universe. Low-density ASW (LDA), also known as hyperquenched glassy water, may be responsible for noctilucent clouds on Earth and is usually formed by deposition of water vapor in cold or vacuum conditions. High-density ASW (HDA) is formed by compression of ordinary ice Ih or LDA at GPa pressures. Very-high-density ASW (VHDA) is HDA slightly warmed to 160K under 1–2 GPa pressures.",
                    "score": 0.8788466453552246
                },
                {
                    "id": 6895992,
                    "contents": "Regelation\nRegelation was discovered by Michael Faraday. It occurs only for substances such as ice, that have the property of expanding upon freezing, for the melting points of those substances decrease with the increasing external pressure. The melting point of ice falls by 0.0072 °C for each additional atm of pressure applied. For example, a pressure of 500 atmospheres is needed for ice to melt at −4 °C. Surface melting For a normal crystalline ice far below its melting point, there will be some relaxation of the atoms near the surface. Simulations of ice near to its melting point show that there is significant melting of the surface layers rather than a symmetric relaxation of atom positions. Nuclear magnetic resonance provided evidence for a liquid layer on the surface of ice. In 1998, using atomic force microscopy, Astrid Döppenschmidt and Hans-Jürgen Butt measured the thickness of the liquid-like layer on ice to be roughly 32 nm at −1 °C, and 11 nm at −10 °C.",
                    "score": 0.8779659271240234
                },
                {
                    "id": 8451,
                    "contents": "Ice XII\nIce XII is a metastable, dense, crystalline phase of solid water, a type of ice. Ice XII was first reported in 1996 by C. Lobban, J.L. Finney and W.F. Kuhs and, after initial caution, was properly identified in 1998. It was first obtained by cooling liquid water to at a pressure of . Ice XII was discovered existing within the phase stability region of ice V. Later research showed that ice XII could be created outside that range. Pure ice XII can be created from ice Ih at by rapid compression (0.81-1.00 GPa/min) or by warming high density amorphous ice at pressures between . The proton-ordered form of ice XII is ice XIV. While it is similar in density (1.29 g/cm3 at ) to ice IV (also found in the ice V space) it exists as a tetragonal crystal. Topologically it is a mix of seven- and eight-membered rings, a 4-connected net (4-coordinate sphere packing)—the densest possible arrangement without hydrogen bond interpenetration.",
                    "score": 0.8774020671844482
                },
                {
                    "id": 1121123,
                    "contents": "Melting\nSupercooling Under a standard set of conditions, the melting point of a substance is a characteristic property. The melting point is often equal to the freezing point. However, under carefully created conditions, supercooling, or superheating past the melting or freezing point can occur. Water on a very clean glass surface will often supercool several degrees below the freezing point without freezing. Fine emulsions of pure water have been cooled to −38 °C without nucleation to form ice. Nucleation occurs due to fluctuations in the properties of the material. If the material is kept still there is often nothing (such as physical vibration) to trigger this change, and supercooling (or superheating) may occur. Thermodynamically, the supercooled liquid is in the metastable state with respect to the crystalline phase, and it is likely to crystallize suddenly.",
                    "score": 0.8747388124465942
                },
                {
                    "id": 13684544,
                    "contents": "Ice II\nHistory The properties of ice II were first described and recorded by Gustav Heinrich Johann Apollon Tammann in 1900 during his experiments with ice under high pressure and low temperatures. Having produced ice III, Tammann then tried condensing the ice at a temperature between under of pressure. Tammann noted that in this state ice II was denser than he had observed ice III to be. He also found that both types of ice can be kept at normal atmospheric pressure in a stable condition so long as the temperature is kept at that of liquid air, which slows the change in conformation back to ice Ih.",
                    "score": 0.873687207698822
                },
                {
                    "id": 16655841,
                    "contents": "Properties of water\nVapor pressure Compressibility The compressibility of water is a function of pressure and temperature. At 0 °C, at the limit of zero pressure, the compressibility is . At the zero-pressure limit, the compressibility reaches a minimum of around 45 °C before increasing again with increasing temperature. As the pressure is increased, the compressibility decreases, being at 0 °C and . The bulk modulus of water is about 2.2 GPa. The low compressibility of non-gases, and of water in particular, leads to their often being assumed as incompressible. The low compressibility of water means that even in the deep oceans at 4 km depth, where pressures are 40 MPa, there is only a 1.8% decrease in volume. The bulk modulus of water ice ranges from 11.3 GPa at 0 K up to 8.6 GPa at 273 K. The large change in the compressibility of ice as a function of temperature is the result of its relatively large thermal expansion coefficient compared to other common solids. Triple point",
                    "score": 0.8729403018951416
                },
                {
                    "id": 1784883,
                    "contents": "Ice\nIce exhibits at least eighteen phases (packing geometries), depending on temperature and pressure. When water is cooled rapidly (quenching), up to three types of amorphous ice can form depending on its history of pressure and temperature. When cooled slowly, correlated proton tunneling occurs below (, ) giving rise to macroscopic quantum phenomena. Virtually all ice on Earth's surface and in its atmosphere is of a hexagonal crystalline structure denoted as ice Ih (spoken as \"ice one h\") with minute traces of cubic ice, denoted as ice Ic and, more recently found, Ice VII inclusions in diamonds. The most common phase transition to ice Ih occurs when liquid water is cooled below (, ) at standard atmospheric pressure. It may also be deposited directly by water vapor, as happens in the formation of frost. The transition from ice to water is melting and from ice directly to water vapor is sublimation.",
                    "score": 0.8727368712425232
                },
                {
                    "id": 905505,
                    "contents": "Thermodynamic temperature\nAt one specific thermodynamic point, the melting point (which is 0 °C across a wide pressure range in the case of water), all the atoms or molecules are, on average, at the maximum energy threshold their chemical bonds can withstand without breaking away from the lattice. Chemical bonds are all-or-nothing forces: they either hold fast, or break; there is no in-between state. Consequently, when a substance is at its melting point, every joule of added thermal energy only breaks the bonds of a specific quantity of its atoms or molecules, converting them into a liquid of precisely the same temperature; no kinetic energy is added to translational motion (which is what gives substances their temperature). The effect is rather like popcorn: at a certain temperature, additional thermal energy can't make the kernels any hotter until the transition (popping) is complete. If the process is reversed (as in the freezing of a liquid), thermal energy must be removed from a substance.",
                    "score": 0.8724659085273743
                },
                {
                    "id": 893919,
                    "contents": "Melting point\nThe melting point (or, rarely, liquefaction point) of a substance is the temperature at which it changes state from solid to liquid. At the melting point the solid and liquid phase exist in equilibrium. The melting point of a substance depends on pressure and is usually specified at a standard pressure such as 1 atmosphere or 100 kPa. When considered as the temperature of the reverse change from liquid to solid, it is referred to as the freezing point or crystallization point. Because of the ability of substances to supercool, the freezing point can easily appear to be below its actual value. When the \"characteristic freezing point\" of a substance is determined, in fact, the actual methodology is almost always \"the principle of observing the disappearance rather than the formation of ice, that is, the melting point.\" Examples",
                    "score": 0.8716676235198975
                },
                {
                    "id": 16655834,
                    "contents": "Properties of water\nDensity of water and ice The density of water is about : this relationship was originally used to define the gram. The density varies with temperature, but not linearly: as the temperature increases, the density rises to a peak at and then decreases; this is unusual. Regular, hexagonal ice is also less dense than liquid water—upon freezing, the density of water decreases by about 9%. These effects are due to the reduction of thermal motion with cooling, which allows water molecules to form more hydrogen bonds that prevent the molecules from coming close to each other. In the range 0-4 °C the breakage of hydrogen bonds due to heating allows water molecules to pack closer despite the increase in the thermal motion (which tends to expand a liquid), above 4 °C water expands as the temperature increases. Water near the boiling point is about 4% less dense than water at .",
                    "score": 0.8706727027893066
                },
                {
                    "id": 13685627,
                    "contents": "Ice XV\nIce XV is a crystalline form of ice, the proton-ordered form of ice VI. It is created by cooling water to around 130 K at 1 GPa (9820 atm). Ordinary water ice is known as ice Ih, (in the Bridgman nomenclature). Different types of ice, from ice II to ice XVI, have been created in the laboratory at different temperatures and pressures. On 14 June 2009, Christoph Salzmann at the University of Oxford and colleagues reported having created ice XV and say that its properties differ significantly from those predicted. In particular, ice XV is antiferroelectric rather than ferroelectric as had been predicted. References Water ice",
                    "score": 0.8704348802566528
                },
                {
                    "id": 6161595,
                    "contents": "Water (data page)\nTable of various forms of ice ‡Ice XI triple point is theoretical and has never been obtained Phase diagram Water with dissolved NaCl Note: ρ is density, n is refractive index at 589 nm, and η is viscosity, all at 20 °C; Teq is the equilibrium temperature between two phases: ice/liquid solution for Teq < 0–0.1 °C and NaCl/liquid solution for Teq above 0.1 °C. Self-ionization Spectral data Self-diffusion coefficients Additional data translated from German \"Wasser (Stoffdaten)\" page The data that follows was copied and translated from the German language Wikipedia version of this page (which has moved to here). It provides supplementary physical, thermodynamic, and vapor pressure data, some of which is redundant with data in the tables above, and some of which is additional. Physical and thermodynamic tables",
                    "score": 0.8695085048675537
                },
                {
                    "id": 8452,
                    "contents": "Ice XII\nOrdinary water ice is known as ice Ih, (in the Bridgman nomenclature). Different types of ice, from ice II to ice XVI, have been created in the laboratory at different temperatures and pressures. See also Ice for other crystalline form of ice References C. Lobban, J.L. Finney and W.F. Kuhs, The structure of a new phase of ice, Nature 391, 268-270, 1998 Water ice",
                    "score": 0.8692711591720581
                },
                {
                    "id": 2714725,
                    "contents": "Ice core\nis 95 m and the age 2500 years. As further layers build up, the pressure increases, and at about 1500 m the crystal structure of the ice changes from hexagonal to cubic, allowing air molecules to move into the cubic crystals and form a clathrate. The bubbles disappear and the ice becomes more transparent.",
                    "score": 0.8691413998603821
                },
                {
                    "id": 13684547,
                    "contents": "Ice II\nSee also Ice, for other crystalline forms of ice References Water ice",
                    "score": 0.8691203594207764
                },
                {
                    "id": 18252933,
                    "contents": "Gibbs–Thomson equation\nThe Gibbs–Thomson effect lowers both melting and freezing point, and also raises boiling point. However, simple cooling of an all-liquid sample usually leads to a state of non-equilibrium super cooling and only eventual non-equilibrium freezing. To obtain a measurement of the equilibrium freezing event, it is necessary to first cool enough to freeze a sample with excess liquid outside the pores, then warm the sample until the liquid in the pores is all melted, but the bulk material is still frozen. Then, on re-cooling the equilibrium freezing event can be measured, as the external ice will then grow into the pores. This is in effect an \"ice intrusion\" measurement (cf. mercury intrusion), and as such in part may provide information on pore throat properties. The melting event can be expected to provide more accurate information on the pore body.",
                    "score": 0.8671544790267944
                },
                {
                    "id": 6161601,
                    "contents": "Water (data page)\nFormulas The table values for −100 °C to 100 °C were computed by the following formulas, where T is in kelvins and vapor pressures, Pw and Pi, are in pascals. Over liquid water loge(Pw) = −6094.4642 T−1 + 21.1249952 − 2.724552×10−2 T + 1.6853396×10−5 T2 + 2.4575506 loge(T) For temperature range: 173.15 K to 373.15 K or equivalently −100 °C to 100 °C Over ice loge(Pi) = −5504.4088 T−1 − 3.5704628 − 1.7337458×10−2 T + 6.5204209×10−6 T2 + 6.1295027 loge(T) For temperature range: 173.15 K to 273.15 K or equivalently −100 °C to 0 °C At triple point An important basic value, which is not registered in the table, is the saturated vapor pressure at the triple point of water. The internationally accepted value according to measurements of Guildner, Johnson and Jones (1976) amounts to: Pw(ttp = 0.01 °C) = 611.657 Pa ± 0.010 Pa at (1 − α) = 99% Magnetic susceptibility Accepted standardized value of the magnetic susceptibility of water at 20 °C (room temperature) is −12.97 cm3/mol.",
                    "score": 0.8668180704116821
                },
                {
                    "id": 11745462,
                    "contents": "Biology\nWater is denser as a liquid than it is as a solid (or ice). This unique property of water allows ice to float above liquid water such as ponds, lakes, and oceans, thereby insulating the liquid below from the cold air above. The lower density of ice compared to liquid water is due to the lower number of water molecules that form the crystal lattice structure of ice, which leaves a large amount of space between water molecules. In contrast, there is no crystal lattice structure in liquid water, which allows more water molecules to occupy the same amount of volume. Water also has the capacity to absorb energy, giving it a higher specific heat capacity than other solvents such as ethanol. Thus, a large amount of energy is needed to break the hydrogen bonds between water molecules to convert liquid water into gas (or water vapor).",
                    "score": 0.8658615350723267
                },
                {
                    "id": 905527,
                    "contents": "Thermodynamic temperature\n1802: Joseph Louis Gay-Lussac (1778–1850) published work (acknowledging the unpublished lab notes of Jacques Charles fifteen years earlier) describing how the volume of gas under constant pressure changes linearly with its absolute (thermodynamic) temperature. This behavior is called Charles's Law and is one of the gas laws. His are the first known formulas to use the number 273 for the expansion coefficient of gas relative to the melting point of ice (indicating that absolute zero was equivalent to −273 °C).",
                    "score": 0.8656373023986816
                },
                {
                    "id": 17780736,
                    "contents": "Liquid\nAt a temperature below the freezing point, a liquid will tend to crystallize, changing to its solid form. Unlike the transition to gas, there is no equilibrium at this transition under constant pressure, so unless supercooling occurs, the liquid will eventually completely crystallize. However, this is only true under constant pressure, so that (for example) water and ice in a closed, strong container might reach an equilibrium where both phases coexist. For the opposite transition from solid to liquid, see melting.",
                    "score": 0.8653324246406555
                },
                {
                    "id": 2401593,
                    "contents": "Jean-André Deluc\nDeluc noticed the disappearance of heat in the thawing of ice about the same time that Joseph Black made it the foundation of his hypothesis of latent heat. He ascertained that water was densest at about 5 °C (and not at the freezing temperature). He was the originator of the theory, later reactivated by John Dalton, that the quantity of water vapour contained in any space is independent of the presence or density of the air, or of any other elastic fluid.",
                    "score": 0.8649322986602783
                },
                {
                    "id": 893920,
                    "contents": "Melting point\nExamples For most substances, melting and freezing points are approximately equal. For example, the melting point and freezing point of mercury is . However, certain substances possess differing solid-liquid transition temperatures. For example, agar melts at and solidifies from ; such direction dependence is known as hysteresis. The melting point of ice at 1 atmosphere of pressure is very close to ; this is also known as the ice point. In the presence of nucleating substances, the freezing point of water is not always the same as the melting point. In the absence of nucleators water can exist as a supercooled liquid down to before freezing.",
                    "score": 0.8643143177032471
                },
                {
                    "id": 905530,
                    "contents": "Thermodynamic temperature\nCirca 1930s: Gas thermometry experiments carefully calibrated to the melting point of ice and boiling point of water showed that absolute zero was equivalent to −273.15 °C. 1948: Resolution 3 of the 9th CGPM (Conférence Générale des Poids et Mesures, also known as the General Conference on Weights and Measures) fixed the triple point of water at precisely 0.01 °C. At this time, the triple point still had no formal definition for its equivalent kelvin value, which the resolution declared \"will be fixed at a later date\". The implication is that if the value of absolute zero measured in the 1930s was truly −273.15 °C, then the triple point of water (0.01 °C) was equivalent to 273.16 K. Additionally, both the CIPM (Comité international des poids et mesures, also known as the International Committee for Weights and Measures) and the CGPM formally adopted the name Celsius for the degree Celsius and the Celsius temperature scale.",
                    "score": 0.8641327619552612
                },
                {
                    "id": 905506,
                    "contents": "Thermodynamic temperature\nAs stated above, the thermal energy required for a phase transition is called latent heat. In the specific cases of melting and freezing, it's called enthalpy of fusion or heat of fusion. If the molecular bonds in a crystal lattice are strong, the heat of fusion can be relatively great, typically in the range of 6 to 30 kJ per mole for water and most of the metallic elements. If the substance is one of the monatomic gases, (which have little tendency to form molecular bonds) the heat of fusion is more modest, ranging from 0.021 to 2.3 kJ per mole. Relatively speaking, phase transitions can be truly energetic events. To completely melt ice at 0 °C into water at 0 °C, one must add roughly 80 times the thermal energy as is required to increase the temperature of the same mass of liquid water by one degree Celsius. The metals' ratios are even greater, typically in the range of 400 to 1200 times. And the phase transition of boiling is much more energetic than freezing. For instance, the",
                    "score": 0.8640812635421753
                },
                {
                    "id": 10661355,
                    "contents": "Introduction to entropy\nExample of increasing entropy Ice melting provides an example in which entropy increases in a small system, a thermodynamic system consisting of the surroundings (the warm room) and the entity of glass container, ice and water which has been allowed to reach thermodynamic equilibrium at the melting temperature of ice. In this system, some heat (δQ) from the warmer surroundings at 298 K (25 °C; 77 °F) transfers to the cooler system of ice and water at its constant temperature (T) of 273 K (0 °C; 32 °F), the melting temperature of ice. The entropy of the system, which is , increases by . The heat δQ for this process is the energy required to change water from the solid state to the liquid state, and is called the enthalpy of fusion, i.e. ΔH for ice fusion.",
                    "score": 0.8630290031433105
                },
                {
                    "id": 905504,
                    "contents": "Thermodynamic temperature\nEven though thermal energy is liberated or absorbed during phase transitions, pure chemical elements, compounds, and eutectic alloys exhibit no temperature change whatsoever while they undergo them (see Fig. 7, below right). Consider one particular type of phase transition: melting. When a solid is melting, crystal lattice chemical bonds are being broken apart; the substance is transitioning from what is known as a more ordered state to a less ordered state. In Fig. 7, the melting of ice is shown within the lower left box heading from blue to green.",
                    "score": 0.8629006147384644
                },
                {
                    "id": 1327776,
                    "contents": "Water\nPhases of ice and water The normal form of ice on the surface of Earth is Ice Ih, a phase that forms crystals with hexagonal symmetry. Another with cubic crystalline symmetry, Ice Ic, can occur in the upper atmosphere. As the pressure increases, ice forms other crystal structures. As of 2019, 17 have been experimentally confirmed and several more are predicted theoretically. The 18th form of ice, ice XVIII, a face-centred-cubic, superionic ice phase, was discovered when a droplet of water was subject to a shock wave that raised the water’s pressure to millions of atmospheres and its temperature to thousands of degrees, resulting in a structure of rigid oxygen atoms in which hydrogen atoms flowed freely. When sandwiched between layers of graphene, ice forms a square lattice. The details of the chemical nature of liquid water are not well understood; some theories suggest that its unusual behaviour is due to the existence of 2 liquid states.",
                    "score": 0.8626425266265869
                },
                {
                    "id": 4676626,
                    "contents": "Ice Ih\nUsing Boltzmann's principle, we conclude that where is the Boltzmann constant, which yields a value of 3.37 J mol−1 K−1, a value very close to the measured value. This estimate is 'naive', as it assumes the six out of 16 hydrogen configurations for oxygen atoms in the second set can be independently chosen, which is false. More complex methods can be employed to better approximate the exact number of possible configurations, and achieve results closer to measured values. By contrast, the structure of ice II is hydrogen-ordered, which helps to explain the entropy change of 3.22 J/mol when the crystal structure changes to that of ice I. Also, ice XI, an orthorhombic, hydrogen-ordered form of ice Ih, is considered the most stable form at low temperatures. See also Ice, for other crystalline forms of ice References Further reading Water ice",
                    "score": 0.8620880246162415
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_46",
        "question": "What is the temperature of a two-level system of energy separation equivalent to $400 \\mathrm{~cm}^{-1}$ when the population of the upper state is one-third that of the lower state?",
        "golden_answers": [
            " 524"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 92609,
                    "contents": "Ground state\nAccording to the third law of thermodynamics, a system at absolute zero temperature exists in its ground state; thus, its entropy is determined by the degeneracy of the ground state. Many systems, such as a perfect crystal lattice, have a unique ground state and therefore have zero entropy at absolute zero. It is also possible for the highest excited state to have absolute zero temperature for systems that exhibit negative temperature. Absence of nodes in one dimension In one dimension, the ground state of the Schrödinger equation can be proven to have no nodes. Derivation Consider the average energy of a state with a node at ; i.e., . The average energy in this state would be where is the potential. With integration by parts: Hence in case that is equal to zero, one gets:",
                    "score": 0.8907657861709595
                },
                {
                    "id": 9840979,
                    "contents": "Fundamental thermodynamic relation\nsuch energy eigenstates. If , all these energy eigenstates will move into the range between and and contribute to an increase in . The number of energy eigenstates that move from below to above is, of course, given by . The difference is thus the net contribution to the increase in . Note that if Y dx is larger than there will be energy eigenstates that move from below to above . They are counted in both and , therefore the above expression is also valid in that case. Expressing the above expression as a derivative with respect to E and summing over Y yields the expression: The logarithmic derivative of with respect to x is thus given by: The first term is intensive, i.e. it does not scale with system size. In contrast, the last term scales as the inverse system size and thus vanishes in the thermodynamic limit. We have thus found that: Combining this with Gives: which we can write as:",
                    "score": 0.8853822946548462
                },
                {
                    "id": 6545917,
                    "contents": "Second law of thermodynamics\nsuch energy eigenstates. If , all these energy eigenstates will move into the range between and and contribute to an increase in . The number of energy eigenstates that move from below to above is given by . The difference is thus the net contribution to the increase in . Note that if Y dx is larger than there will be the energy eigenstates that move from below E to above . They are counted in both and , therefore the above expression is also valid in that case. Expressing the above expression as a derivative with respect to E and summing over Y yields the expression: The logarithmic derivative of with respect to x is thus given by: The first term is intensive, i.e. it does not scale with system size. In contrast, the last term scales as the inverse system size and will thus vanish in the thermodynamic limit. We have thus found that: Combining this with Gives:",
                    "score": 0.8848267793655396
                },
                {
                    "id": 1568569,
                    "contents": "Absolute zero\nIt is commonly thought of as the lowest temperature possible, but it is not the lowest enthalpy state possible, because all real substances begin to depart from the ideal gas when cooled as they approach the change of state to liquid, and then to solid; and the sum of the enthalpy of vaporization (gas to liquid) and enthalpy of fusion (liquid to solid) exceeds the ideal gas's change in enthalpy to absolute zero. In the quantum-mechanical description, matter (solid) at absolute zero is in its ground state, the point of lowest internal energy.",
                    "score": 0.8830102682113647
                },
                {
                    "id": 1867377,
                    "contents": "Metastability\nA metastable state is then long-lived (locally stable with respect to configurations of 'neighbouring' energies) but not eternal (as the global minimum is). Being excited – of an energy above the ground state – it will eventually decay to a more stable state, releasing energy. Indeed, above absolute zero, all states of a system have a non-zero probability to decay; that is, to spontaneously fall into another state (usually lower in energy). One mechanism for this to happen is through tunnelling. Nuclear physics Some energetic states of an atomic nucleus (having distinct spatial mass, charge, spin, isospin distributions) are much longer-lived than others (nuclear isomers of the same isotope), e.g. technetium-99m. The isotope tantalum-180m, although being a metastable excited state, is long-lived enough that it has never been observed to decay, with a half-life calculated to be least years, over 3 million times the current age of the universe.",
                    "score": 0.8814427852630615
                },
                {
                    "id": 22245912,
                    "contents": "Quantum thermodynamics\nThe second law of thermodynamics can be interpreted as quantifying state transformations which are statistically unlikely so that they become effectively forbidden. The second law typically applies to systems composed of many particles interacting; Quantum thermodynamics resource theory is a formulation of thermodynamics in the regime where it can be applied to a small number of particles interacting with a heat bath. For processes which are cyclic or very close to cyclic, the second law for microscopic systems takes on a very different form than it does at the macroscopic scale, imposing not just one constraint on what state transformations are possible, but an entire family of constraints. These second laws are not only relevant for small systems, but also apply to individual macroscopic systems interacting via long-range interactions, which only satisfy the ordinary second law on average. By making precise the definition of thermal operations, the laws of thermodynamics take on a",
                    "score": 0.8798194527626038
                },
                {
                    "id": 884651,
                    "contents": "Zero-point energy\nIf more than one ground state exists, they are said to be degenerate. Many systems have degenerate ground states. Degeneracy occurs whenever there exists a unitary operator which acts non-trivially on a ground state and commutes with the Hamiltonian of the system. According to the third law of thermodynamics, a system at absolute zero temperature exists in its ground state; thus, its entropy is determined by the degeneracy of the ground state. Many systems, such as a perfect crystal lattice, have a unique ground state and therefore have zero entropy at absolute zero. It is also possible for the highest excited state to have absolute zero temperature for systems that exhibit negative temperature. The wave function of the ground state of a particle in a one-dimensional well is a half-period sine wave which goes to zero at the two edges of the well. The energy of the particle is given by:",
                    "score": 0.879487156867981
                },
                {
                    "id": 1568570,
                    "contents": "Absolute zero\nThe laws of thermodynamics indicate that absolute zero cannot be reached using only thermodynamic means, because the temperature of the substance being cooled approaches the temperature of the cooling agent asymptotically, and a system at absolute zero still possesses quantum mechanical zero-point energy, the energy of its ground state at absolute zero. The kinetic energy of the ground state cannot be removed. Scientists and technologists routinely achieve temperatures close to absolute zero, where matter exhibits quantum effects such as Bose–Einstein condensate, superconductivity and superfluidity.",
                    "score": 0.8790236711502075
                },
                {
                    "id": 15576758,
                    "contents": "Temperature\nThe microscopic description in statistical mechanics is based on a model that analyzes a system into its fundamental particles of matter or into a set of classical or quantum-mechanical oscillators and considers the system as a statistical ensemble of microstates. As a collection of classical material particles, the temperature is a measure of the mean energy of motion, called translational kinetic energy, of the particles, whether in solids, liquids, gases, or plasmas. The kinetic energy, a concept of classical mechanics, is half the mass of a particle times its speed squared. In this mechanical interpretation of thermal motion, the kinetic energies of material particles may reside in the velocity of the particles of their translational or vibrational motion or in the inertia of their rotational modes. In monatomic perfect gases and, approximately, in most gas and in simple metals, the temperature is a measure of the mean particle translational kinetic energy, 3/2 kBT. It also",
                    "score": 0.878372311592102
                },
                {
                    "id": 3384392,
                    "contents": "Excited state\nIn quantum mechanics, an excited state of a system (such as an atom, molecule or nucleus) is any quantum state of the system that has a higher energy than the ground state (that is, more energy than the absolute minimum). Excitation refers to an increase in energy level above a chosen starting point, usually the ground state but sometimes an already-excited state. The temperature of a group of particles is indicative of the level of excitation (with the notable exception of systems that exhibit negative temperature). The lifetime of a system in an excited state is usually short: spontaneous or induced emission of a quantum of energy (such as a photon or a phonon) usually occurs shortly after the system is promoted to the excited state, returning the system to a state with lower energy (a less excited state or the ground state). This return to a lower energy level is often loosely described as decay and is the inverse of excitation.",
                    "score": 0.8776305913925171
                },
                {
                    "id": 1106425,
                    "contents": "Timeline of states of matter and phase transitions\n1895 – Pierre Curie discovers that induced magnetization is proportional to magnetic field strength 1911 – Heike Kamerlingh Onnes discloses his research on superconductivity 1912 – Peter Debye derives the T-cubed law for the low temperature heat capacity of a nonmetallic solid 1925 – Ernst Ising presents the solution to the one-dimensional Ising model 1928 – Felix Bloch applies quantum mechanics to electrons in crystal lattices, establishing the quantum theory of solids 1929 – Paul Adrien Maurice Dirac and Werner Karl Heisenberg develop the quantum theory of ferromagnetism 1932 – Louis Eugène Félix Néel discovers antiferromagnetism 1933 – Walther Meissner and Robert Ochsenfeld discover perfect superconducting diamagnetism 1933–1937 – Lev Davidovich Landau develops the Landau theory of phase transitions 1937 – Pyotr Leonidovich Kapitsa and John Frank Allen discover superfluidity 1941 – Lev Davidovich Landau explains superfluidity",
                    "score": 0.8775541186332703
                },
                {
                    "id": 90609,
                    "contents": "Third law of thermodynamics\nThe third law of thermodynamics states, regarding the properties of closed systems in thermodynamic equilibrium: This constant value cannot depend on any other parameters characterizing the closed system, such as pressure or applied magnetic field. At absolute zero (zero kelvins) the system must be in a state with the minimum possible energy. Entropy is related to the number of accessible microstates, and there is typically one unique state (called the ground state) with minimum energy. In such a case, the entropy at absolute zero will be exactly zero. If the system does not have a well-defined order (if its order is glassy, for example), then there may remain some finite entropy as the system is brought to very low temperatures, either because the system becomes locked into a configuration with non-minimal energy or because the minimum energy state is non-unique. The constant value is called the residual entropy of the system. The entropy is essentially a state-function meaning the",
                    "score": 0.8771973252296448
                },
                {
                    "id": 21898894,
                    "contents": "Eigenstate thermalization hypothesis\nThe eigenstate thermalization hypothesis (or ETH) is a set of ideas which purports to explain when and why an isolated quantum mechanical system can be accurately described using equilibrium statistical mechanics. In particular, it is devoted to understanding how systems which are initially prepared in far-from-equilibrium states can evolve in time to a state which appears to be in thermal equilibrium. The phrase \"eigenstate thermalization\" was first coined by Mark Srednicki in 1994, after similar ideas had been introduced by Josh Deutsch in 1991. The principal philosophy underlying the eigenstate thermalization hypothesis is that instead of explaining the ergodicity of a thermodynamic system through the mechanism of dynamical chaos, as is done in classical mechanics, one should instead examine the properties of matrix elements of observable quantities in individual energy eigenstates of the system. Motivation",
                    "score": 0.8766083121299744
                },
                {
                    "id": 1867378,
                    "contents": "Metastability\nAtomic and molecular physics Some atomic energy levels are metastable. Rydberg atoms are an example of metastable excited atomic states. Transitions from metastable excited levels are typically those forbidden by electric dipole selection rules. This means that any transitions from this level are relatively unlikely to occur. In a sense, an electron that happens to find itself in a metastable configuration is trapped there. Of course, since transitions from a metastable state are not impossible (merely less likely), the electron will eventually decay to a less energetic state, typically by an electric quadrupole transition, or often by non-radiative de-excitation (e.g., collisional de-excitation).",
                    "score": 0.875810980796814
                },
                {
                    "id": 26694944,
                    "contents": "Electronic specific heat\nThis implies that the ground state is the only occupied state for electrons in the limit , the takes the Pauli exclusion principle into account. The internal energy of a system within the free electron model is given by the sum over one-electron levels times the mean number of electrons in that level: where the factor of 2 accounts for the spin up and spin down states of the electron. Reduced internal energy and electron density Using the approximation that for a sum over a smooth function over all allowed values of for finite large system is given by: where is the volume of the system. For the reduced internal energy the expression for can be rewritten as: and the expression for the electron density can be written as: The integrals above can be evaluated using the fact that the dependence of the integrals on can be changed to dependence on through the relation for the electronic energy when described as free particles, , which yields for an arbitrary function :",
                    "score": 0.8757402896881104
                },
                {
                    "id": 1106426,
                    "contents": "Timeline of states of matter and phase transitions\n1937 – Pyotr Leonidovich Kapitsa and John Frank Allen discover superfluidity 1941 – Lev Davidovich Landau explains superfluidity 1942 – Hannes Alfvén predicts magnetohydrodynamic waves in plasmas 1944 – Lars Onsager publishes the exact solution to the two-dimensional Ising model 1957 – John Bardeen, Leon Cooper, and Robert Schrieffer develop the BCS theory of superconductivity End of the 50s – Lev Davidovich Landau develops the theory of Fermi liquid 1959 – Philip Warren Anderson predicts localization in disordered systems 1972 – Douglas Osheroff, Robert C. Richardson, and David Lee discover that helium-3 can become a superfluid 1974 – Kenneth G. Wilson develops the renormalization group technique for treating phase transitions 1980 – Klaus von Klitzing discovers the quantum Hall effect 1982 – Horst L. Stoermer and Daniel C. Tsui discover the fractional quantum Hall effect 1983 – Robert B. Laughlin explains the fractional quantum Hall effect",
                    "score": 0.8750542402267456
                },
                {
                    "id": 90616,
                    "contents": "Third law of thermodynamics\nHence: Calculating entropy change: We assume and . The energy change of the system as a result of absorbing the single photon whose energy is : The temperature of the closed system rises by: This can be interpreted as the average temperature of the system over the range from . A single atom was assumed to absorb the photon but the temperature and entropy change characterizes the entire system. Systems with non-zero entropy at absolute zero An example of a system which does not have a unique ground state is one whose net spin is a half-integer, for which time-reversal symmetry gives two degenerate ground states. For such systems, the entropy at zero temperature is at least (which is negligible on a macroscopic scale). Some crystalline systems exhibit geometrical frustration, where the structure of the crystal lattice prevents the emergence of a unique ground state. Ground-state helium (unless under pressure) remains liquid.",
                    "score": 0.8747410178184509
                },
                {
                    "id": 1177363,
                    "contents": "Population inversion\nWe may calculate the ratio of the populations of the two states at room temperature (T ≈ 300 K) for an energy difference ΔE that corresponds to light of a frequency corresponding to visible light (ν ≈ 5×1014 Hz). In this case ΔE = E2 - E1 ≈ 2.07 eV, and kT ≈ 0.026 eV. Since E2 - E1 ≫ kT, it follows that the argument of the exponential in the equation above is a large negative number, and as such N2/N1 is vanishingly small; i.e., there are almost no atoms in the excited state. When in thermal equilibrium, then, it is seen that the lower energy state is more populated than the higher energy state, and this is the normal state of the system. As T increases, the number of electrons in the high-energy state (N2) increases, but N2 never exceeds N1 for a system at thermal equilibrium; rather, at infinite temperature, the populations N2 and N1 become equal. In other words, a population inversion (N2/N1 > 1) can never exist for a system at thermal equilibrium. To achieve population inversion",
                    "score": 0.8747274875640869
                },
                {
                    "id": 13077415,
                    "contents": "Oscillator strength\nThe oscillator strength of a transition from a lower state to an upper state may be defined by where is the mass of an electron and is the reduced Planck constant. The quantum states 1,2, are assumed to have several degenerate sub-states, which are labeled by . \"Degenerate\" means that they all have the same energy . The operator is the sum of the x-coordinates of all electrons in the system, etc.: The oscillator strength is the same for each sub-state . The definition can be recast by inserting the Rydberg energy and Bohr radius In case the matrix elements of are the same, we can get rid of the sum and of the 1/3 factor Thomas–Reiche–Kuhn sum rule",
                    "score": 0.873650312423706
                },
                {
                    "id": 15576771,
                    "contents": "Temperature\nwhere is Boltzmann's constant and W is the number of microstates with the energy E of the system (degeneracy). When two systems with different temperatures are put into purely thermal connection, heat will flow from the higher temperature system to the lower temperature one; thermodynamically this is understood by the second law of thermodynamics: The total change in entropy following a transfer of energy from system 1 to system 2 is: and is thus positive if From the point of view of statistical mechanics, the total number of microstates in the combined system 1 + system 2 is , the logarithm of which (times Boltzmann's constant) is the sum of their entropies; thus a flow of heat from high to low temperature, which brings an increase in total entropy, is more likely than any other scenario (normally it is much more likely), as there are more microstates in the resulting macrostate.",
                    "score": 0.8735498189926147
                },
                {
                    "id": 21678909,
                    "contents": "Superradiant phase transition\nThe critical inequality rewritten yet differently expresses the fact that superradiant phase transition occurs when the frequency of the binding atomic oscillators is lower than so called electron gas plasma frequency. References Quantum mechanics Phase transitions",
                    "score": 0.8733631372451782
                },
                {
                    "id": 11781590,
                    "contents": "Transition state theory\nwhere a and b are constants related to energy terms. Two years later, René Marcelin made an essential contribution by treating the progress of a chemical reaction as a motion of a point in phase space. He then applied Gibbs' statistical-mechanical procedures and obtained an expression similar to the one he had obtained earlier from thermodynamic consideration. In 1915, another important contribution came from British physicist James Rice. Based on his statistical analysis, he concluded that the rate constant is proportional to the \"critical increment\". His ideas were further developed by Richard Chace Tolman. In 1919, Austrian physicist Karl Ferdinand Herzfeld applied statistical mechanics to the equilibrium constant and kinetic theory to the rate constant of the reverse reaction, k−1, for the reversible dissociation of a diatomic molecule. AB <=>[k_1][k_{-1}] {A} + {B} He obtained the following equation for the rate constant of the forward reaction",
                    "score": 0.8733525276184082
                },
                {
                    "id": 1697394,
                    "contents": "Energy\nThis principle is vitally important to understanding the behavior of a quantity closely related to energy, called entropy. Entropy is a measure of evenness of a distribution of energy between parts of a system. When an isolated system is given more degrees of freedom (i.e., given new available energy states that are the same as existing states), then total energy spreads over all available degrees equally without distinction between \"new\" and \"old\" degrees. This mathematical result is part of the second law of thermodynamics. The second law of thermodynamics is simple only for systems which are near or in a physical equilibrium state. For non-equilibrium systems, the laws governing the systems' behavior are still debatable. One of the guiding principles for these systems is the principle of maximum entropy production. It states that nonequilibrium systems behave in such a way as to maximize their entropy production. See also",
                    "score": 0.8732945919036865
                },
                {
                    "id": 3383124,
                    "contents": "Equipartition theorem\nwhere β = 1/kBT and the denominator Z is the partition function, here a geometric series Its average energy is given by Substituting the formula for Z gives the final result At high temperatures, when the thermal energy kBT is much greater than the spacing hν between energy levels, the exponential argument βhν is much less than one and the average energy becomes kBT, in agreement with the equipartition theorem (Figure 10). However, at low temperatures, when hν >> kBT, the average energy goes to zero—the higher-frequency energy levels are \"frozen out\" (Figure 10). As another example, the internal excited electronic states of a hydrogen atom do not contribute to its specific heat as a gas at room temperature, since the thermal energy kBT (roughly 0.025 eV) is much smaller than the spacing between the lowest and next higher electronic energy levels (roughly 10 eV).",
                    "score": 0.8725752830505371
                },
                {
                    "id": 17780817,
                    "contents": "Gas\nMaximum entropy principle As the total number of degrees of freedom approaches infinity, the system will be found in the macrostate that corresponds to the highest multiplicity. In order to illustrate this principle, observe the skin temperature of a frozen metal bar. Using a thermal image of the skin temperature, note the temperature distribution on the surface. This initial observation of temperature represents a \"microstate\". At some future time, a second observation of the skin temperature produces a second microstate. By continuing this observation process, it is possible to produce a series of microstates that illustrate the thermal history of the bar's surface. Characterization of this historical series of microstates is possible by choosing the macrostate that successfully classifies them all into a single grouping. Thermodynamic equilibrium",
                    "score": 0.8722001910209656
                },
                {
                    "id": 26849067,
                    "contents": "Gardner transition\nIn condensed matter physics, the Gardner transition refers to a temperature induced transition in which the free energy basin of a disordered system divides into many marginally stable sub-basins. It is named after Elizabeth Gardner who first described it in 1985. See also Glass transition References Condensed matter physics",
                    "score": 0.8716726303100586
                },
                {
                    "id": 3973016,
                    "contents": "Laws of thermodynamics\nThird law The third law of thermodynamics can be stated as: At zero temperature, the system must be in the state with the minimum thermal energy, the ground state. The constant value (not necessarily zero) of entropy at this point is called the residual entropy of the system. Note that, with the exception of non-crystalline solids (e.g. glasses) the residual entropy of a system is typically close to zero. However, it reaches zero only when the system has a unique ground state (i.e. the state with the minimum thermal energy has only one configuration, or microstate). Microstates are used here to describe the probability of a system being in a specific state, as each microstate is assumed to have the same probability of occurring, so macroscopic states with fewer microstates are less probable. In general, entropy is related to the number of possible microstates according to the Boltzmann principle:",
                    "score": 0.8716096878051758
                },
                {
                    "id": 8181839,
                    "contents": "Maximum entropy thermodynamics\n3. As just indicated, the MaxEnt inference runs equally well in reverse. So given a particular final state, we can ask, what can we \"retrodict\" to improve our knowledge about earlier states? However the Second Law argument above also runs in reverse: given macroscopic information at time t2, we should expect it too to become less useful. The two procedures are time-symmetric. But now the information will become less and less useful at earlier and earlier times. (Compare with Loschmidt's paradox.) The MaxEnt inference would predict that the most probable origin of a currently low-entropy state would be as a spontaneous fluctuation from an earlier high entropy state. But this conflicts with what we know to have happened, namely that entropy has been increasing steadily, even back in the past.",
                    "score": 0.8711229562759399
                },
                {
                    "id": 1628651,
                    "contents": "Condensed matter physics\nTwo classes of phase transitions occur: first-order transitions and second-order or continuous transitions. For the latter, the two phases involved do not co-exist at the transition temperature, also called the critical point. Near the critical point, systems undergo critical behavior, wherein several of their properties such as correlation length, specific heat, and magnetic susceptibility diverge exponentially. These critical phenomena present serious challenges to physicists because normal macroscopic laws are no longer valid in the region, and novel ideas and methods must be invented to find the new laws that can describe the system.",
                    "score": 0.8705865740776062
                },
                {
                    "id": 231015,
                    "contents": "Gibbs paradox\nTo compute the number of states we must compute the volume in phase space in which the system can be found and divide that by . This leads us to another problem: The volume seems to approach zero, as the region in phase space in which the system can be is an area of zero thickness. This problem is an artifact of having specified the energy U with infinite accuracy. In a generic system without symmetries, a full quantum treatment would yield a discrete non-degenerate set of energy eigenstates. An exact specification of the energy would then fix the precise state the system is in, so the number of states available to the system would be one, the entropy would thus be zero.",
                    "score": 0.8705325126647949
                },
                {
                    "id": 905493,
                    "contents": "Thermodynamic temperature\nof heat energy per mole with only a modest temperature change because each molecule comprises an average of 21 atoms and therefore has many internal degrees of freedom. Even larger, more complex molecules can have dozens of internal degrees of freedom.",
                    "score": 0.8705106377601624
                },
                {
                    "id": 11781611,
                    "contents": "Transition state theory\nCanonical variational TST A development of transition state theory in which the position of the dividing surface is varied so as to minimize the rate constant at a given temperature. Improved canonical variational TST A modification of canonical variational transition state theory in which, for energies below the threshold energy, the position of the dividing surface is taken to be that of the microcanonical threshold energy. This forces the contributions to rate constants to be zero if they are below the threshold energy. A compromise dividing surface is then chosen so as to minimize the contributions to the rate constant made by reactants having higher energies. Nonadiabatic TST An expansion of TST to the reactions when two spin-states are involved simultaneously is called nonadiabatic transition state theory (NA-TST). Semiclassical TST Using vibrational perturbation theory, effects such as tunnelling and variational effects can be accounted for within the SCTST formalism.",
                    "score": 0.8704968094825745
                },
                {
                    "id": 92608,
                    "contents": "Ground state\nThe ground state of a quantum-mechanical system is its lowest-energy state; the energy of the ground state is known as the zero-point energy of the system. An excited state is any state with energy greater than the ground state. In quantum field theory, the ground state is usually called the vacuum state or the vacuum. If more than one ground state exists, they are said to be degenerate. Many systems have degenerate ground states. Degeneracy occurs whenever there exists a unitary operator that acts non-trivially on a ground state and commutes with the Hamiltonian of the system.",
                    "score": 0.8700382113456726
                },
                {
                    "id": 4059593,
                    "contents": "Quantum phase transition\nQuantum description Talking about quantum phase transitions means talking about transitions at T = 0: by tuning a non-temperature parameter like pressure, chemical composition or magnetic field, one could suppress e.g. some transition temperature like the Curie or Néel temperature to 0 K. As a system in equilibrium at zero temperature is always in its lowest-energy state (or an equally weighted superposition if the lowest-energy is degenerate), a QPT cannot be explained by thermal fluctuations. Instead, quantum fluctuations, arising from Heisenberg's uncertainty principle, drive the loss of order characteristic of a QPT. The QPT occurs at the quantum critical point (QCP), where quantum fluctuations driving the transition diverge and become scale invariant in space and time.",
                    "score": 0.870029866695404
                },
                {
                    "id": 10661350,
                    "contents": "Introduction to entropy\ntemperature, etc. Statistical mechanics relates the thermodynamic entropy of a macrostate to the number of microstates that could yield that macrostate. In statistical mechanics the entropy of the system is given by Ludwig Boltzmann's famous equation:",
                    "score": 0.8697503805160522
                },
                {
                    "id": 90610,
                    "contents": "Third law of thermodynamics\nwith non-minimal energy or because the minimum energy state is non-unique. The constant value is called the residual entropy of the system. The entropy is essentially a state-function meaning the inherent value of different atoms, molecules, and other configurations of particles including subatomic or atomic material is defined by entropy, which can be discovered near 0 K.",
                    "score": 0.8694283366203308
                },
                {
                    "id": 4669527,
                    "contents": "Old quantum theory\nAt small values of , at high temperatures, the average energy U is equal to . This reproduces the equipartition theorem of classical thermodynamics: every harmonic oscillator at temperature T has energy kT on average. This means that the specific heat of an oscillator is constant in classical mechanics and equal to k. For a collection of atoms connected by springs, a reasonable model of a solid, the total specific heat is equal to the total number of oscillators times k. There are overall three oscillators for each atom, corresponding to the three possible directions of independent oscillations in three dimensions. So the specific heat of a classical solid is always 3k per atom, or in chemistry units, 3R per mole of atoms.",
                    "score": 0.869414210319519
                },
                {
                    "id": 15576755,
                    "contents": "Temperature\nIn the United States, the Fahrenheit scale is the most widely used. On this scale the freezing point of water corresponds to and the boiling point to . The Rankine scale, still used in fields of chemical engineering in the US, is an absolute scale based on the Fahrenheit increment. Conversion The following table shows the temperature conversion formulas for conversions to and from the Celsius scale. Plasma physics The field of plasma physics deals with phenomena of electromagnetic nature that involve very high temperatures. It is customary to express temperature as energy in units of electronvolts (eV) or kiloelectronvolts (keV). The energy, which has a different dimension from temperature, is then calculated as the product of the Boltzmann constant and temperature, . Then, 1eV corresponds to . In the study of QCD matter one routinely encounters temperatures of the order of a few hundred MeV, equivalent to about . Theoretical foundation",
                    "score": 0.8693665862083435
                },
                {
                    "id": 381575,
                    "contents": "Phase space\nThe phase space can also refer to the space that is parameterized by the macroscopic states of the system, such as pressure, temperature, etc. For instance, one may view the pressure-volume diagram or entropy-temperature diagrams as describing part of this phase space. A point in this phase space is correspondingly called a macrostate. There may easily be more than one microstate with the same macrostate. For example, for a fixed temperature, the system could have many dynamic configurations at the microscopic level. When used in this sense, a phase is a region of phase space where the system in question is in, for example, the liquid phase, or solid phase, etc.",
                    "score": 0.8692069053649902
                },
                {
                    "id": 3787068,
                    "contents": "Adiabatic theorem\nThese results are extremely important in atomic and molecular physics for control of the energy-state distribution in a population of atoms or molecules. Mathematical statement Under a slowly changing Hamiltonian with instantaneous eigenstates and corresponding energies , a quantum system evolves from the initial state to the final state where the coefficients undergo the change of phase with the dynamical phase and geometric phase In particular, , so if the system begins in an eigenstate of , it remains in an eigenstate of during the evolution with a change of phase only. Proofs {| class=\"toccolours collapsible collapsed\" width=\"80%\" style=\"text-align:left\" !Sakurai in Modern Quantum Mechanics |- | This proof is partly inspired by one given by Sakurai in Modern Quantum Mechanics. The instantaneous eigenstates and energies , by assumption, satisfy the time-independent Schrödinger equation at all times . Thus, they constitute a basis that can be used to expand the state",
                    "score": 0.8691741228103638
                },
                {
                    "id": 2300183,
                    "contents": "Negative temperature\nTemperature and disorder The distribution of energy among the various translational, vibrational, rotational, electronic, and nuclear modes of a system determines the macroscopic temperature. In a \"normal\" system, thermal energy is constantly being exchanged between the various modes. However, in some situations, it is possible to isolate one or more of the modes. In practice, the isolated modes still exchange energy with the other modes, but the time scale of this exchange is much slower than for the exchanges within the isolated mode. One example is the case of nuclear spins in a strong external magnetic field. In this case, energy flows fairly rapidly among the spin states of interacting atoms, but energy transfer between the nuclear spins and other modes is relatively slow. Since the energy flow is predominantly within the spin system, it makes sense to think of a spin temperature that is distinct from the temperature associated to other modes.",
                    "score": 0.8691553473472595
                },
                {
                    "id": 8181830,
                    "contents": "Maximum entropy thermodynamics\nIs entropy \"real\"? The thermodynamic entropy (at equilibrium) is a function of the state variables of the model description. It is therefore as \"real\" as the other variables in the model description. If the model constraints in the probability assignment are a \"good\" description, containing all the information needed to predict reproducible experimental results, then that includes all of the results one could predict using the formulae involving entropy from classical thermodynamics. To that extent, the MaxEnt STh is as \"real\" as the entropy in classical thermodynamics. Of course, in reality there is only one real state of the system. The entropy is not a direct function of that state. It is a function of the real state only through the (subjectively chosen) macroscopic model description. Is ergodic theory relevant?",
                    "score": 0.8689543008804321
                },
                {
                    "id": 27937100,
                    "contents": "19th century in science\nto describe the disorganization of a state). The statistical versus absolute interpretations of the second law of thermodynamics set up a dispute that would last for several decades (producing arguments such as \"Maxwell's demon\"), and that would not be held to be definitively resolved until the behavior of atoms was firmly established in the early 20th century. In 1902, James Jeans found the length scale required for gravitational perturbations to grow in a static nearly homogeneous medium.",
                    "score": 0.8684109449386597
                },
                {
                    "id": 7520096,
                    "contents": "KMS state\nIn the statistical mechanics of quantum mechanical systems and quantum field theory, the properties of a system in thermal equilibrium can be described by a mathematical object called a Kubo–Martin–Schwinger state or, more commonly, a KMS state: a state satisfying the KMS condition. introduced the condition, used it to define thermodynamic Green's functions, and used the condition to define equilibrium states and called it the KMS condition. Overview The simplest case to study is that of a finite-dimensional Hilbert space, in which one does not encounter complications like phase transitions or spontaneous symmetry breaking. The density matrix of a thermal state is given by where H is the Hamiltonian operator and N is the particle number operator (or charge operator, if we wish to be more general) and is the partition function. We assume that N commutes with H, or in other words, that particle number is conserved.",
                    "score": 0.8680339455604553
                },
                {
                    "id": 884650,
                    "contents": "Zero-point energy\nA more thorough treatment, showing that the energy of the ground state actually saturates this bound and is exactly , requires solving for the ground state of the system. Atomic physics The idea of a quantum harmonic oscillator and its associated energy can apply to either an atom or subatomic particle. In ordinary atomic physics, the zero-point energy is the energy associated with the ground state of the system. The professional physics literature tends to measure frequency, as denoted by above, using angular frequency, denoted with and defined by . This leads to a convention of writing Planck's constant with a bar through its top () to denote the quantity . In these terms, the most famous such example of zero-point energy is the above associated with the ground state of the quantum harmonic oscillator. In quantum mechanical terms, the zero-point energy is the expectation value of the Hamiltonian of the system in the ground state.",
                    "score": 0.8677434921264648
                },
                {
                    "id": 1701683,
                    "contents": "Equation of state\nAny consistent set of units may be used, although SI units are preferred. Absolute temperature refers to the use of the Kelvin (K), with zero being absolute zero. , number of moles of a substance , , molar volume, the volume of 1 mole of gas or liquid , ideal gas constant ≈ 8.3144621J/mol·K , pressure at the critical point , molar volume at the critical point , absolute temperature at the critical point",
                    "score": 0.86762934923172
                },
                {
                    "id": 8373032,
                    "contents": "Entropy (statistical thermodynamics)\nis the microcanonical partition function is the canonical partition function is the grand canonical partition function Lack of knowledge and the second law of thermodynamics We can view Ω as a measure of our lack of knowledge about a system. As an illustration of this idea, consider a set of 100 coins, each of which is either heads up or tails up. The macrostates are specified by the total number of heads and tails, whereas the microstates are specified by the facings of each individual coin. For the macrostates of 100 heads or 100 tails, there is exactly one possible configuration, so our knowledge of the system is complete. At the opposite extreme, the macrostate which gives us the least knowledge about the system consists of 50 heads and 50 tails in any order, for which there are 100,891,344,545,564,193,334,812,497,256 (100 choose 50) ≈ 1029 possible microstates.",
                    "score": 0.8674135804176331
                },
                {
                    "id": 21678908,
                    "contents": "Superradiant phase transition\nis the energy gap between consecutive levels and it is also noticed that is the spatial density of the oscillators. The condition is almost identical to this obtained in the original discovery of the superradiant phase transition when replacing the harmonic oscillators with two level atoms with the same distance between the energy levels, dipole transition strength, and the density which means that it occurs in the regime when the Coulomb interactions between electrons dominate over locally harmonic oscillatory influence of the atoms. It that sense the free electron gas with is also purely superradiant.",
                    "score": 0.8672119379043579
                },
                {
                    "id": 884636,
                    "contents": "Zero-point energy\nThe resolution to this puzzle came in 1926 with Schrödinger's famous equation. This equation explained the new, non-classical fact that an electron confined to be close to a nucleus would necessarily have a large kinetic energy so that the minimum total energy (kinetic plus potential) actually occurs at some positive separation rather than at zero separation; in other words, zero-point energy is essential for atomic stability.",
                    "score": 0.8672112226486206
                },
                {
                    "id": 1701680,
                    "contents": "Equation of state\nIn physics, chemistry, and thermodynamics, an equation of state is a thermodynamic equation relating state variables, which describe the state of matter under a given set of physical conditions, such as pressure, volume, temperature, or internal energy. Most modern equations of state are formulated in the Helmholtz free energy. Equations of state are useful in describing the properties of pure substances and mixtures in liquids, gases, and solid states as well as the state of matter in the interior of stars.",
                    "score": 0.8670256733894348
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_47",
        "question": "At $300 \\mathrm{~K}$ and $20 \\mathrm{~atm}$, the compression factor of a gas is 0.86 . Calculate the volume occupied by $8.2 \\mathrm{mmol}$ of the gas under these conditions.",
        "golden_answers": [
            " 8.7"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 6173702,
                    "contents": "Compressibility factor\nIn thermodynamics, the compressibility factor (Z), also known as the compression factor or the gas deviation factor, is a correction factor which describes the deviation of a real gas from ideal gas behaviour. It is simply defined as the ratio of the molar volume of a gas to the molar volume of an ideal gas at the same temperature and pressure. It is a useful thermodynamic property for modifying the ideal gas law to account for the real gas behaviour. In general, deviation from ideal behaviour becomes more significant the closer a gas is to a phase change, the lower the temperature or the larger the pressure. Compressibility factor values are usually obtained by calculation from equations of state (EOS), such as the virial equation which take compound-specific empirical constants as input. For a gas that is a mixture of two or more pure gases (air or natural gas, for example), the gas composition must be known before compressibility can be calculated.",
                    "score": 0.8840874433517456
                },
                {
                    "id": 6173703,
                    "contents": "Compressibility factor\nAlternatively, the compressibility factor for specific gases can be read from generalized compressibility charts that plot as a function of pressure at constant temperature.",
                    "score": 0.8836768269538879
                },
                {
                    "id": 6173713,
                    "contents": "Compressibility factor\nThe Real gas article features more theoretical methods to compute compressibility factors. Physical mechanism of temperature and pressure dependence Deviations of the compressibility factor, Z, from unity are due to attractive and repulsive intermolecular forces. At a given temperature and pressure, repulsive forces tend to make the volume larger than for an ideal gas; when these forces dominate Z is greater than unity. When attractive forces dominate, Z is less than unity. The relative importance of attractive forces decreases as temperature increases (see effect on gases). As seen above, the behavior of Z is qualitatively similar for all gases. Molecular nitrogen, N, is used here to further describe and understand that behavior. All data used in this section were obtained from the NIST Chemistry WebBook. It is useful to note that for N the normal boiling point of the liquid is 77.4 K and the critical point is at 126.2 K and 34.0 bar.",
                    "score": 0.8805108666419983
                },
                {
                    "id": 564669,
                    "contents": "Compressibility\nThermodynamics The term \"compressibility\" is also used in thermodynamics to describe the deviance in the thermodynamic properties of a real gas from those expected from an ideal gas. The compressibility factor is defined as where is the pressure of the gas, is its temperature, and is its molar volume. In the case of an ideal gas, the compressibility factor is equal to unity, and the familiar ideal gas law is recovered: can, in general, be either greater or less than unity for a real gas. The deviation from ideal gas behavior tends to become particularly significant (or, equivalently, the compressibility factor strays far from unity) near the critical point, or in the case of high pressure or low temperature. In these cases, a generalized compressibility chart or an alternative equation of state better suited to the problem must be utilized to produce accurate results.",
                    "score": 0.8800803422927856
                },
                {
                    "id": 4752487,
                    "contents": "Real gas\nwith , where are (respectively) the molar volume, the pressure and the temperature at the critical point. And with the reduced properties one can write the first equation in the reduced form: Beattie–Bridgeman model This equation is based on five experimentally determined constants. It is expressed as where This equation is known to be reasonably accurate for densities up to about 0.8 ρcr, where ρcr is the density of the substance at its critical point. The constants appearing in the above equation are available in the following table when p is in kPa, v is in , T is in K and R = 8.314 Benedict–Webb–Rubin model The BWR equation, sometimes referred to as the BWRS equation, where d is the molar density and where a, b, c, A, B, C, α, and γ are empirical constants. Note that the γ constant is a derivative of constant α and therefore almost identical to 1. Thermodynamic expansion work The expansion work of the real gas is different than that of the ideal gas by the quantity .",
                    "score": 0.8787370920181274
                },
                {
                    "id": 5597109,
                    "contents": "Molar heat capacity\nIn other words, that theory predicts that the molar heat capacity at constant volume cV,m of all monatomic gases will be the same; specifically, cV,m = R where R is the ideal gas constant, about 8.31446 J⋅K−1⋅mol−1 (which is the product of Boltzmann's constant kB and Avogadro's number). And, indeed, the experimental values of cV,m for the noble gases helium, neon, argon, krypton, and xenon (at 1 atm and 25 °C) are all 12.5 J⋅K−1⋅mol−1, which is R; even though their atomic weights range from 4 to 131. The same theory predicts that the molar heat capacity of a monatomic gas at constant pressure will be cP,m = cV,m + R = R This prediction matches the experimental values, which, for helium through xenon, are 20.78, 20.79, 20.85, 20.95, and 21.01 J⋅K−1⋅mol−1, respectively; very close to the theoretical R = 20.78 J⋅K−1⋅mol−1.",
                    "score": 0.8772686123847961
                },
                {
                    "id": 6173707,
                    "contents": "Compressibility factor\nThe reduced temperature and pressure are defined by and Here and are known as the critical temperature and critical pressure of a gas. They are characteristics of each specific gas with being the temperature above which it is not possible to liquify a given gas and is the minimum pressure required to liquify a given gas at its critical temperature. Together they define the critical point of a fluid above which distinct liquid and gas phases of a given fluid do not exist. The pressure-volume-temperature (PVT) data for real gases varies from one pure gas to another. However, when the compressibility factors of various single-component gases are graphed versus pressure along with temperature isotherms many of the graphs exhibit similar isotherm shapes.",
                    "score": 0.8770216703414917
                },
                {
                    "id": 680057,
                    "contents": "Ideal gas law\nEquation The state of an amount of gas is determined by its pressure, volume, and temperature. The modern form of the equation relates these simply in two main forms. The temperature used in the equation of state is an absolute temperature: the appropriate SI unit is the kelvin. Common forms The most frequently introduced forms are:where: is the pressure of the gas, is the volume of the gas, is the amount of substance of gas (also known as number of moles), is the ideal, or universal, gas constant, equal to the product of the Boltzmann constant and the Avogadro constant, is the Boltzmann constant is the Avogadro constant is the absolute temperature of the gas. In SI units, p is measured in pascals, V is measured in cubic metres, n is measured in moles, and T in kelvins (the Kelvin scale is a shifted Celsius scale, where 0.00 K = −273.15 °C, the lowest possible temperature). R has the value 8.314 J/(K⋅mol) ≈ 2 cal/(K⋅mol), or 0.0821 L⋅atm/(mol⋅K).",
                    "score": 0.8761131167411804
                },
                {
                    "id": 1039019,
                    "contents": "Volumetric heat capacity\nIn monatomic gases (like argon) at room temperature and constant volume, volumetric heat capacities are all very close to 0.5 kJ⋅K−1⋅m−3, which is the same as the theoretical value of RT per kelvin per mole of gas molecules (where R is the gas constant and T is temperature). As noted, the much lower values for gas heat capacity in terms of volume as compared with solids (although more comparable per mole, see below) results mostly from the fact that gases under standard conditions consist of mostly empty space (about 99.9% of volume), which is not filled by the atomic volumes of the atoms in the gas. Since the molar volume of gases is very roughly 1000 times that of solids and liquids, this results in a factor of about 1000 loss in volumetric heat capacity for gases, as compared with liquids and solids. Monatomic gas heat capacities per atom (not per molecule) are decreased by a factor of 2 with regard to solids, due to loss of half of the potential degrees of freedom per atom for",
                    "score": 0.8736228346824646
                },
                {
                    "id": 1039018,
                    "contents": "Volumetric heat capacity\nVolumetric heat capacity of gases Large complex gas molecules may have high heat capacities per mole (of molecules), but their heat capacities per mole of atoms are very similar to those of liquids and solids, again differing by less than a factor of two per mole of atoms. This factor of two represents vibrational degrees of freedom available in solids vs. gas molecules of various complexities.",
                    "score": 0.8735396265983582
                },
                {
                    "id": 4752488,
                    "contents": "Real gas\nThermodynamic expansion work The expansion work of the real gas is different than that of the ideal gas by the quantity . See also Compressibility factor Equation of state Ideal gas law: Boyle's law and Gay-Lussac's law References Further reading External links http://www.ccl.net/cca/documents/dyoung/topics-orig/eq_state.html Gases",
                    "score": 0.8712176084518433
                },
                {
                    "id": 1249260,
                    "contents": "Specific heat capacity\nIdeal gas For an ideal gas, evaluating the partial derivatives above according to the equation of state, where R is the gas constant, for an ideal gas Substituting this equation reduces simply to Mayer's relation: The differences in heat capacities as defined by the above Mayer relation is only exact for an ideal gas and would be different for any real gas. Specific heat capacity The specific heat capacity of a material on a per mass basis is which in the absence of phase transitions is equivalent to where is the heat capacity of a body made of the material in question, is the mass of the body, is the volume of the body, is the density of the material.",
                    "score": 0.8711421489715576
                },
                {
                    "id": 1249246,
                    "contents": "Specific heat capacity\nThis value for the specific heat capacity of nitrogen is practically constant from below −150 °C to about 300 °C. In that temperature range, the two additional degrees of freedom that correspond to vibrations of the atoms, stretching and compressing the bond, are still \"frozen out\". At about that temperature, those modes begin to \"un-freeze\", and as a result starts to increase rapidly at first, then slower as it tends to another constant value. It is 35.5 J⋅K−1⋅mol−1 at 1500 °C, 36.9 at 2500 °C, and 37.5 at 3500 °C. The last value corresponds almost exactly to the predicted value for 7 degrees of freedom per molecule. Derivations of heat capacity Relation between specific heat capacitiesexpansion]], is the isothermal compressibility, and is density. A derivation is discussed in the article Relations between specific heats. For an ideal gas, if is expressed as molar density in the above equation, this equation reduces simply to Mayer's relation,",
                    "score": 0.870594322681427
                },
                {
                    "id": 2450508,
                    "contents": "Charles's law\nRelation to absolute zero Charles's law appears to imply that the volume of a gas will descend to zero at a certain temperature (−266.66 °C according to Gay-Lussac's figures) or −273.15 °C. Gay-Lussac was clear in his description that the law was not applicable at low temperatures: but I may mention that this last conclusion cannot be true except so long as the compressed vapours remain entirely in the elastic state; and this requires that their temperature shall be sufficiently elevated to enable them to resist the pressure which tends to make them assume the liquid state. At absolute zero temperature, the gas possesses zero energy and hence the molecules restrict motion.",
                    "score": 0.8705094456672668
                },
                {
                    "id": 17780802,
                    "contents": "Gas\nIdeal and perfect gas The equation of state for an ideal or perfect gas is the ideal gas law and reads where P is the pressure, V is the volume, n is amount of gas (in mol units), R is the universal gas constant, 8.314 J/(mol K), and T is the temperature. Written this way, it is sometimes called the \"chemist's version\", since it emphasizes the number of molecules n. It can also be written as where is the specific gas constant for a particular gas, in units J/(kg K), and ρ = m/V is density. This notation is the \"gas dynamicist's\" version, which is more practical in modeling of gas flows involving acceleration without chemical reactions.",
                    "score": 0.8703798651695251
                },
                {
                    "id": 680041,
                    "contents": "Gas constant\nHowever, following the 2019 redefinition of the SI base units, R now has an exact value defined in terms of other exactly defined physical constants. Specific gas constant The specific gas constant of a gas or a mixture of gases (Rspecific) is given by the molar gas constant divided by the molar mass (M) of the gas or mixture. Just as the ideal gas constant can be related to the Boltzmann constant, so can the specific gas constant by dividing the Boltzmann constant by the molecular mass of the gas. Another important relationship comes from thermodynamics. Mayer's relation relates the specific gas constant to the specific heat capacities for a calorically perfect gas and a thermally perfect gas. where cp is the specific heat capacity for a constant pressure and cv is the specific heat capacity for a constant volume.",
                    "score": 0.8702754974365234
                },
                {
                    "id": 20480526,
                    "contents": "Monatomic gas\nIn an adiabatic process, monatomic gases have an idealised γ-factor (Cp/Cv) of 5/3, as opposed to 7/5 for ideal diatomic gases where rotation (but not vibration at room temperature) also contributes. Also, for ideal monatomic gases: the molar heat capacity at constant pressure (Cp) is 5/2 R = 20.8 J K−1 mol−1 (4.97 cal K−1 mol−1). the molar heat capacity at constant volume (Cv) is 3/2 R = 12.5 J K−1 mol−1 (2.98 cal K−1 mol−1). References Gases",
                    "score": 0.8702166676521301
                },
                {
                    "id": 739449,
                    "contents": "Boyle's law\nRelation with kinetic theory and ideal gases Boyle's law states that at constant temperature the volume of a given mass of a dry gas is inversely proportional to its pressure. Most gases behave like ideal gases at moderate pressures and temperatures. The technology of the 17th century could not produce very high pressures or very low temperatures. Hence, the law was not likely to have deviations at the time of publication. As improvements in technology permitted higher pressures and lower temperatures, deviations from the ideal gas behavior became noticeable, and the relationship between pressure and volume can only be accurately described employing real gas theory. The deviation is expressed as the compressibility factor.",
                    "score": 0.8698863983154297
                },
                {
                    "id": 1249234,
                    "contents": "Specific heat capacity\nThe value of is usually less than the value of . This difference is particularly notable in gases where values under constant pressure are typically 30% to 66.7% greater than those at constant volume. Hence the heat capacity ratio of gases is typically between 1.3 and 1.67. Applicability The specific heat capacity can be defined and measured for gases, liquids, and solids of fairly general composition and molecular structure. These include gas mixtures, solutions and alloys, or heterogenous materials such as milk, sand, granite, and concrete, if considered at a sufficiently large scale. The specific heat capacity can be defined also for materials that change state or composition as the temperature and pressure change, as long as the changes are reversible and gradual. Thus, for example, the concepts are definable for a gas or liquid that dissociates as the temperature increases, as long as the products of the dissociation promptly and completely recombine when it drops.",
                    "score": 0.8696892857551575
                },
                {
                    "id": 17608477,
                    "contents": "Volume (thermodynamics)\nFor an ideal gas, where, is the specific gas constant, is the temperature and is the pressure of the gas. Specific volume may also refer to molar volume. Gas volume Dependence on pressure and temperature The volume of gas increases proportionally to absolute temperature and decreases inversely proportionally to pressure, approximately according to the ideal gas law: where: p is the pressure V is the volume n is the amount of substance of gas (moles) R is the gas constant, 8.314 J·K−1mol−1 T is the absolute temperature To simplify, a volume of gas may be expressed as the volume it would have in standard conditions for temperature and pressure, which are 0 °C and 100 kPa.",
                    "score": 0.8694758415222168
                },
                {
                    "id": 6173714,
                    "contents": "Compressibility factor\nThe figure on the right shows an overview covering a wide temperature range. At low temperature (100 K), the curve has a characteristic check-mark shape, the rising portion of the curve is very nearly directly proportional to pressure. At intermediate temperature (160 K), there is a smooth curve with a broad minimum; although the high pressure portion is again nearly linear, it is no longer directly proportional to pressure. Finally, at high temperature (400 K), Z is above unity at all pressures. For all curves, Z approaches the ideal gas value of unity at low pressure and exceeds that value at very high pressure.",
                    "score": 0.8688068985939026
                },
                {
                    "id": 1039017,
                    "contents": "Volumetric heat capacity\nFor gases at room temperature, the range of volumetric heat capacities per atom (not per molecule) only varies between different gases by a small factor less than two, because every ideal gas has the same molar volume. Thus, each gas molecule occupies the same mean volume in all ideal gases, regardless of the type of gas (see kinetic theory). This fact gives each gas molecule the same effective \"volume\" in all ideal gases (although this volume/molecule in gases is far larger than molecules occupy on average in solids or liquids). Thus, in the limit of ideal gas behavior (which many gases approximate except at low temperatures and/or extremes of pressure) this property reduces differences in gas volumetric heat capacity to simple differences in the heat capacities of individual molecules. As noted, these differ by a factor depending on the degrees of freedom available to particles within the molecules.",
                    "score": 0.8688024282455444
                },
                {
                    "id": 333023,
                    "contents": "Thermodynamic activity\nFor a mix of gas at low pressure, the activity is equal to the ratio of the partial pressure of the gas over the standard pressure: Therefore, it is equal to the partial pressure in atmospheres (or bars), compared to a standard pressure of 1 atmosphere (or 1 bar). For a solid body, a uniform, single species solid at one bar has an activity of unity. The same thing holds for a pure liquid. The latter follows from any definition based on Raoult's law, because if we let the solute concentration go to zero, the vapor pressure of the solvent will go to . Thus its activity will go to unity. This means that if during a reaction in dilute solution more solvent is generated (the reaction produces water for example) we can typically set its activity to unity.",
                    "score": 0.8685621619224548
                },
                {
                    "id": 1379356,
                    "contents": "Le Chatelier's principle\n⇌ ΔH = −92kJ mol−1 Note the number of moles of gas on the left-hand side and the number of moles of gas on the right-hand side. When the volume of the system is changed, the partial pressures of the gases change. If we were to decrease pressure by increasing volume, the equilibrium of the above reaction will shift to the left, because the reactant side has a greater number of moles than does the product side. The system tries to counteract the decrease in partial pressure of gas molecules by shifting to the side that exerts greater pressure. Similarly, if we were to increase pressure by decreasing volume, the equilibrium shifts to the right, counteracting the pressure increase by shifting to the side with fewer moles of gas that exert less pressure. If the volume is increased because there are more moles of gas on the reactant side, this change is more significant in the denominator of the equilibrium constant expression, causing a shift in equilibrium.",
                    "score": 0.8682562112808228
                },
                {
                    "id": 10829468,
                    "contents": "Émile Amagat\nÉmile Hilaire Amagat (2 January 1841, Saint-Satur – 15 February 1915) was a French physicist. His doctoral thesis, published in 1872, expanded on the work of Thomas Andrews, and included plots of the isotherms of carbon dioxide at high pressures. Amagat published a paper in 1877 that contradicted the current understanding at the time, concluding that the coefficient of compressibility of fluids decreased with increasing pressure. He continued to publish data on isotherms for a number of different gases between 1879 and 1882, and invented the hydraulic manometer, which was able to withstand up to 3200 atmospheres, as opposed to 400 atmospheres using a glass apparatus. In 1880 he published his Law of Partial Volumes. Amagat was elected a member of the French Academy of Sciences on 9 June 1902. A unit of number density, amagat, was named after him. He was elected a foreign member of the Royal Society of London in 1897.",
                    "score": 0.8679311275482178
                },
                {
                    "id": 1249247,
                    "contents": "Specific heat capacity\nFor an ideal gas, if is expressed as molar density in the above equation, this equation reduces simply to Mayer's relation, where and are intensive property heat capacities expressed on a per mole basis at constant pressure and constant volume, respectively. Specific heat capacity The specific heat capacity of a material on a per mass basis is which in the absence of phase transitions is equivalent to where is the heat capacity of a body made of the material in question, is the mass of the body, is the volume of the body, and is the density of the material.",
                    "score": 0.867853581905365
                },
                {
                    "id": 6173709,
                    "contents": "Compressibility factor\nThe quantum gases hydrogen, helium, and neon do not conform to the corresponding-states behavior and the reduced pressure and temperature for those three gases should be redefined in the following manner to improve the accuracy of predicting their compressibility factors when using the generalized graphs: and where the temperatures are in kelvins and the pressures are in atmospheres. Reading a generalized compressibility chart In order to read a compressibility chart, the reduced pressure and temperature must be known. If either the reduced pressure or temperature is unknown, the reduced specific volume must be found. Unlike the reduced pressure and temperature, the reduced specific volume is not found by using the critical volume. The reduced specific volume is defined by, where is the specific volume.",
                    "score": 0.8677982091903687
                },
                {
                    "id": 1249273,
                    "contents": "Specific heat capacity\nIdeal gas For an ideal gas, evaluating the partial derivatives above according to the equation of state, where R is the gas constant, for an ideal gas Substituting this equation reduces simply to Mayer's relation: The differences in heat capacities as defined by the above Mayer relation is only exact for an ideal gas and would be different for any real gas. See also Specific heat of melting (Enthalpy of fusion) Specific heat of vaporization (Enthalpy of vaporization) Frenkel line Heat capacity ratio Heat equation Heat transfer coefficient History of thermodynamics Joback method (Estimation of heat capacities) Latent heat Material properties (thermodynamics) Quantum statistical mechanics R-value (insulation) Specific heat of vaporization Specific melting heat Statistical mechanics Table of specific heat capacities Thermal mass Thermodynamic databases for pure substances Thermodynamic equations Volumetric heat capacity Notes References",
                    "score": 0.8671952486038208
                },
                {
                    "id": 982386,
                    "contents": "Gas laws\nThis can also be written as: With the addition of Avogadro's law, the combined gas law develops into the ideal gas law: where P is pressure V is volume n is the number of moles R is the universal gas constant T is temperature (K) where the proportionality constant, now named R, is the universal gas constant with a value of 8.3144598 (kPa∙L)/(mol∙K). An equivalent formulation of this law is: where P is the pressure V is the volume N is the number of gas molecules k is the Boltzmann constant (1.381×10−23 J·K−1 in SI units) T is the temperature (K) These equations are exact only for an ideal gas, which neglects various intermolecular effects (see real gas). However, the ideal gas law is a good approximation for most gases under moderate pressure and temperature.",
                    "score": 0.8671272397041321
                },
                {
                    "id": 6173715,
                    "contents": "Compressibility factor\nTo better understand these curves, a closer look at the behavior for low temperature and pressure is given in the second figure. All of the curves start out with Z equal to unity at zero pressure and Z initially decreases as pressure increases. N is a gas under these conditions, so the distance between molecules is large, but becomes smaller as pressure increases. This increases the attractive interactions between molecules, pulling the molecules closer together and causing the volume to be less than for an ideal gas at the same temperature and pressure. Higher temperature reduces the effect of the attractive interactions and the gas behaves in a more nearly ideal manner.",
                    "score": 0.8669260740280151
                },
                {
                    "id": 1249236,
                    "contents": "Specific heat capacity\nThe specific heat capacities of gases can be measured at constant volume, by enclosing the sample in a rigid container. On the other hand, measuring the specific heat capacity at constant volume can be prohibitively difficult for liquids and solids, since one often would need impractical pressures in order to prevent the expansion that would be caused by even small increases in temperature. Instead, the common practice is to measure the specific heat capacity at constant pressure (allowing the material to expand or contract as it wishes), determine separately the coefficient of thermal expansion and the compressibility of the material, and compute the specific heat capacity at constant volume from these data according to the laws of thermodynamics. Units",
                    "score": 0.8659257888793945
                },
                {
                    "id": 785728,
                    "contents": "Molar volume\n. Ideal gases For ideal gases, the molar volume is given by the ideal gas equation; this is a good approximation for many common gases at standard temperature and pressure. The ideal gas equation can be rearranged to give an expression for the molar volume of an ideal gas: Hence, for a given temperature and pressure, the molar volume is the same for all ideal gases and is based on the gas constant: R = , or about . The molar volume of an ideal gas at 100 kPa (1 bar) is at 0 °C, at 25 °C. The molar volume of an ideal gas at 1 atmosphere of pressure is at 0 °C, at 25 °C. Crystalline solids For crystalline solids, the molar volume can be measured by X-ray crystallography. The unit cell volume (Vcell) may be calculated from the unit cell parameters, whose determination is the first step in an X-ray crystallography experiment (the calculation is performed automatically by the structure determination software). This is related to the molar volume by",
                    "score": 0.8657227754592896
                },
                {
                    "id": 454321,
                    "contents": "Perfect gas\n, which is exactly zero when . Thus, and are at most functions of only temperature for this particular equation of state.",
                    "score": 0.8655431866645813
                },
                {
                    "id": 1701355,
                    "contents": "Entropy\nHere is the amount of gas (in moles) and is the ideal gas constant. These equations also apply for expansion into a finite vacuum or a throttling process, where the temperature, internal energy and enthalpy for an ideal gas remain constant. Cooling and heating For pure heating or cooling of any system (gas, liquid or solid) at constant pressure from an initial temperature to a final temperature , the entropy change is provided that the constant-pressure molar heat capacity (or specific heat) CP is constant and that no phase transition occurs in this temperature interval. Similarly at constant volume, the entropy change is where the constant-volume molar heat capacity Cv is constant and there is no phase change. At low temperatures near absolute zero, heat capacities of solids quickly drop off to near zero, so the assumption of constant heat capacity does not apply.",
                    "score": 0.8644835948944092
                },
                {
                    "id": 17780803,
                    "contents": "Gas\nThe ideal gas law does not make an assumption about the specific heat of a gas. In the most general case, the specific heat is a function of both temperature and pressure. If the pressure-dependence is neglected (and possibly the temperature-dependence as well) in a particular application, sometimes the gas is said to be a perfect gas, although the exact assumptions may vary depending on the author and/or field of science. For an ideal gas, the ideal gas law applies without restrictions on the specific heat. An ideal gas is a simplified \"real gas\" with the assumption that the compressibility factor Z is set to 1 meaning that this pneumatic ratio remains constant. A compressibility factor of one also requires the four state variables to follow the ideal gas law.",
                    "score": 0.8643714189529419
                },
                {
                    "id": 1249252,
                    "contents": "Specific heat capacity\nSolid phase The theoretical maximum heat capacity for larger and larger multi-atomic gases at higher temperatures, also approaches the Dulong–Petit limit of 3R, so long as this is calculated per mole of atoms, not molecules. The reason is that gases with very large molecules, in theory have almost the same high-temperature heat capacity as solids, lacking only the (small) heat capacity contribution that comes from potential energy that cannot be stored between separate molecules in a gas.",
                    "score": 0.8639165759086609
                },
                {
                    "id": 381780,
                    "contents": "Planck's law\nbut also, independently, by the respective numbers of the different molecules, and independently again, by the specific characteristics of the different molecules. For different material gases at given temperature, the pressure and internal energy density can vary independently, because different molecules can carry independently different excitation energies.",
                    "score": 0.8635041117668152
                },
                {
                    "id": 6173718,
                    "contents": "Compressibility factor\nThis can be seen in the graph showing the high temperature behavior. As temperature increases, the initial slope becomes less negative, the pressure at which Z is a minimum gets smaller, and the pressure at which repulsive interactions start to dominate, i.e. where Z goes from less than unity to greater than unity, gets smaller. At the Boyle temperature (327 K for N), the attractive and repulsive effects cancel each other at low pressure. Then Z remains at the ideal gas value of unity up to pressures of several tens of bar. Above the Boyle temperature, the compressibility factor is always greater than unity and increases slowly but steadily as pressure increases. Experimental values",
                    "score": 0.8634462356567383
                },
                {
                    "id": 6173706,
                    "contents": "Compressibility factor\nFugacity The compressibility factor is linked to the fugacity by the relation: Generalized compressibility factor graphs for pure gases The unique relationship between the compressibility factor and the reduced temperature, , and the reduced pressure, , was first recognized by Johannes Diderik van der Waals in 1873 and is known as the two-parameter principle of corresponding states. The principle of corresponding states expresses the generalization that the properties of a gas which are dependent on intermolecular forces are related to the critical properties of the gas in a universal way. That provides a most important basis for developing correlations of molecular properties. As for the compressibility of gases, the principle of corresponding states indicates that any pure gas at the same reduced temperature, , and reduced pressure, , should have the same compressibility factor.",
                    "score": 0.8630493879318237
                },
                {
                    "id": 5597124,
                    "contents": "Molar heat capacity\nThe following table shows the experimental molar heat capacities at constant pressure cP,m of the above polyatomic gases at standard temperature (25 °C = 298 K), at 500 °C, and at 5000 °C, and the apparent number of degrees of freedom f* estimated by the formula f* = 2cP,m/R − 2: (*) At 3000C Specific heat of solids",
                    "score": 0.8629685640335083
                },
                {
                    "id": 17780813,
                    "contents": "Gas\nwhere n is equal to the number of moles of gas (the number of molecules divided by Avogadro's number). Dalton's law In 1801, John Dalton published the law of partial pressures from his work with ideal gas law relationship: The pressure of a mixture of non reactive gases is equal to the sum of the pressures of all of the constituent gases alone. Mathematically, this can be represented for n species as: Pressuretotal = Pressure1 + Pressure2 + ... + Pressuren The image of Dalton's journal depicts symbology he used as shorthand to record the path he followed. Among his key journal observations upon mixing unreactive \"elastic fluids\" (gases) were the following: Unlike liquids, heavier gases did not drift to the bottom upon mixing. Gas particle identity played no role in determining final pressure (they behaved as if their size was negligible). Special topics Compressibility",
                    "score": 0.8629190921783447
                },
                {
                    "id": 680042,
                    "contents": "Gas constant\nwhere cp is the specific heat capacity for a constant pressure and cv is the specific heat capacity for a constant volume. It is common, especially in engineering applications, to represent the specific gas constant by the symbol R. In such cases, the universal gas constant is usually given a different symbol such as to distinguish it. In any case, the context and/or units of the gas constant should make it clear as to whether the universal or specific gas constant is being referred to. U.S. Standard Atmosphere The U.S. Standard Atmosphere, 1976 (USSA1976) defines the gas constant R∗ as: R∗ = = .",
                    "score": 0.8629066348075867
                },
                {
                    "id": 17608478,
                    "contents": "Volume (thermodynamics)\nTo simplify, a volume of gas may be expressed as the volume it would have in standard conditions for temperature and pressure, which are 0 °C and 100 kPa. Humidity exclusion In contrast to other gas components, water content in air, or humidity, to a higher degree depends on vaporization and condensation from or into water, which, in turn, mainly depends on temperature. Therefore, when applying more pressure to a gas saturated with water, all components will initially decrease in volume approximately according to the ideal gas law. However, some of the water will condense until returning to almost the same humidity as before, giving the resulting total volume deviating from what the ideal gas law predicted. Conversely, decreasing temperature would also make some water condense, again making the final volume deviating from predicted by the ideal gas law.",
                    "score": 0.8627324104309082
                },
                {
                    "id": 680037,
                    "contents": "Gas constant\nThe gas constant occurs in the ideal gas law: where P is the absolute pressure (SI unit pascals), V is the volume of gas (SI unit cubic metres), n is the amount of gas (SI unit moles), m is the mass (SI unit kilograms) contained in V, and T is the thermodynamic temperature (SI unit kelvins). Rspecific is the mass-specific gas constant. The gas constant is expressed in the same units as are molar entropy and molar heat capacity. Dimensions From the ideal gas law PV = nRT we get: where P is pressure, V is volume, n is number of moles of a given substance, and T is temperature. As pressure is defined as force per area of measurement, the gas equation can also be written as: Area and volume are (length)2 and (length)3 respectively. Therefore: Since force × length = work:",
                    "score": 0.8627021908760071
                },
                {
                    "id": 1378279,
                    "contents": "Relative density\nWhere is the molar mass and the approximately equal sign is used because equality pertains only if 1 mol of the gas and 1 mol of air occupy the same volume at a given temperature and pressure i.e. they are both Ideal gases. Ideal behaviour is usually only seen at very low pressure. For example, one mol of an ideal gas occupies 22.414 L at 0 °C and 1 atmosphere whereas carbon dioxide has a molar volume of 22.259 L under those same conditions. Those with SG greater than 1 are denser than water and will, disregarding surface tension effects, sink in it. Those with an SG less than 1 are less dense than water and will float on it. In scientific work, the relationship of mass to volume is usually expressed directly in terms of the density (mass per unit volume) of the substance under study. It is in industry where specific gravity finds wide application, often for historical reasons. True specific gravity of a liquid can be expressed mathematically as:",
                    "score": 0.8626211285591125
                },
                {
                    "id": 17608481,
                    "contents": "Volume (thermodynamics)\nIt can be approximated both from partial pressure and molar fraction: VX is the partial volume of any individual gas component (X) Vtot is the total volume in gas mixture PX is the partial pressure of gas X Ptot is the total pressure in gas mixture nX is the amount of substance of a gas (X) ntot is the total amount of substance in gas mixture See also Volumetric flow rate References Gases Physical chemistry Standards Thermodynamic properties Volume State functions ca:Volum (termodinàmica)#Volum específic",
                    "score": 0.8625444173812866
                },
                {
                    "id": 1568612,
                    "contents": "Adiabatic process\nso the adiabatic constant for this example is about 6.31 Pa m4.2. The gas is now compressed to a 0.1 L (0.0001 m3) volume, which we assume happens quickly enough that no heat enters or leaves the gas through the walls. The adiabatic constant remains the same, but with the resulting pressure unknown We can now solve for the final pressure or 25.1 bar. This pressure increase is more than a simple 10:1 compression ratio would indicate; this is because the gas is not only compressed, but the work done to compress the gas also increases its internal energy, which manifests itself by a rise in the gas temperature and an additional rise in pressure above what would result from a simplistic calculation of 10 times the original pressure.",
                    "score": 0.8624265193939209
                },
                {
                    "id": 28341056,
                    "contents": "William J. Nellis\nSelected articles W. J. Nellis (2017). Ultracondensed Matter by Dynamic Compression. Cambridge University Press. Nellis, W. J., Mitchell, A. C., van Thiel, M., Devine, G. J., Trainor, R. J. and Brown, N. (1983) Equation-of-state data for molecular hydrogen and deuterium at shock pressures in the range 2-76 GPa (20-760 kbar), Journal of Chemical Physics, 79, 1480-1486. Nellis, W. J., Maple, M. B. and Geballe, T. H. (1988). Synthesis of metastable superconductors by high dynamic pressure. In SPIE Vol. 878 Multifunctional Materials, ed. R. L. Bellingham: Society of Photo-Optical Instrumentation Engineers, pp. 2–9. Nellis, W. J., Weir, S. T. and Mitchell, A. C. (1996) Metallization and electrical conductivity of hydrogen in Jupiter, Science, 273, 936-938. Chau, R., Mitchell, A. C., Minich, R. W. and Nellis, W. J. (2003). Metallization of fluid nitrogen and the Mott transition in highly compressed low-Z fluids, Physical Review Letters, 90, 245501-1-245501-4.",
                    "score": 0.8618911504745483
                },
                {
                    "id": 9278657,
                    "contents": "Gas kinetics\nReal gases Real gases are characterized by their compressibility (z) in the equation PV = zn0RT. When the pressure P is set as a function of the volume V where the series is determined by set temperatures T, P, and V began to take hyperbolic relationships that are exhibited by ideal gases as the temperatures start to get very high. A critical point is reached when the slope of the graph is equal to zero and makes the state of the fluid change between a liquid and a vapor. The properties of ideal gases contain viscosity, thermal conductivity, and diffusion.",
                    "score": 0.861884355545044
                },
                {
                    "id": 17780783,
                    "contents": "Gas\nDensity The symbol used to represent density in equations is ρ (rho) with SI units of kilograms per cubic meter. This term is the reciprocal of specific volume.",
                    "score": 0.8616870045661926
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    },
    {
        "id": "test_48",
        "question": "A very crude model of the buckminsterfullerene molecule $\\left(\\mathrm{C}_{60}\\right)$ is to treat it as a collection of electrons in a cube with sides of length equal to the mean diameter of the molecule $(0.7 \\mathrm{~nm})$. Suppose that only the $\\pi$ electrons of the carbon atoms contribute, and predict the wavelength of the first excitation of $\\mathrm{C}_{60}$. (The actual value is $730 \\mathrm{~nm}$.)",
        "golden_answers": [
            " 1.6"
        ],
        "output": {
            "retrieval_result": [
                {
                    "id": 1712034,
                    "contents": "Fullerene\nThe van der Waals diameter of a buckminsterfullerene molecule is about 1.1 nanometers (nm). The nucleus to nucleus diameter of a buckminsterfullerene molecule is about 0.71 nm. The buckminsterfullerene molecule has two bond lengths. The 6:6 ring bonds (between two hexagons) can be considered \"double bonds\" and are shorter than the 6:5 bonds (between a hexagon and a pentagon). Its average bond length is 1.4 Å. Other fullerenes Another fairly common fullerene has empirical formula , but fullerenes with 72, 76, 84 and even up to 100 carbon atoms are commonly obtained.",
                    "score": 0.9035724401473999
                },
                {
                    "id": 1067016,
                    "contents": "Buckminsterfullerene\nStructure Buckminsterfullerene is a truncated icosahedron with 60 vertices and 32 faces (20 hexagons and 12 pentagons where no pentagons share a vertex) with a carbon atom at the vertices of each polygon and a bond along each polygon edge. The van der Waals diameter of a molecule is about 1.01 nanometers (nm). The nucleus to nucleus diameter of a molecule is about 0.71 nm. The molecule has two bond lengths. The 6:6 ring bonds (between two hexagons) can be considered \"double bonds\" and are shorter than the 6:5 bonds (between a hexagon and a pentagon). Its average bond length is 0.14 nm. Each carbon atom in the structure is bonded covalently with 3 others. Properties For a time buckminsterfullerene was the largest known molecule observed to exhibit wave–particle duality; theoretically every object exhibits this behavior. In 2020 the dye molecule phthalocyanine exhibited the duality that is more famously attributed to light, electrons and other small particles and molecules.",
                    "score": 0.9003528952598572
                },
                {
                    "id": 1712033,
                    "contents": "Fullerene\nBuckyballs Buckminsterfullerene Buckminsterfullerene is the smallest fullerene molecule containing pentagonal and hexagonal rings in which no two pentagons share an edge (which can be destabilizing, as in pentalene). It is also most common in terms of natural occurrence, as it can often be found in soot. The empirical formula of buckminsterfullerene is and its structure is a truncated icosahedron, which resembles an association football ball of the type made of twenty hexagons and twelve pentagons, with a carbon atom at the vertices of each polygon and a bond along each polygon edge. The van der Waals diameter of a buckminsterfullerene molecule is about 1.1 nanometers (nm). The nucleus to nucleus diameter of a buckminsterfullerene molecule is about 0.71 nm.",
                    "score": 0.8963227272033691
                },
                {
                    "id": 1067017,
                    "contents": "Buckminsterfullerene\nThe molecule is stable, withstanding high temperatures and high pressures. undergoes six reversible, one-electron reductions to , but oxidation is irreversible. The first reduction needs ≈1.0 V (Fc/), showing that C60 is a moderately effective electron acceptor. tends to avoid having double bonds in the pentagonal rings, which makes electron delocalization poor, and results in not being \"superaromatic\". C60 behaves very much like an electron deficient alkene and readily reacts with electron rich species. A carbon atom in the molecule can be substituted by a nitrogen or boron atom yielding a or C59B respectively. Solution",
                    "score": 0.8917285203933716
                },
                {
                    "id": 1067012,
                    "contents": "Buckminsterfullerene\nIn 1989 physicists Wolfgang Krätschmer, Konstantinos Fostiropoulos, and Donald R. Huffman observed unusual optical absorptions in thin films of carbon dust (soot). The soot had been generated by an arc-process between two graphite electrodes in a helium atmosphere where the electrode material evaporates and condenses forming soot in the quenching atmosphere. Among other features, the IR spectra of the soot showed four discrete bands in close agreement to those proposed for C60.",
                    "score": 0.8850772380828857
                },
                {
                    "id": 1067009,
                    "contents": "Buckminsterfullerene\nHistory Theoretical predictions of buckyball molecules appeared in the late 1960s and early 1970s, but these reports went largely unnoticed. Buckminsterfullerene was first generated in 1984 by Eric Rohlfing, Donald Cox and Andrew Kaldor using a laser to vaporize carbon in a supersonic helium beam. In 1985 their work was repeated by Harold Kroto, James R. Heath, Sean O'Brien, Robert Curl, and Richard Smalley at Rice University, who recognized the structure of C60 as buckminsterfullerene. Concurrent but unconnected to the Kroto-Smalley work, astrophysicists were working with spectroscopists to study infrared emissions from giant red carbon stars. Smalley and team were able to use a laser vaporization technique to create carbon clusters which could potentially emit infrared at the same wavelength as had been emitted by the red carbon star. Hence, the inspiration came to Smalley and team to use the laser technique on graphite to generate fullerenes.",
                    "score": 0.8771680593490601
                },
                {
                    "id": 1067034,
                    "contents": "Buckminsterfullerene\nHistory of C60's discovery carried out by the Chemistry Department at Bristol University A brief overview of buckminsterfullerene described by the University of Wisconsin-Madison A report by Ming Kai College detailing the properties of buckminsterfullerene Donald R. Huffman and Wolfgang Krätschmer's paper pertaining to the synthesis of C60 in Nature published in 1990 A thorough description of C60 by the Oak Ridge National Laboratory An article about buckminsterfullerene on Connexions Science Encyclopaedia Extensive statistical data compiled by the University of Sussex on the numerical quantitative properties of buckminsterfullerene A web portal dedicated to buckminsterfullerene, authored and supported by the University of Bristol Another web portal dedicated to buckminsterfullerene, authored and supported by the Chemistry Department at the University of Bristol A brief article entirely devoted to C60 and its discovery, structure, production, properties, and applications",
                    "score": 0.876953125
                },
                {
                    "id": 1777006,
                    "contents": "Harry Kroto\nDiscovery of buckminsterfullerene In 1985, on the basis of the Sussex studies and the stellar discoveries, laboratory experiments (with co-workers James R. Heath, Sean C. O'Brien, Yuan Liu, Robert Curl and Richard Smalley at Rice University) which simulated the chemical reactions in the atmospheres of the red giant stars demonstrated that stable C60 molecules could form spontaneously from a condensing carbon vapour. The co-investigators directed lasers at graphite and examined the results. The C60 molecule is a molecule with the same symmetry pattern as a football, consisting of 12 pentagons and 20 hexagons of carbon atoms. Kroto named the molecule buckminsterfullerene, after Buckminster Fuller who had conceived of the geodesic domes, as the dome concept had provided a clue to the likely structure of the new species.",
                    "score": 0.8765019774436951
                },
                {
                    "id": 1067013,
                    "contents": "Buckminsterfullerene\nAnother paper on the characterization and verification of the molecular structure followed on in the same year (1990) from their thin film experiments, and detailed also the extraction of an evaporable as well as benzene soluble material from the arc-generated soot. This extract had TEM and X-ray crystal analysis consistent with arrays of spherical C60 molecules, approximately 1.0 nm in van der Waals diameter as well as the expected molecular mass of 720 Da for C60 (and 840 Da for C70) in their mass spectra. The method was simple and efficient to prepare the material in gram amounts per day (1990) which has boosted the fullerene research and is even today applied for the commercial production of fullerenes. The discovery of practical routes to C60 led to the exploration of a new field of chemistry involving the study of fullerenes.",
                    "score": 0.8736180067062378
                },
                {
                    "id": 24251662,
                    "contents": "Donald Huffman\nDonald R. Huffman (born 1935) is a Professor Emeritus of Physics at the University of Arizona. With Wolfgang Krätschmer, he developed a technique in 1990 for the simple production of large quantities of C60, or Buckminsterfullerene. Previously, in 1982~1983, he and Krätschmer had found, in a UV spectrum, the first signal of C60 ever observed. Huffman was featured prominently in the PBS Nova documentary, originally aired in 1995, \"Race to Catch a Buckyball\". Bibliography Bohren, Craig F. and Donald R. Huffman, Absorption and scattering of light by small particles, New York : Wiley, 1998, 530 p., , Awards Hewlett Packard Europhysics Prize, 1994 (with Wolfgang Kraetschmer, Harold Kroto and Richard Smalley) Materials Research Society, Gold Medal 1993, For Synthesis and Pioneering Study of Fullerenes Notes Living people 1935 births 21st-century American physicists Carbon scientists",
                    "score": 0.8730956315994263
                },
                {
                    "id": 19342654,
                    "contents": "C70 fullerene\nHistory Theoretical predictions of buckyball molecules appeared in the late 1960s to early 1970s, but they went largely unnoticed. In the early 1970s, the chemistry of unsaturated carbon configurations was studied by a group at the University of Sussex, led by Harry Kroto and David Walton. In the 1980s a technique was developed by Richard Smalley and Bob Curl at Rice University, Texas to isolate these substances. They used laser vaporization of a suitable target to produce clusters of atoms. Kroto realized that by using a graphite target.",
                    "score": 0.8729853630065918
                },
                {
                    "id": 1067010,
                    "contents": "Buckminsterfullerene\nC60 was discovered in 1985 by Robert Curl, Harold Kroto, and Richard Smalley. Using laser evaporation of graphite they found Cn clusters (where and even) of which the most common were C60 and C70. A solid rotating graphite disk was used as the surface from which carbon was vaporized using a laser beam creating hot plasma that was then passed through a stream of high-density helium gas. The carbon species were subsequently cooled and ionized resulting in the formation of clusters. Clusters ranged in molecular masses, but Kroto and Smalley found predominance in a C60 cluster that could be enhanced further by allowing the plasma to react longer. They also discovered that the C60 molecule formed a cage-like structure, a regular truncated icosahedron. Kroto, Curl and Smalley were awarded the 1996 Nobel Prize in Chemistry for their roles in the discovery of buckminsterfullerene and the related class of molecules, the fullerenes.",
                    "score": 0.8728251457214355
                },
                {
                    "id": 6706686,
                    "contents": "Endohedral fullerene\nNotation In a traditional chemical formula notation, a buckminsterfullerene (C60) with an atom (M) was simply represented as MC60 regardless of whether M was inside or outside the fullerene. In order to allow for more detailed discussions with minimal loss of information, a more explicit notation was proposed in 1991, where the atoms listed to the left of the @ sign are situated inside the network composed of the atoms listed to the right. The example above would then be denoted M@C60 if M were inside the carbon network. A more complex example is K2(K@C59B), which denotes \"a 60-atom fullerene cage with one boron atom substituted for a carbon in the geodesic network, a single potassium trapped inside, and two potassium atoms adhering to the outside.\"",
                    "score": 0.8696944713592529
                },
                {
                    "id": 19342653,
                    "contents": "C70 fullerene\n{{DISPLAYTITLE:C70 fullerene}} C70 fullerene is the fullerene molecule consisting of 70 carbon atoms. It is a cage-like fused-ring structure which resembles a rugby ball, made of 25 hexagons and 12 pentagons, with a carbon atom at the vertices of each polygon and a bond along each polygon edge. A related fullerene molecule, named buckminsterfullerene (C60 fullerene), consists of 60 carbon atoms. It was first intentionally prepared in 1985 by Harold Kroto, James R. Heath, Sean O'Brien, Robert Curl and Richard Smalley at Rice University. Kroto, Curl and Smalley were awarded the 1996 Nobel Prize in Chemistry for their roles in the discovery of cage-like fullerenes. The name is a homage to Buckminster Fuller, whose geodesic domes these molecules resemble. History",
                    "score": 0.8663867712020874
                },
                {
                    "id": 17552771,
                    "contents": "Molecular scale electronics\nbuckminsterfullerenes, buckyballs, or C60, the clusters retained some properties of graphite, such as conductivity. These objects were rapidly envisioned as possible building blocks for molecular electronics.",
                    "score": 0.8646177053451538
                },
                {
                    "id": 1712029,
                    "contents": "Fullerene\nIn 1973, independently from Henson, a group of scientists from the USSR made a quantum-chemical analysis of the stability of and calculated its electronic structure. The paper was published in 1973, but the scientific community did not give much importance to this theoretical prediction. Around 1980, Sumio Iijima identified the molecule of from an electron microscope image of carbon black, where it formed the core of a particle with the structure of a \"bucky onion\". Discovery of In 1985, Harold Kroto of the University of Sussex, working with James R. Heath, Sean O'Brien, Robert Curl and Richard Smalley from Rice University, discovered fullerenes in the sooty residue created by vaporising carbon in a helium atmosphere. In the mass spectrum of the product, discrete peaks appeared corresponding to molecules with the exact mass of sixty or seventy or more carbon atoms, namely and . The team identified their structure as the now familiar \"buckyballs\".",
                    "score": 0.862309992313385
                },
                {
                    "id": 1712030,
                    "contents": "Fullerene\nThe name \"buckminsterfullerene\" was eventually chosen for by the discoverers as an homage to American architect Buckminster Fuller for the vague similarity of the structure to the geodesic domes which he popularized; which, if they were extended to a full sphere, would also have the icosahedral symmetry group. The \"ene\" ending was chosen to indicate that the carbons are unsaturated, being connected to only three other atoms instead of the normal four. The shortened name \"fullerene\" eventually came to be applied to the whole family. Kroto, Curl, and Smalley were awarded the 1996 Nobel Prize in Chemistry for their roles in the discovery of this class of molecules. Further developments Kroto and the Rice team already discovered other fullerenes besides C60, and the list was much expanded in the following years. Carbon nanotubes were first discovered and synthesized in 1991.",
                    "score": 0.8589694499969482
                },
                {
                    "id": 1067014,
                    "contents": "Buckminsterfullerene\nThe discovery of practical routes to C60 led to the exploration of a new field of chemistry involving the study of fullerenes. Etymology The discoverers of the allotrope named the newfound molecule after Buckminster Fuller, who designed many geodesic dome structures that look similar to C60 and who had died in 1983, the year before discovery. This is slightly misleading, however, as Fuller's geodesic domes are constructed only by further dividing hexagons or pentagons into triangles, which are then deformed by moving vertices radially outward to fit the surface of a sphere. Geometrically speaking, buckminsterfullerene is a naturally-occurring example of a Goldberg polyhedron. A common, shortened name for buckminsterfullerene is buckyballs.",
                    "score": 0.8566833734512329
                },
                {
                    "id": 1712040,
                    "contents": "Fullerene\nA type of buckyball which uses boron atoms, instead of the usual carbon, was predicted and described in 2007. The structure, with each atom forming 5 or 6 bonds, was predicted to be more stable than the buckyball. However, subsequent analysis found that the predicted Ih symmetric structure was vibrationally unstable and the resulting cage would undergo a spontaneous symmetry break, yielding a puckered cage with rare Th symmetry (symmetry of a volleyball). The number of six-member rings in this molecule is 20 and number of five-member rings is 12. There is an additional atom in the center of each six-member ring, bonded to each atom surrounding it. By employing a systematic global search algorithm, it was later found that the previously proposed fullerene is not a global maximum for 80-atom boron clusters and hence can not be found in nature; the most stable configurations have complex . In the same paper by Sandip De et al., it was concluded that boron's energy landscape, unlike",
                    "score": 0.8549491167068481
                },
                {
                    "id": 1712035,
                    "contents": "Fullerene\nOther fullerenes Another fairly common fullerene has empirical formula , but fullerenes with 72, 76, 84 and even up to 100 carbon atoms are commonly obtained. The smallest possible fullerene is the dodecahedral . There are no fullerenes with 22 vertices. The number of different fullerenes C2n grows with increasing n = 12, 13, 14, ..., roughly in proportion to n9 . For instance, there are 1812 non-isomorphic fullerenes . Note that only one form of , buckminsterfullerene, has no pair of adjacent pentagons (the smallest such fullerene). To further illustrate the growth, there are 214,127,713 non-isomorphic fullerenes , 15,655,672 of which have no adjacent pentagons. Optimized structures of many fullerene isomers are published and listed on the web.",
                    "score": 0.8539539575576782
                },
                {
                    "id": 1067008,
                    "contents": "Buckminsterfullerene\nBuckminsterfullerene is a type of fullerene with the formula C60. It has a cage-like fused-ring structure (truncated icosahedron) that resembles a football (association football) as, it is made of twenty hexagons and twelve pentagons. Each carbon atom has three bonds. It is a black solid that dissolves in hydrocarbon solvents to produce a violet solution. The compound has received intense study, although few real world applications have been found. Occurrence Buckminsterfullerene is the most common naturally occurring fullerene. Small quantities of it can be found in soot. It also exists in space. Neutral C60 has been observed in planetary nebulae and several types of star. The ionised form, C60+, has been identified in the interstellar medium and is the carrier of several diffuse interstellar bands. History",
                    "score": 0.8535287380218506
                },
                {
                    "id": 1067019,
                    "contents": "Buckminsterfullerene\ncrystallises with some solvents in the lattice (\"solvates\"). For example, crystallization of C60 in benzene solution yields triclinic crystals with the formula C60·4C6H6. Like other solvates, this one readily releases benzene to give the usual fcc C60. Millimeter-sized crystals of C60 and can be grown from solution both for solvates and for pure fullerenes. Solid In solid buckminsterfullerene, the C60 molecules adopt the fcc (face-centered cubic) motif. They start rotating at about −20 °C. This change is associated with a first-order phase transition to an fcc structure and a small, yet abrupt increase in the lattice constant from 1.411 to 1.4154 nm. solid is as soft as graphite, but when compressed to less than 70% of its volume it transforms into a superhard form of diamond (see aggregated diamond nanorod). films and solution have strong non-linear optical properties; in particular, their optical absorption increases with light intensity (saturable absorption).",
                    "score": 0.8530022501945496
                },
                {
                    "id": 1067035,
                    "contents": "Buckminsterfullerene\nA brief article entirely devoted to C60 and its discovery, structure, production, properties, and applications American Chemical Society's complete article on buckminsterfullerene Buckminsterfullerene at The Periodic Table of Videos (University of Nottingham)",
                    "score": 0.8524608016014099
                },
                {
                    "id": 1712052,
                    "contents": "Fullerene\nSolutions of pure buckminsterfullerene have a deep purple color. Solutions of are a reddish brown. The higher fullerenes to have a variety of colors. Millimeter-sized crystals of and , both pure and solvated, can be grown from benzene solution. Crystallization of from benzene solution below 30 °C (when solubility is maximum) yields a triclinic solid solvate ·4. Above 30 °C one obtains solvate-free fcc . Quantum mechanics In 1999, researchers from the University of Vienna demonstrated that wave-particle duality applied to molecules such as fullerene. Superconductivity Fullerenes are normally electrical insulators, but when crystallized with alkali metals, the resultant compound can be conducting or even superconducting. Chirality Some fullerenes (e.g. , , , and ) are inherently chiral because they are D2-symmetric, and have been successfully resolved. Research efforts are ongoing to develop specific sensors for their enantiomers.",
                    "score": 0.8518860340118408
                },
                {
                    "id": 1605247,
                    "contents": "Buckminster Fuller\nConcepts and buildings His concepts and buildings include: Influence and legacy Among the many people who were influenced by Buckminster Fuller are: Constance Abernathy, Ruth Asawa, J. Baldwin, Michael Ben-Eli, Pierre Cabrol, John Cage, Joseph Clinton, Peter Floyd, Norman Foster, Medard Gabel, Michael Hays, Ted Nelson, David Johnston, Peter Jon Pearce, Shoji Sadao, Edwin Schlossberg, Kenneth Snelson, Robert Anton Wilson, Stewart Brand, and Jason McLennan. An allotrope of carbon, fullerene—and a particular molecule of that allotrope C60 (buckminsterfullerene or buckyball) has been named after him. The Buckminsterfullerene molecule, which consists of 60 carbon atoms, very closely resembles a spherical version of Fuller's geodesic dome. The 1996 Nobel prize in chemistry was given to Kroto, Curl, and Smalley for their discovery of the fullerene. He is quoted in the lyric of \"The Tower of Babble\" in the musical Godspell: \"Man is a complex of patterns and processes.\"",
                    "score": 0.8512899875640869
                },
                {
                    "id": 1067020,
                    "contents": "Buckminsterfullerene\nforms a brownish solid with an optical absorption threshold at ≈1.6 eV. It is an n-type semiconductor with a low activation energy of 0.1–0.3 eV; this conductivity is attributed to intrinsic or oxygen-related defects. Fcc C60 contains voids at its octahedral and tetrahedral sites which are sufficiently large (0.6 and 0.2 nm respectively) to accommodate impurity atoms. When alkali metals are doped into these voids, C60 converts from a semiconductor into a conductor or even superconductor. Chemical reactions and properties",
                    "score": 0.850887656211853
                },
                {
                    "id": 1067018,
                    "contents": "Buckminsterfullerene\nA carbon atom in the molecule can be substituted by a nitrogen or boron atom yielding a or C59B respectively. Solution Fullerenes are sparingly soluble in aromatic solvents and carbon disulfide, but insoluble in water. Solutions of pure C60 have a deep purple color which leaves a brown residue upon evaporation. The reason for this color change is the relatively narrow energy width of the band of molecular levels responsible for green light absorption by individual C60 molecules. Thus individual molecules transmit some blue and red light resulting in a purple color. Upon drying, intermolecular interaction results in the overlap and broadening of the energy bands, thereby eliminating the blue light transmittance and causing the purple to brown color change.",
                    "score": 0.8502587676048279
                },
                {
                    "id": 1712028,
                    "contents": "Fullerene\nHistory Predictions and limited observations The icosahedral cage was mentioned in 1965 as a possible topological structure. Eiji Osawa predicted the existence of in 1970. He noticed that the structure of a corannulene molecule was a subset of the shape of a football, and hypothesised that a full ball shape could also exist. Japanese scientific journals reported his idea, but neither it nor any translations of it reached Europe or the Americas. Also in 1970, R. W. Henson (then of the UK Atomic Energy Research Establishment) proposed the structure and made a model of it. Unfortunately, the evidence for that new form of carbon was very weak at the time, so the proposal was met with skepticism, and was never published. It was acknowledged only in 1999.",
                    "score": 0.849504828453064
                },
                {
                    "id": 10834712,
                    "contents": "Fullerene chemistry\nThe double bonds in fullerene are not all the same. Two groups can be identified: 30 so-called [6,6] double bonds connect two hexagons and 60 [5,6] bonds connect a hexagon and a pentagon. Of the two the [6,6] bonds are shorter with more double-bond character and therefore a hexagon is often represented as a cyclohexatriene and a pentagon as a pentalene or [5]radialene. In other words, although the carbon atoms in fullerene are all conjugated the superstructure is not a super aromatic compound. The X-ray diffraction bond length values are 139.1 pm for the [6,6] bond and 145.5 pm for the [5,6] bond. C60 fullerene has 60 π electrons but a closed shell configuration requires 72 electrons. The fullerene is able to acquire the missing electrons by reaction with potassium to form first the salt and then the In this compound the bond length alternation observed in the parent molecule has vanished. Fullerene reactions",
                    "score": 0.8489969372749329
                },
                {
                    "id": 9286169,
                    "contents": "Chamfered dodecahedron\nThe hexagon faces can be equilateral but not regular with D2 symmetry. The angles at the two vertices with vertex configuration 6.6.6 are arccos(-1/sqrt(5)) = 116.565°, and at the remaining four vertices with 5.6.6, they are 121.717° each. It is the Goldberg polyhedron GV(2,0), containing pentagonal and hexagonal faces. It also represents the exterior envelope of a cell-centered orthogonal projection of the 120-cell, one of six (convex regular 4-polytopes). Chemistry This is the shape of the fullerene C80 ; sometimes this shape is denoted C80(Ih) to describe its icosahedral symmetry and distinguish it from other less-symmetric 80-vertex fullerenes. It is one of only four fullerenes found by to have a skeleton that can be isometrically embeddable into an L1 space. Related polyhedra This polyhedron looks very similar to the uniform truncated icosahedron which has 12 pentagons, but only 20 hexagons.",
                    "score": 0.8486322164535522
                },
                {
                    "id": 2778949,
                    "contents": "Particle in a ring\nThis simple model can be used to find approximate energy levels of some ring molecules, such as benzene. Application In organic chemistry, aromatic compounds contain atomic rings, such as benzene rings (the Kekulé structure) consisting of five or six, usually carbon, atoms. So does the surface of \"buckyballs\" (buckminsterfullerene). This ring behaves like a circular waveguide, with the valence electrons orbiting in both directions. To fill all energy levels up to n requires electrons, as electrons have additionally two possible orientations of their spins. This gives exceptional stability (\"aromatic\"), and is known as the Hückel's rule. Further in rotational spectroscopy this model may be used as an approximation of rotational energy levels. See also Angular momentum Harmonic analysis One-dimensional periodic case Semicircular potential well Spherical potential well Quantum models",
                    "score": 0.8463615775108337
                },
                {
                    "id": 1067011,
                    "contents": "Buckminsterfullerene\nKroto, Curl and Smalley were awarded the 1996 Nobel Prize in Chemistry for their roles in the discovery of buckminsterfullerene and the related class of molecules, the fullerenes. The experimental evidence, a strong peak at 720 atomic mass units, indicated that a carbon molecule with 60 carbon atoms was forming, but provided no structural information. The research group concluded after reactivity experiments, that the most likely structure was a spheroidal molecule. The idea was quickly rationalized as the basis of an icosahedral symmetry closed cage structure. Kroto mentioned geodesic dome structures of the noted futurist and inventor Buckminster Fuller as influences in the naming of this particular substance as buckminsterfullerene.",
                    "score": 0.8452894687652588
                },
                {
                    "id": 7369019,
                    "contents": "Jack Linnett\nOctet rule In 1960, Linnett originated a modification to the octet rule, originally proposed by Lewis, concerning valence electrons. He proposed that the octet should be considered as a double quartet of electrons rather than as four pairs, and hence the theory became known as \"Linnett double-quartet theory\". Using this method, he was able to explain the stability of 'odd electron' molecules such as nitric oxide and oxygen. This theory was set out in a book \"The Electronic Structure of Molecules: A New Approach\", published by Methuen & Co Ltd, London, 1964. His general book \"Wave Mechanics and Valency\" also published by Methuen & Co Ltd, London, appeared in 1960. Death He died of a heart attack in the Athenaeum Club, London, on 7 November 1975, only five weeks after ceasing to be Vice-Chancellor of the University of Cambridge. The John Wilfrid Linnett Visiting Professor of Chemistry was established in his memory in 1993 at the University of Cambridge. References",
                    "score": 0.8448712825775146
                },
                {
                    "id": 8348821,
                    "contents": "Hofstadter's butterfly\nTheoretical model In his original paper, Hofstadter considers the following derivation: a charged quantum particle in a two-dimensional square lattice, with a lattice spacing , is described by a periodic Schrödinger equation, under a perpendicular static homogeneous magnetic field restricted to a single Bloch band. For a 2D square lattice, the tight binding energy dispersion relation is , where is the energy function, is the crystal momentum, and is an empirical parameter. The magnetic field , where the magnetic vector potential, can be taken into account by using Peierls substitution, replacing the crystal momentum with the canonical momentum , where is the particle momentum operator and is the charge of the particle ( for the electron, is the elementary charge). For convenience we choose the gauge .",
                    "score": 0.844154417514801
                },
                {
                    "id": 1712048,
                    "contents": "Fullerene\nA spherical fullerene of n carbon atoms has n pi-bonding electrons, free to delocalize. These should try to delocalize over the whole molecule. The quantum mechanics of such an arrangement should be like only one shell of the well-known quantum mechanical structure of a single atom, with a stable filled shell for n = 2, 8, 18, 32, 50, 72, 98, 128, etc. (i.e., twice a perfect square number), but this series does not include 60. This 2(N + 1)2 rule (with N integer) for spherical aromaticity is the three-dimensional analogue of Hückel's rule. The 10+ cation would satisfy this rule, and should be aromatic. This has been shown to be the case using quantum chemical modelling, which showed the existence of strong diamagnetic sphere currents in the cation. As a result, in water tends to pick up two more electrons and become an anion. The n described below may be the result of trying to form a loose metallic bond. Reactions",
                    "score": 0.843897819519043
                },
                {
                    "id": 1712045,
                    "contents": "Fullerene\nThe Schlegel diagram of a closed fullerene is a graph that is planar and 3-regular (or \"cubic\"; meaning that all vertices have degree 3). A closed fullerene with sphere-like shell must have at least some cycles that are pentagons or heptagons. More precisely, if all the faces have 5 or 6 sides, it follows from Euler's polyhedron formula, V−E+F=2 (where V, E, F are the numbers of vertices, edges, and faces), that V must be even, and that there must be exactly 12 pentagons and V/2−10 hexagons. Similar constraints exist if the fullerene has heptagonal (seven-atom) cycles. Open fullerenes, like carbon nanotubes and graphene, can consist entirely of hexagonal rings. In theory, a long nanotube with ends joined to form a closed torus-like sheet could also consist entirely of hexagons.",
                    "score": 0.8433774709701538
                },
                {
                    "id": 5330404,
                    "contents": "Jellium\nThe jellium model has been applied to superatoms, metal clusters, octacarbonyl complexes, and used in nuclear physics. See also Free electron model — a model electron gas where the electrons do not interact with anything. Nearly free electron model — a model electron gas where the electrons do not interact with each other, but do feel a (weak) potential from the atomic lattice. References Condensed matter physics Density functional theory Nuclear physics",
                    "score": 0.8427245616912842
                },
                {
                    "id": 2742922,
                    "contents": "Butadiene\nA qualitative picture of the molecular orbitals of 1,3-butadiene is readily obtained by applying Hückel theory. (The article on Hückel theory gives a derivation for the butadiene orbitals.) 1,3-Butadiene is also thermodynamically stabilized. While a monosubstituted double bond releases about 30.3 kcal/mol of heat upon hydrogenation, 1,3-butadiene releases slightly less (57.1 kcal/mol) than twice this energy (60.6 kcal/mol), expected for two isolated double bonds. That implies a stabilization energy of 3.5 kcal/mol. Similarly, the hydrogenation of the terminal double bond of 1,4-pentadiene releases 30.1 kcal/mol of heat, while hydrogenation of the terminal double bond of conjugated (E)-1,3-pentadiene releases only 26.5 kcal/mol, implying a very similar value of 3.6 kcal/mol for the stabilization energy. The ~3.5 kcal/mol difference in these heats of hydrogenation can be taken to be the resonance energy of a conjugated diene.",
                    "score": 0.8411687612533569
                },
                {
                    "id": 16139173,
                    "contents": "Walsh diagram\nIn his publications, Walsh showed through multiple examples that the geometry adopted by a molecule in its ground state primarily depends on the number of its valence electrons. He himself acknowledged that this general concept was not novel, but explained that the new data available to him allowed the previous generalizations to be expanded upon and honed. He also noted that Mulliken had previously attempted to construct a correlation diagram for the possible orbitals of a polyatomic molecule in two different nuclear configurations, and had even tried to use this diagram to explain shapes and spectra of molecules in their ground and excited states. However, Mulliken was unable to explain the reasons for the rises and falls of certain curves with increases in angle, thus Walsh claimed \"his diagram was either empirical or based upon unpublished computations.\"",
                    "score": 0.8404206037521362
                },
                {
                    "id": 29172249,
                    "contents": "Charles Rugeley Bury\nIn 1921 Bury proposed a model of the atom which suggested that electrons were distributed symmetrically over the surface of concentric spheres which could hold 2, 8, 18, and 32 electrons. He proposed that an outer layer of electrons can contain a maximum of 8 electrons (s2p6 in modern notation), and that for inner layers there occurs a transition series of elements during the change from 8 to 18 (or 18 to 32) electrons. This was the first use of the word transition in the context of electron configurations. In July 1943, Bury moved to the Imperial Chemical Industries to worked with colleague M.P. Appleby and retired from there in 1952. His other works were on the chemistry of colour, freezing points, and on micelles. He married Margaret Adams in 1922 and they had a son and a daughter. References 1890 births 1968 deaths English chemists",
                    "score": 0.8402230739593506
                },
                {
                    "id": 92614,
                    "contents": "Ground state\nThe wave function of the ground state of a particle in a one-dimensional box is a half-period sine wave, which goes to zero at the two edges of the well. The energy of the particle is given by , where h is the Planck constant, m is the mass of the particle, n is the energy state (n = 1 corresponds to the ground-state energy), and L is the width of the well. The wave function of the ground state of a hydrogen atom is a spherically symmetric distribution centred on the nucleus, which is largest at the center and reduces exponentially at larger distances. The electron is most likely to be found at a distance from the nucleus equal to the Bohr radius. This function is known as the 1s atomic orbital. For hydrogen (H), an electron in the ground state has energy , relative to the ionization threshold. In other words, 13.6 eV is the energy input required for the electron to no longer be bound to the atom.",
                    "score": 0.839667558670044
                },
                {
                    "id": 11167222,
                    "contents": "History of molecular theory\nMoreover, noting that a cube has eight corners Lewis envisioned an atom as having eight sides available for electrons, like the corner of a cube. Subsequently, in 1902 he devised a conception in which cubic atoms can bond on their sides to form cubic-structured molecules. In other words, electron-pair bonds are formed when two atoms share an edge, as in structure C below. This results in the sharing of two electrons. Similarly, charged ionic-bonds are formed by the transfer of an electron from one cube to another, without sharing an edge A. An intermediate state B where only one corner is shared was also postulated by Lewis. Hence, double bonds are formed by sharing a face between two cubic atoms. This results in the sharing of four electrons.",
                    "score": 0.8395081758499146
                },
                {
                    "id": 1644431,
                    "contents": "Cuboctahedron\nThe cuboctahedron was probably known to Plato: Heron's Definitiones quotes Archimedes as saying that Plato knew of a solid made of 8 triangles and 6 squares. Other names Heptaparallelohedron (Buckminster Fuller) Fuller applied the name \"Dymaxion\" to this shape, used in an early version of the Dymaxion map. He also called it the \"Vector Equilibrium\" because of its radial equilateral symmetry (its center-to-vertex radius equals its edge length). He called a cuboctahedron consisting of rigid struts connected by flexible vertices a \"jitterbug\" (this shape can be progressively deformed into an icosahedron, octahedron, and tetrahedron by collapsing its square sides). With Oh symmetry, order 48, it is a rectified cube or rectified octahedron (Norman Johnson) With Td symmetry, order 24, it is a cantellated tetrahedron or rhombitetratetrahedron. With D3d symmetry, order 12, it is a triangular gyrobicupola.",
                    "score": 0.839282214641571
                },
                {
                    "id": 16459893,
                    "contents": "Nuclear magnetic resonance\nAn example of nuclear magnetic resonance being used in the determination of a structure is that of buckminsterfullerene (often called \"buckyballs\", composition C60). This now famous form of carbon has 60 carbon atoms forming a sphere. The carbon atoms are all in identical environments and so should see the same internal H field. Unfortunately, buckminsterfullerene contains no hydrogen and so nuclear magnetic resonance has to be used. spectra require longer acquisition times since carbon-13 is not the common isotope of carbon (unlike hydrogen, where is the common isotope). However, in 1990 the spectrum was obtained by R. Taylor and co-workers at the University of Sussex and was found to contain a single peak, confirming the unusual structure of buckminsterfullerene.",
                    "score": 0.8384573459625244
                },
                {
                    "id": 19342657,
                    "contents": "C70 fullerene\nProperties Molecule The C70 molecule has a D5h symmetry and contains 37 faces (25 hexagons and 12 pentagons) with a carbon atom at the vertices of each polygon and a bond along each polygon edge. Its structure is similar to that of C60 molecule (20 hexagons and 12 pentagons), but has a belt of 5 hexagons inserted at the equator. The molecule has eight bond lengths ranging between 0.137 and 0.146 nm. Each carbon atom in the structure is bonded covalently with 3 others. C70 can undergo six reversible, one-electron reductions to , whereas oxidation is irreversible. The first reduction requires around 1.0 V (Fc/), indicating that C70 is an electron acceptor. Solution Fullerenes are sparingly soluble in many aromatic solvents such as toluene and others like carbon disulfide, but not in water. Solutions of C70 are a reddish brown. Millimeter-sized crystals of C70 can be grown from solution. Solid",
                    "score": 0.8384543061256409
                },
                {
                    "id": 1712043,
                    "contents": "Fullerene\nIn the table, \"Num.Isom.\" is the number of possible isomers within the \"isolated pentagon rule\", which states that two pentagons in a fullerene should not share edges. \"Mol.Symm.\" is the symmetry of the molecule, whereas \"Cryst.Symm.\" is that of the crystalline framework in the solid state. Both are specified for the most experimentally abundant form(s). The asterisk * marks symmetries with more than one chiral form. When or crystals are grown from toluene solution they have a monoclinic symmetry. The crystal structure contains toluene molecules packed between the spheres of the fullerene. However, evaporation of the solvent from transforms it into a face-centered cubic form. Both monoclinic and face-centered cubic (fcc) phases are known for better-characterized and fullerenes. Properties Topology Schlegel diagrams are often used to clarify the 3D structure of closed-shell fullerenes, as 2D projections are often not ideal in this sense.",
                    "score": 0.8363544940948486
                },
                {
                    "id": 1620516,
                    "contents": "Bohr model\n“From the above we are led to the following possible scheme for the arrangement of the electrons in light atoms: Periodic table of Bohr in 1913 showing electron configurations in his second paper where he went to the 24th element. In Bohr’s third 1913 paper Part III called systems containing several nuclei, he says that two atoms form molecules on a symmetrical plane and he reverts to describing Hydrogen. The 1913 Bohr model did not discuss higher elements in detail and John William Nicholson was one of the first to prove in 1914 that it couldn’t work for Lithium, but was an attractive theory for Hydrogen and ionized helium.",
                    "score": 0.8363286852836609
                },
                {
                    "id": 1356079,
                    "contents": "1985\nDate unknown The fullerene Buckminsterfullerene (C60) is first intentionally prepared by Harold Kroto, James R. Heath, Sean O'Brien, Robert Curl and Richard Smalley at Rice University in the US. DNA is first used in a criminal case. The Asian tiger mosquito, an invasive species, is first found in Houston, Texas. The Tommy Hilfiger clothing brand is established in the United States. Multiple cases of espionage in the US prompt the media to label this \"The Year of the Spy\". The 1983–85 famine in Ethiopia continues; USA for Africa (We Are the World) and Live Aid raise funds for famine relief. Africa has a population growth of 3.2 percent per year. World population Births January",
                    "score": 0.8361334204673767
                },
                {
                    "id": 4449492,
                    "contents": "Sigma bond\nThis rule fails in the case of molecules which, when drawn flat on paper, have a different number of rings than the molecule actually has - for example, Buckminsterfullerene, C60, which has 32 rings, 60 atoms, and 90 sigma bonds, one for each pair of bonded atoms; however, 60 + 32 - 1 = 91, not 90. This is because the sigma rule is a special case of the Euler characteristic, where each ring is considered a face, each sigma bond is an edge, and each atom is a vertex. Ordinarily, one extra face is assigned to the space not inside any ring, but when Buckminsterfullerene is drawn flat without any crossings, one of the rings makes up the outer pentagon; the inside of that ring is the outside of the graph. This rule fails further when considering other shapes - toroidal fullerenes will obey the rule that the number of sigma bonds in a molecule is exactly the number of atoms plus the number of rings, as will nanotubes - which, when drawn flat as if looking through one from the end, will have",
                    "score": 0.8353104591369629
                },
                {
                    "id": 27692711,
                    "contents": "David Tománek\nDavid Tománek (born July 1954) is a U.S.-Swiss physicist of Czech origin and researcher in nanoscience and nanotechnology. He is Emeritus Professor of Physics at Michigan State University. He is known for predicting the structure and calculating properties of surfaces, atomic clusters including the C60 buckminsterfullerene, nanotubes, nanowires and nanohelices, graphene, and two-dimensional materials including phosphorene.",
                    "score": 0.8345714211463928
                }
            ],
            "metric_score": {
                "retrieval_recall": 0,
                "retrieval_precision": 0.0
            }
        }
    }
]